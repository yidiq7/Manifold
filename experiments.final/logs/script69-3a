+ RUN=3
+ export CUDA_VISIBLE_DEVICES=3
+ CUDA_VISIBLE_DEVICES=3
+ LAYERS='300_300_300_1 500_500_500_500_1'
+ case $RUN in
+ PSI='2 3'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output61
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output69
+ for fn in f1
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0
+ date
Mon Oct 26 09:07:24 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814fd6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f581500af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5815049b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5815049d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f581503f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814f50840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814f39840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814f50bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f581503f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f581503f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814eeb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814e6de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814e0d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814e31268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814e0d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814e31400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814e0dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814d3c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814cfc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814d29e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814d29ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814cc3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814cc3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814d29048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814c5a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814c5a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814c2c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814c76730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814bf32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814b9fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814b9ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814b77378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5814b57510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57e36c56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57e3656ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57e36c5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.30563603e-05
Iter: 2 loss: 1.30370699e-05
Iter: 3 loss: 1.10488891e-05
Iter: 4 loss: 1.05293439e-05
Iter: 5 loss: 9.95202e-06
Iter: 6 loss: 9.87090152e-06
Iter: 7 loss: 9.620534e-06
Iter: 8 loss: 9.5862506e-06
Iter: 9 loss: 9.41246253e-06
Iter: 10 loss: 9.0315516e-06
Iter: 11 loss: 1.46547218e-05
Iter: 12 loss: 9.01484782e-06
Iter: 13 loss: 8.62677916e-06
Iter: 14 loss: 1.19863289e-05
Iter: 15 loss: 8.60588261e-06
Iter: 16 loss: 8.46305375e-06
Iter: 17 loss: 8.46304283e-06
Iter: 18 loss: 8.31655234e-06
Iter: 19 loss: 7.95823144e-06
Iter: 20 loss: 1.16485699e-05
Iter: 21 loss: 7.91598541e-06
Iter: 22 loss: 7.60147168e-06
Iter: 23 loss: 9.33624324e-06
Iter: 24 loss: 7.55593919e-06
Iter: 25 loss: 7.49694e-06
Iter: 26 loss: 7.42752854e-06
Iter: 27 loss: 7.38455219e-06
Iter: 28 loss: 7.26472535e-06
Iter: 29 loss: 7.91028833e-06
Iter: 30 loss: 7.22758614e-06
Iter: 31 loss: 7.07817844e-06
Iter: 32 loss: 7.26542885e-06
Iter: 33 loss: 7.00094461e-06
Iter: 34 loss: 6.8103991e-06
Iter: 35 loss: 6.93966604e-06
Iter: 36 loss: 6.69096562e-06
Iter: 37 loss: 6.4519204e-06
Iter: 38 loss: 7.96819131e-06
Iter: 39 loss: 6.42499162e-06
Iter: 40 loss: 6.40946382e-06
Iter: 41 loss: 6.36409959e-06
Iter: 42 loss: 6.29939768e-06
Iter: 43 loss: 6.37421635e-06
Iter: 44 loss: 6.26483688e-06
Iter: 45 loss: 6.22724156e-06
Iter: 46 loss: 6.31437251e-06
Iter: 47 loss: 6.21327035e-06
Iter: 48 loss: 6.14696228e-06
Iter: 49 loss: 6.05845162e-06
Iter: 50 loss: 6.05353034e-06
Iter: 51 loss: 5.97142571e-06
Iter: 52 loss: 6.38494294e-06
Iter: 53 loss: 5.95774281e-06
Iter: 54 loss: 5.88256717e-06
Iter: 55 loss: 6.08147684e-06
Iter: 56 loss: 5.8573446e-06
Iter: 57 loss: 5.77426181e-06
Iter: 58 loss: 6.38836718e-06
Iter: 59 loss: 5.76761522e-06
Iter: 60 loss: 5.72784893e-06
Iter: 61 loss: 5.66442122e-06
Iter: 62 loss: 5.6639e-06
Iter: 63 loss: 5.63646336e-06
Iter: 64 loss: 5.63145204e-06
Iter: 65 loss: 5.59582077e-06
Iter: 66 loss: 5.56105351e-06
Iter: 67 loss: 5.55343468e-06
Iter: 68 loss: 5.51105813e-06
Iter: 69 loss: 5.41031523e-06
Iter: 70 loss: 6.54729411e-06
Iter: 71 loss: 5.40076417e-06
Iter: 72 loss: 5.35403342e-06
Iter: 73 loss: 5.34607352e-06
Iter: 74 loss: 5.34861e-06
Iter: 75 loss: 5.32959939e-06
Iter: 76 loss: 5.31712112e-06
Iter: 77 loss: 5.28738246e-06
Iter: 78 loss: 5.62209652e-06
Iter: 79 loss: 5.28453347e-06
Iter: 80 loss: 5.27584325e-06
Iter: 81 loss: 5.26999384e-06
Iter: 82 loss: 5.25830092e-06
Iter: 83 loss: 5.24446386e-06
Iter: 84 loss: 5.24296684e-06
Iter: 85 loss: 5.21893344e-06
Iter: 86 loss: 5.21364927e-06
Iter: 87 loss: 5.19806963e-06
Iter: 88 loss: 5.16715681e-06
Iter: 89 loss: 5.49746164e-06
Iter: 90 loss: 5.166356e-06
Iter: 91 loss: 5.14389058e-06
Iter: 92 loss: 5.11052895e-06
Iter: 93 loss: 5.10978225e-06
Iter: 94 loss: 5.08392532e-06
Iter: 95 loss: 5.2935211e-06
Iter: 96 loss: 5.08220273e-06
Iter: 97 loss: 5.06011838e-06
Iter: 98 loss: 5.23840481e-06
Iter: 99 loss: 5.05865864e-06
Iter: 100 loss: 5.0453873e-06
Iter: 101 loss: 5.0058793e-06
Iter: 102 loss: 5.13480609e-06
Iter: 103 loss: 4.98697909e-06
Iter: 104 loss: 4.9362643e-06
Iter: 105 loss: 5.08854191e-06
Iter: 106 loss: 4.92089384e-06
Iter: 107 loss: 4.89357308e-06
Iter: 108 loss: 4.88968726e-06
Iter: 109 loss: 4.8614429e-06
Iter: 110 loss: 5.06394736e-06
Iter: 111 loss: 4.85900637e-06
Iter: 112 loss: 4.8499237e-06
Iter: 113 loss: 4.84117299e-06
Iter: 114 loss: 4.83920849e-06
Iter: 115 loss: 4.81904954e-06
Iter: 116 loss: 4.92144909e-06
Iter: 117 loss: 4.81575807e-06
Iter: 118 loss: 4.80356539e-06
Iter: 119 loss: 4.80027e-06
Iter: 120 loss: 4.79279151e-06
Iter: 121 loss: 4.77028152e-06
Iter: 122 loss: 4.84074417e-06
Iter: 123 loss: 4.76380046e-06
Iter: 124 loss: 4.73920409e-06
Iter: 125 loss: 4.79131268e-06
Iter: 126 loss: 4.72947295e-06
Iter: 127 loss: 4.71231806e-06
Iter: 128 loss: 4.69574616e-06
Iter: 129 loss: 4.69186944e-06
Iter: 130 loss: 4.67832069e-06
Iter: 131 loss: 4.67516065e-06
Iter: 132 loss: 4.66160782e-06
Iter: 133 loss: 4.64085861e-06
Iter: 134 loss: 4.64055e-06
Iter: 135 loss: 4.62547769e-06
Iter: 136 loss: 4.59956755e-06
Iter: 137 loss: 4.59956573e-06
Iter: 138 loss: 4.56381895e-06
Iter: 139 loss: 4.77275807e-06
Iter: 140 loss: 4.55918507e-06
Iter: 141 loss: 4.58285376e-06
Iter: 142 loss: 4.54916153e-06
Iter: 143 loss: 4.54349447e-06
Iter: 144 loss: 4.5302686e-06
Iter: 145 loss: 4.69181396e-06
Iter: 146 loss: 4.52921813e-06
Iter: 147 loss: 4.52317727e-06
Iter: 148 loss: 4.52253153e-06
Iter: 149 loss: 4.5151437e-06
Iter: 150 loss: 4.49547588e-06
Iter: 151 loss: 4.63450715e-06
Iter: 152 loss: 4.49113668e-06
Iter: 153 loss: 4.48344827e-06
Iter: 154 loss: 4.47962702e-06
Iter: 155 loss: 4.47279126e-06
Iter: 156 loss: 4.45491378e-06
Iter: 157 loss: 4.59462944e-06
Iter: 158 loss: 4.45145861e-06
Iter: 159 loss: 4.42859346e-06
Iter: 160 loss: 4.51688629e-06
Iter: 161 loss: 4.42330202e-06
Iter: 162 loss: 4.40499844e-06
Iter: 163 loss: 4.58558225e-06
Iter: 164 loss: 4.40439e-06
Iter: 165 loss: 4.39632277e-06
Iter: 166 loss: 4.38362167e-06
Iter: 167 loss: 4.38350435e-06
Iter: 168 loss: 4.37500694e-06
Iter: 169 loss: 4.37356493e-06
Iter: 170 loss: 4.36109713e-06
Iter: 171 loss: 4.33422429e-06
Iter: 172 loss: 4.75094203e-06
Iter: 173 loss: 4.33319383e-06
Iter: 174 loss: 4.31371427e-06
Iter: 175 loss: 4.35398124e-06
Iter: 176 loss: 4.30602859e-06
Iter: 177 loss: 4.30991486e-06
Iter: 178 loss: 4.29872671e-06
Iter: 179 loss: 4.29187094e-06
Iter: 180 loss: 4.27629e-06
Iter: 181 loss: 4.4842136e-06
Iter: 182 loss: 4.27536179e-06
Iter: 183 loss: 4.27103532e-06
Iter: 184 loss: 4.26990846e-06
Iter: 185 loss: 4.26387396e-06
Iter: 186 loss: 4.2491547e-06
Iter: 187 loss: 4.3965747e-06
Iter: 188 loss: 4.24724203e-06
Iter: 189 loss: 4.23033271e-06
Iter: 190 loss: 4.33238529e-06
Iter: 191 loss: 4.22826361e-06
Iter: 192 loss: 4.20957349e-06
Iter: 193 loss: 4.28485509e-06
Iter: 194 loss: 4.20539209e-06
Iter: 195 loss: 4.19854041e-06
Iter: 196 loss: 4.19679418e-06
Iter: 197 loss: 4.19247181e-06
Iter: 198 loss: 4.1828e-06
Iter: 199 loss: 4.24257678e-06
Iter: 200 loss: 4.18165837e-06
Iter: 201 loss: 4.17439651e-06
Iter: 202 loss: 4.18771424e-06
Iter: 203 loss: 4.17126466e-06
Iter: 204 loss: 4.16076819e-06
Iter: 205 loss: 4.21376672e-06
Iter: 206 loss: 4.15903651e-06
Iter: 207 loss: 4.15333125e-06
Iter: 208 loss: 4.13784e-06
Iter: 209 loss: 4.23059282e-06
Iter: 210 loss: 4.13352973e-06
Iter: 211 loss: 4.1188764e-06
Iter: 212 loss: 4.11878955e-06
Iter: 213 loss: 4.10362327e-06
Iter: 214 loss: 4.20529432e-06
Iter: 215 loss: 4.1020744e-06
Iter: 216 loss: 4.0983914e-06
Iter: 217 loss: 4.09384211e-06
Iter: 218 loss: 4.09341692e-06
Iter: 219 loss: 4.08656433e-06
Iter: 220 loss: 4.17060846e-06
Iter: 221 loss: 4.08651385e-06
Iter: 222 loss: 4.08242613e-06
Iter: 223 loss: 4.07208881e-06
Iter: 224 loss: 4.15633895e-06
Iter: 225 loss: 4.07026937e-06
Iter: 226 loss: 4.06405888e-06
Iter: 227 loss: 4.06208665e-06
Iter: 228 loss: 4.05794526e-06
Iter: 229 loss: 4.0487048e-06
Iter: 230 loss: 4.17748379e-06
Iter: 231 loss: 4.04815546e-06
Iter: 232 loss: 4.03573495e-06
Iter: 233 loss: 4.09552786e-06
Iter: 234 loss: 4.03344e-06
Iter: 235 loss: 4.02343494e-06
Iter: 236 loss: 4.03086096e-06
Iter: 237 loss: 4.01733359e-06
Iter: 238 loss: 4.0143841e-06
Iter: 239 loss: 4.0122959e-06
Iter: 240 loss: 4.00879026e-06
Iter: 241 loss: 3.99783448e-06
Iter: 242 loss: 4.01952821e-06
Iter: 243 loss: 3.99089959e-06
Iter: 244 loss: 3.97458462e-06
Iter: 245 loss: 4.06368235e-06
Iter: 246 loss: 3.9722e-06
Iter: 247 loss: 3.97572285e-06
Iter: 248 loss: 3.96775886e-06
Iter: 249 loss: 3.96469841e-06
Iter: 250 loss: 3.95626057e-06
Iter: 251 loss: 4.00769977e-06
Iter: 252 loss: 3.95396819e-06
Iter: 253 loss: 3.94864719e-06
Iter: 254 loss: 3.94840254e-06
Iter: 255 loss: 3.94203471e-06
Iter: 256 loss: 3.93459322e-06
Iter: 257 loss: 3.93370738e-06
Iter: 258 loss: 3.92757738e-06
Iter: 259 loss: 3.96503674e-06
Iter: 260 loss: 3.92685797e-06
Iter: 261 loss: 3.91821641e-06
Iter: 262 loss: 3.91306776e-06
Iter: 263 loss: 3.90951936e-06
Iter: 264 loss: 3.90007972e-06
Iter: 265 loss: 3.91408093e-06
Iter: 266 loss: 3.89548859e-06
Iter: 267 loss: 3.88920944e-06
Iter: 268 loss: 3.8892108e-06
Iter: 269 loss: 3.88584567e-06
Iter: 270 loss: 3.89642264e-06
Iter: 271 loss: 3.88488752e-06
Iter: 272 loss: 3.87962064e-06
Iter: 273 loss: 3.87061027e-06
Iter: 274 loss: 3.87059026e-06
Iter: 275 loss: 3.86251577e-06
Iter: 276 loss: 3.85393469e-06
Iter: 277 loss: 3.85256226e-06
Iter: 278 loss: 3.84493705e-06
Iter: 279 loss: 3.84393297e-06
Iter: 280 loss: 3.83346378e-06
Iter: 281 loss: 3.83630868e-06
Iter: 282 loss: 3.82587314e-06
Iter: 283 loss: 3.81875e-06
Iter: 284 loss: 3.82251437e-06
Iter: 285 loss: 3.81409859e-06
Iter: 286 loss: 3.80740676e-06
Iter: 287 loss: 3.8071903e-06
Iter: 288 loss: 3.8042208e-06
Iter: 289 loss: 3.79608355e-06
Iter: 290 loss: 3.84935174e-06
Iter: 291 loss: 3.79416906e-06
Iter: 292 loss: 3.78540835e-06
Iter: 293 loss: 3.78518484e-06
Iter: 294 loss: 3.77978404e-06
Iter: 295 loss: 3.76709318e-06
Iter: 296 loss: 3.91819458e-06
Iter: 297 loss: 3.76610319e-06
Iter: 298 loss: 3.75626632e-06
Iter: 299 loss: 3.87773434e-06
Iter: 300 loss: 3.75617469e-06
Iter: 301 loss: 3.74827346e-06
Iter: 302 loss: 3.76808748e-06
Iter: 303 loss: 3.74557112e-06
Iter: 304 loss: 3.73948546e-06
Iter: 305 loss: 3.83037968e-06
Iter: 306 loss: 3.73948706e-06
Iter: 307 loss: 3.73553257e-06
Iter: 308 loss: 3.72635986e-06
Iter: 309 loss: 3.8336857e-06
Iter: 310 loss: 3.72552176e-06
Iter: 311 loss: 3.72050636e-06
Iter: 312 loss: 3.72021327e-06
Iter: 313 loss: 3.71497163e-06
Iter: 314 loss: 3.71367832e-06
Iter: 315 loss: 3.71030819e-06
Iter: 316 loss: 3.70288444e-06
Iter: 317 loss: 3.69659165e-06
Iter: 318 loss: 3.69451391e-06
Iter: 319 loss: 3.69283271e-06
Iter: 320 loss: 3.6895733e-06
Iter: 321 loss: 3.68578731e-06
Iter: 322 loss: 3.67701227e-06
Iter: 323 loss: 3.78226241e-06
Iter: 324 loss: 3.67626967e-06
Iter: 325 loss: 3.67132043e-06
Iter: 326 loss: 3.67079383e-06
Iter: 327 loss: 3.66548579e-06
Iter: 328 loss: 3.65274582e-06
Iter: 329 loss: 3.7938828e-06
Iter: 330 loss: 3.65152778e-06
Iter: 331 loss: 3.64028347e-06
Iter: 332 loss: 3.72921068e-06
Iter: 333 loss: 3.63955496e-06
Iter: 334 loss: 3.6314284e-06
Iter: 335 loss: 3.67176813e-06
Iter: 336 loss: 3.63012214e-06
Iter: 337 loss: 3.62456922e-06
Iter: 338 loss: 3.68553242e-06
Iter: 339 loss: 3.62444234e-06
Iter: 340 loss: 3.61995922e-06
Iter: 341 loss: 3.61497541e-06
Iter: 342 loss: 3.61427965e-06
Iter: 343 loss: 3.60875e-06
Iter: 344 loss: 3.62798892e-06
Iter: 345 loss: 3.60728177e-06
Iter: 346 loss: 3.60113359e-06
Iter: 347 loss: 3.6739757e-06
Iter: 348 loss: 3.6010606e-06
Iter: 349 loss: 3.59817477e-06
Iter: 350 loss: 3.59094975e-06
Iter: 351 loss: 3.66450945e-06
Iter: 352 loss: 3.59006208e-06
Iter: 353 loss: 3.58433454e-06
Iter: 354 loss: 3.58424086e-06
Iter: 355 loss: 3.57781482e-06
Iter: 356 loss: 3.57419526e-06
Iter: 357 loss: 3.57138197e-06
Iter: 358 loss: 3.56666715e-06
Iter: 359 loss: 3.56663259e-06
Iter: 360 loss: 3.56183409e-06
Iter: 361 loss: 3.56517239e-06
Iter: 362 loss: 3.55881207e-06
Iter: 363 loss: 3.55475049e-06
Iter: 364 loss: 3.55391307e-06
Iter: 365 loss: 3.55121e-06
Iter: 366 loss: 3.54504027e-06
Iter: 367 loss: 3.5705466e-06
Iter: 368 loss: 3.54363e-06
Iter: 369 loss: 3.53765563e-06
Iter: 370 loss: 3.57147701e-06
Iter: 371 loss: 3.53683072e-06
Iter: 372 loss: 3.5298317e-06
Iter: 373 loss: 3.52537336e-06
Iter: 374 loss: 3.52267489e-06
Iter: 375 loss: 3.51565723e-06
Iter: 376 loss: 3.52956022e-06
Iter: 377 loss: 3.51279755e-06
Iter: 378 loss: 3.50986056e-06
Iter: 379 loss: 3.50863661e-06
Iter: 380 loss: 3.50580854e-06
Iter: 381 loss: 3.49924449e-06
Iter: 382 loss: 3.57882391e-06
Iter: 383 loss: 3.49868014e-06
Iter: 384 loss: 3.49428e-06
Iter: 385 loss: 3.55263865e-06
Iter: 386 loss: 3.49430024e-06
Iter: 387 loss: 3.48971275e-06
Iter: 388 loss: 3.50329901e-06
Iter: 389 loss: 3.48830918e-06
Iter: 390 loss: 3.48488038e-06
Iter: 391 loss: 3.48045023e-06
Iter: 392 loss: 3.48014987e-06
Iter: 393 loss: 3.47172545e-06
Iter: 394 loss: 3.52614188e-06
Iter: 395 loss: 3.47082482e-06
Iter: 396 loss: 3.4659472e-06
Iter: 397 loss: 3.46149727e-06
Iter: 398 loss: 3.46031948e-06
Iter: 399 loss: 3.45388571e-06
Iter: 400 loss: 3.5023786e-06
Iter: 401 loss: 3.45338981e-06
Iter: 402 loss: 3.44889509e-06
Iter: 403 loss: 3.47588411e-06
Iter: 404 loss: 3.44831074e-06
Iter: 405 loss: 3.44347927e-06
Iter: 406 loss: 3.4514851e-06
Iter: 407 loss: 3.44134332e-06
Iter: 408 loss: 3.43709598e-06
Iter: 409 loss: 3.4311845e-06
Iter: 410 loss: 3.43089414e-06
Iter: 411 loss: 3.42936892e-06
Iter: 412 loss: 3.42711655e-06
Iter: 413 loss: 3.42403018e-06
Iter: 414 loss: 3.41685313e-06
Iter: 415 loss: 3.50991559e-06
Iter: 416 loss: 3.41637019e-06
Iter: 417 loss: 3.41032e-06
Iter: 418 loss: 3.44113801e-06
Iter: 419 loss: 3.40930592e-06
Iter: 420 loss: 3.4045197e-06
Iter: 421 loss: 3.46739193e-06
Iter: 422 loss: 3.40451925e-06
Iter: 423 loss: 3.40215e-06
Iter: 424 loss: 3.39994426e-06
Iter: 425 loss: 3.39936719e-06
Iter: 426 loss: 3.39607232e-06
Iter: 427 loss: 3.44215459e-06
Iter: 428 loss: 3.39609255e-06
Iter: 429 loss: 3.39356711e-06
Iter: 430 loss: 3.38747986e-06
Iter: 431 loss: 3.45124499e-06
Iter: 432 loss: 3.38682275e-06
Iter: 433 loss: 3.38090808e-06
Iter: 434 loss: 3.44962473e-06
Iter: 435 loss: 3.38081145e-06
Iter: 436 loss: 3.37628353e-06
Iter: 437 loss: 3.3976296e-06
Iter: 438 loss: 3.37549045e-06
Iter: 439 loss: 3.37109532e-06
Iter: 440 loss: 3.39066855e-06
Iter: 441 loss: 3.37025904e-06
Iter: 442 loss: 3.36718563e-06
Iter: 443 loss: 3.36397216e-06
Iter: 444 loss: 3.36338371e-06
Iter: 445 loss: 3.36338735e-06
Iter: 446 loss: 3.36173275e-06
Iter: 447 loss: 3.3604183e-06
Iter: 448 loss: 3.35737514e-06
Iter: 449 loss: 3.39266535e-06
Iter: 450 loss: 3.35710934e-06
Iter: 451 loss: 3.35333243e-06
Iter: 452 loss: 3.35150571e-06
Iter: 453 loss: 3.34973447e-06
Iter: 454 loss: 3.34649485e-06
Iter: 455 loss: 3.3454744e-06
Iter: 456 loss: 3.34299966e-06
Iter: 457 loss: 3.33867092e-06
Iter: 458 loss: 3.3386475e-06
Iter: 459 loss: 3.33588855e-06
Iter: 460 loss: 3.3357278e-06
Iter: 461 loss: 3.33308026e-06
Iter: 462 loss: 3.32877289e-06
Iter: 463 loss: 3.32875652e-06
Iter: 464 loss: 3.32513196e-06
Iter: 465 loss: 3.34039964e-06
Iter: 466 loss: 3.32426907e-06
Iter: 467 loss: 3.32071659e-06
Iter: 468 loss: 3.34027027e-06
Iter: 469 loss: 3.32025411e-06
Iter: 470 loss: 3.31699857e-06
Iter: 471 loss: 3.33332582e-06
Iter: 472 loss: 3.31648221e-06
Iter: 473 loss: 3.31351248e-06
Iter: 474 loss: 3.30788112e-06
Iter: 475 loss: 3.42405929e-06
Iter: 476 loss: 3.30788134e-06
Iter: 477 loss: 3.30606417e-06
Iter: 478 loss: 3.30497e-06
Iter: 479 loss: 3.30211469e-06
Iter: 480 loss: 3.29875093e-06
Iter: 481 loss: 3.29836348e-06
Iter: 482 loss: 3.29496515e-06
Iter: 483 loss: 3.29000159e-06
Iter: 484 loss: 3.2899145e-06
Iter: 485 loss: 3.28919873e-06
Iter: 486 loss: 3.28688202e-06
Iter: 487 loss: 3.28408055e-06
Iter: 488 loss: 3.27906969e-06
Iter: 489 loss: 3.39790586e-06
Iter: 490 loss: 3.27905855e-06
Iter: 491 loss: 3.27535577e-06
Iter: 492 loss: 3.31804199e-06
Iter: 493 loss: 3.27532052e-06
Iter: 494 loss: 3.27128646e-06
Iter: 495 loss: 3.27339512e-06
Iter: 496 loss: 3.26868098e-06
Iter: 497 loss: 3.26509462e-06
Iter: 498 loss: 3.26374493e-06
Iter: 499 loss: 3.26178269e-06
Iter: 500 loss: 3.2577268e-06
Iter: 501 loss: 3.30816874e-06
Iter: 502 loss: 3.25768451e-06
Iter: 503 loss: 3.25480823e-06
Iter: 504 loss: 3.28891701e-06
Iter: 505 loss: 3.25479073e-06
Iter: 506 loss: 3.25298652e-06
Iter: 507 loss: 3.24944494e-06
Iter: 508 loss: 3.32128093e-06
Iter: 509 loss: 3.24939856e-06
Iter: 510 loss: 3.2458e-06
Iter: 511 loss: 3.27951284e-06
Iter: 512 loss: 3.24566122e-06
Iter: 513 loss: 3.24114308e-06
Iter: 514 loss: 3.24118e-06
Iter: 515 loss: 3.23757376e-06
Iter: 516 loss: 3.2333835e-06
Iter: 517 loss: 3.2293126e-06
Iter: 518 loss: 3.22840242e-06
Iter: 519 loss: 3.22749884e-06
Iter: 520 loss: 3.22645701e-06
Iter: 521 loss: 3.22441929e-06
Iter: 522 loss: 3.22286178e-06
Iter: 523 loss: 3.22220239e-06
Iter: 524 loss: 3.21943753e-06
Iter: 525 loss: 3.22812934e-06
Iter: 526 loss: 3.21861421e-06
Iter: 527 loss: 3.21496555e-06
Iter: 528 loss: 3.23066e-06
Iter: 529 loss: 3.21416724e-06
Iter: 530 loss: 3.21110588e-06
Iter: 531 loss: 3.20513618e-06
Iter: 532 loss: 3.33135495e-06
Iter: 533 loss: 3.20516392e-06
Iter: 534 loss: 3.19848641e-06
Iter: 535 loss: 3.24050689e-06
Iter: 536 loss: 3.19771584e-06
Iter: 537 loss: 3.1935e-06
Iter: 538 loss: 3.19345622e-06
Iter: 539 loss: 3.19030732e-06
Iter: 540 loss: 3.18763523e-06
Iter: 541 loss: 3.18674324e-06
Iter: 542 loss: 3.18352295e-06
Iter: 543 loss: 3.20256595e-06
Iter: 544 loss: 3.18309026e-06
Iter: 545 loss: 3.17948525e-06
Iter: 546 loss: 3.19629544e-06
Iter: 547 loss: 3.1788029e-06
Iter: 548 loss: 3.17622835e-06
Iter: 549 loss: 3.16916226e-06
Iter: 550 loss: 3.21266134e-06
Iter: 551 loss: 3.16727187e-06
Iter: 552 loss: 3.16148e-06
Iter: 553 loss: 3.1613572e-06
Iter: 554 loss: 3.15521265e-06
Iter: 555 loss: 3.185281e-06
Iter: 556 loss: 3.15417083e-06
Iter: 557 loss: 3.1509644e-06
Iter: 558 loss: 3.15075886e-06
Iter: 559 loss: 3.14840372e-06
Iter: 560 loss: 3.1447853e-06
Iter: 561 loss: 3.19973378e-06
Iter: 562 loss: 3.14479553e-06
Iter: 563 loss: 3.14272847e-06
Iter: 564 loss: 3.13924193e-06
Iter: 565 loss: 3.1392151e-06
Iter: 566 loss: 3.13500755e-06
Iter: 567 loss: 3.13948749e-06
Iter: 568 loss: 3.13267424e-06
Iter: 569 loss: 3.12790621e-06
Iter: 570 loss: 3.19067112e-06
Iter: 571 loss: 3.12787824e-06
Iter: 572 loss: 3.12329848e-06
Iter: 573 loss: 3.12473639e-06
Iter: 574 loss: 3.12005545e-06
Iter: 575 loss: 3.11548729e-06
Iter: 576 loss: 3.11822942e-06
Iter: 577 loss: 3.1125885e-06
Iter: 578 loss: 3.10960104e-06
Iter: 579 loss: 3.10901078e-06
Iter: 580 loss: 3.10745054e-06
Iter: 581 loss: 3.10365886e-06
Iter: 582 loss: 3.14637964e-06
Iter: 583 loss: 3.1033187e-06
Iter: 584 loss: 3.0992237e-06
Iter: 585 loss: 3.09696316e-06
Iter: 586 loss: 3.0951478e-06
Iter: 587 loss: 3.09432176e-06
Iter: 588 loss: 3.09193638e-06
Iter: 589 loss: 3.08998392e-06
Iter: 590 loss: 3.08642e-06
Iter: 591 loss: 3.16746036e-06
Iter: 592 loss: 3.08639733e-06
Iter: 593 loss: 3.08313929e-06
Iter: 594 loss: 3.12456268e-06
Iter: 595 loss: 3.08312087e-06
Iter: 596 loss: 3.07990308e-06
Iter: 597 loss: 3.08377048e-06
Iter: 598 loss: 3.07822665e-06
Iter: 599 loss: 3.07602613e-06
Iter: 600 loss: 3.07705591e-06
Iter: 601 loss: 3.07454775e-06
Iter: 602 loss: 3.07211803e-06
Iter: 603 loss: 3.0718802e-06
Iter: 604 loss: 3.07015262e-06
Iter: 605 loss: 3.06698439e-06
Iter: 606 loss: 3.06693732e-06
Iter: 607 loss: 3.06495394e-06
Iter: 608 loss: 3.05934873e-06
Iter: 609 loss: 3.09090092e-06
Iter: 610 loss: 3.05774029e-06
Iter: 611 loss: 3.05659205e-06
Iter: 612 loss: 3.05447657e-06
Iter: 613 loss: 3.05157118e-06
Iter: 614 loss: 3.05265871e-06
Iter: 615 loss: 3.04944751e-06
Iter: 616 loss: 3.04705645e-06
Iter: 617 loss: 3.04566674e-06
Iter: 618 loss: 3.04462537e-06
Iter: 619 loss: 3.04006176e-06
Iter: 620 loss: 3.03505772e-06
Iter: 621 loss: 3.03428305e-06
Iter: 622 loss: 3.03885781e-06
Iter: 623 loss: 3.03111074e-06
Iter: 624 loss: 3.02902163e-06
Iter: 625 loss: 3.02327226e-06
Iter: 626 loss: 3.05570939e-06
Iter: 627 loss: 3.02154899e-06
Iter: 628 loss: 3.01737782e-06
Iter: 629 loss: 3.01688306e-06
Iter: 630 loss: 3.0130559e-06
Iter: 631 loss: 3.01694035e-06
Iter: 632 loss: 3.01092541e-06
Iter: 633 loss: 3.00845386e-06
Iter: 634 loss: 3.01222553e-06
Iter: 635 loss: 3.0072647e-06
Iter: 636 loss: 3.00521856e-06
Iter: 637 loss: 3.00762849e-06
Iter: 638 loss: 3.00417832e-06
Iter: 639 loss: 3.00266197e-06
Iter: 640 loss: 3.00251031e-06
Iter: 641 loss: 3.00121769e-06
Iter: 642 loss: 2.99744556e-06
Iter: 643 loss: 3.01348905e-06
Iter: 644 loss: 2.99594603e-06
Iter: 645 loss: 2.99523731e-06
Iter: 646 loss: 2.99373e-06
Iter: 647 loss: 2.99131671e-06
Iter: 648 loss: 2.98723717e-06
Iter: 649 loss: 2.98723762e-06
Iter: 650 loss: 2.984199e-06
Iter: 651 loss: 2.98749296e-06
Iter: 652 loss: 2.98254326e-06
Iter: 653 loss: 2.9791081e-06
Iter: 654 loss: 2.98016062e-06
Iter: 655 loss: 2.97669749e-06
Iter: 656 loss: 2.97366046e-06
Iter: 657 loss: 3.0129504e-06
Iter: 658 loss: 2.97363931e-06
Iter: 659 loss: 2.97024917e-06
Iter: 660 loss: 2.9849316e-06
Iter: 661 loss: 2.96953317e-06
Iter: 662 loss: 2.96790813e-06
Iter: 663 loss: 2.96551752e-06
Iter: 664 loss: 2.96543271e-06
Iter: 665 loss: 2.9623086e-06
Iter: 666 loss: 2.9850894e-06
Iter: 667 loss: 2.96208395e-06
Iter: 668 loss: 2.96011467e-06
Iter: 669 loss: 2.98375517e-06
Iter: 670 loss: 2.96005737e-06
Iter: 671 loss: 2.95833706e-06
Iter: 672 loss: 2.95814948e-06
Iter: 673 loss: 2.9569037e-06
Iter: 674 loss: 2.95518134e-06
Iter: 675 loss: 2.9540488e-06
Iter: 676 loss: 2.9533569e-06
Iter: 677 loss: 2.95199743e-06
Iter: 678 loss: 2.95182622e-06
Iter: 679 loss: 2.94998176e-06
Iter: 680 loss: 2.9467742e-06
Iter: 681 loss: 2.94675101e-06
Iter: 682 loss: 2.94540678e-06
Iter: 683 loss: 2.94499478e-06
Iter: 684 loss: 2.94354891e-06
Iter: 685 loss: 2.94002507e-06
Iter: 686 loss: 2.97649831e-06
Iter: 687 loss: 2.93961511e-06
Iter: 688 loss: 2.93598032e-06
Iter: 689 loss: 2.94837719e-06
Iter: 690 loss: 2.93508037e-06
Iter: 691 loss: 2.93735934e-06
Iter: 692 loss: 2.93400285e-06
Iter: 693 loss: 2.93324956e-06
Iter: 694 loss: 2.93110543e-06
Iter: 695 loss: 2.9405619e-06
Iter: 696 loss: 2.93025073e-06
Iter: 697 loss: 2.92715549e-06
Iter: 698 loss: 2.93133576e-06
Iter: 699 loss: 2.92555569e-06
Iter: 700 loss: 2.9235805e-06
Iter: 701 loss: 2.9233579e-06
Iter: 702 loss: 2.92129698e-06
Iter: 703 loss: 2.92191544e-06
Iter: 704 loss: 2.91985884e-06
Iter: 705 loss: 2.91683705e-06
Iter: 706 loss: 2.91836477e-06
Iter: 707 loss: 2.91488868e-06
Iter: 708 loss: 2.91252104e-06
Iter: 709 loss: 2.91897891e-06
Iter: 710 loss: 2.91173e-06
Iter: 711 loss: 2.90887374e-06
Iter: 712 loss: 2.93621542e-06
Iter: 713 loss: 2.90872299e-06
Iter: 714 loss: 2.90766275e-06
Iter: 715 loss: 2.90939e-06
Iter: 716 loss: 2.90710977e-06
Iter: 717 loss: 2.90535309e-06
Iter: 718 loss: 2.90452499e-06
Iter: 719 loss: 2.90358867e-06
Iter: 720 loss: 2.90142862e-06
Iter: 721 loss: 2.89807394e-06
Iter: 722 loss: 2.89800482e-06
Iter: 723 loss: 2.89534432e-06
Iter: 724 loss: 2.89533159e-06
Iter: 725 loss: 2.89192076e-06
Iter: 726 loss: 2.89352465e-06
Iter: 727 loss: 2.88967385e-06
Iter: 728 loss: 2.88733349e-06
Iter: 729 loss: 2.88555816e-06
Iter: 730 loss: 2.88476645e-06
Iter: 731 loss: 2.88212505e-06
Iter: 732 loss: 2.90876733e-06
Iter: 733 loss: 2.88202955e-06
Iter: 734 loss: 2.87971216e-06
Iter: 735 loss: 2.89882564e-06
Iter: 736 loss: 2.87957209e-06
Iter: 737 loss: 2.87804482e-06
Iter: 738 loss: 2.87646208e-06
Iter: 739 loss: 2.87616376e-06
Iter: 740 loss: 2.87293074e-06
Iter: 741 loss: 2.87899093e-06
Iter: 742 loss: 2.871569e-06
Iter: 743 loss: 2.87022385e-06
Iter: 744 loss: 2.87006196e-06
Iter: 745 loss: 2.86858381e-06
Iter: 746 loss: 2.86508316e-06
Iter: 747 loss: 2.90316325e-06
Iter: 748 loss: 2.86467844e-06
Iter: 749 loss: 2.86295472e-06
Iter: 750 loss: 2.86230352e-06
Iter: 751 loss: 2.86116028e-06
Iter: 752 loss: 2.85855799e-06
Iter: 753 loss: 2.89226728e-06
Iter: 754 loss: 2.85837405e-06
Iter: 755 loss: 2.85608394e-06
Iter: 756 loss: 2.85450278e-06
Iter: 757 loss: 2.85362057e-06
Iter: 758 loss: 2.84964608e-06
Iter: 759 loss: 2.87513512e-06
Iter: 760 loss: 2.8491836e-06
Iter: 761 loss: 2.84850739e-06
Iter: 762 loss: 2.84738576e-06
Iter: 763 loss: 2.84643579e-06
Iter: 764 loss: 2.84357702e-06
Iter: 765 loss: 2.85456417e-06
Iter: 766 loss: 2.84240014e-06
Iter: 767 loss: 2.83925965e-06
Iter: 768 loss: 2.86624504e-06
Iter: 769 loss: 2.83909549e-06
Iter: 770 loss: 2.83740724e-06
Iter: 771 loss: 2.83733812e-06
Iter: 772 loss: 2.83640384e-06
Iter: 773 loss: 2.83426903e-06
Iter: 774 loss: 2.85866963e-06
Iter: 775 loss: 2.83401641e-06
Iter: 776 loss: 2.83125928e-06
Iter: 777 loss: 2.8521788e-06
Iter: 778 loss: 2.83106328e-06
Iter: 779 loss: 2.82898031e-06
Iter: 780 loss: 2.84469775e-06
Iter: 781 loss: 2.82879182e-06
Iter: 782 loss: 2.82687324e-06
Iter: 783 loss: 2.82646829e-06
Iter: 784 loss: 2.82520068e-06
Iter: 785 loss: 2.82406904e-06
Iter: 786 loss: 2.82393012e-06
Iter: 787 loss: 2.82314295e-06
Iter: 788 loss: 2.82084829e-06
Iter: 789 loss: 2.82982137e-06
Iter: 790 loss: 2.8198549e-06
Iter: 791 loss: 2.81673965e-06
Iter: 792 loss: 2.82648739e-06
Iter: 793 loss: 2.8158704e-06
Iter: 794 loss: 2.81378266e-06
Iter: 795 loss: 2.81508892e-06
Iter: 796 loss: 2.81247549e-06
Iter: 797 loss: 2.81341909e-06
Iter: 798 loss: 2.81154985e-06
Iter: 799 loss: 2.81054349e-06
Iter: 800 loss: 2.80853556e-06
Iter: 801 loss: 2.84116027e-06
Iter: 802 loss: 2.80847e-06
Iter: 803 loss: 2.8067559e-06
Iter: 804 loss: 2.80663266e-06
Iter: 805 loss: 2.8053546e-06
Iter: 806 loss: 2.80444419e-06
Iter: 807 loss: 2.80405493e-06
Iter: 808 loss: 2.8027298e-06
Iter: 809 loss: 2.80187965e-06
Iter: 810 loss: 2.80133145e-06
Iter: 811 loss: 2.80013091e-06
Iter: 812 loss: 2.80246e-06
Iter: 813 loss: 2.79968413e-06
Iter: 814 loss: 2.79780329e-06
Iter: 815 loss: 2.80390896e-06
Iter: 816 loss: 2.79736059e-06
Iter: 817 loss: 2.79547612e-06
Iter: 818 loss: 2.80003724e-06
Iter: 819 loss: 2.79477581e-06
Iter: 820 loss: 2.79327719e-06
Iter: 821 loss: 2.80229756e-06
Iter: 822 loss: 2.79311553e-06
Iter: 823 loss: 2.79162464e-06
Iter: 824 loss: 2.79066239e-06
Iter: 825 loss: 2.79010555e-06
Iter: 826 loss: 2.78867083e-06
Iter: 827 loss: 2.78730431e-06
Iter: 828 loss: 2.78698371e-06
Iter: 829 loss: 2.78450148e-06
Iter: 830 loss: 2.7880069e-06
Iter: 831 loss: 2.78324706e-06
Iter: 832 loss: 2.78353036e-06
Iter: 833 loss: 2.78242442e-06
Iter: 834 loss: 2.78140215e-06
Iter: 835 loss: 2.7795154e-06
Iter: 836 loss: 2.82432779e-06
Iter: 837 loss: 2.77953086e-06
Iter: 838 loss: 2.77758932e-06
Iter: 839 loss: 2.77752565e-06
Iter: 840 loss: 2.77608478e-06
Iter: 841 loss: 2.77482968e-06
Iter: 842 loss: 2.77480103e-06
Iter: 843 loss: 2.77318395e-06
Iter: 844 loss: 2.77335448e-06
Iter: 845 loss: 2.7718911e-06
Iter: 846 loss: 2.77070762e-06
Iter: 847 loss: 2.77000345e-06
Iter: 848 loss: 2.76945184e-06
Iter: 849 loss: 2.76912465e-06
Iter: 850 loss: 2.76853734e-06
Iter: 851 loss: 2.76794776e-06
Iter: 852 loss: 2.76676838e-06
Iter: 853 loss: 2.7850117e-06
Iter: 854 loss: 2.76674837e-06
Iter: 855 loss: 2.76505943e-06
Iter: 856 loss: 2.77867593e-06
Iter: 857 loss: 2.76495439e-06
Iter: 858 loss: 2.76394121e-06
Iter: 859 loss: 2.76383821e-06
Iter: 860 loss: 2.76311e-06
Iter: 861 loss: 2.76173205e-06
Iter: 862 loss: 2.76333276e-06
Iter: 863 loss: 2.76105447e-06
Iter: 864 loss: 2.75972957e-06
Iter: 865 loss: 2.75895263e-06
Iter: 866 loss: 2.75846969e-06
Iter: 867 loss: 2.7576009e-06
Iter: 868 loss: 2.75719276e-06
Iter: 869 loss: 2.75652314e-06
Iter: 870 loss: 2.75466527e-06
Iter: 871 loss: 2.76762671e-06
Iter: 872 loss: 2.75426078e-06
Iter: 873 loss: 2.75268485e-06
Iter: 874 loss: 2.76773244e-06
Iter: 875 loss: 2.75259913e-06
Iter: 876 loss: 2.75126536e-06
Iter: 877 loss: 2.76766968e-06
Iter: 878 loss: 2.75127945e-06
Iter: 879 loss: 2.75054708e-06
Iter: 880 loss: 2.74854528e-06
Iter: 881 loss: 2.76550099e-06
Iter: 882 loss: 2.74819718e-06
Iter: 883 loss: 2.74813e-06
Iter: 884 loss: 2.74739023e-06
Iter: 885 loss: 2.7465212e-06
Iter: 886 loss: 2.74516401e-06
Iter: 887 loss: 2.74511558e-06
Iter: 888 loss: 2.74401782e-06
Iter: 889 loss: 2.74400804e-06
Iter: 890 loss: 2.74300123e-06
Iter: 891 loss: 2.74098375e-06
Iter: 892 loss: 2.779233e-06
Iter: 893 loss: 2.74102058e-06
Iter: 894 loss: 2.7388553e-06
Iter: 895 loss: 2.75269622e-06
Iter: 896 loss: 2.73864566e-06
Iter: 897 loss: 2.73706496e-06
Iter: 898 loss: 2.73528099e-06
Iter: 899 loss: 2.73506339e-06
Iter: 900 loss: 2.73235196e-06
Iter: 901 loss: 2.73734395e-06
Iter: 902 loss: 2.73120827e-06
Iter: 903 loss: 2.73209798e-06
Iter: 904 loss: 2.73019668e-06
Iter: 905 loss: 2.72940201e-06
Iter: 906 loss: 2.72732473e-06
Iter: 907 loss: 2.7393487e-06
Iter: 908 loss: 2.72664101e-06
Iter: 909 loss: 2.72407692e-06
Iter: 910 loss: 2.72749094e-06
Iter: 911 loss: 2.72273701e-06
Iter: 912 loss: 2.72067746e-06
Iter: 913 loss: 2.74381591e-06
Iter: 914 loss: 2.72057741e-06
Iter: 915 loss: 2.71859199e-06
Iter: 916 loss: 2.73596061e-06
Iter: 917 loss: 2.71848285e-06
Iter: 918 loss: 2.71757244e-06
Iter: 919 loss: 2.71505678e-06
Iter: 920 loss: 2.72477314e-06
Iter: 921 loss: 2.71391855e-06
Iter: 922 loss: 2.71401768e-06
Iter: 923 loss: 2.71261842e-06
Iter: 924 loss: 2.71125896e-06
Iter: 925 loss: 2.71196541e-06
Iter: 926 loss: 2.71036106e-06
Iter: 927 loss: 2.7091055e-06
Iter: 928 loss: 2.71366866e-06
Iter: 929 loss: 2.70877399e-06
Iter: 930 loss: 2.7069691e-06
Iter: 931 loss: 2.706548e-06
Iter: 932 loss: 2.70542773e-06
Iter: 933 loss: 2.70364899e-06
Iter: 934 loss: 2.71001181e-06
Iter: 935 loss: 2.70320265e-06
Iter: 936 loss: 2.70149917e-06
Iter: 937 loss: 2.69840871e-06
Iter: 938 loss: 2.77405434e-06
Iter: 939 loss: 2.69844418e-06
Iter: 940 loss: 2.69535826e-06
Iter: 941 loss: 2.71328213e-06
Iter: 942 loss: 2.69499424e-06
Iter: 943 loss: 2.69438624e-06
Iter: 944 loss: 2.69362317e-06
Iter: 945 loss: 2.69287602e-06
Iter: 946 loss: 2.69087559e-06
Iter: 947 loss: 2.70555984e-06
Iter: 948 loss: 2.69047268e-06
Iter: 949 loss: 2.68838835e-06
Iter: 950 loss: 2.69285283e-06
Iter: 951 loss: 2.68757844e-06
Iter: 952 loss: 2.68676854e-06
Iter: 953 loss: 2.68624785e-06
Iter: 954 loss: 2.68547387e-06
Iter: 955 loss: 2.68339318e-06
Iter: 956 loss: 2.69253e-06
Iter: 957 loss: 2.68262852e-06
Iter: 958 loss: 2.6798034e-06
Iter: 959 loss: 2.68634767e-06
Iter: 960 loss: 2.67883547e-06
Iter: 961 loss: 2.67903624e-06
Iter: 962 loss: 2.6775042e-06
Iter: 963 loss: 2.67668543e-06
Iter: 964 loss: 2.67491578e-06
Iter: 965 loss: 2.69958605e-06
Iter: 966 loss: 2.67479913e-06
Iter: 967 loss: 2.67359974e-06
Iter: 968 loss: 2.67342966e-06
Iter: 969 loss: 2.67277369e-06
Iter: 970 loss: 2.67093947e-06
Iter: 971 loss: 2.68742633e-06
Iter: 972 loss: 2.67072505e-06
Iter: 973 loss: 2.66875372e-06
Iter: 974 loss: 2.68482972e-06
Iter: 975 loss: 2.66862344e-06
Iter: 976 loss: 2.66715961e-06
Iter: 977 loss: 2.66563165e-06
Iter: 978 loss: 2.66535199e-06
Iter: 979 loss: 2.66308507e-06
Iter: 980 loss: 2.66794405e-06
Iter: 981 loss: 2.66209736e-06
Iter: 982 loss: 2.66107872e-06
Iter: 983 loss: 2.66054531e-06
Iter: 984 loss: 2.65973176e-06
Iter: 985 loss: 2.65771268e-06
Iter: 986 loss: 2.67639552e-06
Iter: 987 loss: 2.65745666e-06
Iter: 988 loss: 2.65597555e-06
Iter: 989 loss: 2.65601102e-06
Iter: 990 loss: 2.65426797e-06
Iter: 991 loss: 2.65437188e-06
Iter: 992 loss: 2.65294125e-06
Iter: 993 loss: 2.65175959e-06
Iter: 994 loss: 2.6510354e-06
Iter: 995 loss: 2.65063954e-06
Iter: 996 loss: 2.64939081e-06
Iter: 997 loss: 2.6492894e-06
Iter: 998 loss: 2.64848859e-06
Iter: 999 loss: 2.6470741e-06
Iter: 1000 loss: 2.67837e-06
Iter: 1001 loss: 2.64708638e-06
Iter: 1002 loss: 2.64536538e-06
Iter: 1003 loss: 2.66745292e-06
Iter: 1004 loss: 2.64533355e-06
Iter: 1005 loss: 2.64452365e-06
Iter: 1006 loss: 2.6424932e-06
Iter: 1007 loss: 2.66016514e-06
Iter: 1008 loss: 2.64217397e-06
Iter: 1009 loss: 2.64049e-06
Iter: 1010 loss: 2.66017651e-06
Iter: 1011 loss: 2.64046366e-06
Iter: 1012 loss: 2.63891638e-06
Iter: 1013 loss: 2.6376556e-06
Iter: 1014 loss: 2.6371215e-06
Iter: 1015 loss: 2.63617062e-06
Iter: 1016 loss: 2.63609877e-06
Iter: 1017 loss: 2.63494849e-06
Iter: 1018 loss: 2.63373158e-06
Iter: 1019 loss: 2.63345601e-06
Iter: 1020 loss: 2.63204674e-06
Iter: 1021 loss: 2.63251809e-06
Iter: 1022 loss: 2.63101401e-06
Iter: 1023 loss: 2.63021502e-06
Iter: 1024 loss: 2.63016727e-06
Iter: 1025 loss: 2.62923982e-06
Iter: 1026 loss: 2.62776371e-06
Iter: 1027 loss: 2.627703e-06
Iter: 1028 loss: 2.62690719e-06
Iter: 1029 loss: 2.62687104e-06
Iter: 1030 loss: 2.62606022e-06
Iter: 1031 loss: 2.62441881e-06
Iter: 1032 loss: 2.65445942e-06
Iter: 1033 loss: 2.6244079e-06
Iter: 1034 loss: 2.6231553e-06
Iter: 1035 loss: 2.63921311e-06
Iter: 1036 loss: 2.62311505e-06
Iter: 1037 loss: 2.62185813e-06
Iter: 1038 loss: 2.62496451e-06
Iter: 1039 loss: 2.62138974e-06
Iter: 1040 loss: 2.62069079e-06
Iter: 1041 loss: 2.61878e-06
Iter: 1042 loss: 2.63310517e-06
Iter: 1043 loss: 2.61838568e-06
Iter: 1044 loss: 2.61697733e-06
Iter: 1045 loss: 2.61678724e-06
Iter: 1046 loss: 2.61586092e-06
Iter: 1047 loss: 2.61529067e-06
Iter: 1048 loss: 2.61489049e-06
Iter: 1049 loss: 2.61330752e-06
Iter: 1050 loss: 2.63322909e-06
Iter: 1051 loss: 2.6132866e-06
Iter: 1052 loss: 2.61237346e-06
Iter: 1053 loss: 2.61002447e-06
Iter: 1054 loss: 2.63343168e-06
Iter: 1055 loss: 2.60972274e-06
Iter: 1056 loss: 2.60770958e-06
Iter: 1057 loss: 2.61830633e-06
Iter: 1058 loss: 2.60737579e-06
Iter: 1059 loss: 2.60697607e-06
Iter: 1060 loss: 2.60641423e-06
Iter: 1061 loss: 2.60589013e-06
Iter: 1062 loss: 2.60478737e-06
Iter: 1063 loss: 2.62622962e-06
Iter: 1064 loss: 2.60479101e-06
Iter: 1065 loss: 2.60356137e-06
Iter: 1066 loss: 2.62221988e-06
Iter: 1067 loss: 2.6035359e-06
Iter: 1068 loss: 2.6028813e-06
Iter: 1069 loss: 2.60108709e-06
Iter: 1070 loss: 2.612564e-06
Iter: 1071 loss: 2.60063143e-06
Iter: 1072 loss: 2.59901435e-06
Iter: 1073 loss: 2.59882358e-06
Iter: 1074 loss: 2.5978934e-06
Iter: 1075 loss: 2.59567582e-06
Iter: 1076 loss: 2.6285702e-06
Iter: 1077 loss: 2.59564536e-06
Iter: 1078 loss: 2.59387252e-06
Iter: 1079 loss: 2.59742637e-06
Iter: 1080 loss: 2.59316539e-06
Iter: 1081 loss: 2.591667e-06
Iter: 1082 loss: 2.59960052e-06
Iter: 1083 loss: 2.59140188e-06
Iter: 1084 loss: 2.59019134e-06
Iter: 1085 loss: 2.59017247e-06
Iter: 1086 loss: 2.58942964e-06
Iter: 1087 loss: 2.59143962e-06
Iter: 1088 loss: 2.58916407e-06
Iter: 1089 loss: 2.58842488e-06
Iter: 1090 loss: 2.58693126e-06
Iter: 1091 loss: 2.61179252e-06
Iter: 1092 loss: 2.58690602e-06
Iter: 1093 loss: 2.58498017e-06
Iter: 1094 loss: 2.58580826e-06
Iter: 1095 loss: 2.58362979e-06
Iter: 1096 loss: 2.58169825e-06
Iter: 1097 loss: 2.59793478e-06
Iter: 1098 loss: 2.58156115e-06
Iter: 1099 loss: 2.58028672e-06
Iter: 1100 loss: 2.58024124e-06
Iter: 1101 loss: 2.57959255e-06
Iter: 1102 loss: 2.57806823e-06
Iter: 1103 loss: 2.59370449e-06
Iter: 1104 loss: 2.57782949e-06
Iter: 1105 loss: 2.57754982e-06
Iter: 1106 loss: 2.57695319e-06
Iter: 1107 loss: 2.57633246e-06
Iter: 1108 loss: 2.57459442e-06
Iter: 1109 loss: 2.58168e-06
Iter: 1110 loss: 2.57387819e-06
Iter: 1111 loss: 2.57275406e-06
Iter: 1112 loss: 2.57258171e-06
Iter: 1113 loss: 2.57112e-06
Iter: 1114 loss: 2.56845101e-06
Iter: 1115 loss: 2.63165703e-06
Iter: 1116 loss: 2.56847443e-06
Iter: 1117 loss: 2.56673616e-06
Iter: 1118 loss: 2.58835462e-06
Iter: 1119 loss: 2.56666954e-06
Iter: 1120 loss: 2.56562134e-06
Iter: 1121 loss: 2.56561202e-06
Iter: 1122 loss: 2.56501903e-06
Iter: 1123 loss: 2.56353246e-06
Iter: 1124 loss: 2.57734519e-06
Iter: 1125 loss: 2.56328121e-06
Iter: 1126 loss: 2.56127032e-06
Iter: 1127 loss: 2.57580041e-06
Iter: 1128 loss: 2.56108842e-06
Iter: 1129 loss: 2.56001749e-06
Iter: 1130 loss: 2.5583447e-06
Iter: 1131 loss: 2.55830037e-06
Iter: 1132 loss: 2.55725718e-06
Iter: 1133 loss: 2.55709415e-06
Iter: 1134 loss: 2.55564282e-06
Iter: 1135 loss: 2.55551595e-06
Iter: 1136 loss: 2.55444479e-06
Iter: 1137 loss: 2.55362625e-06
Iter: 1138 loss: 2.55656823e-06
Iter: 1139 loss: 2.55338591e-06
Iter: 1140 loss: 2.55211444e-06
Iter: 1141 loss: 2.55429131e-06
Iter: 1142 loss: 2.55153373e-06
Iter: 1143 loss: 2.55072473e-06
Iter: 1144 loss: 2.54998895e-06
Iter: 1145 loss: 2.54971155e-06
Iter: 1146 loss: 2.54812221e-06
Iter: 1147 loss: 2.56423186e-06
Iter: 1148 loss: 2.54804354e-06
Iter: 1149 loss: 2.54731776e-06
Iter: 1150 loss: 2.5454583e-06
Iter: 1151 loss: 2.56205385e-06
Iter: 1152 loss: 2.54521547e-06
Iter: 1153 loss: 2.54517636e-06
Iter: 1154 loss: 2.54424867e-06
Iter: 1155 loss: 2.54341e-06
Iter: 1156 loss: 2.54229417e-06
Iter: 1157 loss: 2.54227257e-06
Iter: 1158 loss: 2.54127e-06
Iter: 1159 loss: 2.54692941e-06
Iter: 1160 loss: 2.541095e-06
Iter: 1161 loss: 2.54012048e-06
Iter: 1162 loss: 2.53880626e-06
Iter: 1163 loss: 2.53874896e-06
Iter: 1164 loss: 2.53756639e-06
Iter: 1165 loss: 2.5374934e-06
Iter: 1166 loss: 2.53630083e-06
Iter: 1167 loss: 2.53720236e-06
Iter: 1168 loss: 2.53563303e-06
Iter: 1169 loss: 2.53441044e-06
Iter: 1170 loss: 2.53721e-06
Iter: 1171 loss: 2.53401527e-06
Iter: 1172 loss: 2.53281542e-06
Iter: 1173 loss: 2.53926646e-06
Iter: 1174 loss: 2.53262806e-06
Iter: 1175 loss: 2.5317413e-06
Iter: 1176 loss: 2.53046596e-06
Iter: 1177 loss: 2.53037115e-06
Iter: 1178 loss: 2.52971472e-06
Iter: 1179 loss: 2.52948666e-06
Iter: 1180 loss: 2.5289969e-06
Iter: 1181 loss: 2.52768177e-06
Iter: 1182 loss: 2.53619737e-06
Iter: 1183 loss: 2.52739778e-06
Iter: 1184 loss: 2.52618952e-06
Iter: 1185 loss: 2.54004203e-06
Iter: 1186 loss: 2.5261993e-06
Iter: 1187 loss: 2.5246627e-06
Iter: 1188 loss: 2.52691325e-06
Iter: 1189 loss: 2.52394125e-06
Iter: 1190 loss: 2.52280552e-06
Iter: 1191 loss: 2.52202631e-06
Iter: 1192 loss: 2.52158611e-06
Iter: 1193 loss: 2.5192337e-06
Iter: 1194 loss: 2.52461859e-06
Iter: 1195 loss: 2.51833944e-06
Iter: 1196 loss: 2.51649817e-06
Iter: 1197 loss: 2.52575683e-06
Iter: 1198 loss: 2.51617712e-06
Iter: 1199 loss: 2.51597703e-06
Iter: 1200 loss: 2.51543952e-06
Iter: 1201 loss: 2.5150207e-06
Iter: 1202 loss: 2.51435881e-06
Iter: 1203 loss: 2.51435608e-06
Iter: 1204 loss: 2.51369056e-06
Iter: 1205 loss: 2.51369374e-06
Iter: 1206 loss: 2.5132e-06
Iter: 1207 loss: 2.51204415e-06
Iter: 1208 loss: 2.52902964e-06
Iter: 1209 loss: 2.51198685e-06
Iter: 1210 loss: 2.51101619e-06
Iter: 1211 loss: 2.5110362e-06
Iter: 1212 loss: 2.5101433e-06
Iter: 1213 loss: 2.50796461e-06
Iter: 1214 loss: 2.5312238e-06
Iter: 1215 loss: 2.50774065e-06
Iter: 1216 loss: 2.50612766e-06
Iter: 1217 loss: 2.50811468e-06
Iter: 1218 loss: 2.5052841e-06
Iter: 1219 loss: 2.50612766e-06
Iter: 1220 loss: 2.50477297e-06
Iter: 1221 loss: 2.50422272e-06
Iter: 1222 loss: 2.50340827e-06
Iter: 1223 loss: 2.50342032e-06
Iter: 1224 loss: 2.50260587e-06
Iter: 1225 loss: 2.50261655e-06
Iter: 1226 loss: 2.50195421e-06
Iter: 1227 loss: 2.5002571e-06
Iter: 1228 loss: 2.50048765e-06
Iter: 1229 loss: 2.49898085e-06
Iter: 1230 loss: 2.4973283e-06
Iter: 1231 loss: 2.50052017e-06
Iter: 1232 loss: 2.49662253e-06
Iter: 1233 loss: 2.49548202e-06
Iter: 1234 loss: 2.50892117e-06
Iter: 1235 loss: 2.49546474e-06
Iter: 1236 loss: 2.49436926e-06
Iter: 1237 loss: 2.5037989e-06
Iter: 1238 loss: 2.49429559e-06
Iter: 1239 loss: 2.49385312e-06
Iter: 1240 loss: 2.49387858e-06
Iter: 1241 loss: 2.4935398e-06
Iter: 1242 loss: 2.49266714e-06
Iter: 1243 loss: 2.49514665e-06
Iter: 1244 loss: 2.49242612e-06
Iter: 1245 loss: 2.49186292e-06
Iter: 1246 loss: 2.49057848e-06
Iter: 1247 loss: 2.50834137e-06
Iter: 1248 loss: 2.49055097e-06
Iter: 1249 loss: 2.48892638e-06
Iter: 1250 loss: 2.51249048e-06
Iter: 1251 loss: 2.48892366e-06
Iter: 1252 loss: 2.48821834e-06
Iter: 1253 loss: 2.48698666e-06
Iter: 1254 loss: 2.48698666e-06
Iter: 1255 loss: 2.48662241e-06
Iter: 1256 loss: 2.48650849e-06
Iter: 1257 loss: 2.48589458e-06
Iter: 1258 loss: 2.48500669e-06
Iter: 1259 loss: 2.48499146e-06
Iter: 1260 loss: 2.48408674e-06
Iter: 1261 loss: 2.48325046e-06
Iter: 1262 loss: 2.48297e-06
Iter: 1263 loss: 2.48152446e-06
Iter: 1264 loss: 2.48465244e-06
Iter: 1265 loss: 2.48094557e-06
Iter: 1266 loss: 2.47904427e-06
Iter: 1267 loss: 2.49653749e-06
Iter: 1268 loss: 2.47898333e-06
Iter: 1269 loss: 2.47812886e-06
Iter: 1270 loss: 2.47839216e-06
Iter: 1271 loss: 2.47751223e-06
Iter: 1272 loss: 2.47754315e-06
Iter: 1273 loss: 2.47713979e-06
Iter: 1274 loss: 2.47677417e-06
Iter: 1275 loss: 2.47590151e-06
Iter: 1276 loss: 2.48186711e-06
Iter: 1277 loss: 2.4757062e-06
Iter: 1278 loss: 2.47507728e-06
Iter: 1279 loss: 2.474947e-06
Iter: 1280 loss: 2.47439675e-06
Iter: 1281 loss: 2.47285152e-06
Iter: 1282 loss: 2.48466904e-06
Iter: 1283 loss: 2.47254798e-06
Iter: 1284 loss: 2.47227399e-06
Iter: 1285 loss: 2.47184971e-06
Iter: 1286 loss: 2.47119806e-06
Iter: 1287 loss: 2.46982427e-06
Iter: 1288 loss: 2.49309551e-06
Iter: 1289 loss: 2.4697847e-06
Iter: 1290 loss: 2.46929108e-06
Iter: 1291 loss: 2.46903301e-06
Iter: 1292 loss: 2.46870013e-06
Iter: 1293 loss: 2.46849959e-06
Iter: 1294 loss: 2.46836771e-06
Iter: 1295 loss: 2.4678086e-06
Iter: 1296 loss: 2.46778109e-06
Iter: 1297 loss: 2.46741592e-06
Iter: 1298 loss: 2.46679292e-06
Iter: 1299 loss: 2.46535819e-06
Iter: 1300 loss: 2.48247488e-06
Iter: 1301 loss: 2.46524678e-06
Iter: 1302 loss: 2.46368381e-06
Iter: 1303 loss: 2.46958689e-06
Iter: 1304 loss: 2.46334707e-06
Iter: 1305 loss: 2.46226728e-06
Iter: 1306 loss: 2.46215518e-06
Iter: 1307 loss: 2.46152649e-06
Iter: 1308 loss: 2.46062609e-06
Iter: 1309 loss: 2.4605863e-06
Iter: 1310 loss: 2.46006812e-06
Iter: 1311 loss: 2.46003401e-06
Iter: 1312 loss: 2.45935689e-06
Iter: 1313 loss: 2.45952333e-06
Iter: 1314 loss: 2.45890351e-06
Iter: 1315 loss: 2.45836964e-06
Iter: 1316 loss: 2.45925958e-06
Iter: 1317 loss: 2.45813317e-06
Iter: 1318 loss: 2.45722413e-06
Iter: 1319 loss: 2.45730052e-06
Iter: 1320 loss: 2.45646697e-06
Iter: 1321 loss: 2.45576189e-06
Iter: 1322 loss: 2.46160425e-06
Iter: 1323 loss: 2.45566457e-06
Iter: 1324 loss: 2.45473484e-06
Iter: 1325 loss: 2.45379147e-06
Iter: 1326 loss: 2.45363117e-06
Iter: 1327 loss: 2.45289084e-06
Iter: 1328 loss: 2.45664592e-06
Iter: 1329 loss: 2.4527526e-06
Iter: 1330 loss: 2.45207866e-06
Iter: 1331 loss: 2.45691012e-06
Iter: 1332 loss: 2.45195679e-06
Iter: 1333 loss: 2.45158344e-06
Iter: 1334 loss: 2.45076717e-06
Iter: 1335 loss: 2.46825243e-06
Iter: 1336 loss: 2.4507865e-06
Iter: 1337 loss: 2.44974717e-06
Iter: 1338 loss: 2.44855846e-06
Iter: 1339 loss: 2.44835155e-06
Iter: 1340 loss: 2.44646208e-06
Iter: 1341 loss: 2.45673482e-06
Iter: 1342 loss: 2.44622242e-06
Iter: 1343 loss: 2.44480771e-06
Iter: 1344 loss: 2.45535148e-06
Iter: 1345 loss: 2.44470198e-06
Iter: 1346 loss: 2.44442185e-06
Iter: 1347 loss: 2.44421199e-06
Iter: 1348 loss: 2.44385092e-06
Iter: 1349 loss: 2.44326111e-06
Iter: 1350 loss: 2.4432286e-06
Iter: 1351 loss: 2.44242847e-06
Iter: 1352 loss: 2.45196588e-06
Iter: 1353 loss: 2.44242301e-06
Iter: 1354 loss: 2.44195394e-06
Iter: 1355 loss: 2.44062221e-06
Iter: 1356 loss: 2.44380499e-06
Iter: 1357 loss: 2.43982845e-06
Iter: 1358 loss: 2.43954764e-06
Iter: 1359 loss: 2.43887825e-06
Iter: 1360 loss: 2.43800082e-06
Iter: 1361 loss: 2.43852173e-06
Iter: 1362 loss: 2.43744762e-06
Iter: 1363 loss: 2.43683257e-06
Iter: 1364 loss: 2.43659633e-06
Iter: 1365 loss: 2.43626073e-06
Iter: 1366 loss: 2.43559475e-06
Iter: 1367 loss: 2.43556474e-06
Iter: 1368 loss: 2.43523482e-06
Iter: 1369 loss: 2.43461091e-06
Iter: 1370 loss: 2.44777084e-06
Iter: 1371 loss: 2.43458385e-06
Iter: 1372 loss: 2.43385944e-06
Iter: 1373 loss: 2.44339435e-06
Iter: 1374 loss: 2.43384738e-06
Iter: 1375 loss: 2.43322552e-06
Iter: 1376 loss: 2.43178192e-06
Iter: 1377 loss: 2.45249748e-06
Iter: 1378 loss: 2.43169598e-06
Iter: 1379 loss: 2.43007548e-06
Iter: 1380 loss: 2.43183331e-06
Iter: 1381 loss: 2.42923625e-06
Iter: 1382 loss: 2.42831538e-06
Iter: 1383 loss: 2.42826309e-06
Iter: 1384 loss: 2.42747183e-06
Iter: 1385 loss: 2.42694114e-06
Iter: 1386 loss: 2.42668739e-06
Iter: 1387 loss: 2.426229e-06
Iter: 1388 loss: 2.43098702e-06
Iter: 1389 loss: 2.42617534e-06
Iter: 1390 loss: 2.42548163e-06
Iter: 1391 loss: 2.42485476e-06
Iter: 1392 loss: 2.42469332e-06
Iter: 1393 loss: 2.42392434e-06
Iter: 1394 loss: 2.42465808e-06
Iter: 1395 loss: 2.42353553e-06
Iter: 1396 loss: 2.42241458e-06
Iter: 1397 loss: 2.43110094e-06
Iter: 1398 loss: 2.42229748e-06
Iter: 1399 loss: 2.42167448e-06
Iter: 1400 loss: 2.42151737e-06
Iter: 1401 loss: 2.4211156e-06
Iter: 1402 loss: 2.42041688e-06
Iter: 1403 loss: 2.42044e-06
Iter: 1404 loss: 2.42013584e-06
Iter: 1405 loss: 2.41971884e-06
Iter: 1406 loss: 2.41971043e-06
Iter: 1407 loss: 2.41916291e-06
Iter: 1408 loss: 2.42488386e-06
Iter: 1409 loss: 2.41913403e-06
Iter: 1410 loss: 2.41880844e-06
Iter: 1411 loss: 2.4178396e-06
Iter: 1412 loss: 2.42301621e-06
Iter: 1413 loss: 2.41754333e-06
Iter: 1414 loss: 2.41594671e-06
Iter: 1415 loss: 2.41710359e-06
Iter: 1416 loss: 2.41493944e-06
Iter: 1417 loss: 2.41394059e-06
Iter: 1418 loss: 2.4138817e-06
Iter: 1419 loss: 2.41331418e-06
Iter: 1420 loss: 2.4132803e-06
Iter: 1421 loss: 2.41297812e-06
Iter: 1422 loss: 2.41310363e-06
Iter: 1423 loss: 2.41275211e-06
Iter: 1424 loss: 2.41226235e-06
Iter: 1425 loss: 2.41405269e-06
Iter: 1426 loss: 2.41214502e-06
Iter: 1427 loss: 2.41184284e-06
Iter: 1428 loss: 2.41101111e-06
Iter: 1429 loss: 2.41705766e-06
Iter: 1430 loss: 2.41077714e-06
Iter: 1431 loss: 2.4101605e-06
Iter: 1432 loss: 2.41004045e-06
Iter: 1433 loss: 2.40927375e-06
Iter: 1434 loss: 2.40797817e-06
Iter: 1435 loss: 2.40796044e-06
Iter: 1436 loss: 2.40734585e-06
Iter: 1437 loss: 2.40733789e-06
Iter: 1438 loss: 2.40668805e-06
Iter: 1439 loss: 2.40630516e-06
Iter: 1440 loss: 2.40602958e-06
Iter: 1441 loss: 2.40545114e-06
Iter: 1442 loss: 2.41253292e-06
Iter: 1443 loss: 2.4054284e-06
Iter: 1444 loss: 2.40485315e-06
Iter: 1445 loss: 2.40404188e-06
Iter: 1446 loss: 2.40400459e-06
Iter: 1447 loss: 2.40297118e-06
Iter: 1448 loss: 2.40422855e-06
Iter: 1449 loss: 2.40241343e-06
Iter: 1450 loss: 2.40158852e-06
Iter: 1451 loss: 2.40925965e-06
Iter: 1452 loss: 2.40148802e-06
Iter: 1453 loss: 2.40066333e-06
Iter: 1454 loss: 2.40099916e-06
Iter: 1455 loss: 2.40011286e-06
Iter: 1456 loss: 2.39910014e-06
Iter: 1457 loss: 2.40751365e-06
Iter: 1458 loss: 2.39905739e-06
Iter: 1459 loss: 2.39847941e-06
Iter: 1460 loss: 2.39798919e-06
Iter: 1461 loss: 2.39784117e-06
Iter: 1462 loss: 2.39724386e-06
Iter: 1463 loss: 2.39794281e-06
Iter: 1464 loss: 2.39693327e-06
Iter: 1465 loss: 2.39616838e-06
Iter: 1466 loss: 2.40531153e-06
Iter: 1467 loss: 2.39616543e-06
Iter: 1468 loss: 2.39579595e-06
Iter: 1469 loss: 2.39533756e-06
Iter: 1470 loss: 2.39532e-06
Iter: 1471 loss: 2.39440601e-06
Iter: 1472 loss: 2.39906058e-06
Iter: 1473 loss: 2.39431256e-06
Iter: 1474 loss: 2.3936127e-06
Iter: 1475 loss: 2.3940795e-06
Iter: 1476 loss: 2.39321662e-06
Iter: 1477 loss: 2.39219071e-06
Iter: 1478 loss: 2.39508859e-06
Iter: 1479 loss: 2.39183191e-06
Iter: 1480 loss: 2.39134943e-06
Iter: 1481 loss: 2.39119208e-06
Iter: 1482 loss: 2.39091514e-06
Iter: 1483 loss: 2.39046653e-06
Iter: 1484 loss: 2.39045858e-06
Iter: 1485 loss: 2.39011888e-06
Iter: 1486 loss: 2.38958819e-06
Iter: 1487 loss: 2.38951679e-06
Iter: 1488 loss: 2.38871417e-06
Iter: 1489 loss: 2.39363339e-06
Iter: 1490 loss: 2.38863572e-06
Iter: 1491 loss: 2.38769462e-06
Iter: 1492 loss: 2.38697839e-06
Iter: 1493 loss: 2.38669645e-06
Iter: 1494 loss: 2.38572511e-06
Iter: 1495 loss: 2.38636403e-06
Iter: 1496 loss: 2.38509438e-06
Iter: 1497 loss: 2.38511529e-06
Iter: 1498 loss: 2.38464577e-06
Iter: 1499 loss: 2.38421421e-06
Iter: 1500 loss: 2.38337407e-06
Iter: 1501 loss: 2.39640121e-06
Iter: 1502 loss: 2.38332859e-06
Iter: 1503 loss: 2.38291091e-06
Iter: 1504 loss: 2.38288249e-06
Iter: 1505 loss: 2.38243524e-06
Iter: 1506 loss: 2.38178677e-06
Iter: 1507 loss: 2.38178154e-06
Iter: 1508 loss: 2.38105167e-06
Iter: 1509 loss: 2.38881444e-06
Iter: 1510 loss: 2.38100347e-06
Iter: 1511 loss: 2.38037092e-06
Iter: 1512 loss: 2.37876975e-06
Iter: 1513 loss: 2.3941152e-06
Iter: 1514 loss: 2.37855124e-06
Iter: 1515 loss: 2.37853283e-06
Iter: 1516 loss: 2.37792e-06
Iter: 1517 loss: 2.37733707e-06
Iter: 1518 loss: 2.37776089e-06
Iter: 1519 loss: 2.37702147e-06
Iter: 1520 loss: 2.37640643e-06
Iter: 1521 loss: 2.37765721e-06
Iter: 1522 loss: 2.37614836e-06
Iter: 1523 loss: 2.37537779e-06
Iter: 1524 loss: 2.37759332e-06
Iter: 1525 loss: 2.37509175e-06
Iter: 1526 loss: 2.3743894e-06
Iter: 1527 loss: 2.37282393e-06
Iter: 1528 loss: 2.39252313e-06
Iter: 1529 loss: 2.37265795e-06
Iter: 1530 loss: 2.37076051e-06
Iter: 1531 loss: 2.37827226e-06
Iter: 1532 loss: 2.37027552e-06
Iter: 1533 loss: 2.3689895e-06
Iter: 1534 loss: 2.36889946e-06
Iter: 1535 loss: 2.36815299e-06
Iter: 1536 loss: 2.36689903e-06
Iter: 1537 loss: 2.36688584e-06
Iter: 1538 loss: 2.3668008e-06
Iter: 1539 loss: 2.36636606e-06
Iter: 1540 loss: 2.36605456e-06
Iter: 1541 loss: 2.36531059e-06
Iter: 1542 loss: 2.37329732e-06
Iter: 1543 loss: 2.36526785e-06
Iter: 1544 loss: 2.36416076e-06
Iter: 1545 loss: 2.37111067e-06
Iter: 1546 loss: 2.36404162e-06
Iter: 1547 loss: 2.36331198e-06
Iter: 1548 loss: 2.3618893e-06
Iter: 1549 loss: 2.388962e-06
Iter: 1550 loss: 2.36189499e-06
Iter: 1551 loss: 2.36091864e-06
Iter: 1552 loss: 2.36084452e-06
Iter: 1553 loss: 2.35978359e-06
Iter: 1554 loss: 2.35903508e-06
Iter: 1555 loss: 2.3586972e-06
Iter: 1556 loss: 2.35778361e-06
Iter: 1557 loss: 2.35778884e-06
Iter: 1558 loss: 2.3572893e-06
Iter: 1559 loss: 2.35704533e-06
Iter: 1560 loss: 2.35680659e-06
Iter: 1561 loss: 2.35627613e-06
Iter: 1562 loss: 2.35716038e-06
Iter: 1563 loss: 2.35603648e-06
Iter: 1564 loss: 2.35547077e-06
Iter: 1565 loss: 2.35755419e-06
Iter: 1566 loss: 2.35535299e-06
Iter: 1567 loss: 2.35466359e-06
Iter: 1568 loss: 2.35381481e-06
Iter: 1569 loss: 2.35360835e-06
Iter: 1570 loss: 2.35275775e-06
Iter: 1571 loss: 2.35909692e-06
Iter: 1572 loss: 2.35268817e-06
Iter: 1573 loss: 2.35156904e-06
Iter: 1574 loss: 2.35206244e-06
Iter: 1575 loss: 2.35074594e-06
Iter: 1576 loss: 2.34997333e-06
Iter: 1577 loss: 2.35598873e-06
Iter: 1578 loss: 2.34989648e-06
Iter: 1579 loss: 2.34908566e-06
Iter: 1580 loss: 2.34833124e-06
Iter: 1581 loss: 2.34810591e-06
Iter: 1582 loss: 2.34717754e-06
Iter: 1583 loss: 2.34746858e-06
Iter: 1584 loss: 2.34656636e-06
Iter: 1585 loss: 2.3458108e-06
Iter: 1586 loss: 2.34569166e-06
Iter: 1587 loss: 2.34514664e-06
Iter: 1588 loss: 2.34411391e-06
Iter: 1589 loss: 2.34411164e-06
Iter: 1590 loss: 2.34275058e-06
Iter: 1591 loss: 2.3525447e-06
Iter: 1592 loss: 2.34261415e-06
Iter: 1593 loss: 2.34204595e-06
Iter: 1594 loss: 2.34194476e-06
Iter: 1595 loss: 2.34156687e-06
Iter: 1596 loss: 2.34074e-06
Iter: 1597 loss: 2.34950153e-06
Iter: 1598 loss: 2.34071877e-06
Iter: 1599 loss: 2.33987339e-06
Iter: 1600 loss: 2.34148411e-06
Iter: 1601 loss: 2.33958599e-06
Iter: 1602 loss: 2.33907667e-06
Iter: 1603 loss: 2.33897936e-06
Iter: 1604 loss: 2.33862875e-06
Iter: 1605 loss: 2.33774335e-06
Iter: 1606 loss: 2.34528784e-06
Iter: 1607 loss: 2.33765877e-06
Iter: 1608 loss: 2.33709034e-06
Iter: 1609 loss: 2.3360119e-06
Iter: 1610 loss: 2.33601304e-06
Iter: 1611 loss: 2.33476067e-06
Iter: 1612 loss: 2.35149628e-06
Iter: 1613 loss: 2.3347468e-06
Iter: 1614 loss: 2.33412788e-06
Iter: 1615 loss: 2.33277524e-06
Iter: 1616 loss: 2.35256471e-06
Iter: 1617 loss: 2.33277387e-06
Iter: 1618 loss: 2.3319883e-06
Iter: 1619 loss: 2.3319833e-06
Iter: 1620 loss: 2.33104356e-06
Iter: 1621 loss: 2.33244486e-06
Iter: 1622 loss: 2.33062315e-06
Iter: 1623 loss: 2.32990237e-06
Iter: 1624 loss: 2.33276705e-06
Iter: 1625 loss: 2.3297689e-06
Iter: 1626 loss: 2.32897901e-06
Iter: 1627 loss: 2.32872753e-06
Iter: 1628 loss: 2.32829552e-06
Iter: 1629 loss: 2.32747198e-06
Iter: 1630 loss: 2.33204082e-06
Iter: 1631 loss: 2.32737193e-06
Iter: 1632 loss: 2.32645516e-06
Iter: 1633 loss: 2.3290736e-06
Iter: 1634 loss: 2.32615548e-06
Iter: 1635 loss: 2.3253981e-06
Iter: 1636 loss: 2.32466596e-06
Iter: 1637 loss: 2.32450066e-06
Iter: 1638 loss: 2.32395337e-06
Iter: 1639 loss: 2.32389834e-06
Iter: 1640 loss: 2.32334332e-06
Iter: 1641 loss: 2.32293814e-06
Iter: 1642 loss: 2.32273169e-06
Iter: 1643 loss: 2.32223965e-06
Iter: 1644 loss: 2.32841126e-06
Iter: 1645 loss: 2.32222374e-06
Iter: 1646 loss: 2.32179013e-06
Iter: 1647 loss: 2.3208e-06
Iter: 1648 loss: 2.33743822e-06
Iter: 1649 loss: 2.32076127e-06
Iter: 1650 loss: 2.31981e-06
Iter: 1651 loss: 2.31931062e-06
Iter: 1652 loss: 2.31886656e-06
Iter: 1653 loss: 2.31901276e-06
Iter: 1654 loss: 2.31827926e-06
Iter: 1655 loss: 2.31768399e-06
Iter: 1656 loss: 2.31701733e-06
Iter: 1657 loss: 2.31692638e-06
Iter: 1658 loss: 2.31623721e-06
Iter: 1659 loss: 2.32388152e-06
Iter: 1660 loss: 2.31623108e-06
Iter: 1661 loss: 2.31572676e-06
Iter: 1662 loss: 2.31489776e-06
Iter: 1663 loss: 2.31488775e-06
Iter: 1664 loss: 2.31426338e-06
Iter: 1665 loss: 2.31428567e-06
Iter: 1666 loss: 2.31358581e-06
Iter: 1667 loss: 2.31371951e-06
Iter: 1668 loss: 2.3130815e-06
Iter: 1669 loss: 2.31254785e-06
Iter: 1670 loss: 2.31250237e-06
Iter: 1671 loss: 2.3120765e-06
Iter: 1672 loss: 2.31097e-06
Iter: 1673 loss: 2.31544391e-06
Iter: 1674 loss: 2.31073636e-06
Iter: 1675 loss: 2.30995897e-06
Iter: 1676 loss: 2.31336708e-06
Iter: 1677 loss: 2.30974956e-06
Iter: 1678 loss: 2.30909313e-06
Iter: 1679 loss: 2.31043964e-06
Iter: 1680 loss: 2.30878231e-06
Iter: 1681 loss: 2.30828846e-06
Iter: 1682 loss: 2.30711157e-06
Iter: 1683 loss: 2.32411503e-06
Iter: 1684 loss: 2.30709543e-06
Iter: 1685 loss: 2.30642218e-06
Iter: 1686 loss: 2.30637534e-06
Iter: 1687 loss: 2.30573164e-06
Iter: 1688 loss: 2.31120976e-06
Iter: 1689 loss: 2.30569276e-06
Iter: 1690 loss: 2.30532669e-06
Iter: 1691 loss: 2.3048151e-06
Iter: 1692 loss: 2.30476235e-06
Iter: 1693 loss: 2.30385012e-06
Iter: 1694 loss: 2.30664682e-06
Iter: 1695 loss: 2.3035509e-06
Iter: 1696 loss: 2.30283399e-06
Iter: 1697 loss: 2.30240107e-06
Iter: 1698 loss: 2.3020898e-06
Iter: 1699 loss: 2.30095793e-06
Iter: 1700 loss: 2.31884337e-06
Iter: 1701 loss: 2.30098135e-06
Iter: 1702 loss: 2.30053433e-06
Iter: 1703 loss: 2.29953866e-06
Iter: 1704 loss: 2.31382114e-06
Iter: 1705 loss: 2.29948455e-06
Iter: 1706 loss: 2.29856619e-06
Iter: 1707 loss: 2.29857187e-06
Iter: 1708 loss: 2.29800253e-06
Iter: 1709 loss: 2.29786974e-06
Iter: 1710 loss: 2.29750299e-06
Iter: 1711 loss: 2.2967331e-06
Iter: 1712 loss: 2.30254363e-06
Iter: 1713 loss: 2.29663146e-06
Iter: 1714 loss: 2.29608054e-06
Iter: 1715 loss: 2.29459238e-06
Iter: 1716 loss: 2.30662476e-06
Iter: 1717 loss: 2.29435227e-06
Iter: 1718 loss: 2.29259558e-06
Iter: 1719 loss: 2.30159367e-06
Iter: 1720 loss: 2.29234229e-06
Iter: 1721 loss: 2.29226816e-06
Iter: 1722 loss: 2.29168927e-06
Iter: 1723 loss: 2.29113903e-06
Iter: 1724 loss: 2.28999875e-06
Iter: 1725 loss: 2.30599767e-06
Iter: 1726 loss: 2.28993849e-06
Iter: 1727 loss: 2.2893e-06
Iter: 1728 loss: 2.28924819e-06
Iter: 1729 loss: 2.28882936e-06
Iter: 1730 loss: 2.28787258e-06
Iter: 1731 loss: 2.29868e-06
Iter: 1732 loss: 2.28779595e-06
Iter: 1733 loss: 2.28741828e-06
Iter: 1734 loss: 2.28725685e-06
Iter: 1735 loss: 2.28660724e-06
Iter: 1736 loss: 2.2851325e-06
Iter: 1737 loss: 2.3038333e-06
Iter: 1738 loss: 2.28500903e-06
Iter: 1739 loss: 2.28390718e-06
Iter: 1740 loss: 2.29972261e-06
Iter: 1741 loss: 2.28392037e-06
Iter: 1742 loss: 2.2827528e-06
Iter: 1743 loss: 2.28449744e-06
Iter: 1744 loss: 2.28232102e-06
Iter: 1745 loss: 2.28147042e-06
Iter: 1746 loss: 2.28663521e-06
Iter: 1747 loss: 2.28141789e-06
Iter: 1748 loss: 2.28061162e-06
Iter: 1749 loss: 2.27895066e-06
Iter: 1750 loss: 2.30455112e-06
Iter: 1751 loss: 2.27888449e-06
Iter: 1752 loss: 2.27760393e-06
Iter: 1753 loss: 2.28092972e-06
Iter: 1754 loss: 2.27721853e-06
Iter: 1755 loss: 2.27630039e-06
Iter: 1756 loss: 2.28662657e-06
Iter: 1757 loss: 2.27626788e-06
Iter: 1758 loss: 2.27516193e-06
Iter: 1759 loss: 2.27589271e-06
Iter: 1760 loss: 2.27449755e-06
Iter: 1761 loss: 2.27375813e-06
Iter: 1762 loss: 2.27678174e-06
Iter: 1763 loss: 2.27355713e-06
Iter: 1764 loss: 2.27266787e-06
Iter: 1765 loss: 2.2720792e-06
Iter: 1766 loss: 2.2716838e-06
Iter: 1767 loss: 2.27068585e-06
Iter: 1768 loss: 2.2750587e-06
Iter: 1769 loss: 2.27050487e-06
Iter: 1770 loss: 2.26952034e-06
Iter: 1771 loss: 2.27943633e-06
Iter: 1772 loss: 2.26951897e-06
Iter: 1773 loss: 2.269059e-06
Iter: 1774 loss: 2.2681686e-06
Iter: 1775 loss: 2.28779459e-06
Iter: 1776 loss: 2.26819202e-06
Iter: 1777 loss: 2.26738393e-06
Iter: 1778 loss: 2.26736984e-06
Iter: 1779 loss: 2.26679936e-06
Iter: 1780 loss: 2.26591033e-06
Iter: 1781 loss: 2.26588281e-06
Iter: 1782 loss: 2.26435668e-06
Iter: 1783 loss: 2.27165515e-06
Iter: 1784 loss: 2.264062e-06
Iter: 1785 loss: 2.26343809e-06
Iter: 1786 loss: 2.26254178e-06
Iter: 1787 loss: 2.26251541e-06
Iter: 1788 loss: 2.26150314e-06
Iter: 1789 loss: 2.26666839e-06
Iter: 1790 loss: 2.26134239e-06
Iter: 1791 loss: 2.26055135e-06
Iter: 1792 loss: 2.26050724e-06
Iter: 1793 loss: 2.26013412e-06
Iter: 1794 loss: 2.25919121e-06
Iter: 1795 loss: 2.27235751e-06
Iter: 1796 loss: 2.25913209e-06
Iter: 1797 loss: 2.25802614e-06
Iter: 1798 loss: 2.26919428e-06
Iter: 1799 loss: 2.25801227e-06
Iter: 1800 loss: 2.25722e-06
Iter: 1801 loss: 2.25609688e-06
Iter: 1802 loss: 2.25607982e-06
Iter: 1803 loss: 2.2560871e-06
Iter: 1804 loss: 2.25552685e-06
Iter: 1805 loss: 2.25507029e-06
Iter: 1806 loss: 2.25405506e-06
Iter: 1807 loss: 2.2653312e-06
Iter: 1808 loss: 2.25393524e-06
Iter: 1809 loss: 2.25343865e-06
Iter: 1810 loss: 2.25336589e-06
Iter: 1811 loss: 2.25272834e-06
Iter: 1812 loss: 2.25241388e-06
Iter: 1813 loss: 2.25210647e-06
Iter: 1814 loss: 2.25141548e-06
Iter: 1815 loss: 2.25476902e-06
Iter: 1816 loss: 2.25130134e-06
Iter: 1817 loss: 2.25034182e-06
Iter: 1818 loss: 2.24969585e-06
Iter: 1819 loss: 2.24930091e-06
Iter: 1820 loss: 2.24810015e-06
Iter: 1821 loss: 2.24799078e-06
Iter: 1822 loss: 2.24713222e-06
Iter: 1823 loss: 2.24706491e-06
Iter: 1824 loss: 2.24629548e-06
Iter: 1825 loss: 2.2454783e-06
Iter: 1826 loss: 2.24451742e-06
Iter: 1827 loss: 2.24441192e-06
Iter: 1828 loss: 2.24354653e-06
Iter: 1829 loss: 2.24765358e-06
Iter: 1830 loss: 2.24338919e-06
Iter: 1831 loss: 2.2422746e-06
Iter: 1832 loss: 2.24276459e-06
Iter: 1833 loss: 2.24158839e-06
Iter: 1834 loss: 2.24106e-06
Iter: 1835 loss: 2.24105338e-06
Iter: 1836 loss: 2.240512e-06
Iter: 1837 loss: 2.23934944e-06
Iter: 1838 loss: 2.26089287e-06
Iter: 1839 loss: 2.23933716e-06
Iter: 1840 loss: 2.23840721e-06
Iter: 1841 loss: 2.24563473e-06
Iter: 1842 loss: 2.23834945e-06
Iter: 1843 loss: 2.23741426e-06
Iter: 1844 loss: 2.24291284e-06
Iter: 1845 loss: 2.23726306e-06
Iter: 1846 loss: 2.23675761e-06
Iter: 1847 loss: 2.23616712e-06
Iter: 1848 loss: 2.23605639e-06
Iter: 1849 loss: 2.23514144e-06
Iter: 1850 loss: 2.24843939e-06
Iter: 1851 loss: 2.23513689e-06
Iter: 1852 loss: 2.23473717e-06
Iter: 1853 loss: 2.23387974e-06
Iter: 1854 loss: 2.24638757e-06
Iter: 1855 loss: 2.23385064e-06
Iter: 1856 loss: 2.23354573e-06
Iter: 1857 loss: 2.23339703e-06
Iter: 1858 loss: 2.23296547e-06
Iter: 1859 loss: 2.23254392e-06
Iter: 1860 loss: 2.2324657e-06
Iter: 1861 loss: 2.23178404e-06
Iter: 1862 loss: 2.23151574e-06
Iter: 1863 loss: 2.23113739e-06
Iter: 1864 loss: 2.22982771e-06
Iter: 1865 loss: 2.23565758e-06
Iter: 1866 loss: 2.22962626e-06
Iter: 1867 loss: 2.22890026e-06
Iter: 1868 loss: 2.23283473e-06
Iter: 1869 loss: 2.22879044e-06
Iter: 1870 loss: 2.228016e-06
Iter: 1871 loss: 2.22993799e-06
Iter: 1872 loss: 2.22771496e-06
Iter: 1873 loss: 2.22712924e-06
Iter: 1874 loss: 2.22598624e-06
Iter: 1875 loss: 2.24650057e-06
Iter: 1876 loss: 2.22599988e-06
Iter: 1877 loss: 2.226069e-06
Iter: 1878 loss: 2.22539938e-06
Iter: 1879 loss: 2.22495942e-06
Iter: 1880 loss: 2.22415338e-06
Iter: 1881 loss: 2.2398558e-06
Iter: 1882 loss: 2.22412814e-06
Iter: 1883 loss: 2.22307949e-06
Iter: 1884 loss: 2.22146e-06
Iter: 1885 loss: 2.22139101e-06
Iter: 1886 loss: 2.22094059e-06
Iter: 1887 loss: 2.22054405e-06
Iter: 1888 loss: 2.2197728e-06
Iter: 1889 loss: 2.22369226e-06
Iter: 1890 loss: 2.21965183e-06
Iter: 1891 loss: 2.21922e-06
Iter: 1892 loss: 2.21993423e-06
Iter: 1893 loss: 2.2190452e-06
Iter: 1894 loss: 2.2182237e-06
Iter: 1895 loss: 2.217575e-06
Iter: 1896 loss: 2.21735968e-06
Iter: 1897 loss: 2.21624805e-06
Iter: 1898 loss: 2.21758819e-06
Iter: 1899 loss: 2.21562595e-06
Iter: 1900 loss: 2.21410073e-06
Iter: 1901 loss: 2.22093422e-06
Iter: 1902 loss: 2.21380333e-06
Iter: 1903 loss: 2.2131826e-06
Iter: 1904 loss: 2.21438859e-06
Iter: 1905 loss: 2.21302253e-06
Iter: 1906 loss: 2.21206847e-06
Iter: 1907 loss: 2.21566552e-06
Iter: 1908 loss: 2.21182336e-06
Iter: 1909 loss: 2.21130585e-06
Iter: 1910 loss: 2.21025857e-06
Iter: 1911 loss: 2.2313543e-06
Iter: 1912 loss: 2.2102181e-06
Iter: 1913 loss: 2.20890252e-06
Iter: 1914 loss: 2.20936818e-06
Iter: 1915 loss: 2.20797892e-06
Iter: 1916 loss: 2.20806123e-06
Iter: 1917 loss: 2.20719539e-06
Iter: 1918 loss: 2.20671154e-06
Iter: 1919 loss: 2.20541415e-06
Iter: 1920 loss: 2.21333585e-06
Iter: 1921 loss: 2.2050524e-06
Iter: 1922 loss: 2.20422771e-06
Iter: 1923 loss: 2.20419633e-06
Iter: 1924 loss: 2.2034244e-06
Iter: 1925 loss: 2.20870061e-06
Iter: 1926 loss: 2.20334482e-06
Iter: 1927 loss: 2.20295851e-06
Iter: 1928 loss: 2.20433594e-06
Iter: 1929 loss: 2.20284755e-06
Iter: 1930 loss: 2.20225024e-06
Iter: 1931 loss: 2.20142874e-06
Iter: 1932 loss: 2.20139e-06
Iter: 1933 loss: 2.2006102e-06
Iter: 1934 loss: 2.20286347e-06
Iter: 1935 loss: 2.20040147e-06
Iter: 1936 loss: 2.19911203e-06
Iter: 1937 loss: 2.19794083e-06
Iter: 1938 loss: 2.19763365e-06
Iter: 1939 loss: 2.19727235e-06
Iter: 1940 loss: 2.19704157e-06
Iter: 1941 loss: 2.19644789e-06
Iter: 1942 loss: 2.19576e-06
Iter: 1943 loss: 2.19575259e-06
Iter: 1944 loss: 2.19487947e-06
Iter: 1945 loss: 2.19358253e-06
Iter: 1946 loss: 2.19355e-06
Iter: 1947 loss: 2.19220738e-06
Iter: 1948 loss: 2.20175161e-06
Iter: 1949 loss: 2.19202639e-06
Iter: 1950 loss: 2.19042022e-06
Iter: 1951 loss: 2.20063657e-06
Iter: 1952 loss: 2.19021103e-06
Iter: 1953 loss: 2.18938203e-06
Iter: 1954 loss: 2.18823197e-06
Iter: 1955 loss: 2.18823538e-06
Iter: 1956 loss: 2.18746754e-06
Iter: 1957 loss: 2.18744481e-06
Iter: 1958 loss: 2.1866565e-06
Iter: 1959 loss: 2.18614014e-06
Iter: 1960 loss: 2.18581795e-06
Iter: 1961 loss: 2.18560626e-06
Iter: 1962 loss: 2.18542164e-06
Iter: 1963 loss: 2.1851622e-06
Iter: 1964 loss: 2.1843141e-06
Iter: 1965 loss: 2.18780497e-06
Iter: 1966 loss: 2.18408468e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4
+ date
Mon Oct 26 09:18:45 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152b22158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152ac7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152ac7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152ba0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152b6ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152a31378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152a09f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81529a6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81529b5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81529b5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815294a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815294ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815294eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81528f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81528f89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152896bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152889400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81528922f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815285cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152892950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81528008c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81527c8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815276f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815278cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8152791048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f815273dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81342aa8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81342609d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f813426d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f813426d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f813421f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81341ee6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81341ee158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f813419e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81341b6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f810c101b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.01143848e-05
Iter: 2 loss: 1.8363824e-05
Iter: 3 loss: 3.87463806e-05
Iter: 4 loss: 1.83355696e-05
Iter: 5 loss: 1.77637394e-05
Iter: 6 loss: 2.47028165e-05
Iter: 7 loss: 1.77569709e-05
Iter: 8 loss: 1.74483503e-05
Iter: 9 loss: 1.74472807e-05
Iter: 10 loss: 1.72013279e-05
Iter: 11 loss: 1.6893815e-05
Iter: 12 loss: 2.01170224e-05
Iter: 13 loss: 1.68854986e-05
Iter: 14 loss: 1.66096288e-05
Iter: 15 loss: 1.61939552e-05
Iter: 16 loss: 1.61855169e-05
Iter: 17 loss: 1.59672818e-05
Iter: 18 loss: 1.82359363e-05
Iter: 19 loss: 1.59611627e-05
Iter: 20 loss: 1.56858696e-05
Iter: 21 loss: 1.56072238e-05
Iter: 22 loss: 1.54400568e-05
Iter: 23 loss: 1.51805652e-05
Iter: 24 loss: 1.52840203e-05
Iter: 25 loss: 1.50010383e-05
Iter: 26 loss: 1.49708376e-05
Iter: 27 loss: 1.48643139e-05
Iter: 28 loss: 1.47848805e-05
Iter: 29 loss: 1.45705226e-05
Iter: 30 loss: 1.59689043e-05
Iter: 31 loss: 1.45175809e-05
Iter: 32 loss: 1.42691651e-05
Iter: 33 loss: 1.44191208e-05
Iter: 34 loss: 1.41093915e-05
Iter: 35 loss: 1.38407986e-05
Iter: 36 loss: 1.48922309e-05
Iter: 37 loss: 1.37790539e-05
Iter: 38 loss: 1.35801729e-05
Iter: 39 loss: 1.59886476e-05
Iter: 40 loss: 1.35778191e-05
Iter: 41 loss: 1.341196e-05
Iter: 42 loss: 1.52122293e-05
Iter: 43 loss: 1.34083029e-05
Iter: 44 loss: 1.33277608e-05
Iter: 45 loss: 1.33580943e-05
Iter: 46 loss: 1.32718851e-05
Iter: 47 loss: 1.3155e-05
Iter: 48 loss: 1.37073894e-05
Iter: 49 loss: 1.31338e-05
Iter: 50 loss: 1.30232766e-05
Iter: 51 loss: 1.29401615e-05
Iter: 52 loss: 1.2903889e-05
Iter: 53 loss: 1.2751495e-05
Iter: 54 loss: 1.31621136e-05
Iter: 55 loss: 1.27010298e-05
Iter: 56 loss: 1.26056912e-05
Iter: 57 loss: 1.26001696e-05
Iter: 58 loss: 1.25568304e-05
Iter: 59 loss: 1.2435381e-05
Iter: 60 loss: 1.30819681e-05
Iter: 61 loss: 1.23973114e-05
Iter: 62 loss: 1.24077815e-05
Iter: 63 loss: 1.23392801e-05
Iter: 64 loss: 1.22837828e-05
Iter: 65 loss: 1.21488574e-05
Iter: 66 loss: 1.35808395e-05
Iter: 67 loss: 1.21342018e-05
Iter: 68 loss: 1.1996015e-05
Iter: 69 loss: 1.222827e-05
Iter: 70 loss: 1.19336783e-05
Iter: 71 loss: 1.18026619e-05
Iter: 72 loss: 1.1992377e-05
Iter: 73 loss: 1.17389081e-05
Iter: 74 loss: 1.16652081e-05
Iter: 75 loss: 1.16651381e-05
Iter: 76 loss: 1.164481e-05
Iter: 77 loss: 1.16387509e-05
Iter: 78 loss: 1.16095953e-05
Iter: 79 loss: 1.15356679e-05
Iter: 80 loss: 1.21903086e-05
Iter: 81 loss: 1.15241128e-05
Iter: 82 loss: 1.14837476e-05
Iter: 83 loss: 1.14754112e-05
Iter: 84 loss: 1.14390177e-05
Iter: 85 loss: 1.13995238e-05
Iter: 86 loss: 1.13933693e-05
Iter: 87 loss: 1.13202696e-05
Iter: 88 loss: 1.1346865e-05
Iter: 89 loss: 1.1269095e-05
Iter: 90 loss: 1.12302005e-05
Iter: 91 loss: 1.1222528e-05
Iter: 92 loss: 1.11900099e-05
Iter: 93 loss: 1.11408444e-05
Iter: 94 loss: 1.11398749e-05
Iter: 95 loss: 1.10985129e-05
Iter: 96 loss: 1.12444068e-05
Iter: 97 loss: 1.10876781e-05
Iter: 98 loss: 1.10334995e-05
Iter: 99 loss: 1.1305553e-05
Iter: 100 loss: 1.102444e-05
Iter: 101 loss: 1.09846987e-05
Iter: 102 loss: 1.08835393e-05
Iter: 103 loss: 1.17551845e-05
Iter: 104 loss: 1.08668864e-05
Iter: 105 loss: 1.07618898e-05
Iter: 106 loss: 1.12409825e-05
Iter: 107 loss: 1.07418045e-05
Iter: 108 loss: 1.06643474e-05
Iter: 109 loss: 1.09850062e-05
Iter: 110 loss: 1.06476073e-05
Iter: 111 loss: 1.06867956e-05
Iter: 112 loss: 1.0627853e-05
Iter: 113 loss: 1.06125362e-05
Iter: 114 loss: 1.05823765e-05
Iter: 115 loss: 1.11802619e-05
Iter: 116 loss: 1.05820964e-05
Iter: 117 loss: 1.05562804e-05
Iter: 118 loss: 1.09116772e-05
Iter: 119 loss: 1.05562249e-05
Iter: 120 loss: 1.05281442e-05
Iter: 121 loss: 1.0464586e-05
Iter: 122 loss: 1.13201904e-05
Iter: 123 loss: 1.04608598e-05
Iter: 124 loss: 1.04165829e-05
Iter: 125 loss: 1.04164383e-05
Iter: 126 loss: 1.03874299e-05
Iter: 127 loss: 1.05435156e-05
Iter: 128 loss: 1.03831026e-05
Iter: 129 loss: 1.03552684e-05
Iter: 130 loss: 1.03178018e-05
Iter: 131 loss: 1.0315749e-05
Iter: 132 loss: 1.02809427e-05
Iter: 133 loss: 1.05090649e-05
Iter: 134 loss: 1.02771792e-05
Iter: 135 loss: 1.02437352e-05
Iter: 136 loss: 1.04914707e-05
Iter: 137 loss: 1.0241085e-05
Iter: 138 loss: 1.02233116e-05
Iter: 139 loss: 1.01694022e-05
Iter: 140 loss: 1.03096772e-05
Iter: 141 loss: 1.01398382e-05
Iter: 142 loss: 1.00546504e-05
Iter: 143 loss: 1.05152758e-05
Iter: 144 loss: 1.00420348e-05
Iter: 145 loss: 9.98069663e-06
Iter: 146 loss: 1.03809634e-05
Iter: 147 loss: 9.9740937e-06
Iter: 148 loss: 9.97693496e-06
Iter: 149 loss: 9.95380287e-06
Iter: 150 loss: 9.9401077e-06
Iter: 151 loss: 9.90431545e-06
Iter: 152 loss: 1.01690021e-05
Iter: 153 loss: 9.8968867e-06
Iter: 154 loss: 9.88737156e-06
Iter: 155 loss: 9.87618751e-06
Iter: 156 loss: 9.86332088e-06
Iter: 157 loss: 9.82949678e-06
Iter: 158 loss: 1.00922889e-05
Iter: 159 loss: 9.82299935e-06
Iter: 160 loss: 9.78524167e-06
Iter: 161 loss: 1.01188452e-05
Iter: 162 loss: 9.7834e-06
Iter: 163 loss: 9.75009061e-06
Iter: 164 loss: 9.95609e-06
Iter: 165 loss: 9.74621616e-06
Iter: 166 loss: 9.71994905e-06
Iter: 167 loss: 9.72161342e-06
Iter: 168 loss: 9.69931e-06
Iter: 169 loss: 9.67585765e-06
Iter: 170 loss: 9.76828051e-06
Iter: 171 loss: 9.67045071e-06
Iter: 172 loss: 9.63854927e-06
Iter: 173 loss: 9.70707e-06
Iter: 174 loss: 9.62601734e-06
Iter: 175 loss: 9.60402e-06
Iter: 176 loss: 9.57406701e-06
Iter: 177 loss: 9.57257089e-06
Iter: 178 loss: 9.53257768e-06
Iter: 179 loss: 9.55401174e-06
Iter: 180 loss: 9.50618778e-06
Iter: 181 loss: 9.46282762e-06
Iter: 182 loss: 9.82608526e-06
Iter: 183 loss: 9.46027103e-06
Iter: 184 loss: 9.43705163e-06
Iter: 185 loss: 9.43412942e-06
Iter: 186 loss: 9.42377483e-06
Iter: 187 loss: 9.40158134e-06
Iter: 188 loss: 9.76027422e-06
Iter: 189 loss: 9.40093105e-06
Iter: 190 loss: 9.38035191e-06
Iter: 191 loss: 9.38015546e-06
Iter: 192 loss: 9.36700781e-06
Iter: 193 loss: 9.33027e-06
Iter: 194 loss: 9.52318624e-06
Iter: 195 loss: 9.31856903e-06
Iter: 196 loss: 9.30132046e-06
Iter: 197 loss: 9.29403632e-06
Iter: 198 loss: 9.27339e-06
Iter: 199 loss: 9.30182068e-06
Iter: 200 loss: 9.26324174e-06
Iter: 201 loss: 9.24221604e-06
Iter: 202 loss: 9.23517e-06
Iter: 203 loss: 9.22334402e-06
Iter: 204 loss: 9.19722879e-06
Iter: 205 loss: 9.43656e-06
Iter: 206 loss: 9.19608e-06
Iter: 207 loss: 9.16998215e-06
Iter: 208 loss: 9.21312403e-06
Iter: 209 loss: 9.15810051e-06
Iter: 210 loss: 9.14042266e-06
Iter: 211 loss: 9.10348e-06
Iter: 212 loss: 9.72582166e-06
Iter: 213 loss: 9.10270046e-06
Iter: 214 loss: 9.05728848e-06
Iter: 215 loss: 9.18983278e-06
Iter: 216 loss: 9.04336412e-06
Iter: 217 loss: 9.03665386e-06
Iter: 218 loss: 9.02640841e-06
Iter: 219 loss: 9.00897157e-06
Iter: 220 loss: 9.02982174e-06
Iter: 221 loss: 8.99963288e-06
Iter: 222 loss: 8.98735652e-06
Iter: 223 loss: 8.98578219e-06
Iter: 224 loss: 8.97707e-06
Iter: 225 loss: 8.95065568e-06
Iter: 226 loss: 9.01645399e-06
Iter: 227 loss: 8.94146524e-06
Iter: 228 loss: 8.92457e-06
Iter: 229 loss: 8.89856892e-06
Iter: 230 loss: 8.8981169e-06
Iter: 231 loss: 8.88907562e-06
Iter: 232 loss: 8.88131399e-06
Iter: 233 loss: 8.86947146e-06
Iter: 234 loss: 8.84975179e-06
Iter: 235 loss: 8.84969359e-06
Iter: 236 loss: 8.82564564e-06
Iter: 237 loss: 8.91636864e-06
Iter: 238 loss: 8.81987e-06
Iter: 239 loss: 8.80793505e-06
Iter: 240 loss: 8.8075958e-06
Iter: 241 loss: 8.79761046e-06
Iter: 242 loss: 8.77972434e-06
Iter: 243 loss: 9.22348772e-06
Iter: 244 loss: 8.7796825e-06
Iter: 245 loss: 8.75496517e-06
Iter: 246 loss: 8.69985706e-06
Iter: 247 loss: 9.47985609e-06
Iter: 248 loss: 8.69705764e-06
Iter: 249 loss: 8.64797494e-06
Iter: 250 loss: 9.366634e-06
Iter: 251 loss: 8.6479e-06
Iter: 252 loss: 8.63488549e-06
Iter: 253 loss: 8.63121204e-06
Iter: 254 loss: 8.61225453e-06
Iter: 255 loss: 8.59089e-06
Iter: 256 loss: 8.58806561e-06
Iter: 257 loss: 8.57859413e-06
Iter: 258 loss: 8.57838586e-06
Iter: 259 loss: 8.56823226e-06
Iter: 260 loss: 8.54949212e-06
Iter: 261 loss: 8.98345388e-06
Iter: 262 loss: 8.54938207e-06
Iter: 263 loss: 8.5288475e-06
Iter: 264 loss: 8.51582536e-06
Iter: 265 loss: 8.50773358e-06
Iter: 266 loss: 8.47356569e-06
Iter: 267 loss: 8.47356478e-06
Iter: 268 loss: 8.45676e-06
Iter: 269 loss: 8.4360945e-06
Iter: 270 loss: 8.43422094e-06
Iter: 271 loss: 8.41009933e-06
Iter: 272 loss: 8.63391233e-06
Iter: 273 loss: 8.40905159e-06
Iter: 274 loss: 8.3945979e-06
Iter: 275 loss: 8.55589496e-06
Iter: 276 loss: 8.39423e-06
Iter: 277 loss: 8.38443884e-06
Iter: 278 loss: 8.36748768e-06
Iter: 279 loss: 8.36740128e-06
Iter: 280 loss: 8.34907314e-06
Iter: 281 loss: 8.35139508e-06
Iter: 282 loss: 8.33502054e-06
Iter: 283 loss: 8.30562112e-06
Iter: 284 loss: 8.3167015e-06
Iter: 285 loss: 8.28509928e-06
Iter: 286 loss: 8.29328292e-06
Iter: 287 loss: 8.26757241e-06
Iter: 288 loss: 8.25722418e-06
Iter: 289 loss: 8.23240407e-06
Iter: 290 loss: 8.50530523e-06
Iter: 291 loss: 8.22991478e-06
Iter: 292 loss: 8.22513084e-06
Iter: 293 loss: 8.21901449e-06
Iter: 294 loss: 8.21049071e-06
Iter: 295 loss: 8.19093839e-06
Iter: 296 loss: 8.43836915e-06
Iter: 297 loss: 8.18954686e-06
Iter: 298 loss: 8.17205728e-06
Iter: 299 loss: 8.22868606e-06
Iter: 300 loss: 8.16719239e-06
Iter: 301 loss: 8.14569921e-06
Iter: 302 loss: 8.32658952e-06
Iter: 303 loss: 8.1445005e-06
Iter: 304 loss: 8.13232145e-06
Iter: 305 loss: 8.10299389e-06
Iter: 306 loss: 8.42009831e-06
Iter: 307 loss: 8.09992434e-06
Iter: 308 loss: 8.08529148e-06
Iter: 309 loss: 8.08111417e-06
Iter: 310 loss: 8.0668251e-06
Iter: 311 loss: 8.10250276e-06
Iter: 312 loss: 8.06176104e-06
Iter: 313 loss: 8.05058698e-06
Iter: 314 loss: 8.06919e-06
Iter: 315 loss: 8.04543379e-06
Iter: 316 loss: 8.03476905e-06
Iter: 317 loss: 8.02168597e-06
Iter: 318 loss: 8.02040267e-06
Iter: 319 loss: 8.000261e-06
Iter: 320 loss: 8.10360143e-06
Iter: 321 loss: 7.99693589e-06
Iter: 322 loss: 7.97580469e-06
Iter: 323 loss: 8.21308913e-06
Iter: 324 loss: 7.9754e-06
Iter: 325 loss: 7.96619224e-06
Iter: 326 loss: 7.94291191e-06
Iter: 327 loss: 8.15669046e-06
Iter: 328 loss: 7.9395e-06
Iter: 329 loss: 7.91752518e-06
Iter: 330 loss: 7.91645834e-06
Iter: 331 loss: 7.9065012e-06
Iter: 332 loss: 7.88935176e-06
Iter: 333 loss: 7.8893645e-06
Iter: 334 loss: 7.87948738e-06
Iter: 335 loss: 8.03251896e-06
Iter: 336 loss: 7.8794983e-06
Iter: 337 loss: 7.8666817e-06
Iter: 338 loss: 7.84795157e-06
Iter: 339 loss: 7.84740132e-06
Iter: 340 loss: 7.83013274e-06
Iter: 341 loss: 7.84525946e-06
Iter: 342 loss: 7.82006191e-06
Iter: 343 loss: 7.80392111e-06
Iter: 344 loss: 7.80334267e-06
Iter: 345 loss: 7.79244237e-06
Iter: 346 loss: 7.77971945e-06
Iter: 347 loss: 7.77823243e-06
Iter: 348 loss: 7.75928856e-06
Iter: 349 loss: 7.81602e-06
Iter: 350 loss: 7.75355e-06
Iter: 351 loss: 7.73989e-06
Iter: 352 loss: 7.74689943e-06
Iter: 353 loss: 7.73088686e-06
Iter: 354 loss: 7.72653311e-06
Iter: 355 loss: 7.72353269e-06
Iter: 356 loss: 7.71480518e-06
Iter: 357 loss: 7.69412691e-06
Iter: 358 loss: 7.93230174e-06
Iter: 359 loss: 7.69223061e-06
Iter: 360 loss: 7.6720562e-06
Iter: 361 loss: 7.77405876e-06
Iter: 362 loss: 7.66875564e-06
Iter: 363 loss: 7.64611832e-06
Iter: 364 loss: 7.77499281e-06
Iter: 365 loss: 7.64299e-06
Iter: 366 loss: 7.63366e-06
Iter: 367 loss: 7.61172e-06
Iter: 368 loss: 7.86351757e-06
Iter: 369 loss: 7.60975763e-06
Iter: 370 loss: 7.6160768e-06
Iter: 371 loss: 7.59997965e-06
Iter: 372 loss: 7.59351451e-06
Iter: 373 loss: 7.57957787e-06
Iter: 374 loss: 7.79149559e-06
Iter: 375 loss: 7.57891576e-06
Iter: 376 loss: 7.56626241e-06
Iter: 377 loss: 7.57637e-06
Iter: 378 loss: 7.55854671e-06
Iter: 379 loss: 7.53605673e-06
Iter: 380 loss: 7.67294296e-06
Iter: 381 loss: 7.53323047e-06
Iter: 382 loss: 7.52075493e-06
Iter: 383 loss: 7.51074822e-06
Iter: 384 loss: 7.5068865e-06
Iter: 385 loss: 7.49019455e-06
Iter: 386 loss: 7.60156e-06
Iter: 387 loss: 7.4885711e-06
Iter: 388 loss: 7.47598e-06
Iter: 389 loss: 7.47223385e-06
Iter: 390 loss: 7.46465503e-06
Iter: 391 loss: 7.46039404e-06
Iter: 392 loss: 7.45569378e-06
Iter: 393 loss: 7.44822864e-06
Iter: 394 loss: 7.43065448e-06
Iter: 395 loss: 7.63851494e-06
Iter: 396 loss: 7.42916882e-06
Iter: 397 loss: 7.41353051e-06
Iter: 398 loss: 7.42251632e-06
Iter: 399 loss: 7.40334144e-06
Iter: 400 loss: 7.39388e-06
Iter: 401 loss: 7.39046845e-06
Iter: 402 loss: 7.38359176e-06
Iter: 403 loss: 7.36537959e-06
Iter: 404 loss: 7.49596802e-06
Iter: 405 loss: 7.36140419e-06
Iter: 406 loss: 7.35452977e-06
Iter: 407 loss: 7.35248796e-06
Iter: 408 loss: 7.34221385e-06
Iter: 409 loss: 7.33415754e-06
Iter: 410 loss: 7.33097386e-06
Iter: 411 loss: 7.31936507e-06
Iter: 412 loss: 7.33415527e-06
Iter: 413 loss: 7.31334785e-06
Iter: 414 loss: 7.29835574e-06
Iter: 415 loss: 7.46019123e-06
Iter: 416 loss: 7.29803e-06
Iter: 417 loss: 7.29141721e-06
Iter: 418 loss: 7.27838642e-06
Iter: 419 loss: 7.52752476e-06
Iter: 420 loss: 7.27823362e-06
Iter: 421 loss: 7.26434519e-06
Iter: 422 loss: 7.400708e-06
Iter: 423 loss: 7.26393137e-06
Iter: 424 loss: 7.25477321e-06
Iter: 425 loss: 7.31417867e-06
Iter: 426 loss: 7.25375867e-06
Iter: 427 loss: 7.24294159e-06
Iter: 428 loss: 7.25755535e-06
Iter: 429 loss: 7.23758239e-06
Iter: 430 loss: 7.22858e-06
Iter: 431 loss: 7.20632443e-06
Iter: 432 loss: 7.42408338e-06
Iter: 433 loss: 7.2034e-06
Iter: 434 loss: 7.19919262e-06
Iter: 435 loss: 7.19191758e-06
Iter: 436 loss: 7.18101728e-06
Iter: 437 loss: 7.17612966e-06
Iter: 438 loss: 7.17061403e-06
Iter: 439 loss: 7.16345676e-06
Iter: 440 loss: 7.17428338e-06
Iter: 441 loss: 7.16005661e-06
Iter: 442 loss: 7.1530003e-06
Iter: 443 loss: 7.15303258e-06
Iter: 444 loss: 7.14798534e-06
Iter: 445 loss: 7.13566e-06
Iter: 446 loss: 7.26416147e-06
Iter: 447 loss: 7.13422924e-06
Iter: 448 loss: 7.12804e-06
Iter: 449 loss: 7.12709834e-06
Iter: 450 loss: 7.11870825e-06
Iter: 451 loss: 7.10314907e-06
Iter: 452 loss: 7.46349178e-06
Iter: 453 loss: 7.10317e-06
Iter: 454 loss: 7.08841026e-06
Iter: 455 loss: 7.1046361e-06
Iter: 456 loss: 7.08036487e-06
Iter: 457 loss: 7.07517574e-06
Iter: 458 loss: 7.07392701e-06
Iter: 459 loss: 7.06887568e-06
Iter: 460 loss: 7.09565757e-06
Iter: 461 loss: 7.06805122e-06
Iter: 462 loss: 7.06233868e-06
Iter: 463 loss: 7.0520673e-06
Iter: 464 loss: 7.05206e-06
Iter: 465 loss: 7.04282047e-06
Iter: 466 loss: 7.0401984e-06
Iter: 467 loss: 7.03451224e-06
Iter: 468 loss: 7.02812486e-06
Iter: 469 loss: 7.02604211e-06
Iter: 470 loss: 7.01908812e-06
Iter: 471 loss: 7.00049441e-06
Iter: 472 loss: 7.12557539e-06
Iter: 473 loss: 6.99613975e-06
Iter: 474 loss: 6.99310294e-06
Iter: 475 loss: 6.99009661e-06
Iter: 476 loss: 6.9839225e-06
Iter: 477 loss: 6.98918711e-06
Iter: 478 loss: 6.98026952e-06
Iter: 479 loss: 6.97495716e-06
Iter: 480 loss: 6.97041514e-06
Iter: 481 loss: 6.96899451e-06
Iter: 482 loss: 6.9599173e-06
Iter: 483 loss: 7.09585038e-06
Iter: 484 loss: 6.95991957e-06
Iter: 485 loss: 6.95415201e-06
Iter: 486 loss: 6.93921902e-06
Iter: 487 loss: 7.05935236e-06
Iter: 488 loss: 6.93652146e-06
Iter: 489 loss: 6.92107096e-06
Iter: 490 loss: 6.9955986e-06
Iter: 491 loss: 6.91822333e-06
Iter: 492 loss: 6.91355763e-06
Iter: 493 loss: 6.91127934e-06
Iter: 494 loss: 6.90572506e-06
Iter: 495 loss: 6.91422883e-06
Iter: 496 loss: 6.90305433e-06
Iter: 497 loss: 6.8981617e-06
Iter: 498 loss: 6.89518401e-06
Iter: 499 loss: 6.89329681e-06
Iter: 500 loss: 6.88629643e-06
Iter: 501 loss: 6.88545879e-06
Iter: 502 loss: 6.88041837e-06
Iter: 503 loss: 6.87056536e-06
Iter: 504 loss: 6.87059537e-06
Iter: 505 loss: 6.86508974e-06
Iter: 506 loss: 6.85300256e-06
Iter: 507 loss: 7.02553825e-06
Iter: 508 loss: 6.85244868e-06
Iter: 509 loss: 6.84576025e-06
Iter: 510 loss: 6.84555653e-06
Iter: 511 loss: 6.83763938e-06
Iter: 512 loss: 6.83885e-06
Iter: 513 loss: 6.83174267e-06
Iter: 514 loss: 6.82599148e-06
Iter: 515 loss: 6.82449627e-06
Iter: 516 loss: 6.82096743e-06
Iter: 517 loss: 6.8154468e-06
Iter: 518 loss: 6.81491338e-06
Iter: 519 loss: 6.81163328e-06
Iter: 520 loss: 6.8018926e-06
Iter: 521 loss: 6.83484e-06
Iter: 522 loss: 6.79732966e-06
Iter: 523 loss: 6.78379183e-06
Iter: 524 loss: 6.83436974e-06
Iter: 525 loss: 6.78051674e-06
Iter: 526 loss: 6.78284596e-06
Iter: 527 loss: 6.77627258e-06
Iter: 528 loss: 6.77240041e-06
Iter: 529 loss: 6.76492436e-06
Iter: 530 loss: 6.91532841e-06
Iter: 531 loss: 6.76489572e-06
Iter: 532 loss: 6.75629235e-06
Iter: 533 loss: 6.77208345e-06
Iter: 534 loss: 6.7526189e-06
Iter: 535 loss: 6.74321291e-06
Iter: 536 loss: 6.76590662e-06
Iter: 537 loss: 6.73983959e-06
Iter: 538 loss: 6.73526483e-06
Iter: 539 loss: 6.73465365e-06
Iter: 540 loss: 6.73021259e-06
Iter: 541 loss: 6.71864154e-06
Iter: 542 loss: 6.80420089e-06
Iter: 543 loss: 6.71623911e-06
Iter: 544 loss: 6.71065618e-06
Iter: 545 loss: 6.71021e-06
Iter: 546 loss: 6.70345344e-06
Iter: 547 loss: 6.70664622e-06
Iter: 548 loss: 6.69886686e-06
Iter: 549 loss: 6.69278734e-06
Iter: 550 loss: 6.68325e-06
Iter: 551 loss: 6.68322127e-06
Iter: 552 loss: 6.67801214e-06
Iter: 553 loss: 6.67570339e-06
Iter: 554 loss: 6.67103359e-06
Iter: 555 loss: 6.6603825e-06
Iter: 556 loss: 6.80308676e-06
Iter: 557 loss: 6.65977632e-06
Iter: 558 loss: 6.65030166e-06
Iter: 559 loss: 6.66263895e-06
Iter: 560 loss: 6.64545405e-06
Iter: 561 loss: 6.64705931e-06
Iter: 562 loss: 6.64070967e-06
Iter: 563 loss: 6.63656147e-06
Iter: 564 loss: 6.62702769e-06
Iter: 565 loss: 6.74962e-06
Iter: 566 loss: 6.62641469e-06
Iter: 567 loss: 6.61882041e-06
Iter: 568 loss: 6.64681056e-06
Iter: 569 loss: 6.61686408e-06
Iter: 570 loss: 6.60697879e-06
Iter: 571 loss: 6.61632566e-06
Iter: 572 loss: 6.60127444e-06
Iter: 573 loss: 6.59227408e-06
Iter: 574 loss: 6.59212856e-06
Iter: 575 loss: 6.58802355e-06
Iter: 576 loss: 6.58048793e-06
Iter: 577 loss: 6.74740977e-06
Iter: 578 loss: 6.58054159e-06
Iter: 579 loss: 6.57644796e-06
Iter: 580 loss: 6.57615237e-06
Iter: 581 loss: 6.57148485e-06
Iter: 582 loss: 6.56628072e-06
Iter: 583 loss: 6.56556904e-06
Iter: 584 loss: 6.56005341e-06
Iter: 585 loss: 6.55972781e-06
Iter: 586 loss: 6.55560461e-06
Iter: 587 loss: 6.55054919e-06
Iter: 588 loss: 6.55016447e-06
Iter: 589 loss: 6.54579071e-06
Iter: 590 loss: 6.53404504e-06
Iter: 591 loss: 6.60564638e-06
Iter: 592 loss: 6.53090137e-06
Iter: 593 loss: 6.51767732e-06
Iter: 594 loss: 6.54255382e-06
Iter: 595 loss: 6.51206346e-06
Iter: 596 loss: 6.5048057e-06
Iter: 597 loss: 6.5048107e-06
Iter: 598 loss: 6.49952062e-06
Iter: 599 loss: 6.49952835e-06
Iter: 600 loss: 6.49662e-06
Iter: 601 loss: 6.48913056e-06
Iter: 602 loss: 6.54106088e-06
Iter: 603 loss: 6.48728746e-06
Iter: 604 loss: 6.47860452e-06
Iter: 605 loss: 6.52043764e-06
Iter: 606 loss: 6.4771516e-06
Iter: 607 loss: 6.46759872e-06
Iter: 608 loss: 6.50629181e-06
Iter: 609 loss: 6.46556737e-06
Iter: 610 loss: 6.45794262e-06
Iter: 611 loss: 6.55159511e-06
Iter: 612 loss: 6.45776117e-06
Iter: 613 loss: 6.45314321e-06
Iter: 614 loss: 6.44781e-06
Iter: 615 loss: 6.44713964e-06
Iter: 616 loss: 6.44272313e-06
Iter: 617 loss: 6.48616515e-06
Iter: 618 loss: 6.44265947e-06
Iter: 619 loss: 6.43678959e-06
Iter: 620 loss: 6.4306405e-06
Iter: 621 loss: 6.42958184e-06
Iter: 622 loss: 6.42260511e-06
Iter: 623 loss: 6.41601764e-06
Iter: 624 loss: 6.4143851e-06
Iter: 625 loss: 6.41217548e-06
Iter: 626 loss: 6.40900635e-06
Iter: 627 loss: 6.40371491e-06
Iter: 628 loss: 6.39258269e-06
Iter: 629 loss: 6.5854897e-06
Iter: 630 loss: 6.3923776e-06
Iter: 631 loss: 6.38533584e-06
Iter: 632 loss: 6.45200907e-06
Iter: 633 loss: 6.38502934e-06
Iter: 634 loss: 6.38067195e-06
Iter: 635 loss: 6.38066103e-06
Iter: 636 loss: 6.37902394e-06
Iter: 637 loss: 6.37391531e-06
Iter: 638 loss: 6.38099527e-06
Iter: 639 loss: 6.37020366e-06
Iter: 640 loss: 6.35976176e-06
Iter: 641 loss: 6.36548293e-06
Iter: 642 loss: 6.35290507e-06
Iter: 643 loss: 6.34840399e-06
Iter: 644 loss: 6.34586195e-06
Iter: 645 loss: 6.33870923e-06
Iter: 646 loss: 6.34359276e-06
Iter: 647 loss: 6.33422178e-06
Iter: 648 loss: 6.32721549e-06
Iter: 649 loss: 6.34468324e-06
Iter: 650 loss: 6.32475894e-06
Iter: 651 loss: 6.31982857e-06
Iter: 652 loss: 6.34741355e-06
Iter: 653 loss: 6.3191128e-06
Iter: 654 loss: 6.3147163e-06
Iter: 655 loss: 6.3451771e-06
Iter: 656 loss: 6.31431476e-06
Iter: 657 loss: 6.3118523e-06
Iter: 658 loss: 6.30483873e-06
Iter: 659 loss: 6.32898127e-06
Iter: 660 loss: 6.30146815e-06
Iter: 661 loss: 6.29598708e-06
Iter: 662 loss: 6.2951658e-06
Iter: 663 loss: 6.28794032e-06
Iter: 664 loss: 6.28736871e-06
Iter: 665 loss: 6.28205453e-06
Iter: 666 loss: 6.27464215e-06
Iter: 667 loss: 6.26532619e-06
Iter: 668 loss: 6.26462679e-06
Iter: 669 loss: 6.27278132e-06
Iter: 670 loss: 6.26019755e-06
Iter: 671 loss: 6.25800385e-06
Iter: 672 loss: 6.25155e-06
Iter: 673 loss: 6.27698864e-06
Iter: 674 loss: 6.24896938e-06
Iter: 675 loss: 6.24233189e-06
Iter: 676 loss: 6.2546851e-06
Iter: 677 loss: 6.23959158e-06
Iter: 678 loss: 6.23029791e-06
Iter: 679 loss: 6.23884762e-06
Iter: 680 loss: 6.22489642e-06
Iter: 681 loss: 6.22078142e-06
Iter: 682 loss: 6.2180161e-06
Iter: 683 loss: 6.21488834e-06
Iter: 684 loss: 6.20624269e-06
Iter: 685 loss: 6.26693327e-06
Iter: 686 loss: 6.20431319e-06
Iter: 687 loss: 6.20050696e-06
Iter: 688 loss: 6.19919319e-06
Iter: 689 loss: 6.19445836e-06
Iter: 690 loss: 6.19510229e-06
Iter: 691 loss: 6.1908313e-06
Iter: 692 loss: 6.1870096e-06
Iter: 693 loss: 6.1936089e-06
Iter: 694 loss: 6.18533977e-06
Iter: 695 loss: 6.18011563e-06
Iter: 696 loss: 6.21438176e-06
Iter: 697 loss: 6.17960359e-06
Iter: 698 loss: 6.17453952e-06
Iter: 699 loss: 6.19899856e-06
Iter: 700 loss: 6.17367232e-06
Iter: 701 loss: 6.16933539e-06
Iter: 702 loss: 6.16019315e-06
Iter: 703 loss: 6.32064439e-06
Iter: 704 loss: 6.15995305e-06
Iter: 705 loss: 6.15383942e-06
Iter: 706 loss: 6.1537803e-06
Iter: 707 loss: 6.1468736e-06
Iter: 708 loss: 6.15428326e-06
Iter: 709 loss: 6.14315695e-06
Iter: 710 loss: 6.13926386e-06
Iter: 711 loss: 6.13329667e-06
Iter: 712 loss: 6.13327938e-06
Iter: 713 loss: 6.12674285e-06
Iter: 714 loss: 6.1531e-06
Iter: 715 loss: 6.12544864e-06
Iter: 716 loss: 6.1235628e-06
Iter: 717 loss: 6.1223227e-06
Iter: 718 loss: 6.11956693e-06
Iter: 719 loss: 6.11200721e-06
Iter: 720 loss: 6.14893224e-06
Iter: 721 loss: 6.10928601e-06
Iter: 722 loss: 6.10105781e-06
Iter: 723 loss: 6.13403745e-06
Iter: 724 loss: 6.09921653e-06
Iter: 725 loss: 6.09149e-06
Iter: 726 loss: 6.10821462e-06
Iter: 727 loss: 6.0884031e-06
Iter: 728 loss: 6.08858318e-06
Iter: 729 loss: 6.08503524e-06
Iter: 730 loss: 6.08256687e-06
Iter: 731 loss: 6.07594302e-06
Iter: 732 loss: 6.11755286e-06
Iter: 733 loss: 6.07426364e-06
Iter: 734 loss: 6.06621234e-06
Iter: 735 loss: 6.09373228e-06
Iter: 736 loss: 6.064015e-06
Iter: 737 loss: 6.05638206e-06
Iter: 738 loss: 6.12214444e-06
Iter: 739 loss: 6.05592868e-06
Iter: 740 loss: 6.05351624e-06
Iter: 741 loss: 6.05334117e-06
Iter: 742 loss: 6.05090918e-06
Iter: 743 loss: 6.04479646e-06
Iter: 744 loss: 6.10521283e-06
Iter: 745 loss: 6.04407796e-06
Iter: 746 loss: 6.04036586e-06
Iter: 747 loss: 6.04011348e-06
Iter: 748 loss: 6.03632407e-06
Iter: 749 loss: 6.0306611e-06
Iter: 750 loss: 6.03046965e-06
Iter: 751 loss: 6.02663567e-06
Iter: 752 loss: 6.08578102e-06
Iter: 753 loss: 6.02663704e-06
Iter: 754 loss: 6.02225737e-06
Iter: 755 loss: 6.01546435e-06
Iter: 756 loss: 6.01535612e-06
Iter: 757 loss: 6.00838848e-06
Iter: 758 loss: 6.00677276e-06
Iter: 759 loss: 6.00232397e-06
Iter: 760 loss: 5.99489294e-06
Iter: 761 loss: 6.02704677e-06
Iter: 762 loss: 5.99327e-06
Iter: 763 loss: 5.99122905e-06
Iter: 764 loss: 5.9899794e-06
Iter: 765 loss: 5.98648148e-06
Iter: 766 loss: 5.97778262e-06
Iter: 767 loss: 6.0626935e-06
Iter: 768 loss: 5.9767417e-06
Iter: 769 loss: 5.97020698e-06
Iter: 770 loss: 5.99838586e-06
Iter: 771 loss: 5.96874861e-06
Iter: 772 loss: 5.96269365e-06
Iter: 773 loss: 5.9736758e-06
Iter: 774 loss: 5.96005248e-06
Iter: 775 loss: 5.95426945e-06
Iter: 776 loss: 5.95422534e-06
Iter: 777 loss: 5.95011716e-06
Iter: 778 loss: 5.9720669e-06
Iter: 779 loss: 5.94953053e-06
Iter: 780 loss: 5.94688117e-06
Iter: 781 loss: 5.94321727e-06
Iter: 782 loss: 5.94302674e-06
Iter: 783 loss: 5.93864388e-06
Iter: 784 loss: 6.00390376e-06
Iter: 785 loss: 5.93865798e-06
Iter: 786 loss: 5.93533423e-06
Iter: 787 loss: 5.92669403e-06
Iter: 788 loss: 5.99889336e-06
Iter: 789 loss: 5.92527795e-06
Iter: 790 loss: 5.9180984e-06
Iter: 791 loss: 5.94904395e-06
Iter: 792 loss: 5.9165709e-06
Iter: 793 loss: 5.91294611e-06
Iter: 794 loss: 5.91274647e-06
Iter: 795 loss: 5.90866102e-06
Iter: 796 loss: 5.91341268e-06
Iter: 797 loss: 5.90634954e-06
Iter: 798 loss: 5.90318632e-06
Iter: 799 loss: 5.89883803e-06
Iter: 800 loss: 5.89863248e-06
Iter: 801 loss: 5.89747106e-06
Iter: 802 loss: 5.89582214e-06
Iter: 803 loss: 5.89346109e-06
Iter: 804 loss: 5.88681633e-06
Iter: 805 loss: 5.91904154e-06
Iter: 806 loss: 5.88441026e-06
Iter: 807 loss: 5.8773735e-06
Iter: 808 loss: 5.90958825e-06
Iter: 809 loss: 5.87593513e-06
Iter: 810 loss: 5.87245086e-06
Iter: 811 loss: 5.8723881e-06
Iter: 812 loss: 5.86816896e-06
Iter: 813 loss: 5.87356135e-06
Iter: 814 loss: 5.86600891e-06
Iter: 815 loss: 5.86296756e-06
Iter: 816 loss: 5.86801798e-06
Iter: 817 loss: 5.86162605e-06
Iter: 818 loss: 5.85773614e-06
Iter: 819 loss: 5.87710929e-06
Iter: 820 loss: 5.85706493e-06
Iter: 821 loss: 5.85414364e-06
Iter: 822 loss: 5.85254338e-06
Iter: 823 loss: 5.8512037e-06
Iter: 824 loss: 5.84593545e-06
Iter: 825 loss: 5.8446285e-06
Iter: 826 loss: 5.84126246e-06
Iter: 827 loss: 5.83497103e-06
Iter: 828 loss: 5.84960344e-06
Iter: 829 loss: 5.83264591e-06
Iter: 830 loss: 5.83189467e-06
Iter: 831 loss: 5.83017663e-06
Iter: 832 loss: 5.82763369e-06
Iter: 833 loss: 5.82326402e-06
Iter: 834 loss: 5.82327039e-06
Iter: 835 loss: 5.81875247e-06
Iter: 836 loss: 5.82197754e-06
Iter: 837 loss: 5.81596714e-06
Iter: 838 loss: 5.81183212e-06
Iter: 839 loss: 5.81169434e-06
Iter: 840 loss: 5.80963297e-06
Iter: 841 loss: 5.80423921e-06
Iter: 842 loss: 5.8444848e-06
Iter: 843 loss: 5.80311507e-06
Iter: 844 loss: 5.79669677e-06
Iter: 845 loss: 5.81630775e-06
Iter: 846 loss: 5.79480638e-06
Iter: 847 loss: 5.79873e-06
Iter: 848 loss: 5.79289735e-06
Iter: 849 loss: 5.79187054e-06
Iter: 850 loss: 5.78888239e-06
Iter: 851 loss: 5.80299e-06
Iter: 852 loss: 5.78786876e-06
Iter: 853 loss: 5.78455865e-06
Iter: 854 loss: 5.78451454e-06
Iter: 855 loss: 5.78191066e-06
Iter: 856 loss: 5.77997071e-06
Iter: 857 loss: 5.77907304e-06
Iter: 858 loss: 5.77534593e-06
Iter: 859 loss: 5.78302934e-06
Iter: 860 loss: 5.77395485e-06
Iter: 861 loss: 5.769788e-06
Iter: 862 loss: 5.76643879e-06
Iter: 863 loss: 5.76513912e-06
Iter: 864 loss: 5.76347202e-06
Iter: 865 loss: 5.76222283e-06
Iter: 866 loss: 5.75948934e-06
Iter: 867 loss: 5.76006914e-06
Iter: 868 loss: 5.75745253e-06
Iter: 869 loss: 5.75528884e-06
Iter: 870 loss: 5.75141939e-06
Iter: 871 loss: 5.75148078e-06
Iter: 872 loss: 5.74993192e-06
Iter: 873 loss: 5.74886326e-06
Iter: 874 loss: 5.74636852e-06
Iter: 875 loss: 5.74082833e-06
Iter: 876 loss: 5.81335962e-06
Iter: 877 loss: 5.74037267e-06
Iter: 878 loss: 5.73516309e-06
Iter: 879 loss: 5.74253681e-06
Iter: 880 loss: 5.73256966e-06
Iter: 881 loss: 5.72947738e-06
Iter: 882 loss: 5.72926456e-06
Iter: 883 loss: 5.72537101e-06
Iter: 884 loss: 5.72582849e-06
Iter: 885 loss: 5.72233512e-06
Iter: 886 loss: 5.72027329e-06
Iter: 887 loss: 5.72898307e-06
Iter: 888 loss: 5.71983901e-06
Iter: 889 loss: 5.71699593e-06
Iter: 890 loss: 5.7195366e-06
Iter: 891 loss: 5.71538658e-06
Iter: 892 loss: 5.7124862e-06
Iter: 893 loss: 5.71022701e-06
Iter: 894 loss: 5.70937436e-06
Iter: 895 loss: 5.70419115e-06
Iter: 896 loss: 5.72247654e-06
Iter: 897 loss: 5.70286284e-06
Iter: 898 loss: 5.69902613e-06
Iter: 899 loss: 5.70327938e-06
Iter: 900 loss: 5.69703388e-06
Iter: 901 loss: 5.6941517e-06
Iter: 902 loss: 5.69385e-06
Iter: 903 loss: 5.69192e-06
Iter: 904 loss: 5.68734731e-06
Iter: 905 loss: 5.74963815e-06
Iter: 906 loss: 5.6870922e-06
Iter: 907 loss: 5.68336827e-06
Iter: 908 loss: 5.70319935e-06
Iter: 909 loss: 5.68281e-06
Iter: 910 loss: 5.67884126e-06
Iter: 911 loss: 5.7132138e-06
Iter: 912 loss: 5.67858342e-06
Iter: 913 loss: 5.67639e-06
Iter: 914 loss: 5.67053576e-06
Iter: 915 loss: 5.71375131e-06
Iter: 916 loss: 5.66937069e-06
Iter: 917 loss: 5.66312974e-06
Iter: 918 loss: 5.69498479e-06
Iter: 919 loss: 5.66213748e-06
Iter: 920 loss: 5.65815117e-06
Iter: 921 loss: 5.69768144e-06
Iter: 922 loss: 5.65802156e-06
Iter: 923 loss: 5.65429309e-06
Iter: 924 loss: 5.69029817e-06
Iter: 925 loss: 5.65419941e-06
Iter: 926 loss: 5.65240043e-06
Iter: 927 loss: 5.65021855e-06
Iter: 928 loss: 5.64998936e-06
Iter: 929 loss: 5.64686616e-06
Iter: 930 loss: 5.68615178e-06
Iter: 931 loss: 5.64681295e-06
Iter: 932 loss: 5.64508537e-06
Iter: 933 loss: 5.64190759e-06
Iter: 934 loss: 5.70910152e-06
Iter: 935 loss: 5.64187167e-06
Iter: 936 loss: 5.63700542e-06
Iter: 937 loss: 5.64742186e-06
Iter: 938 loss: 5.63504e-06
Iter: 939 loss: 5.63254252e-06
Iter: 940 loss: 5.63253343e-06
Iter: 941 loss: 5.62985133e-06
Iter: 942 loss: 5.6277745e-06
Iter: 943 loss: 5.62695686e-06
Iter: 944 loss: 5.62392e-06
Iter: 945 loss: 5.62121477e-06
Iter: 946 loss: 5.62035711e-06
Iter: 947 loss: 5.61948218e-06
Iter: 948 loss: 5.61791921e-06
Iter: 949 loss: 5.61612569e-06
Iter: 950 loss: 5.61174966e-06
Iter: 951 loss: 5.66513199e-06
Iter: 952 loss: 5.61142e-06
Iter: 953 loss: 5.60723493e-06
Iter: 954 loss: 5.61162778e-06
Iter: 955 loss: 5.60497892e-06
Iter: 956 loss: 5.60173885e-06
Iter: 957 loss: 5.60171293e-06
Iter: 958 loss: 5.59819728e-06
Iter: 959 loss: 5.60913759e-06
Iter: 960 loss: 5.59716864e-06
Iter: 961 loss: 5.59551836e-06
Iter: 962 loss: 5.59612818e-06
Iter: 963 loss: 5.59429463e-06
Iter: 964 loss: 5.59080445e-06
Iter: 965 loss: 5.59259797e-06
Iter: 966 loss: 5.58845477e-06
Iter: 967 loss: 5.58483271e-06
Iter: 968 loss: 5.58570036e-06
Iter: 969 loss: 5.58212605e-06
Iter: 970 loss: 5.57821568e-06
Iter: 971 loss: 5.60776698e-06
Iter: 972 loss: 5.57796466e-06
Iter: 973 loss: 5.57518024e-06
Iter: 974 loss: 5.59448745e-06
Iter: 975 loss: 5.57487374e-06
Iter: 976 loss: 5.57175827e-06
Iter: 977 loss: 5.56826308e-06
Iter: 978 loss: 5.56775967e-06
Iter: 979 loss: 5.56487657e-06
Iter: 980 loss: 5.56890973e-06
Iter: 981 loss: 5.56347823e-06
Iter: 982 loss: 5.56091709e-06
Iter: 983 loss: 5.56086707e-06
Iter: 984 loss: 5.55903034e-06
Iter: 985 loss: 5.55364932e-06
Iter: 986 loss: 5.576082e-06
Iter: 987 loss: 5.5515784e-06
Iter: 988 loss: 5.5459459e-06
Iter: 989 loss: 5.58904048e-06
Iter: 990 loss: 5.54548069e-06
Iter: 991 loss: 5.54407234e-06
Iter: 992 loss: 5.54308053e-06
Iter: 993 loss: 5.54127e-06
Iter: 994 loss: 5.53767131e-06
Iter: 995 loss: 5.61032175e-06
Iter: 996 loss: 5.53767632e-06
Iter: 997 loss: 5.53618702e-06
Iter: 998 loss: 5.53597965e-06
Iter: 999 loss: 5.5343462e-06
Iter: 1000 loss: 5.53142354e-06
Iter: 1001 loss: 5.53141172e-06
Iter: 1002 loss: 5.52861911e-06
Iter: 1003 loss: 5.53181053e-06
Iter: 1004 loss: 5.52702431e-06
Iter: 1005 loss: 5.52284382e-06
Iter: 1006 loss: 5.54012149e-06
Iter: 1007 loss: 5.52186111e-06
Iter: 1008 loss: 5.51788162e-06
Iter: 1009 loss: 5.54729286e-06
Iter: 1010 loss: 5.51755056e-06
Iter: 1011 loss: 5.51492576e-06
Iter: 1012 loss: 5.51284211e-06
Iter: 1013 loss: 5.51194717e-06
Iter: 1014 loss: 5.50946879e-06
Iter: 1015 loss: 5.52238635e-06
Iter: 1016 loss: 5.50906225e-06
Iter: 1017 loss: 5.50571121e-06
Iter: 1018 loss: 5.51410085e-06
Iter: 1019 loss: 5.50464847e-06
Iter: 1020 loss: 5.50247933e-06
Iter: 1021 loss: 5.49886863e-06
Iter: 1022 loss: 5.4988177e-06
Iter: 1023 loss: 5.49511697e-06
Iter: 1024 loss: 5.5217015e-06
Iter: 1025 loss: 5.49479682e-06
Iter: 1026 loss: 5.48977641e-06
Iter: 1027 loss: 5.5034734e-06
Iter: 1028 loss: 5.48819798e-06
Iter: 1029 loss: 5.48509e-06
Iter: 1030 loss: 5.48651224e-06
Iter: 1031 loss: 5.48308299e-06
Iter: 1032 loss: 5.47964828e-06
Iter: 1033 loss: 5.52522124e-06
Iter: 1034 loss: 5.47960644e-06
Iter: 1035 loss: 5.47789887e-06
Iter: 1036 loss: 5.47373838e-06
Iter: 1037 loss: 5.51782705e-06
Iter: 1038 loss: 5.47327591e-06
Iter: 1039 loss: 5.47008085e-06
Iter: 1040 loss: 5.47007539e-06
Iter: 1041 loss: 5.46768024e-06
Iter: 1042 loss: 5.48404887e-06
Iter: 1043 loss: 5.46749288e-06
Iter: 1044 loss: 5.46537694e-06
Iter: 1045 loss: 5.46444107e-06
Iter: 1046 loss: 5.46337924e-06
Iter: 1047 loss: 5.45978128e-06
Iter: 1048 loss: 5.45452713e-06
Iter: 1049 loss: 5.45437706e-06
Iter: 1050 loss: 5.4549896e-06
Iter: 1051 loss: 5.45184821e-06
Iter: 1052 loss: 5.44993827e-06
Iter: 1053 loss: 5.44595059e-06
Iter: 1054 loss: 5.51724725e-06
Iter: 1055 loss: 5.44593195e-06
Iter: 1056 loss: 5.44276918e-06
Iter: 1057 loss: 5.44597697e-06
Iter: 1058 loss: 5.44093791e-06
Iter: 1059 loss: 5.43982424e-06
Iter: 1060 loss: 5.43899023e-06
Iter: 1061 loss: 5.43732494e-06
Iter: 1062 loss: 5.43338138e-06
Iter: 1063 loss: 5.48375647e-06
Iter: 1064 loss: 5.43309034e-06
Iter: 1065 loss: 5.43059923e-06
Iter: 1066 loss: 5.4306438e-06
Iter: 1067 loss: 5.42781891e-06
Iter: 1068 loss: 5.4234124e-06
Iter: 1069 loss: 5.42341832e-06
Iter: 1070 loss: 5.41915824e-06
Iter: 1071 loss: 5.42117095e-06
Iter: 1072 loss: 5.41631653e-06
Iter: 1073 loss: 5.41482e-06
Iter: 1074 loss: 5.41397503e-06
Iter: 1075 loss: 5.41207328e-06
Iter: 1076 loss: 5.41626332e-06
Iter: 1077 loss: 5.41132113e-06
Iter: 1078 loss: 5.40916108e-06
Iter: 1079 loss: 5.40701421e-06
Iter: 1080 loss: 5.40661222e-06
Iter: 1081 loss: 5.40267092e-06
Iter: 1082 loss: 5.40663677e-06
Iter: 1083 loss: 5.4003167e-06
Iter: 1084 loss: 5.39670236e-06
Iter: 1085 loss: 5.39659368e-06
Iter: 1086 loss: 5.39473785e-06
Iter: 1087 loss: 5.39026405e-06
Iter: 1088 loss: 5.43952137e-06
Iter: 1089 loss: 5.389752e-06
Iter: 1090 loss: 5.38634595e-06
Iter: 1091 loss: 5.42612361e-06
Iter: 1092 loss: 5.38624909e-06
Iter: 1093 loss: 5.38248332e-06
Iter: 1094 loss: 5.3985641e-06
Iter: 1095 loss: 5.38165295e-06
Iter: 1096 loss: 5.37991764e-06
Iter: 1097 loss: 5.37871938e-06
Iter: 1098 loss: 5.37801861e-06
Iter: 1099 loss: 5.37571032e-06
Iter: 1100 loss: 5.37572942e-06
Iter: 1101 loss: 5.3739318e-06
Iter: 1102 loss: 5.36857806e-06
Iter: 1103 loss: 5.3791e-06
Iter: 1104 loss: 5.36513789e-06
Iter: 1105 loss: 5.35869367e-06
Iter: 1106 loss: 5.41374084e-06
Iter: 1107 loss: 5.35832896e-06
Iter: 1108 loss: 5.35377512e-06
Iter: 1109 loss: 5.35747949e-06
Iter: 1110 loss: 5.35101663e-06
Iter: 1111 loss: 5.3509516e-06
Iter: 1112 loss: 5.34870196e-06
Iter: 1113 loss: 5.3466124e-06
Iter: 1114 loss: 5.3456929e-06
Iter: 1115 loss: 5.3446729e-06
Iter: 1116 loss: 5.34147603e-06
Iter: 1117 loss: 5.34455194e-06
Iter: 1118 loss: 5.33969796e-06
Iter: 1119 loss: 5.33638695e-06
Iter: 1120 loss: 5.36284e-06
Iter: 1121 loss: 5.33617094e-06
Iter: 1122 loss: 5.33274715e-06
Iter: 1123 loss: 5.33340699e-06
Iter: 1124 loss: 5.33020375e-06
Iter: 1125 loss: 5.32714512e-06
Iter: 1126 loss: 5.32329386e-06
Iter: 1127 loss: 5.32293234e-06
Iter: 1128 loss: 5.31834348e-06
Iter: 1129 loss: 5.34328046e-06
Iter: 1130 loss: 5.317665e-06
Iter: 1131 loss: 5.3145618e-06
Iter: 1132 loss: 5.31437672e-06
Iter: 1133 loss: 5.31275464e-06
Iter: 1134 loss: 5.30872967e-06
Iter: 1135 loss: 5.34066e-06
Iter: 1136 loss: 5.30790749e-06
Iter: 1137 loss: 5.30358193e-06
Iter: 1138 loss: 5.31938258e-06
Iter: 1139 loss: 5.30240504e-06
Iter: 1140 loss: 5.29811041e-06
Iter: 1141 loss: 5.36225934e-06
Iter: 1142 loss: 5.29817498e-06
Iter: 1143 loss: 5.29647332e-06
Iter: 1144 loss: 5.29372392e-06
Iter: 1145 loss: 5.29367662e-06
Iter: 1146 loss: 5.29116733e-06
Iter: 1147 loss: 5.31274827e-06
Iter: 1148 loss: 5.29103363e-06
Iter: 1149 loss: 5.28738747e-06
Iter: 1150 loss: 5.28354212e-06
Iter: 1151 loss: 5.28292549e-06
Iter: 1152 loss: 5.2794021e-06
Iter: 1153 loss: 5.29180397e-06
Iter: 1154 loss: 5.27855445e-06
Iter: 1155 loss: 5.27493467e-06
Iter: 1156 loss: 5.30716352e-06
Iter: 1157 loss: 5.27466455e-06
Iter: 1158 loss: 5.27236034e-06
Iter: 1159 loss: 5.2706655e-06
Iter: 1160 loss: 5.26994836e-06
Iter: 1161 loss: 5.2662358e-06
Iter: 1162 loss: 5.27553539e-06
Iter: 1163 loss: 5.26490794e-06
Iter: 1164 loss: 5.26219083e-06
Iter: 1165 loss: 5.26402118e-06
Iter: 1166 loss: 5.26045e-06
Iter: 1167 loss: 5.25843052e-06
Iter: 1168 loss: 5.25807809e-06
Iter: 1169 loss: 5.25649784e-06
Iter: 1170 loss: 5.25221276e-06
Iter: 1171 loss: 5.27173688e-06
Iter: 1172 loss: 5.25058613e-06
Iter: 1173 loss: 5.24524739e-06
Iter: 1174 loss: 5.2593623e-06
Iter: 1175 loss: 5.2434475e-06
Iter: 1176 loss: 5.24087318e-06
Iter: 1177 loss: 5.2407745e-06
Iter: 1178 loss: 5.23755898e-06
Iter: 1179 loss: 5.24030702e-06
Iter: 1180 loss: 5.23574272e-06
Iter: 1181 loss: 5.23294466e-06
Iter: 1182 loss: 5.22938853e-06
Iter: 1183 loss: 5.22903701e-06
Iter: 1184 loss: 5.22493656e-06
Iter: 1185 loss: 5.25528139e-06
Iter: 1186 loss: 5.22457867e-06
Iter: 1187 loss: 5.21962647e-06
Iter: 1188 loss: 5.24010738e-06
Iter: 1189 loss: 5.21854099e-06
Iter: 1190 loss: 5.21573884e-06
Iter: 1191 loss: 5.21213951e-06
Iter: 1192 loss: 5.21187758e-06
Iter: 1193 loss: 5.21057518e-06
Iter: 1194 loss: 5.20996673e-06
Iter: 1195 loss: 5.2081482e-06
Iter: 1196 loss: 5.20706044e-06
Iter: 1197 loss: 5.20630692e-06
Iter: 1198 loss: 5.20338244e-06
Iter: 1199 loss: 5.20864887e-06
Iter: 1200 loss: 5.20212325e-06
Iter: 1201 loss: 5.19914238e-06
Iter: 1202 loss: 5.19572086e-06
Iter: 1203 loss: 5.19521e-06
Iter: 1204 loss: 5.19511514e-06
Iter: 1205 loss: 5.19310879e-06
Iter: 1206 loss: 5.19077366e-06
Iter: 1207 loss: 5.18543129e-06
Iter: 1208 loss: 5.24770076e-06
Iter: 1209 loss: 5.18495881e-06
Iter: 1210 loss: 5.17968738e-06
Iter: 1211 loss: 5.18315755e-06
Iter: 1212 loss: 5.17641456e-06
Iter: 1213 loss: 5.1741722e-06
Iter: 1214 loss: 5.1738939e-06
Iter: 1215 loss: 5.17119679e-06
Iter: 1216 loss: 5.17771605e-06
Iter: 1217 loss: 5.17022954e-06
Iter: 1218 loss: 5.16810405e-06
Iter: 1219 loss: 5.16272e-06
Iter: 1220 loss: 5.21342781e-06
Iter: 1221 loss: 5.16197542e-06
Iter: 1222 loss: 5.15636657e-06
Iter: 1223 loss: 5.18597517e-06
Iter: 1224 loss: 5.15540296e-06
Iter: 1225 loss: 5.15296233e-06
Iter: 1226 loss: 5.15231e-06
Iter: 1227 loss: 5.14941848e-06
Iter: 1228 loss: 5.14448402e-06
Iter: 1229 loss: 5.14446856e-06
Iter: 1230 loss: 5.1413158e-06
Iter: 1231 loss: 5.15846386e-06
Iter: 1232 loss: 5.14085605e-06
Iter: 1233 loss: 5.13760642e-06
Iter: 1234 loss: 5.15912143e-06
Iter: 1235 loss: 5.13729765e-06
Iter: 1236 loss: 5.13478608e-06
Iter: 1237 loss: 5.13837676e-06
Iter: 1238 loss: 5.13342e-06
Iter: 1239 loss: 5.13057739e-06
Iter: 1240 loss: 5.12559e-06
Iter: 1241 loss: 5.12561473e-06
Iter: 1242 loss: 5.12186307e-06
Iter: 1243 loss: 5.12190036e-06
Iter: 1244 loss: 5.11782582e-06
Iter: 1245 loss: 5.13237819e-06
Iter: 1246 loss: 5.11677899e-06
Iter: 1247 loss: 5.11473581e-06
Iter: 1248 loss: 5.11049211e-06
Iter: 1249 loss: 5.18370962e-06
Iter: 1250 loss: 5.11035068e-06
Iter: 1251 loss: 5.10696282e-06
Iter: 1252 loss: 5.13216492e-06
Iter: 1253 loss: 5.10669452e-06
Iter: 1254 loss: 5.1038528e-06
Iter: 1255 loss: 5.1438119e-06
Iter: 1256 loss: 5.10382688e-06
Iter: 1257 loss: 5.10166774e-06
Iter: 1258 loss: 5.09582514e-06
Iter: 1259 loss: 5.12920178e-06
Iter: 1260 loss: 5.09405072e-06
Iter: 1261 loss: 5.08781341e-06
Iter: 1262 loss: 5.10556e-06
Iter: 1263 loss: 5.08587436e-06
Iter: 1264 loss: 5.08563198e-06
Iter: 1265 loss: 5.08301173e-06
Iter: 1266 loss: 5.08064659e-06
Iter: 1267 loss: 5.07655113e-06
Iter: 1268 loss: 5.07651657e-06
Iter: 1269 loss: 5.07321192e-06
Iter: 1270 loss: 5.08451149e-06
Iter: 1271 loss: 5.07231834e-06
Iter: 1272 loss: 5.06878132e-06
Iter: 1273 loss: 5.09830443e-06
Iter: 1274 loss: 5.06844663e-06
Iter: 1275 loss: 5.06581546e-06
Iter: 1276 loss: 5.06823926e-06
Iter: 1277 loss: 5.06432843e-06
Iter: 1278 loss: 5.06117794e-06
Iter: 1279 loss: 5.05867411e-06
Iter: 1280 loss: 5.0577587e-06
Iter: 1281 loss: 5.05400976e-06
Iter: 1282 loss: 5.07804361e-06
Iter: 1283 loss: 5.05362823e-06
Iter: 1284 loss: 5.05095977e-06
Iter: 1285 loss: 5.05089974e-06
Iter: 1286 loss: 5.04973377e-06
Iter: 1287 loss: 5.04569061e-06
Iter: 1288 loss: 5.04531909e-06
Iter: 1289 loss: 5.04127684e-06
Iter: 1290 loss: 5.0355743e-06
Iter: 1291 loss: 5.11960934e-06
Iter: 1292 loss: 5.03557112e-06
Iter: 1293 loss: 5.03321826e-06
Iter: 1294 loss: 5.03292176e-06
Iter: 1295 loss: 5.03038927e-06
Iter: 1296 loss: 5.02487364e-06
Iter: 1297 loss: 5.11109738e-06
Iter: 1298 loss: 5.02472085e-06
Iter: 1299 loss: 5.02141756e-06
Iter: 1300 loss: 5.03392357e-06
Iter: 1301 loss: 5.02062267e-06
Iter: 1302 loss: 5.01855584e-06
Iter: 1303 loss: 5.0184176e-06
Iter: 1304 loss: 5.01654085e-06
Iter: 1305 loss: 5.01134946e-06
Iter: 1306 loss: 5.03916726e-06
Iter: 1307 loss: 5.00976103e-06
Iter: 1308 loss: 5.00603801e-06
Iter: 1309 loss: 5.00599708e-06
Iter: 1310 loss: 5.00207125e-06
Iter: 1311 loss: 5.01224076e-06
Iter: 1312 loss: 5.00083888e-06
Iter: 1313 loss: 4.99732323e-06
Iter: 1314 loss: 5.00048e-06
Iter: 1315 loss: 4.99535872e-06
Iter: 1316 loss: 4.99135695e-06
Iter: 1317 loss: 4.9928417e-06
Iter: 1318 loss: 4.98858208e-06
Iter: 1319 loss: 4.9869027e-06
Iter: 1320 loss: 4.98662757e-06
Iter: 1321 loss: 4.98449162e-06
Iter: 1322 loss: 4.98409918e-06
Iter: 1323 loss: 4.98266e-06
Iter: 1324 loss: 4.9803366e-06
Iter: 1325 loss: 4.97413203e-06
Iter: 1326 loss: 5.01702e-06
Iter: 1327 loss: 4.9726541e-06
Iter: 1328 loss: 4.97361543e-06
Iter: 1329 loss: 4.96942e-06
Iter: 1330 loss: 4.96637858e-06
Iter: 1331 loss: 4.9618543e-06
Iter: 1332 loss: 4.96166467e-06
Iter: 1333 loss: 4.9575774e-06
Iter: 1334 loss: 4.95698805e-06
Iter: 1335 loss: 4.95406539e-06
Iter: 1336 loss: 4.95397899e-06
Iter: 1337 loss: 4.95189943e-06
Iter: 1338 loss: 4.94997812e-06
Iter: 1339 loss: 4.94830601e-06
Iter: 1340 loss: 4.94773076e-06
Iter: 1341 loss: 4.94534197e-06
Iter: 1342 loss: 4.94202777e-06
Iter: 1343 loss: 4.9418295e-06
Iter: 1344 loss: 4.93962852e-06
Iter: 1345 loss: 4.93903599e-06
Iter: 1346 loss: 4.93659672e-06
Iter: 1347 loss: 4.93300831e-06
Iter: 1348 loss: 4.93291236e-06
Iter: 1349 loss: 4.92865638e-06
Iter: 1350 loss: 4.94857068e-06
Iter: 1351 loss: 4.92789513e-06
Iter: 1352 loss: 4.92494155e-06
Iter: 1353 loss: 4.92690651e-06
Iter: 1354 loss: 4.92313393e-06
Iter: 1355 loss: 4.920842e-06
Iter: 1356 loss: 4.92050185e-06
Iter: 1357 loss: 4.91916671e-06
Iter: 1358 loss: 4.91606443e-06
Iter: 1359 loss: 4.95242421e-06
Iter: 1360 loss: 4.91576975e-06
Iter: 1361 loss: 4.91409537e-06
Iter: 1362 loss: 4.91386845e-06
Iter: 1363 loss: 4.91192077e-06
Iter: 1364 loss: 4.9069713e-06
Iter: 1365 loss: 4.94242477e-06
Iter: 1366 loss: 4.90583398e-06
Iter: 1367 loss: 4.90031061e-06
Iter: 1368 loss: 4.92225809e-06
Iter: 1369 loss: 4.89919648e-06
Iter: 1370 loss: 4.89879085e-06
Iter: 1371 loss: 4.89734111e-06
Iter: 1372 loss: 4.89603644e-06
Iter: 1373 loss: 4.89242166e-06
Iter: 1374 loss: 4.91636729e-06
Iter: 1375 loss: 4.89159356e-06
Iter: 1376 loss: 4.88823571e-06
Iter: 1377 loss: 4.90676393e-06
Iter: 1378 loss: 4.88770092e-06
Iter: 1379 loss: 4.88546448e-06
Iter: 1380 loss: 4.88540036e-06
Iter: 1381 loss: 4.88383921e-06
Iter: 1382 loss: 4.88042588e-06
Iter: 1383 loss: 4.92841082e-06
Iter: 1384 loss: 4.88023579e-06
Iter: 1385 loss: 4.87621628e-06
Iter: 1386 loss: 4.89997e-06
Iter: 1387 loss: 4.87574471e-06
Iter: 1388 loss: 4.87275065e-06
Iter: 1389 loss: 4.87947045e-06
Iter: 1390 loss: 4.87148554e-06
Iter: 1391 loss: 4.8692882e-06
Iter: 1392 loss: 4.86920089e-06
Iter: 1393 loss: 4.86814315e-06
Iter: 1394 loss: 4.86556655e-06
Iter: 1395 loss: 4.89328249e-06
Iter: 1396 loss: 4.86535055e-06
Iter: 1397 loss: 4.86381487e-06
Iter: 1398 loss: 4.86365388e-06
Iter: 1399 loss: 4.86196222e-06
Iter: 1400 loss: 4.85788951e-06
Iter: 1401 loss: 4.90372167e-06
Iter: 1402 loss: 4.8574866e-06
Iter: 1403 loss: 4.85421106e-06
Iter: 1404 loss: 4.86763383e-06
Iter: 1405 loss: 4.8534439e-06
Iter: 1406 loss: 4.85067358e-06
Iter: 1407 loss: 4.85062446e-06
Iter: 1408 loss: 4.84906559e-06
Iter: 1409 loss: 4.84558e-06
Iter: 1410 loss: 4.90197908e-06
Iter: 1411 loss: 4.84547581e-06
Iter: 1412 loss: 4.84344218e-06
Iter: 1413 loss: 4.86577574e-06
Iter: 1414 loss: 4.84345128e-06
Iter: 1415 loss: 4.84126394e-06
Iter: 1416 loss: 4.85001055e-06
Iter: 1417 loss: 4.84077918e-06
Iter: 1418 loss: 4.83930171e-06
Iter: 1419 loss: 4.83662279e-06
Iter: 1420 loss: 4.83661688e-06
Iter: 1421 loss: 4.83390659e-06
Iter: 1422 loss: 4.86208364e-06
Iter: 1423 loss: 4.8338843e-06
Iter: 1424 loss: 4.83197846e-06
Iter: 1425 loss: 4.83298663e-06
Iter: 1426 loss: 4.83070653e-06
Iter: 1427 loss: 4.82809628e-06
Iter: 1428 loss: 4.85957435e-06
Iter: 1429 loss: 4.82811447e-06
Iter: 1430 loss: 4.82687574e-06
Iter: 1431 loss: 4.82469932e-06
Iter: 1432 loss: 4.87658281e-06
Iter: 1433 loss: 4.82473661e-06
Iter: 1434 loss: 4.82354608e-06
Iter: 1435 loss: 4.82326686e-06
Iter: 1436 loss: 4.82230371e-06
Iter: 1437 loss: 4.81987354e-06
Iter: 1438 loss: 4.84422e-06
Iter: 1439 loss: 4.81959796e-06
Iter: 1440 loss: 4.81659572e-06
Iter: 1441 loss: 4.81711731e-06
Iter: 1442 loss: 4.81434381e-06
Iter: 1443 loss: 4.81075676e-06
Iter: 1444 loss: 4.82416453e-06
Iter: 1445 loss: 4.80990229e-06
Iter: 1446 loss: 4.80756898e-06
Iter: 1447 loss: 4.80755534e-06
Iter: 1448 loss: 4.80496e-06
Iter: 1449 loss: 4.81671577e-06
Iter: 1450 loss: 4.80449125e-06
Iter: 1451 loss: 4.80322069e-06
Iter: 1452 loss: 4.80151812e-06
Iter: 1453 loss: 4.80143626e-06
Iter: 1454 loss: 4.79940081e-06
Iter: 1455 loss: 4.81467396e-06
Iter: 1456 loss: 4.79919754e-06
Iter: 1457 loss: 4.79674554e-06
Iter: 1458 loss: 4.80167455e-06
Iter: 1459 loss: 4.79579649e-06
Iter: 1460 loss: 4.7936519e-06
Iter: 1461 loss: 4.80045219e-06
Iter: 1462 loss: 4.79311075e-06
Iter: 1463 loss: 4.79168193e-06
Iter: 1464 loss: 4.79270693e-06
Iter: 1465 loss: 4.79076334e-06
Iter: 1466 loss: 4.78880429e-06
Iter: 1467 loss: 4.80863855e-06
Iter: 1468 loss: 4.78876109e-06
Iter: 1469 loss: 4.78771562e-06
Iter: 1470 loss: 4.78551647e-06
Iter: 1471 loss: 4.82116411e-06
Iter: 1472 loss: 4.78543734e-06
Iter: 1473 loss: 4.78445781e-06
Iter: 1474 loss: 4.78402171e-06
Iter: 1475 loss: 4.783e-06
Iter: 1476 loss: 4.78002266e-06
Iter: 1477 loss: 4.80086692e-06
Iter: 1478 loss: 4.77936874e-06
Iter: 1479 loss: 4.77593039e-06
Iter: 1480 loss: 4.78177435e-06
Iter: 1481 loss: 4.77435242e-06
Iter: 1482 loss: 4.77118829e-06
Iter: 1483 loss: 4.78297261e-06
Iter: 1484 loss: 4.77040385e-06
Iter: 1485 loss: 4.76918967e-06
Iter: 1486 loss: 4.7689723e-06
Iter: 1487 loss: 4.76714422e-06
Iter: 1488 loss: 4.76439618e-06
Iter: 1489 loss: 4.76434343e-06
Iter: 1490 loss: 4.76162131e-06
Iter: 1491 loss: 4.76253e-06
Iter: 1492 loss: 4.75977731e-06
Iter: 1493 loss: 4.75709339e-06
Iter: 1494 loss: 4.78512902e-06
Iter: 1495 loss: 4.7570129e-06
Iter: 1496 loss: 4.75473826e-06
Iter: 1497 loss: 4.76964942e-06
Iter: 1498 loss: 4.75446177e-06
Iter: 1499 loss: 4.75269599e-06
Iter: 1500 loss: 4.75689967e-06
Iter: 1501 loss: 4.75207617e-06
Iter: 1502 loss: 4.75091656e-06
Iter: 1503 loss: 4.75983325e-06
Iter: 1504 loss: 4.75083561e-06
Iter: 1505 loss: 4.74958779e-06
Iter: 1506 loss: 4.74839635e-06
Iter: 1507 loss: 4.74815806e-06
Iter: 1508 loss: 4.74642911e-06
Iter: 1509 loss: 4.74420176e-06
Iter: 1510 loss: 4.74398939e-06
Iter: 1511 loss: 4.74252e-06
Iter: 1512 loss: 4.74195e-06
Iter: 1513 loss: 4.74063791e-06
Iter: 1514 loss: 4.73730688e-06
Iter: 1515 loss: 4.76986861e-06
Iter: 1516 loss: 4.73691e-06
Iter: 1517 loss: 4.73406e-06
Iter: 1518 loss: 4.74074932e-06
Iter: 1519 loss: 4.73301316e-06
Iter: 1520 loss: 4.72996226e-06
Iter: 1521 loss: 4.74055105e-06
Iter: 1522 loss: 4.72921511e-06
Iter: 1523 loss: 4.72964439e-06
Iter: 1524 loss: 4.72818147e-06
Iter: 1525 loss: 4.72732245e-06
Iter: 1526 loss: 4.72493048e-06
Iter: 1527 loss: 4.73009413e-06
Iter: 1528 loss: 4.72338434e-06
Iter: 1529 loss: 4.71955354e-06
Iter: 1530 loss: 4.73519867e-06
Iter: 1531 loss: 4.71867497e-06
Iter: 1532 loss: 4.71682688e-06
Iter: 1533 loss: 4.71653175e-06
Iter: 1534 loss: 4.7152289e-06
Iter: 1535 loss: 4.71265503e-06
Iter: 1536 loss: 4.75913066e-06
Iter: 1537 loss: 4.71263047e-06
Iter: 1538 loss: 4.71001658e-06
Iter: 1539 loss: 4.70998475e-06
Iter: 1540 loss: 4.70868326e-06
Iter: 1541 loss: 4.70675786e-06
Iter: 1542 loss: 4.7067424e-06
Iter: 1543 loss: 4.70460145e-06
Iter: 1544 loss: 4.71693602e-06
Iter: 1545 loss: 4.70437681e-06
Iter: 1546 loss: 4.70274153e-06
Iter: 1547 loss: 4.71267685e-06
Iter: 1548 loss: 4.70260784e-06
Iter: 1549 loss: 4.70071245e-06
Iter: 1550 loss: 4.70004943e-06
Iter: 1551 loss: 4.69900442e-06
Iter: 1552 loss: 4.69666384e-06
Iter: 1553 loss: 4.69266024e-06
Iter: 1554 loss: 4.69266024e-06
Iter: 1555 loss: 4.68886128e-06
Iter: 1556 loss: 4.71556041e-06
Iter: 1557 loss: 4.68851385e-06
Iter: 1558 loss: 4.68721737e-06
Iter: 1559 loss: 4.68685266e-06
Iter: 1560 loss: 4.68515236e-06
Iter: 1561 loss: 4.68390317e-06
Iter: 1562 loss: 4.68335793e-06
Iter: 1563 loss: 4.68166036e-06
Iter: 1564 loss: 4.67917e-06
Iter: 1565 loss: 4.67916107e-06
Iter: 1566 loss: 4.67603968e-06
Iter: 1567 loss: 4.70125178e-06
Iter: 1568 loss: 4.67585278e-06
Iter: 1569 loss: 4.67294103e-06
Iter: 1570 loss: 4.70541272e-06
Iter: 1571 loss: 4.67288464e-06
Iter: 1572 loss: 4.6717978e-06
Iter: 1573 loss: 4.67022937e-06
Iter: 1574 loss: 4.67018117e-06
Iter: 1575 loss: 4.66798065e-06
Iter: 1576 loss: 4.68933922e-06
Iter: 1577 loss: 4.66790698e-06
Iter: 1578 loss: 4.66646452e-06
Iter: 1579 loss: 4.66508027e-06
Iter: 1580 loss: 4.6648e-06
Iter: 1581 loss: 4.66251458e-06
Iter: 1582 loss: 4.67043947e-06
Iter: 1583 loss: 4.66188385e-06
Iter: 1584 loss: 4.65983612e-06
Iter: 1585 loss: 4.66794245e-06
Iter: 1586 loss: 4.6594505e-06
Iter: 1587 loss: 4.65683e-06
Iter: 1588 loss: 4.66255278e-06
Iter: 1589 loss: 4.6558489e-06
Iter: 1590 loss: 4.65405947e-06
Iter: 1591 loss: 4.65069206e-06
Iter: 1592 loss: 4.72522333e-06
Iter: 1593 loss: 4.6506384e-06
Iter: 1594 loss: 4.64745153e-06
Iter: 1595 loss: 4.6628038e-06
Iter: 1596 loss: 4.64690947e-06
Iter: 1597 loss: 4.64642153e-06
Iter: 1598 loss: 4.64554705e-06
Iter: 1599 loss: 4.64435698e-06
Iter: 1600 loss: 4.64122877e-06
Iter: 1601 loss: 4.66601432e-06
Iter: 1602 loss: 4.64061895e-06
Iter: 1603 loss: 4.63733568e-06
Iter: 1604 loss: 4.64814866e-06
Iter: 1605 loss: 4.63637207e-06
Iter: 1606 loss: 4.63652304e-06
Iter: 1607 loss: 4.63521928e-06
Iter: 1608 loss: 4.63426295e-06
Iter: 1609 loss: 4.63149172e-06
Iter: 1610 loss: 4.64888808e-06
Iter: 1611 loss: 4.63084416e-06
Iter: 1612 loss: 4.6296841e-06
Iter: 1613 loss: 4.62915432e-06
Iter: 1614 loss: 4.62789149e-06
Iter: 1615 loss: 4.62631579e-06
Iter: 1616 loss: 4.6261689e-06
Iter: 1617 loss: 4.62434e-06
Iter: 1618 loss: 4.62956632e-06
Iter: 1619 loss: 4.62374419e-06
Iter: 1620 loss: 4.62148455e-06
Iter: 1621 loss: 4.62487787e-06
Iter: 1622 loss: 4.62036769e-06
Iter: 1623 loss: 4.61783338e-06
Iter: 1624 loss: 4.64513096e-06
Iter: 1625 loss: 4.61779564e-06
Iter: 1626 loss: 4.61652598e-06
Iter: 1627 loss: 4.61391755e-06
Iter: 1628 loss: 4.65484936e-06
Iter: 1629 loss: 4.61376067e-06
Iter: 1630 loss: 4.61114087e-06
Iter: 1631 loss: 4.61844502e-06
Iter: 1632 loss: 4.61027594e-06
Iter: 1633 loss: 4.60906358e-06
Iter: 1634 loss: 4.60865704e-06
Iter: 1635 loss: 4.60738192e-06
Iter: 1636 loss: 4.60434103e-06
Iter: 1637 loss: 4.6346554e-06
Iter: 1638 loss: 4.60388856e-06
Iter: 1639 loss: 4.60085039e-06
Iter: 1640 loss: 4.606728e-06
Iter: 1641 loss: 4.59951025e-06
Iter: 1642 loss: 4.59733201e-06
Iter: 1643 loss: 4.59707235e-06
Iter: 1644 loss: 4.59527473e-06
Iter: 1645 loss: 4.59172588e-06
Iter: 1646 loss: 4.64872119e-06
Iter: 1647 loss: 4.59162629e-06
Iter: 1648 loss: 4.59085368e-06
Iter: 1649 loss: 4.59004605e-06
Iter: 1650 loss: 4.58891554e-06
Iter: 1651 loss: 4.58651493e-06
Iter: 1652 loss: 4.62003663e-06
Iter: 1653 loss: 4.58646e-06
Iter: 1654 loss: 4.58388968e-06
Iter: 1655 loss: 4.59676812e-06
Iter: 1656 loss: 4.58346494e-06
Iter: 1657 loss: 4.58131126e-06
Iter: 1658 loss: 4.59428702e-06
Iter: 1659 loss: 4.58093746e-06
Iter: 1660 loss: 4.57871647e-06
Iter: 1661 loss: 4.58551176e-06
Iter: 1662 loss: 4.57805436e-06
Iter: 1663 loss: 4.57626356e-06
Iter: 1664 loss: 4.57217448e-06
Iter: 1665 loss: 4.62607295e-06
Iter: 1666 loss: 4.5718607e-06
Iter: 1667 loss: 4.56772614e-06
Iter: 1668 loss: 4.59999183e-06
Iter: 1669 loss: 4.56742237e-06
Iter: 1670 loss: 4.56575617e-06
Iter: 1671 loss: 4.56531734e-06
Iter: 1672 loss: 4.56444195e-06
Iter: 1673 loss: 4.56228099e-06
Iter: 1674 loss: 4.58292652e-06
Iter: 1675 loss: 4.56195403e-06
Iter: 1676 loss: 4.55957e-06
Iter: 1677 loss: 4.56599946e-06
Iter: 1678 loss: 4.55878398e-06
Iter: 1679 loss: 4.55639156e-06
Iter: 1680 loss: 4.55641384e-06
Iter: 1681 loss: 4.55535428e-06
Iter: 1682 loss: 4.55319378e-06
Iter: 1683 loss: 4.58519298e-06
Iter: 1684 loss: 4.55309828e-06
Iter: 1685 loss: 4.55038116e-06
Iter: 1686 loss: 4.5812908e-06
Iter: 1687 loss: 4.55034433e-06
Iter: 1688 loss: 4.54839528e-06
Iter: 1689 loss: 4.54486599e-06
Iter: 1690 loss: 4.62491107e-06
Iter: 1691 loss: 4.54484052e-06
Iter: 1692 loss: 4.54285328e-06
Iter: 1693 loss: 4.5427887e-06
Iter: 1694 loss: 4.54143083e-06
Iter: 1695 loss: 4.5483971e-06
Iter: 1696 loss: 4.54121755e-06
Iter: 1697 loss: 4.53970097e-06
Iter: 1698 loss: 4.53830035e-06
Iter: 1699 loss: 4.53794564e-06
Iter: 1700 loss: 4.53579196e-06
Iter: 1701 loss: 4.53416669e-06
Iter: 1702 loss: 4.53339e-06
Iter: 1703 loss: 4.53044777e-06
Iter: 1704 loss: 4.55176e-06
Iter: 1705 loss: 4.53019402e-06
Iter: 1706 loss: 4.52682e-06
Iter: 1707 loss: 4.55063719e-06
Iter: 1708 loss: 4.5266197e-06
Iter: 1709 loss: 4.52511085e-06
Iter: 1710 loss: 4.52209724e-06
Iter: 1711 loss: 4.57943815e-06
Iter: 1712 loss: 4.5221077e-06
Iter: 1713 loss: 4.52090353e-06
Iter: 1714 loss: 4.52055428e-06
Iter: 1715 loss: 4.51889218e-06
Iter: 1716 loss: 4.51859523e-06
Iter: 1717 loss: 4.51754249e-06
Iter: 1718 loss: 4.51621509e-06
Iter: 1719 loss: 4.51912638e-06
Iter: 1720 loss: 4.51572714e-06
Iter: 1721 loss: 4.51361484e-06
Iter: 1722 loss: 4.51369442e-06
Iter: 1723 loss: 4.51188043e-06
Iter: 1724 loss: 4.50954622e-06
Iter: 1725 loss: 4.50861126e-06
Iter: 1726 loss: 4.50729385e-06
Iter: 1727 loss: 4.50503376e-06
Iter: 1728 loss: 4.50502557e-06
Iter: 1729 loss: 4.50320204e-06
Iter: 1730 loss: 4.5072743e-06
Iter: 1731 loss: 4.50253e-06
Iter: 1732 loss: 4.500469e-06
Iter: 1733 loss: 4.49992467e-06
Iter: 1734 loss: 4.49871277e-06
Iter: 1735 loss: 4.49676e-06
Iter: 1736 loss: 4.49800882e-06
Iter: 1737 loss: 4.49547633e-06
Iter: 1738 loss: 4.49379468e-06
Iter: 1739 loss: 4.49382424e-06
Iter: 1740 loss: 4.491646e-06
Iter: 1741 loss: 4.48870651e-06
Iter: 1742 loss: 4.48860283e-06
Iter: 1743 loss: 4.48610263e-06
Iter: 1744 loss: 4.49063e-06
Iter: 1745 loss: 4.48506944e-06
Iter: 1746 loss: 4.48361834e-06
Iter: 1747 loss: 4.48323362e-06
Iter: 1748 loss: 4.48222818e-06
Iter: 1749 loss: 4.47981483e-06
Iter: 1750 loss: 4.50929565e-06
Iter: 1751 loss: 4.47960156e-06
Iter: 1752 loss: 4.47881803e-06
Iter: 1753 loss: 4.47837738e-06
Iter: 1754 loss: 4.47735965e-06
Iter: 1755 loss: 4.47517368e-06
Iter: 1756 loss: 4.50791413e-06
Iter: 1757 loss: 4.47514503e-06
Iter: 1758 loss: 4.47313141e-06
Iter: 1759 loss: 4.4813878e-06
Iter: 1760 loss: 4.47272942e-06
Iter: 1761 loss: 4.47048842e-06
Iter: 1762 loss: 4.47959428e-06
Iter: 1763 loss: 4.46995591e-06
Iter: 1764 loss: 4.46780859e-06
Iter: 1765 loss: 4.47057801e-06
Iter: 1766 loss: 4.46664581e-06
Iter: 1767 loss: 4.46425565e-06
Iter: 1768 loss: 4.4646963e-06
Iter: 1769 loss: 4.46249942e-06
Iter: 1770 loss: 4.46023842e-06
Iter: 1771 loss: 4.46101603e-06
Iter: 1772 loss: 4.45850901e-06
Iter: 1773 loss: 4.45808473e-06
Iter: 1774 loss: 4.45727801e-06
Iter: 1775 loss: 4.45596879e-06
Iter: 1776 loss: 4.45484966e-06
Iter: 1777 loss: 4.45450223e-06
Iter: 1778 loss: 4.45303795e-06
Iter: 1779 loss: 4.45419573e-06
Iter: 1780 loss: 4.4522435e-06
Iter: 1781 loss: 4.44943089e-06
Iter: 1782 loss: 4.45933e-06
Iter: 1783 loss: 4.44873831e-06
Iter: 1784 loss: 4.44713714e-06
Iter: 1785 loss: 4.44619718e-06
Iter: 1786 loss: 4.44557554e-06
Iter: 1787 loss: 4.44398347e-06
Iter: 1788 loss: 4.44389116e-06
Iter: 1789 loss: 4.44293073e-06
Iter: 1790 loss: 4.44063835e-06
Iter: 1791 loss: 4.46239e-06
Iter: 1792 loss: 4.44031957e-06
Iter: 1793 loss: 4.43878707e-06
Iter: 1794 loss: 4.43876525e-06
Iter: 1795 loss: 4.43721092e-06
Iter: 1796 loss: 4.43916451e-06
Iter: 1797 loss: 4.43638237e-06
Iter: 1798 loss: 4.43479075e-06
Iter: 1799 loss: 4.43675071e-06
Iter: 1800 loss: 4.43393401e-06
Iter: 1801 loss: 4.43197814e-06
Iter: 1802 loss: 4.43076169e-06
Iter: 1803 loss: 4.42994678e-06
Iter: 1804 loss: 4.42745659e-06
Iter: 1805 loss: 4.43730642e-06
Iter: 1806 loss: 4.42692544e-06
Iter: 1807 loss: 4.42543205e-06
Iter: 1808 loss: 4.425302e-06
Iter: 1809 loss: 4.42432929e-06
Iter: 1810 loss: 4.42228338e-06
Iter: 1811 loss: 4.45083379e-06
Iter: 1812 loss: 4.42218288e-06
Iter: 1813 loss: 4.421433e-06
Iter: 1814 loss: 4.42096871e-06
Iter: 1815 loss: 4.41994871e-06
Iter: 1816 loss: 4.41753764e-06
Iter: 1817 loss: 4.44362377e-06
Iter: 1818 loss: 4.41722887e-06
Iter: 1819 loss: 4.41613338e-06
Iter: 1820 loss: 4.41597331e-06
Iter: 1821 loss: 4.41476095e-06
Iter: 1822 loss: 4.41357679e-06
Iter: 1823 loss: 4.41335669e-06
Iter: 1824 loss: 4.41171323e-06
Iter: 1825 loss: 4.41063548e-06
Iter: 1826 loss: 4.40995109e-06
Iter: 1827 loss: 4.40923122e-06
Iter: 1828 loss: 4.40870917e-06
Iter: 1829 loss: 4.40800659e-06
Iter: 1830 loss: 4.40635358e-06
Iter: 1831 loss: 4.42970577e-06
Iter: 1832 loss: 4.40627264e-06
Iter: 1833 loss: 4.40411304e-06
Iter: 1834 loss: 4.41575639e-06
Iter: 1835 loss: 4.40382655e-06
Iter: 1836 loss: 4.40210715e-06
Iter: 1837 loss: 4.40061649e-06
Iter: 1838 loss: 4.40018266e-06
Iter: 1839 loss: 4.39775749e-06
Iter: 1840 loss: 4.41029442e-06
Iter: 1841 loss: 4.39742416e-06
Iter: 1842 loss: 4.39742325e-06
Iter: 1843 loss: 4.39663518e-06
Iter: 1844 loss: 4.39599535e-06
Iter: 1845 loss: 4.39427e-06
Iter: 1846 loss: 4.40573422e-06
Iter: 1847 loss: 4.39384894e-06
Iter: 1848 loss: 4.39352152e-06
Iter: 1849 loss: 4.39294126e-06
Iter: 1850 loss: 4.39211271e-06
Iter: 1851 loss: 4.39004452e-06
Iter: 1852 loss: 4.41242719e-06
Iter: 1853 loss: 4.38982715e-06
Iter: 1854 loss: 4.3878963e-06
Iter: 1855 loss: 4.40202439e-06
Iter: 1856 loss: 4.38777715e-06
Iter: 1857 loss: 4.38529423e-06
Iter: 1858 loss: 4.38778443e-06
Iter: 1859 loss: 4.38397137e-06
Iter: 1860 loss: 4.38247707e-06
Iter: 1861 loss: 4.38232291e-06
Iter: 1862 loss: 4.38122288e-06
Iter: 1863 loss: 4.38046118e-06
Iter: 1864 loss: 4.38030702e-06
Iter: 1865 loss: 4.37937479e-06
Iter: 1866 loss: 4.37742e-06
Iter: 1867 loss: 4.41548946e-06
Iter: 1868 loss: 4.37741528e-06
Iter: 1869 loss: 4.37557537e-06
Iter: 1870 loss: 4.37638437e-06
Iter: 1871 loss: 4.37433937e-06
Iter: 1872 loss: 4.37161e-06
Iter: 1873 loss: 4.38993e-06
Iter: 1874 loss: 4.37134759e-06
Iter: 1875 loss: 4.36939263e-06
Iter: 1876 loss: 4.36782193e-06
Iter: 1877 loss: 4.36721075e-06
Iter: 1878 loss: 4.36665732e-06
Iter: 1879 loss: 4.36597111e-06
Iter: 1880 loss: 4.36461596e-06
Iter: 1881 loss: 4.36426581e-06
Iter: 1882 loss: 4.36347818e-06
Iter: 1883 loss: 4.36271512e-06
Iter: 1884 loss: 4.36272512e-06
Iter: 1885 loss: 4.36183336e-06
Iter: 1886 loss: 4.35949096e-06
Iter: 1887 loss: 4.37589e-06
Iter: 1888 loss: 4.3588916e-06
Iter: 1889 loss: 4.35679885e-06
Iter: 1890 loss: 4.36710434e-06
Iter: 1891 loss: 4.35651737e-06
Iter: 1892 loss: 4.35484708e-06
Iter: 1893 loss: 4.35483253e-06
Iter: 1894 loss: 4.35383936e-06
Iter: 1895 loss: 4.35149286e-06
Iter: 1896 loss: 4.38396546e-06
Iter: 1897 loss: 4.35135371e-06
Iter: 1898 loss: 4.35007132e-06
Iter: 1899 loss: 4.35001857e-06
Iter: 1900 loss: 4.34858157e-06
Iter: 1901 loss: 4.3512764e-06
Iter: 1902 loss: 4.34791673e-06
Iter: 1903 loss: 4.3468317e-06
Iter: 1904 loss: 4.34462709e-06
Iter: 1905 loss: 4.38827692e-06
Iter: 1906 loss: 4.34458116e-06
Iter: 1907 loss: 4.34184403e-06
Iter: 1908 loss: 4.34715867e-06
Iter: 1909 loss: 4.34077538e-06
Iter: 1910 loss: 4.33875493e-06
Iter: 1911 loss: 4.33874629e-06
Iter: 1912 loss: 4.33718697e-06
Iter: 1913 loss: 4.34750109e-06
Iter: 1914 loss: 4.33700461e-06
Iter: 1915 loss: 4.33558307e-06
Iter: 1916 loss: 4.33730293e-06
Iter: 1917 loss: 4.33482728e-06
Iter: 1918 loss: 4.33355399e-06
Iter: 1919 loss: 4.33597779e-06
Iter: 1920 loss: 4.33295372e-06
Iter: 1921 loss: 4.33092464e-06
Iter: 1922 loss: 4.33519381e-06
Iter: 1923 loss: 4.33007563e-06
Iter: 1924 loss: 4.32894421e-06
Iter: 1925 loss: 4.3262221e-06
Iter: 1926 loss: 4.36169103e-06
Iter: 1927 loss: 4.326007e-06
Iter: 1928 loss: 4.32563502e-06
Iter: 1929 loss: 4.32458455e-06
Iter: 1930 loss: 4.3233631e-06
Iter: 1931 loss: 4.32134448e-06
Iter: 1932 loss: 4.32131583e-06
Iter: 1933 loss: 4.31961053e-06
Iter: 1934 loss: 4.32007482e-06
Iter: 1935 loss: 4.31835088e-06
Iter: 1936 loss: 4.31680382e-06
Iter: 1937 loss: 4.316581e-06
Iter: 1938 loss: 4.31564058e-06
Iter: 1939 loss: 4.3132477e-06
Iter: 1940 loss: 4.33563355e-06
Iter: 1941 loss: 4.31293211e-06
Iter: 1942 loss: 4.30993441e-06
Iter: 1943 loss: 4.31795252e-06
Iter: 1944 loss: 4.3089276e-06
Iter: 1945 loss: 4.30805176e-06
Iter: 1946 loss: 4.30751606e-06
Iter: 1947 loss: 4.30642194e-06
Iter: 1948 loss: 4.30695582e-06
Iter: 1949 loss: 4.30578893e-06
Iter: 1950 loss: 4.30432e-06
Iter: 1951 loss: 4.30557066e-06
Iter: 1952 loss: 4.3035343e-06
Iter: 1953 loss: 4.30264754e-06
Iter: 1954 loss: 4.30263663e-06
Iter: 1955 loss: 4.3019586e-06
Iter: 1956 loss: 4.30003047e-06
Iter: 1957 loss: 4.30801538e-06
Iter: 1958 loss: 4.29926422e-06
Iter: 1959 loss: 4.29702322e-06
Iter: 1960 loss: 4.31257e-06
Iter: 1961 loss: 4.29677584e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8
+ date
Mon Oct 26 09:30:58 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc7a5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc7e5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc7e5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc7e5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0700c8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc75aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc75ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc6d07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc6d4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc695378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc6d0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc6697b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc656d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc607e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc5ed8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc5abd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc5b2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc5b2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc54c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc54cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc50a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc50ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc47a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc4b8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc4b8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc46fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc400048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc3dd268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc3ddae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc3d8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc3d86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc368730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc3552f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc355d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc337598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ffc2d96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.36401026e-05
Iter: 2 loss: 3.27208909e-05
Iter: 3 loss: 3.15441575e-05
Iter: 4 loss: 3.08767339e-05
Iter: 5 loss: 3.02201988e-05
Iter: 6 loss: 3.00793126e-05
Iter: 7 loss: 2.95932514e-05
Iter: 8 loss: 3.54255717e-05
Iter: 9 loss: 2.95871359e-05
Iter: 10 loss: 2.91584402e-05
Iter: 11 loss: 2.95738046e-05
Iter: 12 loss: 2.89141608e-05
Iter: 13 loss: 2.84637572e-05
Iter: 14 loss: 2.86354916e-05
Iter: 15 loss: 2.81506764e-05
Iter: 16 loss: 2.76855153e-05
Iter: 17 loss: 2.97997867e-05
Iter: 18 loss: 2.7596052e-05
Iter: 19 loss: 2.71163444e-05
Iter: 20 loss: 2.99810326e-05
Iter: 21 loss: 2.70553e-05
Iter: 22 loss: 2.67064e-05
Iter: 23 loss: 2.60303423e-05
Iter: 24 loss: 4.00248355e-05
Iter: 25 loss: 2.60258767e-05
Iter: 26 loss: 2.62348931e-05
Iter: 27 loss: 2.57869215e-05
Iter: 28 loss: 2.56309577e-05
Iter: 29 loss: 2.52752179e-05
Iter: 30 loss: 2.99337116e-05
Iter: 31 loss: 2.52522477e-05
Iter: 32 loss: 2.48929282e-05
Iter: 33 loss: 2.46532345e-05
Iter: 34 loss: 2.45188239e-05
Iter: 35 loss: 2.40564659e-05
Iter: 36 loss: 2.85475762e-05
Iter: 37 loss: 2.4039713e-05
Iter: 38 loss: 2.36350788e-05
Iter: 39 loss: 2.37364184e-05
Iter: 40 loss: 2.3339473e-05
Iter: 41 loss: 2.35757943e-05
Iter: 42 loss: 2.31472659e-05
Iter: 43 loss: 2.30422665e-05
Iter: 44 loss: 2.27872242e-05
Iter: 45 loss: 2.544983e-05
Iter: 46 loss: 2.27578494e-05
Iter: 47 loss: 2.25195381e-05
Iter: 48 loss: 2.45816882e-05
Iter: 49 loss: 2.25068106e-05
Iter: 50 loss: 2.23301267e-05
Iter: 51 loss: 2.31950253e-05
Iter: 52 loss: 2.22994458e-05
Iter: 53 loss: 2.2180051e-05
Iter: 54 loss: 2.20722195e-05
Iter: 55 loss: 2.20423281e-05
Iter: 56 loss: 2.18449914e-05
Iter: 57 loss: 2.23848401e-05
Iter: 58 loss: 2.17806e-05
Iter: 59 loss: 2.15602504e-05
Iter: 60 loss: 2.16700209e-05
Iter: 61 loss: 2.14131323e-05
Iter: 62 loss: 2.11441693e-05
Iter: 63 loss: 2.13945568e-05
Iter: 64 loss: 2.09890968e-05
Iter: 65 loss: 2.08776473e-05
Iter: 66 loss: 2.08347283e-05
Iter: 67 loss: 2.06972582e-05
Iter: 68 loss: 2.06308141e-05
Iter: 69 loss: 2.05645156e-05
Iter: 70 loss: 2.04448752e-05
Iter: 71 loss: 2.03332056e-05
Iter: 72 loss: 2.03050022e-05
Iter: 73 loss: 2.01217372e-05
Iter: 74 loss: 2.0855663e-05
Iter: 75 loss: 2.00805553e-05
Iter: 76 loss: 1.99128e-05
Iter: 77 loss: 2.03302079e-05
Iter: 78 loss: 1.985368e-05
Iter: 79 loss: 1.98415928e-05
Iter: 80 loss: 1.97717218e-05
Iter: 81 loss: 1.97139252e-05
Iter: 82 loss: 1.95613939e-05
Iter: 83 loss: 2.07089925e-05
Iter: 84 loss: 1.9530451e-05
Iter: 85 loss: 1.94570475e-05
Iter: 86 loss: 1.94525892e-05
Iter: 87 loss: 1.93626529e-05
Iter: 88 loss: 1.93646811e-05
Iter: 89 loss: 1.92914413e-05
Iter: 90 loss: 1.91962681e-05
Iter: 91 loss: 1.91240833e-05
Iter: 92 loss: 1.90930568e-05
Iter: 93 loss: 1.90165101e-05
Iter: 94 loss: 1.90018472e-05
Iter: 95 loss: 1.89352213e-05
Iter: 96 loss: 1.87844053e-05
Iter: 97 loss: 2.08175334e-05
Iter: 98 loss: 1.87754922e-05
Iter: 99 loss: 1.85946301e-05
Iter: 100 loss: 1.95849061e-05
Iter: 101 loss: 1.8568322e-05
Iter: 102 loss: 1.84363071e-05
Iter: 103 loss: 1.92365114e-05
Iter: 104 loss: 1.84201344e-05
Iter: 105 loss: 1.83113279e-05
Iter: 106 loss: 1.92244697e-05
Iter: 107 loss: 1.83050215e-05
Iter: 108 loss: 1.8253073e-05
Iter: 109 loss: 1.81655414e-05
Iter: 110 loss: 1.81652103e-05
Iter: 111 loss: 1.80587049e-05
Iter: 112 loss: 1.80827919e-05
Iter: 113 loss: 1.79806339e-05
Iter: 114 loss: 1.78747523e-05
Iter: 115 loss: 1.95579451e-05
Iter: 116 loss: 1.78748178e-05
Iter: 117 loss: 1.775903e-05
Iter: 118 loss: 1.81646865e-05
Iter: 119 loss: 1.77290276e-05
Iter: 120 loss: 1.7665112e-05
Iter: 121 loss: 1.75385121e-05
Iter: 122 loss: 1.99993246e-05
Iter: 123 loss: 1.75371479e-05
Iter: 124 loss: 1.75088135e-05
Iter: 125 loss: 1.74607612e-05
Iter: 126 loss: 1.74271954e-05
Iter: 127 loss: 1.73498283e-05
Iter: 128 loss: 1.83187331e-05
Iter: 129 loss: 1.73440167e-05
Iter: 130 loss: 1.72785149e-05
Iter: 131 loss: 1.81388295e-05
Iter: 132 loss: 1.72781347e-05
Iter: 133 loss: 1.72067739e-05
Iter: 134 loss: 1.72220698e-05
Iter: 135 loss: 1.71540396e-05
Iter: 136 loss: 1.70796484e-05
Iter: 137 loss: 1.70035346e-05
Iter: 138 loss: 1.69892082e-05
Iter: 139 loss: 1.6893493e-05
Iter: 140 loss: 1.68928345e-05
Iter: 141 loss: 1.68261431e-05
Iter: 142 loss: 1.71305037e-05
Iter: 143 loss: 1.68134848e-05
Iter: 144 loss: 1.67508915e-05
Iter: 145 loss: 1.66746486e-05
Iter: 146 loss: 1.66674945e-05
Iter: 147 loss: 1.6595528e-05
Iter: 148 loss: 1.6739581e-05
Iter: 149 loss: 1.65663e-05
Iter: 150 loss: 1.64952271e-05
Iter: 151 loss: 1.67955859e-05
Iter: 152 loss: 1.64802077e-05
Iter: 153 loss: 1.64052035e-05
Iter: 154 loss: 1.73019762e-05
Iter: 155 loss: 1.64041157e-05
Iter: 156 loss: 1.63663044e-05
Iter: 157 loss: 1.628461e-05
Iter: 158 loss: 1.75468085e-05
Iter: 159 loss: 1.6281494e-05
Iter: 160 loss: 1.62471042e-05
Iter: 161 loss: 1.62351462e-05
Iter: 162 loss: 1.61893386e-05
Iter: 163 loss: 1.60826567e-05
Iter: 164 loss: 1.73729131e-05
Iter: 165 loss: 1.60738855e-05
Iter: 166 loss: 1.60107575e-05
Iter: 167 loss: 1.67375492e-05
Iter: 168 loss: 1.60098334e-05
Iter: 169 loss: 1.59497031e-05
Iter: 170 loss: 1.62657489e-05
Iter: 171 loss: 1.59403589e-05
Iter: 172 loss: 1.59051106e-05
Iter: 173 loss: 1.58502698e-05
Iter: 174 loss: 1.58494313e-05
Iter: 175 loss: 1.57848608e-05
Iter: 176 loss: 1.64457906e-05
Iter: 177 loss: 1.57828545e-05
Iter: 178 loss: 1.57155555e-05
Iter: 179 loss: 1.57885206e-05
Iter: 180 loss: 1.56787537e-05
Iter: 181 loss: 1.56219103e-05
Iter: 182 loss: 1.58005478e-05
Iter: 183 loss: 1.56054612e-05
Iter: 184 loss: 1.55526814e-05
Iter: 185 loss: 1.54699956e-05
Iter: 186 loss: 1.5469037e-05
Iter: 187 loss: 1.54162753e-05
Iter: 188 loss: 1.54152258e-05
Iter: 189 loss: 1.53753099e-05
Iter: 190 loss: 1.59157935e-05
Iter: 191 loss: 1.53750316e-05
Iter: 192 loss: 1.53547553e-05
Iter: 193 loss: 1.52998364e-05
Iter: 194 loss: 1.56752685e-05
Iter: 195 loss: 1.52873326e-05
Iter: 196 loss: 1.5251665e-05
Iter: 197 loss: 1.52453149e-05
Iter: 198 loss: 1.52030934e-05
Iter: 199 loss: 1.51304293e-05
Iter: 200 loss: 1.51303657e-05
Iter: 201 loss: 1.50691994e-05
Iter: 202 loss: 1.51520471e-05
Iter: 203 loss: 1.50384885e-05
Iter: 204 loss: 1.49728694e-05
Iter: 205 loss: 1.49727102e-05
Iter: 206 loss: 1.49464668e-05
Iter: 207 loss: 1.49035923e-05
Iter: 208 loss: 1.49033431e-05
Iter: 209 loss: 1.48824829e-05
Iter: 210 loss: 1.48776962e-05
Iter: 211 loss: 1.48540421e-05
Iter: 212 loss: 1.48092986e-05
Iter: 213 loss: 1.57974027e-05
Iter: 214 loss: 1.48091049e-05
Iter: 215 loss: 1.47521569e-05
Iter: 216 loss: 1.49173411e-05
Iter: 217 loss: 1.4734569e-05
Iter: 218 loss: 1.4680023e-05
Iter: 219 loss: 1.47118963e-05
Iter: 220 loss: 1.46449438e-05
Iter: 221 loss: 1.45803497e-05
Iter: 222 loss: 1.47661012e-05
Iter: 223 loss: 1.45599643e-05
Iter: 224 loss: 1.45570611e-05
Iter: 225 loss: 1.45318772e-05
Iter: 226 loss: 1.45159584e-05
Iter: 227 loss: 1.44724436e-05
Iter: 228 loss: 1.47358614e-05
Iter: 229 loss: 1.44604974e-05
Iter: 230 loss: 1.44389141e-05
Iter: 231 loss: 1.44347132e-05
Iter: 232 loss: 1.44063379e-05
Iter: 233 loss: 1.43702227e-05
Iter: 234 loss: 1.4367628e-05
Iter: 235 loss: 1.4316518e-05
Iter: 236 loss: 1.42569315e-05
Iter: 237 loss: 1.42500903e-05
Iter: 238 loss: 1.4250556e-05
Iter: 239 loss: 1.42123044e-05
Iter: 240 loss: 1.41872297e-05
Iter: 241 loss: 1.41304954e-05
Iter: 242 loss: 1.48746904e-05
Iter: 243 loss: 1.41268238e-05
Iter: 244 loss: 1.40935881e-05
Iter: 245 loss: 1.40916554e-05
Iter: 246 loss: 1.40576285e-05
Iter: 247 loss: 1.40669599e-05
Iter: 248 loss: 1.40330958e-05
Iter: 249 loss: 1.40023039e-05
Iter: 250 loss: 1.39978511e-05
Iter: 251 loss: 1.39761687e-05
Iter: 252 loss: 1.39246e-05
Iter: 253 loss: 1.40634302e-05
Iter: 254 loss: 1.39075137e-05
Iter: 255 loss: 1.38561663e-05
Iter: 256 loss: 1.38792102e-05
Iter: 257 loss: 1.38213964e-05
Iter: 258 loss: 1.37939287e-05
Iter: 259 loss: 1.37905918e-05
Iter: 260 loss: 1.37560655e-05
Iter: 261 loss: 1.37772486e-05
Iter: 262 loss: 1.37341021e-05
Iter: 263 loss: 1.37077677e-05
Iter: 264 loss: 1.36737381e-05
Iter: 265 loss: 1.36714225e-05
Iter: 266 loss: 1.36398467e-05
Iter: 267 loss: 1.36361214e-05
Iter: 268 loss: 1.361868e-05
Iter: 269 loss: 1.35767459e-05
Iter: 270 loss: 1.40268658e-05
Iter: 271 loss: 1.35722903e-05
Iter: 272 loss: 1.35232494e-05
Iter: 273 loss: 1.38224132e-05
Iter: 274 loss: 1.35172822e-05
Iter: 275 loss: 1.34560123e-05
Iter: 276 loss: 1.35965947e-05
Iter: 277 loss: 1.34331704e-05
Iter: 278 loss: 1.34028869e-05
Iter: 279 loss: 1.34377224e-05
Iter: 280 loss: 1.33867625e-05
Iter: 281 loss: 1.33456624e-05
Iter: 282 loss: 1.36686895e-05
Iter: 283 loss: 1.33428784e-05
Iter: 284 loss: 1.33237527e-05
Iter: 285 loss: 1.32861551e-05
Iter: 286 loss: 1.40313741e-05
Iter: 287 loss: 1.32859486e-05
Iter: 288 loss: 1.32456535e-05
Iter: 289 loss: 1.35437058e-05
Iter: 290 loss: 1.32423556e-05
Iter: 291 loss: 1.32078167e-05
Iter: 292 loss: 1.32500036e-05
Iter: 293 loss: 1.31899305e-05
Iter: 294 loss: 1.31556608e-05
Iter: 295 loss: 1.36054405e-05
Iter: 296 loss: 1.31554825e-05
Iter: 297 loss: 1.31196612e-05
Iter: 298 loss: 1.31090146e-05
Iter: 299 loss: 1.30876497e-05
Iter: 300 loss: 1.30600138e-05
Iter: 301 loss: 1.30811568e-05
Iter: 302 loss: 1.30433391e-05
Iter: 303 loss: 1.30086974e-05
Iter: 304 loss: 1.34751845e-05
Iter: 305 loss: 1.30085191e-05
Iter: 306 loss: 1.299209e-05
Iter: 307 loss: 1.29573918e-05
Iter: 308 loss: 1.35302753e-05
Iter: 309 loss: 1.29564287e-05
Iter: 310 loss: 1.29414138e-05
Iter: 311 loss: 1.29381124e-05
Iter: 312 loss: 1.29187229e-05
Iter: 313 loss: 1.28875517e-05
Iter: 314 loss: 1.28874708e-05
Iter: 315 loss: 1.28511374e-05
Iter: 316 loss: 1.29730906e-05
Iter: 317 loss: 1.28415268e-05
Iter: 318 loss: 1.27968015e-05
Iter: 319 loss: 1.30214994e-05
Iter: 320 loss: 1.27893272e-05
Iter: 321 loss: 1.27664525e-05
Iter: 322 loss: 1.27226131e-05
Iter: 323 loss: 1.36471299e-05
Iter: 324 loss: 1.27223939e-05
Iter: 325 loss: 1.26881559e-05
Iter: 326 loss: 1.30928074e-05
Iter: 327 loss: 1.26876939e-05
Iter: 328 loss: 1.26571849e-05
Iter: 329 loss: 1.27450912e-05
Iter: 330 loss: 1.26475788e-05
Iter: 331 loss: 1.26200293e-05
Iter: 332 loss: 1.300847e-05
Iter: 333 loss: 1.26199839e-05
Iter: 334 loss: 1.26035175e-05
Iter: 335 loss: 1.25677434e-05
Iter: 336 loss: 1.311089e-05
Iter: 337 loss: 1.25664719e-05
Iter: 338 loss: 1.25354891e-05
Iter: 339 loss: 1.29654945e-05
Iter: 340 loss: 1.25353454e-05
Iter: 341 loss: 1.25021434e-05
Iter: 342 loss: 1.25121387e-05
Iter: 343 loss: 1.24783492e-05
Iter: 344 loss: 1.24508333e-05
Iter: 345 loss: 1.24448015e-05
Iter: 346 loss: 1.24266571e-05
Iter: 347 loss: 1.24147537e-05
Iter: 348 loss: 1.2407053e-05
Iter: 349 loss: 1.2396129e-05
Iter: 350 loss: 1.23705431e-05
Iter: 351 loss: 1.26877367e-05
Iter: 352 loss: 1.23686823e-05
Iter: 353 loss: 1.23491973e-05
Iter: 354 loss: 1.23483969e-05
Iter: 355 loss: 1.23302743e-05
Iter: 356 loss: 1.23002364e-05
Iter: 357 loss: 1.23000636e-05
Iter: 358 loss: 1.22681222e-05
Iter: 359 loss: 1.22687479e-05
Iter: 360 loss: 1.22428391e-05
Iter: 361 loss: 1.21996136e-05
Iter: 362 loss: 1.25193328e-05
Iter: 363 loss: 1.21961339e-05
Iter: 364 loss: 1.21742069e-05
Iter: 365 loss: 1.21738258e-05
Iter: 366 loss: 1.215665e-05
Iter: 367 loss: 1.21832645e-05
Iter: 368 loss: 1.21485482e-05
Iter: 369 loss: 1.21356861e-05
Iter: 370 loss: 1.21131416e-05
Iter: 371 loss: 1.21132e-05
Iter: 372 loss: 1.20904451e-05
Iter: 373 loss: 1.20898958e-05
Iter: 374 loss: 1.20765708e-05
Iter: 375 loss: 1.20500918e-05
Iter: 376 loss: 1.25580718e-05
Iter: 377 loss: 1.20496843e-05
Iter: 378 loss: 1.20221139e-05
Iter: 379 loss: 1.21897265e-05
Iter: 380 loss: 1.20187742e-05
Iter: 381 loss: 1.19859169e-05
Iter: 382 loss: 1.20685108e-05
Iter: 383 loss: 1.19743063e-05
Iter: 384 loss: 1.19525903e-05
Iter: 385 loss: 1.1959829e-05
Iter: 386 loss: 1.19372035e-05
Iter: 387 loss: 1.19069764e-05
Iter: 388 loss: 1.22115889e-05
Iter: 389 loss: 1.19058786e-05
Iter: 390 loss: 1.1893012e-05
Iter: 391 loss: 1.18694825e-05
Iter: 392 loss: 1.24141297e-05
Iter: 393 loss: 1.18694934e-05
Iter: 394 loss: 1.18435728e-05
Iter: 395 loss: 1.19525757e-05
Iter: 396 loss: 1.18380358e-05
Iter: 397 loss: 1.1817132e-05
Iter: 398 loss: 1.19996057e-05
Iter: 399 loss: 1.18159433e-05
Iter: 400 loss: 1.17960071e-05
Iter: 401 loss: 1.18929202e-05
Iter: 402 loss: 1.17925483e-05
Iter: 403 loss: 1.17738127e-05
Iter: 404 loss: 1.1742728e-05
Iter: 405 loss: 1.1742658e-05
Iter: 406 loss: 1.17209456e-05
Iter: 407 loss: 1.17208065e-05
Iter: 408 loss: 1.16983374e-05
Iter: 409 loss: 1.16963329e-05
Iter: 410 loss: 1.16798838e-05
Iter: 411 loss: 1.1662557e-05
Iter: 412 loss: 1.16906622e-05
Iter: 413 loss: 1.1654578e-05
Iter: 414 loss: 1.16394913e-05
Iter: 415 loss: 1.16394e-05
Iter: 416 loss: 1.16273504e-05
Iter: 417 loss: 1.16033489e-05
Iter: 418 loss: 1.20692248e-05
Iter: 419 loss: 1.16032079e-05
Iter: 420 loss: 1.15897601e-05
Iter: 421 loss: 1.15879257e-05
Iter: 422 loss: 1.15744542e-05
Iter: 423 loss: 1.15477769e-05
Iter: 424 loss: 1.20727709e-05
Iter: 425 loss: 1.15476014e-05
Iter: 426 loss: 1.15165985e-05
Iter: 427 loss: 1.15006696e-05
Iter: 428 loss: 1.14863451e-05
Iter: 429 loss: 1.14622962e-05
Iter: 430 loss: 1.14600398e-05
Iter: 431 loss: 1.14460563e-05
Iter: 432 loss: 1.14460072e-05
Iter: 433 loss: 1.14349468e-05
Iter: 434 loss: 1.14208524e-05
Iter: 435 loss: 1.14198592e-05
Iter: 436 loss: 1.14015511e-05
Iter: 437 loss: 1.14437862e-05
Iter: 438 loss: 1.13948699e-05
Iter: 439 loss: 1.13783171e-05
Iter: 440 loss: 1.16053652e-05
Iter: 441 loss: 1.13782708e-05
Iter: 442 loss: 1.13679798e-05
Iter: 443 loss: 1.13420538e-05
Iter: 444 loss: 1.15781977e-05
Iter: 445 loss: 1.13382084e-05
Iter: 446 loss: 1.13184169e-05
Iter: 447 loss: 1.13178658e-05
Iter: 448 loss: 1.12975658e-05
Iter: 449 loss: 1.13064707e-05
Iter: 450 loss: 1.1283496e-05
Iter: 451 loss: 1.12682419e-05
Iter: 452 loss: 1.13374463e-05
Iter: 453 loss: 1.12654079e-05
Iter: 454 loss: 1.12494454e-05
Iter: 455 loss: 1.13210817e-05
Iter: 456 loss: 1.12463595e-05
Iter: 457 loss: 1.12353764e-05
Iter: 458 loss: 1.12094149e-05
Iter: 459 loss: 1.15120802e-05
Iter: 460 loss: 1.12070265e-05
Iter: 461 loss: 1.11806939e-05
Iter: 462 loss: 1.13432725e-05
Iter: 463 loss: 1.11776308e-05
Iter: 464 loss: 1.11614681e-05
Iter: 465 loss: 1.11611616e-05
Iter: 466 loss: 1.11446634e-05
Iter: 467 loss: 1.11511781e-05
Iter: 468 loss: 1.11333393e-05
Iter: 469 loss: 1.11144009e-05
Iter: 470 loss: 1.11256031e-05
Iter: 471 loss: 1.11023219e-05
Iter: 472 loss: 1.10895026e-05
Iter: 473 loss: 1.10892615e-05
Iter: 474 loss: 1.10784222e-05
Iter: 475 loss: 1.10715146e-05
Iter: 476 loss: 1.10671745e-05
Iter: 477 loss: 1.10525434e-05
Iter: 478 loss: 1.10405954e-05
Iter: 479 loss: 1.10363053e-05
Iter: 480 loss: 1.10177871e-05
Iter: 481 loss: 1.10171168e-05
Iter: 482 loss: 1.10064138e-05
Iter: 483 loss: 1.09900702e-05
Iter: 484 loss: 1.09897901e-05
Iter: 485 loss: 1.09760031e-05
Iter: 486 loss: 1.09756629e-05
Iter: 487 loss: 1.09639877e-05
Iter: 488 loss: 1.09395114e-05
Iter: 489 loss: 1.1351889e-05
Iter: 490 loss: 1.09388875e-05
Iter: 491 loss: 1.0918171e-05
Iter: 492 loss: 1.09993962e-05
Iter: 493 loss: 1.09132716e-05
Iter: 494 loss: 1.08976474e-05
Iter: 495 loss: 1.09584544e-05
Iter: 496 loss: 1.08940294e-05
Iter: 497 loss: 1.08770682e-05
Iter: 498 loss: 1.10699739e-05
Iter: 499 loss: 1.08766926e-05
Iter: 500 loss: 1.08666027e-05
Iter: 501 loss: 1.08592176e-05
Iter: 502 loss: 1.08557779e-05
Iter: 503 loss: 1.08409249e-05
Iter: 504 loss: 1.08897239e-05
Iter: 505 loss: 1.08370577e-05
Iter: 506 loss: 1.08191525e-05
Iter: 507 loss: 1.08855547e-05
Iter: 508 loss: 1.08146869e-05
Iter: 509 loss: 1.08000459e-05
Iter: 510 loss: 1.07865399e-05
Iter: 511 loss: 1.07830356e-05
Iter: 512 loss: 1.07700307e-05
Iter: 513 loss: 1.07699798e-05
Iter: 514 loss: 1.07568922e-05
Iter: 515 loss: 1.07588048e-05
Iter: 516 loss: 1.07468204e-05
Iter: 517 loss: 1.07365895e-05
Iter: 518 loss: 1.07792857e-05
Iter: 519 loss: 1.07343567e-05
Iter: 520 loss: 1.07201095e-05
Iter: 521 loss: 1.07262504e-05
Iter: 522 loss: 1.0710356e-05
Iter: 523 loss: 1.06943135e-05
Iter: 524 loss: 1.06744474e-05
Iter: 525 loss: 1.06727266e-05
Iter: 526 loss: 1.06456209e-05
Iter: 527 loss: 1.07271808e-05
Iter: 528 loss: 1.06373991e-05
Iter: 529 loss: 1.06322659e-05
Iter: 530 loss: 1.06255929e-05
Iter: 531 loss: 1.061475e-05
Iter: 532 loss: 1.06058624e-05
Iter: 533 loss: 1.06026528e-05
Iter: 534 loss: 1.05903146e-05
Iter: 535 loss: 1.06379412e-05
Iter: 536 loss: 1.05873078e-05
Iter: 537 loss: 1.05774197e-05
Iter: 538 loss: 1.06601465e-05
Iter: 539 loss: 1.05769277e-05
Iter: 540 loss: 1.05676072e-05
Iter: 541 loss: 1.05550789e-05
Iter: 542 loss: 1.05543204e-05
Iter: 543 loss: 1.0536929e-05
Iter: 544 loss: 1.05507515e-05
Iter: 545 loss: 1.05264862e-05
Iter: 546 loss: 1.05078598e-05
Iter: 547 loss: 1.05078961e-05
Iter: 548 loss: 1.04974752e-05
Iter: 549 loss: 1.04842366e-05
Iter: 550 loss: 1.04832561e-05
Iter: 551 loss: 1.0474183e-05
Iter: 552 loss: 1.04730789e-05
Iter: 553 loss: 1.04658302e-05
Iter: 554 loss: 1.04497203e-05
Iter: 555 loss: 1.06884982e-05
Iter: 556 loss: 1.04491646e-05
Iter: 557 loss: 1.04338496e-05
Iter: 558 loss: 1.04572819e-05
Iter: 559 loss: 1.04266492e-05
Iter: 560 loss: 1.0408432e-05
Iter: 561 loss: 1.04863921e-05
Iter: 562 loss: 1.04047058e-05
Iter: 563 loss: 1.03845e-05
Iter: 564 loss: 1.05838772e-05
Iter: 565 loss: 1.03837601e-05
Iter: 566 loss: 1.03714938e-05
Iter: 567 loss: 1.03493967e-05
Iter: 568 loss: 1.08873282e-05
Iter: 569 loss: 1.03493894e-05
Iter: 570 loss: 1.03316415e-05
Iter: 571 loss: 1.03313832e-05
Iter: 572 loss: 1.03193543e-05
Iter: 573 loss: 1.03713637e-05
Iter: 574 loss: 1.0316855e-05
Iter: 575 loss: 1.03082957e-05
Iter: 576 loss: 1.02963177e-05
Iter: 577 loss: 1.02959157e-05
Iter: 578 loss: 1.02877511e-05
Iter: 579 loss: 1.02871836e-05
Iter: 580 loss: 1.0279542e-05
Iter: 581 loss: 1.02789745e-05
Iter: 582 loss: 1.02732884e-05
Iter: 583 loss: 1.02643407e-05
Iter: 584 loss: 1.02751237e-05
Iter: 585 loss: 1.02595495e-05
Iter: 586 loss: 1.02434533e-05
Iter: 587 loss: 1.02652257e-05
Iter: 588 loss: 1.02353788e-05
Iter: 589 loss: 1.02219155e-05
Iter: 590 loss: 1.02056929e-05
Iter: 591 loss: 1.02041586e-05
Iter: 592 loss: 1.01844726e-05
Iter: 593 loss: 1.02623353e-05
Iter: 594 loss: 1.01799851e-05
Iter: 595 loss: 1.0177866e-05
Iter: 596 loss: 1.01725172e-05
Iter: 597 loss: 1.01657279e-05
Iter: 598 loss: 1.01567703e-05
Iter: 599 loss: 1.01562382e-05
Iter: 600 loss: 1.01462956e-05
Iter: 601 loss: 1.01615351e-05
Iter: 602 loss: 1.01416426e-05
Iter: 603 loss: 1.01277365e-05
Iter: 604 loss: 1.02038457e-05
Iter: 605 loss: 1.01257801e-05
Iter: 606 loss: 1.01122023e-05
Iter: 607 loss: 1.01051128e-05
Iter: 608 loss: 1.00989009e-05
Iter: 609 loss: 1.00806155e-05
Iter: 610 loss: 1.01194364e-05
Iter: 611 loss: 1.0073416e-05
Iter: 612 loss: 1.00602338e-05
Iter: 613 loss: 1.00600437e-05
Iter: 614 loss: 1.00521283e-05
Iter: 615 loss: 1.00389225e-05
Iter: 616 loss: 1.00389261e-05
Iter: 617 loss: 1.00290799e-05
Iter: 618 loss: 1.00286525e-05
Iter: 619 loss: 1.00210345e-05
Iter: 620 loss: 1.00101133e-05
Iter: 621 loss: 1.00097e-05
Iter: 622 loss: 9.99734311e-06
Iter: 623 loss: 9.98732685e-06
Iter: 624 loss: 9.98354881e-06
Iter: 625 loss: 9.96362724e-06
Iter: 626 loss: 1.00842672e-05
Iter: 627 loss: 9.96106064e-06
Iter: 628 loss: 9.94329821e-06
Iter: 629 loss: 9.94335096e-06
Iter: 630 loss: 9.93586218e-06
Iter: 631 loss: 9.92528294e-06
Iter: 632 loss: 9.92487185e-06
Iter: 633 loss: 9.91615e-06
Iter: 634 loss: 9.91619527e-06
Iter: 635 loss: 9.90759327e-06
Iter: 636 loss: 9.9070694e-06
Iter: 637 loss: 9.90059652e-06
Iter: 638 loss: 9.88950887e-06
Iter: 639 loss: 9.9068975e-06
Iter: 640 loss: 9.88434113e-06
Iter: 641 loss: 9.87547719e-06
Iter: 642 loss: 9.94646871e-06
Iter: 643 loss: 9.87488238e-06
Iter: 644 loss: 9.86552368e-06
Iter: 645 loss: 9.87354e-06
Iter: 646 loss: 9.85997485e-06
Iter: 647 loss: 9.85028055e-06
Iter: 648 loss: 9.8505825e-06
Iter: 649 loss: 9.84259532e-06
Iter: 650 loss: 9.82424e-06
Iter: 651 loss: 9.90248918e-06
Iter: 652 loss: 9.82040729e-06
Iter: 653 loss: 9.80885306e-06
Iter: 654 loss: 9.797237e-06
Iter: 655 loss: 9.79477227e-06
Iter: 656 loss: 9.77936634e-06
Iter: 657 loss: 9.80800178e-06
Iter: 658 loss: 9.77278069e-06
Iter: 659 loss: 9.76752108e-06
Iter: 660 loss: 9.76468709e-06
Iter: 661 loss: 9.75586318e-06
Iter: 662 loss: 9.74525119e-06
Iter: 663 loss: 9.74427e-06
Iter: 664 loss: 9.73403621e-06
Iter: 665 loss: 9.74670183e-06
Iter: 666 loss: 9.72877388e-06
Iter: 667 loss: 9.7146185e-06
Iter: 668 loss: 9.82590882e-06
Iter: 669 loss: 9.71355075e-06
Iter: 670 loss: 9.70273322e-06
Iter: 671 loss: 9.70096698e-06
Iter: 672 loss: 9.69355642e-06
Iter: 673 loss: 9.68261e-06
Iter: 674 loss: 9.73678743e-06
Iter: 675 loss: 9.68073073e-06
Iter: 676 loss: 9.67184133e-06
Iter: 677 loss: 9.73932765e-06
Iter: 678 loss: 9.67125925e-06
Iter: 679 loss: 9.6630456e-06
Iter: 680 loss: 9.65229e-06
Iter: 681 loss: 9.6517042e-06
Iter: 682 loss: 9.64510218e-06
Iter: 683 loss: 9.64443825e-06
Iter: 684 loss: 9.63823e-06
Iter: 685 loss: 9.62503873e-06
Iter: 686 loss: 9.8546243e-06
Iter: 687 loss: 9.62471586e-06
Iter: 688 loss: 9.60881334e-06
Iter: 689 loss: 9.60830312e-06
Iter: 690 loss: 9.59585486e-06
Iter: 691 loss: 9.57777775e-06
Iter: 692 loss: 9.73147507e-06
Iter: 693 loss: 9.57673819e-06
Iter: 694 loss: 9.56654549e-06
Iter: 695 loss: 9.56582699e-06
Iter: 696 loss: 9.56086296e-06
Iter: 697 loss: 9.54918596e-06
Iter: 698 loss: 9.69211214e-06
Iter: 699 loss: 9.54833376e-06
Iter: 700 loss: 9.54141251e-06
Iter: 701 loss: 9.54116786e-06
Iter: 702 loss: 9.5337e-06
Iter: 703 loss: 9.52994833e-06
Iter: 704 loss: 9.52640221e-06
Iter: 705 loss: 9.51617585e-06
Iter: 706 loss: 9.52835217e-06
Iter: 707 loss: 9.51077345e-06
Iter: 708 loss: 9.49924197e-06
Iter: 709 loss: 9.56417352e-06
Iter: 710 loss: 9.49759396e-06
Iter: 711 loss: 9.48574143e-06
Iter: 712 loss: 9.51542097e-06
Iter: 713 loss: 9.48154866e-06
Iter: 714 loss: 9.47151693e-06
Iter: 715 loss: 9.47679837e-06
Iter: 716 loss: 9.4649431e-06
Iter: 717 loss: 9.45408829e-06
Iter: 718 loss: 9.60006e-06
Iter: 719 loss: 9.45414467e-06
Iter: 720 loss: 9.44839576e-06
Iter: 721 loss: 9.43717805e-06
Iter: 722 loss: 9.6739459e-06
Iter: 723 loss: 9.43714622e-06
Iter: 724 loss: 9.42443148e-06
Iter: 725 loss: 9.4241e-06
Iter: 726 loss: 9.41425242e-06
Iter: 727 loss: 9.40660721e-06
Iter: 728 loss: 9.40470909e-06
Iter: 729 loss: 9.39406527e-06
Iter: 730 loss: 9.40051268e-06
Iter: 731 loss: 9.38726589e-06
Iter: 732 loss: 9.3769122e-06
Iter: 733 loss: 9.35901699e-06
Iter: 734 loss: 9.35901e-06
Iter: 735 loss: 9.36277138e-06
Iter: 736 loss: 9.35111893e-06
Iter: 737 loss: 9.3464887e-06
Iter: 738 loss: 9.33905267e-06
Iter: 739 loss: 9.33896172e-06
Iter: 740 loss: 9.33139381e-06
Iter: 741 loss: 9.36805827e-06
Iter: 742 loss: 9.33006777e-06
Iter: 743 loss: 9.32313833e-06
Iter: 744 loss: 9.360896e-06
Iter: 745 loss: 9.32206422e-06
Iter: 746 loss: 9.31477553e-06
Iter: 747 loss: 9.31110571e-06
Iter: 748 loss: 9.30769056e-06
Iter: 749 loss: 9.29813086e-06
Iter: 750 loss: 9.34584386e-06
Iter: 751 loss: 9.29651469e-06
Iter: 752 loss: 9.28615373e-06
Iter: 753 loss: 9.31198883e-06
Iter: 754 loss: 9.28247391e-06
Iter: 755 loss: 9.27407e-06
Iter: 756 loss: 9.25738914e-06
Iter: 757 loss: 9.58363671e-06
Iter: 758 loss: 9.25718814e-06
Iter: 759 loss: 9.24199321e-06
Iter: 760 loss: 9.3578019e-06
Iter: 761 loss: 9.24084452e-06
Iter: 762 loss: 9.23734297e-06
Iter: 763 loss: 9.23593689e-06
Iter: 764 loss: 9.23040898e-06
Iter: 765 loss: 9.22148047e-06
Iter: 766 loss: 9.22149411e-06
Iter: 767 loss: 9.21286482e-06
Iter: 768 loss: 9.21166065e-06
Iter: 769 loss: 9.2057453e-06
Iter: 770 loss: 9.19636568e-06
Iter: 771 loss: 9.196061e-06
Iter: 772 loss: 9.18838487e-06
Iter: 773 loss: 9.17286707e-06
Iter: 774 loss: 9.45070133e-06
Iter: 775 loss: 9.17253055e-06
Iter: 776 loss: 9.16159843e-06
Iter: 777 loss: 9.31274462e-06
Iter: 778 loss: 9.16151839e-06
Iter: 779 loss: 9.15282e-06
Iter: 780 loss: 9.19404192e-06
Iter: 781 loss: 9.15126293e-06
Iter: 782 loss: 9.14464181e-06
Iter: 783 loss: 9.1581278e-06
Iter: 784 loss: 9.1419106e-06
Iter: 785 loss: 9.13649637e-06
Iter: 786 loss: 9.15253258e-06
Iter: 787 loss: 9.1347847e-06
Iter: 788 loss: 9.12710948e-06
Iter: 789 loss: 9.13078475e-06
Iter: 790 loss: 9.12212e-06
Iter: 791 loss: 9.11343159e-06
Iter: 792 loss: 9.10463677e-06
Iter: 793 loss: 9.10285598e-06
Iter: 794 loss: 9.08822403e-06
Iter: 795 loss: 9.10241943e-06
Iter: 796 loss: 9.07976664e-06
Iter: 797 loss: 9.07808771e-06
Iter: 798 loss: 9.07245521e-06
Iter: 799 loss: 9.06491186e-06
Iter: 800 loss: 9.05799061e-06
Iter: 801 loss: 9.0560452e-06
Iter: 802 loss: 9.04910667e-06
Iter: 803 loss: 9.05504567e-06
Iter: 804 loss: 9.04492208e-06
Iter: 805 loss: 9.04093758e-06
Iter: 806 loss: 9.0400481e-06
Iter: 807 loss: 9.03603905e-06
Iter: 808 loss: 9.02468582e-06
Iter: 809 loss: 9.09232585e-06
Iter: 810 loss: 9.02145075e-06
Iter: 811 loss: 9.0101139e-06
Iter: 812 loss: 9.15514192e-06
Iter: 813 loss: 9.01005842e-06
Iter: 814 loss: 9.00155919e-06
Iter: 815 loss: 9.06811692e-06
Iter: 816 loss: 9.00094165e-06
Iter: 817 loss: 8.99509723e-06
Iter: 818 loss: 8.99514635e-06
Iter: 819 loss: 8.99041879e-06
Iter: 820 loss: 8.98191774e-06
Iter: 821 loss: 9.00503437e-06
Iter: 822 loss: 8.97909922e-06
Iter: 823 loss: 8.96997517e-06
Iter: 824 loss: 9.02013653e-06
Iter: 825 loss: 8.96866186e-06
Iter: 826 loss: 8.96420352e-06
Iter: 827 loss: 8.95656e-06
Iter: 828 loss: 8.95650555e-06
Iter: 829 loss: 8.94507684e-06
Iter: 830 loss: 8.94499135e-06
Iter: 831 loss: 8.93583729e-06
Iter: 832 loss: 8.93134347e-06
Iter: 833 loss: 8.92827484e-06
Iter: 834 loss: 8.92008211e-06
Iter: 835 loss: 8.91814307e-06
Iter: 836 loss: 8.9130117e-06
Iter: 837 loss: 8.90617048e-06
Iter: 838 loss: 8.9006171e-06
Iter: 839 loss: 8.89868e-06
Iter: 840 loss: 8.89487274e-06
Iter: 841 loss: 8.89292551e-06
Iter: 842 loss: 8.88805152e-06
Iter: 843 loss: 8.8798588e-06
Iter: 844 loss: 8.87990245e-06
Iter: 845 loss: 8.87205715e-06
Iter: 846 loss: 8.88343584e-06
Iter: 847 loss: 8.86830185e-06
Iter: 848 loss: 8.85876943e-06
Iter: 849 loss: 8.96426263e-06
Iter: 850 loss: 8.8586221e-06
Iter: 851 loss: 8.85131521e-06
Iter: 852 loss: 8.85012e-06
Iter: 853 loss: 8.84518522e-06
Iter: 854 loss: 8.83608482e-06
Iter: 855 loss: 8.88082923e-06
Iter: 856 loss: 8.83449e-06
Iter: 857 loss: 8.82713903e-06
Iter: 858 loss: 8.8703664e-06
Iter: 859 loss: 8.82613676e-06
Iter: 860 loss: 8.82035692e-06
Iter: 861 loss: 8.81201686e-06
Iter: 862 loss: 8.81176129e-06
Iter: 863 loss: 8.80351217e-06
Iter: 864 loss: 8.82369568e-06
Iter: 865 loss: 8.80051e-06
Iter: 866 loss: 8.79258e-06
Iter: 867 loss: 8.81762389e-06
Iter: 868 loss: 8.79028266e-06
Iter: 869 loss: 8.78230458e-06
Iter: 870 loss: 8.7823737e-06
Iter: 871 loss: 8.77765524e-06
Iter: 872 loss: 8.76563536e-06
Iter: 873 loss: 8.87652459e-06
Iter: 874 loss: 8.76402373e-06
Iter: 875 loss: 8.75643764e-06
Iter: 876 loss: 8.7563858e-06
Iter: 877 loss: 8.74899251e-06
Iter: 878 loss: 8.782441e-06
Iter: 879 loss: 8.74762e-06
Iter: 880 loss: 8.74303441e-06
Iter: 881 loss: 8.73593672e-06
Iter: 882 loss: 8.73586941e-06
Iter: 883 loss: 8.73005592e-06
Iter: 884 loss: 8.73002591e-06
Iter: 885 loss: 8.72391593e-06
Iter: 886 loss: 8.72810051e-06
Iter: 887 loss: 8.72007604e-06
Iter: 888 loss: 8.71261091e-06
Iter: 889 loss: 8.7216722e-06
Iter: 890 loss: 8.70869189e-06
Iter: 891 loss: 8.69971882e-06
Iter: 892 loss: 8.7392591e-06
Iter: 893 loss: 8.69791165e-06
Iter: 894 loss: 8.68889492e-06
Iter: 895 loss: 8.70905387e-06
Iter: 896 loss: 8.68524694e-06
Iter: 897 loss: 8.679659e-06
Iter: 898 loss: 8.67822109e-06
Iter: 899 loss: 8.67470953e-06
Iter: 900 loss: 8.66706523e-06
Iter: 901 loss: 8.66999744e-06
Iter: 902 loss: 8.66180926e-06
Iter: 903 loss: 8.65934726e-06
Iter: 904 loss: 8.6573e-06
Iter: 905 loss: 8.65215588e-06
Iter: 906 loss: 8.64717094e-06
Iter: 907 loss: 8.64610229e-06
Iter: 908 loss: 8.6385262e-06
Iter: 909 loss: 8.62476645e-06
Iter: 910 loss: 8.93982724e-06
Iter: 911 loss: 8.62469278e-06
Iter: 912 loss: 8.62424531e-06
Iter: 913 loss: 8.61687386e-06
Iter: 914 loss: 8.61174613e-06
Iter: 915 loss: 8.60493674e-06
Iter: 916 loss: 8.60454747e-06
Iter: 917 loss: 8.59870852e-06
Iter: 918 loss: 8.61660646e-06
Iter: 919 loss: 8.59695e-06
Iter: 920 loss: 8.59062766e-06
Iter: 921 loss: 8.6487571e-06
Iter: 922 loss: 8.590363e-06
Iter: 923 loss: 8.58599378e-06
Iter: 924 loss: 8.58303611e-06
Iter: 925 loss: 8.58144267e-06
Iter: 926 loss: 8.57355e-06
Iter: 927 loss: 8.59976899e-06
Iter: 928 loss: 8.57131454e-06
Iter: 929 loss: 8.56284714e-06
Iter: 930 loss: 8.59190914e-06
Iter: 931 loss: 8.56057704e-06
Iter: 932 loss: 8.55313192e-06
Iter: 933 loss: 8.54415703e-06
Iter: 934 loss: 8.54325481e-06
Iter: 935 loss: 8.53350866e-06
Iter: 936 loss: 8.57925534e-06
Iter: 937 loss: 8.53174151e-06
Iter: 938 loss: 8.52823723e-06
Iter: 939 loss: 8.52785615e-06
Iter: 940 loss: 8.52334142e-06
Iter: 941 loss: 8.51824279e-06
Iter: 942 loss: 8.51747063e-06
Iter: 943 loss: 8.51095683e-06
Iter: 944 loss: 8.50635661e-06
Iter: 945 loss: 8.50400284e-06
Iter: 946 loss: 8.50083597e-06
Iter: 947 loss: 8.49862226e-06
Iter: 948 loss: 8.49440767e-06
Iter: 949 loss: 8.48462e-06
Iter: 950 loss: 8.60258478e-06
Iter: 951 loss: 8.48391664e-06
Iter: 952 loss: 8.47525826e-06
Iter: 953 loss: 8.5502752e-06
Iter: 954 loss: 8.4747644e-06
Iter: 955 loss: 8.46795228e-06
Iter: 956 loss: 8.53338861e-06
Iter: 957 loss: 8.4678195e-06
Iter: 958 loss: 8.46430157e-06
Iter: 959 loss: 8.462388e-06
Iter: 960 loss: 8.4608e-06
Iter: 961 loss: 8.45479735e-06
Iter: 962 loss: 8.48162472e-06
Iter: 963 loss: 8.45352952e-06
Iter: 964 loss: 8.44748502e-06
Iter: 965 loss: 8.45502291e-06
Iter: 966 loss: 8.44419e-06
Iter: 967 loss: 8.43694215e-06
Iter: 968 loss: 8.43140515e-06
Iter: 969 loss: 8.42910049e-06
Iter: 970 loss: 8.4198291e-06
Iter: 971 loss: 8.44295664e-06
Iter: 972 loss: 8.41653309e-06
Iter: 973 loss: 8.413e-06
Iter: 974 loss: 8.41168185e-06
Iter: 975 loss: 8.40677694e-06
Iter: 976 loss: 8.40141547e-06
Iter: 977 loss: 8.4006042e-06
Iter: 978 loss: 8.39634e-06
Iter: 979 loss: 8.40096345e-06
Iter: 980 loss: 8.39401e-06
Iter: 981 loss: 8.38914821e-06
Iter: 982 loss: 8.45972136e-06
Iter: 983 loss: 8.38915548e-06
Iter: 984 loss: 8.38535743e-06
Iter: 985 loss: 8.37649532e-06
Iter: 986 loss: 8.47332376e-06
Iter: 987 loss: 8.37552216e-06
Iter: 988 loss: 8.36837717e-06
Iter: 989 loss: 8.47745378e-06
Iter: 990 loss: 8.36833806e-06
Iter: 991 loss: 8.36118124e-06
Iter: 992 loss: 8.37806056e-06
Iter: 993 loss: 8.35839637e-06
Iter: 994 loss: 8.35308401e-06
Iter: 995 loss: 8.36160689e-06
Iter: 996 loss: 8.35068749e-06
Iter: 997 loss: 8.34511411e-06
Iter: 998 loss: 8.38757842e-06
Iter: 999 loss: 8.34469301e-06
Iter: 1000 loss: 8.3406685e-06
Iter: 1001 loss: 8.34276943e-06
Iter: 1002 loss: 8.33784907e-06
Iter: 1003 loss: 8.33272861e-06
Iter: 1004 loss: 8.33042941e-06
Iter: 1005 loss: 8.32779551e-06
Iter: 1006 loss: 8.32072419e-06
Iter: 1007 loss: 8.3262712e-06
Iter: 1008 loss: 8.31648867e-06
Iter: 1009 loss: 8.31254511e-06
Iter: 1010 loss: 8.31093712e-06
Iter: 1011 loss: 8.30660247e-06
Iter: 1012 loss: 8.29723376e-06
Iter: 1013 loss: 8.44614078e-06
Iter: 1014 loss: 8.29684268e-06
Iter: 1015 loss: 8.28969314e-06
Iter: 1016 loss: 8.32273145e-06
Iter: 1017 loss: 8.28830525e-06
Iter: 1018 loss: 8.28209886e-06
Iter: 1019 loss: 8.37907555e-06
Iter: 1020 loss: 8.28209886e-06
Iter: 1021 loss: 8.2793922e-06
Iter: 1022 loss: 8.27374424e-06
Iter: 1023 loss: 8.37073276e-06
Iter: 1024 loss: 8.27359872e-06
Iter: 1025 loss: 8.26922e-06
Iter: 1026 loss: 8.26920132e-06
Iter: 1027 loss: 8.26415635e-06
Iter: 1028 loss: 8.2618817e-06
Iter: 1029 loss: 8.25946e-06
Iter: 1030 loss: 8.25280586e-06
Iter: 1031 loss: 8.2662109e-06
Iter: 1032 loss: 8.25014467e-06
Iter: 1033 loss: 8.24190101e-06
Iter: 1034 loss: 8.28635439e-06
Iter: 1035 loss: 8.24070321e-06
Iter: 1036 loss: 8.23506161e-06
Iter: 1037 loss: 8.24281597e-06
Iter: 1038 loss: 8.23225491e-06
Iter: 1039 loss: 8.22641323e-06
Iter: 1040 loss: 8.22534821e-06
Iter: 1041 loss: 8.22136735e-06
Iter: 1042 loss: 8.21449612e-06
Iter: 1043 loss: 8.24504605e-06
Iter: 1044 loss: 8.21315734e-06
Iter: 1045 loss: 8.21097274e-06
Iter: 1046 loss: 8.20982132e-06
Iter: 1047 loss: 8.20781e-06
Iter: 1048 loss: 8.20191053e-06
Iter: 1049 loss: 8.22191487e-06
Iter: 1050 loss: 8.19920751e-06
Iter: 1051 loss: 8.19138586e-06
Iter: 1052 loss: 8.25789e-06
Iter: 1053 loss: 8.19091474e-06
Iter: 1054 loss: 8.18363333e-06
Iter: 1055 loss: 8.24282e-06
Iter: 1056 loss: 8.18319677e-06
Iter: 1057 loss: 8.17958062e-06
Iter: 1058 loss: 8.17208638e-06
Iter: 1059 loss: 8.29965393e-06
Iter: 1060 loss: 8.17182718e-06
Iter: 1061 loss: 8.16931333e-06
Iter: 1062 loss: 8.16791e-06
Iter: 1063 loss: 8.16436204e-06
Iter: 1064 loss: 8.16112788e-06
Iter: 1065 loss: 8.16023e-06
Iter: 1066 loss: 8.15602198e-06
Iter: 1067 loss: 8.18136141e-06
Iter: 1068 loss: 8.15541171e-06
Iter: 1069 loss: 8.15099e-06
Iter: 1070 loss: 8.15977364e-06
Iter: 1071 loss: 8.14924351e-06
Iter: 1072 loss: 8.14432133e-06
Iter: 1073 loss: 8.14081432e-06
Iter: 1074 loss: 8.13916267e-06
Iter: 1075 loss: 8.12957296e-06
Iter: 1076 loss: 8.13584393e-06
Iter: 1077 loss: 8.12348117e-06
Iter: 1078 loss: 8.11598147e-06
Iter: 1079 loss: 8.19195066e-06
Iter: 1080 loss: 8.11575592e-06
Iter: 1081 loss: 8.11028531e-06
Iter: 1082 loss: 8.18683384e-06
Iter: 1083 loss: 8.11020072e-06
Iter: 1084 loss: 8.10788697e-06
Iter: 1085 loss: 8.10215715e-06
Iter: 1086 loss: 8.16528063e-06
Iter: 1087 loss: 8.10152596e-06
Iter: 1088 loss: 8.0972377e-06
Iter: 1089 loss: 8.09725134e-06
Iter: 1090 loss: 8.09256107e-06
Iter: 1091 loss: 8.09453559e-06
Iter: 1092 loss: 8.08934783e-06
Iter: 1093 loss: 8.08492e-06
Iter: 1094 loss: 8.07966171e-06
Iter: 1095 loss: 8.07911601e-06
Iter: 1096 loss: 8.07340803e-06
Iter: 1097 loss: 8.07317701e-06
Iter: 1098 loss: 8.0681e-06
Iter: 1099 loss: 8.06085791e-06
Iter: 1100 loss: 8.0605987e-06
Iter: 1101 loss: 8.05767104e-06
Iter: 1102 loss: 8.05708896e-06
Iter: 1103 loss: 8.0543723e-06
Iter: 1104 loss: 8.05280342e-06
Iter: 1105 loss: 8.05165109e-06
Iter: 1106 loss: 8.04730826e-06
Iter: 1107 loss: 8.05009768e-06
Iter: 1108 loss: 8.0445061e-06
Iter: 1109 loss: 8.03886905e-06
Iter: 1110 loss: 8.04636511e-06
Iter: 1111 loss: 8.03607873e-06
Iter: 1112 loss: 8.03103831e-06
Iter: 1113 loss: 8.07770448e-06
Iter: 1114 loss: 8.03078e-06
Iter: 1115 loss: 8.02447e-06
Iter: 1116 loss: 8.02907743e-06
Iter: 1117 loss: 8.02050909e-06
Iter: 1118 loss: 8.01565238e-06
Iter: 1119 loss: 8.01155784e-06
Iter: 1120 loss: 8.01013448e-06
Iter: 1121 loss: 8.00784346e-06
Iter: 1122 loss: 8.00686576e-06
Iter: 1123 loss: 8.00347334e-06
Iter: 1124 loss: 7.99830286e-06
Iter: 1125 loss: 7.99819827e-06
Iter: 1126 loss: 7.99288e-06
Iter: 1127 loss: 7.99707323e-06
Iter: 1128 loss: 7.98959809e-06
Iter: 1129 loss: 7.98560177e-06
Iter: 1130 loss: 7.98517431e-06
Iter: 1131 loss: 7.98225847e-06
Iter: 1132 loss: 7.97630764e-06
Iter: 1133 loss: 8.08342702e-06
Iter: 1134 loss: 7.97625853e-06
Iter: 1135 loss: 7.97084613e-06
Iter: 1136 loss: 8.05490345e-06
Iter: 1137 loss: 7.9708625e-06
Iter: 1138 loss: 7.96590848e-06
Iter: 1139 loss: 7.96174e-06
Iter: 1140 loss: 7.96028235e-06
Iter: 1141 loss: 7.95509368e-06
Iter: 1142 loss: 7.99360168e-06
Iter: 1143 loss: 7.95467895e-06
Iter: 1144 loss: 7.95075e-06
Iter: 1145 loss: 7.94808875e-06
Iter: 1146 loss: 7.94676635e-06
Iter: 1147 loss: 7.94271364e-06
Iter: 1148 loss: 7.94261905e-06
Iter: 1149 loss: 7.9381407e-06
Iter: 1150 loss: 7.93703111e-06
Iter: 1151 loss: 7.93414802e-06
Iter: 1152 loss: 7.9294914e-06
Iter: 1153 loss: 7.92222545e-06
Iter: 1154 loss: 7.92209084e-06
Iter: 1155 loss: 7.91951243e-06
Iter: 1156 loss: 7.91717139e-06
Iter: 1157 loss: 7.91311049e-06
Iter: 1158 loss: 7.90555e-06
Iter: 1159 loss: 8.07259e-06
Iter: 1160 loss: 7.9055435e-06
Iter: 1161 loss: 7.89955629e-06
Iter: 1162 loss: 7.91792081e-06
Iter: 1163 loss: 7.89766364e-06
Iter: 1164 loss: 7.89652e-06
Iter: 1165 loss: 7.89533624e-06
Iter: 1166 loss: 7.89323894e-06
Iter: 1167 loss: 7.88792e-06
Iter: 1168 loss: 7.92862102e-06
Iter: 1169 loss: 7.88685247e-06
Iter: 1170 loss: 7.882516e-06
Iter: 1171 loss: 7.88244506e-06
Iter: 1172 loss: 7.87792669e-06
Iter: 1173 loss: 7.87845784e-06
Iter: 1174 loss: 7.87455792e-06
Iter: 1175 loss: 7.86904729e-06
Iter: 1176 loss: 7.86905548e-06
Iter: 1177 loss: 7.86475084e-06
Iter: 1178 loss: 7.85693919e-06
Iter: 1179 loss: 7.89351543e-06
Iter: 1180 loss: 7.85553675e-06
Iter: 1181 loss: 7.85188331e-06
Iter: 1182 loss: 7.907709e-06
Iter: 1183 loss: 7.85181874e-06
Iter: 1184 loss: 7.84803342e-06
Iter: 1185 loss: 7.84956501e-06
Iter: 1186 loss: 7.84537951e-06
Iter: 1187 loss: 7.84192525e-06
Iter: 1188 loss: 7.83675569e-06
Iter: 1189 loss: 7.83661926e-06
Iter: 1190 loss: 7.83244832e-06
Iter: 1191 loss: 7.83228097e-06
Iter: 1192 loss: 7.82729148e-06
Iter: 1193 loss: 7.82189181e-06
Iter: 1194 loss: 7.82108145e-06
Iter: 1195 loss: 7.81527069e-06
Iter: 1196 loss: 7.81324e-06
Iter: 1197 loss: 7.80988921e-06
Iter: 1198 loss: 7.8062285e-06
Iter: 1199 loss: 7.80509436e-06
Iter: 1200 loss: 7.80094251e-06
Iter: 1201 loss: 7.79787206e-06
Iter: 1202 loss: 7.79638503e-06
Iter: 1203 loss: 7.7927416e-06
Iter: 1204 loss: 7.80647133e-06
Iter: 1205 loss: 7.79197853e-06
Iter: 1206 loss: 7.78702088e-06
Iter: 1207 loss: 7.79765651e-06
Iter: 1208 loss: 7.78504545e-06
Iter: 1209 loss: 7.78080721e-06
Iter: 1210 loss: 7.77818514e-06
Iter: 1211 loss: 7.77644163e-06
Iter: 1212 loss: 7.76987781e-06
Iter: 1213 loss: 7.80068876e-06
Iter: 1214 loss: 7.76880461e-06
Iter: 1215 loss: 7.76349498e-06
Iter: 1216 loss: 7.78733556e-06
Iter: 1217 loss: 7.76242723e-06
Iter: 1218 loss: 7.75639819e-06
Iter: 1219 loss: 7.79064158e-06
Iter: 1220 loss: 7.75558e-06
Iter: 1221 loss: 7.75247736e-06
Iter: 1222 loss: 7.74688397e-06
Iter: 1223 loss: 7.74691216e-06
Iter: 1224 loss: 7.74281307e-06
Iter: 1225 loss: 7.78853519e-06
Iter: 1226 loss: 7.74269e-06
Iter: 1227 loss: 7.73799184e-06
Iter: 1228 loss: 7.75147146e-06
Iter: 1229 loss: 7.73656211e-06
Iter: 1230 loss: 7.7326531e-06
Iter: 1231 loss: 7.72421572e-06
Iter: 1232 loss: 7.85393604e-06
Iter: 1233 loss: 7.72388194e-06
Iter: 1234 loss: 7.71861687e-06
Iter: 1235 loss: 7.71853138e-06
Iter: 1236 loss: 7.71268788e-06
Iter: 1237 loss: 7.72378735e-06
Iter: 1238 loss: 7.71026771e-06
Iter: 1239 loss: 7.70582301e-06
Iter: 1240 loss: 7.70396e-06
Iter: 1241 loss: 7.7016266e-06
Iter: 1242 loss: 7.6995284e-06
Iter: 1243 loss: 7.69869166e-06
Iter: 1244 loss: 7.69642429e-06
Iter: 1245 loss: 7.69158214e-06
Iter: 1246 loss: 7.75778699e-06
Iter: 1247 loss: 7.691262e-06
Iter: 1248 loss: 7.6852175e-06
Iter: 1249 loss: 7.70116458e-06
Iter: 1250 loss: 7.68313294e-06
Iter: 1251 loss: 7.6763954e-06
Iter: 1252 loss: 7.69449252e-06
Iter: 1253 loss: 7.67410438e-06
Iter: 1254 loss: 7.66846642e-06
Iter: 1255 loss: 7.68727659e-06
Iter: 1256 loss: 7.66688754e-06
Iter: 1257 loss: 7.6632914e-06
Iter: 1258 loss: 7.66302855e-06
Iter: 1259 loss: 7.66061112e-06
Iter: 1260 loss: 7.65452751e-06
Iter: 1261 loss: 7.71306259e-06
Iter: 1262 loss: 7.65382811e-06
Iter: 1263 loss: 7.64913511e-06
Iter: 1264 loss: 7.68545942e-06
Iter: 1265 loss: 7.64881224e-06
Iter: 1266 loss: 7.64463857e-06
Iter: 1267 loss: 7.68722839e-06
Iter: 1268 loss: 7.64447e-06
Iter: 1269 loss: 7.6417009e-06
Iter: 1270 loss: 7.63413118e-06
Iter: 1271 loss: 7.68645532e-06
Iter: 1272 loss: 7.63242588e-06
Iter: 1273 loss: 7.62494437e-06
Iter: 1274 loss: 7.69353665e-06
Iter: 1275 loss: 7.62462105e-06
Iter: 1276 loss: 7.61922911e-06
Iter: 1277 loss: 7.70206e-06
Iter: 1278 loss: 7.61924184e-06
Iter: 1279 loss: 7.61589945e-06
Iter: 1280 loss: 7.61007504e-06
Iter: 1281 loss: 7.61008368e-06
Iter: 1282 loss: 7.60704e-06
Iter: 1283 loss: 7.6066367e-06
Iter: 1284 loss: 7.6036913e-06
Iter: 1285 loss: 7.60131752e-06
Iter: 1286 loss: 7.60042758e-06
Iter: 1287 loss: 7.59615432e-06
Iter: 1288 loss: 7.60312423e-06
Iter: 1289 loss: 7.59422892e-06
Iter: 1290 loss: 7.58837496e-06
Iter: 1291 loss: 7.58344322e-06
Iter: 1292 loss: 7.58172473e-06
Iter: 1293 loss: 7.57279213e-06
Iter: 1294 loss: 7.61950105e-06
Iter: 1295 loss: 7.57134057e-06
Iter: 1296 loss: 7.56858572e-06
Iter: 1297 loss: 7.56819736e-06
Iter: 1298 loss: 7.56452e-06
Iter: 1299 loss: 7.56145619e-06
Iter: 1300 loss: 7.560418e-06
Iter: 1301 loss: 7.55640031e-06
Iter: 1302 loss: 7.55515339e-06
Iter: 1303 loss: 7.55278597e-06
Iter: 1304 loss: 7.5508724e-06
Iter: 1305 loss: 7.54999382e-06
Iter: 1306 loss: 7.54723897e-06
Iter: 1307 loss: 7.5415669e-06
Iter: 1308 loss: 7.63986463e-06
Iter: 1309 loss: 7.54144821e-06
Iter: 1310 loss: 7.53537461e-06
Iter: 1311 loss: 7.53365293e-06
Iter: 1312 loss: 7.52978758e-06
Iter: 1313 loss: 7.52600545e-06
Iter: 1314 loss: 7.52460755e-06
Iter: 1315 loss: 7.52053165e-06
Iter: 1316 loss: 7.51848893e-06
Iter: 1317 loss: 7.51655625e-06
Iter: 1318 loss: 7.51232528e-06
Iter: 1319 loss: 7.5310445e-06
Iter: 1320 loss: 7.5115845e-06
Iter: 1321 loss: 7.50698655e-06
Iter: 1322 loss: 7.52649885e-06
Iter: 1323 loss: 7.5060475e-06
Iter: 1324 loss: 7.50212939e-06
Iter: 1325 loss: 7.5074031e-06
Iter: 1326 loss: 7.50017489e-06
Iter: 1327 loss: 7.49648598e-06
Iter: 1328 loss: 7.49220089e-06
Iter: 1329 loss: 7.49166702e-06
Iter: 1330 loss: 7.48397269e-06
Iter: 1331 loss: 7.49191122e-06
Iter: 1332 loss: 7.47975173e-06
Iter: 1333 loss: 7.47172453e-06
Iter: 1334 loss: 7.51043308e-06
Iter: 1335 loss: 7.47031027e-06
Iter: 1336 loss: 7.46818432e-06
Iter: 1337 loss: 7.46626847e-06
Iter: 1338 loss: 7.46408386e-06
Iter: 1339 loss: 7.45838224e-06
Iter: 1340 loss: 7.51858306e-06
Iter: 1341 loss: 7.45784655e-06
Iter: 1342 loss: 7.45264879e-06
Iter: 1343 loss: 7.48049615e-06
Iter: 1344 loss: 7.45190118e-06
Iter: 1345 loss: 7.44716272e-06
Iter: 1346 loss: 7.50201207e-06
Iter: 1347 loss: 7.44710724e-06
Iter: 1348 loss: 7.44469e-06
Iter: 1349 loss: 7.43915552e-06
Iter: 1350 loss: 7.5079879e-06
Iter: 1351 loss: 7.43865621e-06
Iter: 1352 loss: 7.43361534e-06
Iter: 1353 loss: 7.43359215e-06
Iter: 1354 loss: 7.42912653e-06
Iter: 1355 loss: 7.43569854e-06
Iter: 1356 loss: 7.42687462e-06
Iter: 1357 loss: 7.42321572e-06
Iter: 1358 loss: 7.43112423e-06
Iter: 1359 loss: 7.42174325e-06
Iter: 1360 loss: 7.41782878e-06
Iter: 1361 loss: 7.43238888e-06
Iter: 1362 loss: 7.41681561e-06
Iter: 1363 loss: 7.41233453e-06
Iter: 1364 loss: 7.4274385e-06
Iter: 1365 loss: 7.41109852e-06
Iter: 1366 loss: 7.4083e-06
Iter: 1367 loss: 7.40438281e-06
Iter: 1368 loss: 7.40417636e-06
Iter: 1369 loss: 7.39817369e-06
Iter: 1370 loss: 7.39880034e-06
Iter: 1371 loss: 7.3935571e-06
Iter: 1372 loss: 7.38513972e-06
Iter: 1373 loss: 7.40973974e-06
Iter: 1374 loss: 7.3825604e-06
Iter: 1375 loss: 7.38181916e-06
Iter: 1376 loss: 7.37907521e-06
Iter: 1377 loss: 7.37568462e-06
Iter: 1378 loss: 7.37289611e-06
Iter: 1379 loss: 7.37189202e-06
Iter: 1380 loss: 7.36852462e-06
Iter: 1381 loss: 7.36543188e-06
Iter: 1382 loss: 7.3645715e-06
Iter: 1383 loss: 7.36118182e-06
Iter: 1384 loss: 7.36118272e-06
Iter: 1385 loss: 7.35770209e-06
Iter: 1386 loss: 7.36239599e-06
Iter: 1387 loss: 7.35591766e-06
Iter: 1388 loss: 7.3523529e-06
Iter: 1389 loss: 7.354216e-06
Iter: 1390 loss: 7.35006824e-06
Iter: 1391 loss: 7.34469495e-06
Iter: 1392 loss: 7.36974334e-06
Iter: 1393 loss: 7.34371315e-06
Iter: 1394 loss: 7.33893512e-06
Iter: 1395 loss: 7.34713103e-06
Iter: 1396 loss: 7.33686829e-06
Iter: 1397 loss: 7.33298839e-06
Iter: 1398 loss: 7.3342444e-06
Iter: 1399 loss: 7.33022762e-06
Iter: 1400 loss: 7.32831631e-06
Iter: 1401 loss: 7.32779154e-06
Iter: 1402 loss: 7.32581884e-06
Iter: 1403 loss: 7.32167337e-06
Iter: 1404 loss: 7.39719144e-06
Iter: 1405 loss: 7.32161e-06
Iter: 1406 loss: 7.31717682e-06
Iter: 1407 loss: 7.31677301e-06
Iter: 1408 loss: 7.31348609e-06
Iter: 1409 loss: 7.30976717e-06
Iter: 1410 loss: 7.309593e-06
Iter: 1411 loss: 7.30474221e-06
Iter: 1412 loss: 7.30146e-06
Iter: 1413 loss: 7.29959766e-06
Iter: 1414 loss: 7.29474914e-06
Iter: 1415 loss: 7.29627e-06
Iter: 1416 loss: 7.29134763e-06
Iter: 1417 loss: 7.2869575e-06
Iter: 1418 loss: 7.29748808e-06
Iter: 1419 loss: 7.28535588e-06
Iter: 1420 loss: 7.28274426e-06
Iter: 1421 loss: 7.28239047e-06
Iter: 1422 loss: 7.2797975e-06
Iter: 1423 loss: 7.27617589e-06
Iter: 1424 loss: 7.27613542e-06
Iter: 1425 loss: 7.27217503e-06
Iter: 1426 loss: 7.30075726e-06
Iter: 1427 loss: 7.27190127e-06
Iter: 1428 loss: 7.26773169e-06
Iter: 1429 loss: 7.27151e-06
Iter: 1430 loss: 7.26547023e-06
Iter: 1431 loss: 7.2601847e-06
Iter: 1432 loss: 7.26572625e-06
Iter: 1433 loss: 7.25731661e-06
Iter: 1434 loss: 7.25264908e-06
Iter: 1435 loss: 7.27066799e-06
Iter: 1436 loss: 7.2515445e-06
Iter: 1437 loss: 7.24828e-06
Iter: 1438 loss: 7.24823258e-06
Iter: 1439 loss: 7.2464909e-06
Iter: 1440 loss: 7.24237179e-06
Iter: 1441 loss: 7.2859134e-06
Iter: 1442 loss: 7.24194933e-06
Iter: 1443 loss: 7.23635731e-06
Iter: 1444 loss: 7.23943231e-06
Iter: 1445 loss: 7.23270932e-06
Iter: 1446 loss: 7.22745153e-06
Iter: 1447 loss: 7.28864e-06
Iter: 1448 loss: 7.22746108e-06
Iter: 1449 loss: 7.22220739e-06
Iter: 1450 loss: 7.26080225e-06
Iter: 1451 loss: 7.22185177e-06
Iter: 1452 loss: 7.2188991e-06
Iter: 1453 loss: 7.21305059e-06
Iter: 1454 loss: 7.31166529e-06
Iter: 1455 loss: 7.2128546e-06
Iter: 1456 loss: 7.20735534e-06
Iter: 1457 loss: 7.22493905e-06
Iter: 1458 loss: 7.20579465e-06
Iter: 1459 loss: 7.2017956e-06
Iter: 1460 loss: 7.25130394e-06
Iter: 1461 loss: 7.20169828e-06
Iter: 1462 loss: 7.19794753e-06
Iter: 1463 loss: 7.21560582e-06
Iter: 1464 loss: 7.19733362e-06
Iter: 1465 loss: 7.19411128e-06
Iter: 1466 loss: 7.19606578e-06
Iter: 1467 loss: 7.19208219e-06
Iter: 1468 loss: 7.18856427e-06
Iter: 1469 loss: 7.20308071e-06
Iter: 1470 loss: 7.18777756e-06
Iter: 1471 loss: 7.18390129e-06
Iter: 1472 loss: 7.19338368e-06
Iter: 1473 loss: 7.18248384e-06
Iter: 1474 loss: 7.17879857e-06
Iter: 1475 loss: 7.17244575e-06
Iter: 1476 loss: 7.17245393e-06
Iter: 1477 loss: 7.16924342e-06
Iter: 1478 loss: 7.1689592e-06
Iter: 1479 loss: 7.16605155e-06
Iter: 1480 loss: 7.18163574e-06
Iter: 1481 loss: 7.16549221e-06
Iter: 1482 loss: 7.16357681e-06
Iter: 1483 loss: 7.15865826e-06
Iter: 1484 loss: 7.20098888e-06
Iter: 1485 loss: 7.1579052e-06
Iter: 1486 loss: 7.15453598e-06
Iter: 1487 loss: 7.1542795e-06
Iter: 1488 loss: 7.1500408e-06
Iter: 1489 loss: 7.15241777e-06
Iter: 1490 loss: 7.14732096e-06
Iter: 1491 loss: 7.14394901e-06
Iter: 1492 loss: 7.13919462e-06
Iter: 1493 loss: 7.13903319e-06
Iter: 1494 loss: 7.13277495e-06
Iter: 1495 loss: 7.15016085e-06
Iter: 1496 loss: 7.13070131e-06
Iter: 1497 loss: 7.12689916e-06
Iter: 1498 loss: 7.12693054e-06
Iter: 1499 loss: 7.12404744e-06
Iter: 1500 loss: 7.13666213e-06
Iter: 1501 loss: 7.12346355e-06
Iter: 1502 loss: 7.11998655e-06
Iter: 1503 loss: 7.12591191e-06
Iter: 1504 loss: 7.11842085e-06
Iter: 1505 loss: 7.11485518e-06
Iter: 1506 loss: 7.11079565e-06
Iter: 1507 loss: 7.11022858e-06
Iter: 1508 loss: 7.10703534e-06
Iter: 1509 loss: 7.10691438e-06
Iter: 1510 loss: 7.10364884e-06
Iter: 1511 loss: 7.10047971e-06
Iter: 1512 loss: 7.09982623e-06
Iter: 1513 loss: 7.09571577e-06
Iter: 1514 loss: 7.09858068e-06
Iter: 1515 loss: 7.09328378e-06
Iter: 1516 loss: 7.09220149e-06
Iter: 1517 loss: 7.09116648e-06
Iter: 1518 loss: 7.08928155e-06
Iter: 1519 loss: 7.08553125e-06
Iter: 1520 loss: 7.15030546e-06
Iter: 1521 loss: 7.08539301e-06
Iter: 1522 loss: 7.08246671e-06
Iter: 1523 loss: 7.12210067e-06
Iter: 1524 loss: 7.08246898e-06
Iter: 1525 loss: 7.07878098e-06
Iter: 1526 loss: 7.07334675e-06
Iter: 1527 loss: 7.07318577e-06
Iter: 1528 loss: 7.06841911e-06
Iter: 1529 loss: 7.07247364e-06
Iter: 1530 loss: 7.06555693e-06
Iter: 1531 loss: 7.06014771e-06
Iter: 1532 loss: 7.06519359e-06
Iter: 1533 loss: 7.05702587e-06
Iter: 1534 loss: 7.05252478e-06
Iter: 1535 loss: 7.05234e-06
Iter: 1536 loss: 7.05004049e-06
Iter: 1537 loss: 7.07123672e-06
Iter: 1538 loss: 7.04992772e-06
Iter: 1539 loss: 7.04765762e-06
Iter: 1540 loss: 7.04937247e-06
Iter: 1541 loss: 7.04622471e-06
Iter: 1542 loss: 7.04367085e-06
Iter: 1543 loss: 7.03872911e-06
Iter: 1544 loss: 7.14803627e-06
Iter: 1545 loss: 7.03867772e-06
Iter: 1546 loss: 7.03333444e-06
Iter: 1547 loss: 7.06841502e-06
Iter: 1548 loss: 7.03285787e-06
Iter: 1549 loss: 7.02864554e-06
Iter: 1550 loss: 7.09149936e-06
Iter: 1551 loss: 7.02864509e-06
Iter: 1552 loss: 7.02634907e-06
Iter: 1553 loss: 7.02182297e-06
Iter: 1554 loss: 7.11407074e-06
Iter: 1555 loss: 7.02180932e-06
Iter: 1556 loss: 7.02039597e-06
Iter: 1557 loss: 7.01939416e-06
Iter: 1558 loss: 7.01729277e-06
Iter: 1559 loss: 7.01366798e-06
Iter: 1560 loss: 7.0137512e-06
Iter: 1561 loss: 7.01135195e-06
Iter: 1562 loss: 7.01135195e-06
Iter: 1563 loss: 7.00886267e-06
Iter: 1564 loss: 7.00282453e-06
Iter: 1565 loss: 7.07107029e-06
Iter: 1566 loss: 7.00230521e-06
Iter: 1567 loss: 6.99661359e-06
Iter: 1568 loss: 7.01039835e-06
Iter: 1569 loss: 6.99455131e-06
Iter: 1570 loss: 6.98921576e-06
Iter: 1571 loss: 6.99921293e-06
Iter: 1572 loss: 6.98694e-06
Iter: 1573 loss: 6.98474e-06
Iter: 1574 loss: 6.98373651e-06
Iter: 1575 loss: 6.98127133e-06
Iter: 1576 loss: 6.97902396e-06
Iter: 1577 loss: 6.97843643e-06
Iter: 1578 loss: 6.97516043e-06
Iter: 1579 loss: 6.98378653e-06
Iter: 1580 loss: 6.97424321e-06
Iter: 1581 loss: 6.9706839e-06
Iter: 1582 loss: 6.9726475e-06
Iter: 1583 loss: 6.96854204e-06
Iter: 1584 loss: 6.96508596e-06
Iter: 1585 loss: 6.96509505e-06
Iter: 1586 loss: 6.96220786e-06
Iter: 1587 loss: 6.95850031e-06
Iter: 1588 loss: 6.95822473e-06
Iter: 1589 loss: 6.95514427e-06
Iter: 1590 loss: 7.003664e-06
Iter: 1591 loss: 6.95515155e-06
Iter: 1592 loss: 6.95172548e-06
Iter: 1593 loss: 6.94819209e-06
Iter: 1594 loss: 6.94750815e-06
Iter: 1595 loss: 6.94394885e-06
Iter: 1596 loss: 6.97643327e-06
Iter: 1597 loss: 6.94377422e-06
Iter: 1598 loss: 6.94035316e-06
Iter: 1599 loss: 6.94600385e-06
Iter: 1600 loss: 6.93868378e-06
Iter: 1601 loss: 6.93663196e-06
Iter: 1602 loss: 6.93243874e-06
Iter: 1603 loss: 7.00794772e-06
Iter: 1604 loss: 6.93228594e-06
Iter: 1605 loss: 6.92653612e-06
Iter: 1606 loss: 6.94001938e-06
Iter: 1607 loss: 6.9243215e-06
Iter: 1608 loss: 6.91946389e-06
Iter: 1609 loss: 6.97421501e-06
Iter: 1610 loss: 6.91942114e-06
Iter: 1611 loss: 6.9146331e-06
Iter: 1612 loss: 6.94243954e-06
Iter: 1613 loss: 6.91398736e-06
Iter: 1614 loss: 6.91131936e-06
Iter: 1615 loss: 6.90857723e-06
Iter: 1616 loss: 6.90806837e-06
Iter: 1617 loss: 6.90367324e-06
Iter: 1618 loss: 6.92285175e-06
Iter: 1619 loss: 6.90274646e-06
Iter: 1620 loss: 6.89943863e-06
Iter: 1621 loss: 6.9022235e-06
Iter: 1622 loss: 6.89751596e-06
Iter: 1623 loss: 6.8939753e-06
Iter: 1624 loss: 6.9228181e-06
Iter: 1625 loss: 6.89369608e-06
Iter: 1626 loss: 6.88936598e-06
Iter: 1627 loss: 6.89759236e-06
Iter: 1628 loss: 6.88758655e-06
Iter: 1629 loss: 6.88456e-06
Iter: 1630 loss: 6.887366e-06
Iter: 1631 loss: 6.88294313e-06
Iter: 1632 loss: 6.87867714e-06
Iter: 1633 loss: 6.90497291e-06
Iter: 1634 loss: 6.87823876e-06
Iter: 1635 loss: 6.87583815e-06
Iter: 1636 loss: 6.87100373e-06
Iter: 1637 loss: 6.95450444e-06
Iter: 1638 loss: 6.87088914e-06
Iter: 1639 loss: 6.86737258e-06
Iter: 1640 loss: 6.91357354e-06
Iter: 1641 loss: 6.86740168e-06
Iter: 1642 loss: 6.86430121e-06
Iter: 1643 loss: 6.88452474e-06
Iter: 1644 loss: 6.8639e-06
Iter: 1645 loss: 6.86182102e-06
Iter: 1646 loss: 6.85752912e-06
Iter: 1647 loss: 6.92876165e-06
Iter: 1648 loss: 6.85740906e-06
Iter: 1649 loss: 6.85335817e-06
Iter: 1650 loss: 6.91335617e-06
Iter: 1651 loss: 6.85337091e-06
Iter: 1652 loss: 6.84881752e-06
Iter: 1653 loss: 6.85138912e-06
Iter: 1654 loss: 6.84586394e-06
Iter: 1655 loss: 6.8425561e-06
Iter: 1656 loss: 6.84992392e-06
Iter: 1657 loss: 6.84128827e-06
Iter: 1658 loss: 6.83779399e-06
Iter: 1659 loss: 6.84187125e-06
Iter: 1660 loss: 6.83605049e-06
Iter: 1661 loss: 6.83233202e-06
Iter: 1662 loss: 6.83742201e-06
Iter: 1663 loss: 6.83050348e-06
Iter: 1664 loss: 6.82728569e-06
Iter: 1665 loss: 6.85882787e-06
Iter: 1666 loss: 6.82715654e-06
Iter: 1667 loss: 6.82324617e-06
Iter: 1668 loss: 6.83086364e-06
Iter: 1669 loss: 6.82161044e-06
Iter: 1670 loss: 6.81846041e-06
Iter: 1671 loss: 6.81221809e-06
Iter: 1672 loss: 6.93020138e-06
Iter: 1673 loss: 6.8121517e-06
Iter: 1674 loss: 6.80625362e-06
Iter: 1675 loss: 6.8427421e-06
Iter: 1676 loss: 6.80559697e-06
Iter: 1677 loss: 6.80228732e-06
Iter: 1678 loss: 6.80206222e-06
Iter: 1679 loss: 6.80003e-06
Iter: 1680 loss: 6.79598e-06
Iter: 1681 loss: 6.86978274e-06
Iter: 1682 loss: 6.7958722e-06
Iter: 1683 loss: 6.79354e-06
Iter: 1684 loss: 6.79336654e-06
Iter: 1685 loss: 6.79089453e-06
Iter: 1686 loss: 6.78907691e-06
Iter: 1687 loss: 6.78811375e-06
Iter: 1688 loss: 6.78467541e-06
Iter: 1689 loss: 6.78287506e-06
Iter: 1690 loss: 6.78133893e-06
Iter: 1691 loss: 6.77654407e-06
Iter: 1692 loss: 6.84779025e-06
Iter: 1693 loss: 6.7765277e-06
Iter: 1694 loss: 6.77296748e-06
Iter: 1695 loss: 6.78650349e-06
Iter: 1696 loss: 6.77213211e-06
Iter: 1697 loss: 6.76961827e-06
Iter: 1698 loss: 6.76701529e-06
Iter: 1699 loss: 6.76639183e-06
Iter: 1700 loss: 6.762456e-06
Iter: 1701 loss: 6.76602622e-06
Iter: 1702 loss: 6.7602009e-06
Iter: 1703 loss: 6.75722458e-06
Iter: 1704 loss: 6.75717229e-06
Iter: 1705 loss: 6.75374486e-06
Iter: 1706 loss: 6.75527372e-06
Iter: 1707 loss: 6.75141882e-06
Iter: 1708 loss: 6.74857529e-06
Iter: 1709 loss: 6.74336661e-06
Iter: 1710 loss: 6.86706062e-06
Iter: 1711 loss: 6.74337889e-06
Iter: 1712 loss: 6.73713112e-06
Iter: 1713 loss: 6.76525679e-06
Iter: 1714 loss: 6.73596924e-06
Iter: 1715 loss: 6.73310751e-06
Iter: 1716 loss: 6.73239811e-06
Iter: 1717 loss: 6.73066e-06
Iter: 1718 loss: 6.72725673e-06
Iter: 1719 loss: 6.79737605e-06
Iter: 1720 loss: 6.72725491e-06
Iter: 1721 loss: 6.7239871e-06
Iter: 1722 loss: 6.75149e-06
Iter: 1723 loss: 6.72382703e-06
Iter: 1724 loss: 6.72020087e-06
Iter: 1725 loss: 6.72871e-06
Iter: 1726 loss: 6.71887e-06
Iter: 1727 loss: 6.7162e-06
Iter: 1728 loss: 6.71627e-06
Iter: 1729 loss: 6.7141309e-06
Iter: 1730 loss: 6.7099968e-06
Iter: 1731 loss: 6.7172441e-06
Iter: 1732 loss: 6.70814097e-06
Iter: 1733 loss: 6.70489408e-06
Iter: 1734 loss: 6.7532e-06
Iter: 1735 loss: 6.70483496e-06
Iter: 1736 loss: 6.70139934e-06
Iter: 1737 loss: 6.69854035e-06
Iter: 1738 loss: 6.69766769e-06
Iter: 1739 loss: 6.69371866e-06
Iter: 1740 loss: 6.69558267e-06
Iter: 1741 loss: 6.69124074e-06
Iter: 1742 loss: 6.6894163e-06
Iter: 1743 loss: 6.68897246e-06
Iter: 1744 loss: 6.68651592e-06
Iter: 1745 loss: 6.68302891e-06
Iter: 1746 loss: 6.68280654e-06
Iter: 1747 loss: 6.67974291e-06
Iter: 1748 loss: 6.67783797e-06
Iter: 1749 loss: 6.67654422e-06
Iter: 1750 loss: 6.67128461e-06
Iter: 1751 loss: 6.6762359e-06
Iter: 1752 loss: 6.66818232e-06
Iter: 1753 loss: 6.66667165e-06
Iter: 1754 loss: 6.66504548e-06
Iter: 1755 loss: 6.66227152e-06
Iter: 1756 loss: 6.66066853e-06
Iter: 1757 loss: 6.65939751e-06
Iter: 1758 loss: 6.6566e-06
Iter: 1759 loss: 6.66626329e-06
Iter: 1760 loss: 6.65576954e-06
Iter: 1761 loss: 6.65239622e-06
Iter: 1762 loss: 6.6703974e-06
Iter: 1763 loss: 6.65182597e-06
Iter: 1764 loss: 6.64938216e-06
Iter: 1765 loss: 6.64927484e-06
Iter: 1766 loss: 6.64740492e-06
Iter: 1767 loss: 6.6439593e-06
Iter: 1768 loss: 6.64970048e-06
Iter: 1769 loss: 6.64244271e-06
Iter: 1770 loss: 6.63969695e-06
Iter: 1771 loss: 6.63972696e-06
Iter: 1772 loss: 6.63698484e-06
Iter: 1773 loss: 6.63133778e-06
Iter: 1774 loss: 6.73904287e-06
Iter: 1775 loss: 6.63134779e-06
Iter: 1776 loss: 6.62663206e-06
Iter: 1777 loss: 6.64661729e-06
Iter: 1778 loss: 6.62579168e-06
Iter: 1779 loss: 6.62433285e-06
Iter: 1780 loss: 6.62366756e-06
Iter: 1781 loss: 6.62214052e-06
Iter: 1782 loss: 6.61815784e-06
Iter: 1783 loss: 6.6404873e-06
Iter: 1784 loss: 6.61693684e-06
Iter: 1785 loss: 6.61277818e-06
Iter: 1786 loss: 6.6256971e-06
Iter: 1787 loss: 6.61154809e-06
Iter: 1788 loss: 6.60731575e-06
Iter: 1789 loss: 6.61397416e-06
Iter: 1790 loss: 6.60526166e-06
Iter: 1791 loss: 6.60219348e-06
Iter: 1792 loss: 6.60182468e-06
Iter: 1793 loss: 6.59906618e-06
Iter: 1794 loss: 6.59432908e-06
Iter: 1795 loss: 6.59429088e-06
Iter: 1796 loss: 6.59103716e-06
Iter: 1797 loss: 6.63656101e-06
Iter: 1798 loss: 6.59105081e-06
Iter: 1799 loss: 6.58829595e-06
Iter: 1800 loss: 6.59685429e-06
Iter: 1801 loss: 6.58751378e-06
Iter: 1802 loss: 6.58486897e-06
Iter: 1803 loss: 6.58604131e-06
Iter: 1804 loss: 6.58304907e-06
Iter: 1805 loss: 6.57988403e-06
Iter: 1806 loss: 6.58152339e-06
Iter: 1807 loss: 6.5776976e-06
Iter: 1808 loss: 6.57557803e-06
Iter: 1809 loss: 6.57542932e-06
Iter: 1810 loss: 6.57297551e-06
Iter: 1811 loss: 6.56730617e-06
Iter: 1812 loss: 6.63810624e-06
Iter: 1813 loss: 6.56683733e-06
Iter: 1814 loss: 6.56143766e-06
Iter: 1815 loss: 6.57903365e-06
Iter: 1816 loss: 6.5599188e-06
Iter: 1817 loss: 6.55942813e-06
Iter: 1818 loss: 6.55825852e-06
Iter: 1819 loss: 6.55658323e-06
Iter: 1820 loss: 6.55345229e-06
Iter: 1821 loss: 6.6250127e-06
Iter: 1822 loss: 6.55345639e-06
Iter: 1823 loss: 6.55064468e-06
Iter: 1824 loss: 6.54928135e-06
Iter: 1825 loss: 6.54798e-06
Iter: 1826 loss: 6.54354e-06
Iter: 1827 loss: 6.55480608e-06
Iter: 1828 loss: 6.54208725e-06
Iter: 1829 loss: 6.53804364e-06
Iter: 1830 loss: 6.57723876e-06
Iter: 1831 loss: 6.53789493e-06
Iter: 1832 loss: 6.53354891e-06
Iter: 1833 loss: 6.54774794e-06
Iter: 1834 loss: 6.53225106e-06
Iter: 1835 loss: 6.52920517e-06
Iter: 1836 loss: 6.53283405e-06
Iter: 1837 loss: 6.52770723e-06
Iter: 1838 loss: 6.5245631e-06
Iter: 1839 loss: 6.53136112e-06
Iter: 1840 loss: 6.52333119e-06
Iter: 1841 loss: 6.52095923e-06
Iter: 1842 loss: 6.55724216e-06
Iter: 1843 loss: 6.52094059e-06
Iter: 1844 loss: 6.51884193e-06
Iter: 1845 loss: 6.51551909e-06
Iter: 1846 loss: 6.51545452e-06
Iter: 1847 loss: 6.5129193e-06
Iter: 1848 loss: 6.55104941e-06
Iter: 1849 loss: 6.51288337e-06
Iter: 1850 loss: 6.51001301e-06
Iter: 1851 loss: 6.50706579e-06
Iter: 1852 loss: 6.5065251e-06
Iter: 1853 loss: 6.50231232e-06
Iter: 1854 loss: 6.49910498e-06
Iter: 1855 loss: 6.49771937e-06
Iter: 1856 loss: 6.49430604e-06
Iter: 1857 loss: 6.49405183e-06
Iter: 1858 loss: 6.49039885e-06
Iter: 1859 loss: 6.50166248e-06
Iter: 1860 loss: 6.48932109e-06
Iter: 1861 loss: 6.48761943e-06
Iter: 1862 loss: 6.48390369e-06
Iter: 1863 loss: 6.54295854e-06
Iter: 1864 loss: 6.48377409e-06
Iter: 1865 loss: 6.47914658e-06
Iter: 1866 loss: 6.49244294e-06
Iter: 1867 loss: 6.47775323e-06
Iter: 1868 loss: 6.47383558e-06
Iter: 1869 loss: 6.50162565e-06
Iter: 1870 loss: 6.47351862e-06
Iter: 1871 loss: 6.46954095e-06
Iter: 1872 loss: 6.4967553e-06
Iter: 1873 loss: 6.46917897e-06
Iter: 1874 loss: 6.46597755e-06
Iter: 1875 loss: 6.46951685e-06
Iter: 1876 loss: 6.46424178e-06
Iter: 1877 loss: 6.46116041e-06
Iter: 1878 loss: 6.46280114e-06
Iter: 1879 loss: 6.45907539e-06
Iter: 1880 loss: 6.45693308e-06
Iter: 1881 loss: 6.45695582e-06
Iter: 1882 loss: 6.45464752e-06
Iter: 1883 loss: 6.45193722e-06
Iter: 1884 loss: 6.45161208e-06
Iter: 1885 loss: 6.44826468e-06
Iter: 1886 loss: 6.44770535e-06
Iter: 1887 loss: 6.44547163e-06
Iter: 1888 loss: 6.44362763e-06
Iter: 1889 loss: 6.4429355e-06
Iter: 1890 loss: 6.44089869e-06
Iter: 1891 loss: 6.43675321e-06
Iter: 1892 loss: 6.52709787e-06
Iter: 1893 loss: 6.43672274e-06
Iter: 1894 loss: 6.43431031e-06
Iter: 1895 loss: 6.43407748e-06
Iter: 1896 loss: 6.43163048e-06
Iter: 1897 loss: 6.42796e-06
Iter: 1898 loss: 6.42790656e-06
Iter: 1899 loss: 6.42505665e-06
Iter: 1900 loss: 6.4242e-06
Iter: 1901 loss: 6.42254145e-06
Iter: 1902 loss: 6.41809584e-06
Iter: 1903 loss: 6.43005706e-06
Iter: 1904 loss: 6.41667e-06
Iter: 1905 loss: 6.41480347e-06
Iter: 1906 loss: 6.41436691e-06
Iter: 1907 loss: 6.41201541e-06
Iter: 1908 loss: 6.40948292e-06
Iter: 1909 loss: 6.40908593e-06
Iter: 1910 loss: 6.40525832e-06
Iter: 1911 loss: 6.41239649e-06
Iter: 1912 loss: 6.40366216e-06
Iter: 1913 loss: 6.39942846e-06
Iter: 1914 loss: 6.41357565e-06
Iter: 1915 loss: 6.39829705e-06
Iter: 1916 loss: 6.39522386e-06
Iter: 1917 loss: 6.39518385e-06
Iter: 1918 loss: 6.39366863e-06
Iter: 1919 loss: 6.3905245e-06
Iter: 1920 loss: 6.44740658e-06
Iter: 1921 loss: 6.3904522e-06
Iter: 1922 loss: 6.38684e-06
Iter: 1923 loss: 6.38978145e-06
Iter: 1924 loss: 6.38472739e-06
Iter: 1925 loss: 6.38297615e-06
Iter: 1926 loss: 6.38215079e-06
Iter: 1927 loss: 6.38027723e-06
Iter: 1928 loss: 6.37713947e-06
Iter: 1929 loss: 6.45207456e-06
Iter: 1930 loss: 6.37718449e-06
Iter: 1931 loss: 6.37399808e-06
Iter: 1932 loss: 6.37401536e-06
Iter: 1933 loss: 6.3716825e-06
Iter: 1934 loss: 6.36605182e-06
Iter: 1935 loss: 6.42403484e-06
Iter: 1936 loss: 6.36540426e-06
Iter: 1937 loss: 6.36108552e-06
Iter: 1938 loss: 6.3829948e-06
Iter: 1939 loss: 6.36024834e-06
Iter: 1940 loss: 6.35647484e-06
Iter: 1941 loss: 6.36532877e-06
Iter: 1942 loss: 6.35506649e-06
Iter: 1943 loss: 6.35274e-06
Iter: 1944 loss: 6.35261813e-06
Iter: 1945 loss: 6.35021661e-06
Iter: 1946 loss: 6.35086326e-06
Iter: 1947 loss: 6.34844673e-06
Iter: 1948 loss: 6.34544e-06
Iter: 1949 loss: 6.34849494e-06
Iter: 1950 loss: 6.3437019e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2
+ date
Mon Oct 26 09:42:37 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 1.2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f743e2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7439fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7439fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74465e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7443e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7430dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f742710d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74277598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74277d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f742712f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74219950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f742279d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74227950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74227510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f741752f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74161b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f741618c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f741546a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f741178c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f74117730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f740c00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7408eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7403a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f607f86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f607f8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f607ec378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f607a8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f60763840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f60756598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f6075d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f60722840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f60722d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f606ec1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f60692598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f606b99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f6067c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.20329723e-05
Iter: 2 loss: 1.06646321e-05
Iter: 3 loss: 9.77412492e-06
Iter: 4 loss: 8.93753167e-06
Iter: 5 loss: 8.70517761e-06
Iter: 6 loss: 8.19340949e-06
Iter: 7 loss: 7.62626769e-06
Iter: 8 loss: 9.61056685e-06
Iter: 9 loss: 7.47798777e-06
Iter: 10 loss: 7.03638307e-06
Iter: 11 loss: 1.10137007e-05
Iter: 12 loss: 7.01556e-06
Iter: 13 loss: 6.70011195e-06
Iter: 14 loss: 6.89711032e-06
Iter: 15 loss: 6.49891263e-06
Iter: 16 loss: 6.17904971e-06
Iter: 17 loss: 7.18161164e-06
Iter: 18 loss: 6.08631035e-06
Iter: 19 loss: 5.75057038e-06
Iter: 20 loss: 7.42076418e-06
Iter: 21 loss: 5.69348595e-06
Iter: 22 loss: 5.46171896e-06
Iter: 23 loss: 5.06564447e-06
Iter: 24 loss: 5.06511788e-06
Iter: 25 loss: 5.08422e-06
Iter: 26 loss: 4.91625087e-06
Iter: 27 loss: 4.78140737e-06
Iter: 28 loss: 4.56039834e-06
Iter: 29 loss: 4.55930603e-06
Iter: 30 loss: 4.36740538e-06
Iter: 31 loss: 4.75463821e-06
Iter: 32 loss: 4.28954763e-06
Iter: 33 loss: 4.07439802e-06
Iter: 34 loss: 4.00276804e-06
Iter: 35 loss: 3.87878345e-06
Iter: 36 loss: 3.70320117e-06
Iter: 37 loss: 3.70242515e-06
Iter: 38 loss: 3.49805919e-06
Iter: 39 loss: 4.22118092e-06
Iter: 40 loss: 3.44555383e-06
Iter: 41 loss: 3.35207346e-06
Iter: 42 loss: 3.31340743e-06
Iter: 43 loss: 3.26433405e-06
Iter: 44 loss: 3.20393474e-06
Iter: 45 loss: 3.19805986e-06
Iter: 46 loss: 3.13735177e-06
Iter: 47 loss: 3.05544791e-06
Iter: 48 loss: 3.05125e-06
Iter: 49 loss: 2.9768662e-06
Iter: 50 loss: 4.02223577e-06
Iter: 51 loss: 2.97668294e-06
Iter: 52 loss: 2.91734568e-06
Iter: 53 loss: 2.88983097e-06
Iter: 54 loss: 2.86060049e-06
Iter: 55 loss: 2.78059224e-06
Iter: 56 loss: 2.95182326e-06
Iter: 57 loss: 2.749244e-06
Iter: 58 loss: 2.66306779e-06
Iter: 59 loss: 3.00615056e-06
Iter: 60 loss: 2.64360324e-06
Iter: 61 loss: 2.58111618e-06
Iter: 62 loss: 3.50496475e-06
Iter: 63 loss: 2.58103114e-06
Iter: 64 loss: 2.54824226e-06
Iter: 65 loss: 2.48175502e-06
Iter: 66 loss: 3.7035602e-06
Iter: 67 loss: 2.48073229e-06
Iter: 68 loss: 2.41975249e-06
Iter: 69 loss: 2.55121631e-06
Iter: 70 loss: 2.39608312e-06
Iter: 71 loss: 2.33389392e-06
Iter: 72 loss: 2.54106499e-06
Iter: 73 loss: 2.31683134e-06
Iter: 74 loss: 2.30626756e-06
Iter: 75 loss: 2.28778549e-06
Iter: 76 loss: 2.26429552e-06
Iter: 77 loss: 2.21751498e-06
Iter: 78 loss: 3.12027714e-06
Iter: 79 loss: 2.21701862e-06
Iter: 80 loss: 2.17555953e-06
Iter: 81 loss: 2.22887638e-06
Iter: 82 loss: 2.15435193e-06
Iter: 83 loss: 2.13849e-06
Iter: 84 loss: 2.12866507e-06
Iter: 85 loss: 2.11511315e-06
Iter: 86 loss: 2.07930179e-06
Iter: 87 loss: 2.34060349e-06
Iter: 88 loss: 2.07171524e-06
Iter: 89 loss: 2.05535571e-06
Iter: 90 loss: 2.04852449e-06
Iter: 91 loss: 2.03202262e-06
Iter: 92 loss: 2.0123598e-06
Iter: 93 loss: 2.01035164e-06
Iter: 94 loss: 1.98311386e-06
Iter: 95 loss: 1.98725138e-06
Iter: 96 loss: 1.96259725e-06
Iter: 97 loss: 1.92901803e-06
Iter: 98 loss: 2.07887797e-06
Iter: 99 loss: 1.9223919e-06
Iter: 100 loss: 1.89118691e-06
Iter: 101 loss: 2.11039378e-06
Iter: 102 loss: 1.88832632e-06
Iter: 103 loss: 1.87238857e-06
Iter: 104 loss: 2.11621841e-06
Iter: 105 loss: 1.87239561e-06
Iter: 106 loss: 1.85851843e-06
Iter: 107 loss: 1.83649945e-06
Iter: 108 loss: 1.83632244e-06
Iter: 109 loss: 1.8166952e-06
Iter: 110 loss: 1.8283522e-06
Iter: 111 loss: 1.80407972e-06
Iter: 112 loss: 1.78193795e-06
Iter: 113 loss: 1.94164113e-06
Iter: 114 loss: 1.78009896e-06
Iter: 115 loss: 1.76990943e-06
Iter: 116 loss: 1.76862977e-06
Iter: 117 loss: 1.75941329e-06
Iter: 118 loss: 1.73463786e-06
Iter: 119 loss: 1.90152832e-06
Iter: 120 loss: 1.7287598e-06
Iter: 121 loss: 1.70841929e-06
Iter: 122 loss: 1.76226695e-06
Iter: 123 loss: 1.70157909e-06
Iter: 124 loss: 1.69395105e-06
Iter: 125 loss: 1.68981194e-06
Iter: 126 loss: 1.68178849e-06
Iter: 127 loss: 1.66970881e-06
Iter: 128 loss: 1.66948428e-06
Iter: 129 loss: 1.66217478e-06
Iter: 130 loss: 1.66167968e-06
Iter: 131 loss: 1.65482163e-06
Iter: 132 loss: 1.64481287e-06
Iter: 133 loss: 1.64455059e-06
Iter: 134 loss: 1.6325663e-06
Iter: 135 loss: 1.63561583e-06
Iter: 136 loss: 1.62388358e-06
Iter: 137 loss: 1.61111188e-06
Iter: 138 loss: 1.78384403e-06
Iter: 139 loss: 1.6110157e-06
Iter: 140 loss: 1.59968727e-06
Iter: 141 loss: 1.63963421e-06
Iter: 142 loss: 1.59674858e-06
Iter: 143 loss: 1.58722719e-06
Iter: 144 loss: 1.59605884e-06
Iter: 145 loss: 1.58173521e-06
Iter: 146 loss: 1.57263253e-06
Iter: 147 loss: 1.57253317e-06
Iter: 148 loss: 1.5653759e-06
Iter: 149 loss: 1.55594932e-06
Iter: 150 loss: 1.62475772e-06
Iter: 151 loss: 1.5551534e-06
Iter: 152 loss: 1.5461776e-06
Iter: 153 loss: 1.6375941e-06
Iter: 154 loss: 1.54589566e-06
Iter: 155 loss: 1.54199017e-06
Iter: 156 loss: 1.53129247e-06
Iter: 157 loss: 1.59498722e-06
Iter: 158 loss: 1.5283789e-06
Iter: 159 loss: 1.51402924e-06
Iter: 160 loss: 1.59385559e-06
Iter: 161 loss: 1.51202858e-06
Iter: 162 loss: 1.50594497e-06
Iter: 163 loss: 1.50486744e-06
Iter: 164 loss: 1.50006804e-06
Iter: 165 loss: 1.49157381e-06
Iter: 166 loss: 1.70309454e-06
Iter: 167 loss: 1.49156699e-06
Iter: 168 loss: 1.48885192e-06
Iter: 169 loss: 1.48728577e-06
Iter: 170 loss: 1.48423896e-06
Iter: 171 loss: 1.47687899e-06
Iter: 172 loss: 1.55889245e-06
Iter: 173 loss: 1.47616151e-06
Iter: 174 loss: 1.4678094e-06
Iter: 175 loss: 1.4971298e-06
Iter: 176 loss: 1.4656373e-06
Iter: 177 loss: 1.46114667e-06
Iter: 178 loss: 1.46073057e-06
Iter: 179 loss: 1.45690456e-06
Iter: 180 loss: 1.45033209e-06
Iter: 181 loss: 1.45031527e-06
Iter: 182 loss: 1.44215574e-06
Iter: 183 loss: 1.45393392e-06
Iter: 184 loss: 1.43821637e-06
Iter: 185 loss: 1.43020168e-06
Iter: 186 loss: 1.49785433e-06
Iter: 187 loss: 1.42975205e-06
Iter: 188 loss: 1.42748013e-06
Iter: 189 loss: 1.42743943e-06
Iter: 190 loss: 1.42459191e-06
Iter: 191 loss: 1.4174949e-06
Iter: 192 loss: 1.48112713e-06
Iter: 193 loss: 1.41640169e-06
Iter: 194 loss: 1.41073133e-06
Iter: 195 loss: 1.41704788e-06
Iter: 196 loss: 1.40765781e-06
Iter: 197 loss: 1.40380462e-06
Iter: 198 loss: 1.4033053e-06
Iter: 199 loss: 1.3992576e-06
Iter: 200 loss: 1.39551105e-06
Iter: 201 loss: 1.39451549e-06
Iter: 202 loss: 1.38958296e-06
Iter: 203 loss: 1.42252134e-06
Iter: 204 loss: 1.38911889e-06
Iter: 205 loss: 1.3837182e-06
Iter: 206 loss: 1.39209988e-06
Iter: 207 loss: 1.38118321e-06
Iter: 208 loss: 1.37749566e-06
Iter: 209 loss: 1.37467282e-06
Iter: 210 loss: 1.37350935e-06
Iter: 211 loss: 1.37185884e-06
Iter: 212 loss: 1.37063319e-06
Iter: 213 loss: 1.36832637e-06
Iter: 214 loss: 1.36260428e-06
Iter: 215 loss: 1.41739713e-06
Iter: 216 loss: 1.36180586e-06
Iter: 217 loss: 1.35617984e-06
Iter: 218 loss: 1.39774011e-06
Iter: 219 loss: 1.35572918e-06
Iter: 220 loss: 1.35093273e-06
Iter: 221 loss: 1.36080132e-06
Iter: 222 loss: 1.3490353e-06
Iter: 223 loss: 1.34508184e-06
Iter: 224 loss: 1.34505603e-06
Iter: 225 loss: 1.34207039e-06
Iter: 226 loss: 1.33897936e-06
Iter: 227 loss: 1.33843446e-06
Iter: 228 loss: 1.33525953e-06
Iter: 229 loss: 1.33602759e-06
Iter: 230 loss: 1.33297385e-06
Iter: 231 loss: 1.32998389e-06
Iter: 232 loss: 1.36676351e-06
Iter: 233 loss: 1.32996911e-06
Iter: 234 loss: 1.32713842e-06
Iter: 235 loss: 1.34018205e-06
Iter: 236 loss: 1.32657465e-06
Iter: 237 loss: 1.32473372e-06
Iter: 238 loss: 1.32180162e-06
Iter: 239 loss: 1.32175046e-06
Iter: 240 loss: 1.31745833e-06
Iter: 241 loss: 1.36267272e-06
Iter: 242 loss: 1.31736897e-06
Iter: 243 loss: 1.31502361e-06
Iter: 244 loss: 1.31076649e-06
Iter: 245 loss: 1.41208875e-06
Iter: 246 loss: 1.31076979e-06
Iter: 247 loss: 1.30816e-06
Iter: 248 loss: 1.30796752e-06
Iter: 249 loss: 1.30534988e-06
Iter: 250 loss: 1.30699641e-06
Iter: 251 loss: 1.3036838e-06
Iter: 252 loss: 1.30143781e-06
Iter: 253 loss: 1.29843693e-06
Iter: 254 loss: 1.29827549e-06
Iter: 255 loss: 1.29601381e-06
Iter: 256 loss: 1.29597038e-06
Iter: 257 loss: 1.29362229e-06
Iter: 258 loss: 1.30172134e-06
Iter: 259 loss: 1.2930002e-06
Iter: 260 loss: 1.29086197e-06
Iter: 261 loss: 1.29036755e-06
Iter: 262 loss: 1.28895954e-06
Iter: 263 loss: 1.28603494e-06
Iter: 264 loss: 1.28379179e-06
Iter: 265 loss: 1.28286524e-06
Iter: 266 loss: 1.27951466e-06
Iter: 267 loss: 1.33172807e-06
Iter: 268 loss: 1.2795233e-06
Iter: 269 loss: 1.27682097e-06
Iter: 270 loss: 1.29357727e-06
Iter: 271 loss: 1.27647502e-06
Iter: 272 loss: 1.2747621e-06
Iter: 273 loss: 1.2726282e-06
Iter: 274 loss: 1.27243584e-06
Iter: 275 loss: 1.27064163e-06
Iter: 276 loss: 1.27046826e-06
Iter: 277 loss: 1.26928046e-06
Iter: 278 loss: 1.26622399e-06
Iter: 279 loss: 1.29163959e-06
Iter: 280 loss: 1.26568705e-06
Iter: 281 loss: 1.26468308e-06
Iter: 282 loss: 1.26404302e-06
Iter: 283 loss: 1.26235341e-06
Iter: 284 loss: 1.26004181e-06
Iter: 285 loss: 1.25992233e-06
Iter: 286 loss: 1.25754605e-06
Iter: 287 loss: 1.26134978e-06
Iter: 288 loss: 1.25644658e-06
Iter: 289 loss: 1.25523434e-06
Iter: 290 loss: 1.25509882e-06
Iter: 291 loss: 1.25377403e-06
Iter: 292 loss: 1.25224028e-06
Iter: 293 loss: 1.25206736e-06
Iter: 294 loss: 1.25015515e-06
Iter: 295 loss: 1.2550297e-06
Iter: 296 loss: 1.24953294e-06
Iter: 297 loss: 1.24762801e-06
Iter: 298 loss: 1.24959627e-06
Iter: 299 loss: 1.2465739e-06
Iter: 300 loss: 1.24507119e-06
Iter: 301 loss: 1.24506619e-06
Iter: 302 loss: 1.24341022e-06
Iter: 303 loss: 1.24060853e-06
Iter: 304 loss: 1.24060148e-06
Iter: 305 loss: 1.23855546e-06
Iter: 306 loss: 1.26155112e-06
Iter: 307 loss: 1.23852215e-06
Iter: 308 loss: 1.23659538e-06
Iter: 309 loss: 1.24218718e-06
Iter: 310 loss: 1.23597567e-06
Iter: 311 loss: 1.23446353e-06
Iter: 312 loss: 1.23284872e-06
Iter: 313 loss: 1.23259633e-06
Iter: 314 loss: 1.23159145e-06
Iter: 315 loss: 1.23124312e-06
Iter: 316 loss: 1.23024904e-06
Iter: 317 loss: 1.2283723e-06
Iter: 318 loss: 1.26631926e-06
Iter: 319 loss: 1.22836116e-06
Iter: 320 loss: 1.22642393e-06
Iter: 321 loss: 1.23304403e-06
Iter: 322 loss: 1.22594497e-06
Iter: 323 loss: 1.22376264e-06
Iter: 324 loss: 1.24348503e-06
Iter: 325 loss: 1.22367192e-06
Iter: 326 loss: 1.22245592e-06
Iter: 327 loss: 1.22063193e-06
Iter: 328 loss: 1.22061601e-06
Iter: 329 loss: 1.21848825e-06
Iter: 330 loss: 1.23026348e-06
Iter: 331 loss: 1.21819073e-06
Iter: 332 loss: 1.21665653e-06
Iter: 333 loss: 1.21902337e-06
Iter: 334 loss: 1.21595872e-06
Iter: 335 loss: 1.21450478e-06
Iter: 336 loss: 1.2145008e-06
Iter: 337 loss: 1.21350558e-06
Iter: 338 loss: 1.21188054e-06
Iter: 339 loss: 1.211881e-06
Iter: 340 loss: 1.21047083e-06
Iter: 341 loss: 1.22989422e-06
Iter: 342 loss: 1.21046264e-06
Iter: 343 loss: 1.2089796e-06
Iter: 344 loss: 1.20749303e-06
Iter: 345 loss: 1.2072037e-06
Iter: 346 loss: 1.20537504e-06
Iter: 347 loss: 1.21108201e-06
Iter: 348 loss: 1.20486777e-06
Iter: 349 loss: 1.20304276e-06
Iter: 350 loss: 1.22560596e-06
Iter: 351 loss: 1.20303082e-06
Iter: 352 loss: 1.20237587e-06
Iter: 353 loss: 1.20114078e-06
Iter: 354 loss: 1.22895983e-06
Iter: 355 loss: 1.20112645e-06
Iter: 356 loss: 1.20001346e-06
Iter: 357 loss: 1.20002153e-06
Iter: 358 loss: 1.19889671e-06
Iter: 359 loss: 1.19872084e-06
Iter: 360 loss: 1.19793242e-06
Iter: 361 loss: 1.19697438e-06
Iter: 362 loss: 1.19576396e-06
Iter: 363 loss: 1.19573133e-06
Iter: 364 loss: 1.19354513e-06
Iter: 365 loss: 1.20486538e-06
Iter: 366 loss: 1.19319316e-06
Iter: 367 loss: 1.19188007e-06
Iter: 368 loss: 1.20670018e-06
Iter: 369 loss: 1.19184449e-06
Iter: 370 loss: 1.19049696e-06
Iter: 371 loss: 1.18981256e-06
Iter: 372 loss: 1.18919229e-06
Iter: 373 loss: 1.18786681e-06
Iter: 374 loss: 1.19459958e-06
Iter: 375 loss: 1.18760977e-06
Iter: 376 loss: 1.18654475e-06
Iter: 377 loss: 1.19534866e-06
Iter: 378 loss: 1.18646835e-06
Iter: 379 loss: 1.18576588e-06
Iter: 380 loss: 1.18443961e-06
Iter: 381 loss: 1.21485868e-06
Iter: 382 loss: 1.18446951e-06
Iter: 383 loss: 1.18378614e-06
Iter: 384 loss: 1.18361822e-06
Iter: 385 loss: 1.1828929e-06
Iter: 386 loss: 1.18156902e-06
Iter: 387 loss: 1.21073754e-06
Iter: 388 loss: 1.18156299e-06
Iter: 389 loss: 1.18019557e-06
Iter: 390 loss: 1.18088781e-06
Iter: 391 loss: 1.17928255e-06
Iter: 392 loss: 1.17813784e-06
Iter: 393 loss: 1.1779556e-06
Iter: 394 loss: 1.17715194e-06
Iter: 395 loss: 1.17525406e-06
Iter: 396 loss: 1.19655795e-06
Iter: 397 loss: 1.1750443e-06
Iter: 398 loss: 1.17351476e-06
Iter: 399 loss: 1.18404353e-06
Iter: 400 loss: 1.17340699e-06
Iter: 401 loss: 1.17228569e-06
Iter: 402 loss: 1.18057392e-06
Iter: 403 loss: 1.17218963e-06
Iter: 404 loss: 1.17119532e-06
Iter: 405 loss: 1.17549405e-06
Iter: 406 loss: 1.1710024e-06
Iter: 407 loss: 1.17003879e-06
Iter: 408 loss: 1.16954061e-06
Iter: 409 loss: 1.16913702e-06
Iter: 410 loss: 1.16797969e-06
Iter: 411 loss: 1.17498678e-06
Iter: 412 loss: 1.16782303e-06
Iter: 413 loss: 1.16653678e-06
Iter: 414 loss: 1.16910633e-06
Iter: 415 loss: 1.16601893e-06
Iter: 416 loss: 1.1650809e-06
Iter: 417 loss: 1.16427259e-06
Iter: 418 loss: 1.16400486e-06
Iter: 419 loss: 1.16271474e-06
Iter: 420 loss: 1.16268757e-06
Iter: 421 loss: 1.16196884e-06
Iter: 422 loss: 1.16074216e-06
Iter: 423 loss: 1.16075182e-06
Iter: 424 loss: 1.15977321e-06
Iter: 425 loss: 1.17237551e-06
Iter: 426 loss: 1.15976718e-06
Iter: 427 loss: 1.15876981e-06
Iter: 428 loss: 1.16215119e-06
Iter: 429 loss: 1.15850116e-06
Iter: 430 loss: 1.15787043e-06
Iter: 431 loss: 1.15608384e-06
Iter: 432 loss: 1.16714307e-06
Iter: 433 loss: 1.15565467e-06
Iter: 434 loss: 1.15413877e-06
Iter: 435 loss: 1.15413366e-06
Iter: 436 loss: 1.15298644e-06
Iter: 437 loss: 1.16438628e-06
Iter: 438 loss: 1.15295006e-06
Iter: 439 loss: 1.15191267e-06
Iter: 440 loss: 1.15260127e-06
Iter: 441 loss: 1.15126795e-06
Iter: 442 loss: 1.15023488e-06
Iter: 443 loss: 1.15271189e-06
Iter: 444 loss: 1.14991644e-06
Iter: 445 loss: 1.14905424e-06
Iter: 446 loss: 1.15745763e-06
Iter: 447 loss: 1.14903105e-06
Iter: 448 loss: 1.14828777e-06
Iter: 449 loss: 1.14756563e-06
Iter: 450 loss: 1.14740124e-06
Iter: 451 loss: 1.14661123e-06
Iter: 452 loss: 1.15360535e-06
Iter: 453 loss: 1.14655882e-06
Iter: 454 loss: 1.14559748e-06
Iter: 455 loss: 1.14590682e-06
Iter: 456 loss: 1.14493128e-06
Iter: 457 loss: 1.14397551e-06
Iter: 458 loss: 1.1429554e-06
Iter: 459 loss: 1.14278691e-06
Iter: 460 loss: 1.14245404e-06
Iter: 461 loss: 1.1419047e-06
Iter: 462 loss: 1.14140585e-06
Iter: 463 loss: 1.14052614e-06
Iter: 464 loss: 1.16145839e-06
Iter: 465 loss: 1.14050863e-06
Iter: 466 loss: 1.13958436e-06
Iter: 467 loss: 1.13923761e-06
Iter: 468 loss: 1.13868168e-06
Iter: 469 loss: 1.13783949e-06
Iter: 470 loss: 1.13783301e-06
Iter: 471 loss: 1.13699775e-06
Iter: 472 loss: 1.14055774e-06
Iter: 473 loss: 1.13683984e-06
Iter: 474 loss: 1.13612305e-06
Iter: 475 loss: 1.13588681e-06
Iter: 476 loss: 1.13550709e-06
Iter: 477 loss: 1.13450369e-06
Iter: 478 loss: 1.13906549e-06
Iter: 479 loss: 1.13429178e-06
Iter: 480 loss: 1.1333525e-06
Iter: 481 loss: 1.13782392e-06
Iter: 482 loss: 1.13317492e-06
Iter: 483 loss: 1.13239787e-06
Iter: 484 loss: 1.13169972e-06
Iter: 485 loss: 1.13153476e-06
Iter: 486 loss: 1.13095496e-06
Iter: 487 loss: 1.13083775e-06
Iter: 488 loss: 1.13039141e-06
Iter: 489 loss: 1.12969451e-06
Iter: 490 loss: 1.12967859e-06
Iter: 491 loss: 1.12900057e-06
Iter: 492 loss: 1.13459157e-06
Iter: 493 loss: 1.12894281e-06
Iter: 494 loss: 1.12815951e-06
Iter: 495 loss: 1.12999624e-06
Iter: 496 loss: 1.12787382e-06
Iter: 497 loss: 1.12735938e-06
Iter: 498 loss: 1.12615362e-06
Iter: 499 loss: 1.14087743e-06
Iter: 500 loss: 1.12606585e-06
Iter: 501 loss: 1.12466068e-06
Iter: 502 loss: 1.13064846e-06
Iter: 503 loss: 1.12436e-06
Iter: 504 loss: 1.12382816e-06
Iter: 505 loss: 1.12370185e-06
Iter: 506 loss: 1.12312273e-06
Iter: 507 loss: 1.12372572e-06
Iter: 508 loss: 1.12280168e-06
Iter: 509 loss: 1.12226189e-06
Iter: 510 loss: 1.12237478e-06
Iter: 511 loss: 1.12184864e-06
Iter: 512 loss: 1.12112332e-06
Iter: 513 loss: 1.12712746e-06
Iter: 514 loss: 1.12106932e-06
Iter: 515 loss: 1.12050725e-06
Iter: 516 loss: 1.12136854e-06
Iter: 517 loss: 1.12023167e-06
Iter: 518 loss: 1.1196031e-06
Iter: 519 loss: 1.11970871e-06
Iter: 520 loss: 1.11914278e-06
Iter: 521 loss: 1.11816735e-06
Iter: 522 loss: 1.12480393e-06
Iter: 523 loss: 1.11804422e-06
Iter: 524 loss: 1.11734198e-06
Iter: 525 loss: 1.11609131e-06
Iter: 526 loss: 1.14549539e-06
Iter: 527 loss: 1.11610416e-06
Iter: 528 loss: 1.11594522e-06
Iter: 529 loss: 1.11542784e-06
Iter: 530 loss: 1.11498082e-06
Iter: 531 loss: 1.11428733e-06
Iter: 532 loss: 1.11429438e-06
Iter: 533 loss: 1.11361919e-06
Iter: 534 loss: 1.11318275e-06
Iter: 535 loss: 1.11291115e-06
Iter: 536 loss: 1.11200609e-06
Iter: 537 loss: 1.11573809e-06
Iter: 538 loss: 1.11181078e-06
Iter: 539 loss: 1.11110091e-06
Iter: 540 loss: 1.11107238e-06
Iter: 541 loss: 1.1105675e-06
Iter: 542 loss: 1.10987048e-06
Iter: 543 loss: 1.1098457e-06
Iter: 544 loss: 1.10899555e-06
Iter: 545 loss: 1.11491227e-06
Iter: 546 loss: 1.10894143e-06
Iter: 547 loss: 1.10822316e-06
Iter: 548 loss: 1.11120653e-06
Iter: 549 loss: 1.1080715e-06
Iter: 550 loss: 1.10754331e-06
Iter: 551 loss: 1.10798703e-06
Iter: 552 loss: 1.10722044e-06
Iter: 553 loss: 1.10663234e-06
Iter: 554 loss: 1.11037059e-06
Iter: 555 loss: 1.10654992e-06
Iter: 556 loss: 1.10600718e-06
Iter: 557 loss: 1.10695248e-06
Iter: 558 loss: 1.10573274e-06
Iter: 559 loss: 1.10536303e-06
Iter: 560 loss: 1.10546557e-06
Iter: 561 loss: 1.10509109e-06
Iter: 562 loss: 1.10441124e-06
Iter: 563 loss: 1.10882365e-06
Iter: 564 loss: 1.10433325e-06
Iter: 565 loss: 1.10393489e-06
Iter: 566 loss: 1.10291739e-06
Iter: 567 loss: 1.1091073e-06
Iter: 568 loss: 1.10260498e-06
Iter: 569 loss: 1.10124847e-06
Iter: 570 loss: 1.11036366e-06
Iter: 571 loss: 1.10108954e-06
Iter: 572 loss: 1.10039923e-06
Iter: 573 loss: 1.10580163e-06
Iter: 574 loss: 1.10033852e-06
Iter: 575 loss: 1.0994911e-06
Iter: 576 loss: 1.10173301e-06
Iter: 577 loss: 1.09919358e-06
Iter: 578 loss: 1.09871519e-06
Iter: 579 loss: 1.09929579e-06
Iter: 580 loss: 1.09845109e-06
Iter: 581 loss: 1.09797679e-06
Iter: 582 loss: 1.1023584e-06
Iter: 583 loss: 1.09794496e-06
Iter: 584 loss: 1.09749692e-06
Iter: 585 loss: 1.09727478e-06
Iter: 586 loss: 1.09704069e-06
Iter: 587 loss: 1.09636562e-06
Iter: 588 loss: 1.09896314e-06
Iter: 589 loss: 1.09619123e-06
Iter: 590 loss: 1.09549524e-06
Iter: 591 loss: 1.09879136e-06
Iter: 592 loss: 1.09541588e-06
Iter: 593 loss: 1.09477082e-06
Iter: 594 loss: 1.09436337e-06
Iter: 595 loss: 1.0941344e-06
Iter: 596 loss: 1.09357575e-06
Iter: 597 loss: 1.09357006e-06
Iter: 598 loss: 1.09301698e-06
Iter: 599 loss: 1.09267557e-06
Iter: 600 loss: 1.09248799e-06
Iter: 601 loss: 1.09199209e-06
Iter: 602 loss: 1.09147436e-06
Iter: 603 loss: 1.09139182e-06
Iter: 604 loss: 1.09061671e-06
Iter: 605 loss: 1.09376413e-06
Iter: 606 loss: 1.09046596e-06
Iter: 607 loss: 1.0900518e-06
Iter: 608 loss: 1.09001417e-06
Iter: 609 loss: 1.08953907e-06
Iter: 610 loss: 1.08873564e-06
Iter: 611 loss: 1.08874519e-06
Iter: 612 loss: 1.08794734e-06
Iter: 613 loss: 1.0919473e-06
Iter: 614 loss: 1.08783559e-06
Iter: 615 loss: 1.08719178e-06
Iter: 616 loss: 1.09244706e-06
Iter: 617 loss: 1.08713789e-06
Iter: 618 loss: 1.08665472e-06
Iter: 619 loss: 1.08644826e-06
Iter: 620 loss: 1.08619463e-06
Iter: 621 loss: 1.08566269e-06
Iter: 622 loss: 1.09328687e-06
Iter: 623 loss: 1.08567087e-06
Iter: 624 loss: 1.08535426e-06
Iter: 625 loss: 1.08587051e-06
Iter: 626 loss: 1.0851827e-06
Iter: 627 loss: 1.08477411e-06
Iter: 628 loss: 1.08427912e-06
Iter: 629 loss: 1.08425638e-06
Iter: 630 loss: 1.08373888e-06
Iter: 631 loss: 1.08371364e-06
Iter: 632 loss: 1.0833628e-06
Iter: 633 loss: 1.08265806e-06
Iter: 634 loss: 1.09571965e-06
Iter: 635 loss: 1.08262645e-06
Iter: 636 loss: 1.08185259e-06
Iter: 637 loss: 1.08197673e-06
Iter: 638 loss: 1.08126437e-06
Iter: 639 loss: 1.08042502e-06
Iter: 640 loss: 1.08382915e-06
Iter: 641 loss: 1.08023551e-06
Iter: 642 loss: 1.08003644e-06
Iter: 643 loss: 1.0798301e-06
Iter: 644 loss: 1.07956726e-06
Iter: 645 loss: 1.07901769e-06
Iter: 646 loss: 1.08669383e-06
Iter: 647 loss: 1.07896597e-06
Iter: 648 loss: 1.07849678e-06
Iter: 649 loss: 1.084818e-06
Iter: 650 loss: 1.07846847e-06
Iter: 651 loss: 1.07803191e-06
Iter: 652 loss: 1.07864207e-06
Iter: 653 loss: 1.07779863e-06
Iter: 654 loss: 1.0773108e-06
Iter: 655 loss: 1.0773723e-06
Iter: 656 loss: 1.07695644e-06
Iter: 657 loss: 1.07626386e-06
Iter: 658 loss: 1.08354857e-06
Iter: 659 loss: 1.07624749e-06
Iter: 660 loss: 1.07586209e-06
Iter: 661 loss: 1.07579035e-06
Iter: 662 loss: 1.07549749e-06
Iter: 663 loss: 1.07495498e-06
Iter: 664 loss: 1.07720564e-06
Iter: 665 loss: 1.07481105e-06
Iter: 666 loss: 1.07423978e-06
Iter: 667 loss: 1.07854169e-06
Iter: 668 loss: 1.07421772e-06
Iter: 669 loss: 1.07395e-06
Iter: 670 loss: 1.07326446e-06
Iter: 671 loss: 1.08114591e-06
Iter: 672 loss: 1.07319624e-06
Iter: 673 loss: 1.07244045e-06
Iter: 674 loss: 1.07532514e-06
Iter: 675 loss: 1.07225753e-06
Iter: 676 loss: 1.07149071e-06
Iter: 677 loss: 1.07272444e-06
Iter: 678 loss: 1.07115829e-06
Iter: 679 loss: 1.07055939e-06
Iter: 680 loss: 1.07049937e-06
Iter: 681 loss: 1.07022288e-06
Iter: 682 loss: 1.06965922e-06
Iter: 683 loss: 1.08187464e-06
Iter: 684 loss: 1.06966752e-06
Iter: 685 loss: 1.06930611e-06
Iter: 686 loss: 1.06929667e-06
Iter: 687 loss: 1.06895095e-06
Iter: 688 loss: 1.06890843e-06
Iter: 689 loss: 1.06865423e-06
Iter: 690 loss: 1.0681855e-06
Iter: 691 loss: 1.06910181e-06
Iter: 692 loss: 1.06802236e-06
Iter: 693 loss: 1.0674828e-06
Iter: 694 loss: 1.07118126e-06
Iter: 695 loss: 1.06742402e-06
Iter: 696 loss: 1.0670957e-06
Iter: 697 loss: 1.06685548e-06
Iter: 698 loss: 1.0667361e-06
Iter: 699 loss: 1.0662385e-06
Iter: 700 loss: 1.0727482e-06
Iter: 701 loss: 1.06624668e-06
Iter: 702 loss: 1.06582888e-06
Iter: 703 loss: 1.06635753e-06
Iter: 704 loss: 1.06561788e-06
Iter: 705 loss: 1.06523544e-06
Iter: 706 loss: 1.06465131e-06
Iter: 707 loss: 1.06464427e-06
Iter: 708 loss: 1.06402535e-06
Iter: 709 loss: 1.0654112e-06
Iter: 710 loss: 1.06374625e-06
Iter: 711 loss: 1.06311745e-06
Iter: 712 loss: 1.06935e-06
Iter: 713 loss: 1.06308016e-06
Iter: 714 loss: 1.06252855e-06
Iter: 715 loss: 1.06724667e-06
Iter: 716 loss: 1.06249058e-06
Iter: 717 loss: 1.06215293e-06
Iter: 718 loss: 1.0613345e-06
Iter: 719 loss: 1.06965706e-06
Iter: 720 loss: 1.06123639e-06
Iter: 721 loss: 1.06086077e-06
Iter: 722 loss: 1.06072923e-06
Iter: 723 loss: 1.06028e-06
Iter: 724 loss: 1.06005837e-06
Iter: 725 loss: 1.0598477e-06
Iter: 726 loss: 1.05943832e-06
Iter: 727 loss: 1.06237871e-06
Iter: 728 loss: 1.05943786e-06
Iter: 729 loss: 1.05897834e-06
Iter: 730 loss: 1.05974652e-06
Iter: 731 loss: 1.05876757e-06
Iter: 732 loss: 1.05840923e-06
Iter: 733 loss: 1.05845891e-06
Iter: 734 loss: 1.05814183e-06
Iter: 735 loss: 1.05779191e-06
Iter: 736 loss: 1.06347261e-06
Iter: 737 loss: 1.05778372e-06
Iter: 738 loss: 1.05743e-06
Iter: 739 loss: 1.05730987e-06
Iter: 740 loss: 1.0570626e-06
Iter: 741 loss: 1.05656818e-06
Iter: 742 loss: 1.05622507e-06
Iter: 743 loss: 1.05605977e-06
Iter: 744 loss: 1.05533627e-06
Iter: 745 loss: 1.05754566e-06
Iter: 746 loss: 1.05514744e-06
Iter: 747 loss: 1.05455865e-06
Iter: 748 loss: 1.05554068e-06
Iter: 749 loss: 1.05425579e-06
Iter: 750 loss: 1.05425522e-06
Iter: 751 loss: 1.05400704e-06
Iter: 752 loss: 1.05380991e-06
Iter: 753 loss: 1.0533206e-06
Iter: 754 loss: 1.05877155e-06
Iter: 755 loss: 1.05327081e-06
Iter: 756 loss: 1.05276456e-06
Iter: 757 loss: 1.05736444e-06
Iter: 758 loss: 1.05272818e-06
Iter: 759 loss: 1.05224592e-06
Iter: 760 loss: 1.0539934e-06
Iter: 761 loss: 1.05212814e-06
Iter: 762 loss: 1.05171523e-06
Iter: 763 loss: 1.05108506e-06
Iter: 764 loss: 1.05110394e-06
Iter: 765 loss: 1.05052368e-06
Iter: 766 loss: 1.05047934e-06
Iter: 767 loss: 1.05022468e-06
Iter: 768 loss: 1.04986066e-06
Iter: 769 loss: 1.04984906e-06
Iter: 770 loss: 1.04946821e-06
Iter: 771 loss: 1.05573827e-06
Iter: 772 loss: 1.04946571e-06
Iter: 773 loss: 1.04912283e-06
Iter: 774 loss: 1.04947094e-06
Iter: 775 loss: 1.04892888e-06
Iter: 776 loss: 1.04859873e-06
Iter: 777 loss: 1.04832782e-06
Iter: 778 loss: 1.04823596e-06
Iter: 779 loss: 1.04770459e-06
Iter: 780 loss: 1.04794503e-06
Iter: 781 loss: 1.04730771e-06
Iter: 782 loss: 1.04653054e-06
Iter: 783 loss: 1.0484431e-06
Iter: 784 loss: 1.04621267e-06
Iter: 785 loss: 1.04602714e-06
Iter: 786 loss: 1.04584433e-06
Iter: 787 loss: 1.04550213e-06
Iter: 788 loss: 1.04498884e-06
Iter: 789 loss: 1.04498895e-06
Iter: 790 loss: 1.0446106e-06
Iter: 791 loss: 1.04577589e-06
Iter: 792 loss: 1.04448441e-06
Iter: 793 loss: 1.04407809e-06
Iter: 794 loss: 1.04794e-06
Iter: 795 loss: 1.04403955e-06
Iter: 796 loss: 1.0436828e-06
Iter: 797 loss: 1.04332423e-06
Iter: 798 loss: 1.04326909e-06
Iter: 799 loss: 1.04299056e-06
Iter: 800 loss: 1.0429743e-06
Iter: 801 loss: 1.04273863e-06
Iter: 802 loss: 1.04220635e-06
Iter: 803 loss: 1.05096944e-06
Iter: 804 loss: 1.04217634e-06
Iter: 805 loss: 1.04179787e-06
Iter: 806 loss: 1.04177343e-06
Iter: 807 loss: 1.04145033e-06
Iter: 808 loss: 1.0412349e-06
Iter: 809 loss: 1.0411004e-06
Iter: 810 loss: 1.04074854e-06
Iter: 811 loss: 1.0417391e-06
Iter: 812 loss: 1.04064122e-06
Iter: 813 loss: 1.04022433e-06
Iter: 814 loss: 1.03995114e-06
Iter: 815 loss: 1.03981483e-06
Iter: 816 loss: 1.03926686e-06
Iter: 817 loss: 1.0423546e-06
Iter: 818 loss: 1.03919024e-06
Iter: 819 loss: 1.03873185e-06
Iter: 820 loss: 1.04484332e-06
Iter: 821 loss: 1.0387414e-06
Iter: 822 loss: 1.03842331e-06
Iter: 823 loss: 1.03781895e-06
Iter: 824 loss: 1.05108188e-06
Iter: 825 loss: 1.03784134e-06
Iter: 826 loss: 1.03725097e-06
Iter: 827 loss: 1.04008541e-06
Iter: 828 loss: 1.03714444e-06
Iter: 829 loss: 1.03679042e-06
Iter: 830 loss: 1.03679849e-06
Iter: 831 loss: 1.0365618e-06
Iter: 832 loss: 1.03607613e-06
Iter: 833 loss: 1.04320543e-06
Iter: 834 loss: 1.03605748e-06
Iter: 835 loss: 1.03575917e-06
Iter: 836 loss: 1.03570665e-06
Iter: 837 loss: 1.03546233e-06
Iter: 838 loss: 1.03513787e-06
Iter: 839 loss: 1.03514185e-06
Iter: 840 loss: 1.03484035e-06
Iter: 841 loss: 1.03483694e-06
Iter: 842 loss: 1.03460059e-06
Iter: 843 loss: 1.03408502e-06
Iter: 844 loss: 1.04416597e-06
Iter: 845 loss: 1.03408638e-06
Iter: 846 loss: 1.03350806e-06
Iter: 847 loss: 1.03400498e-06
Iter: 848 loss: 1.0331978e-06
Iter: 849 loss: 1.03256968e-06
Iter: 850 loss: 1.03754621e-06
Iter: 851 loss: 1.0325557e-06
Iter: 852 loss: 1.03216166e-06
Iter: 853 loss: 1.03220236e-06
Iter: 854 loss: 1.0318613e-06
Iter: 855 loss: 1.03169043e-06
Iter: 856 loss: 1.03161608e-06
Iter: 857 loss: 1.03139018e-06
Iter: 858 loss: 1.03088564e-06
Iter: 859 loss: 1.0383319e-06
Iter: 860 loss: 1.03085813e-06
Iter: 861 loss: 1.0303479e-06
Iter: 862 loss: 1.03090235e-06
Iter: 863 loss: 1.03005527e-06
Iter: 864 loss: 1.02957711e-06
Iter: 865 loss: 1.02958302e-06
Iter: 866 loss: 1.02914703e-06
Iter: 867 loss: 1.02890726e-06
Iter: 868 loss: 1.02871991e-06
Iter: 869 loss: 1.02827539e-06
Iter: 870 loss: 1.03004083e-06
Iter: 871 loss: 1.02819217e-06
Iter: 872 loss: 1.02769195e-06
Iter: 873 loss: 1.03102957e-06
Iter: 874 loss: 1.02764682e-06
Iter: 875 loss: 1.02741865e-06
Iter: 876 loss: 1.02742706e-06
Iter: 877 loss: 1.02724346e-06
Iter: 878 loss: 1.02682e-06
Iter: 879 loss: 1.02929107e-06
Iter: 880 loss: 1.02680929e-06
Iter: 881 loss: 1.02658055e-06
Iter: 882 loss: 1.02624358e-06
Iter: 883 loss: 1.02622903e-06
Iter: 884 loss: 1.02576041e-06
Iter: 885 loss: 1.0265004e-06
Iter: 886 loss: 1.0255402e-06
Iter: 887 loss: 1.02494539e-06
Iter: 888 loss: 1.02630145e-06
Iter: 889 loss: 1.02466402e-06
Iter: 890 loss: 1.02405716e-06
Iter: 891 loss: 1.02502736e-06
Iter: 892 loss: 1.02374042e-06
Iter: 893 loss: 1.02323395e-06
Iter: 894 loss: 1.02528509e-06
Iter: 895 loss: 1.02305466e-06
Iter: 896 loss: 1.02278909e-06
Iter: 897 loss: 1.02274453e-06
Iter: 898 loss: 1.02259423e-06
Iter: 899 loss: 1.0223049e-06
Iter: 900 loss: 1.02713921e-06
Iter: 901 loss: 1.02228125e-06
Iter: 902 loss: 1.02198146e-06
Iter: 903 loss: 1.02492243e-06
Iter: 904 loss: 1.02197203e-06
Iter: 905 loss: 1.02159356e-06
Iter: 906 loss: 1.02153422e-06
Iter: 907 loss: 1.02131173e-06
Iter: 908 loss: 1.02089825e-06
Iter: 909 loss: 1.02160766e-06
Iter: 910 loss: 1.02070862e-06
Iter: 911 loss: 1.0201918e-06
Iter: 912 loss: 1.02382694e-06
Iter: 913 loss: 1.02015827e-06
Iter: 914 loss: 1.01990543e-06
Iter: 915 loss: 1.01984665e-06
Iter: 916 loss: 1.01967419e-06
Iter: 917 loss: 1.01917317e-06
Iter: 918 loss: 1.02201238e-06
Iter: 919 loss: 1.01909905e-06
Iter: 920 loss: 1.01883882e-06
Iter: 921 loss: 1.01837281e-06
Iter: 922 loss: 1.01837736e-06
Iter: 923 loss: 1.0179225e-06
Iter: 924 loss: 1.02073591e-06
Iter: 925 loss: 1.01788646e-06
Iter: 926 loss: 1.01748515e-06
Iter: 927 loss: 1.01842556e-06
Iter: 928 loss: 1.01731712e-06
Iter: 929 loss: 1.01683713e-06
Iter: 930 loss: 1.01683952e-06
Iter: 931 loss: 1.01645628e-06
Iter: 932 loss: 1.01614023e-06
Iter: 933 loss: 1.01607964e-06
Iter: 934 loss: 1.01577166e-06
Iter: 935 loss: 1.01548119e-06
Iter: 936 loss: 1.01539104e-06
Iter: 937 loss: 1.01504179e-06
Iter: 938 loss: 1.0152678e-06
Iter: 939 loss: 1.01480816e-06
Iter: 940 loss: 1.01439764e-06
Iter: 941 loss: 1.01439184e-06
Iter: 942 loss: 1.01421028e-06
Iter: 943 loss: 1.01393778e-06
Iter: 944 loss: 1.01391254e-06
Iter: 945 loss: 1.01354567e-06
Iter: 946 loss: 1.01704222e-06
Iter: 947 loss: 1.01353885e-06
Iter: 948 loss: 1.01316095e-06
Iter: 949 loss: 1.01280057e-06
Iter: 950 loss: 1.01273099e-06
Iter: 951 loss: 1.01241494e-06
Iter: 952 loss: 1.01237561e-06
Iter: 953 loss: 1.01217302e-06
Iter: 954 loss: 1.01161675e-06
Iter: 955 loss: 1.01669843e-06
Iter: 956 loss: 1.01153728e-06
Iter: 957 loss: 1.01093269e-06
Iter: 958 loss: 1.01195246e-06
Iter: 959 loss: 1.01073658e-06
Iter: 960 loss: 1.01025717e-06
Iter: 961 loss: 1.01184503e-06
Iter: 962 loss: 1.01010778e-06
Iter: 963 loss: 1.00976695e-06
Iter: 964 loss: 1.00979264e-06
Iter: 965 loss: 1.00948353e-06
Iter: 966 loss: 1.01013029e-06
Iter: 967 loss: 1.00934847e-06
Iter: 968 loss: 1.00896364e-06
Iter: 969 loss: 1.00865157e-06
Iter: 970 loss: 1.00853492e-06
Iter: 971 loss: 1.00803823e-06
Iter: 972 loss: 1.01149556e-06
Iter: 973 loss: 1.00798127e-06
Iter: 974 loss: 1.00759223e-06
Iter: 975 loss: 1.01130286e-06
Iter: 976 loss: 1.00760576e-06
Iter: 977 loss: 1.00733882e-06
Iter: 978 loss: 1.00693455e-06
Iter: 979 loss: 1.00692591e-06
Iter: 980 loss: 1.00665602e-06
Iter: 981 loss: 1.00661612e-06
Iter: 982 loss: 1.0064017e-06
Iter: 983 loss: 1.00608509e-06
Iter: 984 loss: 1.0060603e-06
Iter: 985 loss: 1.0056466e-06
Iter: 986 loss: 1.01107685e-06
Iter: 987 loss: 1.0056292e-06
Iter: 988 loss: 1.00541547e-06
Iter: 989 loss: 1.00487136e-06
Iter: 990 loss: 1.00911404e-06
Iter: 991 loss: 1.00478155e-06
Iter: 992 loss: 1.00404191e-06
Iter: 993 loss: 1.00658463e-06
Iter: 994 loss: 1.00384386e-06
Iter: 995 loss: 1.00318061e-06
Iter: 996 loss: 1.0036714e-06
Iter: 997 loss: 1.00280113e-06
Iter: 998 loss: 1.00220063e-06
Iter: 999 loss: 1.00684599e-06
Iter: 1000 loss: 1.00215107e-06
Iter: 1001 loss: 1.00172042e-06
Iter: 1002 loss: 1.00364741e-06
Iter: 1003 loss: 1.00164743e-06
Iter: 1004 loss: 1.00128261e-06
Iter: 1005 loss: 1.0068718e-06
Iter: 1006 loss: 1.00128e-06
Iter: 1007 loss: 1.0010225e-06
Iter: 1008 loss: 1.00068326e-06
Iter: 1009 loss: 1.00066313e-06
Iter: 1010 loss: 1.0001894e-06
Iter: 1011 loss: 1.00246325e-06
Iter: 1012 loss: 1.00010243e-06
Iter: 1013 loss: 9.9967906e-07
Iter: 1014 loss: 1.00277089e-06
Iter: 1015 loss: 9.99642339e-07
Iter: 1016 loss: 9.99364488e-07
Iter: 1017 loss: 9.99429403e-07
Iter: 1018 loss: 9.99142458e-07
Iter: 1019 loss: 9.9886779e-07
Iter: 1020 loss: 1.00187412e-06
Iter: 1021 loss: 9.98867336e-07
Iter: 1022 loss: 9.98592441e-07
Iter: 1023 loss: 9.98333803e-07
Iter: 1024 loss: 9.98262294e-07
Iter: 1025 loss: 9.97956136e-07
Iter: 1026 loss: 9.99695885e-07
Iter: 1027 loss: 9.97922484e-07
Iter: 1028 loss: 9.97539814e-07
Iter: 1029 loss: 9.97552661e-07
Iter: 1030 loss: 9.97278903e-07
Iter: 1031 loss: 9.96909e-07
Iter: 1032 loss: 9.96328e-07
Iter: 1033 loss: 9.96338485e-07
Iter: 1034 loss: 9.95621804e-07
Iter: 1035 loss: 9.99695771e-07
Iter: 1036 loss: 9.95500386e-07
Iter: 1037 loss: 9.94923312e-07
Iter: 1038 loss: 9.96273343e-07
Iter: 1039 loss: 9.94714128e-07
Iter: 1040 loss: 9.94317361e-07
Iter: 1041 loss: 1.00006423e-06
Iter: 1042 loss: 9.94329639e-07
Iter: 1043 loss: 9.93928552e-07
Iter: 1044 loss: 9.94744596e-07
Iter: 1045 loss: 9.93745743e-07
Iter: 1046 loss: 9.93365461e-07
Iter: 1047 loss: 9.93166168e-07
Iter: 1048 loss: 9.93001e-07
Iter: 1049 loss: 9.925418e-07
Iter: 1050 loss: 9.98032192e-07
Iter: 1051 loss: 9.92514742e-07
Iter: 1052 loss: 9.92100695e-07
Iter: 1053 loss: 9.92616492e-07
Iter: 1054 loss: 9.91869797e-07
Iter: 1055 loss: 9.91481556e-07
Iter: 1056 loss: 9.92410719e-07
Iter: 1057 loss: 9.91359116e-07
Iter: 1058 loss: 9.91018624e-07
Iter: 1059 loss: 9.94599304e-07
Iter: 1060 loss: 9.91008619e-07
Iter: 1061 loss: 9.90724857e-07
Iter: 1062 loss: 9.9044064e-07
Iter: 1063 loss: 9.90380613e-07
Iter: 1064 loss: 9.90155513e-07
Iter: 1065 loss: 9.93608523e-07
Iter: 1066 loss: 9.90172111e-07
Iter: 1067 loss: 9.89926548e-07
Iter: 1068 loss: 9.89516366e-07
Iter: 1069 loss: 9.89495447e-07
Iter: 1070 loss: 9.89097884e-07
Iter: 1071 loss: 9.8912e-07
Iter: 1072 loss: 9.88744432e-07
Iter: 1073 loss: 9.88084366e-07
Iter: 1074 loss: 9.89623e-07
Iter: 1075 loss: 9.87852e-07
Iter: 1076 loss: 9.8726855e-07
Iter: 1077 loss: 9.90784201e-07
Iter: 1078 loss: 9.87182602e-07
Iter: 1079 loss: 9.86814598e-07
Iter: 1080 loss: 9.86778105e-07
Iter: 1081 loss: 9.86610075e-07
Iter: 1082 loss: 9.86233658e-07
Iter: 1083 loss: 9.92121613e-07
Iter: 1084 loss: 9.86185569e-07
Iter: 1085 loss: 9.857647e-07
Iter: 1086 loss: 9.91397656e-07
Iter: 1087 loss: 9.85780389e-07
Iter: 1088 loss: 9.85458655e-07
Iter: 1089 loss: 9.86013447e-07
Iter: 1090 loss: 9.85288239e-07
Iter: 1091 loss: 9.84940357e-07
Iter: 1092 loss: 9.85331553e-07
Iter: 1093 loss: 9.84788585e-07
Iter: 1094 loss: 9.84418e-07
Iter: 1095 loss: 9.87714e-07
Iter: 1096 loss: 9.84391e-07
Iter: 1097 loss: 9.84055873e-07
Iter: 1098 loss: 9.83682639e-07
Iter: 1099 loss: 9.8362807e-07
Iter: 1100 loss: 9.83173209e-07
Iter: 1101 loss: 9.86179316e-07
Iter: 1102 loss: 9.83138193e-07
Iter: 1103 loss: 9.82755523e-07
Iter: 1104 loss: 9.84677399e-07
Iter: 1105 loss: 9.82720508e-07
Iter: 1106 loss: 9.82489723e-07
Iter: 1107 loss: 9.82060669e-07
Iter: 1108 loss: 9.91162096e-07
Iter: 1109 loss: 9.8205669e-07
Iter: 1110 loss: 9.81487801e-07
Iter: 1111 loss: 9.81974381e-07
Iter: 1112 loss: 9.81179483e-07
Iter: 1113 loss: 9.80479854e-07
Iter: 1114 loss: 9.83800646e-07
Iter: 1115 loss: 9.80377081e-07
Iter: 1116 loss: 9.79926654e-07
Iter: 1117 loss: 9.79893684e-07
Iter: 1118 loss: 9.79602419e-07
Iter: 1119 loss: 9.79016818e-07
Iter: 1120 loss: 9.91779643e-07
Iter: 1121 loss: 9.79027845e-07
Iter: 1122 loss: 9.78496359e-07
Iter: 1123 loss: 9.82546226e-07
Iter: 1124 loss: 9.7845691e-07
Iter: 1125 loss: 9.78034109e-07
Iter: 1126 loss: 9.82230176e-07
Iter: 1127 loss: 9.7802581e-07
Iter: 1128 loss: 9.77841182e-07
Iter: 1129 loss: 9.77729542e-07
Iter: 1130 loss: 9.77675e-07
Iter: 1131 loss: 9.77329591e-07
Iter: 1132 loss: 9.79755669e-07
Iter: 1133 loss: 9.77329e-07
Iter: 1134 loss: 9.77068112e-07
Iter: 1135 loss: 9.77098239e-07
Iter: 1136 loss: 9.76865e-07
Iter: 1137 loss: 9.76548449e-07
Iter: 1138 loss: 9.76581759e-07
Iter: 1139 loss: 9.7629686e-07
Iter: 1140 loss: 9.75797434e-07
Iter: 1141 loss: 9.79252604e-07
Iter: 1142 loss: 9.75766852e-07
Iter: 1143 loss: 9.75413855e-07
Iter: 1144 loss: 9.75168e-07
Iter: 1145 loss: 9.75048579e-07
Iter: 1146 loss: 9.74579507e-07
Iter: 1147 loss: 9.75676812e-07
Iter: 1148 loss: 9.74441e-07
Iter: 1149 loss: 9.74033696e-07
Iter: 1150 loss: 9.73787337e-07
Iter: 1151 loss: 9.73607257e-07
Iter: 1152 loss: 9.7358361e-07
Iter: 1153 loss: 9.73349e-07
Iter: 1154 loss: 9.73055307e-07
Iter: 1155 loss: 9.7269708e-07
Iter: 1156 loss: 9.72670136e-07
Iter: 1157 loss: 9.72180487e-07
Iter: 1158 loss: 9.72004159e-07
Iter: 1159 loss: 9.7172483e-07
Iter: 1160 loss: 9.7154043e-07
Iter: 1161 loss: 9.713998e-07
Iter: 1162 loss: 9.7114048e-07
Iter: 1163 loss: 9.70632e-07
Iter: 1164 loss: 9.70627184e-07
Iter: 1165 loss: 9.70286692e-07
Iter: 1166 loss: 9.7438442e-07
Iter: 1167 loss: 9.7029158e-07
Iter: 1168 loss: 9.69943471e-07
Iter: 1169 loss: 9.70682322e-07
Iter: 1170 loss: 9.69845132e-07
Iter: 1171 loss: 9.69525786e-07
Iter: 1172 loss: 9.69566372e-07
Iter: 1173 loss: 9.69289e-07
Iter: 1174 loss: 9.68934273e-07
Iter: 1175 loss: 9.70691303e-07
Iter: 1176 loss: 9.68868335e-07
Iter: 1177 loss: 9.68528298e-07
Iter: 1178 loss: 9.69272e-07
Iter: 1179 loss: 9.68368e-07
Iter: 1180 loss: 9.68002496e-07
Iter: 1181 loss: 9.67503e-07
Iter: 1182 loss: 9.67452e-07
Iter: 1183 loss: 9.6683e-07
Iter: 1184 loss: 9.68807853e-07
Iter: 1185 loss: 9.66645075e-07
Iter: 1186 loss: 9.66135303e-07
Iter: 1187 loss: 9.68894938e-07
Iter: 1188 loss: 9.66055268e-07
Iter: 1189 loss: 9.6591225e-07
Iter: 1190 loss: 9.65827212e-07
Iter: 1191 loss: 9.65656227e-07
Iter: 1192 loss: 9.65243e-07
Iter: 1193 loss: 9.69375606e-07
Iter: 1194 loss: 9.65221261e-07
Iter: 1195 loss: 9.64865194e-07
Iter: 1196 loss: 9.68179847e-07
Iter: 1197 loss: 9.64842911e-07
Iter: 1198 loss: 9.64501e-07
Iter: 1199 loss: 9.66367793e-07
Iter: 1200 loss: 9.64449669e-07
Iter: 1201 loss: 9.64210813e-07
Iter: 1202 loss: 9.63949105e-07
Iter: 1203 loss: 9.63904313e-07
Iter: 1204 loss: 9.63614639e-07
Iter: 1205 loss: 9.63590765e-07
Iter: 1206 loss: 9.63383854e-07
Iter: 1207 loss: 9.63028356e-07
Iter: 1208 loss: 9.71045324e-07
Iter: 1209 loss: 9.63023e-07
Iter: 1210 loss: 9.62725608e-07
Iter: 1211 loss: 9.62719241e-07
Iter: 1212 loss: 9.62474587e-07
Iter: 1213 loss: 9.62536e-07
Iter: 1214 loss: 9.62312697e-07
Iter: 1215 loss: 9.62008357e-07
Iter: 1216 loss: 9.62393e-07
Iter: 1217 loss: 9.61848173e-07
Iter: 1218 loss: 9.61502451e-07
Iter: 1219 loss: 9.61102501e-07
Iter: 1220 loss: 9.61069077e-07
Iter: 1221 loss: 9.60477905e-07
Iter: 1222 loss: 9.64803121e-07
Iter: 1223 loss: 9.60423336e-07
Iter: 1224 loss: 9.60137072e-07
Iter: 1225 loss: 9.60096258e-07
Iter: 1226 loss: 9.59877184e-07
Iter: 1227 loss: 9.59423e-07
Iter: 1228 loss: 9.68937911e-07
Iter: 1229 loss: 9.59422778e-07
Iter: 1230 loss: 9.59030672e-07
Iter: 1231 loss: 9.60784519e-07
Iter: 1232 loss: 9.58982582e-07
Iter: 1233 loss: 9.58658802e-07
Iter: 1234 loss: 9.62943e-07
Iter: 1235 loss: 9.58657324e-07
Iter: 1236 loss: 9.58522605e-07
Iter: 1237 loss: 9.58253167e-07
Iter: 1238 loss: 9.58268e-07
Iter: 1239 loss: 9.57865609e-07
Iter: 1240 loss: 9.60901843e-07
Iter: 1241 loss: 9.5784e-07
Iter: 1242 loss: 9.57600264e-07
Iter: 1243 loss: 9.57230213e-07
Iter: 1244 loss: 9.57241127e-07
Iter: 1245 loss: 9.56916551e-07
Iter: 1246 loss: 9.60211878e-07
Iter: 1247 loss: 9.56887e-07
Iter: 1248 loss: 9.56492386e-07
Iter: 1249 loss: 9.56794793e-07
Iter: 1250 loss: 9.56298e-07
Iter: 1251 loss: 9.55965788e-07
Iter: 1252 loss: 9.56443273e-07
Iter: 1253 loss: 9.55831297e-07
Iter: 1254 loss: 9.55503879e-07
Iter: 1255 loss: 9.56641e-07
Iter: 1256 loss: 9.55402129e-07
Iter: 1257 loss: 9.55077894e-07
Iter: 1258 loss: 9.55203859e-07
Iter: 1259 loss: 9.54885536e-07
Iter: 1260 loss: 9.54638836e-07
Iter: 1261 loss: 9.54607458e-07
Iter: 1262 loss: 9.5438736e-07
Iter: 1263 loss: 9.53835524e-07
Iter: 1264 loss: 9.60686748e-07
Iter: 1265 loss: 9.53811e-07
Iter: 1266 loss: 9.53317056e-07
Iter: 1267 loss: 9.56114377e-07
Iter: 1268 loss: 9.53209508e-07
Iter: 1269 loss: 9.52831215e-07
Iter: 1270 loss: 9.52848609e-07
Iter: 1271 loss: 9.52629648e-07
Iter: 1272 loss: 9.52304958e-07
Iter: 1273 loss: 9.5229791e-07
Iter: 1274 loss: 9.52025061e-07
Iter: 1275 loss: 9.52006417e-07
Iter: 1276 loss: 9.51832e-07
Iter: 1277 loss: 9.51487095e-07
Iter: 1278 loss: 9.57579459e-07
Iter: 1279 loss: 9.51470838e-07
Iter: 1280 loss: 9.51192249e-07
Iter: 1281 loss: 9.52910625e-07
Iter: 1282 loss: 9.51157233e-07
Iter: 1283 loss: 9.50815661e-07
Iter: 1284 loss: 9.51273819e-07
Iter: 1285 loss: 9.50646495e-07
Iter: 1286 loss: 9.5036097e-07
Iter: 1287 loss: 9.49879e-07
Iter: 1288 loss: 9.6131464e-07
Iter: 1289 loss: 9.49875414e-07
Iter: 1290 loss: 9.49267871e-07
Iter: 1291 loss: 9.53633958e-07
Iter: 1292 loss: 9.49205571e-07
Iter: 1293 loss: 9.48868092e-07
Iter: 1294 loss: 9.52469406e-07
Iter: 1295 loss: 9.48869683e-07
Iter: 1296 loss: 9.48526576e-07
Iter: 1297 loss: 9.50312085e-07
Iter: 1298 loss: 9.48484399e-07
Iter: 1299 loss: 9.48285731e-07
Iter: 1300 loss: 9.48258389e-07
Iter: 1301 loss: 9.48091554e-07
Iter: 1302 loss: 9.47781871e-07
Iter: 1303 loss: 9.48013565e-07
Iter: 1304 loss: 9.47592866e-07
Iter: 1305 loss: 9.47354806e-07
Iter: 1306 loss: 9.47352362e-07
Iter: 1307 loss: 9.47163358e-07
Iter: 1308 loss: 9.46730779e-07
Iter: 1309 loss: 9.52842413e-07
Iter: 1310 loss: 9.46733792e-07
Iter: 1311 loss: 9.46481e-07
Iter: 1312 loss: 9.46437922e-07
Iter: 1313 loss: 9.46239766e-07
Iter: 1314 loss: 9.45881709e-07
Iter: 1315 loss: 9.53024369e-07
Iter: 1316 loss: 9.45867782e-07
Iter: 1317 loss: 9.45488864e-07
Iter: 1318 loss: 9.46183491e-07
Iter: 1319 loss: 9.45343174e-07
Iter: 1320 loss: 9.45195779e-07
Iter: 1321 loss: 9.45125066e-07
Iter: 1322 loss: 9.44995463e-07
Iter: 1323 loss: 9.44607052e-07
Iter: 1324 loss: 9.48303182e-07
Iter: 1325 loss: 9.44544695e-07
Iter: 1326 loss: 9.44041062e-07
Iter: 1327 loss: 9.44520139e-07
Iter: 1328 loss: 9.43743203e-07
Iter: 1329 loss: 9.43366e-07
Iter: 1330 loss: 9.49051355e-07
Iter: 1331 loss: 9.43361897e-07
Iter: 1332 loss: 9.4299628e-07
Iter: 1333 loss: 9.44328804e-07
Iter: 1334 loss: 9.42877818e-07
Iter: 1335 loss: 9.42625e-07
Iter: 1336 loss: 9.42879637e-07
Iter: 1337 loss: 9.42434951e-07
Iter: 1338 loss: 9.42153406e-07
Iter: 1339 loss: 9.43133386e-07
Iter: 1340 loss: 9.42105316e-07
Iter: 1341 loss: 9.41879478e-07
Iter: 1342 loss: 9.44504109e-07
Iter: 1343 loss: 9.41863391e-07
Iter: 1344 loss: 9.41671942e-07
Iter: 1345 loss: 9.41501412e-07
Iter: 1346 loss: 9.41464691e-07
Iter: 1347 loss: 9.4122197e-07
Iter: 1348 loss: 9.44164867e-07
Iter: 1349 loss: 9.41228166e-07
Iter: 1350 loss: 9.41020346e-07
Iter: 1351 loss: 9.4063688e-07
Iter: 1352 loss: 9.40644725e-07
Iter: 1353 loss: 9.40284849e-07
Iter: 1354 loss: 9.40263135e-07
Iter: 1355 loss: 9.39981248e-07
Iter: 1356 loss: 9.39711185e-07
Iter: 1357 loss: 9.39662357e-07
Iter: 1358 loss: 9.3944152e-07
Iter: 1359 loss: 9.39415315e-07
Iter: 1360 loss: 9.39240294e-07
Iter: 1361 loss: 9.38980861e-07
Iter: 1362 loss: 9.39034294e-07
Iter: 1363 loss: 9.38756784e-07
Iter: 1364 loss: 9.38523897e-07
Iter: 1365 loss: 9.38507071e-07
Iter: 1366 loss: 9.38296e-07
Iter: 1367 loss: 9.38052153e-07
Iter: 1368 loss: 9.38016797e-07
Iter: 1369 loss: 9.37713367e-07
Iter: 1370 loss: 9.39077836e-07
Iter: 1371 loss: 9.37615312e-07
Iter: 1372 loss: 9.37356674e-07
Iter: 1373 loss: 9.39483357e-07
Iter: 1374 loss: 9.37352354e-07
Iter: 1375 loss: 9.3707888e-07
Iter: 1376 loss: 9.37276809e-07
Iter: 1377 loss: 9.36923243e-07
Iter: 1378 loss: 9.36684273e-07
Iter: 1379 loss: 9.37837569e-07
Iter: 1380 loss: 9.36640959e-07
Iter: 1381 loss: 9.36448089e-07
Iter: 1382 loss: 9.37465245e-07
Iter: 1383 loss: 9.3638721e-07
Iter: 1384 loss: 9.36261301e-07
Iter: 1385 loss: 9.35958383e-07
Iter: 1386 loss: 9.41279325e-07
Iter: 1387 loss: 9.35934622e-07
Iter: 1388 loss: 9.35639719e-07
Iter: 1389 loss: 9.37235825e-07
Iter: 1390 loss: 9.35588901e-07
Iter: 1391 loss: 9.3528206e-07
Iter: 1392 loss: 9.37987465e-07
Iter: 1393 loss: 9.35252e-07
Iter: 1394 loss: 9.35067703e-07
Iter: 1395 loss: 9.3484357e-07
Iter: 1396 loss: 9.34812874e-07
Iter: 1397 loss: 9.34518425e-07
Iter: 1398 loss: 9.37046593e-07
Iter: 1399 loss: 9.34509615e-07
Iter: 1400 loss: 9.34193224e-07
Iter: 1401 loss: 9.34972377e-07
Iter: 1402 loss: 9.34107049e-07
Iter: 1403 loss: 9.33899344e-07
Iter: 1404 loss: 9.33821752e-07
Iter: 1405 loss: 9.3371068e-07
Iter: 1406 loss: 9.3341265e-07
Iter: 1407 loss: 9.35630283e-07
Iter: 1408 loss: 9.33373087e-07
Iter: 1409 loss: 9.33159072e-07
Iter: 1410 loss: 9.35311846e-07
Iter: 1411 loss: 9.33156571e-07
Iter: 1412 loss: 9.33008323e-07
Iter: 1413 loss: 9.32865476e-07
Iter: 1414 loss: 9.32851776e-07
Iter: 1415 loss: 9.3261076e-07
Iter: 1416 loss: 9.34940658e-07
Iter: 1417 loss: 9.32611556e-07
Iter: 1418 loss: 9.32407147e-07
Iter: 1419 loss: 9.32077739e-07
Iter: 1420 loss: 9.32076205e-07
Iter: 1421 loss: 9.31716556e-07
Iter: 1422 loss: 9.31833029e-07
Iter: 1423 loss: 9.31437398e-07
Iter: 1424 loss: 9.31138743e-07
Iter: 1425 loss: 9.31111458e-07
Iter: 1426 loss: 9.30850263e-07
Iter: 1427 loss: 9.3117967e-07
Iter: 1428 loss: 9.30698434e-07
Iter: 1429 loss: 9.30479e-07
Iter: 1430 loss: 9.30543536e-07
Iter: 1431 loss: 9.30318379e-07
Iter: 1432 loss: 9.30079295e-07
Iter: 1433 loss: 9.33953459e-07
Iter: 1434 loss: 9.30056729e-07
Iter: 1435 loss: 9.29922749e-07
Iter: 1436 loss: 9.2968935e-07
Iter: 1437 loss: 9.29687076e-07
Iter: 1438 loss: 9.29401835e-07
Iter: 1439 loss: 9.29803377e-07
Iter: 1440 loss: 9.29234261e-07
Iter: 1441 loss: 9.28949646e-07
Iter: 1442 loss: 9.33674642e-07
Iter: 1443 loss: 9.28956297e-07
Iter: 1444 loss: 9.28682198e-07
Iter: 1445 loss: 9.28844088e-07
Iter: 1446 loss: 9.28549071e-07
Iter: 1447 loss: 9.2829589e-07
Iter: 1448 loss: 9.29204475e-07
Iter: 1449 loss: 9.28219038e-07
Iter: 1450 loss: 9.279305e-07
Iter: 1451 loss: 9.28627856e-07
Iter: 1452 loss: 9.27841768e-07
Iter: 1453 loss: 9.2765606e-07
Iter: 1454 loss: 9.27437e-07
Iter: 1455 loss: 9.27398105e-07
Iter: 1456 loss: 9.27139126e-07
Iter: 1457 loss: 9.28872623e-07
Iter: 1458 loss: 9.27079e-07
Iter: 1459 loss: 9.26802784e-07
Iter: 1460 loss: 9.28816689e-07
Iter: 1461 loss: 9.26795281e-07
Iter: 1462 loss: 9.26565065e-07
Iter: 1463 loss: 9.2624748e-07
Iter: 1464 loss: 9.26234293e-07
Iter: 1465 loss: 9.26003e-07
Iter: 1466 loss: 9.26028861e-07
Iter: 1467 loss: 9.2579603e-07
Iter: 1468 loss: 9.25445192e-07
Iter: 1469 loss: 9.2542075e-07
Iter: 1470 loss: 9.25032907e-07
Iter: 1471 loss: 9.2624623e-07
Iter: 1472 loss: 9.24908e-07
Iter: 1473 loss: 9.24656661e-07
Iter: 1474 loss: 9.28507177e-07
Iter: 1475 loss: 9.2466189e-07
Iter: 1476 loss: 9.24449296e-07
Iter: 1477 loss: 9.24940196e-07
Iter: 1478 loss: 9.2436045e-07
Iter: 1479 loss: 9.24149447e-07
Iter: 1480 loss: 9.24533254e-07
Iter: 1481 loss: 9.24080496e-07
Iter: 1482 loss: 9.23862331e-07
Iter: 1483 loss: 9.25048766e-07
Iter: 1484 loss: 9.23862785e-07
Iter: 1485 loss: 9.23685434e-07
Iter: 1486 loss: 9.23354492e-07
Iter: 1487 loss: 9.23360062e-07
Iter: 1488 loss: 9.23031735e-07
Iter: 1489 loss: 9.23297648e-07
Iter: 1490 loss: 9.22804361e-07
Iter: 1491 loss: 9.22440393e-07
Iter: 1492 loss: 9.22444599e-07
Iter: 1493 loss: 9.22178856e-07
Iter: 1494 loss: 9.22438687e-07
Iter: 1495 loss: 9.22037145e-07
Iter: 1496 loss: 9.21795731e-07
Iter: 1497 loss: 9.22625304e-07
Iter: 1498 loss: 9.21747358e-07
Iter: 1499 loss: 9.21484627e-07
Iter: 1500 loss: 9.22580057e-07
Iter: 1501 loss: 9.21448304e-07
Iter: 1502 loss: 9.21319611e-07
Iter: 1503 loss: 9.20987418e-07
Iter: 1504 loss: 9.2800434e-07
Iter: 1505 loss: 9.20986281e-07
Iter: 1506 loss: 9.20628906e-07
Iter: 1507 loss: 9.23048049e-07
Iter: 1508 loss: 9.20587354e-07
Iter: 1509 loss: 9.20309446e-07
Iter: 1510 loss: 9.23152356e-07
Iter: 1511 loss: 9.2029137e-07
Iter: 1512 loss: 9.20074399e-07
Iter: 1513 loss: 9.19992658e-07
Iter: 1514 loss: 9.19874935e-07
Iter: 1515 loss: 9.19596118e-07
Iter: 1516 loss: 9.21760261e-07
Iter: 1517 loss: 9.1956133e-07
Iter: 1518 loss: 9.19323043e-07
Iter: 1519 loss: 9.19366812e-07
Iter: 1520 loss: 9.19141939e-07
Iter: 1521 loss: 9.18860451e-07
Iter: 1522 loss: 9.18867954e-07
Iter: 1523 loss: 9.18659737e-07
Iter: 1524 loss: 9.18431795e-07
Iter: 1525 loss: 9.21999231e-07
Iter: 1526 loss: 9.18433386e-07
Iter: 1527 loss: 9.1822028e-07
Iter: 1528 loss: 9.18787805e-07
Iter: 1529 loss: 9.18170485e-07
Iter: 1530 loss: 9.17974319e-07
Iter: 1531 loss: 9.17974603e-07
Iter: 1532 loss: 9.17844318e-07
Iter: 1533 loss: 9.17560328e-07
Iter: 1534 loss: 9.20086e-07
Iter: 1535 loss: 9.17557145e-07
Iter: 1536 loss: 9.17356203e-07
Iter: 1537 loss: 9.16978934e-07
Iter: 1538 loss: 9.25540576e-07
Iter: 1539 loss: 9.16971885e-07
Iter: 1540 loss: 9.16563295e-07
Iter: 1541 loss: 9.18236083e-07
Iter: 1542 loss: 9.16510658e-07
Iter: 1543 loss: 9.16233375e-07
Iter: 1544 loss: 9.16243494e-07
Iter: 1545 loss: 9.16050681e-07
Iter: 1546 loss: 9.16134468e-07
Iter: 1547 loss: 9.15916416e-07
Iter: 1548 loss: 9.1573213e-07
Iter: 1549 loss: 9.16938234e-07
Iter: 1550 loss: 9.15708824e-07
Iter: 1551 loss: 9.15524538e-07
Iter: 1552 loss: 9.15827627e-07
Iter: 1553 loss: 9.15446719e-07
Iter: 1554 loss: 9.15289831e-07
Iter: 1555 loss: 9.15071269e-07
Iter: 1556 loss: 9.15059388e-07
Iter: 1557 loss: 9.14735097e-07
Iter: 1558 loss: 9.1554e-07
Iter: 1559 loss: 9.14628345e-07
Iter: 1560 loss: 9.1432679e-07
Iter: 1561 loss: 9.17889736e-07
Iter: 1562 loss: 9.1432139e-07
Iter: 1563 loss: 9.14114253e-07
Iter: 1564 loss: 9.13948043e-07
Iter: 1565 loss: 9.13867893e-07
Iter: 1566 loss: 9.1363529e-07
Iter: 1567 loss: 9.13627e-07
Iter: 1568 loss: 9.13427527e-07
Iter: 1569 loss: 9.13219083e-07
Iter: 1570 loss: 9.13193844e-07
Iter: 1571 loss: 9.1293839e-07
Iter: 1572 loss: 9.13426334e-07
Iter: 1573 loss: 9.12850851e-07
Iter: 1574 loss: 9.12650648e-07
Iter: 1575 loss: 9.12650307e-07
Iter: 1576 loss: 9.12484381e-07
Iter: 1577 loss: 9.12488929e-07
Iter: 1578 loss: 9.12334599e-07
Iter: 1579 loss: 9.1214406e-07
Iter: 1580 loss: 9.13175086e-07
Iter: 1581 loss: 9.12103928e-07
Iter: 1582 loss: 9.11933171e-07
Iter: 1583 loss: 9.12416e-07
Iter: 1584 loss: 9.11861946e-07
Iter: 1585 loss: 9.11657594e-07
Iter: 1586 loss: 9.11285952e-07
Iter: 1587 loss: 9.20628679e-07
Iter: 1588 loss: 9.11285156e-07
Iter: 1589 loss: 9.10847234e-07
Iter: 1590 loss: 9.12974883e-07
Iter: 1591 loss: 9.10781807e-07
Iter: 1592 loss: 9.10593769e-07
Iter: 1593 loss: 9.10585129e-07
Iter: 1594 loss: 9.10416929e-07
Iter: 1595 loss: 9.10290169e-07
Iter: 1596 loss: 9.10253107e-07
Iter: 1597 loss: 9.10039034e-07
Iter: 1598 loss: 9.11681354e-07
Iter: 1599 loss: 9.10002655e-07
Iter: 1600 loss: 9.09748337e-07
Iter: 1601 loss: 9.09852702e-07
Iter: 1602 loss: 9.09574794e-07
Iter: 1603 loss: 9.09362939e-07
Iter: 1604 loss: 9.09275172e-07
Iter: 1605 loss: 9.09147559e-07
Iter: 1606 loss: 9.08892616e-07
Iter: 1607 loss: 9.12684641e-07
Iter: 1608 loss: 9.08879258e-07
Iter: 1609 loss: 9.08666493e-07
Iter: 1610 loss: 9.09562914e-07
Iter: 1611 loss: 9.08609763e-07
Iter: 1612 loss: 9.08483116e-07
Iter: 1613 loss: 9.08652e-07
Iter: 1614 loss: 9.08383356e-07
Iter: 1615 loss: 9.08184916e-07
Iter: 1616 loss: 9.08786092e-07
Iter: 1617 loss: 9.08136201e-07
Iter: 1618 loss: 9.07935259e-07
Iter: 1619 loss: 9.08040192e-07
Iter: 1620 loss: 9.07798551e-07
Iter: 1621 loss: 9.0758067e-07
Iter: 1622 loss: 9.07491199e-07
Iter: 1623 loss: 9.07385868e-07
Iter: 1624 loss: 9.07109e-07
Iter: 1625 loss: 9.10153744e-07
Iter: 1626 loss: 9.07093863e-07
Iter: 1627 loss: 9.06813739e-07
Iter: 1628 loss: 9.0749495e-07
Iter: 1629 loss: 9.06737398e-07
Iter: 1630 loss: 9.06510706e-07
Iter: 1631 loss: 9.06971422e-07
Iter: 1632 loss: 9.06448179e-07
Iter: 1633 loss: 9.06184482e-07
Iter: 1634 loss: 9.07371827e-07
Iter: 1635 loss: 9.06161631e-07
Iter: 1636 loss: 9.05965635e-07
Iter: 1637 loss: 9.05790557e-07
Iter: 1638 loss: 9.05773163e-07
Iter: 1639 loss: 9.05550564e-07
Iter: 1640 loss: 9.07319418e-07
Iter: 1641 loss: 9.05529134e-07
Iter: 1642 loss: 9.05336663e-07
Iter: 1643 loss: 9.0656431e-07
Iter: 1644 loss: 9.05313e-07
Iter: 1645 loss: 9.05154593e-07
Iter: 1646 loss: 9.05128729e-07
Iter: 1647 loss: 9.05007e-07
Iter: 1648 loss: 9.04820354e-07
Iter: 1649 loss: 9.06298169e-07
Iter: 1650 loss: 9.04811714e-07
Iter: 1651 loss: 9.04641752e-07
Iter: 1652 loss: 9.04651642e-07
Iter: 1653 loss: 9.04530566e-07
Iter: 1654 loss: 9.04281706e-07
Iter: 1655 loss: 9.04044839e-07
Iter: 1656 loss: 9.03982823e-07
Iter: 1657 loss: 9.03707928e-07
Iter: 1658 loss: 9.07146159e-07
Iter: 1659 loss: 9.03725e-07
Iter: 1660 loss: 9.03485898e-07
Iter: 1661 loss: 9.04874184e-07
Iter: 1662 loss: 9.03468845e-07
Iter: 1663 loss: 9.03304e-07
Iter: 1664 loss: 9.03268415e-07
Iter: 1665 loss: 9.03155239e-07
Iter: 1666 loss: 9.02947761e-07
Iter: 1667 loss: 9.05441937e-07
Iter: 1668 loss: 9.02943327e-07
Iter: 1669 loss: 9.02784222e-07
Iter: 1670 loss: 9.02554348e-07
Iter: 1671 loss: 9.02548379e-07
Iter: 1672 loss: 9.02298723e-07
Iter: 1673 loss: 9.03678085e-07
Iter: 1674 loss: 9.02242789e-07
Iter: 1675 loss: 9.02014961e-07
Iter: 1676 loss: 9.04678473e-07
Iter: 1677 loss: 9.02010925e-07
Iter: 1678 loss: 9.01844601e-07
Iter: 1679 loss: 9.01807709e-07
Iter: 1680 loss: 9.01729607e-07
Iter: 1681 loss: 9.0155396e-07
Iter: 1682 loss: 9.03447074e-07
Iter: 1683 loss: 9.0153668e-07
Iter: 1684 loss: 9.01428507e-07
Iter: 1685 loss: 9.01471708e-07
Iter: 1686 loss: 9.01346368e-07
Iter: 1687 loss: 9.01189935e-07
Iter: 1688 loss: 9.01204487e-07
Iter: 1689 loss: 9.01055103e-07
Iter: 1690 loss: 9.00882469e-07
Iter: 1691 loss: 9.01293674e-07
Iter: 1692 loss: 9.00807152e-07
Iter: 1693 loss: 9.00606892e-07
Iter: 1694 loss: 9.03016485e-07
Iter: 1695 loss: 9.00600071e-07
Iter: 1696 loss: 9.00451937e-07
Iter: 1697 loss: 9.00338478e-07
Iter: 1698 loss: 9.00279929e-07
Iter: 1699 loss: 9.00079272e-07
Iter: 1700 loss: 9.02780755e-07
Iter: 1701 loss: 9.00065857e-07
Iter: 1702 loss: 8.9991147e-07
Iter: 1703 loss: 8.99716724e-07
Iter: 1704 loss: 8.99681481e-07
Iter: 1705 loss: 8.99472411e-07
Iter: 1706 loss: 9.00136229e-07
Iter: 1707 loss: 8.99407382e-07
Iter: 1708 loss: 8.99216e-07
Iter: 1709 loss: 8.99223551e-07
Iter: 1710 loss: 8.99094857e-07
Iter: 1711 loss: 8.9911066e-07
Iter: 1712 loss: 8.9899379e-07
Iter: 1713 loss: 8.98858104e-07
Iter: 1714 loss: 8.99852239e-07
Iter: 1715 loss: 8.98862368e-07
Iter: 1716 loss: 8.98754536e-07
Iter: 1717 loss: 8.98702694e-07
Iter: 1718 loss: 8.98630788e-07
Iter: 1719 loss: 8.98438e-07
Iter: 1720 loss: 8.98534722e-07
Iter: 1721 loss: 8.98314966e-07
Iter: 1722 loss: 8.98098165e-07
Iter: 1723 loss: 8.98224187e-07
Iter: 1724 loss: 8.97942471e-07
Iter: 1725 loss: 8.97739369e-07
Iter: 1726 loss: 8.97733798e-07
Iter: 1727 loss: 8.97537689e-07
Iter: 1728 loss: 8.9749966e-07
Iter: 1729 loss: 8.97392681e-07
Iter: 1730 loss: 8.97241705e-07
Iter: 1731 loss: 8.9724108e-07
Iter: 1732 loss: 8.97126483e-07
Iter: 1733 loss: 8.97050768e-07
Iter: 1734 loss: 8.96989377e-07
Iter: 1735 loss: 8.96841584e-07
Iter: 1736 loss: 8.96994095e-07
Iter: 1737 loss: 8.96769393e-07
Iter: 1738 loss: 8.96647521e-07
Iter: 1739 loss: 8.9665491e-07
Iter: 1740 loss: 8.96532413e-07
Iter: 1741 loss: 8.9647574e-07
Iter: 1742 loss: 8.96450501e-07
Iter: 1743 loss: 8.96275878e-07
Iter: 1744 loss: 8.96933045e-07
Iter: 1745 loss: 8.96244956e-07
Iter: 1746 loss: 8.96051e-07
Iter: 1747 loss: 8.96471079e-07
Iter: 1748 loss: 8.959654e-07
Iter: 1749 loss: 8.95823632e-07
Iter: 1750 loss: 8.95966252e-07
Iter: 1751 loss: 8.95727112e-07
Iter: 1752 loss: 8.95534868e-07
Iter: 1753 loss: 8.95622634e-07
Iter: 1754 loss: 8.95423398e-07
Iter: 1755 loss: 8.95281801e-07
Iter: 1756 loss: 8.95293226e-07
Iter: 1757 loss: 8.95184371e-07
Iter: 1758 loss: 8.95239168e-07
Iter: 1759 loss: 8.95091489e-07
Iter: 1760 loss: 8.94987636e-07
Iter: 1761 loss: 8.95562152e-07
Iter: 1762 loss: 8.94969958e-07
Iter: 1763 loss: 8.94838877e-07
Iter: 1764 loss: 8.94896232e-07
Iter: 1765 loss: 8.94738548e-07
Iter: 1766 loss: 8.94596326e-07
Iter: 1767 loss: 8.94476216e-07
Iter: 1768 loss: 8.94417951e-07
Iter: 1769 loss: 8.94258335e-07
Iter: 1770 loss: 8.9425032e-07
Iter: 1771 loss: 8.94076607e-07
Iter: 1772 loss: 8.94213372e-07
Iter: 1773 loss: 8.93980882e-07
Iter: 1774 loss: 8.9381615e-07
Iter: 1775 loss: 8.94482127e-07
Iter: 1776 loss: 8.9377113e-07
Iter: 1777 loss: 8.93638969e-07
Iter: 1778 loss: 8.94170739e-07
Iter: 1779 loss: 8.93586673e-07
Iter: 1780 loss: 8.93468211e-07
Iter: 1781 loss: 8.93431093e-07
Iter: 1782 loss: 8.93368565e-07
Iter: 1783 loss: 8.93180413e-07
Iter: 1784 loss: 8.93500044e-07
Iter: 1785 loss: 8.93096683e-07
Iter: 1786 loss: 8.92945934e-07
Iter: 1787 loss: 8.93688252e-07
Iter: 1788 loss: 8.92910919e-07
Iter: 1789 loss: 8.92736239e-07
Iter: 1790 loss: 8.92958042e-07
Iter: 1791 loss: 8.92626076e-07
Iter: 1792 loss: 8.92444746e-07
Iter: 1793 loss: 8.93113452e-07
Iter: 1794 loss: 8.92404387e-07
Iter: 1795 loss: 8.92188041e-07
Iter: 1796 loss: 8.93245669e-07
Iter: 1797 loss: 8.92156152e-07
Iter: 1798 loss: 8.92039111e-07
Iter: 1799 loss: 8.91886316e-07
Iter: 1800 loss: 8.91884156e-07
Iter: 1801 loss: 8.91710101e-07
Iter: 1802 loss: 8.91708623e-07
Iter: 1803 loss: 8.91573109e-07
Iter: 1804 loss: 8.91778313e-07
Iter: 1805 loss: 8.91505579e-07
Iter: 1806 loss: 8.91394336e-07
Iter: 1807 loss: 8.91560148e-07
Iter: 1808 loss: 8.9130117e-07
Iter: 1809 loss: 8.91129957e-07
Iter: 1810 loss: 8.9180719e-07
Iter: 1811 loss: 8.91097329e-07
Iter: 1812 loss: 8.90944136e-07
Iter: 1813 loss: 8.90828233e-07
Iter: 1814 loss: 8.90752744e-07
Iter: 1815 loss: 8.90536455e-07
Iter: 1816 loss: 8.91248874e-07
Iter: 1817 loss: 8.90472847e-07
Iter: 1818 loss: 8.90263038e-07
Iter: 1819 loss: 8.90834428e-07
Iter: 1820 loss: 8.90220463e-07
Iter: 1821 loss: 8.89983198e-07
Iter: 1822 loss: 8.91591299e-07
Iter: 1823 loss: 8.89976e-07
Iter: 1824 loss: 8.89832e-07
Iter: 1825 loss: 8.89916066e-07
Iter: 1826 loss: 8.89735702e-07
Iter: 1827 loss: 8.89552e-07
Iter: 1828 loss: 8.90957381e-07
Iter: 1829 loss: 8.89543117e-07
Iter: 1830 loss: 8.89418743e-07
Iter: 1831 loss: 8.89227294e-07
Iter: 1832 loss: 8.89224793e-07
Iter: 1833 loss: 8.89037437e-07
Iter: 1834 loss: 8.90926458e-07
Iter: 1835 loss: 8.89023681e-07
Iter: 1836 loss: 8.8881643e-07
Iter: 1837 loss: 8.89729563e-07
Iter: 1838 loss: 8.88790453e-07
Iter: 1839 loss: 8.88651e-07
Iter: 1840 loss: 8.88747081e-07
Iter: 1841 loss: 8.88551199e-07
Iter: 1842 loss: 8.88364639e-07
Iter: 1843 loss: 8.89388104e-07
Iter: 1844 loss: 8.88343266e-07
Iter: 1845 loss: 8.88218551e-07
Iter: 1846 loss: 8.88140562e-07
Iter: 1847 loss: 8.88077921e-07
Iter: 1848 loss: 8.87877547e-07
Iter: 1849 loss: 8.88397835e-07
Iter: 1850 loss: 8.87805072e-07
Iter: 1851 loss: 8.87624537e-07
Iter: 1852 loss: 8.87851627e-07
Iter: 1853 loss: 8.87535691e-07
Iter: 1854 loss: 8.87325825e-07
Iter: 1855 loss: 8.89448529e-07
Iter: 1856 loss: 8.87325e-07
Iter: 1857 loss: 8.87158e-07
Iter: 1858 loss: 8.87089641e-07
Iter: 1859 loss: 8.87006536e-07
Iter: 1860 loss: 8.86842088e-07
Iter: 1861 loss: 8.89744797e-07
Iter: 1862 loss: 8.86837029e-07
Iter: 1863 loss: 8.86711291e-07
Iter: 1864 loss: 8.86475107e-07
Iter: 1865 loss: 8.91378249e-07
Iter: 1866 loss: 8.86471128e-07
Iter: 1867 loss: 8.86234602e-07
Iter: 1868 loss: 8.87867486e-07
Iter: 1869 loss: 8.86223859e-07
Iter: 1870 loss: 8.8604213e-07
Iter: 1871 loss: 8.88582576e-07
Iter: 1872 loss: 8.86050941e-07
Iter: 1873 loss: 8.85949248e-07
Iter: 1874 loss: 8.85858526e-07
Iter: 1875 loss: 8.85837721e-07
Iter: 1876 loss: 8.85655709e-07
Iter: 1877 loss: 8.86679231e-07
Iter: 1878 loss: 8.85605061e-07
Iter: 1879 loss: 8.85465511e-07
Iter: 1880 loss: 8.85404575e-07
Iter: 1881 loss: 8.85314591e-07
Iter: 1882 loss: 8.85101088e-07
Iter: 1883 loss: 8.85403097e-07
Iter: 1884 loss: 8.84995075e-07
Iter: 1885 loss: 8.84701308e-07
Iter: 1886 loss: 8.85430723e-07
Iter: 1887 loss: 8.84616725e-07
Iter: 1888 loss: 8.84411861e-07
Iter: 1889 loss: 8.84409587e-07
Iter: 1890 loss: 8.84258327e-07
Iter: 1891 loss: 8.84093e-07
Iter: 1892 loss: 8.84079668e-07
Iter: 1893 loss: 8.83934831e-07
Iter: 1894 loss: 8.83926e-07
Iter: 1895 loss: 8.83800681e-07
Iter: 1896 loss: 8.83606219e-07
Iter: 1897 loss: 8.87836336e-07
Iter: 1898 loss: 8.83607072e-07
Iter: 1899 loss: 8.83395842e-07
Iter: 1900 loss: 8.83358723e-07
Iter: 1901 loss: 8.83199e-07
Iter: 1902 loss: 8.82968834e-07
Iter: 1903 loss: 8.82945301e-07
Iter: 1904 loss: 8.82792222e-07
Iter: 1905 loss: 8.82589e-07
Iter: 1906 loss: 8.82567065e-07
Iter: 1907 loss: 8.82275e-07
Iter: 1908 loss: 8.84122528e-07
Iter: 1909 loss: 8.82266477e-07
Iter: 1910 loss: 8.82055701e-07
Iter: 1911 loss: 8.82089466e-07
Iter: 1912 loss: 8.81901542e-07
Iter: 1913 loss: 8.81660185e-07
Iter: 1914 loss: 8.82231802e-07
Iter: 1915 loss: 8.81560709e-07
Iter: 1916 loss: 8.81348512e-07
Iter: 1917 loss: 8.81604365e-07
Iter: 1918 loss: 8.81248297e-07
Iter: 1919 loss: 8.80979e-07
Iter: 1920 loss: 8.8343819e-07
Iter: 1921 loss: 8.8098335e-07
Iter: 1922 loss: 8.80773428e-07
Iter: 1923 loss: 8.80695268e-07
Iter: 1924 loss: 8.80557423e-07
Iter: 1925 loss: 8.80297648e-07
Iter: 1926 loss: 8.82586278e-07
Iter: 1927 loss: 8.8029492e-07
Iter: 1928 loss: 8.80000812e-07
Iter: 1929 loss: 8.7989406e-07
Iter: 1930 loss: 8.79757181e-07
Iter: 1931 loss: 8.79476261e-07
Iter: 1932 loss: 8.79565221e-07
Iter: 1933 loss: 8.79297886e-07
Iter: 1934 loss: 8.79238769e-07
Iter: 1935 loss: 8.79142817e-07
Iter: 1936 loss: 8.79027198e-07
Iter: 1937 loss: 8.78877756e-07
Iter: 1938 loss: 8.78838534e-07
Iter: 1939 loss: 8.78667834e-07
Iter: 1940 loss: 8.80210791e-07
Iter: 1941 loss: 8.78657147e-07
Iter: 1942 loss: 8.78521348e-07
Iter: 1943 loss: 8.783731e-07
Iter: 1944 loss: 8.78345e-07
Iter: 1945 loss: 8.78112814e-07
Iter: 1946 loss: 8.78704441e-07
Iter: 1947 loss: 8.78001401e-07
Iter: 1948 loss: 8.77728e-07
Iter: 1949 loss: 8.78194101e-07
Iter: 1950 loss: 8.77598779e-07
Iter: 1951 loss: 8.77376465e-07
Iter: 1952 loss: 8.79308971e-07
Iter: 1953 loss: 8.77375442e-07
Iter: 1954 loss: 8.77147215e-07
Iter: 1955 loss: 8.77692116e-07
Iter: 1956 loss: 8.77062575e-07
Iter: 1957 loss: 8.76889032e-07
Iter: 1958 loss: 8.77090201e-07
Iter: 1959 loss: 8.76817069e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6
+ date
Mon Oct 26 09:53:53 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 1.6 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c0211158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c01de620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c01ded90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05d8045e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05d80612f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c016ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c012b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c00dd0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c00ddd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c00dd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c0070950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c00736a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c0073730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c0070378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05c0004510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574729b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f057475c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f057475c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574701048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574701bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05746c7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05746c7510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574653950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05746bdb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05746c7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574614378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05745add90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574577730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574584510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574584e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0574556ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05745246a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05745142f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05744b87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05744d89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05744d82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.30889457e-05
Iter: 2 loss: 1.08680106e-05
Iter: 3 loss: 1.06477892e-05
Iter: 4 loss: 9.88498687e-06
Iter: 5 loss: 1.11310883e-05
Iter: 6 loss: 9.53620838e-06
Iter: 7 loss: 8.80932112e-06
Iter: 8 loss: 1.47709452e-05
Iter: 9 loss: 8.76401373e-06
Iter: 10 loss: 8.39600943e-06
Iter: 11 loss: 8.21706635e-06
Iter: 12 loss: 8.04012598e-06
Iter: 13 loss: 7.59607155e-06
Iter: 14 loss: 9.63393177e-06
Iter: 15 loss: 7.51203561e-06
Iter: 16 loss: 7.01697e-06
Iter: 17 loss: 8.10544771e-06
Iter: 18 loss: 6.82702557e-06
Iter: 19 loss: 6.47633397e-06
Iter: 20 loss: 6.9525081e-06
Iter: 21 loss: 6.30035083e-06
Iter: 22 loss: 5.90774243e-06
Iter: 23 loss: 6.19801358e-06
Iter: 24 loss: 5.66636436e-06
Iter: 25 loss: 5.63555386e-06
Iter: 26 loss: 5.50003097e-06
Iter: 27 loss: 5.3893832e-06
Iter: 28 loss: 5.0890294e-06
Iter: 29 loss: 7.0050437e-06
Iter: 30 loss: 5.01265367e-06
Iter: 31 loss: 4.69380029e-06
Iter: 32 loss: 7.54258735e-06
Iter: 33 loss: 4.67844529e-06
Iter: 34 loss: 4.46335707e-06
Iter: 35 loss: 4.31184435e-06
Iter: 36 loss: 4.23571237e-06
Iter: 37 loss: 3.95847474e-06
Iter: 38 loss: 6.04892239e-06
Iter: 39 loss: 3.93710934e-06
Iter: 40 loss: 3.75518766e-06
Iter: 41 loss: 6.14613555e-06
Iter: 42 loss: 3.75418085e-06
Iter: 43 loss: 3.59807495e-06
Iter: 44 loss: 4.0190771e-06
Iter: 45 loss: 3.54665417e-06
Iter: 46 loss: 3.44409136e-06
Iter: 47 loss: 3.99454075e-06
Iter: 48 loss: 3.42863268e-06
Iter: 49 loss: 3.3341596e-06
Iter: 50 loss: 4.00951421e-06
Iter: 51 loss: 3.32590275e-06
Iter: 52 loss: 3.27241696e-06
Iter: 53 loss: 3.28029182e-06
Iter: 54 loss: 3.23190488e-06
Iter: 55 loss: 3.14823455e-06
Iter: 56 loss: 3.40968722e-06
Iter: 57 loss: 3.12397469e-06
Iter: 58 loss: 3.05554204e-06
Iter: 59 loss: 3.03160687e-06
Iter: 60 loss: 2.99292333e-06
Iter: 61 loss: 2.89955824e-06
Iter: 62 loss: 3.17706736e-06
Iter: 63 loss: 2.87110493e-06
Iter: 64 loss: 2.79186224e-06
Iter: 65 loss: 2.83974396e-06
Iter: 66 loss: 2.7407948e-06
Iter: 67 loss: 2.66617e-06
Iter: 68 loss: 2.66274628e-06
Iter: 69 loss: 2.62515186e-06
Iter: 70 loss: 2.6001253e-06
Iter: 71 loss: 2.58598834e-06
Iter: 72 loss: 2.52965333e-06
Iter: 73 loss: 2.4833048e-06
Iter: 74 loss: 2.46688478e-06
Iter: 75 loss: 2.3936127e-06
Iter: 76 loss: 2.75858065e-06
Iter: 77 loss: 2.38121083e-06
Iter: 78 loss: 2.33099308e-06
Iter: 79 loss: 2.98203577e-06
Iter: 80 loss: 2.33070455e-06
Iter: 81 loss: 2.29655302e-06
Iter: 82 loss: 2.54219367e-06
Iter: 83 loss: 2.29357829e-06
Iter: 84 loss: 2.26201291e-06
Iter: 85 loss: 2.22683639e-06
Iter: 86 loss: 2.22198764e-06
Iter: 87 loss: 2.22564881e-06
Iter: 88 loss: 2.20510969e-06
Iter: 89 loss: 2.19165236e-06
Iter: 90 loss: 2.16062153e-06
Iter: 91 loss: 2.55604164e-06
Iter: 92 loss: 2.15839464e-06
Iter: 93 loss: 2.12159284e-06
Iter: 94 loss: 2.49967434e-06
Iter: 95 loss: 2.12053351e-06
Iter: 96 loss: 2.09923837e-06
Iter: 97 loss: 2.11780048e-06
Iter: 98 loss: 2.0867185e-06
Iter: 99 loss: 2.06139657e-06
Iter: 100 loss: 2.03305945e-06
Iter: 101 loss: 2.02923e-06
Iter: 102 loss: 1.99558053e-06
Iter: 103 loss: 2.29912939e-06
Iter: 104 loss: 1.9940403e-06
Iter: 105 loss: 1.97015947e-06
Iter: 106 loss: 2.25360282e-06
Iter: 107 loss: 1.96984411e-06
Iter: 108 loss: 1.9535205e-06
Iter: 109 loss: 1.93700635e-06
Iter: 110 loss: 1.93379219e-06
Iter: 111 loss: 1.90954847e-06
Iter: 112 loss: 1.91348909e-06
Iter: 113 loss: 1.89132243e-06
Iter: 114 loss: 1.86019884e-06
Iter: 115 loss: 1.9700251e-06
Iter: 116 loss: 1.85222643e-06
Iter: 117 loss: 1.82848646e-06
Iter: 118 loss: 2.08313986e-06
Iter: 119 loss: 1.82796964e-06
Iter: 120 loss: 1.80699658e-06
Iter: 121 loss: 1.90330604e-06
Iter: 122 loss: 1.80299457e-06
Iter: 123 loss: 1.78966422e-06
Iter: 124 loss: 1.81468783e-06
Iter: 125 loss: 1.78400182e-06
Iter: 126 loss: 1.77346817e-06
Iter: 127 loss: 1.77337108e-06
Iter: 128 loss: 1.76543313e-06
Iter: 129 loss: 1.74718912e-06
Iter: 130 loss: 1.98215594e-06
Iter: 131 loss: 1.74589445e-06
Iter: 132 loss: 1.72703335e-06
Iter: 133 loss: 1.72702937e-06
Iter: 134 loss: 1.71817499e-06
Iter: 135 loss: 1.70537919e-06
Iter: 136 loss: 1.70499038e-06
Iter: 137 loss: 1.68660449e-06
Iter: 138 loss: 1.74153388e-06
Iter: 139 loss: 1.68105271e-06
Iter: 140 loss: 1.6672642e-06
Iter: 141 loss: 1.71947454e-06
Iter: 142 loss: 1.66394443e-06
Iter: 143 loss: 1.6490402e-06
Iter: 144 loss: 1.76076151e-06
Iter: 145 loss: 1.64787889e-06
Iter: 146 loss: 1.64069934e-06
Iter: 147 loss: 1.63172251e-06
Iter: 148 loss: 1.63100276e-06
Iter: 149 loss: 1.61608318e-06
Iter: 150 loss: 1.62848073e-06
Iter: 151 loss: 1.60719151e-06
Iter: 152 loss: 1.59161664e-06
Iter: 153 loss: 1.63138611e-06
Iter: 154 loss: 1.58620924e-06
Iter: 155 loss: 1.57452746e-06
Iter: 156 loss: 1.57401132e-06
Iter: 157 loss: 1.56701071e-06
Iter: 158 loss: 1.5689676e-06
Iter: 159 loss: 1.56193255e-06
Iter: 160 loss: 1.55557677e-06
Iter: 161 loss: 1.55552891e-06
Iter: 162 loss: 1.55013618e-06
Iter: 163 loss: 1.54421309e-06
Iter: 164 loss: 1.54333566e-06
Iter: 165 loss: 1.5378389e-06
Iter: 166 loss: 1.60404011e-06
Iter: 167 loss: 1.53774783e-06
Iter: 168 loss: 1.53226438e-06
Iter: 169 loss: 1.52153279e-06
Iter: 170 loss: 1.7348832e-06
Iter: 171 loss: 1.52144207e-06
Iter: 172 loss: 1.51188124e-06
Iter: 173 loss: 1.56632086e-06
Iter: 174 loss: 1.51052859e-06
Iter: 175 loss: 1.50199685e-06
Iter: 176 loss: 1.51928043e-06
Iter: 177 loss: 1.49854441e-06
Iter: 178 loss: 1.49149469e-06
Iter: 179 loss: 1.60074205e-06
Iter: 180 loss: 1.49152174e-06
Iter: 181 loss: 1.48605011e-06
Iter: 182 loss: 1.48001732e-06
Iter: 183 loss: 1.47914398e-06
Iter: 184 loss: 1.47060246e-06
Iter: 185 loss: 1.47952051e-06
Iter: 186 loss: 1.46589696e-06
Iter: 187 loss: 1.45652871e-06
Iter: 188 loss: 1.46913749e-06
Iter: 189 loss: 1.45183901e-06
Iter: 190 loss: 1.44532032e-06
Iter: 191 loss: 1.44519151e-06
Iter: 192 loss: 1.43905731e-06
Iter: 193 loss: 1.45080128e-06
Iter: 194 loss: 1.43645502e-06
Iter: 195 loss: 1.43217721e-06
Iter: 196 loss: 1.48319793e-06
Iter: 197 loss: 1.43211673e-06
Iter: 198 loss: 1.42769147e-06
Iter: 199 loss: 1.42308534e-06
Iter: 200 loss: 1.42225895e-06
Iter: 201 loss: 1.41658688e-06
Iter: 202 loss: 1.44385876e-06
Iter: 203 loss: 1.41561179e-06
Iter: 204 loss: 1.40964573e-06
Iter: 205 loss: 1.42361773e-06
Iter: 206 loss: 1.4074177e-06
Iter: 207 loss: 1.40246323e-06
Iter: 208 loss: 1.39862948e-06
Iter: 209 loss: 1.39710573e-06
Iter: 210 loss: 1.39178474e-06
Iter: 211 loss: 1.42392048e-06
Iter: 212 loss: 1.39113661e-06
Iter: 213 loss: 1.38572409e-06
Iter: 214 loss: 1.41154931e-06
Iter: 215 loss: 1.38477287e-06
Iter: 216 loss: 1.37952736e-06
Iter: 217 loss: 1.39295503e-06
Iter: 218 loss: 1.37769837e-06
Iter: 219 loss: 1.37280028e-06
Iter: 220 loss: 1.36650215e-06
Iter: 221 loss: 1.36604399e-06
Iter: 222 loss: 1.35857795e-06
Iter: 223 loss: 1.38583187e-06
Iter: 224 loss: 1.35670916e-06
Iter: 225 loss: 1.34937409e-06
Iter: 226 loss: 1.38090957e-06
Iter: 227 loss: 1.34786274e-06
Iter: 228 loss: 1.34426296e-06
Iter: 229 loss: 1.34404434e-06
Iter: 230 loss: 1.34116931e-06
Iter: 231 loss: 1.3404092e-06
Iter: 232 loss: 1.33863819e-06
Iter: 233 loss: 1.33297704e-06
Iter: 234 loss: 1.35133405e-06
Iter: 235 loss: 1.3313205e-06
Iter: 236 loss: 1.32898947e-06
Iter: 237 loss: 1.33020171e-06
Iter: 238 loss: 1.32754167e-06
Iter: 239 loss: 1.32372543e-06
Iter: 240 loss: 1.33660581e-06
Iter: 241 loss: 1.32268246e-06
Iter: 242 loss: 1.31965362e-06
Iter: 243 loss: 1.31830666e-06
Iter: 244 loss: 1.31676779e-06
Iter: 245 loss: 1.31212119e-06
Iter: 246 loss: 1.31063621e-06
Iter: 247 loss: 1.30792114e-06
Iter: 248 loss: 1.30466833e-06
Iter: 249 loss: 1.30398951e-06
Iter: 250 loss: 1.30096726e-06
Iter: 251 loss: 1.30128478e-06
Iter: 252 loss: 1.29860939e-06
Iter: 253 loss: 1.294208e-06
Iter: 254 loss: 1.29799093e-06
Iter: 255 loss: 1.29159571e-06
Iter: 256 loss: 1.28782744e-06
Iter: 257 loss: 1.29113198e-06
Iter: 258 loss: 1.28561749e-06
Iter: 259 loss: 1.28045383e-06
Iter: 260 loss: 1.29427542e-06
Iter: 261 loss: 1.27881549e-06
Iter: 262 loss: 1.27562691e-06
Iter: 263 loss: 1.27554551e-06
Iter: 264 loss: 1.27255294e-06
Iter: 265 loss: 1.27434055e-06
Iter: 266 loss: 1.27060366e-06
Iter: 267 loss: 1.26698785e-06
Iter: 268 loss: 1.29524733e-06
Iter: 269 loss: 1.26671102e-06
Iter: 270 loss: 1.26460623e-06
Iter: 271 loss: 1.26094585e-06
Iter: 272 loss: 1.26093369e-06
Iter: 273 loss: 1.25821271e-06
Iter: 274 loss: 1.25808037e-06
Iter: 275 loss: 1.25606152e-06
Iter: 276 loss: 1.25275085e-06
Iter: 277 loss: 1.2527538e-06
Iter: 278 loss: 1.24932899e-06
Iter: 279 loss: 1.25387226e-06
Iter: 280 loss: 1.24762153e-06
Iter: 281 loss: 1.24404835e-06
Iter: 282 loss: 1.27814451e-06
Iter: 283 loss: 1.24389248e-06
Iter: 284 loss: 1.24100336e-06
Iter: 285 loss: 1.25960685e-06
Iter: 286 loss: 1.24067515e-06
Iter: 287 loss: 1.23868222e-06
Iter: 288 loss: 1.23580139e-06
Iter: 289 loss: 1.23577502e-06
Iter: 290 loss: 1.23142809e-06
Iter: 291 loss: 1.24748794e-06
Iter: 292 loss: 1.23033988e-06
Iter: 293 loss: 1.22774918e-06
Iter: 294 loss: 1.23121686e-06
Iter: 295 loss: 1.22645736e-06
Iter: 296 loss: 1.22349206e-06
Iter: 297 loss: 1.24800863e-06
Iter: 298 loss: 1.223357e-06
Iter: 299 loss: 1.22105257e-06
Iter: 300 loss: 1.24657447e-06
Iter: 301 loss: 1.22100391e-06
Iter: 302 loss: 1.21954645e-06
Iter: 303 loss: 1.22109327e-06
Iter: 304 loss: 1.21874837e-06
Iter: 305 loss: 1.21664209e-06
Iter: 306 loss: 1.21654102e-06
Iter: 307 loss: 1.21501125e-06
Iter: 308 loss: 1.21329663e-06
Iter: 309 loss: 1.22159804e-06
Iter: 310 loss: 1.21297069e-06
Iter: 311 loss: 1.21047196e-06
Iter: 312 loss: 1.20786717e-06
Iter: 313 loss: 1.20740742e-06
Iter: 314 loss: 1.20459731e-06
Iter: 315 loss: 1.20814127e-06
Iter: 316 loss: 1.20313723e-06
Iter: 317 loss: 1.19963499e-06
Iter: 318 loss: 1.21120752e-06
Iter: 319 loss: 1.1986042e-06
Iter: 320 loss: 1.19645506e-06
Iter: 321 loss: 1.19634194e-06
Iter: 322 loss: 1.19511526e-06
Iter: 323 loss: 1.19258584e-06
Iter: 324 loss: 1.23589848e-06
Iter: 325 loss: 1.19253991e-06
Iter: 326 loss: 1.1896235e-06
Iter: 327 loss: 1.20478978e-06
Iter: 328 loss: 1.18919456e-06
Iter: 329 loss: 1.18662103e-06
Iter: 330 loss: 1.18811568e-06
Iter: 331 loss: 1.18490959e-06
Iter: 332 loss: 1.18322259e-06
Iter: 333 loss: 1.183206e-06
Iter: 334 loss: 1.18149501e-06
Iter: 335 loss: 1.18726678e-06
Iter: 336 loss: 1.18104117e-06
Iter: 337 loss: 1.1794682e-06
Iter: 338 loss: 1.18109415e-06
Iter: 339 loss: 1.17858747e-06
Iter: 340 loss: 1.17662921e-06
Iter: 341 loss: 1.18062417e-06
Iter: 342 loss: 1.17582135e-06
Iter: 343 loss: 1.17433945e-06
Iter: 344 loss: 1.17749801e-06
Iter: 345 loss: 1.17378431e-06
Iter: 346 loss: 1.17184834e-06
Iter: 347 loss: 1.17908553e-06
Iter: 348 loss: 1.17136437e-06
Iter: 349 loss: 1.17010791e-06
Iter: 350 loss: 1.16820411e-06
Iter: 351 loss: 1.16817773e-06
Iter: 352 loss: 1.16620879e-06
Iter: 353 loss: 1.17655702e-06
Iter: 354 loss: 1.16590422e-06
Iter: 355 loss: 1.16382353e-06
Iter: 356 loss: 1.18125422e-06
Iter: 357 loss: 1.16367664e-06
Iter: 358 loss: 1.16223578e-06
Iter: 359 loss: 1.16057856e-06
Iter: 360 loss: 1.16036654e-06
Iter: 361 loss: 1.15814635e-06
Iter: 362 loss: 1.16584204e-06
Iter: 363 loss: 1.15755006e-06
Iter: 364 loss: 1.15553121e-06
Iter: 365 loss: 1.16127057e-06
Iter: 366 loss: 1.15491298e-06
Iter: 367 loss: 1.15294665e-06
Iter: 368 loss: 1.16419142e-06
Iter: 369 loss: 1.15270495e-06
Iter: 370 loss: 1.15139483e-06
Iter: 371 loss: 1.15138801e-06
Iter: 372 loss: 1.15068588e-06
Iter: 373 loss: 1.14956424e-06
Iter: 374 loss: 1.14958311e-06
Iter: 375 loss: 1.14770864e-06
Iter: 376 loss: 1.15174305e-06
Iter: 377 loss: 1.14692148e-06
Iter: 378 loss: 1.14547129e-06
Iter: 379 loss: 1.14909813e-06
Iter: 380 loss: 1.14499562e-06
Iter: 381 loss: 1.14329828e-06
Iter: 382 loss: 1.15057526e-06
Iter: 383 loss: 1.14297507e-06
Iter: 384 loss: 1.14155876e-06
Iter: 385 loss: 1.14056604e-06
Iter: 386 loss: 1.14007776e-06
Iter: 387 loss: 1.13818601e-06
Iter: 388 loss: 1.13952342e-06
Iter: 389 loss: 1.13703152e-06
Iter: 390 loss: 1.13609349e-06
Iter: 391 loss: 1.13565125e-06
Iter: 392 loss: 1.13490285e-06
Iter: 393 loss: 1.13338035e-06
Iter: 394 loss: 1.16149329e-06
Iter: 395 loss: 1.13338979e-06
Iter: 396 loss: 1.13131171e-06
Iter: 397 loss: 1.13462488e-06
Iter: 398 loss: 1.13037834e-06
Iter: 399 loss: 1.12880821e-06
Iter: 400 loss: 1.13805368e-06
Iter: 401 loss: 1.12861426e-06
Iter: 402 loss: 1.12713133e-06
Iter: 403 loss: 1.13490228e-06
Iter: 404 loss: 1.12684017e-06
Iter: 405 loss: 1.12537009e-06
Iter: 406 loss: 1.13660496e-06
Iter: 407 loss: 1.12525299e-06
Iter: 408 loss: 1.12434395e-06
Iter: 409 loss: 1.12321993e-06
Iter: 410 loss: 1.12315502e-06
Iter: 411 loss: 1.1214546e-06
Iter: 412 loss: 1.13430201e-06
Iter: 413 loss: 1.12137377e-06
Iter: 414 loss: 1.12043688e-06
Iter: 415 loss: 1.1200475e-06
Iter: 416 loss: 1.11956774e-06
Iter: 417 loss: 1.11771647e-06
Iter: 418 loss: 1.12494706e-06
Iter: 419 loss: 1.11732618e-06
Iter: 420 loss: 1.11603651e-06
Iter: 421 loss: 1.11665565e-06
Iter: 422 loss: 1.11520478e-06
Iter: 423 loss: 1.11383e-06
Iter: 424 loss: 1.11416352e-06
Iter: 425 loss: 1.11283464e-06
Iter: 426 loss: 1.11140537e-06
Iter: 427 loss: 1.11137047e-06
Iter: 428 loss: 1.11051645e-06
Iter: 429 loss: 1.10920928e-06
Iter: 430 loss: 1.10917256e-06
Iter: 431 loss: 1.10766018e-06
Iter: 432 loss: 1.11023792e-06
Iter: 433 loss: 1.10698693e-06
Iter: 434 loss: 1.10521819e-06
Iter: 435 loss: 1.1100542e-06
Iter: 436 loss: 1.10457984e-06
Iter: 437 loss: 1.10374594e-06
Iter: 438 loss: 1.10360861e-06
Iter: 439 loss: 1.10266933e-06
Iter: 440 loss: 1.10262272e-06
Iter: 441 loss: 1.10194856e-06
Iter: 442 loss: 1.10091025e-06
Iter: 443 loss: 1.10274823e-06
Iter: 444 loss: 1.10048427e-06
Iter: 445 loss: 1.09946404e-06
Iter: 446 loss: 1.10550559e-06
Iter: 447 loss: 1.09931398e-06
Iter: 448 loss: 1.098506e-06
Iter: 449 loss: 1.0983465e-06
Iter: 450 loss: 1.09775215e-06
Iter: 451 loss: 1.09675943e-06
Iter: 452 loss: 1.10812312e-06
Iter: 453 loss: 1.09672669e-06
Iter: 454 loss: 1.09589598e-06
Iter: 455 loss: 1.09371808e-06
Iter: 456 loss: 1.11046518e-06
Iter: 457 loss: 1.09330438e-06
Iter: 458 loss: 1.09192979e-06
Iter: 459 loss: 1.09190239e-06
Iter: 460 loss: 1.09086773e-06
Iter: 461 loss: 1.10016799e-06
Iter: 462 loss: 1.09081088e-06
Iter: 463 loss: 1.09000916e-06
Iter: 464 loss: 1.08920653e-06
Iter: 465 loss: 1.08906329e-06
Iter: 466 loss: 1.08793188e-06
Iter: 467 loss: 1.08733104e-06
Iter: 468 loss: 1.08682923e-06
Iter: 469 loss: 1.08535664e-06
Iter: 470 loss: 1.10282861e-06
Iter: 471 loss: 1.08534846e-06
Iter: 472 loss: 1.08451638e-06
Iter: 473 loss: 1.08450809e-06
Iter: 474 loss: 1.08373638e-06
Iter: 475 loss: 1.08264385e-06
Iter: 476 loss: 1.08260156e-06
Iter: 477 loss: 1.0815894e-06
Iter: 478 loss: 1.08939992e-06
Iter: 479 loss: 1.08150562e-06
Iter: 480 loss: 1.08065728e-06
Iter: 481 loss: 1.0814781e-06
Iter: 482 loss: 1.08014137e-06
Iter: 483 loss: 1.07884955e-06
Iter: 484 loss: 1.07923915e-06
Iter: 485 loss: 1.07793312e-06
Iter: 486 loss: 1.0768141e-06
Iter: 487 loss: 1.07679466e-06
Iter: 488 loss: 1.07611845e-06
Iter: 489 loss: 1.07464189e-06
Iter: 490 loss: 1.09571056e-06
Iter: 491 loss: 1.07455321e-06
Iter: 492 loss: 1.07310677e-06
Iter: 493 loss: 1.08260372e-06
Iter: 494 loss: 1.07300389e-06
Iter: 495 loss: 1.07171559e-06
Iter: 496 loss: 1.08425183e-06
Iter: 497 loss: 1.07170024e-06
Iter: 498 loss: 1.07081291e-06
Iter: 499 loss: 1.07038147e-06
Iter: 500 loss: 1.069973e-06
Iter: 501 loss: 1.06882794e-06
Iter: 502 loss: 1.06751929e-06
Iter: 503 loss: 1.0673491e-06
Iter: 504 loss: 1.0664138e-06
Iter: 505 loss: 1.06631364e-06
Iter: 506 loss: 1.06548941e-06
Iter: 507 loss: 1.07399455e-06
Iter: 508 loss: 1.06546418e-06
Iter: 509 loss: 1.06488301e-06
Iter: 510 loss: 1.06394623e-06
Iter: 511 loss: 1.06395737e-06
Iter: 512 loss: 1.0628919e-06
Iter: 513 loss: 1.06895254e-06
Iter: 514 loss: 1.06276229e-06
Iter: 515 loss: 1.06172524e-06
Iter: 516 loss: 1.06363677e-06
Iter: 517 loss: 1.06124435e-06
Iter: 518 loss: 1.06038078e-06
Iter: 519 loss: 1.06470281e-06
Iter: 520 loss: 1.060204e-06
Iter: 521 loss: 1.05937306e-06
Iter: 522 loss: 1.06097718e-06
Iter: 523 loss: 1.05902677e-06
Iter: 524 loss: 1.05807464e-06
Iter: 525 loss: 1.05781521e-06
Iter: 526 loss: 1.0571689e-06
Iter: 527 loss: 1.05615095e-06
Iter: 528 loss: 1.0576706e-06
Iter: 529 loss: 1.0556596e-06
Iter: 530 loss: 1.05458844e-06
Iter: 531 loss: 1.05459367e-06
Iter: 532 loss: 1.0538505e-06
Iter: 533 loss: 1.0531337e-06
Iter: 534 loss: 1.05299284e-06
Iter: 535 loss: 1.05192544e-06
Iter: 536 loss: 1.05229219e-06
Iter: 537 loss: 1.05112781e-06
Iter: 538 loss: 1.04993319e-06
Iter: 539 loss: 1.056472e-06
Iter: 540 loss: 1.04975857e-06
Iter: 541 loss: 1.04908099e-06
Iter: 542 loss: 1.04898686e-06
Iter: 543 loss: 1.04859805e-06
Iter: 544 loss: 1.04757066e-06
Iter: 545 loss: 1.05751144e-06
Iter: 546 loss: 1.04743401e-06
Iter: 547 loss: 1.04645278e-06
Iter: 548 loss: 1.06002074e-06
Iter: 549 loss: 1.04644278e-06
Iter: 550 loss: 1.04565993e-06
Iter: 551 loss: 1.04622075e-06
Iter: 552 loss: 1.04518699e-06
Iter: 553 loss: 1.04416813e-06
Iter: 554 loss: 1.04719788e-06
Iter: 555 loss: 1.04386106e-06
Iter: 556 loss: 1.04299204e-06
Iter: 557 loss: 1.04751939e-06
Iter: 558 loss: 1.04285846e-06
Iter: 559 loss: 1.04215269e-06
Iter: 560 loss: 1.04134438e-06
Iter: 561 loss: 1.04121432e-06
Iter: 562 loss: 1.04003379e-06
Iter: 563 loss: 1.04579908e-06
Iter: 564 loss: 1.03982234e-06
Iter: 565 loss: 1.03908337e-06
Iter: 566 loss: 1.0479032e-06
Iter: 567 loss: 1.03905904e-06
Iter: 568 loss: 1.03827972e-06
Iter: 569 loss: 1.03706543e-06
Iter: 570 loss: 1.03703746e-06
Iter: 571 loss: 1.03571119e-06
Iter: 572 loss: 1.03689649e-06
Iter: 573 loss: 1.03489708e-06
Iter: 574 loss: 1.03347361e-06
Iter: 575 loss: 1.04373748e-06
Iter: 576 loss: 1.03337868e-06
Iter: 577 loss: 1.03341108e-06
Iter: 578 loss: 1.03294792e-06
Iter: 579 loss: 1.03264324e-06
Iter: 580 loss: 1.03169759e-06
Iter: 581 loss: 1.03332377e-06
Iter: 582 loss: 1.0310597e-06
Iter: 583 loss: 1.03032892e-06
Iter: 584 loss: 1.03028128e-06
Iter: 585 loss: 1.02948229e-06
Iter: 586 loss: 1.03061484e-06
Iter: 587 loss: 1.0290787e-06
Iter: 588 loss: 1.02825311e-06
Iter: 589 loss: 1.03052196e-06
Iter: 590 loss: 1.02800573e-06
Iter: 591 loss: 1.02729962e-06
Iter: 592 loss: 1.0310539e-06
Iter: 593 loss: 1.02715899e-06
Iter: 594 loss: 1.02642991e-06
Iter: 595 loss: 1.02564229e-06
Iter: 596 loss: 1.02550644e-06
Iter: 597 loss: 1.02435638e-06
Iter: 598 loss: 1.02767751e-06
Iter: 599 loss: 1.02400975e-06
Iter: 600 loss: 1.02287e-06
Iter: 601 loss: 1.03471393e-06
Iter: 602 loss: 1.02285298e-06
Iter: 603 loss: 1.02207332e-06
Iter: 604 loss: 1.02440958e-06
Iter: 605 loss: 1.02186345e-06
Iter: 606 loss: 1.02142178e-06
Iter: 607 loss: 1.02014724e-06
Iter: 608 loss: 1.02710987e-06
Iter: 609 loss: 1.019764e-06
Iter: 610 loss: 1.01846069e-06
Iter: 611 loss: 1.0184333e-06
Iter: 612 loss: 1.01789669e-06
Iter: 613 loss: 1.01783212e-06
Iter: 614 loss: 1.01738055e-06
Iter: 615 loss: 1.01639603e-06
Iter: 616 loss: 1.03017646e-06
Iter: 617 loss: 1.01633054e-06
Iter: 618 loss: 1.01551063e-06
Iter: 619 loss: 1.01561216e-06
Iter: 620 loss: 1.01487603e-06
Iter: 621 loss: 1.01436672e-06
Iter: 622 loss: 1.01418584e-06
Iter: 623 loss: 1.01371393e-06
Iter: 624 loss: 1.01286628e-06
Iter: 625 loss: 1.03335833e-06
Iter: 626 loss: 1.01285445e-06
Iter: 627 loss: 1.01211072e-06
Iter: 628 loss: 1.01210071e-06
Iter: 629 loss: 1.01147691e-06
Iter: 630 loss: 1.01122862e-06
Iter: 631 loss: 1.01088938e-06
Iter: 632 loss: 1.01017486e-06
Iter: 633 loss: 1.01280898e-06
Iter: 634 loss: 1.01001206e-06
Iter: 635 loss: 1.00930242e-06
Iter: 636 loss: 1.01655314e-06
Iter: 637 loss: 1.00927639e-06
Iter: 638 loss: 1.00859472e-06
Iter: 639 loss: 1.00799048e-06
Iter: 640 loss: 1.00785905e-06
Iter: 641 loss: 1.0070064e-06
Iter: 642 loss: 1.00873888e-06
Iter: 643 loss: 1.00669138e-06
Iter: 644 loss: 1.00584634e-06
Iter: 645 loss: 1.00939928e-06
Iter: 646 loss: 1.00568252e-06
Iter: 647 loss: 1.00508441e-06
Iter: 648 loss: 1.00506395e-06
Iter: 649 loss: 1.00460056e-06
Iter: 650 loss: 1.00366947e-06
Iter: 651 loss: 1.02180593e-06
Iter: 652 loss: 1.00365435e-06
Iter: 653 loss: 1.0027486e-06
Iter: 654 loss: 1.00500961e-06
Iter: 655 loss: 1.00247769e-06
Iter: 656 loss: 1.00160332e-06
Iter: 657 loss: 1.00258399e-06
Iter: 658 loss: 1.00108389e-06
Iter: 659 loss: 1.00039233e-06
Iter: 660 loss: 1.0003497e-06
Iter: 661 loss: 9.99964e-07
Iter: 662 loss: 9.99111194e-07
Iter: 663 loss: 1.01184196e-06
Iter: 664 loss: 9.99055715e-07
Iter: 665 loss: 9.98402584e-07
Iter: 666 loss: 9.98356427e-07
Iter: 667 loss: 9.97821871e-07
Iter: 668 loss: 9.97407e-07
Iter: 669 loss: 9.97208645e-07
Iter: 670 loss: 9.96392373e-07
Iter: 671 loss: 9.97403617e-07
Iter: 672 loss: 9.95993219e-07
Iter: 673 loss: 9.95232767e-07
Iter: 674 loss: 1.00141051e-06
Iter: 675 loss: 9.95185e-07
Iter: 676 loss: 9.94295078e-07
Iter: 677 loss: 9.95304276e-07
Iter: 678 loss: 9.93811682e-07
Iter: 679 loss: 9.93197659e-07
Iter: 680 loss: 9.93144113e-07
Iter: 681 loss: 9.92712103e-07
Iter: 682 loss: 9.92058e-07
Iter: 683 loss: 9.92048e-07
Iter: 684 loss: 9.91366164e-07
Iter: 685 loss: 9.92077617e-07
Iter: 686 loss: 9.910068e-07
Iter: 687 loss: 9.90466447e-07
Iter: 688 loss: 9.90083549e-07
Iter: 689 loss: 9.89908472e-07
Iter: 690 loss: 9.8909959e-07
Iter: 691 loss: 9.92061814e-07
Iter: 692 loss: 9.8894327e-07
Iter: 693 loss: 9.88241254e-07
Iter: 694 loss: 9.88057764e-07
Iter: 695 loss: 9.87573685e-07
Iter: 696 loss: 9.86965688e-07
Iter: 697 loss: 9.86873829e-07
Iter: 698 loss: 9.86484338e-07
Iter: 699 loss: 9.85920224e-07
Iter: 700 loss: 9.85888e-07
Iter: 701 loss: 9.85122597e-07
Iter: 702 loss: 9.85433871e-07
Iter: 703 loss: 9.84531198e-07
Iter: 704 loss: 9.83966402e-07
Iter: 705 loss: 9.83923e-07
Iter: 706 loss: 9.83448444e-07
Iter: 707 loss: 9.82604206e-07
Iter: 708 loss: 9.82598067e-07
Iter: 709 loss: 9.81949484e-07
Iter: 710 loss: 9.87729e-07
Iter: 711 loss: 9.81928792e-07
Iter: 712 loss: 9.81229505e-07
Iter: 713 loss: 9.83847826e-07
Iter: 714 loss: 9.81058406e-07
Iter: 715 loss: 9.80608093e-07
Iter: 716 loss: 9.80905384e-07
Iter: 717 loss: 9.80325126e-07
Iter: 718 loss: 9.79735319e-07
Iter: 719 loss: 9.85887709e-07
Iter: 720 loss: 9.79717697e-07
Iter: 721 loss: 9.79255105e-07
Iter: 722 loss: 9.78336288e-07
Iter: 723 loss: 9.96811423e-07
Iter: 724 loss: 9.78289791e-07
Iter: 725 loss: 9.77593231e-07
Iter: 726 loss: 9.80529e-07
Iter: 727 loss: 9.77479e-07
Iter: 728 loss: 9.76766842e-07
Iter: 729 loss: 9.78184289e-07
Iter: 730 loss: 9.76449201e-07
Iter: 731 loss: 9.75766511e-07
Iter: 732 loss: 9.75955686e-07
Iter: 733 loss: 9.75303919e-07
Iter: 734 loss: 9.7474674e-07
Iter: 735 loss: 9.74695e-07
Iter: 736 loss: 9.74259819e-07
Iter: 737 loss: 9.74760837e-07
Iter: 738 loss: 9.74017894e-07
Iter: 739 loss: 9.73499482e-07
Iter: 740 loss: 9.72358066e-07
Iter: 741 loss: 9.88810598e-07
Iter: 742 loss: 9.72332145e-07
Iter: 743 loss: 9.72054409e-07
Iter: 744 loss: 9.71738132e-07
Iter: 745 loss: 9.71225e-07
Iter: 746 loss: 9.70682549e-07
Iter: 747 loss: 9.70597739e-07
Iter: 748 loss: 9.69931079e-07
Iter: 749 loss: 9.71458689e-07
Iter: 750 loss: 9.69683697e-07
Iter: 751 loss: 9.69348548e-07
Iter: 752 loss: 9.69254188e-07
Iter: 753 loss: 9.68885388e-07
Iter: 754 loss: 9.68528411e-07
Iter: 755 loss: 9.6849476e-07
Iter: 756 loss: 9.68035465e-07
Iter: 757 loss: 9.69573307e-07
Iter: 758 loss: 9.67924507e-07
Iter: 759 loss: 9.67376309e-07
Iter: 760 loss: 9.6780775e-07
Iter: 761 loss: 9.67016149e-07
Iter: 762 loss: 9.66459424e-07
Iter: 763 loss: 9.67036385e-07
Iter: 764 loss: 9.66134849e-07
Iter: 765 loss: 9.65422828e-07
Iter: 766 loss: 9.66017183e-07
Iter: 767 loss: 9.6495819e-07
Iter: 768 loss: 9.64178639e-07
Iter: 769 loss: 9.65774461e-07
Iter: 770 loss: 9.63806656e-07
Iter: 771 loss: 9.63051889e-07
Iter: 772 loss: 9.68521135e-07
Iter: 773 loss: 9.62963213e-07
Iter: 774 loss: 9.62558715e-07
Iter: 775 loss: 9.62515287e-07
Iter: 776 loss: 9.62184458e-07
Iter: 777 loss: 9.61515e-07
Iter: 778 loss: 9.74570185e-07
Iter: 779 loss: 9.61505179e-07
Iter: 780 loss: 9.60883e-07
Iter: 781 loss: 9.6643987e-07
Iter: 782 loss: 9.60848638e-07
Iter: 783 loss: 9.60218131e-07
Iter: 784 loss: 9.61196861e-07
Iter: 785 loss: 9.59905e-07
Iter: 786 loss: 9.59373892e-07
Iter: 787 loss: 9.58908913e-07
Iter: 788 loss: 9.58801934e-07
Iter: 789 loss: 9.58789315e-07
Iter: 790 loss: 9.5841574e-07
Iter: 791 loss: 9.58099463e-07
Iter: 792 loss: 9.57644829e-07
Iter: 793 loss: 9.57632437e-07
Iter: 794 loss: 9.57077646e-07
Iter: 795 loss: 9.57788302e-07
Iter: 796 loss: 9.56859594e-07
Iter: 797 loss: 9.5625569e-07
Iter: 798 loss: 9.62866579e-07
Iter: 799 loss: 9.56234885e-07
Iter: 800 loss: 9.55917699e-07
Iter: 801 loss: 9.55531732e-07
Iter: 802 loss: 9.55482506e-07
Iter: 803 loss: 9.54847565e-07
Iter: 804 loss: 9.56332769e-07
Iter: 805 loss: 9.54659754e-07
Iter: 806 loss: 9.5398741e-07
Iter: 807 loss: 9.53814151e-07
Iter: 808 loss: 9.53426763e-07
Iter: 809 loss: 9.52864696e-07
Iter: 810 loss: 9.52834569e-07
Iter: 811 loss: 9.52277617e-07
Iter: 812 loss: 9.53159599e-07
Iter: 813 loss: 9.52032565e-07
Iter: 814 loss: 9.51448555e-07
Iter: 815 loss: 9.51314348e-07
Iter: 816 loss: 9.50964647e-07
Iter: 817 loss: 9.50624724e-07
Iter: 818 loss: 9.50589595e-07
Iter: 819 loss: 9.50272806e-07
Iter: 820 loss: 9.49712444e-07
Iter: 821 loss: 9.61653654e-07
Iter: 822 loss: 9.49704372e-07
Iter: 823 loss: 9.49059881e-07
Iter: 824 loss: 9.49591822e-07
Iter: 825 loss: 9.48702507e-07
Iter: 826 loss: 9.48457739e-07
Iter: 827 loss: 9.48234174e-07
Iter: 828 loss: 9.47908916e-07
Iter: 829 loss: 9.47431772e-07
Iter: 830 loss: 9.47399826e-07
Iter: 831 loss: 9.46910745e-07
Iter: 832 loss: 9.48640263e-07
Iter: 833 loss: 9.46798764e-07
Iter: 834 loss: 9.46208615e-07
Iter: 835 loss: 9.47405e-07
Iter: 836 loss: 9.45972772e-07
Iter: 837 loss: 9.45525358e-07
Iter: 838 loss: 9.45799911e-07
Iter: 839 loss: 9.45227043e-07
Iter: 840 loss: 9.44548447e-07
Iter: 841 loss: 9.44802252e-07
Iter: 842 loss: 9.44095063e-07
Iter: 843 loss: 9.43391115e-07
Iter: 844 loss: 9.44572776e-07
Iter: 845 loss: 9.43046643e-07
Iter: 846 loss: 9.42341956e-07
Iter: 847 loss: 9.50423043e-07
Iter: 848 loss: 9.42331098e-07
Iter: 849 loss: 9.41815586e-07
Iter: 850 loss: 9.46327646e-07
Iter: 851 loss: 9.41805752e-07
Iter: 852 loss: 9.41416431e-07
Iter: 853 loss: 9.40540588e-07
Iter: 854 loss: 9.52306209e-07
Iter: 855 loss: 9.40501138e-07
Iter: 856 loss: 9.39812821e-07
Iter: 857 loss: 9.48505431e-07
Iter: 858 loss: 9.39805659e-07
Iter: 859 loss: 9.39170434e-07
Iter: 860 loss: 9.42488441e-07
Iter: 861 loss: 9.39076813e-07
Iter: 862 loss: 9.38696e-07
Iter: 863 loss: 9.39494043e-07
Iter: 864 loss: 9.38538619e-07
Iter: 865 loss: 9.38045616e-07
Iter: 866 loss: 9.41534609e-07
Iter: 867 loss: 9.37998436e-07
Iter: 868 loss: 9.37692334e-07
Iter: 869 loss: 9.37083882e-07
Iter: 870 loss: 9.48110142e-07
Iter: 871 loss: 9.37080074e-07
Iter: 872 loss: 9.36475772e-07
Iter: 873 loss: 9.37115885e-07
Iter: 874 loss: 9.36119477e-07
Iter: 875 loss: 9.3548465e-07
Iter: 876 loss: 9.35491528e-07
Iter: 877 loss: 9.3503661e-07
Iter: 878 loss: 9.3566797e-07
Iter: 879 loss: 9.34822481e-07
Iter: 880 loss: 9.34303273e-07
Iter: 881 loss: 9.34019624e-07
Iter: 882 loss: 9.33813453e-07
Iter: 883 loss: 9.33106037e-07
Iter: 884 loss: 9.35631761e-07
Iter: 885 loss: 9.32989963e-07
Iter: 886 loss: 9.32581315e-07
Iter: 887 loss: 9.32579383e-07
Iter: 888 loss: 9.32211492e-07
Iter: 889 loss: 9.32179546e-07
Iter: 890 loss: 9.3188396e-07
Iter: 891 loss: 9.3138118e-07
Iter: 892 loss: 9.31260729e-07
Iter: 893 loss: 9.30974466e-07
Iter: 894 loss: 9.30487943e-07
Iter: 895 loss: 9.34830155e-07
Iter: 896 loss: 9.3045935e-07
Iter: 897 loss: 9.29907515e-07
Iter: 898 loss: 9.30978331e-07
Iter: 899 loss: 9.29695602e-07
Iter: 900 loss: 9.29211524e-07
Iter: 901 loss: 9.29419912e-07
Iter: 902 loss: 9.28872566e-07
Iter: 903 loss: 9.28459599e-07
Iter: 904 loss: 9.28431518e-07
Iter: 905 loss: 9.28103475e-07
Iter: 906 loss: 9.27382416e-07
Iter: 907 loss: 9.39215909e-07
Iter: 908 loss: 9.27364852e-07
Iter: 909 loss: 9.26777886e-07
Iter: 910 loss: 9.27605186e-07
Iter: 911 loss: 9.26448763e-07
Iter: 912 loss: 9.26040798e-07
Iter: 913 loss: 9.26022722e-07
Iter: 914 loss: 9.2571122e-07
Iter: 915 loss: 9.25983954e-07
Iter: 916 loss: 9.25512211e-07
Iter: 917 loss: 9.25085828e-07
Iter: 918 loss: 9.24758865e-07
Iter: 919 loss: 9.24609878e-07
Iter: 920 loss: 9.24028484e-07
Iter: 921 loss: 9.27298e-07
Iter: 922 loss: 9.23933669e-07
Iter: 923 loss: 9.23384391e-07
Iter: 924 loss: 9.27123494e-07
Iter: 925 loss: 9.23334255e-07
Iter: 926 loss: 9.22937886e-07
Iter: 927 loss: 9.22616607e-07
Iter: 928 loss: 9.22527192e-07
Iter: 929 loss: 9.219101e-07
Iter: 930 loss: 9.22039078e-07
Iter: 931 loss: 9.21416643e-07
Iter: 932 loss: 9.21158517e-07
Iter: 933 loss: 9.21027606e-07
Iter: 934 loss: 9.20743446e-07
Iter: 935 loss: 9.2024527e-07
Iter: 936 loss: 9.3067149e-07
Iter: 937 loss: 9.20232083e-07
Iter: 938 loss: 9.20091e-07
Iter: 939 loss: 9.19950423e-07
Iter: 940 loss: 9.19730724e-07
Iter: 941 loss: 9.19390686e-07
Iter: 942 loss: 9.19351e-07
Iter: 943 loss: 9.18933665e-07
Iter: 944 loss: 9.18206467e-07
Iter: 945 loss: 9.18195667e-07
Iter: 946 loss: 9.17810553e-07
Iter: 947 loss: 9.17753084e-07
Iter: 948 loss: 9.17313059e-07
Iter: 949 loss: 9.16960516e-07
Iter: 950 loss: 9.16847569e-07
Iter: 951 loss: 9.16303293e-07
Iter: 952 loss: 9.19707645e-07
Iter: 953 loss: 9.16278907e-07
Iter: 954 loss: 9.15863268e-07
Iter: 955 loss: 9.15776809e-07
Iter: 956 loss: 9.15477642e-07
Iter: 957 loss: 9.14894599e-07
Iter: 958 loss: 9.23090624e-07
Iter: 959 loss: 9.14883e-07
Iter: 960 loss: 9.14547513e-07
Iter: 961 loss: 9.14143243e-07
Iter: 962 loss: 9.14124826e-07
Iter: 963 loss: 9.13598342e-07
Iter: 964 loss: 9.15275336e-07
Iter: 965 loss: 9.1343145e-07
Iter: 966 loss: 9.12938049e-07
Iter: 967 loss: 9.16738372e-07
Iter: 968 loss: 9.12890414e-07
Iter: 969 loss: 9.12464884e-07
Iter: 970 loss: 9.11961592e-07
Iter: 971 loss: 9.11897359e-07
Iter: 972 loss: 9.11686641e-07
Iter: 973 loss: 9.11536063e-07
Iter: 974 loss: 9.11182838e-07
Iter: 975 loss: 9.10512654e-07
Iter: 976 loss: 9.23810433e-07
Iter: 977 loss: 9.10495032e-07
Iter: 978 loss: 9.0989e-07
Iter: 979 loss: 9.11928453e-07
Iter: 980 loss: 9.09742539e-07
Iter: 981 loss: 9.0943e-07
Iter: 982 loss: 9.09435641e-07
Iter: 983 loss: 9.09141249e-07
Iter: 984 loss: 9.08603397e-07
Iter: 985 loss: 9.0860118e-07
Iter: 986 loss: 9.0801359e-07
Iter: 987 loss: 9.09882033e-07
Iter: 988 loss: 9.07855281e-07
Iter: 989 loss: 9.07224774e-07
Iter: 990 loss: 9.1095643e-07
Iter: 991 loss: 9.07181629e-07
Iter: 992 loss: 9.06703e-07
Iter: 993 loss: 9.09720029e-07
Iter: 994 loss: 9.06643322e-07
Iter: 995 loss: 9.0624394e-07
Iter: 996 loss: 9.05697505e-07
Iter: 997 loss: 9.05684374e-07
Iter: 998 loss: 9.0507e-07
Iter: 999 loss: 9.08584582e-07
Iter: 1000 loss: 9.05009301e-07
Iter: 1001 loss: 9.04450815e-07
Iter: 1002 loss: 9.08492552e-07
Iter: 1003 loss: 9.04410115e-07
Iter: 1004 loss: 9.04074284e-07
Iter: 1005 loss: 9.03868568e-07
Iter: 1006 loss: 9.0374283e-07
Iter: 1007 loss: 9.03363343e-07
Iter: 1008 loss: 9.03369e-07
Iter: 1009 loss: 9.02995112e-07
Iter: 1010 loss: 9.03154955e-07
Iter: 1011 loss: 9.02685315e-07
Iter: 1012 loss: 9.02405077e-07
Iter: 1013 loss: 9.01901444e-07
Iter: 1014 loss: 9.14027396e-07
Iter: 1015 loss: 9.01915541e-07
Iter: 1016 loss: 9.01199201e-07
Iter: 1017 loss: 9.07384333e-07
Iter: 1018 loss: 9.01155545e-07
Iter: 1019 loss: 9.00558064e-07
Iter: 1020 loss: 9.02733916e-07
Iter: 1021 loss: 9.00416921e-07
Iter: 1022 loss: 8.99996849e-07
Iter: 1023 loss: 8.99316035e-07
Iter: 1024 loss: 8.99329734e-07
Iter: 1025 loss: 8.98835879e-07
Iter: 1026 loss: 8.98816154e-07
Iter: 1027 loss: 8.98436383e-07
Iter: 1028 loss: 8.99895838e-07
Iter: 1029 loss: 8.98343046e-07
Iter: 1030 loss: 8.98015344e-07
Iter: 1031 loss: 8.97960547e-07
Iter: 1032 loss: 8.97744542e-07
Iter: 1033 loss: 8.97291898e-07
Iter: 1034 loss: 8.96975507e-07
Iter: 1035 loss: 8.96848519e-07
Iter: 1036 loss: 8.96262691e-07
Iter: 1037 loss: 8.96259678e-07
Iter: 1038 loss: 8.95906908e-07
Iter: 1039 loss: 8.95757125e-07
Iter: 1040 loss: 8.95561186e-07
Iter: 1041 loss: 8.95055e-07
Iter: 1042 loss: 8.95131905e-07
Iter: 1043 loss: 8.94645268e-07
Iter: 1044 loss: 8.94634297e-07
Iter: 1045 loss: 8.944e-07
Iter: 1046 loss: 8.94125208e-07
Iter: 1047 loss: 8.93503511e-07
Iter: 1048 loss: 9.00523105e-07
Iter: 1049 loss: 8.93449851e-07
Iter: 1050 loss: 8.9298e-07
Iter: 1051 loss: 8.94202685e-07
Iter: 1052 loss: 8.92818775e-07
Iter: 1053 loss: 8.92289222e-07
Iter: 1054 loss: 8.96705728e-07
Iter: 1055 loss: 8.92257503e-07
Iter: 1056 loss: 8.91755462e-07
Iter: 1057 loss: 8.92005914e-07
Iter: 1058 loss: 8.91411e-07
Iter: 1059 loss: 8.90998763e-07
Iter: 1060 loss: 8.90490242e-07
Iter: 1061 loss: 8.90454544e-07
Iter: 1062 loss: 8.89831767e-07
Iter: 1063 loss: 8.89820399e-07
Iter: 1064 loss: 8.89461774e-07
Iter: 1065 loss: 8.9173966e-07
Iter: 1066 loss: 8.89436649e-07
Iter: 1067 loss: 8.89051137e-07
Iter: 1068 loss: 8.89141461e-07
Iter: 1069 loss: 8.88807904e-07
Iter: 1070 loss: 8.88412274e-07
Iter: 1071 loss: 8.8841773e-07
Iter: 1072 loss: 8.88111572e-07
Iter: 1073 loss: 8.87646365e-07
Iter: 1074 loss: 8.93464232e-07
Iter: 1075 loss: 8.87651424e-07
Iter: 1076 loss: 8.87268641e-07
Iter: 1077 loss: 8.87791e-07
Iter: 1078 loss: 8.87124486e-07
Iter: 1079 loss: 8.86774728e-07
Iter: 1080 loss: 8.86262967e-07
Iter: 1081 loss: 8.8626183e-07
Iter: 1082 loss: 8.86311454e-07
Iter: 1083 loss: 8.85948225e-07
Iter: 1084 loss: 8.85744498e-07
Iter: 1085 loss: 8.85213865e-07
Iter: 1086 loss: 8.88369073e-07
Iter: 1087 loss: 8.85005818e-07
Iter: 1088 loss: 8.84501219e-07
Iter: 1089 loss: 8.89670162e-07
Iter: 1090 loss: 8.84480414e-07
Iter: 1091 loss: 8.84005033e-07
Iter: 1092 loss: 8.86195e-07
Iter: 1093 loss: 8.83914709e-07
Iter: 1094 loss: 8.8350464e-07
Iter: 1095 loss: 8.83056543e-07
Iter: 1096 loss: 8.82977133e-07
Iter: 1097 loss: 8.82489417e-07
Iter: 1098 loss: 8.83712119e-07
Iter: 1099 loss: 8.82295808e-07
Iter: 1100 loss: 8.81805818e-07
Iter: 1101 loss: 8.87491e-07
Iter: 1102 loss: 8.81800361e-07
Iter: 1103 loss: 8.813916e-07
Iter: 1104 loss: 8.83227926e-07
Iter: 1105 loss: 8.81334699e-07
Iter: 1106 loss: 8.8102729e-07
Iter: 1107 loss: 8.80567768e-07
Iter: 1108 loss: 8.80568e-07
Iter: 1109 loss: 8.79946811e-07
Iter: 1110 loss: 8.81163e-07
Iter: 1111 loss: 8.79710797e-07
Iter: 1112 loss: 8.79195056e-07
Iter: 1113 loss: 8.87020576e-07
Iter: 1114 loss: 8.79178e-07
Iter: 1115 loss: 8.78756964e-07
Iter: 1116 loss: 8.78922e-07
Iter: 1117 loss: 8.7846081e-07
Iter: 1118 loss: 8.78089e-07
Iter: 1119 loss: 8.79980519e-07
Iter: 1120 loss: 8.78042215e-07
Iter: 1121 loss: 8.77665e-07
Iter: 1122 loss: 8.80293e-07
Iter: 1123 loss: 8.7763749e-07
Iter: 1124 loss: 8.77429e-07
Iter: 1125 loss: 8.76922172e-07
Iter: 1126 loss: 8.81368919e-07
Iter: 1127 loss: 8.7686891e-07
Iter: 1128 loss: 8.76499939e-07
Iter: 1129 loss: 8.82400172e-07
Iter: 1130 loss: 8.76489196e-07
Iter: 1131 loss: 8.76077479e-07
Iter: 1132 loss: 8.76995e-07
Iter: 1133 loss: 8.759107e-07
Iter: 1134 loss: 8.75499438e-07
Iter: 1135 loss: 8.75381033e-07
Iter: 1136 loss: 8.75121486e-07
Iter: 1137 loss: 8.74618479e-07
Iter: 1138 loss: 8.74319539e-07
Iter: 1139 loss: 8.74070508e-07
Iter: 1140 loss: 8.73822614e-07
Iter: 1141 loss: 8.73672434e-07
Iter: 1142 loss: 8.73344e-07
Iter: 1143 loss: 8.73784415e-07
Iter: 1144 loss: 8.73207114e-07
Iter: 1145 loss: 8.72832345e-07
Iter: 1146 loss: 8.72826718e-07
Iter: 1147 loss: 8.72558758e-07
Iter: 1148 loss: 8.72111457e-07
Iter: 1149 loss: 8.72810062e-07
Iter: 1150 loss: 8.71878115e-07
Iter: 1151 loss: 8.71476118e-07
Iter: 1152 loss: 8.76478509e-07
Iter: 1153 loss: 8.71455313e-07
Iter: 1154 loss: 8.71119823e-07
Iter: 1155 loss: 8.72311773e-07
Iter: 1156 loss: 8.71008524e-07
Iter: 1157 loss: 8.70708845e-07
Iter: 1158 loss: 8.72280737e-07
Iter: 1159 loss: 8.70619374e-07
Iter: 1160 loss: 8.70308e-07
Iter: 1161 loss: 8.69691576e-07
Iter: 1162 loss: 8.82435131e-07
Iter: 1163 loss: 8.69677422e-07
Iter: 1164 loss: 8.69166e-07
Iter: 1165 loss: 8.69752739e-07
Iter: 1166 loss: 8.68896905e-07
Iter: 1167 loss: 8.68307552e-07
Iter: 1168 loss: 8.72363444e-07
Iter: 1169 loss: 8.68263157e-07
Iter: 1170 loss: 8.6791124e-07
Iter: 1171 loss: 8.71236e-07
Iter: 1172 loss: 8.67887138e-07
Iter: 1173 loss: 8.67534595e-07
Iter: 1174 loss: 8.67921926e-07
Iter: 1175 loss: 8.67334904e-07
Iter: 1176 loss: 8.67038239e-07
Iter: 1177 loss: 8.66804385e-07
Iter: 1178 loss: 8.66699622e-07
Iter: 1179 loss: 8.66180699e-07
Iter: 1180 loss: 8.69139512e-07
Iter: 1181 loss: 8.66101914e-07
Iter: 1182 loss: 8.65661377e-07
Iter: 1183 loss: 8.69501832e-07
Iter: 1184 loss: 8.65651259e-07
Iter: 1185 loss: 8.65333334e-07
Iter: 1186 loss: 8.64955325e-07
Iter: 1187 loss: 8.64917808e-07
Iter: 1188 loss: 8.64352103e-07
Iter: 1189 loss: 8.66490041e-07
Iter: 1190 loss: 8.6424177e-07
Iter: 1191 loss: 8.63926516e-07
Iter: 1192 loss: 8.68279358e-07
Iter: 1193 loss: 8.63927824e-07
Iter: 1194 loss: 8.63603248e-07
Iter: 1195 loss: 8.64312e-07
Iter: 1196 loss: 8.63496382e-07
Iter: 1197 loss: 8.63226148e-07
Iter: 1198 loss: 8.6372836e-07
Iter: 1199 loss: 8.63126559e-07
Iter: 1200 loss: 8.62829609e-07
Iter: 1201 loss: 8.62498609e-07
Iter: 1202 loss: 8.62437446e-07
Iter: 1203 loss: 8.6198088e-07
Iter: 1204 loss: 8.6275935e-07
Iter: 1205 loss: 8.61765329e-07
Iter: 1206 loss: 8.61266e-07
Iter: 1207 loss: 8.63346258e-07
Iter: 1208 loss: 8.61138915e-07
Iter: 1209 loss: 8.60723958e-07
Iter: 1210 loss: 8.66007156e-07
Iter: 1211 loss: 8.60721912e-07
Iter: 1212 loss: 8.60459636e-07
Iter: 1213 loss: 8.59975e-07
Iter: 1214 loss: 8.59968964e-07
Iter: 1215 loss: 8.59537408e-07
Iter: 1216 loss: 8.62207969e-07
Iter: 1217 loss: 8.59486136e-07
Iter: 1218 loss: 8.59062879e-07
Iter: 1219 loss: 8.62138336e-07
Iter: 1220 loss: 8.59024055e-07
Iter: 1221 loss: 8.5872432e-07
Iter: 1222 loss: 8.5882192e-07
Iter: 1223 loss: 8.58492513e-07
Iter: 1224 loss: 8.58145e-07
Iter: 1225 loss: 8.58224837e-07
Iter: 1226 loss: 8.57841769e-07
Iter: 1227 loss: 8.57475356e-07
Iter: 1228 loss: 8.57485929e-07
Iter: 1229 loss: 8.57149871e-07
Iter: 1230 loss: 8.57906855e-07
Iter: 1231 loss: 8.57019131e-07
Iter: 1232 loss: 8.56746908e-07
Iter: 1233 loss: 8.56928636e-07
Iter: 1234 loss: 8.56581664e-07
Iter: 1235 loss: 8.56189558e-07
Iter: 1236 loss: 8.56987185e-07
Iter: 1237 loss: 8.56033694e-07
Iter: 1238 loss: 8.55710823e-07
Iter: 1239 loss: 8.55409837e-07
Iter: 1240 loss: 8.55355665e-07
Iter: 1241 loss: 8.54930533e-07
Iter: 1242 loss: 8.60050704e-07
Iter: 1243 loss: 8.54906943e-07
Iter: 1244 loss: 8.54526888e-07
Iter: 1245 loss: 8.56336897e-07
Iter: 1246 loss: 8.54471295e-07
Iter: 1247 loss: 8.54089194e-07
Iter: 1248 loss: 8.53380243e-07
Iter: 1249 loss: 8.69113364e-07
Iter: 1250 loss: 8.53379447e-07
Iter: 1251 loss: 8.52937319e-07
Iter: 1252 loss: 8.5293857e-07
Iter: 1253 loss: 8.52565e-07
Iter: 1254 loss: 8.54243069e-07
Iter: 1255 loss: 8.52500705e-07
Iter: 1256 loss: 8.52192557e-07
Iter: 1257 loss: 8.52084099e-07
Iter: 1258 loss: 8.51922664e-07
Iter: 1259 loss: 8.51496281e-07
Iter: 1260 loss: 8.52476205e-07
Iter: 1261 loss: 8.51320124e-07
Iter: 1262 loss: 8.5102522e-07
Iter: 1263 loss: 8.5099316e-07
Iter: 1264 loss: 8.50758283e-07
Iter: 1265 loss: 8.50769368e-07
Iter: 1266 loss: 8.50528352e-07
Iter: 1267 loss: 8.50287051e-07
Iter: 1268 loss: 8.50922788e-07
Iter: 1269 loss: 8.50195761e-07
Iter: 1270 loss: 8.49867e-07
Iter: 1271 loss: 8.50095034e-07
Iter: 1272 loss: 8.49674848e-07
Iter: 1273 loss: 8.49327307e-07
Iter: 1274 loss: 8.49121534e-07
Iter: 1275 loss: 8.48972036e-07
Iter: 1276 loss: 8.48533602e-07
Iter: 1277 loss: 8.54634038e-07
Iter: 1278 loss: 8.4852752e-07
Iter: 1279 loss: 8.48139e-07
Iter: 1280 loss: 8.49269441e-07
Iter: 1281 loss: 8.47988417e-07
Iter: 1282 loss: 8.47659464e-07
Iter: 1283 loss: 8.47466652e-07
Iter: 1284 loss: 8.47315505e-07
Iter: 1285 loss: 8.46927492e-07
Iter: 1286 loss: 8.4985686e-07
Iter: 1287 loss: 8.46913281e-07
Iter: 1288 loss: 8.46511909e-07
Iter: 1289 loss: 8.48057141e-07
Iter: 1290 loss: 8.46388502e-07
Iter: 1291 loss: 8.46106559e-07
Iter: 1292 loss: 8.45951263e-07
Iter: 1293 loss: 8.45790794e-07
Iter: 1294 loss: 8.45411705e-07
Iter: 1295 loss: 8.48023035e-07
Iter: 1296 loss: 8.45389309e-07
Iter: 1297 loss: 8.4504245e-07
Iter: 1298 loss: 8.47714e-07
Iter: 1299 loss: 8.45037562e-07
Iter: 1300 loss: 8.44748e-07
Iter: 1301 loss: 8.44491751e-07
Iter: 1302 loss: 8.44436158e-07
Iter: 1303 loss: 8.44015233e-07
Iter: 1304 loss: 8.46650948e-07
Iter: 1305 loss: 8.43979933e-07
Iter: 1306 loss: 8.43616817e-07
Iter: 1307 loss: 8.43720386e-07
Iter: 1308 loss: 8.43368639e-07
Iter: 1309 loss: 8.42930547e-07
Iter: 1310 loss: 8.43056682e-07
Iter: 1311 loss: 8.42627401e-07
Iter: 1312 loss: 8.42346708e-07
Iter: 1313 loss: 8.42335567e-07
Iter: 1314 loss: 8.42068857e-07
Iter: 1315 loss: 8.42377858e-07
Iter: 1316 loss: 8.41947667e-07
Iter: 1317 loss: 8.41694259e-07
Iter: 1318 loss: 8.41658732e-07
Iter: 1319 loss: 8.41491556e-07
Iter: 1320 loss: 8.41110648e-07
Iter: 1321 loss: 8.42243821e-07
Iter: 1322 loss: 8.41005203e-07
Iter: 1323 loss: 8.40598773e-07
Iter: 1324 loss: 8.44272847e-07
Iter: 1325 loss: 8.4060116e-07
Iter: 1326 loss: 8.40406074e-07
Iter: 1327 loss: 8.40054213e-07
Iter: 1328 loss: 8.40070186e-07
Iter: 1329 loss: 8.39691438e-07
Iter: 1330 loss: 8.44386932e-07
Iter: 1331 loss: 8.39685072e-07
Iter: 1332 loss: 8.3933412e-07
Iter: 1333 loss: 8.40499581e-07
Iter: 1334 loss: 8.3922e-07
Iter: 1335 loss: 8.38964183e-07
Iter: 1336 loss: 8.38736298e-07
Iter: 1337 loss: 8.38648248e-07
Iter: 1338 loss: 8.38239146e-07
Iter: 1339 loss: 8.41090184e-07
Iter: 1340 loss: 8.38190772e-07
Iter: 1341 loss: 8.37864491e-07
Iter: 1342 loss: 8.37874779e-07
Iter: 1343 loss: 8.3761779e-07
Iter: 1344 loss: 8.37176231e-07
Iter: 1345 loss: 8.38052642e-07
Iter: 1346 loss: 8.37026278e-07
Iter: 1347 loss: 8.36756726e-07
Iter: 1348 loss: 8.39924496e-07
Iter: 1349 loss: 8.36750587e-07
Iter: 1350 loss: 8.3644818e-07
Iter: 1351 loss: 8.36142192e-07
Iter: 1352 loss: 8.36027141e-07
Iter: 1353 loss: 8.35666242e-07
Iter: 1354 loss: 8.36509685e-07
Iter: 1355 loss: 8.35503215e-07
Iter: 1356 loss: 8.35111905e-07
Iter: 1357 loss: 8.37138487e-07
Iter: 1358 loss: 8.35065634e-07
Iter: 1359 loss: 8.34674267e-07
Iter: 1360 loss: 8.36711e-07
Iter: 1361 loss: 8.34617367e-07
Iter: 1362 loss: 8.3437078e-07
Iter: 1363 loss: 8.34014031e-07
Iter: 1364 loss: 8.3402648e-07
Iter: 1365 loss: 8.33825709e-07
Iter: 1366 loss: 8.33761248e-07
Iter: 1367 loss: 8.33553372e-07
Iter: 1368 loss: 8.33484819e-07
Iter: 1369 loss: 8.33347542e-07
Iter: 1370 loss: 8.33071681e-07
Iter: 1371 loss: 8.32965839e-07
Iter: 1372 loss: 8.3280645e-07
Iter: 1373 loss: 8.32400929e-07
Iter: 1374 loss: 8.35806247e-07
Iter: 1375 loss: 8.32382909e-07
Iter: 1376 loss: 8.32096816e-07
Iter: 1377 loss: 8.32042e-07
Iter: 1378 loss: 8.31855118e-07
Iter: 1379 loss: 8.3144e-07
Iter: 1380 loss: 8.31841248e-07
Iter: 1381 loss: 8.31177374e-07
Iter: 1382 loss: 8.30887871e-07
Iter: 1383 loss: 8.30898898e-07
Iter: 1384 loss: 8.30576369e-07
Iter: 1385 loss: 8.30528847e-07
Iter: 1386 loss: 8.30332738e-07
Iter: 1387 loss: 8.29989176e-07
Iter: 1388 loss: 8.29816372e-07
Iter: 1389 loss: 8.29652265e-07
Iter: 1390 loss: 8.29324563e-07
Iter: 1391 loss: 8.29313194e-07
Iter: 1392 loss: 8.29027954e-07
Iter: 1393 loss: 8.29928069e-07
Iter: 1394 loss: 8.28953262e-07
Iter: 1395 loss: 8.28718385e-07
Iter: 1396 loss: 8.28314569e-07
Iter: 1397 loss: 8.2831059e-07
Iter: 1398 loss: 8.28089e-07
Iter: 1399 loss: 8.28016255e-07
Iter: 1400 loss: 8.27783765e-07
Iter: 1401 loss: 8.27369377e-07
Iter: 1402 loss: 8.27377278e-07
Iter: 1403 loss: 8.27018368e-07
Iter: 1404 loss: 8.2900317e-07
Iter: 1405 loss: 8.26981307e-07
Iter: 1406 loss: 8.2667475e-07
Iter: 1407 loss: 8.27420877e-07
Iter: 1408 loss: 8.2654833e-07
Iter: 1409 loss: 8.26233645e-07
Iter: 1410 loss: 8.26524399e-07
Iter: 1411 loss: 8.26023779e-07
Iter: 1412 loss: 8.25727966e-07
Iter: 1413 loss: 8.26633311e-07
Iter: 1414 loss: 8.25598818e-07
Iter: 1415 loss: 8.25323241e-07
Iter: 1416 loss: 8.28170641e-07
Iter: 1417 loss: 8.2530471e-07
Iter: 1418 loss: 8.25041809e-07
Iter: 1419 loss: 8.25028508e-07
Iter: 1420 loss: 8.24820177e-07
Iter: 1421 loss: 8.24504809e-07
Iter: 1422 loss: 8.24163294e-07
Iter: 1423 loss: 8.24106337e-07
Iter: 1424 loss: 8.23787786e-07
Iter: 1425 loss: 8.23784433e-07
Iter: 1426 loss: 8.23441383e-07
Iter: 1427 loss: 8.23736912e-07
Iter: 1428 loss: 8.23239702e-07
Iter: 1429 loss: 8.22913762e-07
Iter: 1430 loss: 8.23324e-07
Iter: 1431 loss: 8.22719926e-07
Iter: 1432 loss: 8.22598e-07
Iter: 1433 loss: 8.22549964e-07
Iter: 1434 loss: 8.22415586e-07
Iter: 1435 loss: 8.2207049e-07
Iter: 1436 loss: 8.24015331e-07
Iter: 1437 loss: 8.21950607e-07
Iter: 1438 loss: 8.21556284e-07
Iter: 1439 loss: 8.25192103e-07
Iter: 1440 loss: 8.21572485e-07
Iter: 1441 loss: 8.2122358e-07
Iter: 1442 loss: 8.21687422e-07
Iter: 1443 loss: 8.2104691e-07
Iter: 1444 loss: 8.20611092e-07
Iter: 1445 loss: 8.21255583e-07
Iter: 1446 loss: 8.20422315e-07
Iter: 1447 loss: 8.200617e-07
Iter: 1448 loss: 8.21092385e-07
Iter: 1449 loss: 8.19948809e-07
Iter: 1450 loss: 8.19700347e-07
Iter: 1451 loss: 8.23220773e-07
Iter: 1452 loss: 8.19677e-07
Iter: 1453 loss: 8.19478714e-07
Iter: 1454 loss: 8.19461377e-07
Iter: 1455 loss: 8.19304319e-07
Iter: 1456 loss: 8.19015e-07
Iter: 1457 loss: 8.18618332e-07
Iter: 1458 loss: 8.1861009e-07
Iter: 1459 loss: 8.18098329e-07
Iter: 1460 loss: 8.19260322e-07
Iter: 1461 loss: 8.17921375e-07
Iter: 1462 loss: 8.17386308e-07
Iter: 1463 loss: 8.22038601e-07
Iter: 1464 loss: 8.17324803e-07
Iter: 1465 loss: 8.16986528e-07
Iter: 1466 loss: 8.22531376e-07
Iter: 1467 loss: 8.16991303e-07
Iter: 1468 loss: 8.16779448e-07
Iter: 1469 loss: 8.16626368e-07
Iter: 1470 loss: 8.16549402e-07
Iter: 1471 loss: 8.16296449e-07
Iter: 1472 loss: 8.16314468e-07
Iter: 1473 loss: 8.1615508e-07
Iter: 1474 loss: 8.15794579e-07
Iter: 1475 loss: 8.18979458e-07
Iter: 1476 loss: 8.15729663e-07
Iter: 1477 loss: 8.15311751e-07
Iter: 1478 loss: 8.1805581e-07
Iter: 1479 loss: 8.15265707e-07
Iter: 1480 loss: 8.14941359e-07
Iter: 1481 loss: 8.16961574e-07
Iter: 1482 loss: 8.14893099e-07
Iter: 1483 loss: 8.14647819e-07
Iter: 1484 loss: 8.14966597e-07
Iter: 1485 loss: 8.1455164e-07
Iter: 1486 loss: 8.14224109e-07
Iter: 1487 loss: 8.14075349e-07
Iter: 1488 loss: 8.13899135e-07
Iter: 1489 loss: 8.1350322e-07
Iter: 1490 loss: 8.16434749e-07
Iter: 1491 loss: 8.13472468e-07
Iter: 1492 loss: 8.13200415e-07
Iter: 1493 loss: 8.15726366e-07
Iter: 1494 loss: 8.13197971e-07
Iter: 1495 loss: 8.1286413e-07
Iter: 1496 loss: 8.12628855e-07
Iter: 1497 loss: 8.12530516e-07
Iter: 1498 loss: 8.12193491e-07
Iter: 1499 loss: 8.12026201e-07
Iter: 1500 loss: 8.118746e-07
Iter: 1501 loss: 8.11279392e-07
Iter: 1502 loss: 8.13577344e-07
Iter: 1503 loss: 8.11140239e-07
Iter: 1504 loss: 8.10929805e-07
Iter: 1505 loss: 8.10857273e-07
Iter: 1506 loss: 8.10583344e-07
Iter: 1507 loss: 8.10437029e-07
Iter: 1508 loss: 8.10308222e-07
Iter: 1509 loss: 8.10112113e-07
Iter: 1510 loss: 8.10180211e-07
Iter: 1511 loss: 8.09944936e-07
Iter: 1512 loss: 8.09576932e-07
Iter: 1513 loss: 8.11603343e-07
Iter: 1514 loss: 8.09521339e-07
Iter: 1515 loss: 8.09242863e-07
Iter: 1516 loss: 8.09507299e-07
Iter: 1517 loss: 8.09078529e-07
Iter: 1518 loss: 8.08820971e-07
Iter: 1519 loss: 8.094446e-07
Iter: 1520 loss: 8.08701259e-07
Iter: 1521 loss: 8.08454161e-07
Iter: 1522 loss: 8.10474148e-07
Iter: 1523 loss: 8.08412e-07
Iter: 1524 loss: 8.08195125e-07
Iter: 1525 loss: 8.08057564e-07
Iter: 1526 loss: 8.07952574e-07
Iter: 1527 loss: 8.07547394e-07
Iter: 1528 loss: 8.075e-07
Iter: 1529 loss: 8.0722134e-07
Iter: 1530 loss: 8.06665639e-07
Iter: 1531 loss: 8.07481229e-07
Iter: 1532 loss: 8.06422577e-07
Iter: 1533 loss: 8.06043e-07
Iter: 1534 loss: 8.06010576e-07
Iter: 1535 loss: 8.05729201e-07
Iter: 1536 loss: 8.07016249e-07
Iter: 1537 loss: 8.05683158e-07
Iter: 1538 loss: 8.05451293e-07
Iter: 1539 loss: 8.04981198e-07
Iter: 1540 loss: 8.13994802e-07
Iter: 1541 loss: 8.0496045e-07
Iter: 1542 loss: 8.05131094e-07
Iter: 1543 loss: 8.04770366e-07
Iter: 1544 loss: 8.04647925e-07
Iter: 1545 loss: 8.04323122e-07
Iter: 1546 loss: 8.09822495e-07
Iter: 1547 loss: 8.04325452e-07
Iter: 1548 loss: 8.04050387e-07
Iter: 1549 loss: 8.04137358e-07
Iter: 1550 loss: 8.03839157e-07
Iter: 1551 loss: 8.03438184e-07
Iter: 1552 loss: 8.05561342e-07
Iter: 1553 loss: 8.03368721e-07
Iter: 1554 loss: 8.03012199e-07
Iter: 1555 loss: 8.05752222e-07
Iter: 1556 loss: 8.0299526e-07
Iter: 1557 loss: 8.02736167e-07
Iter: 1558 loss: 8.02647264e-07
Iter: 1559 loss: 8.02488444e-07
Iter: 1560 loss: 8.02161e-07
Iter: 1561 loss: 8.04434137e-07
Iter: 1562 loss: 8.02159775e-07
Iter: 1563 loss: 8.01898921e-07
Iter: 1564 loss: 8.02275e-07
Iter: 1565 loss: 8.01780402e-07
Iter: 1566 loss: 8.01487658e-07
Iter: 1567 loss: 8.01448323e-07
Iter: 1568 loss: 8.01242322e-07
Iter: 1569 loss: 8.00902626e-07
Iter: 1570 loss: 8.00844475e-07
Iter: 1571 loss: 8.00638304e-07
Iter: 1572 loss: 8.00284397e-07
Iter: 1573 loss: 8.00279736e-07
Iter: 1574 loss: 7.99951465e-07
Iter: 1575 loss: 8.00779048e-07
Iter: 1576 loss: 7.99858071e-07
Iter: 1577 loss: 7.99604436e-07
Iter: 1578 loss: 8.00573218e-07
Iter: 1579 loss: 7.99577265e-07
Iter: 1580 loss: 7.992561e-07
Iter: 1581 loss: 7.99677764e-07
Iter: 1582 loss: 7.99084773e-07
Iter: 1583 loss: 7.98882638e-07
Iter: 1584 loss: 7.98603651e-07
Iter: 1585 loss: 7.98600354e-07
Iter: 1586 loss: 7.98253666e-07
Iter: 1587 loss: 7.99937311e-07
Iter: 1588 loss: 7.9818517e-07
Iter: 1589 loss: 7.97910047e-07
Iter: 1590 loss: 7.99875579e-07
Iter: 1591 loss: 7.97850646e-07
Iter: 1592 loss: 7.97533971e-07
Iter: 1593 loss: 7.98691303e-07
Iter: 1594 loss: 7.97454845e-07
Iter: 1595 loss: 7.97248276e-07
Iter: 1596 loss: 7.97159657e-07
Iter: 1597 loss: 7.97047051e-07
Iter: 1598 loss: 7.96687971e-07
Iter: 1599 loss: 7.97242933e-07
Iter: 1600 loss: 7.96530912e-07
Iter: 1601 loss: 7.96204574e-07
Iter: 1602 loss: 7.99563054e-07
Iter: 1603 loss: 7.96179052e-07
Iter: 1604 loss: 7.9586988e-07
Iter: 1605 loss: 7.95785922e-07
Iter: 1606 loss: 7.9559004e-07
Iter: 1607 loss: 7.95265294e-07
Iter: 1608 loss: 7.95809569e-07
Iter: 1609 loss: 7.9514632e-07
Iter: 1610 loss: 7.94917696e-07
Iter: 1611 loss: 7.9489854e-07
Iter: 1612 loss: 7.9474961e-07
Iter: 1613 loss: 7.94626885e-07
Iter: 1614 loss: 7.94538551e-07
Iter: 1615 loss: 7.94271443e-07
Iter: 1616 loss: 7.96355835e-07
Iter: 1617 loss: 7.94259165e-07
Iter: 1618 loss: 7.94050436e-07
Iter: 1619 loss: 7.93731601e-07
Iter: 1620 loss: 7.93712388e-07
Iter: 1621 loss: 7.93344384e-07
Iter: 1622 loss: 7.934118e-07
Iter: 1623 loss: 7.93033564e-07
Iter: 1624 loss: 7.92896685e-07
Iter: 1625 loss: 7.9280926e-07
Iter: 1626 loss: 7.92597916e-07
Iter: 1627 loss: 7.92237643e-07
Iter: 1628 loss: 7.92237415e-07
Iter: 1629 loss: 7.9184008e-07
Iter: 1630 loss: 7.93043114e-07
Iter: 1631 loss: 7.91721845e-07
Iter: 1632 loss: 7.91457182e-07
Iter: 1633 loss: 7.93607455e-07
Iter: 1634 loss: 7.9145957e-07
Iter: 1635 loss: 7.91179446e-07
Iter: 1636 loss: 7.91520108e-07
Iter: 1637 loss: 7.91054617e-07
Iter: 1638 loss: 7.90843046e-07
Iter: 1639 loss: 7.90682066e-07
Iter: 1640 loss: 7.90599643e-07
Iter: 1641 loss: 7.90302636e-07
Iter: 1642 loss: 7.94700497e-07
Iter: 1643 loss: 7.90298145e-07
Iter: 1644 loss: 7.90062757e-07
Iter: 1645 loss: 7.91451157e-07
Iter: 1646 loss: 7.90020295e-07
Iter: 1647 loss: 7.89835269e-07
Iter: 1648 loss: 7.90024274e-07
Iter: 1649 loss: 7.89723799e-07
Iter: 1650 loss: 7.89447029e-07
Iter: 1651 loss: 7.89527235e-07
Iter: 1652 loss: 7.89266835e-07
Iter: 1653 loss: 7.88923842e-07
Iter: 1654 loss: 7.89125238e-07
Iter: 1655 loss: 7.88700333e-07
Iter: 1656 loss: 7.88341254e-07
Iter: 1657 loss: 7.89009448e-07
Iter: 1658 loss: 7.88177431e-07
Iter: 1659 loss: 7.87974898e-07
Iter: 1660 loss: 7.87953866e-07
Iter: 1661 loss: 7.87755084e-07
Iter: 1662 loss: 7.8754374e-07
Iter: 1663 loss: 7.87486442e-07
Iter: 1664 loss: 7.87196768e-07
Iter: 1665 loss: 7.87309204e-07
Iter: 1666 loss: 7.8699054e-07
Iter: 1667 loss: 7.8668e-07
Iter: 1668 loss: 7.90865954e-07
Iter: 1669 loss: 7.86673354e-07
Iter: 1670 loss: 7.86388114e-07
Iter: 1671 loss: 7.86904934e-07
Iter: 1672 loss: 7.86296482e-07
Iter: 1673 loss: 7.86050634e-07
Iter: 1674 loss: 7.85922623e-07
Iter: 1675 loss: 7.85792906e-07
Iter: 1676 loss: 7.85618113e-07
Iter: 1677 loss: 7.85592647e-07
Iter: 1678 loss: 7.85379029e-07
Iter: 1679 loss: 7.85102486e-07
Iter: 1680 loss: 7.85086399e-07
Iter: 1681 loss: 7.84876875e-07
Iter: 1682 loss: 7.84869769e-07
Iter: 1683 loss: 7.847093e-07
Iter: 1684 loss: 7.84378e-07
Iter: 1685 loss: 7.89644048e-07
Iter: 1686 loss: 7.84378756e-07
Iter: 1687 loss: 7.83994437e-07
Iter: 1688 loss: 7.85073e-07
Iter: 1689 loss: 7.83859036e-07
Iter: 1690 loss: 7.83498194e-07
Iter: 1691 loss: 7.85250904e-07
Iter: 1692 loss: 7.83434302e-07
Iter: 1693 loss: 7.83097107e-07
Iter: 1694 loss: 7.85913869e-07
Iter: 1695 loss: 7.83080395e-07
Iter: 1696 loss: 7.82838583e-07
Iter: 1697 loss: 7.82854954e-07
Iter: 1698 loss: 7.82665552e-07
Iter: 1699 loss: 7.82381846e-07
Iter: 1700 loss: 7.82148902e-07
Iter: 1701 loss: 7.82046186e-07
Iter: 1702 loss: 7.81735707e-07
Iter: 1703 loss: 7.86405963e-07
Iter: 1704 loss: 7.81741221e-07
Iter: 1705 loss: 7.81445749e-07
Iter: 1706 loss: 7.82422887e-07
Iter: 1707 loss: 7.81368e-07
Iter: 1708 loss: 7.8111e-07
Iter: 1709 loss: 7.81113783e-07
Iter: 1710 loss: 7.80882374e-07
Iter: 1711 loss: 7.80738787e-07
Iter: 1712 loss: 7.80724804e-07
Iter: 1713 loss: 7.80546316e-07
Iter: 1714 loss: 7.80339633e-07
Iter: 1715 loss: 7.8030024e-07
Iter: 1716 loss: 7.80044388e-07
Iter: 1717 loss: 7.80895789e-07
Iter: 1718 loss: 7.79999823e-07
Iter: 1719 loss: 7.79665e-07
Iter: 1720 loss: 7.80109929e-07
Iter: 1721 loss: 7.79524044e-07
Iter: 1722 loss: 7.79254492e-07
Iter: 1723 loss: 7.79054744e-07
Iter: 1724 loss: 7.78999947e-07
Iter: 1725 loss: 7.78722665e-07
Iter: 1726 loss: 7.82647817e-07
Iter: 1727 loss: 7.787296e-07
Iter: 1728 loss: 7.78519848e-07
Iter: 1729 loss: 7.79335e-07
Iter: 1730 loss: 7.7844345e-07
Iter: 1731 loss: 7.78219601e-07
Iter: 1732 loss: 7.77993137e-07
Iter: 1733 loss: 7.77961873e-07
Iter: 1734 loss: 7.77602793e-07
Iter: 1735 loss: 7.784422e-07
Iter: 1736 loss: 7.77495245e-07
Iter: 1737 loss: 7.77095408e-07
Iter: 1738 loss: 7.78040146e-07
Iter: 1739 loss: 7.76921638e-07
Iter: 1740 loss: 7.76721265e-07
Iter: 1741 loss: 7.76719162e-07
Iter: 1742 loss: 7.76518959e-07
Iter: 1743 loss: 7.76414083e-07
Iter: 1744 loss: 7.76315858e-07
Iter: 1745 loss: 7.76144304e-07
Iter: 1746 loss: 7.76139473e-07
Iter: 1747 loss: 7.75944272e-07
Iter: 1748 loss: 7.75750891e-07
Iter: 1749 loss: 7.75714057e-07
Iter: 1750 loss: 7.75487706e-07
Iter: 1751 loss: 7.76032152e-07
Iter: 1752 loss: 7.7537544e-07
Iter: 1753 loss: 7.75115154e-07
Iter: 1754 loss: 7.77212563e-07
Iter: 1755 loss: 7.75096623e-07
Iter: 1756 loss: 7.74871523e-07
Iter: 1757 loss: 7.74459409e-07
Iter: 1758 loss: 7.82267932e-07
Iter: 1759 loss: 7.74451451e-07
Iter: 1760 loss: 7.74009209e-07
Iter: 1761 loss: 7.75922501e-07
Iter: 1762 loss: 7.73914508e-07
Iter: 1763 loss: 7.73663601e-07
Iter: 1764 loss: 7.73634952e-07
Iter: 1765 loss: 7.73460556e-07
Iter: 1766 loss: 7.73157467e-07
Iter: 1767 loss: 7.7315849e-07
Iter: 1768 loss: 7.7284659e-07
Iter: 1769 loss: 7.73814861e-07
Iter: 1770 loss: 7.72785029e-07
Iter: 1771 loss: 7.72487795e-07
Iter: 1772 loss: 7.72857959e-07
Iter: 1773 loss: 7.72313342e-07
Iter: 1774 loss: 7.72005933e-07
Iter: 1775 loss: 7.76390948e-07
Iter: 1776 loss: 7.7200184e-07
Iter: 1777 loss: 7.71785153e-07
Iter: 1778 loss: 7.72472902e-07
Iter: 1779 loss: 7.71704208e-07
Iter: 1780 loss: 7.71493774e-07
Iter: 1781 loss: 7.72584144e-07
Iter: 1782 loss: 7.71426926e-07
Iter: 1783 loss: 7.71210921e-07
Iter: 1784 loss: 7.71289365e-07
Iter: 1785 loss: 7.71053692e-07
Iter: 1786 loss: 7.70817735e-07
Iter: 1787 loss: 7.70784368e-07
Iter: 1788 loss: 7.7063828e-07
Iter: 1789 loss: 7.70350425e-07
Iter: 1790 loss: 7.74009095e-07
Iter: 1791 loss: 7.70331496e-07
Iter: 1792 loss: 7.70142492e-07
Iter: 1793 loss: 7.70070471e-07
Iter: 1794 loss: 7.69985263e-07
Iter: 1795 loss: 7.69708151e-07
Iter: 1796 loss: 7.69563371e-07
Iter: 1797 loss: 7.69441499e-07
Iter: 1798 loss: 7.69329233e-07
Iter: 1799 loss: 7.69272901e-07
Iter: 1800 loss: 7.69084181e-07
Iter: 1801 loss: 7.68898076e-07
Iter: 1802 loss: 7.68857888e-07
Iter: 1803 loss: 7.68600898e-07
Iter: 1804 loss: 7.68600387e-07
Iter: 1805 loss: 7.68385291e-07
Iter: 1806 loss: 7.68057e-07
Iter: 1807 loss: 7.68910695e-07
Iter: 1808 loss: 7.67927077e-07
Iter: 1809 loss: 7.67611823e-07
Iter: 1810 loss: 7.7115908e-07
Iter: 1811 loss: 7.67610118e-07
Iter: 1812 loss: 7.67316919e-07
Iter: 1813 loss: 7.68738744e-07
Iter: 1814 loss: 7.67267522e-07
Iter: 1815 loss: 7.67068286e-07
Iter: 1816 loss: 7.67812367e-07
Iter: 1817 loss: 7.67021334e-07
Iter: 1818 loss: 7.66832613e-07
Iter: 1819 loss: 7.66624908e-07
Iter: 1820 loss: 7.66604842e-07
Iter: 1821 loss: 7.66293738e-07
Iter: 1822 loss: 7.67533606e-07
Iter: 1823 loss: 7.66258324e-07
Iter: 1824 loss: 7.65980189e-07
Iter: 1825 loss: 7.67533663e-07
Iter: 1826 loss: 7.65936818e-07
Iter: 1827 loss: 7.65694892e-07
Iter: 1828 loss: 7.65639754e-07
Iter: 1829 loss: 7.65480763e-07
Iter: 1830 loss: 7.65196603e-07
Iter: 1831 loss: 7.65777258e-07
Iter: 1832 loss: 7.65092636e-07
Iter: 1833 loss: 7.64757829e-07
Iter: 1834 loss: 7.65830691e-07
Iter: 1835 loss: 7.6467677e-07
Iter: 1836 loss: 7.6437891e-07
Iter: 1837 loss: 7.67954759e-07
Iter: 1838 loss: 7.64350148e-07
Iter: 1839 loss: 7.64224637e-07
Iter: 1840 loss: 7.63920639e-07
Iter: 1841 loss: 7.67870176e-07
Iter: 1842 loss: 7.63907337e-07
Iter: 1843 loss: 7.63512503e-07
Iter: 1844 loss: 7.64808533e-07
Iter: 1845 loss: 7.63440198e-07
Iter: 1846 loss: 7.63067533e-07
Iter: 1847 loss: 7.64845481e-07
Iter: 1848 loss: 7.62996933e-07
Iter: 1849 loss: 7.62880632e-07
Iter: 1850 loss: 7.6283311e-07
Iter: 1851 loss: 7.62714762e-07
Iter: 1852 loss: 7.62431853e-07
Iter: 1853 loss: 7.64972867e-07
Iter: 1854 loss: 7.62378704e-07
Iter: 1855 loss: 7.62107163e-07
Iter: 1856 loss: 7.66453468e-07
Iter: 1857 loss: 7.62106311e-07
Iter: 1858 loss: 7.61946069e-07
Iter: 1859 loss: 7.61808224e-07
Iter: 1860 loss: 7.61767865e-07
Iter: 1861 loss: 7.61483648e-07
Iter: 1862 loss: 7.61751039e-07
Iter: 1863 loss: 7.61343e-07
Iter: 1864 loss: 7.61047318e-07
Iter: 1865 loss: 7.63383241e-07
Iter: 1866 loss: 7.61046692e-07
Iter: 1867 loss: 7.60840067e-07
Iter: 1868 loss: 7.62116485e-07
Iter: 1869 loss: 7.60831654e-07
Iter: 1870 loss: 7.60629e-07
Iter: 1871 loss: 7.60543116e-07
Iter: 1872 loss: 7.60447733e-07
Iter: 1873 loss: 7.60152489e-07
Iter: 1874 loss: 7.60187902e-07
Iter: 1875 loss: 7.59917782e-07
Iter: 1876 loss: 7.59586101e-07
Iter: 1877 loss: 7.61571187e-07
Iter: 1878 loss: 7.59550915e-07
Iter: 1879 loss: 7.59231852e-07
Iter: 1880 loss: 7.62373418e-07
Iter: 1881 loss: 7.59225941e-07
Iter: 1882 loss: 7.59083605e-07
Iter: 1883 loss: 7.58782789e-07
Iter: 1884 loss: 7.64593494e-07
Iter: 1885 loss: 7.58774149e-07
Iter: 1886 loss: 7.58549788e-07
Iter: 1887 loss: 7.585204e-07
Iter: 1888 loss: 7.58298029e-07
Iter: 1889 loss: 7.58990097e-07
Iter: 1890 loss: 7.58231863e-07
Iter: 1891 loss: 7.58079238e-07
Iter: 1892 loss: 7.57712428e-07
Iter: 1893 loss: 7.61102228e-07
Iter: 1894 loss: 7.57649332e-07
Iter: 1895 loss: 7.57422072e-07
Iter: 1896 loss: 7.57395469e-07
Iter: 1897 loss: 7.57152065e-07
Iter: 1898 loss: 7.5734647e-07
Iter: 1899 loss: 7.56989493e-07
Iter: 1900 loss: 7.56675888e-07
Iter: 1901 loss: 7.56763882e-07
Iter: 1902 loss: 7.56465738e-07
Iter: 1903 loss: 7.56160091e-07
Iter: 1904 loss: 7.58781709e-07
Iter: 1905 loss: 7.56139059e-07
Iter: 1906 loss: 7.55950794e-07
Iter: 1907 loss: 7.56994154e-07
Iter: 1908 loss: 7.55895826e-07
Iter: 1909 loss: 7.55719043e-07
Iter: 1910 loss: 7.56179247e-07
Iter: 1911 loss: 7.55635426e-07
Iter: 1912 loss: 7.55421524e-07
Iter: 1913 loss: 7.55343081e-07
Iter: 1914 loss: 7.55261e-07
Iter: 1915 loss: 7.55100814e-07
Iter: 1916 loss: 7.55070744e-07
Iter: 1917 loss: 7.54924088e-07
Iter: 1918 loss: 7.54614348e-07
Iter: 1919 loss: 7.54612472e-07
Iter: 1920 loss: 7.54408461e-07
Iter: 1921 loss: 7.5440164e-07
Iter: 1922 loss: 7.54185066e-07
Iter: 1923 loss: 7.5384628e-07
Iter: 1924 loss: 7.53840595e-07
Iter: 1925 loss: 7.53544839e-07
Iter: 1926 loss: 7.53753397e-07
Iter: 1927 loss: 7.53379368e-07
Iter: 1928 loss: 7.53017048e-07
Iter: 1929 loss: 7.53951099e-07
Iter: 1930 loss: 7.52907511e-07
Iter: 1931 loss: 7.52700942e-07
Iter: 1932 loss: 7.5270043e-07
Iter: 1933 loss: 7.52520918e-07
Iter: 1934 loss: 7.52485221e-07
Iter: 1935 loss: 7.52402343e-07
Iter: 1936 loss: 7.52160645e-07
Iter: 1937 loss: 7.5237341e-07
Iter: 1938 loss: 7.52028086e-07
Iter: 1939 loss: 7.5177104e-07
Iter: 1940 loss: 7.52704636e-07
Iter: 1941 loss: 7.51670655e-07
Iter: 1942 loss: 7.51385699e-07
Iter: 1943 loss: 7.53333666e-07
Iter: 1944 loss: 7.51348637e-07
Iter: 1945 loss: 7.51162e-07
Iter: 1946 loss: 7.51295033e-07
Iter: 1947 loss: 7.51037476e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2
+ date
Mon Oct 26 10:04:55 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33456b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3344340d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3344bbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3344c29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3344e8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334390598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334364ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33432a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33432a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334322048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3342872f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3342a96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3342a9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33425d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3341c06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33420a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3341f51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33420dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334176950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334132048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3341328c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334120c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3340c8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3340c3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3340c3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc334071d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc33403e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3207da2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3207da158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3207f1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3207939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc32076e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc32076ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc320779a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc32072bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc32072bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.27539858e-05
Iter: 2 loss: 1.95139583e-05
Iter: 3 loss: 1.92789248e-05
Iter: 4 loss: 1.82075346e-05
Iter: 5 loss: 2.70124838e-05
Iter: 6 loss: 1.81406558e-05
Iter: 7 loss: 1.73463759e-05
Iter: 8 loss: 1.85924328e-05
Iter: 9 loss: 1.69753439e-05
Iter: 10 loss: 1.59913761e-05
Iter: 11 loss: 1.50757278e-05
Iter: 12 loss: 1.48417175e-05
Iter: 13 loss: 1.36419612e-05
Iter: 14 loss: 2.13840358e-05
Iter: 15 loss: 1.35114378e-05
Iter: 16 loss: 1.2556673e-05
Iter: 17 loss: 1.29225245e-05
Iter: 18 loss: 1.18934713e-05
Iter: 19 loss: 1.0957634e-05
Iter: 20 loss: 1.56045917e-05
Iter: 21 loss: 1.0798005e-05
Iter: 22 loss: 1.00583311e-05
Iter: 23 loss: 1.23571654e-05
Iter: 24 loss: 9.84270628e-06
Iter: 25 loss: 9.38151607e-06
Iter: 26 loss: 9.381376e-06
Iter: 27 loss: 9.09115897e-06
Iter: 28 loss: 8.63918649e-06
Iter: 29 loss: 8.63310288e-06
Iter: 30 loss: 8.04189585e-06
Iter: 31 loss: 1.03080338e-05
Iter: 32 loss: 7.90220656e-06
Iter: 33 loss: 7.4352397e-06
Iter: 34 loss: 7.80107803e-06
Iter: 35 loss: 7.15256101e-06
Iter: 36 loss: 6.76330274e-06
Iter: 37 loss: 1.16195879e-05
Iter: 38 loss: 6.75977662e-06
Iter: 39 loss: 6.60985734e-06
Iter: 40 loss: 6.58042882e-06
Iter: 41 loss: 6.45219097e-06
Iter: 42 loss: 6.41153247e-06
Iter: 43 loss: 6.33625314e-06
Iter: 44 loss: 6.13160864e-06
Iter: 45 loss: 6.41997576e-06
Iter: 46 loss: 6.03072294e-06
Iter: 47 loss: 5.86661508e-06
Iter: 48 loss: 6.08646678e-06
Iter: 49 loss: 5.78413619e-06
Iter: 50 loss: 5.58801776e-06
Iter: 51 loss: 6.14984174e-06
Iter: 52 loss: 5.52639e-06
Iter: 53 loss: 5.33598632e-06
Iter: 54 loss: 5.57541762e-06
Iter: 55 loss: 5.23772269e-06
Iter: 56 loss: 5.11081635e-06
Iter: 57 loss: 6.11945552e-06
Iter: 58 loss: 5.10219434e-06
Iter: 59 loss: 4.9782584e-06
Iter: 60 loss: 5.05030948e-06
Iter: 61 loss: 4.89790273e-06
Iter: 62 loss: 4.729804e-06
Iter: 63 loss: 5.71507326e-06
Iter: 64 loss: 4.70779378e-06
Iter: 65 loss: 4.60697493e-06
Iter: 66 loss: 4.4940839e-06
Iter: 67 loss: 4.47861521e-06
Iter: 68 loss: 4.33029163e-06
Iter: 69 loss: 5.71858e-06
Iter: 70 loss: 4.3242535e-06
Iter: 71 loss: 4.21964114e-06
Iter: 72 loss: 4.13895532e-06
Iter: 73 loss: 4.10567145e-06
Iter: 74 loss: 4.23813572e-06
Iter: 75 loss: 4.0641944e-06
Iter: 76 loss: 4.02380647e-06
Iter: 77 loss: 3.93983419e-06
Iter: 78 loss: 5.38781205e-06
Iter: 79 loss: 3.93795563e-06
Iter: 80 loss: 3.85676685e-06
Iter: 81 loss: 4.69687711e-06
Iter: 82 loss: 3.85456678e-06
Iter: 83 loss: 3.80737811e-06
Iter: 84 loss: 3.81417044e-06
Iter: 85 loss: 3.77154288e-06
Iter: 86 loss: 3.70900125e-06
Iter: 87 loss: 3.78074969e-06
Iter: 88 loss: 3.67536222e-06
Iter: 89 loss: 3.60697686e-06
Iter: 90 loss: 4.07419793e-06
Iter: 91 loss: 3.60039667e-06
Iter: 92 loss: 3.55277803e-06
Iter: 93 loss: 3.45916919e-06
Iter: 94 loss: 5.32631748e-06
Iter: 95 loss: 3.45858734e-06
Iter: 96 loss: 3.39148255e-06
Iter: 97 loss: 3.39108328e-06
Iter: 98 loss: 3.33728167e-06
Iter: 99 loss: 3.35194773e-06
Iter: 100 loss: 3.29828936e-06
Iter: 101 loss: 3.24594976e-06
Iter: 102 loss: 3.90674222e-06
Iter: 103 loss: 3.24548046e-06
Iter: 104 loss: 3.20317849e-06
Iter: 105 loss: 3.29139766e-06
Iter: 106 loss: 3.18630828e-06
Iter: 107 loss: 3.13548026e-06
Iter: 108 loss: 3.22364986e-06
Iter: 109 loss: 3.11300278e-06
Iter: 110 loss: 3.07002301e-06
Iter: 111 loss: 3.0770484e-06
Iter: 112 loss: 3.03767683e-06
Iter: 113 loss: 3.00220677e-06
Iter: 114 loss: 3.0021e-06
Iter: 115 loss: 2.96822691e-06
Iter: 116 loss: 3.17314925e-06
Iter: 117 loss: 2.96392773e-06
Iter: 118 loss: 2.94528081e-06
Iter: 119 loss: 2.98225041e-06
Iter: 120 loss: 2.9375442e-06
Iter: 121 loss: 2.91416768e-06
Iter: 122 loss: 2.87985108e-06
Iter: 123 loss: 2.8788952e-06
Iter: 124 loss: 2.83692407e-06
Iter: 125 loss: 3.0203953e-06
Iter: 126 loss: 2.82833071e-06
Iter: 127 loss: 2.80074505e-06
Iter: 128 loss: 2.98712484e-06
Iter: 129 loss: 2.79798269e-06
Iter: 130 loss: 2.77110394e-06
Iter: 131 loss: 2.73789919e-06
Iter: 132 loss: 2.73510682e-06
Iter: 133 loss: 2.70151395e-06
Iter: 134 loss: 2.86055092e-06
Iter: 135 loss: 2.69547286e-06
Iter: 136 loss: 2.65909375e-06
Iter: 137 loss: 2.71903127e-06
Iter: 138 loss: 2.64248138e-06
Iter: 139 loss: 2.61481136e-06
Iter: 140 loss: 2.92382197e-06
Iter: 141 loss: 2.61430068e-06
Iter: 142 loss: 2.58724594e-06
Iter: 143 loss: 2.62306412e-06
Iter: 144 loss: 2.5736249e-06
Iter: 145 loss: 2.54948372e-06
Iter: 146 loss: 2.67687847e-06
Iter: 147 loss: 2.5457457e-06
Iter: 148 loss: 2.52713107e-06
Iter: 149 loss: 2.50947369e-06
Iter: 150 loss: 2.50520816e-06
Iter: 151 loss: 2.50842754e-06
Iter: 152 loss: 2.4923188e-06
Iter: 153 loss: 2.4819492e-06
Iter: 154 loss: 2.46416721e-06
Iter: 155 loss: 2.4640749e-06
Iter: 156 loss: 2.44470493e-06
Iter: 157 loss: 2.55500868e-06
Iter: 158 loss: 2.44203829e-06
Iter: 159 loss: 2.42501051e-06
Iter: 160 loss: 2.42752958e-06
Iter: 161 loss: 2.41195221e-06
Iter: 162 loss: 2.39399697e-06
Iter: 163 loss: 2.38153461e-06
Iter: 164 loss: 2.37510972e-06
Iter: 165 loss: 2.35934021e-06
Iter: 166 loss: 2.35726429e-06
Iter: 167 loss: 2.34759909e-06
Iter: 168 loss: 2.32667571e-06
Iter: 169 loss: 2.6472e-06
Iter: 170 loss: 2.32593038e-06
Iter: 171 loss: 2.30524438e-06
Iter: 172 loss: 2.55105829e-06
Iter: 173 loss: 2.30494652e-06
Iter: 174 loss: 2.29234411e-06
Iter: 175 loss: 2.30666524e-06
Iter: 176 loss: 2.28548697e-06
Iter: 177 loss: 2.27193982e-06
Iter: 178 loss: 2.41584621e-06
Iter: 179 loss: 2.27158125e-06
Iter: 180 loss: 2.25933036e-06
Iter: 181 loss: 2.25297936e-06
Iter: 182 loss: 2.24726773e-06
Iter: 183 loss: 2.23274674e-06
Iter: 184 loss: 2.33860328e-06
Iter: 185 loss: 2.23154552e-06
Iter: 186 loss: 2.22372887e-06
Iter: 187 loss: 2.22365543e-06
Iter: 188 loss: 2.21609321e-06
Iter: 189 loss: 2.20417678e-06
Iter: 190 loss: 2.2040158e-06
Iter: 191 loss: 2.19322487e-06
Iter: 192 loss: 2.2522097e-06
Iter: 193 loss: 2.19168169e-06
Iter: 194 loss: 2.18030254e-06
Iter: 195 loss: 2.18978357e-06
Iter: 196 loss: 2.17359479e-06
Iter: 197 loss: 2.16393164e-06
Iter: 198 loss: 2.16496051e-06
Iter: 199 loss: 2.15645809e-06
Iter: 200 loss: 2.14272586e-06
Iter: 201 loss: 2.21254345e-06
Iter: 202 loss: 2.14044485e-06
Iter: 203 loss: 2.12843634e-06
Iter: 204 loss: 2.18173454e-06
Iter: 205 loss: 2.1260521e-06
Iter: 206 loss: 2.11633483e-06
Iter: 207 loss: 2.10643248e-06
Iter: 208 loss: 2.10463168e-06
Iter: 209 loss: 2.09006475e-06
Iter: 210 loss: 2.13825319e-06
Iter: 211 loss: 2.08605388e-06
Iter: 212 loss: 2.07126686e-06
Iter: 213 loss: 2.20224229e-06
Iter: 214 loss: 2.07055e-06
Iter: 215 loss: 2.06214418e-06
Iter: 216 loss: 2.14464922e-06
Iter: 217 loss: 2.06179129e-06
Iter: 218 loss: 2.05672859e-06
Iter: 219 loss: 2.04637035e-06
Iter: 220 loss: 2.23434108e-06
Iter: 221 loss: 2.04622938e-06
Iter: 222 loss: 2.03809782e-06
Iter: 223 loss: 2.03681134e-06
Iter: 224 loss: 2.03087529e-06
Iter: 225 loss: 2.02889169e-06
Iter: 226 loss: 2.02548154e-06
Iter: 227 loss: 2.01972625e-06
Iter: 228 loss: 2.02562296e-06
Iter: 229 loss: 2.01652347e-06
Iter: 230 loss: 2.00734758e-06
Iter: 231 loss: 2.02633646e-06
Iter: 232 loss: 2.00367708e-06
Iter: 233 loss: 1.99622082e-06
Iter: 234 loss: 2.00120439e-06
Iter: 235 loss: 1.99152646e-06
Iter: 236 loss: 1.98224529e-06
Iter: 237 loss: 2.00252771e-06
Iter: 238 loss: 1.97868121e-06
Iter: 239 loss: 1.97268332e-06
Iter: 240 loss: 2.06899585e-06
Iter: 241 loss: 1.97266854e-06
Iter: 242 loss: 1.96734663e-06
Iter: 243 loss: 1.95500888e-06
Iter: 244 loss: 2.10058579e-06
Iter: 245 loss: 1.95392727e-06
Iter: 246 loss: 1.94340714e-06
Iter: 247 loss: 2.04734624e-06
Iter: 248 loss: 1.94312724e-06
Iter: 249 loss: 1.933774e-06
Iter: 250 loss: 1.96718929e-06
Iter: 251 loss: 1.93150981e-06
Iter: 252 loss: 1.92375182e-06
Iter: 253 loss: 2.00118075e-06
Iter: 254 loss: 1.9235838e-06
Iter: 255 loss: 1.91821482e-06
Iter: 256 loss: 1.91424942e-06
Iter: 257 loss: 1.91250183e-06
Iter: 258 loss: 1.9088875e-06
Iter: 259 loss: 1.9073957e-06
Iter: 260 loss: 1.90508717e-06
Iter: 261 loss: 1.89941193e-06
Iter: 262 loss: 1.95970915e-06
Iter: 263 loss: 1.89882144e-06
Iter: 264 loss: 1.89211289e-06
Iter: 265 loss: 1.92894572e-06
Iter: 266 loss: 1.89109744e-06
Iter: 267 loss: 1.88477952e-06
Iter: 268 loss: 1.90242486e-06
Iter: 269 loss: 1.88276397e-06
Iter: 270 loss: 1.87726573e-06
Iter: 271 loss: 1.87888088e-06
Iter: 272 loss: 1.87327919e-06
Iter: 273 loss: 1.86635759e-06
Iter: 274 loss: 1.87370836e-06
Iter: 275 loss: 1.86250713e-06
Iter: 276 loss: 1.85531428e-06
Iter: 277 loss: 1.92314133e-06
Iter: 278 loss: 1.85505075e-06
Iter: 279 loss: 1.84998021e-06
Iter: 280 loss: 1.8660038e-06
Iter: 281 loss: 1.84848636e-06
Iter: 282 loss: 1.84392979e-06
Iter: 283 loss: 1.84258897e-06
Iter: 284 loss: 1.83989209e-06
Iter: 285 loss: 1.83384827e-06
Iter: 286 loss: 1.84005353e-06
Iter: 287 loss: 1.83049292e-06
Iter: 288 loss: 1.82455312e-06
Iter: 289 loss: 1.8244549e-06
Iter: 290 loss: 1.82086092e-06
Iter: 291 loss: 1.82705719e-06
Iter: 292 loss: 1.81917494e-06
Iter: 293 loss: 1.81584346e-06
Iter: 294 loss: 1.86463467e-06
Iter: 295 loss: 1.81584369e-06
Iter: 296 loss: 1.8129424e-06
Iter: 297 loss: 1.80680217e-06
Iter: 298 loss: 1.90778064e-06
Iter: 299 loss: 1.80665029e-06
Iter: 300 loss: 1.80223128e-06
Iter: 301 loss: 1.81917324e-06
Iter: 302 loss: 1.80123561e-06
Iter: 303 loss: 1.79580013e-06
Iter: 304 loss: 1.81481073e-06
Iter: 305 loss: 1.7943712e-06
Iter: 306 loss: 1.7900802e-06
Iter: 307 loss: 1.79290714e-06
Iter: 308 loss: 1.78740947e-06
Iter: 309 loss: 1.78183e-06
Iter: 310 loss: 1.78699679e-06
Iter: 311 loss: 1.77867935e-06
Iter: 312 loss: 1.77370271e-06
Iter: 313 loss: 1.8174253e-06
Iter: 314 loss: 1.77344623e-06
Iter: 315 loss: 1.76956962e-06
Iter: 316 loss: 1.77635036e-06
Iter: 317 loss: 1.76787114e-06
Iter: 318 loss: 1.76279275e-06
Iter: 319 loss: 1.76897458e-06
Iter: 320 loss: 1.76025151e-06
Iter: 321 loss: 1.75507944e-06
Iter: 322 loss: 1.74929119e-06
Iter: 323 loss: 1.74839e-06
Iter: 324 loss: 1.74572153e-06
Iter: 325 loss: 1.74436536e-06
Iter: 326 loss: 1.74054048e-06
Iter: 327 loss: 1.74290051e-06
Iter: 328 loss: 1.73800663e-06
Iter: 329 loss: 1.73433364e-06
Iter: 330 loss: 1.73429271e-06
Iter: 331 loss: 1.73185322e-06
Iter: 332 loss: 1.73105877e-06
Iter: 333 loss: 1.72972966e-06
Iter: 334 loss: 1.72729187e-06
Iter: 335 loss: 1.722761e-06
Iter: 336 loss: 1.81477265e-06
Iter: 337 loss: 1.72273189e-06
Iter: 338 loss: 1.71766385e-06
Iter: 339 loss: 1.71763759e-06
Iter: 340 loss: 1.71481599e-06
Iter: 341 loss: 1.71043507e-06
Iter: 342 loss: 1.71039642e-06
Iter: 343 loss: 1.70519729e-06
Iter: 344 loss: 1.74074285e-06
Iter: 345 loss: 1.70470571e-06
Iter: 346 loss: 1.70135036e-06
Iter: 347 loss: 1.70854116e-06
Iter: 348 loss: 1.70003909e-06
Iter: 349 loss: 1.69604266e-06
Iter: 350 loss: 1.71131626e-06
Iter: 351 loss: 1.69516579e-06
Iter: 352 loss: 1.69178372e-06
Iter: 353 loss: 1.6994868e-06
Iter: 354 loss: 1.69053033e-06
Iter: 355 loss: 1.68662245e-06
Iter: 356 loss: 1.682635e-06
Iter: 357 loss: 1.68189035e-06
Iter: 358 loss: 1.67813118e-06
Iter: 359 loss: 1.67810833e-06
Iter: 360 loss: 1.67510711e-06
Iter: 361 loss: 1.69852331e-06
Iter: 362 loss: 1.67491396e-06
Iter: 363 loss: 1.6727015e-06
Iter: 364 loss: 1.68773443e-06
Iter: 365 loss: 1.67251994e-06
Iter: 366 loss: 1.67058897e-06
Iter: 367 loss: 1.66818177e-06
Iter: 368 loss: 1.66795667e-06
Iter: 369 loss: 1.66497387e-06
Iter: 370 loss: 1.6631426e-06
Iter: 371 loss: 1.66190034e-06
Iter: 372 loss: 1.65838605e-06
Iter: 373 loss: 1.65836821e-06
Iter: 374 loss: 1.65520942e-06
Iter: 375 loss: 1.65478832e-06
Iter: 376 loss: 1.6525405e-06
Iter: 377 loss: 1.64902826e-06
Iter: 378 loss: 1.6489621e-06
Iter: 379 loss: 1.64622452e-06
Iter: 380 loss: 1.64233688e-06
Iter: 381 loss: 1.68790643e-06
Iter: 382 loss: 1.64231346e-06
Iter: 383 loss: 1.63968207e-06
Iter: 384 loss: 1.64229596e-06
Iter: 385 loss: 1.63818117e-06
Iter: 386 loss: 1.63399432e-06
Iter: 387 loss: 1.64287485e-06
Iter: 388 loss: 1.63244385e-06
Iter: 389 loss: 1.62973208e-06
Iter: 390 loss: 1.64360904e-06
Iter: 391 loss: 1.6291915e-06
Iter: 392 loss: 1.62637889e-06
Iter: 393 loss: 1.62305196e-06
Iter: 394 loss: 1.62274898e-06
Iter: 395 loss: 1.6213819e-06
Iter: 396 loss: 1.62059814e-06
Iter: 397 loss: 1.61834191e-06
Iter: 398 loss: 1.62238553e-06
Iter: 399 loss: 1.61742264e-06
Iter: 400 loss: 1.61509774e-06
Iter: 401 loss: 1.6219401e-06
Iter: 402 loss: 1.61442722e-06
Iter: 403 loss: 1.61276466e-06
Iter: 404 loss: 1.60956552e-06
Iter: 405 loss: 1.67276926e-06
Iter: 406 loss: 1.60950731e-06
Iter: 407 loss: 1.60598324e-06
Iter: 408 loss: 1.63808272e-06
Iter: 409 loss: 1.60576849e-06
Iter: 410 loss: 1.6039678e-06
Iter: 411 loss: 1.63131926e-06
Iter: 412 loss: 1.60396803e-06
Iter: 413 loss: 1.60279728e-06
Iter: 414 loss: 1.5997648e-06
Iter: 415 loss: 1.626678e-06
Iter: 416 loss: 1.59925685e-06
Iter: 417 loss: 1.5957454e-06
Iter: 418 loss: 1.61657135e-06
Iter: 419 loss: 1.5953201e-06
Iter: 420 loss: 1.59204455e-06
Iter: 421 loss: 1.60528191e-06
Iter: 422 loss: 1.59127194e-06
Iter: 423 loss: 1.58850878e-06
Iter: 424 loss: 1.60371451e-06
Iter: 425 loss: 1.58811065e-06
Iter: 426 loss: 1.58561488e-06
Iter: 427 loss: 1.58411069e-06
Iter: 428 loss: 1.58309172e-06
Iter: 429 loss: 1.57966497e-06
Iter: 430 loss: 1.60744844e-06
Iter: 431 loss: 1.57945954e-06
Iter: 432 loss: 1.57729903e-06
Iter: 433 loss: 1.57469572e-06
Iter: 434 loss: 1.57446379e-06
Iter: 435 loss: 1.5716588e-06
Iter: 436 loss: 1.57158649e-06
Iter: 437 loss: 1.56904048e-06
Iter: 438 loss: 1.57403576e-06
Iter: 439 loss: 1.56801582e-06
Iter: 440 loss: 1.56602482e-06
Iter: 441 loss: 1.57710019e-06
Iter: 442 loss: 1.56578517e-06
Iter: 443 loss: 1.56364831e-06
Iter: 444 loss: 1.57561965e-06
Iter: 445 loss: 1.5633351e-06
Iter: 446 loss: 1.56195642e-06
Iter: 447 loss: 1.5593788e-06
Iter: 448 loss: 1.61599951e-06
Iter: 449 loss: 1.55934981e-06
Iter: 450 loss: 1.55671421e-06
Iter: 451 loss: 1.58745411e-06
Iter: 452 loss: 1.55665202e-06
Iter: 453 loss: 1.55452062e-06
Iter: 454 loss: 1.55254907e-06
Iter: 455 loss: 1.55202883e-06
Iter: 456 loss: 1.54966278e-06
Iter: 457 loss: 1.54926329e-06
Iter: 458 loss: 1.54766849e-06
Iter: 459 loss: 1.54499116e-06
Iter: 460 loss: 1.54502823e-06
Iter: 461 loss: 1.54339727e-06
Iter: 462 loss: 1.54493023e-06
Iter: 463 loss: 1.54246436e-06
Iter: 464 loss: 1.54005647e-06
Iter: 465 loss: 1.54149075e-06
Iter: 466 loss: 1.53862607e-06
Iter: 467 loss: 1.53576229e-06
Iter: 468 loss: 1.5411581e-06
Iter: 469 loss: 1.53456926e-06
Iter: 470 loss: 1.53161011e-06
Iter: 471 loss: 1.54585939e-06
Iter: 472 loss: 1.53097471e-06
Iter: 473 loss: 1.52936536e-06
Iter: 474 loss: 1.54801774e-06
Iter: 475 loss: 1.52930988e-06
Iter: 476 loss: 1.5274934e-06
Iter: 477 loss: 1.52479151e-06
Iter: 478 loss: 1.52476969e-06
Iter: 479 loss: 1.52440828e-06
Iter: 480 loss: 1.52327391e-06
Iter: 481 loss: 1.52211874e-06
Iter: 482 loss: 1.52118901e-06
Iter: 483 loss: 1.5208384e-06
Iter: 484 loss: 1.51937707e-06
Iter: 485 loss: 1.51882546e-06
Iter: 486 loss: 1.51802567e-06
Iter: 487 loss: 1.51561e-06
Iter: 488 loss: 1.53488145e-06
Iter: 489 loss: 1.51545009e-06
Iter: 490 loss: 1.51408619e-06
Iter: 491 loss: 1.51111249e-06
Iter: 492 loss: 1.5524538e-06
Iter: 493 loss: 1.5109465e-06
Iter: 494 loss: 1.50833648e-06
Iter: 495 loss: 1.53863971e-06
Iter: 496 loss: 1.50825645e-06
Iter: 497 loss: 1.5062376e-06
Iter: 498 loss: 1.51051518e-06
Iter: 499 loss: 1.50544122e-06
Iter: 500 loss: 1.50318169e-06
Iter: 501 loss: 1.51688357e-06
Iter: 502 loss: 1.50288429e-06
Iter: 503 loss: 1.50116261e-06
Iter: 504 loss: 1.50278072e-06
Iter: 505 loss: 1.50019412e-06
Iter: 506 loss: 1.4983159e-06
Iter: 507 loss: 1.5007704e-06
Iter: 508 loss: 1.49733387e-06
Iter: 509 loss: 1.49492621e-06
Iter: 510 loss: 1.50275957e-06
Iter: 511 loss: 1.49421271e-06
Iter: 512 loss: 1.492774e-06
Iter: 513 loss: 1.49274172e-06
Iter: 514 loss: 1.49145853e-06
Iter: 515 loss: 1.49443792e-06
Iter: 516 loss: 1.49098241e-06
Iter: 517 loss: 1.48951494e-06
Iter: 518 loss: 1.49160883e-06
Iter: 519 loss: 1.48883021e-06
Iter: 520 loss: 1.48765469e-06
Iter: 521 loss: 1.48694971e-06
Iter: 522 loss: 1.48646541e-06
Iter: 523 loss: 1.48467689e-06
Iter: 524 loss: 1.495211e-06
Iter: 525 loss: 1.48444042e-06
Iter: 526 loss: 1.48269589e-06
Iter: 527 loss: 1.48664617e-06
Iter: 528 loss: 1.48201661e-06
Iter: 529 loss: 1.48045888e-06
Iter: 530 loss: 1.47762739e-06
Iter: 531 loss: 1.54463908e-06
Iter: 532 loss: 1.47762125e-06
Iter: 533 loss: 1.47511059e-06
Iter: 534 loss: 1.49719699e-06
Iter: 535 loss: 1.47492187e-06
Iter: 536 loss: 1.4726777e-06
Iter: 537 loss: 1.48169022e-06
Iter: 538 loss: 1.4722408e-06
Iter: 539 loss: 1.47045159e-06
Iter: 540 loss: 1.48237348e-06
Iter: 541 loss: 1.47029482e-06
Iter: 542 loss: 1.46846742e-06
Iter: 543 loss: 1.46583977e-06
Iter: 544 loss: 1.46577497e-06
Iter: 545 loss: 1.46371269e-06
Iter: 546 loss: 1.47752087e-06
Iter: 547 loss: 1.46345849e-06
Iter: 548 loss: 1.46227978e-06
Iter: 549 loss: 1.46215916e-06
Iter: 550 loss: 1.46125944e-06
Iter: 551 loss: 1.46138177e-06
Iter: 552 loss: 1.46061961e-06
Iter: 553 loss: 1.45927527e-06
Iter: 554 loss: 1.45896047e-06
Iter: 555 loss: 1.45812237e-06
Iter: 556 loss: 1.45610886e-06
Iter: 557 loss: 1.45676324e-06
Iter: 558 loss: 1.45474735e-06
Iter: 559 loss: 1.45347838e-06
Iter: 560 loss: 1.45341141e-06
Iter: 561 loss: 1.45233548e-06
Iter: 562 loss: 1.45061176e-06
Iter: 563 loss: 1.45054923e-06
Iter: 564 loss: 1.44882085e-06
Iter: 565 loss: 1.45795218e-06
Iter: 566 loss: 1.44859928e-06
Iter: 567 loss: 1.44701835e-06
Iter: 568 loss: 1.44815476e-06
Iter: 569 loss: 1.44605815e-06
Iter: 570 loss: 1.44381954e-06
Iter: 571 loss: 1.44261776e-06
Iter: 572 loss: 1.44152068e-06
Iter: 573 loss: 1.44081969e-06
Iter: 574 loss: 1.4400797e-06
Iter: 575 loss: 1.43900616e-06
Iter: 576 loss: 1.43799775e-06
Iter: 577 loss: 1.43774037e-06
Iter: 578 loss: 1.43607963e-06
Iter: 579 loss: 1.44384774e-06
Iter: 580 loss: 1.43577222e-06
Iter: 581 loss: 1.434909e-06
Iter: 582 loss: 1.43478144e-06
Iter: 583 loss: 1.43410057e-06
Iter: 584 loss: 1.43230352e-06
Iter: 585 loss: 1.44699447e-06
Iter: 586 loss: 1.43195109e-06
Iter: 587 loss: 1.43013426e-06
Iter: 588 loss: 1.45375805e-06
Iter: 589 loss: 1.43015473e-06
Iter: 590 loss: 1.42896658e-06
Iter: 591 loss: 1.4277814e-06
Iter: 592 loss: 1.42757631e-06
Iter: 593 loss: 1.4260138e-06
Iter: 594 loss: 1.44408443e-06
Iter: 595 loss: 1.42601186e-06
Iter: 596 loss: 1.42490762e-06
Iter: 597 loss: 1.42914359e-06
Iter: 598 loss: 1.42465035e-06
Iter: 599 loss: 1.42368356e-06
Iter: 600 loss: 1.421158e-06
Iter: 601 loss: 1.44484227e-06
Iter: 602 loss: 1.42081967e-06
Iter: 603 loss: 1.41864803e-06
Iter: 604 loss: 1.43137936e-06
Iter: 605 loss: 1.41833266e-06
Iter: 606 loss: 1.41660712e-06
Iter: 607 loss: 1.43234058e-06
Iter: 608 loss: 1.41655642e-06
Iter: 609 loss: 1.41509656e-06
Iter: 610 loss: 1.41889097e-06
Iter: 611 loss: 1.41454132e-06
Iter: 612 loss: 1.41272619e-06
Iter: 613 loss: 1.41710166e-06
Iter: 614 loss: 1.41208898e-06
Iter: 615 loss: 1.41090413e-06
Iter: 616 loss: 1.42209706e-06
Iter: 617 loss: 1.41083183e-06
Iter: 618 loss: 1.40943052e-06
Iter: 619 loss: 1.41239502e-06
Iter: 620 loss: 1.40887084e-06
Iter: 621 loss: 1.40781174e-06
Iter: 622 loss: 1.40724774e-06
Iter: 623 loss: 1.40678253e-06
Iter: 624 loss: 1.40541079e-06
Iter: 625 loss: 1.41508792e-06
Iter: 626 loss: 1.40525287e-06
Iter: 627 loss: 1.4041882e-06
Iter: 628 loss: 1.40551617e-06
Iter: 629 loss: 1.40369661e-06
Iter: 630 loss: 1.40235e-06
Iter: 631 loss: 1.40152861e-06
Iter: 632 loss: 1.40088252e-06
Iter: 633 loss: 1.39923156e-06
Iter: 634 loss: 1.39921042e-06
Iter: 635 loss: 1.39834697e-06
Iter: 636 loss: 1.39724682e-06
Iter: 637 loss: 1.39718054e-06
Iter: 638 loss: 1.39540452e-06
Iter: 639 loss: 1.39719452e-06
Iter: 640 loss: 1.39442318e-06
Iter: 641 loss: 1.39266069e-06
Iter: 642 loss: 1.39611575e-06
Iter: 643 loss: 1.39186113e-06
Iter: 644 loss: 1.39024223e-06
Iter: 645 loss: 1.39872532e-06
Iter: 646 loss: 1.38997075e-06
Iter: 647 loss: 1.38819e-06
Iter: 648 loss: 1.39735721e-06
Iter: 649 loss: 1.38794326e-06
Iter: 650 loss: 1.38695259e-06
Iter: 651 loss: 1.38693417e-06
Iter: 652 loss: 1.38618452e-06
Iter: 653 loss: 1.38719167e-06
Iter: 654 loss: 1.38582482e-06
Iter: 655 loss: 1.3850804e-06
Iter: 656 loss: 1.38335918e-06
Iter: 657 loss: 1.40326904e-06
Iter: 658 loss: 1.3831833e-06
Iter: 659 loss: 1.38191615e-06
Iter: 660 loss: 1.38185897e-06
Iter: 661 loss: 1.38072028e-06
Iter: 662 loss: 1.3803583e-06
Iter: 663 loss: 1.37962741e-06
Iter: 664 loss: 1.37836446e-06
Iter: 665 loss: 1.38531368e-06
Iter: 666 loss: 1.37820177e-06
Iter: 667 loss: 1.37704239e-06
Iter: 668 loss: 1.38203791e-06
Iter: 669 loss: 1.37680161e-06
Iter: 670 loss: 1.37562256e-06
Iter: 671 loss: 1.37382608e-06
Iter: 672 loss: 1.37382403e-06
Iter: 673 loss: 1.3721185e-06
Iter: 674 loss: 1.37510813e-06
Iter: 675 loss: 1.37135316e-06
Iter: 676 loss: 1.36931453e-06
Iter: 677 loss: 1.37727739e-06
Iter: 678 loss: 1.36884705e-06
Iter: 679 loss: 1.36715039e-06
Iter: 680 loss: 1.37620816e-06
Iter: 681 loss: 1.36686344e-06
Iter: 682 loss: 1.36578e-06
Iter: 683 loss: 1.38196367e-06
Iter: 684 loss: 1.36578296e-06
Iter: 685 loss: 1.36473852e-06
Iter: 686 loss: 1.36904578e-06
Iter: 687 loss: 1.36456015e-06
Iter: 688 loss: 1.36370738e-06
Iter: 689 loss: 1.36350025e-06
Iter: 690 loss: 1.36299013e-06
Iter: 691 loss: 1.36180222e-06
Iter: 692 loss: 1.36085396e-06
Iter: 693 loss: 1.36055428e-06
Iter: 694 loss: 1.35939808e-06
Iter: 695 loss: 1.35937785e-06
Iter: 696 loss: 1.35860057e-06
Iter: 697 loss: 1.35974653e-06
Iter: 698 loss: 1.35816799e-06
Iter: 699 loss: 1.35698372e-06
Iter: 700 loss: 1.35617597e-06
Iter: 701 loss: 1.35575885e-06
Iter: 702 loss: 1.3546188e-06
Iter: 703 loss: 1.35459027e-06
Iter: 704 loss: 1.3537408e-06
Iter: 705 loss: 1.35294e-06
Iter: 706 loss: 1.35279822e-06
Iter: 707 loss: 1.35128334e-06
Iter: 708 loss: 1.35364007e-06
Iter: 709 loss: 1.35055416e-06
Iter: 710 loss: 1.34899119e-06
Iter: 711 loss: 1.34806669e-06
Iter: 712 loss: 1.34743152e-06
Iter: 713 loss: 1.3455774e-06
Iter: 714 loss: 1.35013863e-06
Iter: 715 loss: 1.34498e-06
Iter: 716 loss: 1.34555341e-06
Iter: 717 loss: 1.34412767e-06
Iter: 718 loss: 1.34341144e-06
Iter: 719 loss: 1.34306242e-06
Iter: 720 loss: 1.34271704e-06
Iter: 721 loss: 1.34190293e-06
Iter: 722 loss: 1.34217794e-06
Iter: 723 loss: 1.34125821e-06
Iter: 724 loss: 1.33998083e-06
Iter: 725 loss: 1.3419309e-06
Iter: 726 loss: 1.33939557e-06
Iter: 727 loss: 1.33822527e-06
Iter: 728 loss: 1.34063077e-06
Iter: 729 loss: 1.33771516e-06
Iter: 730 loss: 1.33638923e-06
Iter: 731 loss: 1.34464358e-06
Iter: 732 loss: 1.33615151e-06
Iter: 733 loss: 1.3351538e-06
Iter: 734 loss: 1.33526873e-06
Iter: 735 loss: 1.33440915e-06
Iter: 736 loss: 1.33315962e-06
Iter: 737 loss: 1.34547088e-06
Iter: 738 loss: 1.33307685e-06
Iter: 739 loss: 1.33216668e-06
Iter: 740 loss: 1.33101366e-06
Iter: 741 loss: 1.33090214e-06
Iter: 742 loss: 1.32931279e-06
Iter: 743 loss: 1.33562935e-06
Iter: 744 loss: 1.32893047e-06
Iter: 745 loss: 1.32771265e-06
Iter: 746 loss: 1.32956018e-06
Iter: 747 loss: 1.32717173e-06
Iter: 748 loss: 1.32564492e-06
Iter: 749 loss: 1.33130902e-06
Iter: 750 loss: 1.32526827e-06
Iter: 751 loss: 1.32416221e-06
Iter: 752 loss: 1.33085916e-06
Iter: 753 loss: 1.32401806e-06
Iter: 754 loss: 1.32284572e-06
Iter: 755 loss: 1.33355832e-06
Iter: 756 loss: 1.32276784e-06
Iter: 757 loss: 1.32232776e-06
Iter: 758 loss: 1.32117566e-06
Iter: 759 loss: 1.33168771e-06
Iter: 760 loss: 1.32102e-06
Iter: 761 loss: 1.31948661e-06
Iter: 762 loss: 1.32323498e-06
Iter: 763 loss: 1.31893717e-06
Iter: 764 loss: 1.31778165e-06
Iter: 765 loss: 1.32596722e-06
Iter: 766 loss: 1.31767706e-06
Iter: 767 loss: 1.31649335e-06
Iter: 768 loss: 1.31993738e-06
Iter: 769 loss: 1.31609477e-06
Iter: 770 loss: 1.31520983e-06
Iter: 771 loss: 1.31614286e-06
Iter: 772 loss: 1.31468551e-06
Iter: 773 loss: 1.31352976e-06
Iter: 774 loss: 1.32187517e-06
Iter: 775 loss: 1.31342631e-06
Iter: 776 loss: 1.31240131e-06
Iter: 777 loss: 1.31313345e-06
Iter: 778 loss: 1.31182037e-06
Iter: 779 loss: 1.31084414e-06
Iter: 780 loss: 1.3127252e-06
Iter: 781 loss: 1.31047477e-06
Iter: 782 loss: 1.30893886e-06
Iter: 783 loss: 1.31178786e-06
Iter: 784 loss: 1.30830017e-06
Iter: 785 loss: 1.30740773e-06
Iter: 786 loss: 1.30731928e-06
Iter: 787 loss: 1.30664171e-06
Iter: 788 loss: 1.30548312e-06
Iter: 789 loss: 1.31722209e-06
Iter: 790 loss: 1.305458e-06
Iter: 791 loss: 1.30479202e-06
Iter: 792 loss: 1.30478213e-06
Iter: 793 loss: 1.30427111e-06
Iter: 794 loss: 1.30300396e-06
Iter: 795 loss: 1.31212164e-06
Iter: 796 loss: 1.30272656e-06
Iter: 797 loss: 1.30140722e-06
Iter: 798 loss: 1.30645799e-06
Iter: 799 loss: 1.30114063e-06
Iter: 800 loss: 1.29995851e-06
Iter: 801 loss: 1.30125397e-06
Iter: 802 loss: 1.29929208e-06
Iter: 803 loss: 1.29787713e-06
Iter: 804 loss: 1.30173771e-06
Iter: 805 loss: 1.29741215e-06
Iter: 806 loss: 1.29625732e-06
Iter: 807 loss: 1.30518606e-06
Iter: 808 loss: 1.29619889e-06
Iter: 809 loss: 1.29504065e-06
Iter: 810 loss: 1.29940327e-06
Iter: 811 loss: 1.29479815e-06
Iter: 812 loss: 1.29380737e-06
Iter: 813 loss: 1.29529178e-06
Iter: 814 loss: 1.29337855e-06
Iter: 815 loss: 1.2925118e-06
Iter: 816 loss: 1.29620844e-06
Iter: 817 loss: 1.29237492e-06
Iter: 818 loss: 1.29146542e-06
Iter: 819 loss: 1.29174691e-06
Iter: 820 loss: 1.2907318e-06
Iter: 821 loss: 1.28979718e-06
Iter: 822 loss: 1.29104455e-06
Iter: 823 loss: 1.28934334e-06
Iter: 824 loss: 1.28803549e-06
Iter: 825 loss: 1.29706984e-06
Iter: 826 loss: 1.28792919e-06
Iter: 827 loss: 1.28734337e-06
Iter: 828 loss: 1.28733e-06
Iter: 829 loss: 1.28692773e-06
Iter: 830 loss: 1.28594661e-06
Iter: 831 loss: 1.29573823e-06
Iter: 832 loss: 1.28581064e-06
Iter: 833 loss: 1.28461431e-06
Iter: 834 loss: 1.28724514e-06
Iter: 835 loss: 1.28411421e-06
Iter: 836 loss: 1.28318675e-06
Iter: 837 loss: 1.28428951e-06
Iter: 838 loss: 1.2825875e-06
Iter: 839 loss: 1.28105762e-06
Iter: 840 loss: 1.28351417e-06
Iter: 841 loss: 1.28037391e-06
Iter: 842 loss: 1.2789119e-06
Iter: 843 loss: 1.2806014e-06
Iter: 844 loss: 1.27816043e-06
Iter: 845 loss: 1.27675037e-06
Iter: 846 loss: 1.28677357e-06
Iter: 847 loss: 1.27665146e-06
Iter: 848 loss: 1.27564203e-06
Iter: 849 loss: 1.28197792e-06
Iter: 850 loss: 1.27554233e-06
Iter: 851 loss: 1.27454518e-06
Iter: 852 loss: 1.28016404e-06
Iter: 853 loss: 1.27440694e-06
Iter: 854 loss: 1.27375688e-06
Iter: 855 loss: 1.27285489e-06
Iter: 856 loss: 1.27285568e-06
Iter: 857 loss: 1.27165276e-06
Iter: 858 loss: 1.27831322e-06
Iter: 859 loss: 1.27145131e-06
Iter: 860 loss: 1.27033945e-06
Iter: 861 loss: 1.28130318e-06
Iter: 862 loss: 1.2702759e-06
Iter: 863 loss: 1.26950044e-06
Iter: 864 loss: 1.27464432e-06
Iter: 865 loss: 1.26943439e-06
Iter: 866 loss: 1.26901386e-06
Iter: 867 loss: 1.26827672e-06
Iter: 868 loss: 1.26826194e-06
Iter: 869 loss: 1.26730754e-06
Iter: 870 loss: 1.27072735e-06
Iter: 871 loss: 1.26712143e-06
Iter: 872 loss: 1.26611781e-06
Iter: 873 loss: 1.26865052e-06
Iter: 874 loss: 1.2658079e-06
Iter: 875 loss: 1.26494103e-06
Iter: 876 loss: 1.26512305e-06
Iter: 877 loss: 1.26427472e-06
Iter: 878 loss: 1.26327973e-06
Iter: 879 loss: 1.26602674e-06
Iter: 880 loss: 1.26292775e-06
Iter: 881 loss: 1.26165162e-06
Iter: 882 loss: 1.26363432e-06
Iter: 883 loss: 1.26107625e-06
Iter: 884 loss: 1.26015391e-06
Iter: 885 loss: 1.2643618e-06
Iter: 886 loss: 1.25993415e-06
Iter: 887 loss: 1.25880888e-06
Iter: 888 loss: 1.25854388e-06
Iter: 889 loss: 1.25776273e-06
Iter: 890 loss: 1.25735755e-06
Iter: 891 loss: 1.25709107e-06
Iter: 892 loss: 1.25648717e-06
Iter: 893 loss: 1.25547422e-06
Iter: 894 loss: 1.25545353e-06
Iter: 895 loss: 1.25533188e-06
Iter: 896 loss: 1.2550779e-06
Iter: 897 loss: 1.25460178e-06
Iter: 898 loss: 1.25342672e-06
Iter: 899 loss: 1.2641774e-06
Iter: 900 loss: 1.25326039e-06
Iter: 901 loss: 1.25218196e-06
Iter: 902 loss: 1.25609847e-06
Iter: 903 loss: 1.25190468e-06
Iter: 904 loss: 1.25113161e-06
Iter: 905 loss: 1.25752229e-06
Iter: 906 loss: 1.25108807e-06
Iter: 907 loss: 1.25033819e-06
Iter: 908 loss: 1.2503001e-06
Iter: 909 loss: 1.24972235e-06
Iter: 910 loss: 1.24888049e-06
Iter: 911 loss: 1.24891858e-06
Iter: 912 loss: 1.24811436e-06
Iter: 913 loss: 1.24703377e-06
Iter: 914 loss: 1.25470115e-06
Iter: 915 loss: 1.24697522e-06
Iter: 916 loss: 1.24598375e-06
Iter: 917 loss: 1.24826363e-06
Iter: 918 loss: 1.24564224e-06
Iter: 919 loss: 1.24461712e-06
Iter: 920 loss: 1.24781252e-06
Iter: 921 loss: 1.24438066e-06
Iter: 922 loss: 1.24318785e-06
Iter: 923 loss: 1.24600967e-06
Iter: 924 loss: 1.24275334e-06
Iter: 925 loss: 1.24196674e-06
Iter: 926 loss: 1.24431097e-06
Iter: 927 loss: 1.24174471e-06
Iter: 928 loss: 1.24081203e-06
Iter: 929 loss: 1.24423855e-06
Iter: 930 loss: 1.24059488e-06
Iter: 931 loss: 1.23962673e-06
Iter: 932 loss: 1.24483154e-06
Iter: 933 loss: 1.23945756e-06
Iter: 934 loss: 1.23904749e-06
Iter: 935 loss: 1.23906534e-06
Iter: 936 loss: 1.23880329e-06
Iter: 937 loss: 1.23794371e-06
Iter: 938 loss: 1.23859627e-06
Iter: 939 loss: 1.23719474e-06
Iter: 940 loss: 1.23599318e-06
Iter: 941 loss: 1.24752864e-06
Iter: 942 loss: 1.23594259e-06
Iter: 943 loss: 1.23509813e-06
Iter: 944 loss: 1.2363522e-06
Iter: 945 loss: 1.23467544e-06
Iter: 946 loss: 1.23390862e-06
Iter: 947 loss: 1.24610347e-06
Iter: 948 loss: 1.23391794e-06
Iter: 949 loss: 1.23318557e-06
Iter: 950 loss: 1.23210668e-06
Iter: 951 loss: 1.23204791e-06
Iter: 952 loss: 1.23092718e-06
Iter: 953 loss: 1.23680616e-06
Iter: 954 loss: 1.23075165e-06
Iter: 955 loss: 1.22984943e-06
Iter: 956 loss: 1.22964968e-06
Iter: 957 loss: 1.22904657e-06
Iter: 958 loss: 1.22787219e-06
Iter: 959 loss: 1.2383515e-06
Iter: 960 loss: 1.22779443e-06
Iter: 961 loss: 1.22683775e-06
Iter: 962 loss: 1.2287984e-06
Iter: 963 loss: 1.22645281e-06
Iter: 964 loss: 1.22565166e-06
Iter: 965 loss: 1.23287168e-06
Iter: 966 loss: 1.22560527e-06
Iter: 967 loss: 1.22503468e-06
Iter: 968 loss: 1.22527115e-06
Iter: 969 loss: 1.22460597e-06
Iter: 970 loss: 1.22371466e-06
Iter: 971 loss: 1.22852566e-06
Iter: 972 loss: 1.22353845e-06
Iter: 973 loss: 1.2230945e-06
Iter: 974 loss: 1.22309291e-06
Iter: 975 loss: 1.22271263e-06
Iter: 976 loss: 1.22188555e-06
Iter: 977 loss: 1.23502309e-06
Iter: 978 loss: 1.22190693e-06
Iter: 979 loss: 1.22113e-06
Iter: 980 loss: 1.22125903e-06
Iter: 981 loss: 1.22050892e-06
Iter: 982 loss: 1.21956191e-06
Iter: 983 loss: 1.22347058e-06
Iter: 984 loss: 1.21934829e-06
Iter: 985 loss: 1.21837718e-06
Iter: 986 loss: 1.21824235e-06
Iter: 987 loss: 1.21760775e-06
Iter: 988 loss: 1.21635799e-06
Iter: 989 loss: 1.22140364e-06
Iter: 990 loss: 1.21608662e-06
Iter: 991 loss: 1.21501455e-06
Iter: 992 loss: 1.22764027e-06
Iter: 993 loss: 1.21502057e-06
Iter: 994 loss: 1.21428934e-06
Iter: 995 loss: 1.21861706e-06
Iter: 996 loss: 1.21421442e-06
Iter: 997 loss: 1.21368362e-06
Iter: 998 loss: 1.21247763e-06
Iter: 999 loss: 1.22751487e-06
Iter: 1000 loss: 1.21241305e-06
Iter: 1001 loss: 1.2116177e-06
Iter: 1002 loss: 1.21151777e-06
Iter: 1003 loss: 1.21091239e-06
Iter: 1004 loss: 1.21297444e-06
Iter: 1005 loss: 1.21079233e-06
Iter: 1006 loss: 1.21011033e-06
Iter: 1007 loss: 1.21168864e-06
Iter: 1008 loss: 1.2099066e-06
Iter: 1009 loss: 1.20927564e-06
Iter: 1010 loss: 1.21481742e-06
Iter: 1011 loss: 1.20921982e-06
Iter: 1012 loss: 1.20891787e-06
Iter: 1013 loss: 1.2081598e-06
Iter: 1014 loss: 1.21826622e-06
Iter: 1015 loss: 1.20811228e-06
Iter: 1016 loss: 1.20728157e-06
Iter: 1017 loss: 1.21075914e-06
Iter: 1018 loss: 1.20709956e-06
Iter: 1019 loss: 1.20650498e-06
Iter: 1020 loss: 1.21120115e-06
Iter: 1021 loss: 1.20642744e-06
Iter: 1022 loss: 1.20589607e-06
Iter: 1023 loss: 1.20524862e-06
Iter: 1024 loss: 1.20519962e-06
Iter: 1025 loss: 1.20422146e-06
Iter: 1026 loss: 1.20517598e-06
Iter: 1027 loss: 1.20366667e-06
Iter: 1028 loss: 1.20255072e-06
Iter: 1029 loss: 1.20640823e-06
Iter: 1030 loss: 1.2023163e-06
Iter: 1031 loss: 1.20149161e-06
Iter: 1032 loss: 1.21043513e-06
Iter: 1033 loss: 1.2014392e-06
Iter: 1034 loss: 1.20081381e-06
Iter: 1035 loss: 1.20463642e-06
Iter: 1036 loss: 1.20073355e-06
Iter: 1037 loss: 1.20018365e-06
Iter: 1038 loss: 1.19967353e-06
Iter: 1039 loss: 1.19952699e-06
Iter: 1040 loss: 1.1985851e-06
Iter: 1041 loss: 1.19987794e-06
Iter: 1042 loss: 1.19814149e-06
Iter: 1043 loss: 1.19725837e-06
Iter: 1044 loss: 1.2110745e-06
Iter: 1045 loss: 1.19726383e-06
Iter: 1046 loss: 1.19668675e-06
Iter: 1047 loss: 1.20193727e-06
Iter: 1048 loss: 1.19667209e-06
Iter: 1049 loss: 1.19626623e-06
Iter: 1050 loss: 1.19708852e-06
Iter: 1051 loss: 1.196119e-06
Iter: 1052 loss: 1.19565107e-06
Iter: 1053 loss: 1.19470928e-06
Iter: 1054 loss: 1.21370658e-06
Iter: 1055 loss: 1.19470656e-06
Iter: 1056 loss: 1.19388164e-06
Iter: 1057 loss: 1.19870469e-06
Iter: 1058 loss: 1.19380888e-06
Iter: 1059 loss: 1.19309561e-06
Iter: 1060 loss: 1.19378296e-06
Iter: 1061 loss: 1.19269112e-06
Iter: 1062 loss: 1.19179208e-06
Iter: 1063 loss: 1.19753213e-06
Iter: 1064 loss: 1.19167589e-06
Iter: 1065 loss: 1.19111883e-06
Iter: 1066 loss: 1.1904134e-06
Iter: 1067 loss: 1.19035076e-06
Iter: 1068 loss: 1.18937282e-06
Iter: 1069 loss: 1.19385197e-06
Iter: 1070 loss: 1.18922571e-06
Iter: 1071 loss: 1.18815205e-06
Iter: 1072 loss: 1.18931735e-06
Iter: 1073 loss: 1.18755486e-06
Iter: 1074 loss: 1.18646221e-06
Iter: 1075 loss: 1.1912831e-06
Iter: 1076 loss: 1.18625053e-06
Iter: 1077 loss: 1.18568562e-06
Iter: 1078 loss: 1.18566413e-06
Iter: 1079 loss: 1.1851796e-06
Iter: 1080 loss: 1.18504477e-06
Iter: 1081 loss: 1.18478442e-06
Iter: 1082 loss: 1.18443859e-06
Iter: 1083 loss: 1.18440948e-06
Iter: 1084 loss: 1.18403159e-06
Iter: 1085 loss: 1.18333958e-06
Iter: 1086 loss: 1.19567471e-06
Iter: 1087 loss: 1.18335117e-06
Iter: 1088 loss: 1.18267076e-06
Iter: 1089 loss: 1.18513742e-06
Iter: 1090 loss: 1.18246157e-06
Iter: 1091 loss: 1.1817566e-06
Iter: 1092 loss: 1.18513503e-06
Iter: 1093 loss: 1.18159551e-06
Iter: 1094 loss: 1.18102184e-06
Iter: 1095 loss: 1.18091566e-06
Iter: 1096 loss: 1.18049934e-06
Iter: 1097 loss: 1.17971967e-06
Iter: 1098 loss: 1.1825432e-06
Iter: 1099 loss: 1.17955017e-06
Iter: 1100 loss: 1.17888726e-06
Iter: 1101 loss: 1.17966283e-06
Iter: 1102 loss: 1.17858e-06
Iter: 1103 loss: 1.17757509e-06
Iter: 1104 loss: 1.18064054e-06
Iter: 1105 loss: 1.17728302e-06
Iter: 1106 loss: 1.176556e-06
Iter: 1107 loss: 1.17611762e-06
Iter: 1108 loss: 1.17585648e-06
Iter: 1109 loss: 1.17489242e-06
Iter: 1110 loss: 1.18326943e-06
Iter: 1111 loss: 1.17488241e-06
Iter: 1112 loss: 1.17417062e-06
Iter: 1113 loss: 1.17422906e-06
Iter: 1114 loss: 1.17360628e-06
Iter: 1115 loss: 1.172976e-06
Iter: 1116 loss: 1.17290824e-06
Iter: 1117 loss: 1.17257889e-06
Iter: 1118 loss: 1.17427646e-06
Iter: 1119 loss: 1.17253535e-06
Iter: 1120 loss: 1.17209379e-06
Iter: 1121 loss: 1.1711885e-06
Iter: 1122 loss: 1.18662706e-06
Iter: 1123 loss: 1.17116929e-06
Iter: 1124 loss: 1.17023023e-06
Iter: 1125 loss: 1.17314426e-06
Iter: 1126 loss: 1.16999524e-06
Iter: 1127 loss: 1.16950662e-06
Iter: 1128 loss: 1.16949673e-06
Iter: 1129 loss: 1.169087e-06
Iter: 1130 loss: 1.16841898e-06
Iter: 1131 loss: 1.16840602e-06
Iter: 1132 loss: 1.16757406e-06
Iter: 1133 loss: 1.16943306e-06
Iter: 1134 loss: 1.16723606e-06
Iter: 1135 loss: 1.16639205e-06
Iter: 1136 loss: 1.16983915e-06
Iter: 1137 loss: 1.16618344e-06
Iter: 1138 loss: 1.16554281e-06
Iter: 1139 loss: 1.16855392e-06
Iter: 1140 loss: 1.16543333e-06
Iter: 1141 loss: 1.16474735e-06
Iter: 1142 loss: 1.16602268e-06
Iter: 1143 loss: 1.16444016e-06
Iter: 1144 loss: 1.16381057e-06
Iter: 1145 loss: 1.16348087e-06
Iter: 1146 loss: 1.16323633e-06
Iter: 1147 loss: 1.1621878e-06
Iter: 1148 loss: 1.16757928e-06
Iter: 1149 loss: 1.16199499e-06
Iter: 1150 loss: 1.1612085e-06
Iter: 1151 loss: 1.16069759e-06
Iter: 1152 loss: 1.16038677e-06
Iter: 1153 loss: 1.16003207e-06
Iter: 1154 loss: 1.15963167e-06
Iter: 1155 loss: 1.15933324e-06
Iter: 1156 loss: 1.16161459e-06
Iter: 1157 loss: 1.1592831e-06
Iter: 1158 loss: 1.15891146e-06
Iter: 1159 loss: 1.15848184e-06
Iter: 1160 loss: 1.1584425e-06
Iter: 1161 loss: 1.15781575e-06
Iter: 1162 loss: 1.15727778e-06
Iter: 1163 loss: 1.15704825e-06
Iter: 1164 loss: 1.15643809e-06
Iter: 1165 loss: 1.16226181e-06
Iter: 1166 loss: 1.15642479e-06
Iter: 1167 loss: 1.15583714e-06
Iter: 1168 loss: 1.15864475e-06
Iter: 1169 loss: 1.15576e-06
Iter: 1170 loss: 1.15531566e-06
Iter: 1171 loss: 1.15510034e-06
Iter: 1172 loss: 1.15482669e-06
Iter: 1173 loss: 1.15406647e-06
Iter: 1174 loss: 1.15473688e-06
Iter: 1175 loss: 1.15351804e-06
Iter: 1176 loss: 1.15279818e-06
Iter: 1177 loss: 1.15980606e-06
Iter: 1178 loss: 1.15273383e-06
Iter: 1179 loss: 1.15213368e-06
Iter: 1180 loss: 1.15303033e-06
Iter: 1181 loss: 1.15186458e-06
Iter: 1182 loss: 1.15113846e-06
Iter: 1183 loss: 1.15098828e-06
Iter: 1184 loss: 1.15045964e-06
Iter: 1185 loss: 1.149642e-06
Iter: 1186 loss: 1.15509306e-06
Iter: 1187 loss: 1.14956651e-06
Iter: 1188 loss: 1.1488512e-06
Iter: 1189 loss: 1.14892305e-06
Iter: 1190 loss: 1.14832255e-06
Iter: 1191 loss: 1.14803538e-06
Iter: 1192 loss: 1.1478387e-06
Iter: 1193 loss: 1.14740919e-06
Iter: 1194 loss: 1.14797888e-06
Iter: 1195 loss: 1.14725299e-06
Iter: 1196 loss: 1.14675447e-06
Iter: 1197 loss: 1.1466708e-06
Iter: 1198 loss: 1.14637476e-06
Iter: 1199 loss: 1.14572117e-06
Iter: 1200 loss: 1.14605041e-06
Iter: 1201 loss: 1.14531565e-06
Iter: 1202 loss: 1.14466366e-06
Iter: 1203 loss: 1.14641898e-06
Iter: 1204 loss: 1.14450495e-06
Iter: 1205 loss: 1.14361251e-06
Iter: 1206 loss: 1.14706063e-06
Iter: 1207 loss: 1.14337729e-06
Iter: 1208 loss: 1.14287593e-06
Iter: 1209 loss: 1.14318823e-06
Iter: 1210 loss: 1.14250224e-06
Iter: 1211 loss: 1.14179034e-06
Iter: 1212 loss: 1.14333102e-06
Iter: 1213 loss: 1.14147906e-06
Iter: 1214 loss: 1.14092541e-06
Iter: 1215 loss: 1.14506679e-06
Iter: 1216 loss: 1.14083741e-06
Iter: 1217 loss: 1.14025261e-06
Iter: 1218 loss: 1.13997203e-06
Iter: 1219 loss: 1.13966382e-06
Iter: 1220 loss: 1.13888723e-06
Iter: 1221 loss: 1.14218517e-06
Iter: 1222 loss: 1.13875512e-06
Iter: 1223 loss: 1.1380364e-06
Iter: 1224 loss: 1.13815418e-06
Iter: 1225 loss: 1.13753663e-06
Iter: 1226 loss: 1.13681176e-06
Iter: 1227 loss: 1.14298e-06
Iter: 1228 loss: 1.13672581e-06
Iter: 1229 loss: 1.13656165e-06
Iter: 1230 loss: 1.13643978e-06
Iter: 1231 loss: 1.13619672e-06
Iter: 1232 loss: 1.13560134e-06
Iter: 1233 loss: 1.1400723e-06
Iter: 1234 loss: 1.13550755e-06
Iter: 1235 loss: 1.13466876e-06
Iter: 1236 loss: 1.13985925e-06
Iter: 1237 loss: 1.13456531e-06
Iter: 1238 loss: 1.13400233e-06
Iter: 1239 loss: 1.13443502e-06
Iter: 1240 loss: 1.13360875e-06
Iter: 1241 loss: 1.13295891e-06
Iter: 1242 loss: 1.13330145e-06
Iter: 1243 loss: 1.13255112e-06
Iter: 1244 loss: 1.132129e-06
Iter: 1245 loss: 1.13206295e-06
Iter: 1246 loss: 1.13177225e-06
Iter: 1247 loss: 1.13137503e-06
Iter: 1248 loss: 1.13133501e-06
Iter: 1249 loss: 1.13068359e-06
Iter: 1250 loss: 1.13148371e-06
Iter: 1251 loss: 1.1302601e-06
Iter: 1252 loss: 1.12955695e-06
Iter: 1253 loss: 1.13281908e-06
Iter: 1254 loss: 1.12943519e-06
Iter: 1255 loss: 1.12864313e-06
Iter: 1256 loss: 1.13013243e-06
Iter: 1257 loss: 1.12833141e-06
Iter: 1258 loss: 1.12770783e-06
Iter: 1259 loss: 1.12928728e-06
Iter: 1260 loss: 1.12748069e-06
Iter: 1261 loss: 1.12680743e-06
Iter: 1262 loss: 1.12708858e-06
Iter: 1263 loss: 1.12632e-06
Iter: 1264 loss: 1.12609951e-06
Iter: 1265 loss: 1.12595512e-06
Iter: 1266 loss: 1.12549731e-06
Iter: 1267 loss: 1.1249474e-06
Iter: 1268 loss: 1.12494013e-06
Iter: 1269 loss: 1.12438011e-06
Iter: 1270 loss: 1.12449356e-06
Iter: 1271 loss: 1.12396378e-06
Iter: 1272 loss: 1.12341286e-06
Iter: 1273 loss: 1.12799489e-06
Iter: 1274 loss: 1.12332259e-06
Iter: 1275 loss: 1.12271937e-06
Iter: 1276 loss: 1.12368934e-06
Iter: 1277 loss: 1.12245925e-06
Iter: 1278 loss: 1.12194232e-06
Iter: 1279 loss: 1.12170085e-06
Iter: 1280 loss: 1.12142993e-06
Iter: 1281 loss: 1.12064515e-06
Iter: 1282 loss: 1.12402358e-06
Iter: 1283 loss: 1.12046746e-06
Iter: 1284 loss: 1.1197053e-06
Iter: 1285 loss: 1.12447105e-06
Iter: 1286 loss: 1.11963186e-06
Iter: 1287 loss: 1.11906786e-06
Iter: 1288 loss: 1.12264649e-06
Iter: 1289 loss: 1.11903614e-06
Iter: 1290 loss: 1.11859367e-06
Iter: 1291 loss: 1.11831707e-06
Iter: 1292 loss: 1.11813029e-06
Iter: 1293 loss: 1.11737018e-06
Iter: 1294 loss: 1.12134239e-06
Iter: 1295 loss: 1.11726877e-06
Iter: 1296 loss: 1.1167175e-06
Iter: 1297 loss: 1.11685631e-06
Iter: 1298 loss: 1.11631175e-06
Iter: 1299 loss: 1.11571535e-06
Iter: 1300 loss: 1.12069631e-06
Iter: 1301 loss: 1.11565464e-06
Iter: 1302 loss: 1.11524434e-06
Iter: 1303 loss: 1.12162616e-06
Iter: 1304 loss: 1.11524855e-06
Iter: 1305 loss: 1.11501515e-06
Iter: 1306 loss: 1.11430052e-06
Iter: 1307 loss: 1.11486099e-06
Iter: 1308 loss: 1.11371332e-06
Iter: 1309 loss: 1.11296106e-06
Iter: 1310 loss: 1.11294787e-06
Iter: 1311 loss: 1.11234328e-06
Iter: 1312 loss: 1.11236545e-06
Iter: 1313 loss: 1.11188433e-06
Iter: 1314 loss: 1.11118788e-06
Iter: 1315 loss: 1.12265298e-06
Iter: 1316 loss: 1.11119084e-06
Iter: 1317 loss: 1.11072666e-06
Iter: 1318 loss: 1.11029101e-06
Iter: 1319 loss: 1.11022428e-06
Iter: 1320 loss: 1.10957e-06
Iter: 1321 loss: 1.10987492e-06
Iter: 1322 loss: 1.10914937e-06
Iter: 1323 loss: 1.10841086e-06
Iter: 1324 loss: 1.11498775e-06
Iter: 1325 loss: 1.10842825e-06
Iter: 1326 loss: 1.10780275e-06
Iter: 1327 loss: 1.1096871e-06
Iter: 1328 loss: 1.10757037e-06
Iter: 1329 loss: 1.1069551e-06
Iter: 1330 loss: 1.10802102e-06
Iter: 1331 loss: 1.10665951e-06
Iter: 1332 loss: 1.10616361e-06
Iter: 1333 loss: 1.10941e-06
Iter: 1334 loss: 1.10609881e-06
Iter: 1335 loss: 1.10557289e-06
Iter: 1336 loss: 1.10487053e-06
Iter: 1337 loss: 1.10480482e-06
Iter: 1338 loss: 1.10407677e-06
Iter: 1339 loss: 1.10965425e-06
Iter: 1340 loss: 1.10402107e-06
Iter: 1341 loss: 1.10365431e-06
Iter: 1342 loss: 1.10366364e-06
Iter: 1343 loss: 1.10320047e-06
Iter: 1344 loss: 1.10255633e-06
Iter: 1345 loss: 1.10253859e-06
Iter: 1346 loss: 1.1020112e-06
Iter: 1347 loss: 1.10204542e-06
Iter: 1348 loss: 1.10155679e-06
Iter: 1349 loss: 1.10089843e-06
Iter: 1350 loss: 1.10623262e-06
Iter: 1351 loss: 1.10094e-06
Iter: 1352 loss: 1.10040151e-06
Iter: 1353 loss: 1.10308747e-06
Iter: 1354 loss: 1.10033e-06
Iter: 1355 loss: 1.09989037e-06
Iter: 1356 loss: 1.0989944e-06
Iter: 1357 loss: 1.11380973e-06
Iter: 1358 loss: 1.09897894e-06
Iter: 1359 loss: 1.09833809e-06
Iter: 1360 loss: 1.09831115e-06
Iter: 1361 loss: 1.09785776e-06
Iter: 1362 loss: 1.09961206e-06
Iter: 1363 loss: 1.09769746e-06
Iter: 1364 loss: 1.09721748e-06
Iter: 1365 loss: 1.09768928e-06
Iter: 1366 loss: 1.09694929e-06
Iter: 1367 loss: 1.0964045e-06
Iter: 1368 loss: 1.09903112e-06
Iter: 1369 loss: 1.09626103e-06
Iter: 1370 loss: 1.09592906e-06
Iter: 1371 loss: 1.09586256e-06
Iter: 1372 loss: 1.09562961e-06
Iter: 1373 loss: 1.09502139e-06
Iter: 1374 loss: 1.0953645e-06
Iter: 1375 loss: 1.0946294e-06
Iter: 1376 loss: 1.09486086e-06
Iter: 1377 loss: 1.0943445e-06
Iter: 1378 loss: 1.09411803e-06
Iter: 1379 loss: 1.09351276e-06
Iter: 1380 loss: 1.09472444e-06
Iter: 1381 loss: 1.09312862e-06
Iter: 1382 loss: 1.09242592e-06
Iter: 1383 loss: 1.09990765e-06
Iter: 1384 loss: 1.092415e-06
Iter: 1385 loss: 1.0919357e-06
Iter: 1386 loss: 1.09288248e-06
Iter: 1387 loss: 1.09171242e-06
Iter: 1388 loss: 1.09095163e-06
Iter: 1389 loss: 1.09312543e-06
Iter: 1390 loss: 1.09069231e-06
Iter: 1391 loss: 1.09029963e-06
Iter: 1392 loss: 1.09079e-06
Iter: 1393 loss: 1.09005782e-06
Iter: 1394 loss: 1.08938912e-06
Iter: 1395 loss: 1.09050131e-06
Iter: 1396 loss: 1.08910876e-06
Iter: 1397 loss: 1.0885351e-06
Iter: 1398 loss: 1.09555128e-06
Iter: 1399 loss: 1.08853351e-06
Iter: 1400 loss: 1.08817517e-06
Iter: 1401 loss: 1.08785014e-06
Iter: 1402 loss: 1.08769927e-06
Iter: 1403 loss: 1.08716745e-06
Iter: 1404 loss: 1.09129769e-06
Iter: 1405 loss: 1.08715437e-06
Iter: 1406 loss: 1.08661891e-06
Iter: 1407 loss: 1.0858937e-06
Iter: 1408 loss: 1.08585255e-06
Iter: 1409 loss: 1.0852491e-06
Iter: 1410 loss: 1.0852375e-06
Iter: 1411 loss: 1.0848172e-06
Iter: 1412 loss: 1.09034477e-06
Iter: 1413 loss: 1.08480572e-06
Iter: 1414 loss: 1.08454333e-06
Iter: 1415 loss: 1.08392828e-06
Iter: 1416 loss: 1.08876202e-06
Iter: 1417 loss: 1.08384484e-06
Iter: 1418 loss: 1.08311781e-06
Iter: 1419 loss: 1.08458926e-06
Iter: 1420 loss: 1.08277e-06
Iter: 1421 loss: 1.08231825e-06
Iter: 1422 loss: 1.0823037e-06
Iter: 1423 loss: 1.08190636e-06
Iter: 1424 loss: 1.0822838e-06
Iter: 1425 loss: 1.08164488e-06
Iter: 1426 loss: 1.08115546e-06
Iter: 1427 loss: 1.08089466e-06
Iter: 1428 loss: 1.08066251e-06
Iter: 1429 loss: 1.0800261e-06
Iter: 1430 loss: 1.08376196e-06
Iter: 1431 loss: 1.07997857e-06
Iter: 1432 loss: 1.07944356e-06
Iter: 1433 loss: 1.08399865e-06
Iter: 1434 loss: 1.07938274e-06
Iter: 1435 loss: 1.07902667e-06
Iter: 1436 loss: 1.07916821e-06
Iter: 1437 loss: 1.07884557e-06
Iter: 1438 loss: 1.07830738e-06
Iter: 1439 loss: 1.07848439e-06
Iter: 1440 loss: 1.07796041e-06
Iter: 1441 loss: 1.0774661e-06
Iter: 1442 loss: 1.0844e-06
Iter: 1443 loss: 1.0774653e-06
Iter: 1444 loss: 1.07714527e-06
Iter: 1445 loss: 1.07746382e-06
Iter: 1446 loss: 1.07693609e-06
Iter: 1447 loss: 1.07643666e-06
Iter: 1448 loss: 1.08030645e-06
Iter: 1449 loss: 1.07641279e-06
Iter: 1450 loss: 1.07621668e-06
Iter: 1451 loss: 1.07560822e-06
Iter: 1452 loss: 1.08083668e-06
Iter: 1453 loss: 1.07553194e-06
Iter: 1454 loss: 1.07476467e-06
Iter: 1455 loss: 1.07729625e-06
Iter: 1456 loss: 1.0745805e-06
Iter: 1457 loss: 1.07413155e-06
Iter: 1458 loss: 1.07865787e-06
Iter: 1459 loss: 1.07410722e-06
Iter: 1460 loss: 1.07359597e-06
Iter: 1461 loss: 1.07364986e-06
Iter: 1462 loss: 1.07319261e-06
Iter: 1463 loss: 1.0727224e-06
Iter: 1464 loss: 1.07482083e-06
Iter: 1465 loss: 1.07261371e-06
Iter: 1466 loss: 1.07221649e-06
Iter: 1467 loss: 1.07210144e-06
Iter: 1468 loss: 1.07184201e-06
Iter: 1469 loss: 1.07127948e-06
Iter: 1470 loss: 1.07126652e-06
Iter: 1471 loss: 1.0709922e-06
Iter: 1472 loss: 1.07053916e-06
Iter: 1473 loss: 1.0705113e-06
Iter: 1474 loss: 1.06989523e-06
Iter: 1475 loss: 1.0722357e-06
Iter: 1476 loss: 1.06971356e-06
Iter: 1477 loss: 1.06923835e-06
Iter: 1478 loss: 1.07349217e-06
Iter: 1479 loss: 1.06920186e-06
Iter: 1480 loss: 1.06884988e-06
Iter: 1481 loss: 1.07221831e-06
Iter: 1482 loss: 1.06883772e-06
Iter: 1483 loss: 1.06848495e-06
Iter: 1484 loss: 1.06842072e-06
Iter: 1485 loss: 1.06823086e-06
Iter: 1486 loss: 1.06785342e-06
Iter: 1487 loss: 1.06742948e-06
Iter: 1488 loss: 1.06735206e-06
Iter: 1489 loss: 1.06667744e-06
Iter: 1490 loss: 1.06847517e-06
Iter: 1491 loss: 1.0664786e-06
Iter: 1492 loss: 1.06585821e-06
Iter: 1493 loss: 1.06782591e-06
Iter: 1494 loss: 1.06566199e-06
Iter: 1495 loss: 1.06520883e-06
Iter: 1496 loss: 1.06523066e-06
Iter: 1497 loss: 1.06492303e-06
Iter: 1498 loss: 1.064245e-06
Iter: 1499 loss: 1.07379083e-06
Iter: 1500 loss: 1.06421317e-06
Iter: 1501 loss: 1.06365815e-06
Iter: 1502 loss: 1.06365394e-06
Iter: 1503 loss: 1.06326206e-06
Iter: 1504 loss: 1.06511402e-06
Iter: 1505 loss: 1.06317e-06
Iter: 1506 loss: 1.06276127e-06
Iter: 1507 loss: 1.06301309e-06
Iter: 1508 loss: 1.06250161e-06
Iter: 1509 loss: 1.06210234e-06
Iter: 1510 loss: 1.06201105e-06
Iter: 1511 loss: 1.06178993e-06
Iter: 1512 loss: 1.0612888e-06
Iter: 1513 loss: 1.06128e-06
Iter: 1514 loss: 1.0609599e-06
Iter: 1515 loss: 1.06342429e-06
Iter: 1516 loss: 1.06091375e-06
Iter: 1517 loss: 1.06072753e-06
Iter: 1518 loss: 1.06023185e-06
Iter: 1519 loss: 1.06625851e-06
Iter: 1520 loss: 1.0601924e-06
Iter: 1521 loss: 1.05956883e-06
Iter: 1522 loss: 1.06165749e-06
Iter: 1523 loss: 1.05938159e-06
Iter: 1524 loss: 1.05897448e-06
Iter: 1525 loss: 1.05963409e-06
Iter: 1526 loss: 1.05876484e-06
Iter: 1527 loss: 1.05821971e-06
Iter: 1528 loss: 1.05996446e-06
Iter: 1529 loss: 1.05806362e-06
Iter: 1530 loss: 1.05764298e-06
Iter: 1531 loss: 1.06297523e-06
Iter: 1532 loss: 1.05766662e-06
Iter: 1533 loss: 1.05734387e-06
Iter: 1534 loss: 1.05677407e-06
Iter: 1535 loss: 1.05678441e-06
Iter: 1536 loss: 1.05633967e-06
Iter: 1537 loss: 1.06066886e-06
Iter: 1538 loss: 1.05631739e-06
Iter: 1539 loss: 1.05588151e-06
Iter: 1540 loss: 1.05740151e-06
Iter: 1541 loss: 1.05577806e-06
Iter: 1542 loss: 1.05537947e-06
Iter: 1543 loss: 1.05566448e-06
Iter: 1544 loss: 1.05514414e-06
Iter: 1545 loss: 1.05478443e-06
Iter: 1546 loss: 1.05470463e-06
Iter: 1547 loss: 1.05444883e-06
Iter: 1548 loss: 1.05408503e-06
Iter: 1549 loss: 1.05401296e-06
Iter: 1550 loss: 1.05377228e-06
Iter: 1551 loss: 1.05373363e-06
Iter: 1552 loss: 1.05357549e-06
Iter: 1553 loss: 1.05323841e-06
Iter: 1554 loss: 1.05286563e-06
Iter: 1555 loss: 1.05285528e-06
Iter: 1556 loss: 1.0523313e-06
Iter: 1557 loss: 1.05489198e-06
Iter: 1558 loss: 1.05231993e-06
Iter: 1559 loss: 1.05189588e-06
Iter: 1560 loss: 1.05155607e-06
Iter: 1561 loss: 1.05145114e-06
Iter: 1562 loss: 1.05077072e-06
Iter: 1563 loss: 1.05712775e-06
Iter: 1564 loss: 1.05075014e-06
Iter: 1565 loss: 1.05030165e-06
Iter: 1566 loss: 1.05297931e-06
Iter: 1567 loss: 1.05027573e-06
Iter: 1568 loss: 1.04990795e-06
Iter: 1569 loss: 1.05017034e-06
Iter: 1570 loss: 1.04967444e-06
Iter: 1571 loss: 1.04930837e-06
Iter: 1572 loss: 1.04919343e-06
Iter: 1573 loss: 1.04895457e-06
Iter: 1574 loss: 1.04858623e-06
Iter: 1575 loss: 1.04856144e-06
Iter: 1576 loss: 1.04833134e-06
Iter: 1577 loss: 1.04787875e-06
Iter: 1578 loss: 1.05761774e-06
Iter: 1579 loss: 1.04787432e-06
Iter: 1580 loss: 1.04741264e-06
Iter: 1581 loss: 1.05329877e-06
Iter: 1582 loss: 1.0474281e-06
Iter: 1583 loss: 1.04693117e-06
Iter: 1584 loss: 1.04843355e-06
Iter: 1585 loss: 1.04678907e-06
Iter: 1586 loss: 1.04648484e-06
Iter: 1587 loss: 1.04648416e-06
Iter: 1588 loss: 1.04628919e-06
Iter: 1589 loss: 1.04585411e-06
Iter: 1590 loss: 1.04664423e-06
Iter: 1591 loss: 1.04568767e-06
Iter: 1592 loss: 1.0453175e-06
Iter: 1593 loss: 1.04492824e-06
Iter: 1594 loss: 1.04483911e-06
Iter: 1595 loss: 1.04421179e-06
Iter: 1596 loss: 1.04600485e-06
Iter: 1597 loss: 1.04400601e-06
Iter: 1598 loss: 1.04345145e-06
Iter: 1599 loss: 1.04832861e-06
Iter: 1600 loss: 1.04338176e-06
Iter: 1601 loss: 1.04295441e-06
Iter: 1602 loss: 1.04469507e-06
Iter: 1603 loss: 1.04282276e-06
Iter: 1604 loss: 1.04239825e-06
Iter: 1605 loss: 1.04279684e-06
Iter: 1606 loss: 1.04207504e-06
Iter: 1607 loss: 1.04169249e-06
Iter: 1608 loss: 1.04344053e-06
Iter: 1609 loss: 1.04160472e-06
Iter: 1610 loss: 1.04125877e-06
Iter: 1611 loss: 1.04239166e-06
Iter: 1612 loss: 1.04110984e-06
Iter: 1613 loss: 1.04063383e-06
Iter: 1614 loss: 1.04072296e-06
Iter: 1615 loss: 1.04025241e-06
Iter: 1616 loss: 1.03984576e-06
Iter: 1617 loss: 1.04186438e-06
Iter: 1618 loss: 1.03976618e-06
Iter: 1619 loss: 1.03925868e-06
Iter: 1620 loss: 1.0429535e-06
Iter: 1621 loss: 1.03919092e-06
Iter: 1622 loss: 1.03900402e-06
Iter: 1623 loss: 1.03881621e-06
Iter: 1624 loss: 1.03875709e-06
Iter: 1625 loss: 1.03845241e-06
Iter: 1626 loss: 1.03858724e-06
Iter: 1627 loss: 1.03824516e-06
Iter: 1628 loss: 1.03761181e-06
Iter: 1629 loss: 1.03800016e-06
Iter: 1630 loss: 1.03723141e-06
Iter: 1631 loss: 1.03673415e-06
Iter: 1632 loss: 1.03702905e-06
Iter: 1633 loss: 1.03643129e-06
Iter: 1634 loss: 1.03586387e-06
Iter: 1635 loss: 1.04021842e-06
Iter: 1636 loss: 1.03575167e-06
Iter: 1637 loss: 1.03542538e-06
Iter: 1638 loss: 1.0398162e-06
Iter: 1639 loss: 1.03542902e-06
Iter: 1640 loss: 1.03510274e-06
Iter: 1641 loss: 1.03478749e-06
Iter: 1642 loss: 1.03469233e-06
Iter: 1643 loss: 1.03421507e-06
Iter: 1644 loss: 1.03540674e-06
Iter: 1645 loss: 1.03402522e-06
Iter: 1646 loss: 1.03354273e-06
Iter: 1647 loss: 1.03812135e-06
Iter: 1648 loss: 1.03352181e-06
Iter: 1649 loss: 1.03316165e-06
Iter: 1650 loss: 1.03467357e-06
Iter: 1651 loss: 1.03313494e-06
Iter: 1652 loss: 1.0328572e-06
Iter: 1653 loss: 1.03308787e-06
Iter: 1654 loss: 1.03272555e-06
Iter: 1655 loss: 1.03240279e-06
Iter: 1656 loss: 1.03627372e-06
Iter: 1657 loss: 1.03238949e-06
Iter: 1658 loss: 1.03223897e-06
Iter: 1659 loss: 1.03177399e-06
Iter: 1660 loss: 1.03350828e-06
Iter: 1661 loss: 1.03152126e-06
Iter: 1662 loss: 1.03107777e-06
Iter: 1663 loss: 1.03744583e-06
Iter: 1664 loss: 1.03109403e-06
Iter: 1665 loss: 1.03067703e-06
Iter: 1666 loss: 1.0313704e-06
Iter: 1667 loss: 1.030455e-06
Iter: 1668 loss: 1.02999229e-06
Iter: 1669 loss: 1.03078219e-06
Iter: 1670 loss: 1.02979493e-06
Iter: 1671 loss: 1.02930653e-06
Iter: 1672 loss: 1.0292614e-06
Iter: 1673 loss: 1.02888566e-06
Iter: 1674 loss: 1.02856347e-06
Iter: 1675 loss: 1.02856006e-06
Iter: 1676 loss: 1.02822275e-06
Iter: 1677 loss: 1.02810827e-06
Iter: 1678 loss: 1.02792035e-06
Iter: 1679 loss: 1.02743081e-06
Iter: 1680 loss: 1.02811828e-06
Iter: 1681 loss: 1.02718025e-06
Iter: 1682 loss: 1.02675881e-06
Iter: 1683 loss: 1.02871809e-06
Iter: 1684 loss: 1.02666377e-06
Iter: 1685 loss: 1.02629269e-06
Iter: 1686 loss: 1.02947774e-06
Iter: 1687 loss: 1.0262288e-06
Iter: 1688 loss: 1.02595379e-06
Iter: 1689 loss: 1.02608954e-06
Iter: 1690 loss: 1.02576018e-06
Iter: 1691 loss: 1.02536444e-06
Iter: 1692 loss: 1.029656e-06
Iter: 1693 loss: 1.0253616e-06
Iter: 1694 loss: 1.02500337e-06
Iter: 1695 loss: 1.02475508e-06
Iter: 1696 loss: 1.02461911e-06
Iter: 1697 loss: 1.02434501e-06
Iter: 1698 loss: 1.02403396e-06
Iter: 1699 loss: 1.02402078e-06
Iter: 1700 loss: 1.02350316e-06
Iter: 1701 loss: 1.02676245e-06
Iter: 1702 loss: 1.02346507e-06
Iter: 1703 loss: 1.02310344e-06
Iter: 1704 loss: 1.02586773e-06
Iter: 1705 loss: 1.02309798e-06
Iter: 1706 loss: 1.02278921e-06
Iter: 1707 loss: 1.02255922e-06
Iter: 1708 loss: 1.02249032e-06
Iter: 1709 loss: 1.02198987e-06
Iter: 1710 loss: 1.02276795e-06
Iter: 1711 loss: 1.02174386e-06
Iter: 1712 loss: 1.02139597e-06
Iter: 1713 loss: 1.02139484e-06
Iter: 1714 loss: 1.02103695e-06
Iter: 1715 loss: 1.02081322e-06
Iter: 1716 loss: 1.02070499e-06
Iter: 1717 loss: 1.02022545e-06
Iter: 1718 loss: 1.02191211e-06
Iter: 1719 loss: 1.02012632e-06
Iter: 1720 loss: 1.01976593e-06
Iter: 1721 loss: 1.02236686e-06
Iter: 1722 loss: 1.0197499e-06
Iter: 1723 loss: 1.01940986e-06
Iter: 1724 loss: 1.01968499e-06
Iter: 1725 loss: 1.01916419e-06
Iter: 1726 loss: 1.01903584e-06
Iter: 1727 loss: 1.01897592e-06
Iter: 1728 loss: 1.0188478e-06
Iter: 1729 loss: 1.01848309e-06
Iter: 1730 loss: 1.02075e-06
Iter: 1731 loss: 1.01837418e-06
Iter: 1732 loss: 1.01780449e-06
Iter: 1733 loss: 1.0187772e-06
Iter: 1734 loss: 1.01753676e-06
Iter: 1735 loss: 1.01707758e-06
Iter: 1736 loss: 1.0177539e-06
Iter: 1737 loss: 1.01681962e-06
Iter: 1738 loss: 1.01644616e-06
Iter: 1739 loss: 1.02213176e-06
Iter: 1740 loss: 1.01645423e-06
Iter: 1741 loss: 1.01613978e-06
Iter: 1742 loss: 1.01665705e-06
Iter: 1743 loss: 1.01600551e-06
Iter: 1744 loss: 1.01562136e-06
Iter: 1745 loss: 1.01566241e-06
Iter: 1746 loss: 1.01534556e-06
Iter: 1747 loss: 1.01494629e-06
Iter: 1748 loss: 1.01582327e-06
Iter: 1749 loss: 1.01479782e-06
Iter: 1750 loss: 1.01431328e-06
Iter: 1751 loss: 1.01742489e-06
Iter: 1752 loss: 1.01428213e-06
Iter: 1753 loss: 1.01390992e-06
Iter: 1754 loss: 1.01608123e-06
Iter: 1755 loss: 1.01384796e-06
Iter: 1756 loss: 1.01357261e-06
Iter: 1757 loss: 1.01383546e-06
Iter: 1758 loss: 1.01342403e-06
Iter: 1759 loss: 1.01316311e-06
Iter: 1760 loss: 1.01612363e-06
Iter: 1761 loss: 1.01315379e-06
Iter: 1762 loss: 1.01293972e-06
Iter: 1763 loss: 1.01325236e-06
Iter: 1764 loss: 1.01284377e-06
Iter: 1765 loss: 1.01244268e-06
Iter: 1766 loss: 1.01244348e-06
Iter: 1767 loss: 1.0121455e-06
Iter: 1768 loss: 1.01186833e-06
Iter: 1769 loss: 1.01140961e-06
Iter: 1770 loss: 1.01139449e-06
Iter: 1771 loss: 1.01095634e-06
Iter: 1772 loss: 1.01566911e-06
Iter: 1773 loss: 1.0109336e-06
Iter: 1774 loss: 1.01058413e-06
Iter: 1775 loss: 1.01068258e-06
Iter: 1776 loss: 1.01034402e-06
Iter: 1777 loss: 1.00996795e-06
Iter: 1778 loss: 1.01517344e-06
Iter: 1779 loss: 1.00995408e-06
Iter: 1780 loss: 1.00971806e-06
Iter: 1781 loss: 1.00964974e-06
Iter: 1782 loss: 1.00946636e-06
Iter: 1783 loss: 1.00908926e-06
Iter: 1784 loss: 1.01012211e-06
Iter: 1785 loss: 1.00897364e-06
Iter: 1786 loss: 1.00858801e-06
Iter: 1787 loss: 1.00869477e-06
Iter: 1788 loss: 1.00830903e-06
Iter: 1789 loss: 1.00804778e-06
Iter: 1790 loss: 1.00798695e-06
Iter: 1791 loss: 1.00781085e-06
Iter: 1792 loss: 1.00769967e-06
Iter: 1793 loss: 1.00758666e-06
Iter: 1794 loss: 1.00722968e-06
Iter: 1795 loss: 1.00937791e-06
Iter: 1796 loss: 1.00720376e-06
Iter: 1797 loss: 1.00689567e-06
Iter: 1798 loss: 1.00751708e-06
Iter: 1799 loss: 1.00680359e-06
Iter: 1800 loss: 1.00651027e-06
Iter: 1801 loss: 1.00722286e-06
Iter: 1802 loss: 1.00638135e-06
Iter: 1803 loss: 1.00616353e-06
Iter: 1804 loss: 1.00572731e-06
Iter: 1805 loss: 1.01431328e-06
Iter: 1806 loss: 1.00571583e-06
Iter: 1807 loss: 1.00522493e-06
Iter: 1808 loss: 1.00681689e-06
Iter: 1809 loss: 1.00510772e-06
Iter: 1810 loss: 1.00467878e-06
Iter: 1811 loss: 1.00852583e-06
Iter: 1812 loss: 1.0046665e-06
Iter: 1813 loss: 1.00436159e-06
Iter: 1814 loss: 1.00499392e-06
Iter: 1815 loss: 1.00420948e-06
Iter: 1816 loss: 1.00383e-06
Iter: 1817 loss: 1.00479315e-06
Iter: 1818 loss: 1.00366174e-06
Iter: 1819 loss: 1.00330794e-06
Iter: 1820 loss: 1.00416855e-06
Iter: 1821 loss: 1.00312559e-06
Iter: 1822 loss: 1.00279567e-06
Iter: 1823 loss: 1.00361694e-06
Iter: 1824 loss: 1.00266209e-06
Iter: 1825 loss: 1.00232569e-06
Iter: 1826 loss: 1.00441241e-06
Iter: 1827 loss: 1.00226589e-06
Iter: 1828 loss: 1.00193199e-06
Iter: 1829 loss: 1.0027768e-06
Iter: 1830 loss: 1.0018075e-06
Iter: 1831 loss: 1.00158809e-06
Iter: 1832 loss: 1.00156512e-06
Iter: 1833 loss: 1.00139073e-06
Iter: 1834 loss: 1.00107354e-06
Iter: 1835 loss: 1.00107673e-06
Iter: 1836 loss: 1.00075977e-06
Iter: 1837 loss: 1.00360228e-06
Iter: 1838 loss: 1.00074635e-06
Iter: 1839 loss: 1.00053967e-06
Iter: 1840 loss: 1.00022748e-06
Iter: 1841 loss: 1.00019304e-06
Iter: 1842 loss: 9.99685767e-07
Iter: 1843 loss: 1.00007355e-06
Iter: 1844 loss: 9.99343683e-07
Iter: 1845 loss: 9.988795e-07
Iter: 1846 loss: 9.98848236e-07
Iter: 1847 loss: 9.98476253e-07
Iter: 1848 loss: 9.97978873e-07
Iter: 1849 loss: 9.97952384e-07
Iter: 1850 loss: 9.97558345e-07
Iter: 1851 loss: 9.98308565e-07
Iter: 1852 loss: 9.97419647e-07
Iter: 1853 loss: 9.97021516e-07
Iter: 1854 loss: 1.00000398e-06
Iter: 1855 loss: 9.96994459e-07
Iter: 1856 loss: 9.96673066e-07
Iter: 1857 loss: 9.96297103e-07
Iter: 1858 loss: 9.96250265e-07
Iter: 1859 loss: 9.95769369e-07
Iter: 1860 loss: 9.99687813e-07
Iter: 1861 loss: 9.95723667e-07
Iter: 1862 loss: 9.95402161e-07
Iter: 1863 loss: 9.97978e-07
Iter: 1864 loss: 9.95394203e-07
Iter: 1865 loss: 9.95129312e-07
Iter: 1866 loss: 9.96535618e-07
Iter: 1867 loss: 9.95075766e-07
Iter: 1868 loss: 9.94827587e-07
Iter: 1869 loss: 9.95515e-07
Iter: 1870 loss: 9.9473e-07
Iter: 1871 loss: 9.94492e-07
Iter: 1872 loss: 9.94278139e-07
Iter: 1873 loss: 9.9422391e-07
Iter: 1874 loss: 9.93879098e-07
Iter: 1875 loss: 9.95699565e-07
Iter: 1876 loss: 9.93856361e-07
Iter: 1877 loss: 9.93516096e-07
Iter: 1878 loss: 9.93551339e-07
Iter: 1879 loss: 9.93263e-07
Iter: 1880 loss: 9.92789865e-07
Iter: 1881 loss: 9.93320782e-07
Iter: 1882 loss: 9.92547484e-07
Iter: 1883 loss: 9.92131731e-07
Iter: 1884 loss: 9.92385594e-07
Iter: 1885 loss: 9.91800562e-07
Iter: 1886 loss: 9.91340244e-07
Iter: 1887 loss: 9.93282356e-07
Iter: 1888 loss: 9.91251113e-07
Iter: 1889 loss: 9.90789204e-07
Iter: 1890 loss: 9.9325166e-07
Iter: 1891 loss: 9.9069041e-07
Iter: 1892 loss: 9.90370609e-07
Iter: 1893 loss: 9.92097398e-07
Iter: 1894 loss: 9.90298076e-07
Iter: 1895 loss: 9.89897785e-07
Iter: 1896 loss: 9.90472e-07
Iter: 1897 loss: 9.89745104e-07
Iter: 1898 loss: 9.8941e-07
Iter: 1899 loss: 9.90781587e-07
Iter: 1900 loss: 9.89320824e-07
Iter: 1901 loss: 9.88957368e-07
Iter: 1902 loss: 9.91521e-07
Iter: 1903 loss: 9.88935881e-07
Iter: 1904 loss: 9.88682586e-07
Iter: 1905 loss: 9.8916064e-07
Iter: 1906 loss: 9.88595275e-07
Iter: 1907 loss: 9.88364832e-07
Iter: 1908 loss: 9.88328793e-07
Iter: 1909 loss: 9.88194415e-07
Iter: 1910 loss: 9.87826184e-07
Iter: 1911 loss: 9.87699e-07
Iter: 1912 loss: 9.8752e-07
Iter: 1913 loss: 9.87083695e-07
Iter: 1914 loss: 9.87105864e-07
Iter: 1915 loss: 9.86834493e-07
Iter: 1916 loss: 9.86495934e-07
Iter: 1917 loss: 9.96296876e-07
Iter: 1918 loss: 9.86493092e-07
Iter: 1919 loss: 9.85959446e-07
Iter: 1920 loss: 9.89200316e-07
Iter: 1921 loss: 9.85899874e-07
Iter: 1922 loss: 9.85576548e-07
Iter: 1923 loss: 9.85709448e-07
Iter: 1924 loss: 9.85403403e-07
Iter: 1925 loss: 9.84944904e-07
Iter: 1926 loss: 9.85425459e-07
Iter: 1927 loss: 9.84692861e-07
Iter: 1928 loss: 9.84223107e-07
Iter: 1929 loss: 9.88447255e-07
Iter: 1930 loss: 9.84192e-07
Iter: 1931 loss: 9.83851123e-07
Iter: 1932 loss: 9.84111125e-07
Iter: 1933 loss: 9.8361761e-07
Iter: 1934 loss: 9.83330551e-07
Iter: 1935 loss: 9.83324071e-07
Iter: 1936 loss: 9.83117e-07
Iter: 1937 loss: 9.84031431e-07
Iter: 1938 loss: 9.83064865e-07
Iter: 1939 loss: 9.82836241e-07
Iter: 1940 loss: 9.82441634e-07
Iter: 1941 loss: 9.92136e-07
Iter: 1942 loss: 9.82445727e-07
Iter: 1943 loss: 9.82123e-07
Iter: 1944 loss: 9.86331088e-07
Iter: 1945 loss: 9.82124334e-07
Iter: 1946 loss: 9.81899689e-07
Iter: 1947 loss: 9.81856488e-07
Iter: 1948 loss: 9.81718813e-07
Iter: 1949 loss: 9.81378207e-07
Iter: 1950 loss: 9.81904691e-07
Iter: 1951 loss: 9.81194262e-07
Iter: 1952 loss: 9.80853656e-07
Iter: 1953 loss: 9.84490498e-07
Iter: 1954 loss: 9.80864684e-07
Iter: 1955 loss: 9.80606728e-07
Iter: 1956 loss: 9.80109462e-07
Iter: 1957 loss: 9.90520562e-07
Iter: 1958 loss: 9.80112759e-07
Iter: 1959 loss: 9.7962743e-07
Iter: 1960 loss: 9.79983724e-07
Iter: 1961 loss: 9.79313882e-07
Iter: 1962 loss: 9.78802518e-07
Iter: 1963 loss: 9.83506197e-07
Iter: 1964 loss: 9.78760227e-07
Iter: 1965 loss: 9.78309799e-07
Iter: 1966 loss: 9.78770572e-07
Iter: 1967 loss: 9.78057301e-07
Iter: 1968 loss: 9.77512514e-07
Iter: 1969 loss: 9.78990329e-07
Iter: 1970 loss: 9.77323e-07
Iter: 1971 loss: 9.77307e-07
Iter: 1972 loss: 9.77088121e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4
+ date
Mon Oct 26 10:16:53 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f5c0cb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f5c0cba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f5c0700d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f5c193d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f5c1949d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f5c03b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f407b6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f407836a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40759488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f407597b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f406eb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f406e3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4067e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4068a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40657ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4062c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4062c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40626400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40580048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40580ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4058a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4053fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f405016a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40533f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4053b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f404e1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4049cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40467840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40444620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40467510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f4042eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f403bf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f403ea8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f403846a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f403419d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f40353f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.34886087e-05
Iter: 2 loss: 0.00048860861
Iter: 3 loss: 6.84604893e-05
Iter: 4 loss: 6.54753821e-05
Iter: 5 loss: 6.06673384e-05
Iter: 6 loss: 6.06319e-05
Iter: 7 loss: 5.70982666e-05
Iter: 8 loss: 6.06183312e-05
Iter: 9 loss: 5.51193225e-05
Iter: 10 loss: 5.20779286e-05
Iter: 11 loss: 4.59538787e-05
Iter: 12 loss: 0.000160870433
Iter: 13 loss: 4.58684153e-05
Iter: 14 loss: 4.26673796e-05
Iter: 15 loss: 8.50924698e-05
Iter: 16 loss: 4.26513579e-05
Iter: 17 loss: 4.08762e-05
Iter: 18 loss: 4.2014366e-05
Iter: 19 loss: 3.97506519e-05
Iter: 20 loss: 3.75418749e-05
Iter: 21 loss: 3.38141872e-05
Iter: 22 loss: 3.38068894e-05
Iter: 23 loss: 3.06491129e-05
Iter: 24 loss: 6.86851272e-05
Iter: 25 loss: 3.06093607e-05
Iter: 26 loss: 2.86849845e-05
Iter: 27 loss: 3.23309287e-05
Iter: 28 loss: 2.78684274e-05
Iter: 29 loss: 2.63912734e-05
Iter: 30 loss: 3.40890838e-05
Iter: 31 loss: 2.61581717e-05
Iter: 32 loss: 2.48307097e-05
Iter: 33 loss: 2.37844488e-05
Iter: 34 loss: 2.33771025e-05
Iter: 35 loss: 2.20230922e-05
Iter: 36 loss: 3.05478898e-05
Iter: 37 loss: 2.18678797e-05
Iter: 38 loss: 2.04066237e-05
Iter: 39 loss: 2.4715584e-05
Iter: 40 loss: 1.99569531e-05
Iter: 41 loss: 1.97121317e-05
Iter: 42 loss: 1.95808207e-05
Iter: 43 loss: 1.90926803e-05
Iter: 44 loss: 1.91150721e-05
Iter: 45 loss: 1.8707824e-05
Iter: 46 loss: 1.82670865e-05
Iter: 47 loss: 1.84815126e-05
Iter: 48 loss: 1.797195e-05
Iter: 49 loss: 1.7393937e-05
Iter: 50 loss: 1.8858389e-05
Iter: 51 loss: 1.71937136e-05
Iter: 52 loss: 1.67206017e-05
Iter: 53 loss: 1.69901905e-05
Iter: 54 loss: 1.64123157e-05
Iter: 55 loss: 1.57650557e-05
Iter: 56 loss: 1.67006783e-05
Iter: 57 loss: 1.54498084e-05
Iter: 58 loss: 1.49103616e-05
Iter: 59 loss: 1.7760578e-05
Iter: 60 loss: 1.48269373e-05
Iter: 61 loss: 1.42748304e-05
Iter: 62 loss: 1.42695553e-05
Iter: 63 loss: 1.383171e-05
Iter: 64 loss: 1.34028714e-05
Iter: 65 loss: 1.97259869e-05
Iter: 66 loss: 1.34024394e-05
Iter: 67 loss: 1.30809249e-05
Iter: 68 loss: 1.27565399e-05
Iter: 69 loss: 1.26921132e-05
Iter: 70 loss: 1.22893789e-05
Iter: 71 loss: 1.64819376e-05
Iter: 72 loss: 1.22778201e-05
Iter: 73 loss: 1.19727392e-05
Iter: 74 loss: 1.22533502e-05
Iter: 75 loss: 1.17955833e-05
Iter: 76 loss: 1.17186537e-05
Iter: 77 loss: 1.15708699e-05
Iter: 78 loss: 1.15108605e-05
Iter: 79 loss: 1.13625783e-05
Iter: 80 loss: 1.28414295e-05
Iter: 81 loss: 1.13435326e-05
Iter: 82 loss: 1.11459167e-05
Iter: 83 loss: 1.25958813e-05
Iter: 84 loss: 1.11295594e-05
Iter: 85 loss: 1.09715202e-05
Iter: 86 loss: 1.09103694e-05
Iter: 87 loss: 1.08246404e-05
Iter: 88 loss: 1.06182433e-05
Iter: 89 loss: 1.10132114e-05
Iter: 90 loss: 1.05313811e-05
Iter: 91 loss: 1.02527447e-05
Iter: 92 loss: 1.04563424e-05
Iter: 93 loss: 1.00811394e-05
Iter: 94 loss: 9.85563111e-06
Iter: 95 loss: 1.07593805e-05
Iter: 96 loss: 9.80493132e-06
Iter: 97 loss: 9.5903e-06
Iter: 98 loss: 9.97603638e-06
Iter: 99 loss: 9.49680725e-06
Iter: 100 loss: 9.333653e-06
Iter: 101 loss: 1.05630306e-05
Iter: 102 loss: 9.32095827e-06
Iter: 103 loss: 9.15164946e-06
Iter: 104 loss: 9.0852518e-06
Iter: 105 loss: 8.99402585e-06
Iter: 106 loss: 8.83488792e-06
Iter: 107 loss: 8.83446137e-06
Iter: 108 loss: 8.81474443e-06
Iter: 109 loss: 8.79417803e-06
Iter: 110 loss: 8.74598754e-06
Iter: 111 loss: 8.61838271e-06
Iter: 112 loss: 9.53739345e-06
Iter: 113 loss: 8.59060765e-06
Iter: 114 loss: 8.47920455e-06
Iter: 115 loss: 9.52095e-06
Iter: 116 loss: 8.47454339e-06
Iter: 117 loss: 8.38755568e-06
Iter: 118 loss: 8.57254054e-06
Iter: 119 loss: 8.35313949e-06
Iter: 120 loss: 8.28193697e-06
Iter: 121 loss: 8.17749606e-06
Iter: 122 loss: 8.17483578e-06
Iter: 123 loss: 8.06902335e-06
Iter: 124 loss: 9.61828482e-06
Iter: 125 loss: 8.0690088e-06
Iter: 126 loss: 7.98376186e-06
Iter: 127 loss: 7.92695e-06
Iter: 128 loss: 7.8949106e-06
Iter: 129 loss: 7.75807439e-06
Iter: 130 loss: 8.24990457e-06
Iter: 131 loss: 7.72326803e-06
Iter: 132 loss: 7.61481624e-06
Iter: 133 loss: 7.9242e-06
Iter: 134 loss: 7.58045189e-06
Iter: 135 loss: 7.48934144e-06
Iter: 136 loss: 8.16051488e-06
Iter: 137 loss: 7.4820864e-06
Iter: 138 loss: 7.41635176e-06
Iter: 139 loss: 7.49250376e-06
Iter: 140 loss: 7.38133167e-06
Iter: 141 loss: 7.3109577e-06
Iter: 142 loss: 8.20111563e-06
Iter: 143 loss: 7.31019645e-06
Iter: 144 loss: 7.24027177e-06
Iter: 145 loss: 7.72362637e-06
Iter: 146 loss: 7.23350149e-06
Iter: 147 loss: 7.21336528e-06
Iter: 148 loss: 7.16583054e-06
Iter: 149 loss: 7.74915225e-06
Iter: 150 loss: 7.1620525e-06
Iter: 151 loss: 7.09147753e-06
Iter: 152 loss: 7.47660442e-06
Iter: 153 loss: 7.08108928e-06
Iter: 154 loss: 7.02562193e-06
Iter: 155 loss: 7.01646786e-06
Iter: 156 loss: 6.97810628e-06
Iter: 157 loss: 6.91666901e-06
Iter: 158 loss: 7.03891237e-06
Iter: 159 loss: 6.89140415e-06
Iter: 160 loss: 6.81366146e-06
Iter: 161 loss: 7.13500276e-06
Iter: 162 loss: 6.7968067e-06
Iter: 163 loss: 6.73620343e-06
Iter: 164 loss: 6.89303488e-06
Iter: 165 loss: 6.71545604e-06
Iter: 166 loss: 6.65479274e-06
Iter: 167 loss: 6.65921652e-06
Iter: 168 loss: 6.60749538e-06
Iter: 169 loss: 6.53770712e-06
Iter: 170 loss: 6.99276279e-06
Iter: 171 loss: 6.53034658e-06
Iter: 172 loss: 6.46925e-06
Iter: 173 loss: 6.61927197e-06
Iter: 174 loss: 6.44727425e-06
Iter: 175 loss: 6.40093276e-06
Iter: 176 loss: 7.01915133e-06
Iter: 177 loss: 6.40073904e-06
Iter: 178 loss: 6.38601114e-06
Iter: 179 loss: 6.37902667e-06
Iter: 180 loss: 6.36805726e-06
Iter: 181 loss: 6.33329455e-06
Iter: 182 loss: 6.36356117e-06
Iter: 183 loss: 6.30407794e-06
Iter: 184 loss: 6.26930159e-06
Iter: 185 loss: 6.26616657e-06
Iter: 186 loss: 6.2424624e-06
Iter: 187 loss: 6.23363667e-06
Iter: 188 loss: 6.22045309e-06
Iter: 189 loss: 6.18598551e-06
Iter: 190 loss: 6.15869703e-06
Iter: 191 loss: 6.14840064e-06
Iter: 192 loss: 6.10131474e-06
Iter: 193 loss: 6.60558317e-06
Iter: 194 loss: 6.10016923e-06
Iter: 195 loss: 6.06371259e-06
Iter: 196 loss: 6.05836294e-06
Iter: 197 loss: 6.03272383e-06
Iter: 198 loss: 5.97831468e-06
Iter: 199 loss: 6.16356601e-06
Iter: 200 loss: 5.96366408e-06
Iter: 201 loss: 5.91923254e-06
Iter: 202 loss: 6.00059775e-06
Iter: 203 loss: 5.90007949e-06
Iter: 204 loss: 5.86035412e-06
Iter: 205 loss: 6.09692506e-06
Iter: 206 loss: 5.85541466e-06
Iter: 207 loss: 5.82681696e-06
Iter: 208 loss: 5.95255187e-06
Iter: 209 loss: 5.82103712e-06
Iter: 210 loss: 5.81781296e-06
Iter: 211 loss: 5.80800224e-06
Iter: 212 loss: 5.79708922e-06
Iter: 213 loss: 5.76708044e-06
Iter: 214 loss: 5.96808241e-06
Iter: 215 loss: 5.7600264e-06
Iter: 216 loss: 5.73437501e-06
Iter: 217 loss: 5.84122427e-06
Iter: 218 loss: 5.72883891e-06
Iter: 219 loss: 5.69468193e-06
Iter: 220 loss: 5.74683145e-06
Iter: 221 loss: 5.67850657e-06
Iter: 222 loss: 5.64993752e-06
Iter: 223 loss: 5.66613562e-06
Iter: 224 loss: 5.63142e-06
Iter: 225 loss: 5.60574836e-06
Iter: 226 loss: 5.60935359e-06
Iter: 227 loss: 5.58615284e-06
Iter: 228 loss: 5.5450223e-06
Iter: 229 loss: 5.84573e-06
Iter: 230 loss: 5.5417122e-06
Iter: 231 loss: 5.51988023e-06
Iter: 232 loss: 5.56524174e-06
Iter: 233 loss: 5.51141056e-06
Iter: 234 loss: 5.48348407e-06
Iter: 235 loss: 5.45933153e-06
Iter: 236 loss: 5.45191324e-06
Iter: 237 loss: 5.41272766e-06
Iter: 238 loss: 5.76181264e-06
Iter: 239 loss: 5.41076724e-06
Iter: 240 loss: 5.38221593e-06
Iter: 241 loss: 5.42518092e-06
Iter: 242 loss: 5.36861444e-06
Iter: 243 loss: 5.36959624e-06
Iter: 244 loss: 5.35707204e-06
Iter: 245 loss: 5.343878e-06
Iter: 246 loss: 5.34517858e-06
Iter: 247 loss: 5.33358798e-06
Iter: 248 loss: 5.32213653e-06
Iter: 249 loss: 5.2966825e-06
Iter: 250 loss: 5.67499774e-06
Iter: 251 loss: 5.2955229e-06
Iter: 252 loss: 5.28090686e-06
Iter: 253 loss: 5.27840621e-06
Iter: 254 loss: 5.26519943e-06
Iter: 255 loss: 5.25387622e-06
Iter: 256 loss: 5.25036103e-06
Iter: 257 loss: 5.22727e-06
Iter: 258 loss: 5.22241817e-06
Iter: 259 loss: 5.20729827e-06
Iter: 260 loss: 5.18158777e-06
Iter: 261 loss: 5.38153154e-06
Iter: 262 loss: 5.17955777e-06
Iter: 263 loss: 5.15374632e-06
Iter: 264 loss: 5.21817e-06
Iter: 265 loss: 5.14471367e-06
Iter: 266 loss: 5.12318547e-06
Iter: 267 loss: 5.21427091e-06
Iter: 268 loss: 5.11879625e-06
Iter: 269 loss: 5.09902702e-06
Iter: 270 loss: 5.0896947e-06
Iter: 271 loss: 5.0802887e-06
Iter: 272 loss: 5.05399566e-06
Iter: 273 loss: 5.22857954e-06
Iter: 274 loss: 5.05113394e-06
Iter: 275 loss: 5.03350566e-06
Iter: 276 loss: 5.13357509e-06
Iter: 277 loss: 5.03112915e-06
Iter: 278 loss: 5.02606736e-06
Iter: 279 loss: 5.02169269e-06
Iter: 280 loss: 5.01770546e-06
Iter: 281 loss: 5.00630813e-06
Iter: 282 loss: 5.0722374e-06
Iter: 283 loss: 5.00304031e-06
Iter: 284 loss: 4.98727786e-06
Iter: 285 loss: 4.98345662e-06
Iter: 286 loss: 4.97353085e-06
Iter: 287 loss: 4.95425684e-06
Iter: 288 loss: 4.95407767e-06
Iter: 289 loss: 4.94550659e-06
Iter: 290 loss: 4.93446e-06
Iter: 291 loss: 4.93367952e-06
Iter: 292 loss: 4.91634592e-06
Iter: 293 loss: 4.90771799e-06
Iter: 294 loss: 4.89942067e-06
Iter: 295 loss: 4.8817119e-06
Iter: 296 loss: 5.10391146e-06
Iter: 297 loss: 4.88154092e-06
Iter: 298 loss: 4.86563476e-06
Iter: 299 loss: 4.88268188e-06
Iter: 300 loss: 4.85704e-06
Iter: 301 loss: 4.83709664e-06
Iter: 302 loss: 4.88435035e-06
Iter: 303 loss: 4.82986388e-06
Iter: 304 loss: 4.81350889e-06
Iter: 305 loss: 4.83055646e-06
Iter: 306 loss: 4.80423114e-06
Iter: 307 loss: 4.78455786e-06
Iter: 308 loss: 4.86404952e-06
Iter: 309 loss: 4.7799831e-06
Iter: 310 loss: 4.77131744e-06
Iter: 311 loss: 4.77124058e-06
Iter: 312 loss: 4.76187461e-06
Iter: 313 loss: 4.82415817e-06
Iter: 314 loss: 4.76101286e-06
Iter: 315 loss: 4.75659954e-06
Iter: 316 loss: 4.74528906e-06
Iter: 317 loss: 4.83458825e-06
Iter: 318 loss: 4.74313902e-06
Iter: 319 loss: 4.73036744e-06
Iter: 320 loss: 4.79462051e-06
Iter: 321 loss: 4.72823e-06
Iter: 322 loss: 4.71380099e-06
Iter: 323 loss: 4.77900903e-06
Iter: 324 loss: 4.71105886e-06
Iter: 325 loss: 4.70206487e-06
Iter: 326 loss: 4.69955239e-06
Iter: 327 loss: 4.69404495e-06
Iter: 328 loss: 4.67975678e-06
Iter: 329 loss: 4.67575865e-06
Iter: 330 loss: 4.66702568e-06
Iter: 331 loss: 4.6556197e-06
Iter: 332 loss: 4.65551921e-06
Iter: 333 loss: 4.64567302e-06
Iter: 334 loss: 4.64515097e-06
Iter: 335 loss: 4.63753167e-06
Iter: 336 loss: 4.62207663e-06
Iter: 337 loss: 4.67565405e-06
Iter: 338 loss: 4.61800073e-06
Iter: 339 loss: 4.60718911e-06
Iter: 340 loss: 4.60762203e-06
Iter: 341 loss: 4.59874e-06
Iter: 342 loss: 4.58133218e-06
Iter: 343 loss: 4.63061588e-06
Iter: 344 loss: 4.57595434e-06
Iter: 345 loss: 4.58784325e-06
Iter: 346 loss: 4.57234955e-06
Iter: 347 loss: 4.56798534e-06
Iter: 348 loss: 4.5595043e-06
Iter: 349 loss: 4.72701049e-06
Iter: 350 loss: 4.55930831e-06
Iter: 351 loss: 4.55165082e-06
Iter: 352 loss: 4.54216297e-06
Iter: 353 loss: 4.54126894e-06
Iter: 354 loss: 4.53301436e-06
Iter: 355 loss: 4.53285793e-06
Iter: 356 loss: 4.52489257e-06
Iter: 357 loss: 4.52604218e-06
Iter: 358 loss: 4.51872438e-06
Iter: 359 loss: 4.50928155e-06
Iter: 360 loss: 4.51493634e-06
Iter: 361 loss: 4.50325933e-06
Iter: 362 loss: 4.49121353e-06
Iter: 363 loss: 4.48914079e-06
Iter: 364 loss: 4.48066e-06
Iter: 365 loss: 4.46692775e-06
Iter: 366 loss: 4.63438209e-06
Iter: 367 loss: 4.46678177e-06
Iter: 368 loss: 4.45654405e-06
Iter: 369 loss: 4.46583454e-06
Iter: 370 loss: 4.45038586e-06
Iter: 371 loss: 4.43798535e-06
Iter: 372 loss: 4.47813454e-06
Iter: 373 loss: 4.43417139e-06
Iter: 374 loss: 4.4249623e-06
Iter: 375 loss: 4.42644068e-06
Iter: 376 loss: 4.41794e-06
Iter: 377 loss: 4.40624808e-06
Iter: 378 loss: 4.52032646e-06
Iter: 379 loss: 4.40597432e-06
Iter: 380 loss: 4.40773874e-06
Iter: 381 loss: 4.4020785e-06
Iter: 382 loss: 4.40009262e-06
Iter: 383 loss: 4.39368159e-06
Iter: 384 loss: 4.39614359e-06
Iter: 385 loss: 4.3877053e-06
Iter: 386 loss: 4.37725976e-06
Iter: 387 loss: 4.41113571e-06
Iter: 388 loss: 4.37433664e-06
Iter: 389 loss: 4.37010658e-06
Iter: 390 loss: 4.3692703e-06
Iter: 391 loss: 4.36520168e-06
Iter: 392 loss: 4.35964921e-06
Iter: 393 loss: 4.35921083e-06
Iter: 394 loss: 4.35103e-06
Iter: 395 loss: 4.35623588e-06
Iter: 396 loss: 4.34574213e-06
Iter: 397 loss: 4.335835e-06
Iter: 398 loss: 4.34656749e-06
Iter: 399 loss: 4.33049172e-06
Iter: 400 loss: 4.31834087e-06
Iter: 401 loss: 4.38495454e-06
Iter: 402 loss: 4.31649642e-06
Iter: 403 loss: 4.30774799e-06
Iter: 404 loss: 4.3500454e-06
Iter: 405 loss: 4.30630917e-06
Iter: 406 loss: 4.2986444e-06
Iter: 407 loss: 4.30156342e-06
Iter: 408 loss: 4.29303964e-06
Iter: 409 loss: 4.28336716e-06
Iter: 410 loss: 4.29814554e-06
Iter: 411 loss: 4.27896384e-06
Iter: 412 loss: 4.27364103e-06
Iter: 413 loss: 4.27310169e-06
Iter: 414 loss: 4.26744646e-06
Iter: 415 loss: 4.31158287e-06
Iter: 416 loss: 4.2669335e-06
Iter: 417 loss: 4.26514271e-06
Iter: 418 loss: 4.25918961e-06
Iter: 419 loss: 4.26346469e-06
Iter: 420 loss: 4.25417329e-06
Iter: 421 loss: 4.24390601e-06
Iter: 422 loss: 4.32831075e-06
Iter: 423 loss: 4.2430438e-06
Iter: 424 loss: 4.23802521e-06
Iter: 425 loss: 4.23799611e-06
Iter: 426 loss: 4.23355687e-06
Iter: 427 loss: 4.22738185e-06
Iter: 428 loss: 4.22708581e-06
Iter: 429 loss: 4.21840559e-06
Iter: 430 loss: 4.23116398e-06
Iter: 431 loss: 4.21409641e-06
Iter: 432 loss: 4.20629249e-06
Iter: 433 loss: 4.22733137e-06
Iter: 434 loss: 4.20379047e-06
Iter: 435 loss: 4.19487833e-06
Iter: 436 loss: 4.21538289e-06
Iter: 437 loss: 4.19121852e-06
Iter: 438 loss: 4.18349464e-06
Iter: 439 loss: 4.23015626e-06
Iter: 440 loss: 4.18250056e-06
Iter: 441 loss: 4.175914e-06
Iter: 442 loss: 4.18544687e-06
Iter: 443 loss: 4.17245201e-06
Iter: 444 loss: 4.16530384e-06
Iter: 445 loss: 4.17515275e-06
Iter: 446 loss: 4.16180319e-06
Iter: 447 loss: 4.17023875e-06
Iter: 448 loss: 4.15970089e-06
Iter: 449 loss: 4.15779e-06
Iter: 450 loss: 4.15174054e-06
Iter: 451 loss: 4.16679086e-06
Iter: 452 loss: 4.14845454e-06
Iter: 453 loss: 4.14146234e-06
Iter: 454 loss: 4.14717306e-06
Iter: 455 loss: 4.13720591e-06
Iter: 456 loss: 4.129025e-06
Iter: 457 loss: 4.19753451e-06
Iter: 458 loss: 4.12862664e-06
Iter: 459 loss: 4.12260124e-06
Iter: 460 loss: 4.18497348e-06
Iter: 461 loss: 4.12243844e-06
Iter: 462 loss: 4.11916835e-06
Iter: 463 loss: 4.1126832e-06
Iter: 464 loss: 4.23820256e-06
Iter: 465 loss: 4.11257042e-06
Iter: 466 loss: 4.10387293e-06
Iter: 467 loss: 4.12707641e-06
Iter: 468 loss: 4.10105076e-06
Iter: 469 loss: 4.09441736e-06
Iter: 470 loss: 4.13635553e-06
Iter: 471 loss: 4.09351287e-06
Iter: 472 loss: 4.08760479e-06
Iter: 473 loss: 4.09138647e-06
Iter: 474 loss: 4.08374e-06
Iter: 475 loss: 4.07684456e-06
Iter: 476 loss: 4.12598774e-06
Iter: 477 loss: 4.07630614e-06
Iter: 478 loss: 4.07122388e-06
Iter: 479 loss: 4.0747932e-06
Iter: 480 loss: 4.06809067e-06
Iter: 481 loss: 4.06368508e-06
Iter: 482 loss: 4.11321435e-06
Iter: 483 loss: 4.06350227e-06
Iter: 484 loss: 4.05900028e-06
Iter: 485 loss: 4.10538041e-06
Iter: 486 loss: 4.05895935e-06
Iter: 487 loss: 4.05737546e-06
Iter: 488 loss: 4.05264245e-06
Iter: 489 loss: 4.05867831e-06
Iter: 490 loss: 4.04903312e-06
Iter: 491 loss: 4.04190087e-06
Iter: 492 loss: 4.08027154e-06
Iter: 493 loss: 4.04084449e-06
Iter: 494 loss: 4.03770628e-06
Iter: 495 loss: 4.03749618e-06
Iter: 496 loss: 4.03403874e-06
Iter: 497 loss: 4.03078138e-06
Iter: 498 loss: 4.03016838e-06
Iter: 499 loss: 4.02556498e-06
Iter: 500 loss: 4.0306013e-06
Iter: 501 loss: 4.02314072e-06
Iter: 502 loss: 4.01688976e-06
Iter: 503 loss: 4.02277874e-06
Iter: 504 loss: 4.0132154e-06
Iter: 505 loss: 4.00693307e-06
Iter: 506 loss: 4.0371574e-06
Iter: 507 loss: 4.00584213e-06
Iter: 508 loss: 3.99990768e-06
Iter: 509 loss: 4.0181535e-06
Iter: 510 loss: 3.99844703e-06
Iter: 511 loss: 3.99347255e-06
Iter: 512 loss: 4.02132e-06
Iter: 513 loss: 3.9929987e-06
Iter: 514 loss: 3.98913835e-06
Iter: 515 loss: 3.98639804e-06
Iter: 516 loss: 3.98491738e-06
Iter: 517 loss: 3.98435259e-06
Iter: 518 loss: 3.98221891e-06
Iter: 519 loss: 3.9789079e-06
Iter: 520 loss: 3.97519943e-06
Iter: 521 loss: 3.97467556e-06
Iter: 522 loss: 3.97178519e-06
Iter: 523 loss: 3.96594442e-06
Iter: 524 loss: 4.05481114e-06
Iter: 525 loss: 3.96573387e-06
Iter: 526 loss: 3.95973348e-06
Iter: 527 loss: 3.99952569e-06
Iter: 528 loss: 3.95907136e-06
Iter: 529 loss: 3.95674715e-06
Iter: 530 loss: 3.95643383e-06
Iter: 531 loss: 3.95378629e-06
Iter: 532 loss: 3.94825611e-06
Iter: 533 loss: 4.02864907e-06
Iter: 534 loss: 3.94798417e-06
Iter: 535 loss: 3.94186e-06
Iter: 536 loss: 3.95988718e-06
Iter: 537 loss: 3.9401657e-06
Iter: 538 loss: 3.93458322e-06
Iter: 539 loss: 3.9627248e-06
Iter: 540 loss: 3.93375421e-06
Iter: 541 loss: 3.92905258e-06
Iter: 542 loss: 3.93476694e-06
Iter: 543 loss: 3.92645597e-06
Iter: 544 loss: 3.9211609e-06
Iter: 545 loss: 3.93938399e-06
Iter: 546 loss: 3.9199067e-06
Iter: 547 loss: 3.91479716e-06
Iter: 548 loss: 3.94022936e-06
Iter: 549 loss: 3.91397543e-06
Iter: 550 loss: 3.91045e-06
Iter: 551 loss: 3.91063759e-06
Iter: 552 loss: 3.90760397e-06
Iter: 553 loss: 3.90756168e-06
Iter: 554 loss: 3.90484047e-06
Iter: 555 loss: 3.90324158e-06
Iter: 556 loss: 3.89857951e-06
Iter: 557 loss: 3.91972389e-06
Iter: 558 loss: 3.89688785e-06
Iter: 559 loss: 3.89242814e-06
Iter: 560 loss: 3.88904482e-06
Iter: 561 loss: 3.8874623e-06
Iter: 562 loss: 3.88065473e-06
Iter: 563 loss: 3.91716549e-06
Iter: 564 loss: 3.87975524e-06
Iter: 565 loss: 3.87420141e-06
Iter: 566 loss: 3.88456283e-06
Iter: 567 loss: 3.87188811e-06
Iter: 568 loss: 3.86859938e-06
Iter: 569 loss: 3.86816509e-06
Iter: 570 loss: 3.86478041e-06
Iter: 571 loss: 3.86378952e-06
Iter: 572 loss: 3.86159809e-06
Iter: 573 loss: 3.85773e-06
Iter: 574 loss: 3.85334897e-06
Iter: 575 loss: 3.85274507e-06
Iter: 576 loss: 3.84742634e-06
Iter: 577 loss: 3.91295316e-06
Iter: 578 loss: 3.84748228e-06
Iter: 579 loss: 3.84346185e-06
Iter: 580 loss: 3.84737587e-06
Iter: 581 loss: 3.84130453e-06
Iter: 582 loss: 3.83699762e-06
Iter: 583 loss: 3.85595467e-06
Iter: 584 loss: 3.83617498e-06
Iter: 585 loss: 3.83252791e-06
Iter: 586 loss: 3.8497883e-06
Iter: 587 loss: 3.83166753e-06
Iter: 588 loss: 3.8295525e-06
Iter: 589 loss: 3.82927874e-06
Iter: 590 loss: 3.82810231e-06
Iter: 591 loss: 3.82482631e-06
Iter: 592 loss: 3.8502385e-06
Iter: 593 loss: 3.8242797e-06
Iter: 594 loss: 3.82036251e-06
Iter: 595 loss: 3.81603422e-06
Iter: 596 loss: 3.81547488e-06
Iter: 597 loss: 3.80953838e-06
Iter: 598 loss: 3.84566783e-06
Iter: 599 loss: 3.80874963e-06
Iter: 600 loss: 3.80382335e-06
Iter: 601 loss: 3.80860297e-06
Iter: 602 loss: 3.80092206e-06
Iter: 603 loss: 3.79832795e-06
Iter: 604 loss: 3.79765766e-06
Iter: 605 loss: 3.79445328e-06
Iter: 606 loss: 3.79267567e-06
Iter: 607 loss: 3.79123594e-06
Iter: 608 loss: 3.78683217e-06
Iter: 609 loss: 3.78294135e-06
Iter: 610 loss: 3.78182699e-06
Iter: 611 loss: 3.77660308e-06
Iter: 612 loss: 3.83289625e-06
Iter: 613 loss: 3.77654715e-06
Iter: 614 loss: 3.77282663e-06
Iter: 615 loss: 3.77247329e-06
Iter: 616 loss: 3.77002698e-06
Iter: 617 loss: 3.76535627e-06
Iter: 618 loss: 3.81084374e-06
Iter: 619 loss: 3.76508956e-06
Iter: 620 loss: 3.76176718e-06
Iter: 621 loss: 3.77021934e-06
Iter: 622 loss: 3.76058574e-06
Iter: 623 loss: 3.75812942e-06
Iter: 624 loss: 3.75782383e-06
Iter: 625 loss: 3.75662489e-06
Iter: 626 loss: 3.75353193e-06
Iter: 627 loss: 3.77372089e-06
Iter: 628 loss: 3.75284753e-06
Iter: 629 loss: 3.74886736e-06
Iter: 630 loss: 3.75973036e-06
Iter: 631 loss: 3.74759475e-06
Iter: 632 loss: 3.74480624e-06
Iter: 633 loss: 3.7467662e-06
Iter: 634 loss: 3.74306524e-06
Iter: 635 loss: 3.73862167e-06
Iter: 636 loss: 3.73749117e-06
Iter: 637 loss: 3.73468629e-06
Iter: 638 loss: 3.73027115e-06
Iter: 639 loss: 3.73025659e-06
Iter: 640 loss: 3.72700879e-06
Iter: 641 loss: 3.75916397e-06
Iter: 642 loss: 3.72691125e-06
Iter: 643 loss: 3.72437285e-06
Iter: 644 loss: 3.7202883e-06
Iter: 645 loss: 3.72026739e-06
Iter: 646 loss: 3.71625288e-06
Iter: 647 loss: 3.72302407e-06
Iter: 648 loss: 3.7146815e-06
Iter: 649 loss: 3.70942871e-06
Iter: 650 loss: 3.71588499e-06
Iter: 651 loss: 3.70689895e-06
Iter: 652 loss: 3.70222597e-06
Iter: 653 loss: 3.7341083e-06
Iter: 654 loss: 3.70184216e-06
Iter: 655 loss: 3.70107682e-06
Iter: 656 loss: 3.70035445e-06
Iter: 657 loss: 3.69817576e-06
Iter: 658 loss: 3.69448117e-06
Iter: 659 loss: 3.69453437e-06
Iter: 660 loss: 3.69217514e-06
Iter: 661 loss: 3.68929e-06
Iter: 662 loss: 3.6889785e-06
Iter: 663 loss: 3.68465953e-06
Iter: 664 loss: 3.70399084e-06
Iter: 665 loss: 3.68385486e-06
Iter: 666 loss: 3.68020551e-06
Iter: 667 loss: 3.69414374e-06
Iter: 668 loss: 3.67922212e-06
Iter: 669 loss: 3.67608982e-06
Iter: 670 loss: 3.68138194e-06
Iter: 671 loss: 3.67454095e-06
Iter: 672 loss: 3.67131588e-06
Iter: 673 loss: 3.67490884e-06
Iter: 674 loss: 3.66935819e-06
Iter: 675 loss: 3.66558083e-06
Iter: 676 loss: 3.66565655e-06
Iter: 677 loss: 3.66258587e-06
Iter: 678 loss: 3.66430186e-06
Iter: 679 loss: 3.66070958e-06
Iter: 680 loss: 3.65808728e-06
Iter: 681 loss: 3.65913138e-06
Iter: 682 loss: 3.65632081e-06
Iter: 683 loss: 3.65268534e-06
Iter: 684 loss: 3.65747428e-06
Iter: 685 loss: 3.65080859e-06
Iter: 686 loss: 3.64706489e-06
Iter: 687 loss: 3.65999244e-06
Iter: 688 loss: 3.64611515e-06
Iter: 689 loss: 3.64227481e-06
Iter: 690 loss: 3.64868674e-06
Iter: 691 loss: 3.6405886e-06
Iter: 692 loss: 3.64054358e-06
Iter: 693 loss: 3.63834442e-06
Iter: 694 loss: 3.63744493e-06
Iter: 695 loss: 3.63463505e-06
Iter: 696 loss: 3.63791378e-06
Iter: 697 loss: 3.63242e-06
Iter: 698 loss: 3.62861283e-06
Iter: 699 loss: 3.63513391e-06
Iter: 700 loss: 3.62697187e-06
Iter: 701 loss: 3.623049e-06
Iter: 702 loss: 3.64784296e-06
Iter: 703 loss: 3.62263063e-06
Iter: 704 loss: 3.61933462e-06
Iter: 705 loss: 3.63376148e-06
Iter: 706 loss: 3.61848743e-06
Iter: 707 loss: 3.61576167e-06
Iter: 708 loss: 3.62018045e-06
Iter: 709 loss: 3.61445086e-06
Iter: 710 loss: 3.61190018e-06
Iter: 711 loss: 3.64951029e-06
Iter: 712 loss: 3.61193e-06
Iter: 713 loss: 3.60977583e-06
Iter: 714 loss: 3.60782587e-06
Iter: 715 loss: 3.60718923e-06
Iter: 716 loss: 3.60476452e-06
Iter: 717 loss: 3.60596232e-06
Iter: 718 loss: 3.60295144e-06
Iter: 719 loss: 3.59927867e-06
Iter: 720 loss: 3.60706258e-06
Iter: 721 loss: 3.59783394e-06
Iter: 722 loss: 3.59486535e-06
Iter: 723 loss: 3.61462162e-06
Iter: 724 loss: 3.59442629e-06
Iter: 725 loss: 3.59305523e-06
Iter: 726 loss: 3.59291585e-06
Iter: 727 loss: 3.59102091e-06
Iter: 728 loss: 3.5880239e-06
Iter: 729 loss: 3.58790885e-06
Iter: 730 loss: 3.58597799e-06
Iter: 731 loss: 3.5842354e-06
Iter: 732 loss: 3.58375178e-06
Iter: 733 loss: 3.58060879e-06
Iter: 734 loss: 3.58263969e-06
Iter: 735 loss: 3.57868635e-06
Iter: 736 loss: 3.5752023e-06
Iter: 737 loss: 3.59732758e-06
Iter: 738 loss: 3.5748767e-06
Iter: 739 loss: 3.5723358e-06
Iter: 740 loss: 3.58679335e-06
Iter: 741 loss: 3.57191311e-06
Iter: 742 loss: 3.5694186e-06
Iter: 743 loss: 3.57464501e-06
Iter: 744 loss: 3.56841701e-06
Iter: 745 loss: 3.56608894e-06
Iter: 746 loss: 3.59108503e-06
Iter: 747 loss: 3.56596729e-06
Iter: 748 loss: 3.56431019e-06
Iter: 749 loss: 3.56199189e-06
Iter: 750 loss: 3.56197506e-06
Iter: 751 loss: 3.55920133e-06
Iter: 752 loss: 3.56406281e-06
Iter: 753 loss: 3.5579958e-06
Iter: 754 loss: 3.55493671e-06
Iter: 755 loss: 3.56051919e-06
Iter: 756 loss: 3.55342058e-06
Iter: 757 loss: 3.55249085e-06
Iter: 758 loss: 3.55183397e-06
Iter: 759 loss: 3.55037241e-06
Iter: 760 loss: 3.55832708e-06
Iter: 761 loss: 3.55011161e-06
Iter: 762 loss: 3.54935764e-06
Iter: 763 loss: 3.54716121e-06
Iter: 764 loss: 3.55782572e-06
Iter: 765 loss: 3.54636131e-06
Iter: 766 loss: 3.54349845e-06
Iter: 767 loss: 3.5540811e-06
Iter: 768 loss: 3.54282497e-06
Iter: 769 loss: 3.54045483e-06
Iter: 770 loss: 3.54327358e-06
Iter: 771 loss: 3.53927589e-06
Iter: 772 loss: 3.53662244e-06
Iter: 773 loss: 3.55145085e-06
Iter: 774 loss: 3.53624978e-06
Iter: 775 loss: 3.53421865e-06
Iter: 776 loss: 3.55340444e-06
Iter: 777 loss: 3.53418795e-06
Iter: 778 loss: 3.53280166e-06
Iter: 779 loss: 3.53857263e-06
Iter: 780 loss: 3.53254882e-06
Iter: 781 loss: 3.53082487e-06
Iter: 782 loss: 3.52925917e-06
Iter: 783 loss: 3.52874099e-06
Iter: 784 loss: 3.52641655e-06
Iter: 785 loss: 3.52909046e-06
Iter: 786 loss: 3.52511529e-06
Iter: 787 loss: 3.52277243e-06
Iter: 788 loss: 3.53026076e-06
Iter: 789 loss: 3.52217035e-06
Iter: 790 loss: 3.52066218e-06
Iter: 791 loss: 3.52072e-06
Iter: 792 loss: 3.51948256e-06
Iter: 793 loss: 3.53443534e-06
Iter: 794 loss: 3.51945528e-06
Iter: 795 loss: 3.51881386e-06
Iter: 796 loss: 3.51715107e-06
Iter: 797 loss: 3.53250744e-06
Iter: 798 loss: 3.51685071e-06
Iter: 799 loss: 3.51536073e-06
Iter: 800 loss: 3.5166529e-06
Iter: 801 loss: 3.5144044e-06
Iter: 802 loss: 3.51235371e-06
Iter: 803 loss: 3.51265044e-06
Iter: 804 loss: 3.51071026e-06
Iter: 805 loss: 3.50852565e-06
Iter: 806 loss: 3.53182668e-06
Iter: 807 loss: 3.50837877e-06
Iter: 808 loss: 3.50683467e-06
Iter: 809 loss: 3.51307426e-06
Iter: 810 loss: 3.50638629e-06
Iter: 811 loss: 3.50463597e-06
Iter: 812 loss: 3.51221115e-06
Iter: 813 loss: 3.50435084e-06
Iter: 814 loss: 3.50255368e-06
Iter: 815 loss: 3.50855089e-06
Iter: 816 loss: 3.50223559e-06
Iter: 817 loss: 3.50097184e-06
Iter: 818 loss: 3.49871925e-06
Iter: 819 loss: 3.49871084e-06
Iter: 820 loss: 3.49661241e-06
Iter: 821 loss: 3.50668961e-06
Iter: 822 loss: 3.49608558e-06
Iter: 823 loss: 3.49438278e-06
Iter: 824 loss: 3.50158552e-06
Iter: 825 loss: 3.49410789e-06
Iter: 826 loss: 3.49340303e-06
Iter: 827 loss: 3.49318498e-06
Iter: 828 loss: 3.49263064e-06
Iter: 829 loss: 3.49104766e-06
Iter: 830 loss: 3.5066837e-06
Iter: 831 loss: 3.49079073e-06
Iter: 832 loss: 3.48947242e-06
Iter: 833 loss: 3.48938192e-06
Iter: 834 loss: 3.48828917e-06
Iter: 835 loss: 3.48629692e-06
Iter: 836 loss: 3.4914865e-06
Iter: 837 loss: 3.48563981e-06
Iter: 838 loss: 3.48355525e-06
Iter: 839 loss: 3.48531785e-06
Iter: 840 loss: 3.48229355e-06
Iter: 841 loss: 3.48017375e-06
Iter: 842 loss: 3.50669097e-06
Iter: 843 loss: 3.4801385e-06
Iter: 844 loss: 3.47857736e-06
Iter: 845 loss: 3.48973026e-06
Iter: 846 loss: 3.47843866e-06
Iter: 847 loss: 3.47721812e-06
Iter: 848 loss: 3.47863352e-06
Iter: 849 loss: 3.47654759e-06
Iter: 850 loss: 3.47481955e-06
Iter: 851 loss: 3.47462628e-06
Iter: 852 loss: 3.47328432e-06
Iter: 853 loss: 3.47158266e-06
Iter: 854 loss: 3.47480409e-06
Iter: 855 loss: 3.47078e-06
Iter: 856 loss: 3.4687996e-06
Iter: 857 loss: 3.47241348e-06
Iter: 858 loss: 3.46788715e-06
Iter: 859 loss: 3.47072751e-06
Iter: 860 loss: 3.46736647e-06
Iter: 861 loss: 3.46694196e-06
Iter: 862 loss: 3.4656764e-06
Iter: 863 loss: 3.47160858e-06
Iter: 864 loss: 3.46528282e-06
Iter: 865 loss: 3.4632917e-06
Iter: 866 loss: 3.46270031e-06
Iter: 867 loss: 3.46147363e-06
Iter: 868 loss: 3.45925719e-06
Iter: 869 loss: 3.46876868e-06
Iter: 870 loss: 3.4588511e-06
Iter: 871 loss: 3.45663079e-06
Iter: 872 loss: 3.46071647e-06
Iter: 873 loss: 3.45570606e-06
Iter: 874 loss: 3.45377202e-06
Iter: 875 loss: 3.45968829e-06
Iter: 876 loss: 3.45298486e-06
Iter: 877 loss: 3.45105968e-06
Iter: 878 loss: 3.47648574e-06
Iter: 879 loss: 3.45110379e-06
Iter: 880 loss: 3.44965906e-06
Iter: 881 loss: 3.45498347e-06
Iter: 882 loss: 3.44933733e-06
Iter: 883 loss: 3.44807063e-06
Iter: 884 loss: 3.44778437e-06
Iter: 885 loss: 3.44696446e-06
Iter: 886 loss: 3.4449522e-06
Iter: 887 loss: 3.44459363e-06
Iter: 888 loss: 3.4432519e-06
Iter: 889 loss: 3.44086e-06
Iter: 890 loss: 3.45027684e-06
Iter: 891 loss: 3.44029036e-06
Iter: 892 loss: 3.4387931e-06
Iter: 893 loss: 3.43879174e-06
Iter: 894 loss: 3.43665965e-06
Iter: 895 loss: 3.43767579e-06
Iter: 896 loss: 3.43522197e-06
Iter: 897 loss: 3.4341565e-06
Iter: 898 loss: 3.43282909e-06
Iter: 899 loss: 3.43269085e-06
Iter: 900 loss: 3.4307775e-06
Iter: 901 loss: 3.43088504e-06
Iter: 902 loss: 3.42924113e-06
Iter: 903 loss: 3.42659177e-06
Iter: 904 loss: 3.43792362e-06
Iter: 905 loss: 3.42599833e-06
Iter: 906 loss: 3.42329554e-06
Iter: 907 loss: 3.42533622e-06
Iter: 908 loss: 3.42188878e-06
Iter: 909 loss: 3.41900841e-06
Iter: 910 loss: 3.44524597e-06
Iter: 911 loss: 3.41899909e-06
Iter: 912 loss: 3.41688724e-06
Iter: 913 loss: 3.43557167e-06
Iter: 914 loss: 3.41674604e-06
Iter: 915 loss: 3.4151e-06
Iter: 916 loss: 3.41480882e-06
Iter: 917 loss: 3.41357509e-06
Iter: 918 loss: 3.41148e-06
Iter: 919 loss: 3.41641498e-06
Iter: 920 loss: 3.41068585e-06
Iter: 921 loss: 3.40853626e-06
Iter: 922 loss: 3.40840552e-06
Iter: 923 loss: 3.40686779e-06
Iter: 924 loss: 3.40446081e-06
Iter: 925 loss: 3.42228418e-06
Iter: 926 loss: 3.40425277e-06
Iter: 927 loss: 3.40323436e-06
Iter: 928 loss: 3.40274642e-06
Iter: 929 loss: 3.4021507e-06
Iter: 930 loss: 3.40026759e-06
Iter: 931 loss: 3.40296424e-06
Iter: 932 loss: 3.39892767e-06
Iter: 933 loss: 3.3960589e-06
Iter: 934 loss: 3.40977203e-06
Iter: 935 loss: 3.39564576e-06
Iter: 936 loss: 3.39341454e-06
Iter: 937 loss: 3.39486041e-06
Iter: 938 loss: 3.39191956e-06
Iter: 939 loss: 3.38926975e-06
Iter: 940 loss: 3.40318047e-06
Iter: 941 loss: 3.38866562e-06
Iter: 942 loss: 3.38646441e-06
Iter: 943 loss: 3.39016651e-06
Iter: 944 loss: 3.38571635e-06
Iter: 945 loss: 3.38332643e-06
Iter: 946 loss: 3.41394502e-06
Iter: 947 loss: 3.38341397e-06
Iter: 948 loss: 3.38149721e-06
Iter: 949 loss: 3.38587597e-06
Iter: 950 loss: 3.38078189e-06
Iter: 951 loss: 3.37934e-06
Iter: 952 loss: 3.38012478e-06
Iter: 953 loss: 3.37837059e-06
Iter: 954 loss: 3.37627398e-06
Iter: 955 loss: 3.37493702e-06
Iter: 956 loss: 3.37414031e-06
Iter: 957 loss: 3.37091205e-06
Iter: 958 loss: 3.37919573e-06
Iter: 959 loss: 3.36995e-06
Iter: 960 loss: 3.37154893e-06
Iter: 961 loss: 3.36911739e-06
Iter: 962 loss: 3.36803646e-06
Iter: 963 loss: 3.36549465e-06
Iter: 964 loss: 3.39488861e-06
Iter: 965 loss: 3.36532617e-06
Iter: 966 loss: 3.36327e-06
Iter: 967 loss: 3.35984032e-06
Iter: 968 loss: 3.35965592e-06
Iter: 969 loss: 3.35697359e-06
Iter: 970 loss: 3.39217331e-06
Iter: 971 loss: 3.3569961e-06
Iter: 972 loss: 3.35466348e-06
Iter: 973 loss: 3.3559877e-06
Iter: 974 loss: 3.35320419e-06
Iter: 975 loss: 3.35004688e-06
Iter: 976 loss: 3.35700338e-06
Iter: 977 loss: 3.34883407e-06
Iter: 978 loss: 3.34639299e-06
Iter: 979 loss: 3.36189623e-06
Iter: 980 loss: 3.34607307e-06
Iter: 981 loss: 3.34427909e-06
Iter: 982 loss: 3.3669719e-06
Iter: 983 loss: 3.34428364e-06
Iter: 984 loss: 3.34255719e-06
Iter: 985 loss: 3.3411909e-06
Iter: 986 loss: 3.34078959e-06
Iter: 987 loss: 3.33891239e-06
Iter: 988 loss: 3.34986544e-06
Iter: 989 loss: 3.33856565e-06
Iter: 990 loss: 3.33694061e-06
Iter: 991 loss: 3.33549451e-06
Iter: 992 loss: 3.33494017e-06
Iter: 993 loss: 3.33371668e-06
Iter: 994 loss: 3.33358184e-06
Iter: 995 loss: 3.3319825e-06
Iter: 996 loss: 3.3374622e-06
Iter: 997 loss: 3.3315489e-06
Iter: 998 loss: 3.3307083e-06
Iter: 999 loss: 3.32837067e-06
Iter: 1000 loss: 3.34331935e-06
Iter: 1001 loss: 3.32773334e-06
Iter: 1002 loss: 3.32502577e-06
Iter: 1003 loss: 3.33154503e-06
Iter: 1004 loss: 3.32401578e-06
Iter: 1005 loss: 3.3212059e-06
Iter: 1006 loss: 3.33120329e-06
Iter: 1007 loss: 3.32057039e-06
Iter: 1008 loss: 3.31800402e-06
Iter: 1009 loss: 3.32730383e-06
Iter: 1010 loss: 3.31741558e-06
Iter: 1011 loss: 3.31503543e-06
Iter: 1012 loss: 3.32117725e-06
Iter: 1013 loss: 3.3142876e-06
Iter: 1014 loss: 3.31268507e-06
Iter: 1015 loss: 3.31267552e-06
Iter: 1016 loss: 3.31111551e-06
Iter: 1017 loss: 3.31087381e-06
Iter: 1018 loss: 3.30988064e-06
Iter: 1019 loss: 3.30787771e-06
Iter: 1020 loss: 3.30829926e-06
Iter: 1021 loss: 3.30631565e-06
Iter: 1022 loss: 3.3039646e-06
Iter: 1023 loss: 3.32362265e-06
Iter: 1024 loss: 3.30383091e-06
Iter: 1025 loss: 3.30239823e-06
Iter: 1026 loss: 3.30133412e-06
Iter: 1027 loss: 3.30086459e-06
Iter: 1028 loss: 3.30089915e-06
Iter: 1029 loss: 3.29958425e-06
Iter: 1030 loss: 3.29898421e-06
Iter: 1031 loss: 3.2974408e-06
Iter: 1032 loss: 3.30334706e-06
Iter: 1033 loss: 3.29675186e-06
Iter: 1034 loss: 3.29470549e-06
Iter: 1035 loss: 3.29500926e-06
Iter: 1036 loss: 3.29331351e-06
Iter: 1037 loss: 3.29066e-06
Iter: 1038 loss: 3.29999693e-06
Iter: 1039 loss: 3.28993565e-06
Iter: 1040 loss: 3.28765054e-06
Iter: 1041 loss: 3.29548243e-06
Iter: 1042 loss: 3.2868777e-06
Iter: 1043 loss: 3.28447959e-06
Iter: 1044 loss: 3.28862779e-06
Iter: 1045 loss: 3.28345664e-06
Iter: 1046 loss: 3.28210967e-06
Iter: 1047 loss: 3.28199121e-06
Iter: 1048 loss: 3.28072338e-06
Iter: 1049 loss: 3.28071815e-06
Iter: 1050 loss: 3.27985617e-06
Iter: 1051 loss: 3.27816588e-06
Iter: 1052 loss: 3.27920861e-06
Iter: 1053 loss: 3.27714906e-06
Iter: 1054 loss: 3.27528073e-06
Iter: 1055 loss: 3.2838102e-06
Iter: 1056 loss: 3.27486146e-06
Iter: 1057 loss: 3.27325779e-06
Iter: 1058 loss: 3.27203384e-06
Iter: 1059 loss: 3.27133421e-06
Iter: 1060 loss: 3.27001771e-06
Iter: 1061 loss: 3.26984855e-06
Iter: 1062 loss: 3.26777399e-06
Iter: 1063 loss: 3.26929739e-06
Iter: 1064 loss: 3.2664675e-06
Iter: 1065 loss: 3.26544773e-06
Iter: 1066 loss: 3.26311874e-06
Iter: 1067 loss: 3.30141711e-06
Iter: 1068 loss: 3.26304371e-06
Iter: 1069 loss: 3.2606913e-06
Iter: 1070 loss: 3.26011832e-06
Iter: 1071 loss: 3.25864448e-06
Iter: 1072 loss: 3.25628207e-06
Iter: 1073 loss: 3.29145428e-06
Iter: 1074 loss: 3.25625524e-06
Iter: 1075 loss: 3.25409883e-06
Iter: 1076 loss: 3.25501378e-06
Iter: 1077 loss: 3.25270776e-06
Iter: 1078 loss: 3.25029532e-06
Iter: 1079 loss: 3.2730411e-06
Iter: 1080 loss: 3.25022643e-06
Iter: 1081 loss: 3.24903931e-06
Iter: 1082 loss: 3.26908685e-06
Iter: 1083 loss: 3.24902453e-06
Iter: 1084 loss: 3.24781013e-06
Iter: 1085 loss: 3.24804705e-06
Iter: 1086 loss: 3.24699931e-06
Iter: 1087 loss: 3.24561825e-06
Iter: 1088 loss: 3.24650182e-06
Iter: 1089 loss: 3.24477583e-06
Iter: 1090 loss: 3.24301186e-06
Iter: 1091 loss: 3.24432403e-06
Iter: 1092 loss: 3.24199505e-06
Iter: 1093 loss: 3.23997028e-06
Iter: 1094 loss: 3.25145925e-06
Iter: 1095 loss: 3.23958557e-06
Iter: 1096 loss: 3.23837753e-06
Iter: 1097 loss: 3.23834229e-06
Iter: 1098 loss: 3.23694803e-06
Iter: 1099 loss: 3.23696759e-06
Iter: 1100 loss: 3.23583413e-06
Iter: 1101 loss: 3.23513973e-06
Iter: 1102 loss: 3.23358086e-06
Iter: 1103 loss: 3.26045893e-06
Iter: 1104 loss: 3.23353402e-06
Iter: 1105 loss: 3.23135828e-06
Iter: 1106 loss: 3.23580412e-06
Iter: 1107 loss: 3.23046652e-06
Iter: 1108 loss: 3.22843812e-06
Iter: 1109 loss: 3.23190852e-06
Iter: 1110 loss: 3.22746e-06
Iter: 1111 loss: 3.22500682e-06
Iter: 1112 loss: 3.23395966e-06
Iter: 1113 loss: 3.22433061e-06
Iter: 1114 loss: 3.22223582e-06
Iter: 1115 loss: 3.22660321e-06
Iter: 1116 loss: 3.22143796e-06
Iter: 1117 loss: 3.21921448e-06
Iter: 1118 loss: 3.25057181e-06
Iter: 1119 loss: 3.21923062e-06
Iter: 1120 loss: 3.21750667e-06
Iter: 1121 loss: 3.21792231e-06
Iter: 1122 loss: 3.21630705e-06
Iter: 1123 loss: 3.21473794e-06
Iter: 1124 loss: 3.21867333e-06
Iter: 1125 loss: 3.21426933e-06
Iter: 1126 loss: 3.21275866e-06
Iter: 1127 loss: 3.21222547e-06
Iter: 1128 loss: 3.21124253e-06
Iter: 1129 loss: 3.20956906e-06
Iter: 1130 loss: 3.23386621e-06
Iter: 1131 loss: 3.20960976e-06
Iter: 1132 loss: 3.20851541e-06
Iter: 1133 loss: 3.20847403e-06
Iter: 1134 loss: 3.207688e-06
Iter: 1135 loss: 3.20549952e-06
Iter: 1136 loss: 3.21999187e-06
Iter: 1137 loss: 3.20491745e-06
Iter: 1138 loss: 3.20327763e-06
Iter: 1139 loss: 3.20513573e-06
Iter: 1140 loss: 3.20228037e-06
Iter: 1141 loss: 3.20000026e-06
Iter: 1142 loss: 3.20343361e-06
Iter: 1143 loss: 3.19903575e-06
Iter: 1144 loss: 3.19648689e-06
Iter: 1145 loss: 3.20032359e-06
Iter: 1146 loss: 3.1955e-06
Iter: 1147 loss: 3.19257128e-06
Iter: 1148 loss: 3.20190384e-06
Iter: 1149 loss: 3.19166111e-06
Iter: 1150 loss: 3.18917682e-06
Iter: 1151 loss: 3.19498167e-06
Iter: 1152 loss: 3.18831167e-06
Iter: 1153 loss: 3.18671482e-06
Iter: 1154 loss: 3.18653906e-06
Iter: 1155 loss: 3.18532352e-06
Iter: 1156 loss: 3.18412685e-06
Iter: 1157 loss: 3.18395291e-06
Iter: 1158 loss: 3.18202706e-06
Iter: 1159 loss: 3.18398315e-06
Iter: 1160 loss: 3.18110801e-06
Iter: 1161 loss: 3.17878084e-06
Iter: 1162 loss: 3.18624689e-06
Iter: 1163 loss: 3.17822719e-06
Iter: 1164 loss: 3.17644162e-06
Iter: 1165 loss: 3.18227922e-06
Iter: 1166 loss: 3.1760826e-06
Iter: 1167 loss: 3.17475269e-06
Iter: 1168 loss: 3.1747245e-06
Iter: 1169 loss: 3.17398826e-06
Iter: 1170 loss: 3.17192735e-06
Iter: 1171 loss: 3.18909019e-06
Iter: 1172 loss: 3.1716686e-06
Iter: 1173 loss: 3.16976411e-06
Iter: 1174 loss: 3.17246418e-06
Iter: 1175 loss: 3.16891987e-06
Iter: 1176 loss: 3.16657292e-06
Iter: 1177 loss: 3.16625301e-06
Iter: 1178 loss: 3.16451701e-06
Iter: 1179 loss: 3.16187925e-06
Iter: 1180 loss: 3.17267791e-06
Iter: 1181 loss: 3.16128308e-06
Iter: 1182 loss: 3.15879265e-06
Iter: 1183 loss: 3.16872229e-06
Iter: 1184 loss: 3.15825037e-06
Iter: 1185 loss: 3.15615716e-06
Iter: 1186 loss: 3.15951047e-06
Iter: 1187 loss: 3.1550162e-06
Iter: 1188 loss: 3.15412444e-06
Iter: 1189 loss: 3.15373245e-06
Iter: 1190 loss: 3.15281159e-06
Iter: 1191 loss: 3.151074e-06
Iter: 1192 loss: 3.19151377e-06
Iter: 1193 loss: 3.15107764e-06
Iter: 1194 loss: 3.14908584e-06
Iter: 1195 loss: 3.14834574e-06
Iter: 1196 loss: 3.14718454e-06
Iter: 1197 loss: 3.14473164e-06
Iter: 1198 loss: 3.15863144e-06
Iter: 1199 loss: 3.14434033e-06
Iter: 1200 loss: 3.14471981e-06
Iter: 1201 loss: 3.14358022e-06
Iter: 1202 loss: 3.14260114e-06
Iter: 1203 loss: 3.14076465e-06
Iter: 1204 loss: 3.17352919e-06
Iter: 1205 loss: 3.14076146e-06
Iter: 1206 loss: 3.13928217e-06
Iter: 1207 loss: 3.14118097e-06
Iter: 1208 loss: 3.13848e-06
Iter: 1209 loss: 3.13688702e-06
Iter: 1210 loss: 3.13450164e-06
Iter: 1211 loss: 3.13437022e-06
Iter: 1212 loss: 3.1326008e-06
Iter: 1213 loss: 3.13256123e-06
Iter: 1214 loss: 3.13114288e-06
Iter: 1215 loss: 3.12916336e-06
Iter: 1216 loss: 3.12912562e-06
Iter: 1217 loss: 3.1269642e-06
Iter: 1218 loss: 3.15451052e-06
Iter: 1219 loss: 3.12696943e-06
Iter: 1220 loss: 3.12583734e-06
Iter: 1221 loss: 3.13194187e-06
Iter: 1222 loss: 3.1255006e-06
Iter: 1223 loss: 3.12418706e-06
Iter: 1224 loss: 3.12957854e-06
Iter: 1225 loss: 3.12388374e-06
Iter: 1226 loss: 3.12296743e-06
Iter: 1227 loss: 3.12192196e-06
Iter: 1228 loss: 3.12175143e-06
Iter: 1229 loss: 3.12013572e-06
Iter: 1230 loss: 3.11997837e-06
Iter: 1231 loss: 3.11872e-06
Iter: 1232 loss: 3.11749773e-06
Iter: 1233 loss: 3.11749591e-06
Iter: 1234 loss: 3.11612712e-06
Iter: 1235 loss: 3.12052794e-06
Iter: 1236 loss: 3.11566896e-06
Iter: 1237 loss: 3.11475333e-06
Iter: 1238 loss: 3.11361327e-06
Iter: 1239 loss: 3.11358417e-06
Iter: 1240 loss: 3.11243866e-06
Iter: 1241 loss: 3.11440135e-06
Iter: 1242 loss: 3.11179679e-06
Iter: 1243 loss: 3.11032932e-06
Iter: 1244 loss: 3.11153644e-06
Iter: 1245 loss: 3.10942028e-06
Iter: 1246 loss: 3.10796167e-06
Iter: 1247 loss: 3.11469512e-06
Iter: 1248 loss: 3.10771816e-06
Iter: 1249 loss: 3.10627e-06
Iter: 1250 loss: 3.10785163e-06
Iter: 1251 loss: 3.10545215e-06
Iter: 1252 loss: 3.10392443e-06
Iter: 1253 loss: 3.11397548e-06
Iter: 1254 loss: 3.10370751e-06
Iter: 1255 loss: 3.10233327e-06
Iter: 1256 loss: 3.10427322e-06
Iter: 1257 loss: 3.10184782e-06
Iter: 1258 loss: 3.0997287e-06
Iter: 1259 loss: 3.11220856e-06
Iter: 1260 loss: 3.09947382e-06
Iter: 1261 loss: 3.09868255e-06
Iter: 1262 loss: 3.09838742e-06
Iter: 1263 loss: 3.09794723e-06
Iter: 1264 loss: 3.09658094e-06
Iter: 1265 loss: 3.09520101e-06
Iter: 1266 loss: 3.0950041e-06
Iter: 1267 loss: 3.09392317e-06
Iter: 1268 loss: 3.09385314e-06
Iter: 1269 loss: 3.0928552e-06
Iter: 1270 loss: 3.10475662e-06
Iter: 1271 loss: 3.09279267e-06
Iter: 1272 loss: 3.09223697e-06
Iter: 1273 loss: 3.0906815e-06
Iter: 1274 loss: 3.09568532e-06
Iter: 1275 loss: 3.08988933e-06
Iter: 1276 loss: 3.08806284e-06
Iter: 1277 loss: 3.08878953e-06
Iter: 1278 loss: 3.0868739e-06
Iter: 1279 loss: 3.08493895e-06
Iter: 1280 loss: 3.11190752e-06
Iter: 1281 loss: 3.0849194e-06
Iter: 1282 loss: 3.08328413e-06
Iter: 1283 loss: 3.08556287e-06
Iter: 1284 loss: 3.08254857e-06
Iter: 1285 loss: 3.08071412e-06
Iter: 1286 loss: 3.08530684e-06
Iter: 1287 loss: 3.08010067e-06
Iter: 1288 loss: 3.07854043e-06
Iter: 1289 loss: 3.07799201e-06
Iter: 1290 loss: 3.07709297e-06
Iter: 1291 loss: 3.07672326e-06
Iter: 1292 loss: 3.07591017e-06
Iter: 1293 loss: 3.0750889e-06
Iter: 1294 loss: 3.07418486e-06
Iter: 1295 loss: 3.07418713e-06
Iter: 1296 loss: 3.07253458e-06
Iter: 1297 loss: 3.07110145e-06
Iter: 1298 loss: 3.07073174e-06
Iter: 1299 loss: 3.06882339e-06
Iter: 1300 loss: 3.09920051e-06
Iter: 1301 loss: 3.06883067e-06
Iter: 1302 loss: 3.06784e-06
Iter: 1303 loss: 3.0792603e-06
Iter: 1304 loss: 3.06778907e-06
Iter: 1305 loss: 3.06641982e-06
Iter: 1306 loss: 3.06578568e-06
Iter: 1307 loss: 3.06498282e-06
Iter: 1308 loss: 3.06408538e-06
Iter: 1309 loss: 3.06327888e-06
Iter: 1310 loss: 3.06292304e-06
Iter: 1311 loss: 3.06143102e-06
Iter: 1312 loss: 3.05903882e-06
Iter: 1313 loss: 3.05900608e-06
Iter: 1314 loss: 3.05733306e-06
Iter: 1315 loss: 3.05730941e-06
Iter: 1316 loss: 3.05576259e-06
Iter: 1317 loss: 3.05394201e-06
Iter: 1318 loss: 3.05370031e-06
Iter: 1319 loss: 3.05274807e-06
Iter: 1320 loss: 3.05238405e-06
Iter: 1321 loss: 3.05140065e-06
Iter: 1322 loss: 3.04945888e-06
Iter: 1323 loss: 3.08528979e-06
Iter: 1324 loss: 3.0494225e-06
Iter: 1325 loss: 3.04756441e-06
Iter: 1326 loss: 3.04753848e-06
Iter: 1327 loss: 3.04650848e-06
Iter: 1328 loss: 3.06217817e-06
Iter: 1329 loss: 3.04648938e-06
Iter: 1330 loss: 3.04583295e-06
Iter: 1331 loss: 3.04372816e-06
Iter: 1332 loss: 3.04766877e-06
Iter: 1333 loss: 3.04233708e-06
Iter: 1334 loss: 3.04115156e-06
Iter: 1335 loss: 3.04078662e-06
Iter: 1336 loss: 3.04028072e-06
Iter: 1337 loss: 3.0401618e-06
Iter: 1338 loss: 3.03960519e-06
Iter: 1339 loss: 3.03815887e-06
Iter: 1340 loss: 3.04186779e-06
Iter: 1341 loss: 3.03736715e-06
Iter: 1342 loss: 3.03552338e-06
Iter: 1343 loss: 3.04470495e-06
Iter: 1344 loss: 3.03528e-06
Iter: 1345 loss: 3.03364459e-06
Iter: 1346 loss: 3.03239813e-06
Iter: 1347 loss: 3.03188153e-06
Iter: 1348 loss: 3.02929629e-06
Iter: 1349 loss: 3.04318701e-06
Iter: 1350 loss: 3.02910576e-06
Iter: 1351 loss: 3.02717103e-06
Iter: 1352 loss: 3.02737089e-06
Iter: 1353 loss: 3.02570038e-06
Iter: 1354 loss: 3.02370177e-06
Iter: 1355 loss: 3.05467802e-06
Iter: 1356 loss: 3.02370677e-06
Iter: 1357 loss: 3.02215585e-06
Iter: 1358 loss: 3.02206718e-06
Iter: 1359 loss: 3.02102148e-06
Iter: 1360 loss: 3.01876344e-06
Iter: 1361 loss: 3.02466924e-06
Iter: 1362 loss: 3.01792943e-06
Iter: 1363 loss: 3.01677937e-06
Iter: 1364 loss: 3.01673208e-06
Iter: 1365 loss: 3.01532236e-06
Iter: 1366 loss: 3.01633668e-06
Iter: 1367 loss: 3.01450609e-06
Iter: 1368 loss: 3.01342538e-06
Iter: 1369 loss: 3.01495106e-06
Iter: 1370 loss: 3.01296495e-06
Iter: 1371 loss: 3.01288355e-06
Iter: 1372 loss: 3.01232876e-06
Iter: 1373 loss: 3.01194268e-06
Iter: 1374 loss: 3.01062e-06
Iter: 1375 loss: 3.00934016e-06
Iter: 1376 loss: 3.00883585e-06
Iter: 1377 loss: 3.00658303e-06
Iter: 1378 loss: 3.01653517e-06
Iter: 1379 loss: 3.00629472e-06
Iter: 1380 loss: 3.0038027e-06
Iter: 1381 loss: 3.00673537e-06
Iter: 1382 loss: 3.00259057e-06
Iter: 1383 loss: 3.00063903e-06
Iter: 1384 loss: 3.01012687e-06
Iter: 1385 loss: 3.00026977e-06
Iter: 1386 loss: 2.99846806e-06
Iter: 1387 loss: 3.00214151e-06
Iter: 1388 loss: 2.99761e-06
Iter: 1389 loss: 2.99594194e-06
Iter: 1390 loss: 3.00108013e-06
Iter: 1391 loss: 2.99544081e-06
Iter: 1392 loss: 2.993419e-06
Iter: 1393 loss: 2.99523845e-06
Iter: 1394 loss: 2.9922071e-06
Iter: 1395 loss: 2.99078192e-06
Iter: 1396 loss: 2.99084786e-06
Iter: 1397 loss: 2.98989903e-06
Iter: 1398 loss: 2.99383851e-06
Iter: 1399 loss: 2.98966438e-06
Iter: 1400 loss: 2.98864325e-06
Iter: 1401 loss: 2.98770919e-06
Iter: 1402 loss: 2.98741884e-06
Iter: 1403 loss: 2.98776035e-06
Iter: 1404 loss: 2.98700206e-06
Iter: 1405 loss: 2.98641771e-06
Iter: 1406 loss: 2.98521604e-06
Iter: 1407 loss: 3.00348051e-06
Iter: 1408 loss: 2.98525129e-06
Iter: 1409 loss: 2.98415148e-06
Iter: 1410 loss: 2.98227042e-06
Iter: 1411 loss: 3.02520402e-06
Iter: 1412 loss: 2.98223858e-06
Iter: 1413 loss: 2.98034638e-06
Iter: 1414 loss: 2.99145e-06
Iter: 1415 loss: 2.98018722e-06
Iter: 1416 loss: 2.9784469e-06
Iter: 1417 loss: 2.97898032e-06
Iter: 1418 loss: 2.97712313e-06
Iter: 1419 loss: 2.97579936e-06
Iter: 1420 loss: 2.99005796e-06
Iter: 1421 loss: 2.97577844e-06
Iter: 1422 loss: 2.97445604e-06
Iter: 1423 loss: 2.97418364e-06
Iter: 1424 loss: 2.97319502e-06
Iter: 1425 loss: 2.97162751e-06
Iter: 1426 loss: 2.97850488e-06
Iter: 1427 loss: 2.97123142e-06
Iter: 1428 loss: 2.97027918e-06
Iter: 1429 loss: 2.97983411e-06
Iter: 1430 loss: 2.97014685e-06
Iter: 1431 loss: 2.9692917e-06
Iter: 1432 loss: 2.9698333e-06
Iter: 1433 loss: 2.96871758e-06
Iter: 1434 loss: 2.96751523e-06
Iter: 1435 loss: 2.97514885e-06
Iter: 1436 loss: 2.96737699e-06
Iter: 1437 loss: 2.96677536e-06
Iter: 1438 loss: 2.96984922e-06
Iter: 1439 loss: 2.96659346e-06
Iter: 1440 loss: 2.96563167e-06
Iter: 1441 loss: 2.96755593e-06
Iter: 1442 loss: 2.96532971e-06
Iter: 1443 loss: 2.9648163e-06
Iter: 1444 loss: 2.96345547e-06
Iter: 1445 loss: 2.97662473e-06
Iter: 1446 loss: 2.9632829e-06
Iter: 1447 loss: 2.96170583e-06
Iter: 1448 loss: 2.96241979e-06
Iter: 1449 loss: 2.96061762e-06
Iter: 1450 loss: 2.9593316e-06
Iter: 1451 loss: 2.97836186e-06
Iter: 1452 loss: 2.95920745e-06
Iter: 1453 loss: 2.95828067e-06
Iter: 1454 loss: 2.95740324e-06
Iter: 1455 loss: 2.95711561e-06
Iter: 1456 loss: 2.95535051e-06
Iter: 1457 loss: 2.96902044e-06
Iter: 1458 loss: 2.95521545e-06
Iter: 1459 loss: 2.95434688e-06
Iter: 1460 loss: 2.95530208e-06
Iter: 1461 loss: 2.95378368e-06
Iter: 1462 loss: 2.95235895e-06
Iter: 1463 loss: 2.9529549e-06
Iter: 1464 loss: 2.95137897e-06
Iter: 1465 loss: 2.9501723e-06
Iter: 1466 loss: 2.95771906e-06
Iter: 1467 loss: 2.95003429e-06
Iter: 1468 loss: 2.94896381e-06
Iter: 1469 loss: 2.94981237e-06
Iter: 1470 loss: 2.94836696e-06
Iter: 1471 loss: 2.94722076e-06
Iter: 1472 loss: 2.95972541e-06
Iter: 1473 loss: 2.94724578e-06
Iter: 1474 loss: 2.94674965e-06
Iter: 1475 loss: 2.94669667e-06
Iter: 1476 loss: 2.94619076e-06
Iter: 1477 loss: 2.9472792e-06
Iter: 1478 loss: 2.94597248e-06
Iter: 1479 loss: 2.94534175e-06
Iter: 1480 loss: 2.94560141e-06
Iter: 1481 loss: 2.94494839e-06
Iter: 1482 loss: 2.94437586e-06
Iter: 1483 loss: 2.94385109e-06
Iter: 1484 loss: 2.94375309e-06
Iter: 1485 loss: 2.94277061e-06
Iter: 1486 loss: 2.94195979e-06
Iter: 1487 loss: 2.94170104e-06
Iter: 1488 loss: 2.94040547e-06
Iter: 1489 loss: 2.95173732e-06
Iter: 1490 loss: 2.94038273e-06
Iter: 1491 loss: 2.9394555e-06
Iter: 1492 loss: 2.93962694e-06
Iter: 1493 loss: 2.93874314e-06
Iter: 1494 loss: 2.93752964e-06
Iter: 1495 loss: 2.94448387e-06
Iter: 1496 loss: 2.93732637e-06
Iter: 1497 loss: 2.93622952e-06
Iter: 1498 loss: 2.94000711e-06
Iter: 1499 loss: 2.93590597e-06
Iter: 1500 loss: 2.93496896e-06
Iter: 1501 loss: 2.94077768e-06
Iter: 1502 loss: 2.93484936e-06
Iter: 1503 loss: 2.93390167e-06
Iter: 1504 loss: 2.9323428e-06
Iter: 1505 loss: 2.93236326e-06
Iter: 1506 loss: 2.93152698e-06
Iter: 1507 loss: 2.93141966e-06
Iter: 1508 loss: 2.93104313e-06
Iter: 1509 loss: 2.93732933e-06
Iter: 1510 loss: 2.93095832e-06
Iter: 1511 loss: 2.93044445e-06
Iter: 1512 loss: 2.92972618e-06
Iter: 1513 loss: 2.92977575e-06
Iter: 1514 loss: 2.92903815e-06
Iter: 1515 loss: 2.92946015e-06
Iter: 1516 loss: 2.92852837e-06
Iter: 1517 loss: 2.92789196e-06
Iter: 1518 loss: 2.92968753e-06
Iter: 1519 loss: 2.92768254e-06
Iter: 1520 loss: 2.92683285e-06
Iter: 1521 loss: 2.93081212e-06
Iter: 1522 loss: 2.92666437e-06
Iter: 1523 loss: 2.92603727e-06
Iter: 1524 loss: 2.92564619e-06
Iter: 1525 loss: 2.92534514e-06
Iter: 1526 loss: 2.9244718e-06
Iter: 1527 loss: 2.92454024e-06
Iter: 1528 loss: 2.92377558e-06
Iter: 1529 loss: 2.9225962e-06
Iter: 1530 loss: 2.92955315e-06
Iter: 1531 loss: 2.92239974e-06
Iter: 1532 loss: 2.92161303e-06
Iter: 1533 loss: 2.92099708e-06
Iter: 1534 loss: 2.92072218e-06
Iter: 1535 loss: 2.91947026e-06
Iter: 1536 loss: 2.91947845e-06
Iter: 1537 loss: 2.91888091e-06
Iter: 1538 loss: 2.92026084e-06
Iter: 1539 loss: 2.91862034e-06
Iter: 1540 loss: 2.91781635e-06
Iter: 1541 loss: 2.92031655e-06
Iter: 1542 loss: 2.91749939e-06
Iter: 1543 loss: 2.91658216e-06
Iter: 1544 loss: 2.92816662e-06
Iter: 1545 loss: 2.91659853e-06
Iter: 1546 loss: 2.91644915e-06
Iter: 1547 loss: 2.91575952e-06
Iter: 1548 loss: 2.91917331e-06
Iter: 1549 loss: 2.91564606e-06
Iter: 1550 loss: 2.91451647e-06
Iter: 1551 loss: 2.91539664e-06
Iter: 1552 loss: 2.91395509e-06
Iter: 1553 loss: 2.91297465e-06
Iter: 1554 loss: 2.91298556e-06
Iter: 1555 loss: 2.91246442e-06
Iter: 1556 loss: 2.91326751e-06
Iter: 1557 loss: 2.91216907e-06
Iter: 1558 loss: 2.9115065e-06
Iter: 1559 loss: 2.91015976e-06
Iter: 1560 loss: 2.92930963e-06
Iter: 1561 loss: 2.9101393e-06
Iter: 1562 loss: 2.90888e-06
Iter: 1563 loss: 2.92322693e-06
Iter: 1564 loss: 2.9088942e-06
Iter: 1565 loss: 2.90789012e-06
Iter: 1566 loss: 2.90759317e-06
Iter: 1567 loss: 2.90710614e-06
Iter: 1568 loss: 2.90604203e-06
Iter: 1569 loss: 2.91686843e-06
Iter: 1570 loss: 2.90605522e-06
Iter: 1571 loss: 2.90518983e-06
Iter: 1572 loss: 2.90631397e-06
Iter: 1573 loss: 2.90499815e-06
Iter: 1574 loss: 2.90388039e-06
Iter: 1575 loss: 2.90606977e-06
Iter: 1576 loss: 2.90351704e-06
Iter: 1577 loss: 2.90462231e-06
Iter: 1578 loss: 2.9030798e-06
Iter: 1579 loss: 2.90299067e-06
Iter: 1580 loss: 2.90234493e-06
Iter: 1581 loss: 2.90177331e-06
Iter: 1582 loss: 2.90156549e-06
Iter: 1583 loss: 2.90044068e-06
Iter: 1584 loss: 2.90551202e-06
Iter: 1585 loss: 2.90014555e-06
Iter: 1586 loss: 2.89951481e-06
Iter: 1587 loss: 2.8994491e-06
Iter: 1588 loss: 2.89887907e-06
Iter: 1589 loss: 2.899023e-06
Iter: 1590 loss: 2.89843501e-06
Iter: 1591 loss: 2.89756281e-06
Iter: 1592 loss: 2.89848549e-06
Iter: 1593 loss: 2.8970735e-06
Iter: 1594 loss: 2.89627042e-06
Iter: 1595 loss: 2.89539912e-06
Iter: 1596 loss: 2.89518835e-06
Iter: 1597 loss: 2.89383252e-06
Iter: 1598 loss: 2.90437401e-06
Iter: 1599 loss: 2.89367176e-06
Iter: 1600 loss: 2.89264926e-06
Iter: 1601 loss: 2.89199716e-06
Iter: 1602 loss: 2.89154627e-06
Iter: 1603 loss: 2.89025343e-06
Iter: 1604 loss: 2.9116818e-06
Iter: 1605 loss: 2.89024138e-06
Iter: 1606 loss: 2.8893096e-06
Iter: 1607 loss: 2.8914078e-06
Iter: 1608 loss: 2.88891488e-06
Iter: 1609 loss: 2.88844899e-06
Iter: 1610 loss: 2.88842375e-06
Iter: 1611 loss: 2.88765659e-06
Iter: 1612 loss: 2.8864672e-06
Iter: 1613 loss: 2.88650381e-06
Iter: 1614 loss: 2.88587103e-06
Iter: 1615 loss: 2.8851257e-06
Iter: 1616 loss: 2.88494493e-06
Iter: 1617 loss: 2.88367573e-06
Iter: 1618 loss: 2.88759497e-06
Iter: 1619 loss: 2.88332558e-06
Iter: 1620 loss: 2.88268302e-06
Iter: 1621 loss: 2.88259025e-06
Iter: 1622 loss: 2.88215188e-06
Iter: 1623 loss: 2.8811105e-06
Iter: 1624 loss: 2.90216758e-06
Iter: 1625 loss: 2.88112051e-06
Iter: 1626 loss: 2.87978537e-06
Iter: 1627 loss: 2.88398223e-06
Iter: 1628 loss: 2.87933017e-06
Iter: 1629 loss: 2.87851435e-06
Iter: 1630 loss: 2.88005572e-06
Iter: 1631 loss: 2.87815533e-06
Iter: 1632 loss: 2.8767663e-06
Iter: 1633 loss: 2.87520925e-06
Iter: 1634 loss: 2.875e-06
Iter: 1635 loss: 2.87355897e-06
Iter: 1636 loss: 2.87359353e-06
Iter: 1637 loss: 2.87249668e-06
Iter: 1638 loss: 2.87333023e-06
Iter: 1639 loss: 2.87176431e-06
Iter: 1640 loss: 2.87193916e-06
Iter: 1641 loss: 2.871172e-06
Iter: 1642 loss: 2.8706379e-06
Iter: 1643 loss: 2.87124612e-06
Iter: 1644 loss: 2.87028183e-06
Iter: 1645 loss: 2.86983482e-06
Iter: 1646 loss: 2.868519e-06
Iter: 1647 loss: 2.87405419e-06
Iter: 1648 loss: 2.86801355e-06
Iter: 1649 loss: 2.8666127e-06
Iter: 1650 loss: 2.87930129e-06
Iter: 1651 loss: 2.86655677e-06
Iter: 1652 loss: 2.86575414e-06
Iter: 1653 loss: 2.86754926e-06
Iter: 1654 loss: 2.86539307e-06
Iter: 1655 loss: 2.86409477e-06
Iter: 1656 loss: 2.8674533e-06
Iter: 1657 loss: 2.86363684e-06
Iter: 1658 loss: 2.86263321e-06
Iter: 1659 loss: 2.86488353e-06
Iter: 1660 loss: 2.86232398e-06
Iter: 1661 loss: 2.86138879e-06
Iter: 1662 loss: 2.86132718e-06
Iter: 1663 loss: 2.86063732e-06
Iter: 1664 loss: 2.85920237e-06
Iter: 1665 loss: 2.86340014e-06
Iter: 1666 loss: 2.85880947e-06
Iter: 1667 loss: 2.85769738e-06
Iter: 1668 loss: 2.85839724e-06
Iter: 1669 loss: 2.85693886e-06
Iter: 1670 loss: 2.85542865e-06
Iter: 1671 loss: 2.85875421e-06
Iter: 1672 loss: 2.85478245e-06
Iter: 1673 loss: 2.85444548e-06
Iter: 1674 loss: 2.85420629e-06
Iter: 1675 loss: 2.85352689e-06
Iter: 1676 loss: 2.85491797e-06
Iter: 1677 loss: 2.8531831e-06
Iter: 1678 loss: 2.85252372e-06
Iter: 1679 loss: 2.85130136e-06
Iter: 1680 loss: 2.8812758e-06
Iter: 1681 loss: 2.85134729e-06
Iter: 1682 loss: 2.85013107e-06
Iter: 1683 loss: 2.85248302e-06
Iter: 1684 loss: 2.84970429e-06
Iter: 1685 loss: 2.84855923e-06
Iter: 1686 loss: 2.85070723e-06
Iter: 1687 loss: 2.84812177e-06
Iter: 1688 loss: 2.84737712e-06
Iter: 1689 loss: 2.8472989e-06
Iter: 1690 loss: 2.84673433e-06
Iter: 1691 loss: 2.84564385e-06
Iter: 1692 loss: 2.86543332e-06
Iter: 1693 loss: 2.84563475e-06
Iter: 1694 loss: 2.84413386e-06
Iter: 1695 loss: 2.85116903e-06
Iter: 1696 loss: 2.84391331e-06
Iter: 1697 loss: 2.84297494e-06
Iter: 1698 loss: 2.8450836e-06
Iter: 1699 loss: 2.84258363e-06
Iter: 1700 loss: 2.84138105e-06
Iter: 1701 loss: 2.84004818e-06
Iter: 1702 loss: 2.83977579e-06
Iter: 1703 loss: 2.83837403e-06
Iter: 1704 loss: 2.85306442e-06
Iter: 1705 loss: 2.83828945e-06
Iter: 1706 loss: 2.83689542e-06
Iter: 1707 loss: 2.83698841e-06
Iter: 1708 loss: 2.83595409e-06
Iter: 1709 loss: 2.83779696e-06
Iter: 1710 loss: 2.8352365e-06
Iter: 1711 loss: 2.83497684e-06
Iter: 1712 loss: 2.83413465e-06
Iter: 1713 loss: 2.84073417e-06
Iter: 1714 loss: 2.83401869e-06
Iter: 1715 loss: 2.83296276e-06
Iter: 1716 loss: 2.83306485e-06
Iter: 1717 loss: 2.83200256e-06
Iter: 1718 loss: 2.83056966e-06
Iter: 1719 loss: 2.83364807e-06
Iter: 1720 loss: 2.82999827e-06
Iter: 1721 loss: 2.82912424e-06
Iter: 1722 loss: 2.82915016e-06
Iter: 1723 loss: 2.82803239e-06
Iter: 1724 loss: 2.82626274e-06
Iter: 1725 loss: 2.82629208e-06
Iter: 1726 loss: 2.82463657e-06
Iter: 1727 loss: 2.83566487e-06
Iter: 1728 loss: 2.82445262e-06
Iter: 1729 loss: 2.82326664e-06
Iter: 1730 loss: 2.82617862e-06
Iter: 1731 loss: 2.82282735e-06
Iter: 1732 loss: 2.82135738e-06
Iter: 1733 loss: 2.82165615e-06
Iter: 1734 loss: 2.82011524e-06
Iter: 1735 loss: 2.81882558e-06
Iter: 1736 loss: 2.8209663e-06
Iter: 1737 loss: 2.8181089e-06
Iter: 1738 loss: 2.81622169e-06
Iter: 1739 loss: 2.82149585e-06
Iter: 1740 loss: 2.81560824e-06
Iter: 1741 loss: 2.81509847e-06
Iter: 1742 loss: 2.81477878e-06
Iter: 1743 loss: 2.8138279e-06
Iter: 1744 loss: 2.81227108e-06
Iter: 1745 loss: 2.81228222e-06
Iter: 1746 loss: 2.81098323e-06
Iter: 1747 loss: 2.81127404e-06
Iter: 1748 loss: 2.81015059e-06
Iter: 1749 loss: 2.80898053e-06
Iter: 1750 loss: 2.81730763e-06
Iter: 1751 loss: 2.80882591e-06
Iter: 1752 loss: 2.80792437e-06
Iter: 1753 loss: 2.80913355e-06
Iter: 1754 loss: 2.80752511e-06
Iter: 1755 loss: 2.80635231e-06
Iter: 1756 loss: 2.81195116e-06
Iter: 1757 loss: 2.80601e-06
Iter: 1758 loss: 2.80513314e-06
Iter: 1759 loss: 2.8045115e-06
Iter: 1760 loss: 2.80427525e-06
Iter: 1761 loss: 2.80281301e-06
Iter: 1762 loss: 2.80683798e-06
Iter: 1763 loss: 2.80238191e-06
Iter: 1764 loss: 2.80111044e-06
Iter: 1765 loss: 2.80765153e-06
Iter: 1766 loss: 2.80073118e-06
Iter: 1767 loss: 2.79948335e-06
Iter: 1768 loss: 2.79840356e-06
Iter: 1769 loss: 2.79797041e-06
Iter: 1770 loss: 2.79653295e-06
Iter: 1771 loss: 2.81195435e-06
Iter: 1772 loss: 2.79653409e-06
Iter: 1773 loss: 2.79533333e-06
Iter: 1774 loss: 2.79709047e-06
Iter: 1775 loss: 2.79481083e-06
Iter: 1776 loss: 2.79380288e-06
Iter: 1777 loss: 2.79381175e-06
Iter: 1778 loss: 2.79338701e-06
Iter: 1779 loss: 2.79248434e-06
Iter: 1780 loss: 2.79769029e-06
Iter: 1781 loss: 2.79217147e-06
Iter: 1782 loss: 2.79099095e-06
Iter: 1783 loss: 2.79284609e-06
Iter: 1784 loss: 2.79042706e-06
Iter: 1785 loss: 2.78914126e-06
Iter: 1786 loss: 2.79495862e-06
Iter: 1787 loss: 2.78887592e-06
Iter: 1788 loss: 2.78793959e-06
Iter: 1789 loss: 2.79333108e-06
Iter: 1790 loss: 2.78778e-06
Iter: 1791 loss: 2.78656353e-06
Iter: 1792 loss: 2.7853896e-06
Iter: 1793 loss: 2.785177e-06
Iter: 1794 loss: 2.78387552e-06
Iter: 1795 loss: 2.79115693e-06
Iter: 1796 loss: 2.78364155e-06
Iter: 1797 loss: 2.78260677e-06
Iter: 1798 loss: 2.78409652e-06
Iter: 1799 loss: 2.78200696e-06
Iter: 1800 loss: 2.7805313e-06
Iter: 1801 loss: 2.78513335e-06
Iter: 1802 loss: 2.78013977e-06
Iter: 1803 loss: 2.77915115e-06
Iter: 1804 loss: 2.7796309e-06
Iter: 1805 loss: 2.77856407e-06
Iter: 1806 loss: 2.776977e-06
Iter: 1807 loss: 2.77901245e-06
Iter: 1808 loss: 2.77606432e-06
Iter: 1809 loss: 2.7788451e-06
Iter: 1810 loss: 2.77572508e-06
Iter: 1811 loss: 2.77550384e-06
Iter: 1812 loss: 2.7747094e-06
Iter: 1813 loss: 2.77434037e-06
Iter: 1814 loss: 2.77379195e-06
Iter: 1815 loss: 2.77221625e-06
Iter: 1816 loss: 2.7792521e-06
Iter: 1817 loss: 2.77183403e-06
Iter: 1818 loss: 2.77071786e-06
Iter: 1819 loss: 2.78393827e-06
Iter: 1820 loss: 2.7707049e-06
Iter: 1821 loss: 2.76991022e-06
Iter: 1822 loss: 2.76981973e-06
Iter: 1823 loss: 2.7694216e-06
Iter: 1824 loss: 2.76818037e-06
Iter: 1825 loss: 2.77547042e-06
Iter: 1826 loss: 2.76792935e-06
Iter: 1827 loss: 2.76724222e-06
Iter: 1828 loss: 2.76750643e-06
Iter: 1829 loss: 2.76667652e-06
Iter: 1830 loss: 2.76565697e-06
Iter: 1831 loss: 2.7657602e-06
Iter: 1832 loss: 2.76478386e-06
Iter: 1833 loss: 2.76397941e-06
Iter: 1834 loss: 2.77958952e-06
Iter: 1835 loss: 2.76396577e-06
Iter: 1836 loss: 2.76326227e-06
Iter: 1837 loss: 2.76192873e-06
Iter: 1838 loss: 2.78473181e-06
Iter: 1839 loss: 2.76189053e-06
Iter: 1840 loss: 2.76021228e-06
Iter: 1841 loss: 2.77271283e-06
Iter: 1842 loss: 2.76011428e-06
Iter: 1843 loss: 2.76018227e-06
Iter: 1844 loss: 2.75977663e-06
Iter: 1845 loss: 2.75926959e-06
Iter: 1846 loss: 2.75832986e-06
Iter: 1847 loss: 2.77338404e-06
Iter: 1848 loss: 2.75825596e-06
Iter: 1849 loss: 2.7576591e-06
Iter: 1850 loss: 2.75685079e-06
Iter: 1851 loss: 2.75675166e-06
Iter: 1852 loss: 2.75538969e-06
Iter: 1853 loss: 2.75955722e-06
Iter: 1854 loss: 2.755e-06
Iter: 1855 loss: 2.75389357e-06
Iter: 1856 loss: 2.75389425e-06
Iter: 1857 loss: 2.75333377e-06
Iter: 1858 loss: 2.75387765e-06
Iter: 1859 loss: 2.75284492e-06
Iter: 1860 loss: 2.75184766e-06
Iter: 1861 loss: 2.75157299e-06
Iter: 1862 loss: 2.7509318e-06
Iter: 1863 loss: 2.75002367e-06
Iter: 1864 loss: 2.75430853e-06
Iter: 1865 loss: 2.74984541e-06
Iter: 1866 loss: 2.74907416e-06
Iter: 1867 loss: 2.74957233e-06
Iter: 1868 loss: 2.74851209e-06
Iter: 1869 loss: 2.74711783e-06
Iter: 1870 loss: 2.751073e-06
Iter: 1871 loss: 2.74676358e-06
Iter: 1872 loss: 2.74568924e-06
Iter: 1873 loss: 2.74742342e-06
Iter: 1874 loss: 2.74514082e-06
Iter: 1875 loss: 2.74424792e-06
Iter: 1876 loss: 2.75510433e-06
Iter: 1877 loss: 2.74419426e-06
Iter: 1878 loss: 2.743084e-06
Iter: 1879 loss: 2.74930562e-06
Iter: 1880 loss: 2.74296076e-06
Iter: 1881 loss: 2.74259969e-06
Iter: 1882 loss: 2.7416072e-06
Iter: 1883 loss: 2.74636409e-06
Iter: 1884 loss: 2.74134754e-06
Iter: 1885 loss: 2.73998444e-06
Iter: 1886 loss: 2.74390254e-06
Iter: 1887 loss: 2.73960586e-06
Iter: 1888 loss: 2.73901037e-06
Iter: 1889 loss: 2.73891806e-06
Iter: 1890 loss: 2.73831552e-06
Iter: 1891 loss: 2.73793171e-06
Iter: 1892 loss: 2.7377132e-06
Iter: 1893 loss: 2.73668957e-06
Iter: 1894 loss: 2.73926753e-06
Iter: 1895 loss: 2.73623436e-06
Iter: 1896 loss: 2.73540127e-06
Iter: 1897 loss: 2.73493697e-06
Iter: 1898 loss: 2.73452679e-06
Iter: 1899 loss: 2.73296837e-06
Iter: 1900 loss: 2.73635942e-06
Iter: 1901 loss: 2.73237e-06
Iter: 1902 loss: 2.73120372e-06
Iter: 1903 loss: 2.7444587e-06
Iter: 1904 loss: 2.73118576e-06
Iter: 1905 loss: 2.7303729e-06
Iter: 1906 loss: 2.73006822e-06
Iter: 1907 loss: 2.72965667e-06
Iter: 1908 loss: 2.72872171e-06
Iter: 1909 loss: 2.74025228e-06
Iter: 1910 loss: 2.7286751e-06
Iter: 1911 loss: 2.72800844e-06
Iter: 1912 loss: 2.7279907e-06
Iter: 1913 loss: 2.72776833e-06
Iter: 1914 loss: 2.72698867e-06
Iter: 1915 loss: 2.72674924e-06
Iter: 1916 loss: 2.72611737e-06
Iter: 1917 loss: 2.72466377e-06
Iter: 1918 loss: 2.7327078e-06
Iter: 1919 loss: 2.72442367e-06
Iter: 1920 loss: 2.72331636e-06
Iter: 1921 loss: 2.72709349e-06
Iter: 1922 loss: 2.72302827e-06
Iter: 1923 loss: 2.72200123e-06
Iter: 1924 loss: 2.73623391e-06
Iter: 1925 loss: 2.7220085e-06
Iter: 1926 loss: 2.72121565e-06
Iter: 1927 loss: 2.72216266e-06
Iter: 1928 loss: 2.72090574e-06
Iter: 1929 loss: 2.72001034e-06
Iter: 1930 loss: 2.71855424e-06
Iter: 1931 loss: 2.71862473e-06
Iter: 1932 loss: 2.71725094e-06
Iter: 1933 loss: 2.72915213e-06
Iter: 1934 loss: 2.71719227e-06
Iter: 1935 loss: 2.71619365e-06
Iter: 1936 loss: 2.71840372e-06
Iter: 1937 loss: 2.71589079e-06
Iter: 1938 loss: 2.71472663e-06
Iter: 1939 loss: 2.71923227e-06
Iter: 1940 loss: 2.71451631e-06
Iter: 1941 loss: 2.71374074e-06
Iter: 1942 loss: 2.71557519e-06
Iter: 1943 loss: 2.71342424e-06
Iter: 1944 loss: 2.71305112e-06
Iter: 1945 loss: 2.712899e-06
Iter: 1946 loss: 2.71255453e-06
Iter: 1947 loss: 2.7117344e-06
Iter: 1948 loss: 2.71555655e-06
Iter: 1949 loss: 2.71126828e-06
Iter: 1950 loss: 2.71033582e-06
Iter: 1951 loss: 2.71189333e-06
Iter: 1952 loss: 2.7098738e-06
Iter: 1953 loss: 2.70877513e-06
Iter: 1954 loss: 2.71295335e-06
Iter: 1955 loss: 2.70851024e-06
Iter: 1956 loss: 2.70777809e-06
Iter: 1957 loss: 2.7077906e-06
Iter: 1958 loss: 2.70731698e-06
Iter: 1959 loss: 2.70672263e-06
Iter: 1960 loss: 2.70672808e-06
Iter: 1961 loss: 2.70557484e-06
Iter: 1962 loss: 2.70568262e-06
Iter: 1963 loss: 2.70473652e-06
Iter: 1964 loss: 2.70356441e-06
Iter: 1965 loss: 2.71156387e-06
Iter: 1966 loss: 2.70347073e-06
Iter: 1967 loss: 2.70247915e-06
Iter: 1968 loss: 2.70224609e-06
Iter: 1969 loss: 2.70155806e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8
+ date
Mon Oct 26 10:28:10 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880d6f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880d94950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880d94d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880d94048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880e30510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880c97950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880c568c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880c5e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880c61510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880c61950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880c616a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b888c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b88840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b88488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b522f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b01b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b00488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b36510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880ada0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880b36f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880a8f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880a8ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6880a15950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846d0f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846d0f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846d3e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846d7f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846ce7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846cda620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846cdabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846ccbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846c63510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6846c78268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68203ce840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68203768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68203841e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.86728376e-05
Iter: 2 loss: 8.86760536e-05
Iter: 3 loss: 7.58593742e-05
Iter: 4 loss: 6.80731464e-05
Iter: 5 loss: 7.31968903e-05
Iter: 6 loss: 6.31578878e-05
Iter: 7 loss: 5.84198e-05
Iter: 8 loss: 5.21461661e-05
Iter: 9 loss: 5.17818844e-05
Iter: 10 loss: 4.59835355e-05
Iter: 11 loss: 7.69364269e-05
Iter: 12 loss: 4.51105516e-05
Iter: 13 loss: 4.06103427e-05
Iter: 14 loss: 4.28013336e-05
Iter: 15 loss: 3.75683376e-05
Iter: 16 loss: 3.37589445e-05
Iter: 17 loss: 7.46931764e-05
Iter: 18 loss: 3.36702833e-05
Iter: 19 loss: 3.13404271e-05
Iter: 20 loss: 3.45227563e-05
Iter: 21 loss: 3.01841083e-05
Iter: 22 loss: 2.80296317e-05
Iter: 23 loss: 3.40915831e-05
Iter: 24 loss: 2.73422411e-05
Iter: 25 loss: 2.60133093e-05
Iter: 26 loss: 2.63102156e-05
Iter: 27 loss: 2.50302473e-05
Iter: 28 loss: 2.36427059e-05
Iter: 29 loss: 2.77607869e-05
Iter: 30 loss: 2.32194e-05
Iter: 31 loss: 2.22436101e-05
Iter: 32 loss: 2.20148322e-05
Iter: 33 loss: 2.13894018e-05
Iter: 34 loss: 2.02111842e-05
Iter: 35 loss: 3.75043601e-05
Iter: 36 loss: 2.02095798e-05
Iter: 37 loss: 1.95447556e-05
Iter: 38 loss: 2.45471711e-05
Iter: 39 loss: 1.94931454e-05
Iter: 40 loss: 1.90217525e-05
Iter: 41 loss: 1.89493912e-05
Iter: 42 loss: 1.86219186e-05
Iter: 43 loss: 1.78729297e-05
Iter: 44 loss: 1.74283723e-05
Iter: 45 loss: 1.71150205e-05
Iter: 46 loss: 1.63550903e-05
Iter: 47 loss: 2.24013238e-05
Iter: 48 loss: 1.6304044e-05
Iter: 49 loss: 1.57162631e-05
Iter: 50 loss: 1.62051365e-05
Iter: 51 loss: 1.53664769e-05
Iter: 52 loss: 1.481871e-05
Iter: 53 loss: 2.09104928e-05
Iter: 54 loss: 1.48080871e-05
Iter: 55 loss: 1.44829028e-05
Iter: 56 loss: 1.44700898e-05
Iter: 57 loss: 1.42187528e-05
Iter: 58 loss: 1.37018214e-05
Iter: 59 loss: 1.68356237e-05
Iter: 60 loss: 1.36383987e-05
Iter: 61 loss: 1.33873073e-05
Iter: 62 loss: 1.3641351e-05
Iter: 63 loss: 1.32468449e-05
Iter: 64 loss: 1.2892895e-05
Iter: 65 loss: 1.31796623e-05
Iter: 66 loss: 1.26807954e-05
Iter: 67 loss: 1.23982591e-05
Iter: 68 loss: 1.23982254e-05
Iter: 69 loss: 1.22036054e-05
Iter: 70 loss: 1.37299021e-05
Iter: 71 loss: 1.21900412e-05
Iter: 72 loss: 1.19940196e-05
Iter: 73 loss: 1.19647066e-05
Iter: 74 loss: 1.1827824e-05
Iter: 75 loss: 1.16501178e-05
Iter: 76 loss: 1.26455398e-05
Iter: 77 loss: 1.16252904e-05
Iter: 78 loss: 1.15106423e-05
Iter: 79 loss: 1.12926073e-05
Iter: 80 loss: 1.59664414e-05
Iter: 81 loss: 1.12913622e-05
Iter: 82 loss: 1.10073106e-05
Iter: 83 loss: 1.32661426e-05
Iter: 84 loss: 1.09881084e-05
Iter: 85 loss: 1.08446038e-05
Iter: 86 loss: 1.14197983e-05
Iter: 87 loss: 1.08120457e-05
Iter: 88 loss: 1.06445805e-05
Iter: 89 loss: 1.06147054e-05
Iter: 90 loss: 1.05016316e-05
Iter: 91 loss: 1.03423708e-05
Iter: 92 loss: 1.03423117e-05
Iter: 93 loss: 1.02425656e-05
Iter: 94 loss: 1.02804288e-05
Iter: 95 loss: 1.01728747e-05
Iter: 96 loss: 1.00318557e-05
Iter: 97 loss: 1.04529227e-05
Iter: 98 loss: 9.98913856e-06
Iter: 99 loss: 9.87915064e-06
Iter: 100 loss: 1.01325213e-05
Iter: 101 loss: 9.83801328e-06
Iter: 102 loss: 9.71269947e-06
Iter: 103 loss: 1.04801793e-05
Iter: 104 loss: 9.69784651e-06
Iter: 105 loss: 9.57623e-06
Iter: 106 loss: 1.04502878e-05
Iter: 107 loss: 9.56546e-06
Iter: 108 loss: 9.51146649e-06
Iter: 109 loss: 9.45022657e-06
Iter: 110 loss: 9.44244493e-06
Iter: 111 loss: 9.3435292e-06
Iter: 112 loss: 9.53228482e-06
Iter: 113 loss: 9.30225724e-06
Iter: 114 loss: 9.22403524e-06
Iter: 115 loss: 9.41901817e-06
Iter: 116 loss: 9.19640479e-06
Iter: 117 loss: 9.09877781e-06
Iter: 118 loss: 9.21800802e-06
Iter: 119 loss: 9.04804619e-06
Iter: 120 loss: 8.96503479e-06
Iter: 121 loss: 9.64571154e-06
Iter: 122 loss: 8.95976245e-06
Iter: 123 loss: 8.88210343e-06
Iter: 124 loss: 8.87159e-06
Iter: 125 loss: 8.81656069e-06
Iter: 126 loss: 8.72364e-06
Iter: 127 loss: 9.72172347e-06
Iter: 128 loss: 8.72154669e-06
Iter: 129 loss: 8.66246774e-06
Iter: 130 loss: 8.69936412e-06
Iter: 131 loss: 8.62464731e-06
Iter: 132 loss: 8.54104474e-06
Iter: 133 loss: 8.73844874e-06
Iter: 134 loss: 8.51001732e-06
Iter: 135 loss: 8.45681461e-06
Iter: 136 loss: 9.09653136e-06
Iter: 137 loss: 8.45632349e-06
Iter: 138 loss: 8.41447218e-06
Iter: 139 loss: 8.75819569e-06
Iter: 140 loss: 8.41184283e-06
Iter: 141 loss: 8.37672451e-06
Iter: 142 loss: 8.31683428e-06
Iter: 143 loss: 8.3167788e-06
Iter: 144 loss: 8.26428732e-06
Iter: 145 loss: 8.55479084e-06
Iter: 146 loss: 8.25677e-06
Iter: 147 loss: 8.21275171e-06
Iter: 148 loss: 8.20790046e-06
Iter: 149 loss: 8.1762737e-06
Iter: 150 loss: 8.12012877e-06
Iter: 151 loss: 8.5089e-06
Iter: 152 loss: 8.11509472e-06
Iter: 153 loss: 8.07356446e-06
Iter: 154 loss: 8.07464494e-06
Iter: 155 loss: 8.04072806e-06
Iter: 156 loss: 7.97352e-06
Iter: 157 loss: 8.35397259e-06
Iter: 158 loss: 7.96415861e-06
Iter: 159 loss: 7.92756782e-06
Iter: 160 loss: 8.11087648e-06
Iter: 161 loss: 7.9214833e-06
Iter: 162 loss: 7.88125e-06
Iter: 163 loss: 7.86556302e-06
Iter: 164 loss: 7.84362601e-06
Iter: 165 loss: 7.79212951e-06
Iter: 166 loss: 8.30582212e-06
Iter: 167 loss: 7.79035327e-06
Iter: 168 loss: 7.76295383e-06
Iter: 169 loss: 7.77606e-06
Iter: 170 loss: 7.7446357e-06
Iter: 171 loss: 7.70809311e-06
Iter: 172 loss: 8.23419214e-06
Iter: 173 loss: 7.70803581e-06
Iter: 174 loss: 7.68173777e-06
Iter: 175 loss: 7.670993e-06
Iter: 176 loss: 7.65714776e-06
Iter: 177 loss: 7.62984564e-06
Iter: 178 loss: 7.63324351e-06
Iter: 179 loss: 7.60917465e-06
Iter: 180 loss: 7.56610507e-06
Iter: 181 loss: 7.65423738e-06
Iter: 182 loss: 7.54875464e-06
Iter: 183 loss: 7.5180219e-06
Iter: 184 loss: 7.69600138e-06
Iter: 185 loss: 7.51399739e-06
Iter: 186 loss: 7.48561433e-06
Iter: 187 loss: 7.47057356e-06
Iter: 188 loss: 7.4577938e-06
Iter: 189 loss: 7.41721442e-06
Iter: 190 loss: 7.83665655e-06
Iter: 191 loss: 7.41618578e-06
Iter: 192 loss: 7.38984636e-06
Iter: 193 loss: 7.42411066e-06
Iter: 194 loss: 7.37639948e-06
Iter: 195 loss: 7.34009518e-06
Iter: 196 loss: 7.43634973e-06
Iter: 197 loss: 7.32811441e-06
Iter: 198 loss: 7.30038801e-06
Iter: 199 loss: 7.45135276e-06
Iter: 200 loss: 7.29639578e-06
Iter: 201 loss: 7.27018414e-06
Iter: 202 loss: 7.26813869e-06
Iter: 203 loss: 7.24878055e-06
Iter: 204 loss: 7.23365702e-06
Iter: 205 loss: 7.22826189e-06
Iter: 206 loss: 7.21373181e-06
Iter: 207 loss: 7.21305378e-06
Iter: 208 loss: 7.20215303e-06
Iter: 209 loss: 7.1855693e-06
Iter: 210 loss: 7.15762644e-06
Iter: 211 loss: 7.15759597e-06
Iter: 212 loss: 7.12543306e-06
Iter: 213 loss: 7.41378472e-06
Iter: 214 loss: 7.12397468e-06
Iter: 215 loss: 7.10377481e-06
Iter: 216 loss: 7.11207576e-06
Iter: 217 loss: 7.08974403e-06
Iter: 218 loss: 7.05906223e-06
Iter: 219 loss: 7.13541158e-06
Iter: 220 loss: 7.04845297e-06
Iter: 221 loss: 7.02616126e-06
Iter: 222 loss: 7.17888906e-06
Iter: 223 loss: 7.02420039e-06
Iter: 224 loss: 7.00138e-06
Iter: 225 loss: 6.98971326e-06
Iter: 226 loss: 6.97894211e-06
Iter: 227 loss: 6.94799564e-06
Iter: 228 loss: 7.27962924e-06
Iter: 229 loss: 6.94716437e-06
Iter: 230 loss: 6.92824096e-06
Iter: 231 loss: 6.95309063e-06
Iter: 232 loss: 6.91847072e-06
Iter: 233 loss: 6.89150329e-06
Iter: 234 loss: 6.9202847e-06
Iter: 235 loss: 6.87666488e-06
Iter: 236 loss: 6.86835028e-06
Iter: 237 loss: 6.86305293e-06
Iter: 238 loss: 6.85215e-06
Iter: 239 loss: 6.84666611e-06
Iter: 240 loss: 6.84141241e-06
Iter: 241 loss: 6.82470818e-06
Iter: 242 loss: 6.80458925e-06
Iter: 243 loss: 6.80253424e-06
Iter: 244 loss: 6.78320612e-06
Iter: 245 loss: 7.0088272e-06
Iter: 246 loss: 6.78303877e-06
Iter: 247 loss: 6.76848504e-06
Iter: 248 loss: 6.75262163e-06
Iter: 249 loss: 6.7502624e-06
Iter: 250 loss: 6.72346823e-06
Iter: 251 loss: 6.89635408e-06
Iter: 252 loss: 6.72058741e-06
Iter: 253 loss: 6.70378495e-06
Iter: 254 loss: 6.7520823e-06
Iter: 255 loss: 6.69877181e-06
Iter: 256 loss: 6.67887889e-06
Iter: 257 loss: 6.71987164e-06
Iter: 258 loss: 6.67096e-06
Iter: 259 loss: 6.65285097e-06
Iter: 260 loss: 6.75289539e-06
Iter: 261 loss: 6.65009156e-06
Iter: 262 loss: 6.63341143e-06
Iter: 263 loss: 6.64258278e-06
Iter: 264 loss: 6.62217e-06
Iter: 265 loss: 6.6028706e-06
Iter: 266 loss: 6.75228785e-06
Iter: 267 loss: 6.6017933e-06
Iter: 268 loss: 6.59251236e-06
Iter: 269 loss: 6.69355813e-06
Iter: 270 loss: 6.59223542e-06
Iter: 271 loss: 6.58167892e-06
Iter: 272 loss: 6.58014415e-06
Iter: 273 loss: 6.57286e-06
Iter: 274 loss: 6.55855e-06
Iter: 275 loss: 6.55265194e-06
Iter: 276 loss: 6.54513497e-06
Iter: 277 loss: 6.53139614e-06
Iter: 278 loss: 6.59713805e-06
Iter: 279 loss: 6.52897234e-06
Iter: 280 loss: 6.51316668e-06
Iter: 281 loss: 6.50259426e-06
Iter: 282 loss: 6.49675894e-06
Iter: 283 loss: 6.47706656e-06
Iter: 284 loss: 6.68788743e-06
Iter: 285 loss: 6.47655361e-06
Iter: 286 loss: 6.46270337e-06
Iter: 287 loss: 6.45627551e-06
Iter: 288 loss: 6.449583e-06
Iter: 289 loss: 6.43129169e-06
Iter: 290 loss: 6.65910193e-06
Iter: 291 loss: 6.43118756e-06
Iter: 292 loss: 6.42022178e-06
Iter: 293 loss: 6.43233216e-06
Iter: 294 loss: 6.41420047e-06
Iter: 295 loss: 6.39846394e-06
Iter: 296 loss: 6.43898511e-06
Iter: 297 loss: 6.39288464e-06
Iter: 298 loss: 6.37935182e-06
Iter: 299 loss: 6.44761622e-06
Iter: 300 loss: 6.37703079e-06
Iter: 301 loss: 6.36802088e-06
Iter: 302 loss: 6.44578085e-06
Iter: 303 loss: 6.36768391e-06
Iter: 304 loss: 6.35834112e-06
Iter: 305 loss: 6.3773432e-06
Iter: 306 loss: 6.35474089e-06
Iter: 307 loss: 6.34636945e-06
Iter: 308 loss: 6.34263506e-06
Iter: 309 loss: 6.33847594e-06
Iter: 310 loss: 6.32757565e-06
Iter: 311 loss: 6.32920592e-06
Iter: 312 loss: 6.31906914e-06
Iter: 313 loss: 6.30249451e-06
Iter: 314 loss: 6.37245103e-06
Iter: 315 loss: 6.29885244e-06
Iter: 316 loss: 6.2868171e-06
Iter: 317 loss: 6.31424427e-06
Iter: 318 loss: 6.28234375e-06
Iter: 319 loss: 6.26756264e-06
Iter: 320 loss: 6.29217266e-06
Iter: 321 loss: 6.26082328e-06
Iter: 322 loss: 6.24824042e-06
Iter: 323 loss: 6.31864077e-06
Iter: 324 loss: 6.24638778e-06
Iter: 325 loss: 6.23284814e-06
Iter: 326 loss: 6.24817585e-06
Iter: 327 loss: 6.22550942e-06
Iter: 328 loss: 6.21391655e-06
Iter: 329 loss: 6.31761486e-06
Iter: 330 loss: 6.21344952e-06
Iter: 331 loss: 6.20412766e-06
Iter: 332 loss: 6.21154777e-06
Iter: 333 loss: 6.19874754e-06
Iter: 334 loss: 6.18752938e-06
Iter: 335 loss: 6.26965902e-06
Iter: 336 loss: 6.18676677e-06
Iter: 337 loss: 6.17780188e-06
Iter: 338 loss: 6.24978111e-06
Iter: 339 loss: 6.17722344e-06
Iter: 340 loss: 6.17229944e-06
Iter: 341 loss: 6.16510715e-06
Iter: 342 loss: 6.16477064e-06
Iter: 343 loss: 6.15466752e-06
Iter: 344 loss: 6.15729641e-06
Iter: 345 loss: 6.14731289e-06
Iter: 346 loss: 6.13509201e-06
Iter: 347 loss: 6.2081308e-06
Iter: 348 loss: 6.13354632e-06
Iter: 349 loss: 6.12243366e-06
Iter: 350 loss: 6.12256508e-06
Iter: 351 loss: 6.11354335e-06
Iter: 352 loss: 6.10107782e-06
Iter: 353 loss: 6.22086827e-06
Iter: 354 loss: 6.10059669e-06
Iter: 355 loss: 6.09174185e-06
Iter: 356 loss: 6.0879097e-06
Iter: 357 loss: 6.08323e-06
Iter: 358 loss: 6.06737285e-06
Iter: 359 loss: 6.16372927e-06
Iter: 360 loss: 6.06543972e-06
Iter: 361 loss: 6.05624246e-06
Iter: 362 loss: 6.09650942e-06
Iter: 363 loss: 6.05451442e-06
Iter: 364 loss: 6.04520392e-06
Iter: 365 loss: 6.05648e-06
Iter: 366 loss: 6.04042498e-06
Iter: 367 loss: 6.03268927e-06
Iter: 368 loss: 6.1323708e-06
Iter: 369 loss: 6.0326247e-06
Iter: 370 loss: 6.02731643e-06
Iter: 371 loss: 6.06836647e-06
Iter: 372 loss: 6.02697492e-06
Iter: 373 loss: 6.02287719e-06
Iter: 374 loss: 6.01465945e-06
Iter: 375 loss: 6.1600249e-06
Iter: 376 loss: 6.01440206e-06
Iter: 377 loss: 6.00350768e-06
Iter: 378 loss: 6.01904685e-06
Iter: 379 loss: 5.99820396e-06
Iter: 380 loss: 5.98949418e-06
Iter: 381 loss: 6.04710567e-06
Iter: 382 loss: 5.98859924e-06
Iter: 383 loss: 5.98007728e-06
Iter: 384 loss: 5.97747567e-06
Iter: 385 loss: 5.9723543e-06
Iter: 386 loss: 5.96180689e-06
Iter: 387 loss: 6.04558591e-06
Iter: 388 loss: 5.96119025e-06
Iter: 389 loss: 5.9525164e-06
Iter: 390 loss: 5.94916764e-06
Iter: 391 loss: 5.94436096e-06
Iter: 392 loss: 5.93285313e-06
Iter: 393 loss: 6.07554557e-06
Iter: 394 loss: 5.93285768e-06
Iter: 395 loss: 5.92562e-06
Iter: 396 loss: 5.92873539e-06
Iter: 397 loss: 5.92075594e-06
Iter: 398 loss: 5.90992977e-06
Iter: 399 loss: 5.95413076e-06
Iter: 400 loss: 5.90754462e-06
Iter: 401 loss: 5.90074e-06
Iter: 402 loss: 5.95822348e-06
Iter: 403 loss: 5.90040509e-06
Iter: 404 loss: 5.89495312e-06
Iter: 405 loss: 5.9332051e-06
Iter: 406 loss: 5.89436513e-06
Iter: 407 loss: 5.8898504e-06
Iter: 408 loss: 5.88151488e-06
Iter: 409 loss: 5.88152398e-06
Iter: 410 loss: 5.87233808e-06
Iter: 411 loss: 5.89430692e-06
Iter: 412 loss: 5.86900205e-06
Iter: 413 loss: 5.86032911e-06
Iter: 414 loss: 5.87225031e-06
Iter: 415 loss: 5.85584348e-06
Iter: 416 loss: 5.84550344e-06
Iter: 417 loss: 5.89203955e-06
Iter: 418 loss: 5.84356576e-06
Iter: 419 loss: 5.83599149e-06
Iter: 420 loss: 5.84923873e-06
Iter: 421 loss: 5.83267501e-06
Iter: 422 loss: 5.82244138e-06
Iter: 423 loss: 5.83318251e-06
Iter: 424 loss: 5.81679251e-06
Iter: 425 loss: 5.80767846e-06
Iter: 426 loss: 5.89380852e-06
Iter: 427 loss: 5.80733058e-06
Iter: 428 loss: 5.79905736e-06
Iter: 429 loss: 5.80244614e-06
Iter: 430 loss: 5.79345078e-06
Iter: 431 loss: 5.78510617e-06
Iter: 432 loss: 5.87021304e-06
Iter: 433 loss: 5.78491517e-06
Iter: 434 loss: 5.77942046e-06
Iter: 435 loss: 5.79795369e-06
Iter: 436 loss: 5.77794526e-06
Iter: 437 loss: 5.77224728e-06
Iter: 438 loss: 5.81161521e-06
Iter: 439 loss: 5.77178389e-06
Iter: 440 loss: 5.76693674e-06
Iter: 441 loss: 5.76420962e-06
Iter: 442 loss: 5.76199318e-06
Iter: 443 loss: 5.75602098e-06
Iter: 444 loss: 5.75635067e-06
Iter: 445 loss: 5.75139939e-06
Iter: 446 loss: 5.74280875e-06
Iter: 447 loss: 5.76716684e-06
Iter: 448 loss: 5.7401985e-06
Iter: 449 loss: 5.73305715e-06
Iter: 450 loss: 5.76580169e-06
Iter: 451 loss: 5.73184388e-06
Iter: 452 loss: 5.72427462e-06
Iter: 453 loss: 5.7230759e-06
Iter: 454 loss: 5.71789042e-06
Iter: 455 loss: 5.70869406e-06
Iter: 456 loss: 5.78575964e-06
Iter: 457 loss: 5.70822e-06
Iter: 458 loss: 5.70154634e-06
Iter: 459 loss: 5.70869543e-06
Iter: 460 loss: 5.69801296e-06
Iter: 461 loss: 5.68837368e-06
Iter: 462 loss: 5.71649525e-06
Iter: 463 loss: 5.68530231e-06
Iter: 464 loss: 5.67940333e-06
Iter: 465 loss: 5.73623447e-06
Iter: 466 loss: 5.6791032e-06
Iter: 467 loss: 5.67467805e-06
Iter: 468 loss: 5.68254291e-06
Iter: 469 loss: 5.67257484e-06
Iter: 470 loss: 5.66793e-06
Iter: 471 loss: 5.72310864e-06
Iter: 472 loss: 5.66788549e-06
Iter: 473 loss: 5.66448216e-06
Iter: 474 loss: 5.66318613e-06
Iter: 475 loss: 5.66143353e-06
Iter: 476 loss: 5.65705614e-06
Iter: 477 loss: 5.65319e-06
Iter: 478 loss: 5.65208302e-06
Iter: 479 loss: 5.64425409e-06
Iter: 480 loss: 5.6707795e-06
Iter: 481 loss: 5.64212041e-06
Iter: 482 loss: 5.63602225e-06
Iter: 483 loss: 5.65872733e-06
Iter: 484 loss: 5.6344461e-06
Iter: 485 loss: 5.62734931e-06
Iter: 486 loss: 5.62900368e-06
Iter: 487 loss: 5.62229798e-06
Iter: 488 loss: 5.61417392e-06
Iter: 489 loss: 5.66500876e-06
Iter: 490 loss: 5.61321349e-06
Iter: 491 loss: 5.60595026e-06
Iter: 492 loss: 5.61124034e-06
Iter: 493 loss: 5.60147873e-06
Iter: 494 loss: 5.59322871e-06
Iter: 495 loss: 5.67043753e-06
Iter: 496 loss: 5.59281762e-06
Iter: 497 loss: 5.588156e-06
Iter: 498 loss: 5.59780756e-06
Iter: 499 loss: 5.5861874e-06
Iter: 500 loss: 5.58035072e-06
Iter: 501 loss: 5.60163335e-06
Iter: 502 loss: 5.57889689e-06
Iter: 503 loss: 5.57445856e-06
Iter: 504 loss: 5.63184858e-06
Iter: 505 loss: 5.57450085e-06
Iter: 506 loss: 5.57119074e-06
Iter: 507 loss: 5.57157318e-06
Iter: 508 loss: 5.56854729e-06
Iter: 509 loss: 5.56500527e-06
Iter: 510 loss: 5.55987208e-06
Iter: 511 loss: 5.55960241e-06
Iter: 512 loss: 5.55217775e-06
Iter: 513 loss: 5.58454849e-06
Iter: 514 loss: 5.55068254e-06
Iter: 515 loss: 5.54439612e-06
Iter: 516 loss: 5.55494444e-06
Iter: 517 loss: 5.54172084e-06
Iter: 518 loss: 5.5336568e-06
Iter: 519 loss: 5.55372026e-06
Iter: 520 loss: 5.53085556e-06
Iter: 521 loss: 5.52390475e-06
Iter: 522 loss: 5.54464805e-06
Iter: 523 loss: 5.52177926e-06
Iter: 524 loss: 5.51389712e-06
Iter: 525 loss: 5.52654501e-06
Iter: 526 loss: 5.51040102e-06
Iter: 527 loss: 5.50306595e-06
Iter: 528 loss: 5.5716e-06
Iter: 529 loss: 5.50274081e-06
Iter: 530 loss: 5.49776087e-06
Iter: 531 loss: 5.50658933e-06
Iter: 532 loss: 5.49570677e-06
Iter: 533 loss: 5.49033757e-06
Iter: 534 loss: 5.51936864e-06
Iter: 535 loss: 5.48954404e-06
Iter: 536 loss: 5.48589e-06
Iter: 537 loss: 5.53238942e-06
Iter: 538 loss: 5.48592334e-06
Iter: 539 loss: 5.48304251e-06
Iter: 540 loss: 5.48141816e-06
Iter: 541 loss: 5.48006801e-06
Iter: 542 loss: 5.47580976e-06
Iter: 543 loss: 5.47313493e-06
Iter: 544 loss: 5.47135369e-06
Iter: 545 loss: 5.46553e-06
Iter: 546 loss: 5.48729531e-06
Iter: 547 loss: 5.46411502e-06
Iter: 548 loss: 5.45797593e-06
Iter: 549 loss: 5.46175397e-06
Iter: 550 loss: 5.45395687e-06
Iter: 551 loss: 5.44690465e-06
Iter: 552 loss: 5.49637434e-06
Iter: 553 loss: 5.44622799e-06
Iter: 554 loss: 5.44058e-06
Iter: 555 loss: 5.44276e-06
Iter: 556 loss: 5.43654187e-06
Iter: 557 loss: 5.429255e-06
Iter: 558 loss: 5.46716819e-06
Iter: 559 loss: 5.42798e-06
Iter: 560 loss: 5.42313e-06
Iter: 561 loss: 5.45534294e-06
Iter: 562 loss: 5.42261841e-06
Iter: 563 loss: 5.41809e-06
Iter: 564 loss: 5.41855843e-06
Iter: 565 loss: 5.41465124e-06
Iter: 566 loss: 5.40945621e-06
Iter: 567 loss: 5.47630043e-06
Iter: 568 loss: 5.40941164e-06
Iter: 569 loss: 5.40673227e-06
Iter: 570 loss: 5.43083297e-06
Iter: 571 loss: 5.40665587e-06
Iter: 572 loss: 5.40415567e-06
Iter: 573 loss: 5.40262045e-06
Iter: 574 loss: 5.40153042e-06
Iter: 575 loss: 5.39767188e-06
Iter: 576 loss: 5.39811481e-06
Iter: 577 loss: 5.39488428e-06
Iter: 578 loss: 5.39040639e-06
Iter: 579 loss: 5.39803e-06
Iter: 580 loss: 5.38869381e-06
Iter: 581 loss: 5.38303811e-06
Iter: 582 loss: 5.39221446e-06
Iter: 583 loss: 5.38037693e-06
Iter: 584 loss: 5.3750623e-06
Iter: 585 loss: 5.40520614e-06
Iter: 586 loss: 5.37451388e-06
Iter: 587 loss: 5.36954394e-06
Iter: 588 loss: 5.36914e-06
Iter: 589 loss: 5.3654303e-06
Iter: 590 loss: 5.35926392e-06
Iter: 591 loss: 5.40801966e-06
Iter: 592 loss: 5.35879872e-06
Iter: 593 loss: 5.35448589e-06
Iter: 594 loss: 5.36529569e-06
Iter: 595 loss: 5.35289246e-06
Iter: 596 loss: 5.34742412e-06
Iter: 597 loss: 5.35555364e-06
Iter: 598 loss: 5.34493165e-06
Iter: 599 loss: 5.34080618e-06
Iter: 600 loss: 5.39618077e-06
Iter: 601 loss: 5.340808e-06
Iter: 602 loss: 5.33823641e-06
Iter: 603 loss: 5.35903609e-06
Iter: 604 loss: 5.33804359e-06
Iter: 605 loss: 5.3357453e-06
Iter: 606 loss: 5.33361435e-06
Iter: 607 loss: 5.3329818e-06
Iter: 608 loss: 5.32911963e-06
Iter: 609 loss: 5.33324737e-06
Iter: 610 loss: 5.32711692e-06
Iter: 611 loss: 5.32351351e-06
Iter: 612 loss: 5.32540116e-06
Iter: 613 loss: 5.32126751e-06
Iter: 614 loss: 5.31571095e-06
Iter: 615 loss: 5.32747435e-06
Iter: 616 loss: 5.31358637e-06
Iter: 617 loss: 5.3086178e-06
Iter: 618 loss: 5.33028651e-06
Iter: 619 loss: 5.30764919e-06
Iter: 620 loss: 5.30220586e-06
Iter: 621 loss: 5.30310353e-06
Iter: 622 loss: 5.29816452e-06
Iter: 623 loss: 5.29221506e-06
Iter: 624 loss: 5.33944194e-06
Iter: 625 loss: 5.29184399e-06
Iter: 626 loss: 5.28722239e-06
Iter: 627 loss: 5.29646695e-06
Iter: 628 loss: 5.28530472e-06
Iter: 629 loss: 5.27956581e-06
Iter: 630 loss: 5.29458794e-06
Iter: 631 loss: 5.27776137e-06
Iter: 632 loss: 5.27402517e-06
Iter: 633 loss: 5.32013746e-06
Iter: 634 loss: 5.27390239e-06
Iter: 635 loss: 5.27150314e-06
Iter: 636 loss: 5.28590726e-06
Iter: 637 loss: 5.27112024e-06
Iter: 638 loss: 5.26862914e-06
Iter: 639 loss: 5.26824942e-06
Iter: 640 loss: 5.26642134e-06
Iter: 641 loss: 5.26310123e-06
Iter: 642 loss: 5.26585154e-06
Iter: 643 loss: 5.26124768e-06
Iter: 644 loss: 5.25768792e-06
Iter: 645 loss: 5.25673659e-06
Iter: 646 loss: 5.25452288e-06
Iter: 647 loss: 5.24870711e-06
Iter: 648 loss: 5.27559e-06
Iter: 649 loss: 5.24769348e-06
Iter: 650 loss: 5.24352572e-06
Iter: 651 loss: 5.25576252e-06
Iter: 652 loss: 5.24221377e-06
Iter: 653 loss: 5.23707058e-06
Iter: 654 loss: 5.24005372e-06
Iter: 655 loss: 5.23381095e-06
Iter: 656 loss: 5.22880782e-06
Iter: 657 loss: 5.26540771e-06
Iter: 658 loss: 5.22827577e-06
Iter: 659 loss: 5.22381833e-06
Iter: 660 loss: 5.22867595e-06
Iter: 661 loss: 5.22144092e-06
Iter: 662 loss: 5.21580751e-06
Iter: 663 loss: 5.2451287e-06
Iter: 664 loss: 5.2149062e-06
Iter: 665 loss: 5.21144602e-06
Iter: 666 loss: 5.23360723e-06
Iter: 667 loss: 5.2110081e-06
Iter: 668 loss: 5.2081914e-06
Iter: 669 loss: 5.22917071e-06
Iter: 670 loss: 5.20788944e-06
Iter: 671 loss: 5.20520734e-06
Iter: 672 loss: 5.20572394e-06
Iter: 673 loss: 5.20326739e-06
Iter: 674 loss: 5.20028607e-06
Iter: 675 loss: 5.20355024e-06
Iter: 676 loss: 5.19871583e-06
Iter: 677 loss: 5.19533705e-06
Iter: 678 loss: 5.19363903e-06
Iter: 679 loss: 5.1923239e-06
Iter: 680 loss: 5.18722572e-06
Iter: 681 loss: 5.21884522e-06
Iter: 682 loss: 5.18656452e-06
Iter: 683 loss: 5.18290835e-06
Iter: 684 loss: 5.18928437e-06
Iter: 685 loss: 5.18141042e-06
Iter: 686 loss: 5.17650824e-06
Iter: 687 loss: 5.18334764e-06
Iter: 688 loss: 5.17420676e-06
Iter: 689 loss: 5.16945374e-06
Iter: 690 loss: 5.189288e-06
Iter: 691 loss: 5.16833279e-06
Iter: 692 loss: 5.16347609e-06
Iter: 693 loss: 5.17092303e-06
Iter: 694 loss: 5.16115097e-06
Iter: 695 loss: 5.15569263e-06
Iter: 696 loss: 5.18992374e-06
Iter: 697 loss: 5.15529064e-06
Iter: 698 loss: 5.15168722e-06
Iter: 699 loss: 5.17274566e-06
Iter: 700 loss: 5.15136708e-06
Iter: 701 loss: 5.14874182e-06
Iter: 702 loss: 5.16528917e-06
Iter: 703 loss: 5.1483903e-06
Iter: 704 loss: 5.1456027e-06
Iter: 705 loss: 5.14857675e-06
Iter: 706 loss: 5.14407293e-06
Iter: 707 loss: 5.14150179e-06
Iter: 708 loss: 5.14193562e-06
Iter: 709 loss: 5.13968871e-06
Iter: 710 loss: 5.13603482e-06
Iter: 711 loss: 5.13380064e-06
Iter: 712 loss: 5.1323932e-06
Iter: 713 loss: 5.12764564e-06
Iter: 714 loss: 5.16895852e-06
Iter: 715 loss: 5.12723682e-06
Iter: 716 loss: 5.1237e-06
Iter: 717 loss: 5.12615725e-06
Iter: 718 loss: 5.12160068e-06
Iter: 719 loss: 5.11631561e-06
Iter: 720 loss: 5.12934548e-06
Iter: 721 loss: 5.11442795e-06
Iter: 722 loss: 5.10971222e-06
Iter: 723 loss: 5.12530823e-06
Iter: 724 loss: 5.10852942e-06
Iter: 725 loss: 5.10329755e-06
Iter: 726 loss: 5.11196322e-06
Iter: 727 loss: 5.101037e-06
Iter: 728 loss: 5.09589336e-06
Iter: 729 loss: 5.13858595e-06
Iter: 730 loss: 5.09572419e-06
Iter: 731 loss: 5.09262554e-06
Iter: 732 loss: 5.10072277e-06
Iter: 733 loss: 5.09154279e-06
Iter: 734 loss: 5.08835501e-06
Iter: 735 loss: 5.11840426e-06
Iter: 736 loss: 5.08812809e-06
Iter: 737 loss: 5.08555058e-06
Iter: 738 loss: 5.0888857e-06
Iter: 739 loss: 5.08406447e-06
Iter: 740 loss: 5.08162611e-06
Iter: 741 loss: 5.08099265e-06
Iter: 742 loss: 5.0794e-06
Iter: 743 loss: 5.07544246e-06
Iter: 744 loss: 5.07468849e-06
Iter: 745 loss: 5.07208051e-06
Iter: 746 loss: 5.0675153e-06
Iter: 747 loss: 5.09996062e-06
Iter: 748 loss: 5.06710603e-06
Iter: 749 loss: 5.06302058e-06
Iter: 750 loss: 5.06507968e-06
Iter: 751 loss: 5.06040851e-06
Iter: 752 loss: 5.05509342e-06
Iter: 753 loss: 5.08083576e-06
Iter: 754 loss: 5.05416119e-06
Iter: 755 loss: 5.05005437e-06
Iter: 756 loss: 5.05308071e-06
Iter: 757 loss: 5.04741e-06
Iter: 758 loss: 5.04138552e-06
Iter: 759 loss: 5.06784272e-06
Iter: 760 loss: 5.04026957e-06
Iter: 761 loss: 5.03596766e-06
Iter: 762 loss: 5.06169863e-06
Iter: 763 loss: 5.03556657e-06
Iter: 764 loss: 5.03204956e-06
Iter: 765 loss: 5.04317813e-06
Iter: 766 loss: 5.03121919e-06
Iter: 767 loss: 5.02841067e-06
Iter: 768 loss: 5.05839807e-06
Iter: 769 loss: 5.02826333e-06
Iter: 770 loss: 5.0257886e-06
Iter: 771 loss: 5.02945841e-06
Iter: 772 loss: 5.02475e-06
Iter: 773 loss: 5.02244256e-06
Iter: 774 loss: 5.02038893e-06
Iter: 775 loss: 5.01985915e-06
Iter: 776 loss: 5.01569139e-06
Iter: 777 loss: 5.01893373e-06
Iter: 778 loss: 5.01310114e-06
Iter: 779 loss: 5.00927035e-06
Iter: 780 loss: 5.0298122e-06
Iter: 781 loss: 5.00860551e-06
Iter: 782 loss: 5.00465148e-06
Iter: 783 loss: 5.00776e-06
Iter: 784 loss: 5.00210172e-06
Iter: 785 loss: 4.99755424e-06
Iter: 786 loss: 5.02131934e-06
Iter: 787 loss: 4.99678663e-06
Iter: 788 loss: 4.99261523e-06
Iter: 789 loss: 4.99501857e-06
Iter: 790 loss: 4.98991903e-06
Iter: 791 loss: 4.98475129e-06
Iter: 792 loss: 5.01796831e-06
Iter: 793 loss: 4.98420832e-06
Iter: 794 loss: 4.98069585e-06
Iter: 795 loss: 4.99646785e-06
Iter: 796 loss: 4.98001918e-06
Iter: 797 loss: 4.97683595e-06
Iter: 798 loss: 4.98408554e-06
Iter: 799 loss: 4.97560541e-06
Iter: 800 loss: 4.97310066e-06
Iter: 801 loss: 4.9730952e-06
Iter: 802 loss: 4.97115707e-06
Iter: 803 loss: 4.97298697e-06
Iter: 804 loss: 4.97002065e-06
Iter: 805 loss: 4.96770826e-06
Iter: 806 loss: 4.96568e-06
Iter: 807 loss: 4.96508073e-06
Iter: 808 loss: 4.96119083e-06
Iter: 809 loss: 4.96924167e-06
Iter: 810 loss: 4.95986842e-06
Iter: 811 loss: 4.9565565e-06
Iter: 812 loss: 4.9625628e-06
Iter: 813 loss: 4.95517179e-06
Iter: 814 loss: 4.95076529e-06
Iter: 815 loss: 4.95847507e-06
Iter: 816 loss: 4.94879623e-06
Iter: 817 loss: 4.94483538e-06
Iter: 818 loss: 4.96677194e-06
Iter: 819 loss: 4.94421465e-06
Iter: 820 loss: 4.94035612e-06
Iter: 821 loss: 4.93967536e-06
Iter: 822 loss: 4.93708285e-06
Iter: 823 loss: 4.93239531e-06
Iter: 824 loss: 4.98311692e-06
Iter: 825 loss: 4.93244443e-06
Iter: 826 loss: 4.92926165e-06
Iter: 827 loss: 4.93473544e-06
Iter: 828 loss: 4.92788604e-06
Iter: 829 loss: 4.92438721e-06
Iter: 830 loss: 4.93939797e-06
Iter: 831 loss: 4.92354229e-06
Iter: 832 loss: 4.92106574e-06
Iter: 833 loss: 4.95592394e-06
Iter: 834 loss: 4.92107756e-06
Iter: 835 loss: 4.91921583e-06
Iter: 836 loss: 4.92179424e-06
Iter: 837 loss: 4.91828905e-06
Iter: 838 loss: 4.91611627e-06
Iter: 839 loss: 4.9135474e-06
Iter: 840 loss: 4.91334913e-06
Iter: 841 loss: 4.90936372e-06
Iter: 842 loss: 4.92020035e-06
Iter: 843 loss: 4.90821276e-06
Iter: 844 loss: 4.90491311e-06
Iter: 845 loss: 4.90839102e-06
Iter: 846 loss: 4.90312368e-06
Iter: 847 loss: 4.89866079e-06
Iter: 848 loss: 4.91356695e-06
Iter: 849 loss: 4.89755666e-06
Iter: 850 loss: 4.89386457e-06
Iter: 851 loss: 4.90495131e-06
Iter: 852 loss: 4.8926504e-06
Iter: 853 loss: 4.88838577e-06
Iter: 854 loss: 4.8935176e-06
Iter: 855 loss: 4.88622845e-06
Iter: 856 loss: 4.88258411e-06
Iter: 857 loss: 4.91124592e-06
Iter: 858 loss: 4.88238129e-06
Iter: 859 loss: 4.87915077e-06
Iter: 860 loss: 4.88297792e-06
Iter: 861 loss: 4.87753732e-06
Iter: 862 loss: 4.87360285e-06
Iter: 863 loss: 4.89055265e-06
Iter: 864 loss: 4.8728607e-06
Iter: 865 loss: 4.87035231e-06
Iter: 866 loss: 4.87040097e-06
Iter: 867 loss: 4.86855424e-06
Iter: 868 loss: 4.8695083e-06
Iter: 869 loss: 4.86740282e-06
Iter: 870 loss: 4.86506269e-06
Iter: 871 loss: 4.86225599e-06
Iter: 872 loss: 4.8619977e-06
Iter: 873 loss: 4.85810551e-06
Iter: 874 loss: 4.87431726e-06
Iter: 875 loss: 4.85719147e-06
Iter: 876 loss: 4.85409237e-06
Iter: 877 loss: 4.85493956e-06
Iter: 878 loss: 4.85195369e-06
Iter: 879 loss: 4.84751263e-06
Iter: 880 loss: 4.8677548e-06
Iter: 881 loss: 4.84667362e-06
Iter: 882 loss: 4.84303382e-06
Iter: 883 loss: 4.85316377e-06
Iter: 884 loss: 4.84182965e-06
Iter: 885 loss: 4.83783742e-06
Iter: 886 loss: 4.84284e-06
Iter: 887 loss: 4.83602071e-06
Iter: 888 loss: 4.83219264e-06
Iter: 889 loss: 4.85999135e-06
Iter: 890 loss: 4.83195572e-06
Iter: 891 loss: 4.82881569e-06
Iter: 892 loss: 4.83104031e-06
Iter: 893 loss: 4.82682663e-06
Iter: 894 loss: 4.822959e-06
Iter: 895 loss: 4.85084729e-06
Iter: 896 loss: 4.82257747e-06
Iter: 897 loss: 4.82044061e-06
Iter: 898 loss: 4.84848078e-06
Iter: 899 loss: 4.82050928e-06
Iter: 900 loss: 4.81862662e-06
Iter: 901 loss: 4.82047835e-06
Iter: 902 loss: 4.81761026e-06
Iter: 903 loss: 4.81531652e-06
Iter: 904 loss: 4.81330881e-06
Iter: 905 loss: 4.81284633e-06
Iter: 906 loss: 4.80972267e-06
Iter: 907 loss: 4.82182577e-06
Iter: 908 loss: 4.80886047e-06
Iter: 909 loss: 4.80594235e-06
Iter: 910 loss: 4.80468179e-06
Iter: 911 loss: 4.80304425e-06
Iter: 912 loss: 4.79879827e-06
Iter: 913 loss: 4.82925589e-06
Iter: 914 loss: 4.79838764e-06
Iter: 915 loss: 4.79509617e-06
Iter: 916 loss: 4.79904338e-06
Iter: 917 loss: 4.79337587e-06
Iter: 918 loss: 4.78910897e-06
Iter: 919 loss: 4.8025413e-06
Iter: 920 loss: 4.78774837e-06
Iter: 921 loss: 4.78454831e-06
Iter: 922 loss: 4.79834944e-06
Iter: 923 loss: 4.78388483e-06
Iter: 924 loss: 4.7805388e-06
Iter: 925 loss: 4.78713e-06
Iter: 926 loss: 4.77909225e-06
Iter: 927 loss: 4.77581943e-06
Iter: 928 loss: 4.79800474e-06
Iter: 929 loss: 4.77544199e-06
Iter: 930 loss: 4.77384856e-06
Iter: 931 loss: 4.77382946e-06
Iter: 932 loss: 4.77234971e-06
Iter: 933 loss: 4.77252343e-06
Iter: 934 loss: 4.77123e-06
Iter: 935 loss: 4.76898e-06
Iter: 936 loss: 4.76784498e-06
Iter: 937 loss: 4.7667636e-06
Iter: 938 loss: 4.76410514e-06
Iter: 939 loss: 4.77161666e-06
Iter: 940 loss: 4.76325931e-06
Iter: 941 loss: 4.760308e-06
Iter: 942 loss: 4.75925208e-06
Iter: 943 loss: 4.7575395e-06
Iter: 944 loss: 4.75343404e-06
Iter: 945 loss: 4.78311904e-06
Iter: 946 loss: 4.75318939e-06
Iter: 947 loss: 4.74971148e-06
Iter: 948 loss: 4.75442175e-06
Iter: 949 loss: 4.748219e-06
Iter: 950 loss: 4.7445692e-06
Iter: 951 loss: 4.7591052e-06
Iter: 952 loss: 4.74373428e-06
Iter: 953 loss: 4.74059289e-06
Iter: 954 loss: 4.74788067e-06
Iter: 955 loss: 4.73953605e-06
Iter: 956 loss: 4.73603086e-06
Iter: 957 loss: 4.74718081e-06
Iter: 958 loss: 4.73503769e-06
Iter: 959 loss: 4.7321596e-06
Iter: 960 loss: 4.75250135e-06
Iter: 961 loss: 4.73186856e-06
Iter: 962 loss: 4.73007094e-06
Iter: 963 loss: 4.74389162e-06
Iter: 964 loss: 4.72979e-06
Iter: 965 loss: 4.72779266e-06
Iter: 966 loss: 4.73056116e-06
Iter: 967 loss: 4.72678812e-06
Iter: 968 loss: 4.72477905e-06
Iter: 969 loss: 4.7246549e-06
Iter: 970 loss: 4.7229687e-06
Iter: 971 loss: 4.72060583e-06
Iter: 972 loss: 4.72299598e-06
Iter: 973 loss: 4.71915e-06
Iter: 974 loss: 4.71576641e-06
Iter: 975 loss: 4.71827661e-06
Iter: 976 loss: 4.71362e-06
Iter: 977 loss: 4.7098556e-06
Iter: 978 loss: 4.72989e-06
Iter: 979 loss: 4.70945906e-06
Iter: 980 loss: 4.70601663e-06
Iter: 981 loss: 4.71004205e-06
Iter: 982 loss: 4.70417e-06
Iter: 983 loss: 4.70085888e-06
Iter: 984 loss: 4.72109423e-06
Iter: 985 loss: 4.70045507e-06
Iter: 986 loss: 4.69740098e-06
Iter: 987 loss: 4.69808401e-06
Iter: 988 loss: 4.69524821e-06
Iter: 989 loss: 4.69104907e-06
Iter: 990 loss: 4.72060901e-06
Iter: 991 loss: 4.69069892e-06
Iter: 992 loss: 4.68800681e-06
Iter: 993 loss: 4.69799443e-06
Iter: 994 loss: 4.68719099e-06
Iter: 995 loss: 4.68498865e-06
Iter: 996 loss: 4.70996793e-06
Iter: 997 loss: 4.68497819e-06
Iter: 998 loss: 4.68292774e-06
Iter: 999 loss: 4.6865307e-06
Iter: 1000 loss: 4.68217604e-06
Iter: 1001 loss: 4.68012695e-06
Iter: 1002 loss: 4.68040889e-06
Iter: 1003 loss: 4.67859e-06
Iter: 1004 loss: 4.67611062e-06
Iter: 1005 loss: 4.67596283e-06
Iter: 1006 loss: 4.67429027e-06
Iter: 1007 loss: 4.67059454e-06
Iter: 1008 loss: 4.68199414e-06
Iter: 1009 loss: 4.66955089e-06
Iter: 1010 loss: 4.66669e-06
Iter: 1011 loss: 4.67316477e-06
Iter: 1012 loss: 4.66540587e-06
Iter: 1013 loss: 4.66189431e-06
Iter: 1014 loss: 4.67240261e-06
Iter: 1015 loss: 4.66082929e-06
Iter: 1016 loss: 4.65789071e-06
Iter: 1017 loss: 4.66758e-06
Iter: 1018 loss: 4.65722269e-06
Iter: 1019 loss: 4.65402945e-06
Iter: 1020 loss: 4.65569428e-06
Iter: 1021 loss: 4.65182939e-06
Iter: 1022 loss: 4.648301e-06
Iter: 1023 loss: 4.68204144e-06
Iter: 1024 loss: 4.64803043e-06
Iter: 1025 loss: 4.64567438e-06
Iter: 1026 loss: 4.65325047e-06
Iter: 1027 loss: 4.6449718e-06
Iter: 1028 loss: 4.64279356e-06
Iter: 1029 loss: 4.6562518e-06
Iter: 1030 loss: 4.64257482e-06
Iter: 1031 loss: 4.64020832e-06
Iter: 1032 loss: 4.64871027e-06
Iter: 1033 loss: 4.63975084e-06
Iter: 1034 loss: 4.63804099e-06
Iter: 1035 loss: 4.63767947e-06
Iter: 1036 loss: 4.63670585e-06
Iter: 1037 loss: 4.63428387e-06
Iter: 1038 loss: 4.63371407e-06
Iter: 1039 loss: 4.63220158e-06
Iter: 1040 loss: 4.62886055e-06
Iter: 1041 loss: 4.64352797e-06
Iter: 1042 loss: 4.62815569e-06
Iter: 1043 loss: 4.62539174e-06
Iter: 1044 loss: 4.62863227e-06
Iter: 1045 loss: 4.62401613e-06
Iter: 1046 loss: 4.62055323e-06
Iter: 1047 loss: 4.63563e-06
Iter: 1048 loss: 4.61980198e-06
Iter: 1049 loss: 4.61723675e-06
Iter: 1050 loss: 4.62376556e-06
Iter: 1051 loss: 4.61625268e-06
Iter: 1052 loss: 4.61311902e-06
Iter: 1053 loss: 4.61453192e-06
Iter: 1054 loss: 4.61090349e-06
Iter: 1055 loss: 4.60754791e-06
Iter: 1056 loss: 4.64823961e-06
Iter: 1057 loss: 4.60747651e-06
Iter: 1058 loss: 4.60529736e-06
Iter: 1059 loss: 4.60778665e-06
Iter: 1060 loss: 4.6041705e-06
Iter: 1061 loss: 4.60172168e-06
Iter: 1062 loss: 4.63085598e-06
Iter: 1063 loss: 4.60163028e-06
Iter: 1064 loss: 4.59969851e-06
Iter: 1065 loss: 4.60628053e-06
Iter: 1066 loss: 4.59918556e-06
Iter: 1067 loss: 4.59745934e-06
Iter: 1068 loss: 4.5973693e-06
Iter: 1069 loss: 4.59625608e-06
Iter: 1070 loss: 4.59404828e-06
Iter: 1071 loss: 4.5930492e-06
Iter: 1072 loss: 4.59201965e-06
Iter: 1073 loss: 4.58888462e-06
Iter: 1074 loss: 4.60545107e-06
Iter: 1075 loss: 4.58852128e-06
Iter: 1076 loss: 4.58599879e-06
Iter: 1077 loss: 4.5863726e-06
Iter: 1078 loss: 4.58410386e-06
Iter: 1079 loss: 4.58060231e-06
Iter: 1080 loss: 4.60351657e-06
Iter: 1081 loss: 4.58020077e-06
Iter: 1082 loss: 4.57759097e-06
Iter: 1083 loss: 4.57955275e-06
Iter: 1084 loss: 4.57602209e-06
Iter: 1085 loss: 4.57205715e-06
Iter: 1086 loss: 4.57783153e-06
Iter: 1087 loss: 4.57016267e-06
Iter: 1088 loss: 4.56685393e-06
Iter: 1089 loss: 4.60453248e-06
Iter: 1090 loss: 4.56682847e-06
Iter: 1091 loss: 4.56457474e-06
Iter: 1092 loss: 4.56943417e-06
Iter: 1093 loss: 4.56361295e-06
Iter: 1094 loss: 4.56144289e-06
Iter: 1095 loss: 4.57845545e-06
Iter: 1096 loss: 4.56114049e-06
Iter: 1097 loss: 4.55932695e-06
Iter: 1098 loss: 4.57136093e-06
Iter: 1099 loss: 4.55904046e-06
Iter: 1100 loss: 4.55781719e-06
Iter: 1101 loss: 4.55681857e-06
Iter: 1102 loss: 4.55653e-06
Iter: 1103 loss: 4.5543643e-06
Iter: 1104 loss: 4.55292866e-06
Iter: 1105 loss: 4.55205645e-06
Iter: 1106 loss: 4.54887231e-06
Iter: 1107 loss: 4.56736416e-06
Iter: 1108 loss: 4.54840301e-06
Iter: 1109 loss: 4.54567726e-06
Iter: 1110 loss: 4.54659403e-06
Iter: 1111 loss: 4.54373094e-06
Iter: 1112 loss: 4.54032215e-06
Iter: 1113 loss: 4.56343651e-06
Iter: 1114 loss: 4.54005567e-06
Iter: 1115 loss: 4.53722578e-06
Iter: 1116 loss: 4.53838538e-06
Iter: 1117 loss: 4.53533e-06
Iter: 1118 loss: 4.53134771e-06
Iter: 1119 loss: 4.54215024e-06
Iter: 1120 loss: 4.53001076e-06
Iter: 1121 loss: 4.52723725e-06
Iter: 1122 loss: 4.55833833e-06
Iter: 1123 loss: 4.52716449e-06
Iter: 1124 loss: 4.5249767e-06
Iter: 1125 loss: 4.5259967e-06
Iter: 1126 loss: 4.52354e-06
Iter: 1127 loss: 4.52133236e-06
Iter: 1128 loss: 4.55393774e-06
Iter: 1129 loss: 4.52129098e-06
Iter: 1130 loss: 4.51978212e-06
Iter: 1131 loss: 4.52840413e-06
Iter: 1132 loss: 4.5195693e-06
Iter: 1133 loss: 4.51846336e-06
Iter: 1134 loss: 4.51692722e-06
Iter: 1135 loss: 4.51685491e-06
Iter: 1136 loss: 4.51440292e-06
Iter: 1137 loss: 4.51332562e-06
Iter: 1138 loss: 4.51223e-06
Iter: 1139 loss: 4.50934385e-06
Iter: 1140 loss: 4.52842869e-06
Iter: 1141 loss: 4.50891184e-06
Iter: 1142 loss: 4.50649031e-06
Iter: 1143 loss: 4.50644e-06
Iter: 1144 loss: 4.50460357e-06
Iter: 1145 loss: 4.50148582e-06
Iter: 1146 loss: 4.52675704e-06
Iter: 1147 loss: 4.50138714e-06
Iter: 1148 loss: 4.49901e-06
Iter: 1149 loss: 4.49950585e-06
Iter: 1150 loss: 4.49728941e-06
Iter: 1151 loss: 4.49389699e-06
Iter: 1152 loss: 4.50884636e-06
Iter: 1153 loss: 4.49328854e-06
Iter: 1154 loss: 4.49101708e-06
Iter: 1155 loss: 4.50369089e-06
Iter: 1156 loss: 4.49070058e-06
Iter: 1157 loss: 4.48846276e-06
Iter: 1158 loss: 4.49301706e-06
Iter: 1159 loss: 4.48760602e-06
Iter: 1160 loss: 4.48574156e-06
Iter: 1161 loss: 4.50302468e-06
Iter: 1162 loss: 4.48559967e-06
Iter: 1163 loss: 4.4840308e-06
Iter: 1164 loss: 4.49707113e-06
Iter: 1165 loss: 4.48400351e-06
Iter: 1166 loss: 4.4829867e-06
Iter: 1167 loss: 4.48132869e-06
Iter: 1168 loss: 4.52481163e-06
Iter: 1169 loss: 4.48133687e-06
Iter: 1170 loss: 4.47845196e-06
Iter: 1171 loss: 4.48001674e-06
Iter: 1172 loss: 4.47666389e-06
Iter: 1173 loss: 4.47419643e-06
Iter: 1174 loss: 4.48504579e-06
Iter: 1175 loss: 4.47360253e-06
Iter: 1176 loss: 4.47112416e-06
Iter: 1177 loss: 4.47349294e-06
Iter: 1178 loss: 4.46964168e-06
Iter: 1179 loss: 4.46713557e-06
Iter: 1180 loss: 4.48451465e-06
Iter: 1181 loss: 4.46690592e-06
Iter: 1182 loss: 4.46473587e-06
Iter: 1183 loss: 4.46506237e-06
Iter: 1184 loss: 4.46286913e-06
Iter: 1185 loss: 4.46002332e-06
Iter: 1186 loss: 4.47423872e-06
Iter: 1187 loss: 4.45944761e-06
Iter: 1188 loss: 4.45711157e-06
Iter: 1189 loss: 4.46729e-06
Iter: 1190 loss: 4.45645946e-06
Iter: 1191 loss: 4.45412479e-06
Iter: 1192 loss: 4.45979458e-06
Iter: 1193 loss: 4.45317164e-06
Iter: 1194 loss: 4.45139312e-06
Iter: 1195 loss: 4.47433467e-06
Iter: 1196 loss: 4.45134629e-06
Iter: 1197 loss: 4.44991838e-06
Iter: 1198 loss: 4.45819205e-06
Iter: 1199 loss: 4.44969555e-06
Iter: 1200 loss: 4.44841498e-06
Iter: 1201 loss: 4.44675788e-06
Iter: 1202 loss: 4.44673833e-06
Iter: 1203 loss: 4.44432862e-06
Iter: 1204 loss: 4.44959142e-06
Iter: 1205 loss: 4.44353827e-06
Iter: 1206 loss: 4.44167745e-06
Iter: 1207 loss: 4.44447596e-06
Iter: 1208 loss: 4.44074158e-06
Iter: 1209 loss: 4.43858153e-06
Iter: 1210 loss: 4.44387e-06
Iter: 1211 loss: 4.43768477e-06
Iter: 1212 loss: 4.43572617e-06
Iter: 1213 loss: 4.4425019e-06
Iter: 1214 loss: 4.43514182e-06
Iter: 1215 loss: 4.43289673e-06
Iter: 1216 loss: 4.43644967e-06
Iter: 1217 loss: 4.43177669e-06
Iter: 1218 loss: 4.42947839e-06
Iter: 1219 loss: 4.43791214e-06
Iter: 1220 loss: 4.42905184e-06
Iter: 1221 loss: 4.42679129e-06
Iter: 1222 loss: 4.43057797e-06
Iter: 1223 loss: 4.42575811e-06
Iter: 1224 loss: 4.42333749e-06
Iter: 1225 loss: 4.44232683e-06
Iter: 1226 loss: 4.42322471e-06
Iter: 1227 loss: 4.42159035e-06
Iter: 1228 loss: 4.42714509e-06
Iter: 1229 loss: 4.42116334e-06
Iter: 1230 loss: 4.41962811e-06
Iter: 1231 loss: 4.4341532e-06
Iter: 1232 loss: 4.41949669e-06
Iter: 1233 loss: 4.41838893e-06
Iter: 1234 loss: 4.41702e-06
Iter: 1235 loss: 4.41694556e-06
Iter: 1236 loss: 4.4151393e-06
Iter: 1237 loss: 4.41916791e-06
Iter: 1238 loss: 4.41449356e-06
Iter: 1239 loss: 4.4125145e-06
Iter: 1240 loss: 4.41251677e-06
Iter: 1241 loss: 4.41121938e-06
Iter: 1242 loss: 4.40886379e-06
Iter: 1243 loss: 4.42464352e-06
Iter: 1244 loss: 4.40861459e-06
Iter: 1245 loss: 4.40675876e-06
Iter: 1246 loss: 4.4068e-06
Iter: 1247 loss: 4.405239e-06
Iter: 1248 loss: 4.40243366e-06
Iter: 1249 loss: 4.41809516e-06
Iter: 1250 loss: 4.40199165e-06
Iter: 1251 loss: 4.40001895e-06
Iter: 1252 loss: 4.40219401e-06
Iter: 1253 loss: 4.39897849e-06
Iter: 1254 loss: 4.39636915e-06
Iter: 1255 loss: 4.40512895e-06
Iter: 1256 loss: 4.39569703e-06
Iter: 1257 loss: 4.39372e-06
Iter: 1258 loss: 4.40948406e-06
Iter: 1259 loss: 4.3935147e-06
Iter: 1260 loss: 4.39198948e-06
Iter: 1261 loss: 4.39747782e-06
Iter: 1262 loss: 4.39157702e-06
Iter: 1263 loss: 4.3902387e-06
Iter: 1264 loss: 4.40319764e-06
Iter: 1265 loss: 4.39026599e-06
Iter: 1266 loss: 4.38916413e-06
Iter: 1267 loss: 4.38891948e-06
Iter: 1268 loss: 4.38820825e-06
Iter: 1269 loss: 4.38703546e-06
Iter: 1270 loss: 4.38741881e-06
Iter: 1271 loss: 4.38623101e-06
Iter: 1272 loss: 4.38457027e-06
Iter: 1273 loss: 4.38498819e-06
Iter: 1274 loss: 4.38330153e-06
Iter: 1275 loss: 4.38132884e-06
Iter: 1276 loss: 4.39220912e-06
Iter: 1277 loss: 4.3810378e-06
Iter: 1278 loss: 4.37920289e-06
Iter: 1279 loss: 4.37977e-06
Iter: 1280 loss: 4.37787457e-06
Iter: 1281 loss: 4.37591643e-06
Iter: 1282 loss: 4.39448559e-06
Iter: 1283 loss: 4.37577e-06
Iter: 1284 loss: 4.37442213e-06
Iter: 1285 loss: 4.37404105e-06
Iter: 1286 loss: 4.37304334e-06
Iter: 1287 loss: 4.37071776e-06
Iter: 1288 loss: 4.38017e-06
Iter: 1289 loss: 4.37017115e-06
Iter: 1290 loss: 4.36840583e-06
Iter: 1291 loss: 4.38312145e-06
Iter: 1292 loss: 4.3682594e-06
Iter: 1293 loss: 4.36686878e-06
Iter: 1294 loss: 4.36899109e-06
Iter: 1295 loss: 4.36628352e-06
Iter: 1296 loss: 4.36493656e-06
Iter: 1297 loss: 4.36497e-06
Iter: 1298 loss: 4.36420851e-06
Iter: 1299 loss: 4.36378e-06
Iter: 1300 loss: 4.36336541e-06
Iter: 1301 loss: 4.3622631e-06
Iter: 1302 loss: 4.36181836e-06
Iter: 1303 loss: 4.36121536e-06
Iter: 1304 loss: 4.35939182e-06
Iter: 1305 loss: 4.36253e-06
Iter: 1306 loss: 4.35857964e-06
Iter: 1307 loss: 4.35691254e-06
Iter: 1308 loss: 4.3614582e-06
Iter: 1309 loss: 4.35633046e-06
Iter: 1310 loss: 4.354265e-06
Iter: 1311 loss: 4.35688e-06
Iter: 1312 loss: 4.35329412e-06
Iter: 1313 loss: 4.35144466e-06
Iter: 1314 loss: 4.36519531e-06
Iter: 1315 loss: 4.35130278e-06
Iter: 1316 loss: 4.34975573e-06
Iter: 1317 loss: 4.35045285e-06
Iter: 1318 loss: 4.34859885e-06
Iter: 1319 loss: 4.34664889e-06
Iter: 1320 loss: 4.35613811e-06
Iter: 1321 loss: 4.34633785e-06
Iter: 1322 loss: 4.34472713e-06
Iter: 1323 loss: 4.35052198e-06
Iter: 1324 loss: 4.34437106e-06
Iter: 1325 loss: 4.34269714e-06
Iter: 1326 loss: 4.35008678e-06
Iter: 1327 loss: 4.34241338e-06
Iter: 1328 loss: 4.34119e-06
Iter: 1329 loss: 4.35843413e-06
Iter: 1330 loss: 4.34122649e-06
Iter: 1331 loss: 4.34043386e-06
Iter: 1332 loss: 4.34006461e-06
Iter: 1333 loss: 4.3396667e-06
Iter: 1334 loss: 4.33848618e-06
Iter: 1335 loss: 4.33734613e-06
Iter: 1336 loss: 4.33712967e-06
Iter: 1337 loss: 4.33513196e-06
Iter: 1338 loss: 4.34430558e-06
Iter: 1339 loss: 4.33483638e-06
Iter: 1340 loss: 4.33312698e-06
Iter: 1341 loss: 4.33356445e-06
Iter: 1342 loss: 4.33193145e-06
Iter: 1343 loss: 4.32982779e-06
Iter: 1344 loss: 4.34179128e-06
Iter: 1345 loss: 4.32951038e-06
Iter: 1346 loss: 4.32805609e-06
Iter: 1347 loss: 4.33220521e-06
Iter: 1348 loss: 4.32754587e-06
Iter: 1349 loss: 4.32584329e-06
Iter: 1350 loss: 4.32852221e-06
Iter: 1351 loss: 4.32501383e-06
Iter: 1352 loss: 4.32332672e-06
Iter: 1353 loss: 4.33065134e-06
Iter: 1354 loss: 4.32289744e-06
Iter: 1355 loss: 4.32129173e-06
Iter: 1356 loss: 4.32624893e-06
Iter: 1357 loss: 4.32093657e-06
Iter: 1358 loss: 4.3193636e-06
Iter: 1359 loss: 4.32765592e-06
Iter: 1360 loss: 4.3191003e-06
Iter: 1361 loss: 4.31818535e-06
Iter: 1362 loss: 4.31816716e-06
Iter: 1363 loss: 4.31745411e-06
Iter: 1364 loss: 4.31668104e-06
Iter: 1365 loss: 4.31667559e-06
Iter: 1366 loss: 4.31517128e-06
Iter: 1367 loss: 4.31509943e-06
Iter: 1368 loss: 4.31422e-06
Iter: 1369 loss: 4.31266153e-06
Iter: 1370 loss: 4.31905801e-06
Iter: 1371 loss: 4.3123564e-06
Iter: 1372 loss: 4.31099579e-06
Iter: 1373 loss: 4.31085755e-06
Iter: 1374 loss: 4.30973751e-06
Iter: 1375 loss: 4.30800083e-06
Iter: 1376 loss: 4.32180514e-06
Iter: 1377 loss: 4.30794e-06
Iter: 1378 loss: 4.30651562e-06
Iter: 1379 loss: 4.30727232e-06
Iter: 1380 loss: 4.30554519e-06
Iter: 1381 loss: 4.30378532e-06
Iter: 1382 loss: 4.31308581e-06
Iter: 1383 loss: 4.30340697e-06
Iter: 1384 loss: 4.30199361e-06
Iter: 1385 loss: 4.30397131e-06
Iter: 1386 loss: 4.3013606e-06
Iter: 1387 loss: 4.29945612e-06
Iter: 1388 loss: 4.30382806e-06
Iter: 1389 loss: 4.29878037e-06
Iter: 1390 loss: 4.29713054e-06
Iter: 1391 loss: 4.31591798e-06
Iter: 1392 loss: 4.29716511e-06
Iter: 1393 loss: 4.2962215e-06
Iter: 1394 loss: 4.30452292e-06
Iter: 1395 loss: 4.29616e-06
Iter: 1396 loss: 4.29517513e-06
Iter: 1397 loss: 4.29458487e-06
Iter: 1398 loss: 4.29418e-06
Iter: 1399 loss: 4.29276906e-06
Iter: 1400 loss: 4.293659e-06
Iter: 1401 loss: 4.29199144e-06
Iter: 1402 loss: 4.29051534e-06
Iter: 1403 loss: 4.29343618e-06
Iter: 1404 loss: 4.28995918e-06
Iter: 1405 loss: 4.28812473e-06
Iter: 1406 loss: 4.29036709e-06
Iter: 1407 loss: 4.28715202e-06
Iter: 1408 loss: 4.28563635e-06
Iter: 1409 loss: 4.29436932e-06
Iter: 1410 loss: 4.28548083e-06
Iter: 1411 loss: 4.28371732e-06
Iter: 1412 loss: 4.28413159e-06
Iter: 1413 loss: 4.28259136e-06
Iter: 1414 loss: 4.2808847e-06
Iter: 1415 loss: 4.29534521e-06
Iter: 1416 loss: 4.28061276e-06
Iter: 1417 loss: 4.27912346e-06
Iter: 1418 loss: 4.27963369e-06
Iter: 1419 loss: 4.27813939e-06
Iter: 1420 loss: 4.27624946e-06
Iter: 1421 loss: 4.28784915e-06
Iter: 1422 loss: 4.27598e-06
Iter: 1423 loss: 4.27471969e-06
Iter: 1424 loss: 4.28391741e-06
Iter: 1425 loss: 4.27459509e-06
Iter: 1426 loss: 4.27368195e-06
Iter: 1427 loss: 4.281972e-06
Iter: 1428 loss: 4.27364375e-06
Iter: 1429 loss: 4.27269151e-06
Iter: 1430 loss: 4.27260602e-06
Iter: 1431 loss: 4.27191571e-06
Iter: 1432 loss: 4.27096256e-06
Iter: 1433 loss: 4.27175291e-06
Iter: 1434 loss: 4.27039049e-06
Iter: 1435 loss: 4.26914767e-06
Iter: 1436 loss: 4.26945644e-06
Iter: 1437 loss: 4.26832594e-06
Iter: 1438 loss: 4.26664519e-06
Iter: 1439 loss: 4.27211125e-06
Iter: 1440 loss: 4.26622955e-06
Iter: 1441 loss: 4.26473753e-06
Iter: 1442 loss: 4.26669158e-06
Iter: 1443 loss: 4.26413499e-06
Iter: 1444 loss: 4.26213455e-06
Iter: 1445 loss: 4.26672068e-06
Iter: 1446 loss: 4.26154293e-06
Iter: 1447 loss: 4.25994131e-06
Iter: 1448 loss: 4.26846509e-06
Iter: 1449 loss: 4.25977623e-06
Iter: 1450 loss: 4.25832513e-06
Iter: 1451 loss: 4.25850931e-06
Iter: 1452 loss: 4.25720737e-06
Iter: 1453 loss: 4.25551707e-06
Iter: 1454 loss: 4.2680731e-06
Iter: 1455 loss: 4.25528879e-06
Iter: 1456 loss: 4.25411235e-06
Iter: 1457 loss: 4.26184397e-06
Iter: 1458 loss: 4.25390499e-06
Iter: 1459 loss: 4.25292137e-06
Iter: 1460 loss: 4.25962071e-06
Iter: 1461 loss: 4.25273e-06
Iter: 1462 loss: 4.25161124e-06
Iter: 1463 loss: 4.25267581e-06
Iter: 1464 loss: 4.25100916e-06
Iter: 1465 loss: 4.2500269e-06
Iter: 1466 loss: 4.25028475e-06
Iter: 1467 loss: 4.24930568e-06
Iter: 1468 loss: 4.2479187e-06
Iter: 1469 loss: 4.24815789e-06
Iter: 1470 loss: 4.24697282e-06
Iter: 1471 loss: 4.24500695e-06
Iter: 1472 loss: 4.25369e-06
Iter: 1473 loss: 4.24479549e-06
Iter: 1474 loss: 4.24322025e-06
Iter: 1475 loss: 4.24416658e-06
Iter: 1476 loss: 4.24238442e-06
Iter: 1477 loss: 4.24050904e-06
Iter: 1478 loss: 4.25056623e-06
Iter: 1479 loss: 4.24016434e-06
Iter: 1480 loss: 4.23889e-06
Iter: 1481 loss: 4.24224436e-06
Iter: 1482 loss: 4.23844449e-06
Iter: 1483 loss: 4.23673373e-06
Iter: 1484 loss: 4.23870551e-06
Iter: 1485 loss: 4.23588654e-06
Iter: 1486 loss: 4.23443498e-06
Iter: 1487 loss: 4.24530481e-06
Iter: 1488 loss: 4.23422807e-06
Iter: 1489 loss: 4.23302117e-06
Iter: 1490 loss: 4.23627e-06
Iter: 1491 loss: 4.23263828e-06
Iter: 1492 loss: 4.23142728e-06
Iter: 1493 loss: 4.24584869e-06
Iter: 1494 loss: 4.23140864e-06
Iter: 1495 loss: 4.23042457e-06
Iter: 1496 loss: 4.23188794e-06
Iter: 1497 loss: 4.22997073e-06
Iter: 1498 loss: 4.22899211e-06
Iter: 1499 loss: 4.22867561e-06
Iter: 1500 loss: 4.22828634e-06
Iter: 1501 loss: 4.22689118e-06
Iter: 1502 loss: 4.22717176e-06
Iter: 1503 loss: 4.22587345e-06
Iter: 1504 loss: 4.22420044e-06
Iter: 1505 loss: 4.23348501e-06
Iter: 1506 loss: 4.22399944e-06
Iter: 1507 loss: 4.22262883e-06
Iter: 1508 loss: 4.22266703e-06
Iter: 1509 loss: 4.22145922e-06
Iter: 1510 loss: 4.21953519e-06
Iter: 1511 loss: 4.23284e-06
Iter: 1512 loss: 4.21939876e-06
Iter: 1513 loss: 4.21808636e-06
Iter: 1514 loss: 4.21978666e-06
Iter: 1515 loss: 4.21753066e-06
Iter: 1516 loss: 4.21563709e-06
Iter: 1517 loss: 4.22063749e-06
Iter: 1518 loss: 4.21506866e-06
Iter: 1519 loss: 4.21367304e-06
Iter: 1520 loss: 4.2194838e-06
Iter: 1521 loss: 4.21340337e-06
Iter: 1522 loss: 4.21188133e-06
Iter: 1523 loss: 4.21687309e-06
Iter: 1524 loss: 4.21154846e-06
Iter: 1525 loss: 4.21043615e-06
Iter: 1526 loss: 4.22511312e-06
Iter: 1527 loss: 4.21046389e-06
Iter: 1528 loss: 4.20953211e-06
Iter: 1529 loss: 4.21178811e-06
Iter: 1530 loss: 4.20912238e-06
Iter: 1531 loss: 4.20831e-06
Iter: 1532 loss: 4.20713377e-06
Iter: 1533 loss: 4.20715969e-06
Iter: 1534 loss: 4.20540709e-06
Iter: 1535 loss: 4.20884135e-06
Iter: 1536 loss: 4.20493734e-06
Iter: 1537 loss: 4.20341e-06
Iter: 1538 loss: 4.20721517e-06
Iter: 1539 loss: 4.20274228e-06
Iter: 1540 loss: 4.20124934e-06
Iter: 1541 loss: 4.20382457e-06
Iter: 1542 loss: 4.20039487e-06
Iter: 1543 loss: 4.19877551e-06
Iter: 1544 loss: 4.2067104e-06
Iter: 1545 loss: 4.19847174e-06
Iter: 1546 loss: 4.19704611e-06
Iter: 1547 loss: 4.19866728e-06
Iter: 1548 loss: 4.19621574e-06
Iter: 1549 loss: 4.19446724e-06
Iter: 1550 loss: 4.20304377e-06
Iter: 1551 loss: 4.194143e-06
Iter: 1552 loss: 4.19278376e-06
Iter: 1553 loss: 4.1955459e-06
Iter: 1554 loss: 4.19212256e-06
Iter: 1555 loss: 4.19058415e-06
Iter: 1556 loss: 4.19819753e-06
Iter: 1557 loss: 4.19021717e-06
Iter: 1558 loss: 4.18931222e-06
Iter: 1559 loss: 4.18927539e-06
Iter: 1560 loss: 4.18841273e-06
Iter: 1561 loss: 4.1898e-06
Iter: 1562 loss: 4.18822128e-06
Iter: 1563 loss: 4.18723039e-06
Iter: 1564 loss: 4.18593208e-06
Iter: 1565 loss: 4.18586251e-06
Iter: 1566 loss: 4.18440868e-06
Iter: 1567 loss: 4.19096295e-06
Iter: 1568 loss: 4.184104e-06
Iter: 1569 loss: 4.18286527e-06
Iter: 1570 loss: 4.18335e-06
Iter: 1571 loss: 4.18198897e-06
Iter: 1572 loss: 4.18015134e-06
Iter: 1573 loss: 4.18624086e-06
Iter: 1574 loss: 4.17972342e-06
Iter: 1575 loss: 4.17818228e-06
Iter: 1576 loss: 4.18195395e-06
Iter: 1577 loss: 4.17751653e-06
Iter: 1578 loss: 4.17586762e-06
Iter: 1579 loss: 4.17970477e-06
Iter: 1580 loss: 4.17515139e-06
Iter: 1581 loss: 4.17356296e-06
Iter: 1582 loss: 4.18239415e-06
Iter: 1583 loss: 4.1731937e-06
Iter: 1584 loss: 4.17186948e-06
Iter: 1585 loss: 4.17200226e-06
Iter: 1586 loss: 4.17072124e-06
Iter: 1587 loss: 4.16890771e-06
Iter: 1588 loss: 4.18836316e-06
Iter: 1589 loss: 4.16891635e-06
Iter: 1590 loss: 4.16796547e-06
Iter: 1591 loss: 4.17874799e-06
Iter: 1592 loss: 4.16796502e-06
Iter: 1593 loss: 4.16715193e-06
Iter: 1594 loss: 4.16839339e-06
Iter: 1595 loss: 4.16669172e-06
Iter: 1596 loss: 4.1657031e-06
Iter: 1597 loss: 4.16454714e-06
Iter: 1598 loss: 4.16442617e-06
Iter: 1599 loss: 4.16301555e-06
Iter: 1600 loss: 4.16926923e-06
Iter: 1601 loss: 4.1625708e-06
Iter: 1602 loss: 4.16118655e-06
Iter: 1603 loss: 4.16117109e-06
Iter: 1604 loss: 4.16006696e-06
Iter: 1605 loss: 4.15831164e-06
Iter: 1606 loss: 4.16873081e-06
Iter: 1607 loss: 4.15804971e-06
Iter: 1608 loss: 4.15649811e-06
Iter: 1609 loss: 4.15763043e-06
Iter: 1610 loss: 4.15572413e-06
Iter: 1611 loss: 4.15359864e-06
Iter: 1612 loss: 4.16057674e-06
Iter: 1613 loss: 4.15307295e-06
Iter: 1614 loss: 4.15153272e-06
Iter: 1615 loss: 4.15894829e-06
Iter: 1616 loss: 4.15117029e-06
Iter: 1617 loss: 4.14963142e-06
Iter: 1618 loss: 4.15010845e-06
Iter: 1619 loss: 4.1485664e-06
Iter: 1620 loss: 4.14704346e-06
Iter: 1621 loss: 4.16710736e-06
Iter: 1622 loss: 4.14709893e-06
Iter: 1623 loss: 4.14614897e-06
Iter: 1624 loss: 4.15469458e-06
Iter: 1625 loss: 4.14607166e-06
Iter: 1626 loss: 4.14515489e-06
Iter: 1627 loss: 4.14624355e-06
Iter: 1628 loss: 4.14474925e-06
Iter: 1629 loss: 4.1437961e-06
Iter: 1630 loss: 4.1431781e-06
Iter: 1631 loss: 4.14273109e-06
Iter: 1632 loss: 4.14143142e-06
Iter: 1633 loss: 4.14408078e-06
Iter: 1634 loss: 4.14094211e-06
Iter: 1635 loss: 4.13945781e-06
Iter: 1636 loss: 4.14089482e-06
Iter: 1637 loss: 4.13855378e-06
Iter: 1638 loss: 4.13695125e-06
Iter: 1639 loss: 4.14351052e-06
Iter: 1640 loss: 4.13660973e-06
Iter: 1641 loss: 4.13503767e-06
Iter: 1642 loss: 4.13666748e-06
Iter: 1643 loss: 4.13425278e-06
Iter: 1644 loss: 4.13265434e-06
Iter: 1645 loss: 4.14178294e-06
Iter: 1646 loss: 4.13236921e-06
Iter: 1647 loss: 4.1311996e-06
Iter: 1648 loss: 4.1329904e-06
Iter: 1649 loss: 4.13067301e-06
Iter: 1650 loss: 4.12895679e-06
Iter: 1651 loss: 4.13157068e-06
Iter: 1652 loss: 4.12807276e-06
Iter: 1653 loss: 4.12674399e-06
Iter: 1654 loss: 4.13994439e-06
Iter: 1655 loss: 4.12669851e-06
Iter: 1656 loss: 4.12555846e-06
Iter: 1657 loss: 4.1317262e-06
Iter: 1658 loss: 4.12540885e-06
Iter: 1659 loss: 4.12433837e-06
Iter: 1660 loss: 4.12863346e-06
Iter: 1661 loss: 4.12406507e-06
Iter: 1662 loss: 4.12321606e-06
Iter: 1663 loss: 4.12267673e-06
Iter: 1664 loss: 4.12231111e-06
Iter: 1665 loss: 4.12114059e-06
Iter: 1666 loss: 4.1219937e-06
Iter: 1667 loss: 4.12039572e-06
Iter: 1668 loss: 4.11881911e-06
Iter: 1669 loss: 4.12378222e-06
Iter: 1670 loss: 4.11833298e-06
Iter: 1671 loss: 4.11700466e-06
Iter: 1672 loss: 4.11968904e-06
Iter: 1673 loss: 4.11645033e-06
Iter: 1674 loss: 4.11484507e-06
Iter: 1675 loss: 4.11768087e-06
Iter: 1676 loss: 4.1141875e-06
Iter: 1677 loss: 4.11259953e-06
Iter: 1678 loss: 4.12058853e-06
Iter: 1679 loss: 4.11244e-06
Iter: 1680 loss: 4.11098154e-06
Iter: 1681 loss: 4.11193741e-06
Iter: 1682 loss: 4.11006249e-06
Iter: 1683 loss: 4.10840312e-06
Iter: 1684 loss: 4.11756082e-06
Iter: 1685 loss: 4.10813936e-06
Iter: 1686 loss: 4.10676512e-06
Iter: 1687 loss: 4.11068413e-06
Iter: 1688 loss: 4.10634129e-06
Iter: 1689 loss: 4.10506073e-06
Iter: 1690 loss: 4.11876499e-06
Iter: 1691 loss: 4.10510347e-06
Iter: 1692 loss: 4.10418e-06
Iter: 1693 loss: 4.10922303e-06
Iter: 1694 loss: 4.10397251e-06
Iter: 1695 loss: 4.10333359e-06
Iter: 1696 loss: 4.10269877e-06
Iter: 1697 loss: 4.1024532e-06
Iter: 1698 loss: 4.10143639e-06
Iter: 1699 loss: 4.10148687e-06
Iter: 1700 loss: 4.10052598e-06
Iter: 1701 loss: 4.0990335e-06
Iter: 1702 loss: 4.10441453e-06
Iter: 1703 loss: 4.09851737e-06
Iter: 1704 loss: 4.09715085e-06
Iter: 1705 loss: 4.09787e-06
Iter: 1706 loss: 4.09624681e-06
Iter: 1707 loss: 4.09418499e-06
Iter: 1708 loss: 4.10175426e-06
Iter: 1709 loss: 4.0936593e-06
Iter: 1710 loss: 4.09220411e-06
Iter: 1711 loss: 4.09667064e-06
Iter: 1712 loss: 4.09182394e-06
Iter: 1713 loss: 4.08999e-06
Iter: 1714 loss: 4.0920022e-06
Iter: 1715 loss: 4.08902542e-06
Iter: 1716 loss: 4.08741107e-06
Iter: 1717 loss: 4.10011216e-06
Iter: 1718 loss: 4.08721e-06
Iter: 1719 loss: 4.08594224e-06
Iter: 1720 loss: 4.08729829e-06
Iter: 1721 loss: 4.08526103e-06
Iter: 1722 loss: 4.08397818e-06
Iter: 1723 loss: 4.10193525e-06
Iter: 1724 loss: 4.08391315e-06
Iter: 1725 loss: 4.08290725e-06
Iter: 1726 loss: 4.08954e-06
Iter: 1727 loss: 4.08281039e-06
Iter: 1728 loss: 4.08215783e-06
Iter: 1729 loss: 4.08129472e-06
Iter: 1730 loss: 4.08121468e-06
Iter: 1731 loss: 4.08008509e-06
Iter: 1732 loss: 4.08007782e-06
Iter: 1733 loss: 4.07896914e-06
Iter: 1734 loss: 4.07738207e-06
Iter: 1735 loss: 4.08529377e-06
Iter: 1736 loss: 4.07706148e-06
Iter: 1737 loss: 4.07564812e-06
Iter: 1738 loss: 4.07661628e-06
Iter: 1739 loss: 4.07477182e-06
Iter: 1740 loss: 4.0730838e-06
Iter: 1741 loss: 4.08223605e-06
Iter: 1742 loss: 4.0728919e-06
Iter: 1743 loss: 4.07150537e-06
Iter: 1744 loss: 4.07316e-06
Iter: 1745 loss: 4.07093466e-06
Iter: 1746 loss: 4.06926756e-06
Iter: 1747 loss: 4.07441439e-06
Iter: 1748 loss: 4.0689074e-06
Iter: 1749 loss: 4.06753861e-06
Iter: 1750 loss: 4.07387552e-06
Iter: 1751 loss: 4.06734171e-06
Iter: 1752 loss: 4.06595609e-06
Iter: 1753 loss: 4.06615163e-06
Iter: 1754 loss: 4.0651189e-06
Iter: 1755 loss: 4.06387e-06
Iter: 1756 loss: 4.06386789e-06
Iter: 1757 loss: 4.06297931e-06
Iter: 1758 loss: 4.06845083e-06
Iter: 1759 loss: 4.06289428e-06
Iter: 1760 loss: 4.06219078e-06
Iter: 1761 loss: 4.06141589e-06
Iter: 1762 loss: 4.06130539e-06
Iter: 1763 loss: 4.06005711e-06
Iter: 1764 loss: 4.06058643e-06
Iter: 1765 loss: 4.05920673e-06
Iter: 1766 loss: 4.05790615e-06
Iter: 1767 loss: 4.06489198e-06
Iter: 1768 loss: 4.05760829e-06
Iter: 1769 loss: 4.05634455e-06
Iter: 1770 loss: 4.05607079e-06
Iter: 1771 loss: 4.05531318e-06
Iter: 1772 loss: 4.0536097e-06
Iter: 1773 loss: 4.06599702e-06
Iter: 1774 loss: 4.05359606e-06
Iter: 1775 loss: 4.052441e-06
Iter: 1776 loss: 4.05265837e-06
Iter: 1777 loss: 4.05133142e-06
Iter: 1778 loss: 4.04960838e-06
Iter: 1779 loss: 4.05781793e-06
Iter: 1780 loss: 4.04921639e-06
Iter: 1781 loss: 4.04793354e-06
Iter: 1782 loss: 4.05258788e-06
Iter: 1783 loss: 4.04760976e-06
Iter: 1784 loss: 4.04629372e-06
Iter: 1785 loss: 4.04806269e-06
Iter: 1786 loss: 4.04547563e-06
Iter: 1787 loss: 4.04444654e-06
Iter: 1788 loss: 4.04445882e-06
Iter: 1789 loss: 4.0436762e-06
Iter: 1790 loss: 4.04965112e-06
Iter: 1791 loss: 4.04361708e-06
Iter: 1792 loss: 4.04298089e-06
Iter: 1793 loss: 4.0421678e-06
Iter: 1794 loss: 4.04210323e-06
Iter: 1795 loss: 4.04084631e-06
Iter: 1796 loss: 4.04223556e-06
Iter: 1797 loss: 4.04029925e-06
Iter: 1798 loss: 4.03905824e-06
Iter: 1799 loss: 4.04367893e-06
Iter: 1800 loss: 4.03871627e-06
Iter: 1801 loss: 4.03746662e-06
Iter: 1802 loss: 4.03758213e-06
Iter: 1803 loss: 4.03644162e-06
Iter: 1804 loss: 4.03508557e-06
Iter: 1805 loss: 4.04504272e-06
Iter: 1806 loss: 4.03493777e-06
Iter: 1807 loss: 4.03360536e-06
Iter: 1808 loss: 4.0341356e-06
Iter: 1809 loss: 4.03279182e-06
Iter: 1810 loss: 4.0312043e-06
Iter: 1811 loss: 4.04004277e-06
Iter: 1812 loss: 4.03103149e-06
Iter: 1813 loss: 4.02980504e-06
Iter: 1814 loss: 4.03201602e-06
Iter: 1815 loss: 4.02935257e-06
Iter: 1816 loss: 4.02778915e-06
Iter: 1817 loss: 4.03094919e-06
Iter: 1818 loss: 4.02731439e-06
Iter: 1819 loss: 4.02627302e-06
Iter: 1820 loss: 4.04094772e-06
Iter: 1821 loss: 4.02623482e-06
Iter: 1822 loss: 4.02522301e-06
Iter: 1823 loss: 4.03111335e-06
Iter: 1824 loss: 4.02515252e-06
Iter: 1825 loss: 4.02440219e-06
Iter: 1826 loss: 4.02346723e-06
Iter: 1827 loss: 4.02333626e-06
Iter: 1828 loss: 4.02216665e-06
Iter: 1829 loss: 4.02401611e-06
Iter: 1830 loss: 4.02158139e-06
Iter: 1831 loss: 4.02033311e-06
Iter: 1832 loss: 4.02276237e-06
Iter: 1833 loss: 4.01986745e-06
Iter: 1834 loss: 4.01825946e-06
Iter: 1835 loss: 4.01995112e-06
Iter: 1836 loss: 4.01748957e-06
Iter: 1837 loss: 4.01603666e-06
Iter: 1838 loss: 4.02438582e-06
Iter: 1839 loss: 4.01587931e-06
Iter: 1840 loss: 4.0146133e-06
Iter: 1841 loss: 4.01491e-06
Iter: 1842 loss: 4.0137129e-06
Iter: 1843 loss: 4.01215857e-06
Iter: 1844 loss: 4.02311434e-06
Iter: 1845 loss: 4.01208945e-06
Iter: 1846 loss: 4.0109253e-06
Iter: 1847 loss: 4.01175976e-06
Iter: 1848 loss: 4.0102118e-06
Iter: 1849 loss: 4.00875933e-06
Iter: 1850 loss: 4.01575835e-06
Iter: 1851 loss: 4.00845602e-06
Iter: 1852 loss: 4.00744648e-06
Iter: 1853 loss: 4.0133782e-06
Iter: 1854 loss: 4.00728e-06
Iter: 1855 loss: 4.00624867e-06
Iter: 1856 loss: 4.01739135e-06
Iter: 1857 loss: 4.00634053e-06
Iter: 1858 loss: 4.00568615e-06
Iter: 1859 loss: 4.00516e-06
Iter: 1860 loss: 4.0048526e-06
Iter: 1861 loss: 4.00390036e-06
Iter: 1862 loss: 4.00477074e-06
Iter: 1863 loss: 4.0034738e-06
Iter: 1864 loss: 4.0023715e-06
Iter: 1865 loss: 4.00379668e-06
Iter: 1866 loss: 4.0017585e-06
Iter: 1867 loss: 4.00051977e-06
Iter: 1868 loss: 4.00454701e-06
Iter: 1869 loss: 4.00014505e-06
Iter: 1870 loss: 3.99913e-06
Iter: 1871 loss: 4.00080444e-06
Iter: 1872 loss: 3.99857481e-06
Iter: 1873 loss: 3.99723649e-06
Iter: 1874 loss: 3.99950568e-06
Iter: 1875 loss: 3.99659621e-06
Iter: 1876 loss: 3.99529563e-06
Iter: 1877 loss: 4.00137878e-06
Iter: 1878 loss: 3.99497912e-06
Iter: 1879 loss: 3.99373175e-06
Iter: 1880 loss: 3.99546298e-06
Iter: 1881 loss: 3.99313103e-06
Iter: 1882 loss: 3.99181863e-06
Iter: 1883 loss: 4.00071667e-06
Iter: 1884 loss: 3.99178498e-06
Iter: 1885 loss: 3.9908e-06
Iter: 1886 loss: 3.99330656e-06
Iter: 1887 loss: 3.99035e-06
Iter: 1888 loss: 3.9896513e-06
Iter: 1889 loss: 3.98963357e-06
Iter: 1890 loss: 3.98909924e-06
Iter: 1891 loss: 3.98902557e-06
Iter: 1892 loss: 3.98857173e-06
Iter: 1893 loss: 3.98788688e-06
Iter: 1894 loss: 3.98745033e-06
Iter: 1895 loss: 3.98714928e-06
Iter: 1896 loss: 3.98589873e-06
Iter: 1897 loss: 3.988152e-06
Iter: 1898 loss: 3.98521115e-06
Iter: 1899 loss: 3.98402244e-06
Iter: 1900 loss: 3.98905195e-06
Iter: 1901 loss: 3.98368411e-06
Iter: 1902 loss: 3.98247403e-06
Iter: 1903 loss: 3.98344673e-06
Iter: 1904 loss: 3.98180373e-06
Iter: 1905 loss: 3.98039356e-06
Iter: 1906 loss: 3.98733528e-06
Iter: 1907 loss: 3.9800866e-06
Iter: 1908 loss: 3.97894974e-06
Iter: 1909 loss: 3.98029715e-06
Iter: 1910 loss: 3.97842268e-06
Iter: 1911 loss: 3.97693884e-06
Iter: 1912 loss: 3.98264e-06
Iter: 1913 loss: 3.97650456e-06
Iter: 1914 loss: 3.97544318e-06
Iter: 1915 loss: 3.97918438e-06
Iter: 1916 loss: 3.97508802e-06
Iter: 1917 loss: 3.97379699e-06
Iter: 1918 loss: 3.97666e-06
Iter: 1919 loss: 3.9733186e-06
Iter: 1920 loss: 3.97268104e-06
Iter: 1921 loss: 3.97257736e-06
Iter: 1922 loss: 3.97186886e-06
Iter: 1923 loss: 3.97167696e-06
Iter: 1924 loss: 3.97144231e-06
Iter: 1925 loss: 3.97055237e-06
Iter: 1926 loss: 3.96972791e-06
Iter: 1927 loss: 3.96957967e-06
Iter: 1928 loss: 3.96811e-06
Iter: 1929 loss: 3.97389704e-06
Iter: 1930 loss: 3.9678348e-06
Iter: 1931 loss: 3.96670202e-06
Iter: 1932 loss: 3.96933501e-06
Iter: 1933 loss: 3.96633641e-06
Iter: 1934 loss: 3.96496125e-06
Iter: 1935 loss: 3.96641462e-06
Iter: 1936 loss: 3.96414271e-06
Iter: 1937 loss: 3.96270343e-06
Iter: 1938 loss: 3.9712213e-06
Iter: 1939 loss: 3.96266296e-06
Iter: 1940 loss: 3.9614888e-06
Iter: 1941 loss: 3.96184896e-06
Iter: 1942 loss: 3.96072573e-06
Iter: 1943 loss: 3.95927054e-06
Iter: 1944 loss: 3.96907353e-06
Iter: 1945 loss: 3.9590559e-06
Iter: 1946 loss: 3.95807365e-06
Iter: 1947 loss: 3.95930238e-06
Iter: 1948 loss: 3.95752522e-06
Iter: 1949 loss: 3.95603593e-06
Iter: 1950 loss: 3.96088308e-06
Iter: 1951 loss: 3.95567349e-06
Iter: 1952 loss: 3.95528559e-06
Iter: 1953 loss: 3.95514417e-06
Iter: 1954 loss: 3.95457664e-06
Iter: 1955 loss: 3.95437746e-06
Iter: 1956 loss: 3.95408e-06
Iter: 1957 loss: 3.95322513e-06
Iter: 1958 loss: 3.9523261e-06
Iter: 1959 loss: 3.95220422e-06
Iter: 1960 loss: 3.95089228e-06
Iter: 1961 loss: 3.95770621e-06
Iter: 1962 loss: 3.95064e-06
Iter: 1963 loss: 3.94969811e-06
Iter: 1964 loss: 3.95098687e-06
Iter: 1965 loss: 3.94910694e-06
Iter: 1966 loss: 3.94782683e-06
Iter: 1967 loss: 3.9517563e-06
Iter: 1968 loss: 3.94751896e-06
Iter: 1969 loss: 3.94639846e-06
Iter: 1970 loss: 3.94992549e-06
Iter: 1971 loss: 3.94600329e-06
Iter: 1972 loss: 3.94488779e-06
Iter: 1973 loss: 3.94607196e-06
Iter: 1974 loss: 3.94426934e-06
Iter: 1975 loss: 3.94296239e-06
Iter: 1976 loss: 3.95163806e-06
Iter: 1977 loss: 3.94299968e-06
Iter: 1978 loss: 3.94195922e-06
Iter: 1979 loss: 3.94224662e-06
Iter: 1980 loss: 3.94122571e-06
Iter: 1981 loss: 3.93990604e-06
Iter: 1982 loss: 3.94852486e-06
Iter: 1983 loss: 3.93959272e-06
Iter: 1984 loss: 3.93929804e-06
Iter: 1985 loss: 3.93922255e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3
+ date
Mon Oct 26 10:39:33 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6087201bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60871db730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60871920d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f608718ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6087288c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6087100378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6087135f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60870bd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60870b4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60870b48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f608704c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f608705bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60870616a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60870226a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086fc59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086fbfb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086f82400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086fa1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086f697b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086f69d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086f259d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086ee07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086f25bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086f25620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086e9b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086e0f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086e35840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086d78620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086d92598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086d929d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6086de8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60550c9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60550f41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60550867b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f60550b7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f605504c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.50328914e-05
Iter: 2 loss: 4.78272123e-05
Iter: 3 loss: 8.99993829e-05
Iter: 4 loss: 4.6853449e-05
Iter: 5 loss: 4.34337453e-05
Iter: 6 loss: 9.33291667e-05
Iter: 7 loss: 4.34324174e-05
Iter: 8 loss: 4.02371916e-05
Iter: 9 loss: 3.3025819e-05
Iter: 10 loss: 0.000128231492
Iter: 11 loss: 3.25902765e-05
Iter: 12 loss: 2.82572837e-05
Iter: 13 loss: 7.25534337e-05
Iter: 14 loss: 2.81333305e-05
Iter: 15 loss: 2.53539019e-05
Iter: 16 loss: 2.78240477e-05
Iter: 17 loss: 2.37225886e-05
Iter: 18 loss: 2.11508686e-05
Iter: 19 loss: 4.44480538e-05
Iter: 20 loss: 2.10332691e-05
Iter: 21 loss: 1.96800756e-05
Iter: 22 loss: 2.40370046e-05
Iter: 23 loss: 1.92994485e-05
Iter: 24 loss: 1.80093921e-05
Iter: 25 loss: 1.9396397e-05
Iter: 26 loss: 1.73020726e-05
Iter: 27 loss: 1.60016607e-05
Iter: 28 loss: 1.71899537e-05
Iter: 29 loss: 1.5247334e-05
Iter: 30 loss: 1.41197552e-05
Iter: 31 loss: 2.36337655e-05
Iter: 32 loss: 1.40529382e-05
Iter: 33 loss: 1.33178964e-05
Iter: 34 loss: 1.38507512e-05
Iter: 35 loss: 1.28644515e-05
Iter: 36 loss: 1.22918773e-05
Iter: 37 loss: 1.80959742e-05
Iter: 38 loss: 1.22744059e-05
Iter: 39 loss: 1.18671469e-05
Iter: 40 loss: 1.1754395e-05
Iter: 41 loss: 1.15045577e-05
Iter: 42 loss: 1.17399668e-05
Iter: 43 loss: 1.12863891e-05
Iter: 44 loss: 1.11356785e-05
Iter: 45 loss: 1.09473185e-05
Iter: 46 loss: 1.09316861e-05
Iter: 47 loss: 1.06663829e-05
Iter: 48 loss: 1.02361155e-05
Iter: 49 loss: 1.02332961e-05
Iter: 50 loss: 9.92692094e-06
Iter: 51 loss: 9.92007244e-06
Iter: 52 loss: 9.63402454e-06
Iter: 53 loss: 9.87806652e-06
Iter: 54 loss: 9.46498949e-06
Iter: 55 loss: 9.15649252e-06
Iter: 56 loss: 1.18526659e-05
Iter: 57 loss: 9.14045813e-06
Iter: 58 loss: 8.97840619e-06
Iter: 59 loss: 8.92067874e-06
Iter: 60 loss: 8.82984e-06
Iter: 61 loss: 8.56204861e-06
Iter: 62 loss: 9.31064824e-06
Iter: 63 loss: 8.47588126e-06
Iter: 64 loss: 8.30186764e-06
Iter: 65 loss: 8.52636549e-06
Iter: 66 loss: 8.2130191e-06
Iter: 67 loss: 7.99220197e-06
Iter: 68 loss: 9.14268821e-06
Iter: 69 loss: 7.95723554e-06
Iter: 70 loss: 7.80685696e-06
Iter: 71 loss: 8.11343e-06
Iter: 72 loss: 7.74604e-06
Iter: 73 loss: 7.55051633e-06
Iter: 74 loss: 8.64763751e-06
Iter: 75 loss: 7.5232474e-06
Iter: 76 loss: 7.46855721e-06
Iter: 77 loss: 7.45081024e-06
Iter: 78 loss: 7.389649e-06
Iter: 79 loss: 7.24066422e-06
Iter: 80 loss: 8.79625077e-06
Iter: 81 loss: 7.2236744e-06
Iter: 82 loss: 7.09737424e-06
Iter: 83 loss: 7.58243277e-06
Iter: 84 loss: 7.06758692e-06
Iter: 85 loss: 6.97073528e-06
Iter: 86 loss: 6.99985731e-06
Iter: 87 loss: 6.90140678e-06
Iter: 88 loss: 6.78711058e-06
Iter: 89 loss: 7.44508543e-06
Iter: 90 loss: 6.77157777e-06
Iter: 91 loss: 6.67073618e-06
Iter: 92 loss: 7.44899899e-06
Iter: 93 loss: 6.66345522e-06
Iter: 94 loss: 6.59694206e-06
Iter: 95 loss: 6.84998076e-06
Iter: 96 loss: 6.58081e-06
Iter: 97 loss: 6.52391736e-06
Iter: 98 loss: 6.43910607e-06
Iter: 99 loss: 6.43715839e-06
Iter: 100 loss: 6.34897333e-06
Iter: 101 loss: 7.63545813e-06
Iter: 102 loss: 6.34884327e-06
Iter: 103 loss: 6.29003898e-06
Iter: 104 loss: 6.19388857e-06
Iter: 105 loss: 6.19333468e-06
Iter: 106 loss: 6.12436e-06
Iter: 107 loss: 6.11793348e-06
Iter: 108 loss: 6.07325956e-06
Iter: 109 loss: 5.98664064e-06
Iter: 110 loss: 7.76911747e-06
Iter: 111 loss: 5.98605129e-06
Iter: 112 loss: 6.07106085e-06
Iter: 113 loss: 5.96063637e-06
Iter: 114 loss: 5.93590676e-06
Iter: 115 loss: 5.92570632e-06
Iter: 116 loss: 5.9126628e-06
Iter: 117 loss: 5.87773775e-06
Iter: 118 loss: 5.79118114e-06
Iter: 119 loss: 6.63492756e-06
Iter: 120 loss: 5.77971105e-06
Iter: 121 loss: 5.73231637e-06
Iter: 122 loss: 5.73168745e-06
Iter: 123 loss: 5.68439282e-06
Iter: 124 loss: 5.73692432e-06
Iter: 125 loss: 5.65887422e-06
Iter: 126 loss: 5.61400975e-06
Iter: 127 loss: 5.89870524e-06
Iter: 128 loss: 5.60912667e-06
Iter: 129 loss: 5.57285193e-06
Iter: 130 loss: 5.58032662e-06
Iter: 131 loss: 5.54605049e-06
Iter: 132 loss: 5.48371099e-06
Iter: 133 loss: 5.75806462e-06
Iter: 134 loss: 5.47111586e-06
Iter: 135 loss: 5.44041859e-06
Iter: 136 loss: 5.43120586e-06
Iter: 137 loss: 5.41292457e-06
Iter: 138 loss: 5.35938398e-06
Iter: 139 loss: 5.48130311e-06
Iter: 140 loss: 5.33950606e-06
Iter: 141 loss: 5.30270881e-06
Iter: 142 loss: 5.3821941e-06
Iter: 143 loss: 5.28838427e-06
Iter: 144 loss: 5.2456171e-06
Iter: 145 loss: 5.54429698e-06
Iter: 146 loss: 5.24147072e-06
Iter: 147 loss: 5.22499431e-06
Iter: 148 loss: 5.22270511e-06
Iter: 149 loss: 5.20377216e-06
Iter: 150 loss: 5.17835406e-06
Iter: 151 loss: 5.17704711e-06
Iter: 152 loss: 5.15435704e-06
Iter: 153 loss: 5.16505224e-06
Iter: 154 loss: 5.13912573e-06
Iter: 155 loss: 5.10746668e-06
Iter: 156 loss: 5.10998734e-06
Iter: 157 loss: 5.08285666e-06
Iter: 158 loss: 5.05182e-06
Iter: 159 loss: 5.29884301e-06
Iter: 160 loss: 5.04984837e-06
Iter: 161 loss: 5.01848444e-06
Iter: 162 loss: 5.10732798e-06
Iter: 163 loss: 5.0084077e-06
Iter: 164 loss: 4.98295594e-06
Iter: 165 loss: 5.07222e-06
Iter: 166 loss: 4.97631027e-06
Iter: 167 loss: 4.9481514e-06
Iter: 168 loss: 4.97253723e-06
Iter: 169 loss: 4.93162e-06
Iter: 170 loss: 4.89556487e-06
Iter: 171 loss: 5.10205791e-06
Iter: 172 loss: 4.89089689e-06
Iter: 173 loss: 4.87215357e-06
Iter: 174 loss: 4.85786495e-06
Iter: 175 loss: 4.85174769e-06
Iter: 176 loss: 4.81825191e-06
Iter: 177 loss: 4.95824497e-06
Iter: 178 loss: 4.81107963e-06
Iter: 179 loss: 4.7862095e-06
Iter: 180 loss: 4.80910785e-06
Iter: 181 loss: 4.77195044e-06
Iter: 182 loss: 4.76442528e-06
Iter: 183 loss: 4.75553179e-06
Iter: 184 loss: 4.74155058e-06
Iter: 185 loss: 4.74207127e-06
Iter: 186 loss: 4.73055798e-06
Iter: 187 loss: 4.71940393e-06
Iter: 188 loss: 4.69327188e-06
Iter: 189 loss: 5.00609667e-06
Iter: 190 loss: 4.69118277e-06
Iter: 191 loss: 4.67018253e-06
Iter: 192 loss: 4.67023528e-06
Iter: 193 loss: 4.65474295e-06
Iter: 194 loss: 4.63936885e-06
Iter: 195 loss: 4.63629749e-06
Iter: 196 loss: 4.61252512e-06
Iter: 197 loss: 4.92322442e-06
Iter: 198 loss: 4.6122741e-06
Iter: 199 loss: 4.59850889e-06
Iter: 200 loss: 4.58641807e-06
Iter: 201 loss: 4.5827228e-06
Iter: 202 loss: 4.55553936e-06
Iter: 203 loss: 4.78878428e-06
Iter: 204 loss: 4.55413738e-06
Iter: 205 loss: 4.54260044e-06
Iter: 206 loss: 4.54592e-06
Iter: 207 loss: 4.53431949e-06
Iter: 208 loss: 4.51279266e-06
Iter: 209 loss: 4.53749271e-06
Iter: 210 loss: 4.50113839e-06
Iter: 211 loss: 4.48504215e-06
Iter: 212 loss: 4.59057446e-06
Iter: 213 loss: 4.48338415e-06
Iter: 214 loss: 4.47040838e-06
Iter: 215 loss: 4.46656759e-06
Iter: 216 loss: 4.45879141e-06
Iter: 217 loss: 4.46687136e-06
Iter: 218 loss: 4.45188834e-06
Iter: 219 loss: 4.44786201e-06
Iter: 220 loss: 4.4361168e-06
Iter: 221 loss: 4.49460276e-06
Iter: 222 loss: 4.4322951e-06
Iter: 223 loss: 4.41600332e-06
Iter: 224 loss: 4.43346107e-06
Iter: 225 loss: 4.40701569e-06
Iter: 226 loss: 4.39047926e-06
Iter: 227 loss: 4.45300066e-06
Iter: 228 loss: 4.38645202e-06
Iter: 229 loss: 4.36824757e-06
Iter: 230 loss: 4.40099575e-06
Iter: 231 loss: 4.36011578e-06
Iter: 232 loss: 4.34226786e-06
Iter: 233 loss: 4.41636848e-06
Iter: 234 loss: 4.33830519e-06
Iter: 235 loss: 4.32419392e-06
Iter: 236 loss: 4.42096734e-06
Iter: 237 loss: 4.3226355e-06
Iter: 238 loss: 4.3121704e-06
Iter: 239 loss: 4.34194362e-06
Iter: 240 loss: 4.30903265e-06
Iter: 241 loss: 4.29565716e-06
Iter: 242 loss: 4.2992865e-06
Iter: 243 loss: 4.28595285e-06
Iter: 244 loss: 4.27318946e-06
Iter: 245 loss: 4.37702e-06
Iter: 246 loss: 4.27241685e-06
Iter: 247 loss: 4.26206225e-06
Iter: 248 loss: 4.25826875e-06
Iter: 249 loss: 4.25249891e-06
Iter: 250 loss: 4.23885558e-06
Iter: 251 loss: 4.36732762e-06
Iter: 252 loss: 4.23842084e-06
Iter: 253 loss: 4.23373103e-06
Iter: 254 loss: 4.23311212e-06
Iter: 255 loss: 4.22794255e-06
Iter: 256 loss: 4.21237883e-06
Iter: 257 loss: 4.26259339e-06
Iter: 258 loss: 4.205e-06
Iter: 259 loss: 4.19275193e-06
Iter: 260 loss: 4.28405156e-06
Iter: 261 loss: 4.19191e-06
Iter: 262 loss: 4.17949559e-06
Iter: 263 loss: 4.17107094e-06
Iter: 264 loss: 4.16648709e-06
Iter: 265 loss: 4.15202157e-06
Iter: 266 loss: 4.23861957e-06
Iter: 267 loss: 4.15018849e-06
Iter: 268 loss: 4.13506314e-06
Iter: 269 loss: 4.19476464e-06
Iter: 270 loss: 4.13169346e-06
Iter: 271 loss: 4.12299141e-06
Iter: 272 loss: 4.18769832e-06
Iter: 273 loss: 4.12217378e-06
Iter: 274 loss: 4.11311885e-06
Iter: 275 loss: 4.1127787e-06
Iter: 276 loss: 4.10586927e-06
Iter: 277 loss: 4.09336644e-06
Iter: 278 loss: 4.18063746e-06
Iter: 279 loss: 4.09224685e-06
Iter: 280 loss: 4.08465121e-06
Iter: 281 loss: 4.08809683e-06
Iter: 282 loss: 4.07961625e-06
Iter: 283 loss: 4.06790969e-06
Iter: 284 loss: 4.08974392e-06
Iter: 285 loss: 4.062882e-06
Iter: 286 loss: 4.05409855e-06
Iter: 287 loss: 4.16080138e-06
Iter: 288 loss: 4.05397668e-06
Iter: 289 loss: 4.04664797e-06
Iter: 290 loss: 4.10692064e-06
Iter: 291 loss: 4.04624188e-06
Iter: 292 loss: 4.04073216e-06
Iter: 293 loss: 4.02855494e-06
Iter: 294 loss: 4.20082415e-06
Iter: 295 loss: 4.02797059e-06
Iter: 296 loss: 4.01958459e-06
Iter: 297 loss: 4.03467448e-06
Iter: 298 loss: 4.01583475e-06
Iter: 299 loss: 4.00345107e-06
Iter: 300 loss: 4.02634714e-06
Iter: 301 loss: 3.99822329e-06
Iter: 302 loss: 3.98881912e-06
Iter: 303 loss: 4.00317413e-06
Iter: 304 loss: 3.98430711e-06
Iter: 305 loss: 3.97209078e-06
Iter: 306 loss: 4.02543219e-06
Iter: 307 loss: 3.96971427e-06
Iter: 308 loss: 3.96042924e-06
Iter: 309 loss: 4.00866611e-06
Iter: 310 loss: 3.95892721e-06
Iter: 311 loss: 3.95113693e-06
Iter: 312 loss: 3.99816236e-06
Iter: 313 loss: 3.95004508e-06
Iter: 314 loss: 3.94378503e-06
Iter: 315 loss: 3.94756353e-06
Iter: 316 loss: 3.93965229e-06
Iter: 317 loss: 3.93066148e-06
Iter: 318 loss: 3.95304869e-06
Iter: 319 loss: 3.92740094e-06
Iter: 320 loss: 3.91962158e-06
Iter: 321 loss: 3.93848541e-06
Iter: 322 loss: 3.91686444e-06
Iter: 323 loss: 3.90993773e-06
Iter: 324 loss: 3.9884535e-06
Iter: 325 loss: 3.90986952e-06
Iter: 326 loss: 3.90344303e-06
Iter: 327 loss: 3.93509799e-06
Iter: 328 loss: 3.90237483e-06
Iter: 329 loss: 3.89889556e-06
Iter: 330 loss: 3.89479555e-06
Iter: 331 loss: 3.89456955e-06
Iter: 332 loss: 3.88756052e-06
Iter: 333 loss: 3.87627733e-06
Iter: 334 loss: 3.87612818e-06
Iter: 335 loss: 3.86814827e-06
Iter: 336 loss: 3.86813144e-06
Iter: 337 loss: 3.85993189e-06
Iter: 338 loss: 3.85075964e-06
Iter: 339 loss: 3.84954456e-06
Iter: 340 loss: 3.84064651e-06
Iter: 341 loss: 3.92673292e-06
Iter: 342 loss: 3.84044506e-06
Iter: 343 loss: 3.83138e-06
Iter: 344 loss: 3.84150098e-06
Iter: 345 loss: 3.82650614e-06
Iter: 346 loss: 3.82058579e-06
Iter: 347 loss: 3.8205485e-06
Iter: 348 loss: 3.81477275e-06
Iter: 349 loss: 3.80600432e-06
Iter: 350 loss: 3.8058854e-06
Iter: 351 loss: 3.79723565e-06
Iter: 352 loss: 3.91545882e-06
Iter: 353 loss: 3.79716175e-06
Iter: 354 loss: 3.79215567e-06
Iter: 355 loss: 3.7956595e-06
Iter: 356 loss: 3.78897494e-06
Iter: 357 loss: 3.78421601e-06
Iter: 358 loss: 3.78414597e-06
Iter: 359 loss: 3.77976698e-06
Iter: 360 loss: 3.78173081e-06
Iter: 361 loss: 3.77684773e-06
Iter: 362 loss: 3.77330343e-06
Iter: 363 loss: 3.7668533e-06
Iter: 364 loss: 3.92077072e-06
Iter: 365 loss: 3.76688149e-06
Iter: 366 loss: 3.75734135e-06
Iter: 367 loss: 3.78787581e-06
Iter: 368 loss: 3.75465788e-06
Iter: 369 loss: 3.74830165e-06
Iter: 370 loss: 3.75622176e-06
Iter: 371 loss: 3.74508136e-06
Iter: 372 loss: 3.7362006e-06
Iter: 373 loss: 3.7561781e-06
Iter: 374 loss: 3.73283274e-06
Iter: 375 loss: 3.72556224e-06
Iter: 376 loss: 3.73698686e-06
Iter: 377 loss: 3.72232489e-06
Iter: 378 loss: 3.71365013e-06
Iter: 379 loss: 3.78007417e-06
Iter: 380 loss: 3.71302622e-06
Iter: 381 loss: 3.70811586e-06
Iter: 382 loss: 3.73564899e-06
Iter: 383 loss: 3.70742828e-06
Iter: 384 loss: 3.70153748e-06
Iter: 385 loss: 3.69854433e-06
Iter: 386 loss: 3.69571239e-06
Iter: 387 loss: 3.69050167e-06
Iter: 388 loss: 3.7609957e-06
Iter: 389 loss: 3.69050963e-06
Iter: 390 loss: 3.6867682e-06
Iter: 391 loss: 3.68672227e-06
Iter: 392 loss: 3.68390465e-06
Iter: 393 loss: 3.67726443e-06
Iter: 394 loss: 3.73303783e-06
Iter: 395 loss: 3.67695156e-06
Iter: 396 loss: 3.67256735e-06
Iter: 397 loss: 3.67237953e-06
Iter: 398 loss: 3.66895256e-06
Iter: 399 loss: 3.66511972e-06
Iter: 400 loss: 3.66101904e-06
Iter: 401 loss: 3.66030372e-06
Iter: 402 loss: 3.65314622e-06
Iter: 403 loss: 3.69086251e-06
Iter: 404 loss: 3.65200913e-06
Iter: 405 loss: 3.64622429e-06
Iter: 406 loss: 3.65395499e-06
Iter: 407 loss: 3.64342e-06
Iter: 408 loss: 3.63761137e-06
Iter: 409 loss: 3.65501955e-06
Iter: 410 loss: 3.63585627e-06
Iter: 411 loss: 3.6293095e-06
Iter: 412 loss: 3.63286063e-06
Iter: 413 loss: 3.62504989e-06
Iter: 414 loss: 3.61850061e-06
Iter: 415 loss: 3.67614393e-06
Iter: 416 loss: 3.61828461e-06
Iter: 417 loss: 3.61271441e-06
Iter: 418 loss: 3.62222363e-06
Iter: 419 loss: 3.61025059e-06
Iter: 420 loss: 3.6047154e-06
Iter: 421 loss: 3.66560062e-06
Iter: 422 loss: 3.60467038e-06
Iter: 423 loss: 3.60121521e-06
Iter: 424 loss: 3.59408091e-06
Iter: 425 loss: 3.71326132e-06
Iter: 426 loss: 3.59382079e-06
Iter: 427 loss: 3.59365231e-06
Iter: 428 loss: 3.58988314e-06
Iter: 429 loss: 3.58720467e-06
Iter: 430 loss: 3.59606247e-06
Iter: 431 loss: 3.58631678e-06
Iter: 432 loss: 3.58432271e-06
Iter: 433 loss: 3.57889712e-06
Iter: 434 loss: 3.61484899e-06
Iter: 435 loss: 3.57760518e-06
Iter: 436 loss: 3.57010094e-06
Iter: 437 loss: 3.62566925e-06
Iter: 438 loss: 3.56957253e-06
Iter: 439 loss: 3.56562214e-06
Iter: 440 loss: 3.57198e-06
Iter: 441 loss: 3.56381088e-06
Iter: 442 loss: 3.55805878e-06
Iter: 443 loss: 3.56248438e-06
Iter: 444 loss: 3.55454949e-06
Iter: 445 loss: 3.54909571e-06
Iter: 446 loss: 3.56150304e-06
Iter: 447 loss: 3.54696203e-06
Iter: 448 loss: 3.54020131e-06
Iter: 449 loss: 3.57069621e-06
Iter: 450 loss: 3.53873656e-06
Iter: 451 loss: 3.5343196e-06
Iter: 452 loss: 3.53631685e-06
Iter: 453 loss: 3.53131486e-06
Iter: 454 loss: 3.5258181e-06
Iter: 455 loss: 3.5889916e-06
Iter: 456 loss: 3.52571351e-06
Iter: 457 loss: 3.52154893e-06
Iter: 458 loss: 3.53464293e-06
Iter: 459 loss: 3.52039797e-06
Iter: 460 loss: 3.51644439e-06
Iter: 461 loss: 3.51301833e-06
Iter: 462 loss: 3.51198059e-06
Iter: 463 loss: 3.51026347e-06
Iter: 464 loss: 3.50816572e-06
Iter: 465 loss: 3.50639698e-06
Iter: 466 loss: 3.50384084e-06
Iter: 467 loss: 3.50385199e-06
Iter: 468 loss: 3.50008258e-06
Iter: 469 loss: 3.49705124e-06
Iter: 470 loss: 3.49600941e-06
Iter: 471 loss: 3.49059019e-06
Iter: 472 loss: 3.51661e-06
Iter: 473 loss: 3.48958247e-06
Iter: 474 loss: 3.4848631e-06
Iter: 475 loss: 3.49753873e-06
Iter: 476 loss: 3.48316098e-06
Iter: 477 loss: 3.4789955e-06
Iter: 478 loss: 3.48698563e-06
Iter: 479 loss: 3.47738796e-06
Iter: 480 loss: 3.47183982e-06
Iter: 481 loss: 3.477684e-06
Iter: 482 loss: 3.46867182e-06
Iter: 483 loss: 3.46320485e-06
Iter: 484 loss: 3.47338391e-06
Iter: 485 loss: 3.46081424e-06
Iter: 486 loss: 3.45380204e-06
Iter: 487 loss: 3.48822823e-06
Iter: 488 loss: 3.45270337e-06
Iter: 489 loss: 3.44880732e-06
Iter: 490 loss: 3.47075593e-06
Iter: 491 loss: 3.44825139e-06
Iter: 492 loss: 3.44341811e-06
Iter: 493 loss: 3.44490218e-06
Iter: 494 loss: 3.44001978e-06
Iter: 495 loss: 3.43738088e-06
Iter: 496 loss: 3.43725e-06
Iter: 497 loss: 3.43463444e-06
Iter: 498 loss: 3.4427876e-06
Iter: 499 loss: 3.43390548e-06
Iter: 500 loss: 3.43160309e-06
Iter: 501 loss: 3.42541398e-06
Iter: 502 loss: 3.46374645e-06
Iter: 503 loss: 3.42375506e-06
Iter: 504 loss: 3.41949499e-06
Iter: 505 loss: 3.419324e-06
Iter: 506 loss: 3.41644864e-06
Iter: 507 loss: 3.41436521e-06
Iter: 508 loss: 3.41343e-06
Iter: 509 loss: 3.40815427e-06
Iter: 510 loss: 3.42352268e-06
Iter: 511 loss: 3.40651127e-06
Iter: 512 loss: 3.40270708e-06
Iter: 513 loss: 3.41217356e-06
Iter: 514 loss: 3.4011714e-06
Iter: 515 loss: 3.39609414e-06
Iter: 516 loss: 3.40696079e-06
Iter: 517 loss: 3.39401959e-06
Iter: 518 loss: 3.39061762e-06
Iter: 519 loss: 3.38963946e-06
Iter: 520 loss: 3.3874428e-06
Iter: 521 loss: 3.38207656e-06
Iter: 522 loss: 3.43634156e-06
Iter: 523 loss: 3.38190375e-06
Iter: 524 loss: 3.3788e-06
Iter: 525 loss: 3.39314329e-06
Iter: 526 loss: 3.37817983e-06
Iter: 527 loss: 3.37417214e-06
Iter: 528 loss: 3.37492565e-06
Iter: 529 loss: 3.37116671e-06
Iter: 530 loss: 3.37021493e-06
Iter: 531 loss: 3.3688184e-06
Iter: 532 loss: 3.36721473e-06
Iter: 533 loss: 3.36399353e-06
Iter: 534 loss: 3.41921168e-06
Iter: 535 loss: 3.36397e-06
Iter: 536 loss: 3.36075527e-06
Iter: 537 loss: 3.36476705e-06
Iter: 538 loss: 3.35904815e-06
Iter: 539 loss: 3.35573441e-06
Iter: 540 loss: 3.36436642e-06
Iter: 541 loss: 3.35452796e-06
Iter: 542 loss: 3.35030018e-06
Iter: 543 loss: 3.36190215e-06
Iter: 544 loss: 3.34896231e-06
Iter: 545 loss: 3.34540255e-06
Iter: 546 loss: 3.34658762e-06
Iter: 547 loss: 3.34295851e-06
Iter: 548 loss: 3.33815206e-06
Iter: 549 loss: 3.36694552e-06
Iter: 550 loss: 3.33759726e-06
Iter: 551 loss: 3.33440153e-06
Iter: 552 loss: 3.33788603e-06
Iter: 553 loss: 3.33262687e-06
Iter: 554 loss: 3.32793388e-06
Iter: 555 loss: 3.3379763e-06
Iter: 556 loss: 3.32603895e-06
Iter: 557 loss: 3.32218679e-06
Iter: 558 loss: 3.33423077e-06
Iter: 559 loss: 3.32104059e-06
Iter: 560 loss: 3.31649471e-06
Iter: 561 loss: 3.32752279e-06
Iter: 562 loss: 3.31492788e-06
Iter: 563 loss: 3.31243291e-06
Iter: 564 loss: 3.31219076e-06
Iter: 565 loss: 3.31061142e-06
Iter: 566 loss: 3.32180593e-06
Iter: 567 loss: 3.31052183e-06
Iter: 568 loss: 3.30890862e-06
Iter: 569 loss: 3.3046108e-06
Iter: 570 loss: 3.33286243e-06
Iter: 571 loss: 3.30359489e-06
Iter: 572 loss: 3.30001694e-06
Iter: 573 loss: 3.32046557e-06
Iter: 574 loss: 3.29952218e-06
Iter: 575 loss: 3.29558929e-06
Iter: 576 loss: 3.29316481e-06
Iter: 577 loss: 3.29169461e-06
Iter: 578 loss: 3.28847955e-06
Iter: 579 loss: 3.28816532e-06
Iter: 580 loss: 3.28605347e-06
Iter: 581 loss: 3.28119177e-06
Iter: 582 loss: 3.34409037e-06
Iter: 583 loss: 3.28076021e-06
Iter: 584 loss: 3.27731277e-06
Iter: 585 loss: 3.27713883e-06
Iter: 586 loss: 3.27468979e-06
Iter: 587 loss: 3.27276712e-06
Iter: 588 loss: 3.27207e-06
Iter: 589 loss: 3.2683788e-06
Iter: 590 loss: 3.29771183e-06
Iter: 591 loss: 3.26816871e-06
Iter: 592 loss: 3.26519103e-06
Iter: 593 loss: 3.26522968e-06
Iter: 594 loss: 3.26287363e-06
Iter: 595 loss: 3.25894371e-06
Iter: 596 loss: 3.30044236e-06
Iter: 597 loss: 3.25889096e-06
Iter: 598 loss: 3.25706833e-06
Iter: 599 loss: 3.25705241e-06
Iter: 600 loss: 3.25560609e-06
Iter: 601 loss: 3.25603287e-06
Iter: 602 loss: 3.25449764e-06
Iter: 603 loss: 3.25213182e-06
Iter: 604 loss: 3.24805751e-06
Iter: 605 loss: 3.24803341e-06
Iter: 606 loss: 3.2445846e-06
Iter: 607 loss: 3.2531691e-06
Iter: 608 loss: 3.24343409e-06
Iter: 609 loss: 3.23909239e-06
Iter: 610 loss: 3.24708299e-06
Iter: 611 loss: 3.23718245e-06
Iter: 612 loss: 3.23348718e-06
Iter: 613 loss: 3.27300336e-06
Iter: 614 loss: 3.23339373e-06
Iter: 615 loss: 3.23038807e-06
Iter: 616 loss: 3.22982032e-06
Iter: 617 loss: 3.22783035e-06
Iter: 618 loss: 3.22415235e-06
Iter: 619 loss: 3.23105064e-06
Iter: 620 loss: 3.22253936e-06
Iter: 621 loss: 3.21855623e-06
Iter: 622 loss: 3.24277653e-06
Iter: 623 loss: 3.21800508e-06
Iter: 624 loss: 3.21500443e-06
Iter: 625 loss: 3.21610923e-06
Iter: 626 loss: 3.21284688e-06
Iter: 627 loss: 3.20899085e-06
Iter: 628 loss: 3.24165285e-06
Iter: 629 loss: 3.20875552e-06
Iter: 630 loss: 3.20691015e-06
Iter: 631 loss: 3.22510846e-06
Iter: 632 loss: 3.20680169e-06
Iter: 633 loss: 3.20460776e-06
Iter: 634 loss: 3.2090411e-06
Iter: 635 loss: 3.20366689e-06
Iter: 636 loss: 3.20158824e-06
Iter: 637 loss: 3.20523031e-06
Iter: 638 loss: 3.20053823e-06
Iter: 639 loss: 3.19880519e-06
Iter: 640 loss: 3.19725723e-06
Iter: 641 loss: 3.19674882e-06
Iter: 642 loss: 3.19324704e-06
Iter: 643 loss: 3.19215269e-06
Iter: 644 loss: 3.19010041e-06
Iter: 645 loss: 3.18726143e-06
Iter: 646 loss: 3.18716525e-06
Iter: 647 loss: 3.18470484e-06
Iter: 648 loss: 3.18219327e-06
Iter: 649 loss: 3.18163552e-06
Iter: 650 loss: 3.17802142e-06
Iter: 651 loss: 3.23249e-06
Iter: 652 loss: 3.17798e-06
Iter: 653 loss: 3.17620629e-06
Iter: 654 loss: 3.1727e-06
Iter: 655 loss: 3.2481139e-06
Iter: 656 loss: 3.17257263e-06
Iter: 657 loss: 3.16847809e-06
Iter: 658 loss: 3.21239304e-06
Iter: 659 loss: 3.16828277e-06
Iter: 660 loss: 3.16566911e-06
Iter: 661 loss: 3.16300498e-06
Iter: 662 loss: 3.16244586e-06
Iter: 663 loss: 3.15929765e-06
Iter: 664 loss: 3.15921852e-06
Iter: 665 loss: 3.15814282e-06
Iter: 666 loss: 3.15795705e-06
Iter: 667 loss: 3.15692387e-06
Iter: 668 loss: 3.15405305e-06
Iter: 669 loss: 3.17735453e-06
Iter: 670 loss: 3.15357056e-06
Iter: 671 loss: 3.15057468e-06
Iter: 672 loss: 3.18090497e-06
Iter: 673 loss: 3.15052785e-06
Iter: 674 loss: 3.14885347e-06
Iter: 675 loss: 3.14889189e-06
Iter: 676 loss: 3.14761724e-06
Iter: 677 loss: 3.14498129e-06
Iter: 678 loss: 3.1458037e-06
Iter: 679 loss: 3.14321619e-06
Iter: 680 loss: 3.14023055e-06
Iter: 681 loss: 3.15041166e-06
Iter: 682 loss: 3.13945702e-06
Iter: 683 loss: 3.13662895e-06
Iter: 684 loss: 3.15130023e-06
Iter: 685 loss: 3.13613441e-06
Iter: 686 loss: 3.13335295e-06
Iter: 687 loss: 3.13947112e-06
Iter: 688 loss: 3.13238479e-06
Iter: 689 loss: 3.12929114e-06
Iter: 690 loss: 3.13109467e-06
Iter: 691 loss: 3.12735938e-06
Iter: 692 loss: 3.12437305e-06
Iter: 693 loss: 3.12818497e-06
Iter: 694 loss: 3.12277803e-06
Iter: 695 loss: 3.12013935e-06
Iter: 696 loss: 3.15599709e-06
Iter: 697 loss: 3.1201339e-06
Iter: 698 loss: 3.11831695e-06
Iter: 699 loss: 3.13081591e-06
Iter: 700 loss: 3.11821532e-06
Iter: 701 loss: 3.11606846e-06
Iter: 702 loss: 3.12151542e-06
Iter: 703 loss: 3.11532449e-06
Iter: 704 loss: 3.11378017e-06
Iter: 705 loss: 3.115146e-06
Iter: 706 loss: 3.11289614e-06
Iter: 707 loss: 3.11135364e-06
Iter: 708 loss: 3.1124157e-06
Iter: 709 loss: 3.11034819e-06
Iter: 710 loss: 3.10780888e-06
Iter: 711 loss: 3.10823862e-06
Iter: 712 loss: 3.10592304e-06
Iter: 713 loss: 3.10355199e-06
Iter: 714 loss: 3.10655355e-06
Iter: 715 loss: 3.10242535e-06
Iter: 716 loss: 3.0990127e-06
Iter: 717 loss: 3.10987275e-06
Iter: 718 loss: 3.09809047e-06
Iter: 719 loss: 3.09579536e-06
Iter: 720 loss: 3.10545192e-06
Iter: 721 loss: 3.09530719e-06
Iter: 722 loss: 3.09243705e-06
Iter: 723 loss: 3.09569032e-06
Iter: 724 loss: 3.09085e-06
Iter: 725 loss: 3.08845961e-06
Iter: 726 loss: 3.09381812e-06
Iter: 727 loss: 3.08752124e-06
Iter: 728 loss: 3.08436029e-06
Iter: 729 loss: 3.08583731e-06
Iter: 730 loss: 3.08229482e-06
Iter: 731 loss: 3.07944833e-06
Iter: 732 loss: 3.11136819e-06
Iter: 733 loss: 3.07943787e-06
Iter: 734 loss: 3.07774371e-06
Iter: 735 loss: 3.07771984e-06
Iter: 736 loss: 3.07605524e-06
Iter: 737 loss: 3.07328833e-06
Iter: 738 loss: 3.07327468e-06
Iter: 739 loss: 3.07165465e-06
Iter: 740 loss: 3.08862286e-06
Iter: 741 loss: 3.07157893e-06
Iter: 742 loss: 3.0702015e-06
Iter: 743 loss: 3.06768925e-06
Iter: 744 loss: 3.06765719e-06
Iter: 745 loss: 3.06458742e-06
Iter: 746 loss: 3.0840265e-06
Iter: 747 loss: 3.06427728e-06
Iter: 748 loss: 3.06196375e-06
Iter: 749 loss: 3.06492734e-06
Iter: 750 loss: 3.06071161e-06
Iter: 751 loss: 3.05834146e-06
Iter: 752 loss: 3.06555057e-06
Iter: 753 loss: 3.05763501e-06
Iter: 754 loss: 3.05482627e-06
Iter: 755 loss: 3.05680555e-06
Iter: 756 loss: 3.05315984e-06
Iter: 757 loss: 3.0507822e-06
Iter: 758 loss: 3.08567633e-06
Iter: 759 loss: 3.05074036e-06
Iter: 760 loss: 3.04874038e-06
Iter: 761 loss: 3.04638797e-06
Iter: 762 loss: 3.04607056e-06
Iter: 763 loss: 3.0434428e-06
Iter: 764 loss: 3.06057632e-06
Iter: 765 loss: 3.04321338e-06
Iter: 766 loss: 3.04044238e-06
Iter: 767 loss: 3.03819411e-06
Iter: 768 loss: 3.03734191e-06
Iter: 769 loss: 3.04235982e-06
Iter: 770 loss: 3.0362819e-06
Iter: 771 loss: 3.03541856e-06
Iter: 772 loss: 3.03325578e-06
Iter: 773 loss: 3.05099093e-06
Iter: 774 loss: 3.03273873e-06
Iter: 775 loss: 3.0300198e-06
Iter: 776 loss: 3.03812931e-06
Iter: 777 loss: 3.02941498e-06
Iter: 778 loss: 3.02756962e-06
Iter: 779 loss: 3.04759374e-06
Iter: 780 loss: 3.02753779e-06
Iter: 781 loss: 3.02611147e-06
Iter: 782 loss: 3.02326816e-06
Iter: 783 loss: 3.0770409e-06
Iter: 784 loss: 3.02310127e-06
Iter: 785 loss: 3.02032686e-06
Iter: 786 loss: 3.05466483e-06
Iter: 787 loss: 3.02033163e-06
Iter: 788 loss: 3.01853106e-06
Iter: 789 loss: 3.01522e-06
Iter: 790 loss: 3.09562165e-06
Iter: 791 loss: 3.01521663e-06
Iter: 792 loss: 3.01281534e-06
Iter: 793 loss: 3.01265459e-06
Iter: 794 loss: 3.01064119e-06
Iter: 795 loss: 3.01023942e-06
Iter: 796 loss: 3.0089036e-06
Iter: 797 loss: 3.00603324e-06
Iter: 798 loss: 3.02566605e-06
Iter: 799 loss: 3.00582042e-06
Iter: 800 loss: 3.00386841e-06
Iter: 801 loss: 3.00170768e-06
Iter: 802 loss: 3.00135207e-06
Iter: 803 loss: 2.99892645e-06
Iter: 804 loss: 2.99896237e-06
Iter: 805 loss: 2.99791236e-06
Iter: 806 loss: 2.99789713e-06
Iter: 807 loss: 2.9967573e-06
Iter: 808 loss: 2.99525573e-06
Iter: 809 loss: 2.99509566e-06
Iter: 810 loss: 2.99350904e-06
Iter: 811 loss: 2.99321164e-06
Iter: 812 loss: 2.99203748e-06
Iter: 813 loss: 2.9900757e-06
Iter: 814 loss: 3.00599595e-06
Iter: 815 loss: 2.98996338e-06
Iter: 816 loss: 2.98815576e-06
Iter: 817 loss: 2.99153908e-06
Iter: 818 loss: 2.98749046e-06
Iter: 819 loss: 2.9857581e-06
Iter: 820 loss: 2.98351597e-06
Iter: 821 loss: 2.9834423e-06
Iter: 822 loss: 2.98045825e-06
Iter: 823 loss: 3.00590273e-06
Iter: 824 loss: 2.98026589e-06
Iter: 825 loss: 2.97813e-06
Iter: 826 loss: 2.97664701e-06
Iter: 827 loss: 2.97591873e-06
Iter: 828 loss: 2.9735761e-06
Iter: 829 loss: 2.9736002e-06
Iter: 830 loss: 2.97177212e-06
Iter: 831 loss: 2.97232236e-06
Iter: 832 loss: 2.97060888e-06
Iter: 833 loss: 2.96805933e-06
Iter: 834 loss: 2.98135024e-06
Iter: 835 loss: 2.96764256e-06
Iter: 836 loss: 2.96585677e-06
Iter: 837 loss: 2.96586927e-06
Iter: 838 loss: 2.96438975e-06
Iter: 839 loss: 2.96163262e-06
Iter: 840 loss: 2.97628776e-06
Iter: 841 loss: 2.96127e-06
Iter: 842 loss: 2.9608027e-06
Iter: 843 loss: 2.96014036e-06
Iter: 844 loss: 2.95967834e-06
Iter: 845 loss: 2.95811469e-06
Iter: 846 loss: 2.95948735e-06
Iter: 847 loss: 2.95689e-06
Iter: 848 loss: 2.95419204e-06
Iter: 849 loss: 2.97088854e-06
Iter: 850 loss: 2.95388509e-06
Iter: 851 loss: 2.95187442e-06
Iter: 852 loss: 2.95388691e-06
Iter: 853 loss: 2.95077e-06
Iter: 854 loss: 2.94792289e-06
Iter: 855 loss: 2.9606108e-06
Iter: 856 loss: 2.94744586e-06
Iter: 857 loss: 2.94608162e-06
Iter: 858 loss: 2.96501048e-06
Iter: 859 loss: 2.94606548e-06
Iter: 860 loss: 2.94494544e-06
Iter: 861 loss: 2.94201345e-06
Iter: 862 loss: 2.97542283e-06
Iter: 863 loss: 2.94182973e-06
Iter: 864 loss: 2.93916082e-06
Iter: 865 loss: 2.95775908e-06
Iter: 866 loss: 2.93895437e-06
Iter: 867 loss: 2.93655239e-06
Iter: 868 loss: 2.93918356e-06
Iter: 869 loss: 2.93503035e-06
Iter: 870 loss: 2.93291964e-06
Iter: 871 loss: 2.94969595e-06
Iter: 872 loss: 2.9327507e-06
Iter: 873 loss: 2.93066296e-06
Iter: 874 loss: 2.92999403e-06
Iter: 875 loss: 2.92883192e-06
Iter: 876 loss: 2.92882896e-06
Iter: 877 loss: 2.92771097e-06
Iter: 878 loss: 2.92654431e-06
Iter: 879 loss: 2.92614595e-06
Iter: 880 loss: 2.92549748e-06
Iter: 881 loss: 2.92401296e-06
Iter: 882 loss: 2.92434788e-06
Iter: 883 loss: 2.92287268e-06
Iter: 884 loss: 2.92106756e-06
Iter: 885 loss: 2.92093773e-06
Iter: 886 loss: 2.91948163e-06
Iter: 887 loss: 2.91701235e-06
Iter: 888 loss: 2.93241897e-06
Iter: 889 loss: 2.91679544e-06
Iter: 890 loss: 2.91488482e-06
Iter: 891 loss: 2.91403467e-06
Iter: 892 loss: 2.91316951e-06
Iter: 893 loss: 2.91133051e-06
Iter: 894 loss: 2.91124184e-06
Iter: 895 loss: 2.91005949e-06
Iter: 896 loss: 2.90822845e-06
Iter: 897 loss: 2.90829803e-06
Iter: 898 loss: 2.90549906e-06
Iter: 899 loss: 2.913348e-06
Iter: 900 loss: 2.90467e-06
Iter: 901 loss: 2.90257549e-06
Iter: 902 loss: 2.91194419e-06
Iter: 903 loss: 2.90215053e-06
Iter: 904 loss: 2.89977947e-06
Iter: 905 loss: 2.89864192e-06
Iter: 906 loss: 2.89751256e-06
Iter: 907 loss: 2.89544596e-06
Iter: 908 loss: 2.91577089e-06
Iter: 909 loss: 2.89534e-06
Iter: 910 loss: 2.89408445e-06
Iter: 911 loss: 2.9148714e-06
Iter: 912 loss: 2.89407035e-06
Iter: 913 loss: 2.89238233e-06
Iter: 914 loss: 2.89194122e-06
Iter: 915 loss: 2.89104628e-06
Iter: 916 loss: 2.88990782e-06
Iter: 917 loss: 2.88751562e-06
Iter: 918 loss: 2.92117215e-06
Iter: 919 loss: 2.88737237e-06
Iter: 920 loss: 2.8846066e-06
Iter: 921 loss: 2.91441074e-06
Iter: 922 loss: 2.88458955e-06
Iter: 923 loss: 2.88290585e-06
Iter: 924 loss: 2.8844488e-06
Iter: 925 loss: 2.88194178e-06
Iter: 926 loss: 2.87927742e-06
Iter: 927 loss: 2.88697265e-06
Iter: 928 loss: 2.8785314e-06
Iter: 929 loss: 2.87650664e-06
Iter: 930 loss: 2.88479896e-06
Iter: 931 loss: 2.87615e-06
Iter: 932 loss: 2.87407829e-06
Iter: 933 loss: 2.87983357e-06
Iter: 934 loss: 2.87342505e-06
Iter: 935 loss: 2.871677e-06
Iter: 936 loss: 2.88029946e-06
Iter: 937 loss: 2.87140301e-06
Iter: 938 loss: 2.8699792e-06
Iter: 939 loss: 2.86853083e-06
Iter: 940 loss: 2.86828254e-06
Iter: 941 loss: 2.86611203e-06
Iter: 942 loss: 2.87466628e-06
Iter: 943 loss: 2.86577415e-06
Iter: 944 loss: 2.86354839e-06
Iter: 945 loss: 2.87300782e-06
Iter: 946 loss: 2.86316026e-06
Iter: 947 loss: 2.86237855e-06
Iter: 948 loss: 2.86226259e-06
Iter: 949 loss: 2.86124896e-06
Iter: 950 loss: 2.8601371e-06
Iter: 951 loss: 2.85999545e-06
Iter: 952 loss: 2.85840269e-06
Iter: 953 loss: 2.85766032e-06
Iter: 954 loss: 2.85691158e-06
Iter: 955 loss: 2.85508759e-06
Iter: 956 loss: 2.85477245e-06
Iter: 957 loss: 2.85360466e-06
Iter: 958 loss: 2.85076521e-06
Iter: 959 loss: 2.87201146e-06
Iter: 960 loss: 2.85052511e-06
Iter: 961 loss: 2.8487957e-06
Iter: 962 loss: 2.85190481e-06
Iter: 963 loss: 2.84803514e-06
Iter: 964 loss: 2.84573753e-06
Iter: 965 loss: 2.85876195e-06
Iter: 966 loss: 2.84545922e-06
Iter: 967 loss: 2.84417501e-06
Iter: 968 loss: 2.84672069e-06
Iter: 969 loss: 2.84360476e-06
Iter: 970 loss: 2.84178395e-06
Iter: 971 loss: 2.84356202e-06
Iter: 972 loss: 2.84071848e-06
Iter: 973 loss: 2.83904228e-06
Iter: 974 loss: 2.85598662e-06
Iter: 975 loss: 2.83895406e-06
Iter: 976 loss: 2.83768759e-06
Iter: 977 loss: 2.8351742e-06
Iter: 978 loss: 2.87818693e-06
Iter: 979 loss: 2.83509212e-06
Iter: 980 loss: 2.83262239e-06
Iter: 981 loss: 2.86988507e-06
Iter: 982 loss: 2.83260988e-06
Iter: 983 loss: 2.83119789e-06
Iter: 984 loss: 2.8310476e-06
Iter: 985 loss: 2.83008239e-06
Iter: 986 loss: 2.82975202e-06
Iter: 987 loss: 2.8290483e-06
Iter: 988 loss: 2.82830024e-06
Iter: 989 loss: 2.82764677e-06
Iter: 990 loss: 2.82745054e-06
Iter: 991 loss: 2.82649876e-06
Iter: 992 loss: 2.82439487e-06
Iter: 993 loss: 2.85697797e-06
Iter: 994 loss: 2.82426618e-06
Iter: 995 loss: 2.8217969e-06
Iter: 996 loss: 2.83515556e-06
Iter: 997 loss: 2.82143196e-06
Iter: 998 loss: 2.8193358e-06
Iter: 999 loss: 2.826328e-06
Iter: 1000 loss: 2.81868552e-06
Iter: 1001 loss: 2.81679763e-06
Iter: 1002 loss: 2.82127621e-06
Iter: 1003 loss: 2.81609482e-06
Iter: 1004 loss: 2.81389703e-06
Iter: 1005 loss: 2.82860765e-06
Iter: 1006 loss: 2.81376742e-06
Iter: 1007 loss: 2.81244183e-06
Iter: 1008 loss: 2.81639905e-06
Iter: 1009 loss: 2.81208577e-06
Iter: 1010 loss: 2.8106374e-06
Iter: 1011 loss: 2.81081e-06
Iter: 1012 loss: 2.8094496e-06
Iter: 1013 loss: 2.80710719e-06
Iter: 1014 loss: 2.81678945e-06
Iter: 1015 loss: 2.80664608e-06
Iter: 1016 loss: 2.80506492e-06
Iter: 1017 loss: 2.80487939e-06
Iter: 1018 loss: 2.80377708e-06
Iter: 1019 loss: 2.80152244e-06
Iter: 1020 loss: 2.81705798e-06
Iter: 1021 loss: 2.80133236e-06
Iter: 1022 loss: 2.80010545e-06
Iter: 1023 loss: 2.80245399e-06
Iter: 1024 loss: 2.79957726e-06
Iter: 1025 loss: 2.79764549e-06
Iter: 1026 loss: 2.80733479e-06
Iter: 1027 loss: 2.79723145e-06
Iter: 1028 loss: 2.79603182e-06
Iter: 1029 loss: 2.79608798e-06
Iter: 1030 loss: 2.79514552e-06
Iter: 1031 loss: 2.79417281e-06
Iter: 1032 loss: 2.79265169e-06
Iter: 1033 loss: 2.79255096e-06
Iter: 1034 loss: 2.79031065e-06
Iter: 1035 loss: 2.80243898e-06
Iter: 1036 loss: 2.79000778e-06
Iter: 1037 loss: 2.78838525e-06
Iter: 1038 loss: 2.78978064e-06
Iter: 1039 loss: 2.78758239e-06
Iter: 1040 loss: 2.78549669e-06
Iter: 1041 loss: 2.79835695e-06
Iter: 1042 loss: 2.78522634e-06
Iter: 1043 loss: 2.78386528e-06
Iter: 1044 loss: 2.79020287e-06
Iter: 1045 loss: 2.78350672e-06
Iter: 1046 loss: 2.78194352e-06
Iter: 1047 loss: 2.7825904e-06
Iter: 1048 loss: 2.78096149e-06
Iter: 1049 loss: 2.77936761e-06
Iter: 1050 loss: 2.79367441e-06
Iter: 1051 loss: 2.77925301e-06
Iter: 1052 loss: 2.77793697e-06
Iter: 1053 loss: 2.77683853e-06
Iter: 1054 loss: 2.77640629e-06
Iter: 1055 loss: 2.77448203e-06
Iter: 1056 loss: 2.78382549e-06
Iter: 1057 loss: 2.7741753e-06
Iter: 1058 loss: 2.77241452e-06
Iter: 1059 loss: 2.77505683e-06
Iter: 1060 loss: 2.77164645e-06
Iter: 1061 loss: 2.76997662e-06
Iter: 1062 loss: 2.77620211e-06
Iter: 1063 loss: 2.76963056e-06
Iter: 1064 loss: 2.76838273e-06
Iter: 1065 loss: 2.76839137e-06
Iter: 1066 loss: 2.76730111e-06
Iter: 1067 loss: 2.76576839e-06
Iter: 1068 loss: 2.76572018e-06
Iter: 1069 loss: 2.76435139e-06
Iter: 1070 loss: 2.76473611e-06
Iter: 1071 loss: 2.76345236e-06
Iter: 1072 loss: 2.76143123e-06
Iter: 1073 loss: 2.76554829e-06
Iter: 1074 loss: 2.76051151e-06
Iter: 1075 loss: 2.75913453e-06
Iter: 1076 loss: 2.76180413e-06
Iter: 1077 loss: 2.75845605e-06
Iter: 1078 loss: 2.75647176e-06
Iter: 1079 loss: 2.76215269e-06
Iter: 1080 loss: 2.75580783e-06
Iter: 1081 loss: 2.75434058e-06
Iter: 1082 loss: 2.76774153e-06
Iter: 1083 loss: 2.75420507e-06
Iter: 1084 loss: 2.75273806e-06
Iter: 1085 loss: 2.75157845e-06
Iter: 1086 loss: 2.75107323e-06
Iter: 1087 loss: 2.74966828e-06
Iter: 1088 loss: 2.74968806e-06
Iter: 1089 loss: 2.74880108e-06
Iter: 1090 loss: 2.74779427e-06
Iter: 1091 loss: 2.74763443e-06
Iter: 1092 loss: 2.74565127e-06
Iter: 1093 loss: 2.74920922e-06
Iter: 1094 loss: 2.74471859e-06
Iter: 1095 loss: 2.74316858e-06
Iter: 1096 loss: 2.7464871e-06
Iter: 1097 loss: 2.74255558e-06
Iter: 1098 loss: 2.74055014e-06
Iter: 1099 loss: 2.74738204e-06
Iter: 1100 loss: 2.73995306e-06
Iter: 1101 loss: 2.73957949e-06
Iter: 1102 loss: 2.73924616e-06
Iter: 1103 loss: 2.7385131e-06
Iter: 1104 loss: 2.73716569e-06
Iter: 1105 loss: 2.73720457e-06
Iter: 1106 loss: 2.73586784e-06
Iter: 1107 loss: 2.73677165e-06
Iter: 1108 loss: 2.7349422e-06
Iter: 1109 loss: 2.73337355e-06
Iter: 1110 loss: 2.73431169e-06
Iter: 1111 loss: 2.73239402e-06
Iter: 1112 loss: 2.73022215e-06
Iter: 1113 loss: 2.73981414e-06
Iter: 1114 loss: 2.7299302e-06
Iter: 1115 loss: 2.72846137e-06
Iter: 1116 loss: 2.73044589e-06
Iter: 1117 loss: 2.72775424e-06
Iter: 1118 loss: 2.72588022e-06
Iter: 1119 loss: 2.73573937e-06
Iter: 1120 loss: 2.72554462e-06
Iter: 1121 loss: 2.72385296e-06
Iter: 1122 loss: 2.7281485e-06
Iter: 1123 loss: 2.72328862e-06
Iter: 1124 loss: 2.72166244e-06
Iter: 1125 loss: 2.72755733e-06
Iter: 1126 loss: 2.72135753e-06
Iter: 1127 loss: 2.71996055e-06
Iter: 1128 loss: 2.72481839e-06
Iter: 1129 loss: 2.71959834e-06
Iter: 1130 loss: 2.71809768e-06
Iter: 1131 loss: 2.71704766e-06
Iter: 1132 loss: 2.71648878e-06
Iter: 1133 loss: 2.71508361e-06
Iter: 1134 loss: 2.72513603e-06
Iter: 1135 loss: 2.7148817e-06
Iter: 1136 loss: 2.71338104e-06
Iter: 1137 loss: 2.71424142e-06
Iter: 1138 loss: 2.71239242e-06
Iter: 1139 loss: 2.71172303e-06
Iter: 1140 loss: 2.7111837e-06
Iter: 1141 loss: 2.71076806e-06
Iter: 1142 loss: 2.70986311e-06
Iter: 1143 loss: 2.72458828e-06
Iter: 1144 loss: 2.70989631e-06
Iter: 1145 loss: 2.70874943e-06
Iter: 1146 loss: 2.70751184e-06
Iter: 1147 loss: 2.70727787e-06
Iter: 1148 loss: 2.70572514e-06
Iter: 1149 loss: 2.71829504e-06
Iter: 1150 loss: 2.7056376e-06
Iter: 1151 loss: 2.70401938e-06
Iter: 1152 loss: 2.70293367e-06
Iter: 1153 loss: 2.70239957e-06
Iter: 1154 loss: 2.70062947e-06
Iter: 1155 loss: 2.72082207e-06
Iter: 1156 loss: 2.70059945e-06
Iter: 1157 loss: 2.69914426e-06
Iter: 1158 loss: 2.69916768e-06
Iter: 1159 loss: 2.69802445e-06
Iter: 1160 loss: 2.69656834e-06
Iter: 1161 loss: 2.69655e-06
Iter: 1162 loss: 2.69576208e-06
Iter: 1163 loss: 2.6948419e-06
Iter: 1164 loss: 2.6947107e-06
Iter: 1165 loss: 2.69292696e-06
Iter: 1166 loss: 2.69965e-06
Iter: 1167 loss: 2.69255634e-06
Iter: 1168 loss: 2.69140401e-06
Iter: 1169 loss: 2.69427528e-06
Iter: 1170 loss: 2.69095517e-06
Iter: 1171 loss: 2.68978374e-06
Iter: 1172 loss: 2.6918533e-06
Iter: 1173 loss: 2.68921622e-06
Iter: 1174 loss: 2.68815984e-06
Iter: 1175 loss: 2.68816166e-06
Iter: 1176 loss: 2.68766871e-06
Iter: 1177 loss: 2.68659414e-06
Iter: 1178 loss: 2.69694033e-06
Iter: 1179 loss: 2.68643589e-06
Iter: 1180 loss: 2.685053e-06
Iter: 1181 loss: 2.6891903e-06
Iter: 1182 loss: 2.68457916e-06
Iter: 1183 loss: 2.68316603e-06
Iter: 1184 loss: 2.68277427e-06
Iter: 1185 loss: 2.68182066e-06
Iter: 1186 loss: 2.68002304e-06
Iter: 1187 loss: 2.69584189e-06
Iter: 1188 loss: 2.67989071e-06
Iter: 1189 loss: 2.67832615e-06
Iter: 1190 loss: 2.67841097e-06
Iter: 1191 loss: 2.67704127e-06
Iter: 1192 loss: 2.67543692e-06
Iter: 1193 loss: 2.69440807e-06
Iter: 1194 loss: 2.67537303e-06
Iter: 1195 loss: 2.67409746e-06
Iter: 1196 loss: 2.67570749e-06
Iter: 1197 loss: 2.67342148e-06
Iter: 1198 loss: 2.67177e-06
Iter: 1199 loss: 2.67895257e-06
Iter: 1200 loss: 2.67152632e-06
Iter: 1201 loss: 2.67042606e-06
Iter: 1202 loss: 2.67448445e-06
Iter: 1203 loss: 2.67027895e-06
Iter: 1204 loss: 2.66907296e-06
Iter: 1205 loss: 2.668045e-06
Iter: 1206 loss: 2.66777306e-06
Iter: 1207 loss: 2.66639859e-06
Iter: 1208 loss: 2.68032818e-06
Iter: 1209 loss: 2.66635607e-06
Iter: 1210 loss: 2.66543475e-06
Iter: 1211 loss: 2.66936831e-06
Iter: 1212 loss: 2.66520601e-06
Iter: 1213 loss: 2.6636942e-06
Iter: 1214 loss: 2.66404936e-06
Iter: 1215 loss: 2.66258621e-06
Iter: 1216 loss: 2.66177494e-06
Iter: 1217 loss: 2.66160123e-06
Iter: 1218 loss: 2.66106463e-06
Iter: 1219 loss: 2.65963376e-06
Iter: 1220 loss: 2.66019106e-06
Iter: 1221 loss: 2.65863264e-06
Iter: 1222 loss: 2.65707558e-06
Iter: 1223 loss: 2.66756251e-06
Iter: 1224 loss: 2.65697486e-06
Iter: 1225 loss: 2.65557628e-06
Iter: 1226 loss: 2.65542781e-06
Iter: 1227 loss: 2.65445988e-06
Iter: 1228 loss: 2.65290782e-06
Iter: 1229 loss: 2.66192478e-06
Iter: 1230 loss: 2.65264066e-06
Iter: 1231 loss: 2.65115204e-06
Iter: 1232 loss: 2.65638869e-06
Iter: 1233 loss: 2.65076642e-06
Iter: 1234 loss: 2.64942082e-06
Iter: 1235 loss: 2.65467702e-06
Iter: 1236 loss: 2.64924165e-06
Iter: 1237 loss: 2.64777827e-06
Iter: 1238 loss: 2.65012295e-06
Iter: 1239 loss: 2.64704136e-06
Iter: 1240 loss: 2.64600499e-06
Iter: 1241 loss: 2.65367225e-06
Iter: 1242 loss: 2.64586879e-06
Iter: 1243 loss: 2.64491928e-06
Iter: 1244 loss: 2.64422351e-06
Iter: 1245 loss: 2.64385108e-06
Iter: 1246 loss: 2.64266964e-06
Iter: 1247 loss: 2.64268647e-06
Iter: 1248 loss: 2.64166465e-06
Iter: 1249 loss: 2.64258597e-06
Iter: 1250 loss: 2.64102891e-06
Iter: 1251 loss: 2.64028176e-06
Iter: 1252 loss: 2.63841457e-06
Iter: 1253 loss: 2.65611334e-06
Iter: 1254 loss: 2.63821335e-06
Iter: 1255 loss: 2.63650486e-06
Iter: 1256 loss: 2.66033703e-06
Iter: 1257 loss: 2.63645734e-06
Iter: 1258 loss: 2.63511356e-06
Iter: 1259 loss: 2.63447828e-06
Iter: 1260 loss: 2.63391212e-06
Iter: 1261 loss: 2.63209017e-06
Iter: 1262 loss: 2.6520579e-06
Iter: 1263 loss: 2.63207266e-06
Iter: 1264 loss: 2.63091943e-06
Iter: 1265 loss: 2.62929552e-06
Iter: 1266 loss: 2.62918775e-06
Iter: 1267 loss: 2.62764911e-06
Iter: 1268 loss: 2.62764888e-06
Iter: 1269 loss: 2.62655431e-06
Iter: 1270 loss: 2.62823e-06
Iter: 1271 loss: 2.62597723e-06
Iter: 1272 loss: 2.62441745e-06
Iter: 1273 loss: 2.62857543e-06
Iter: 1274 loss: 2.62387357e-06
Iter: 1275 loss: 2.6228513e-06
Iter: 1276 loss: 2.62982803e-06
Iter: 1277 loss: 2.62274e-06
Iter: 1278 loss: 2.62167487e-06
Iter: 1279 loss: 2.62179537e-06
Iter: 1280 loss: 2.62098911e-06
Iter: 1281 loss: 2.61994774e-06
Iter: 1282 loss: 2.61993614e-06
Iter: 1283 loss: 2.61933019e-06
Iter: 1284 loss: 2.61869673e-06
Iter: 1285 loss: 2.6186126e-06
Iter: 1286 loss: 2.61772902e-06
Iter: 1287 loss: 2.61613559e-06
Iter: 1288 loss: 2.65190897e-06
Iter: 1289 loss: 2.61610558e-06
Iter: 1290 loss: 2.6144005e-06
Iter: 1291 loss: 2.62689559e-06
Iter: 1292 loss: 2.61419359e-06
Iter: 1293 loss: 2.61273726e-06
Iter: 1294 loss: 2.61762102e-06
Iter: 1295 loss: 2.61225023e-06
Iter: 1296 loss: 2.6109733e-06
Iter: 1297 loss: 2.61495529e-06
Iter: 1298 loss: 2.61060518e-06
Iter: 1299 loss: 2.60923593e-06
Iter: 1300 loss: 2.61225114e-06
Iter: 1301 loss: 2.60870866e-06
Iter: 1302 loss: 2.60731463e-06
Iter: 1303 loss: 2.60790921e-06
Iter: 1304 loss: 2.606517e-06
Iter: 1305 loss: 2.60472439e-06
Iter: 1306 loss: 2.62016192e-06
Iter: 1307 loss: 2.60467164e-06
Iter: 1308 loss: 2.60362367e-06
Iter: 1309 loss: 2.60957313e-06
Iter: 1310 loss: 2.6035e-06
Iter: 1311 loss: 2.60243405e-06
Iter: 1312 loss: 2.60126785e-06
Iter: 1313 loss: 2.6010689e-06
Iter: 1314 loss: 2.6010116e-06
Iter: 1315 loss: 2.60036518e-06
Iter: 1316 loss: 2.59986064e-06
Iter: 1317 loss: 2.60065144e-06
Iter: 1318 loss: 2.59959916e-06
Iter: 1319 loss: 2.59908256e-06
Iter: 1320 loss: 2.5975196e-06
Iter: 1321 loss: 2.61376954e-06
Iter: 1322 loss: 2.59736953e-06
Iter: 1323 loss: 2.5955444e-06
Iter: 1324 loss: 2.60433171e-06
Iter: 1325 loss: 2.5952811e-06
Iter: 1326 loss: 2.59415356e-06
Iter: 1327 loss: 2.59306853e-06
Iter: 1328 loss: 2.592893e-06
Iter: 1329 loss: 2.59152011e-06
Iter: 1330 loss: 2.59151489e-06
Iter: 1331 loss: 2.59052649e-06
Iter: 1332 loss: 2.58920591e-06
Iter: 1333 loss: 2.58913656e-06
Iter: 1334 loss: 2.58748673e-06
Iter: 1335 loss: 2.60657953e-06
Iter: 1336 loss: 2.58749151e-06
Iter: 1337 loss: 2.58613363e-06
Iter: 1338 loss: 2.58445721e-06
Iter: 1339 loss: 2.58428281e-06
Iter: 1340 loss: 2.58289265e-06
Iter: 1341 loss: 2.58282e-06
Iter: 1342 loss: 2.58185764e-06
Iter: 1343 loss: 2.58204091e-06
Iter: 1344 loss: 2.58112414e-06
Iter: 1345 loss: 2.57970169e-06
Iter: 1346 loss: 2.59173657e-06
Iter: 1347 loss: 2.57966644e-06
Iter: 1348 loss: 2.57886086e-06
Iter: 1349 loss: 2.57888451e-06
Iter: 1350 loss: 2.57837883e-06
Iter: 1351 loss: 2.57740976e-06
Iter: 1352 loss: 2.57744091e-06
Iter: 1353 loss: 2.57612237e-06
Iter: 1354 loss: 2.57683359e-06
Iter: 1355 loss: 2.5752156e-06
Iter: 1356 loss: 2.57402507e-06
Iter: 1357 loss: 2.58029331e-06
Iter: 1358 loss: 2.57372903e-06
Iter: 1359 loss: 2.57260535e-06
Iter: 1360 loss: 2.57155352e-06
Iter: 1361 loss: 2.5713025e-06
Iter: 1362 loss: 2.56957719e-06
Iter: 1363 loss: 2.57562306e-06
Iter: 1364 loss: 2.5692193e-06
Iter: 1365 loss: 2.56758767e-06
Iter: 1366 loss: 2.57326951e-06
Iter: 1367 loss: 2.56712383e-06
Iter: 1368 loss: 2.56550834e-06
Iter: 1369 loss: 2.56758631e-06
Iter: 1370 loss: 2.56462249e-06
Iter: 1371 loss: 2.56320845e-06
Iter: 1372 loss: 2.57331521e-06
Iter: 1373 loss: 2.56306203e-06
Iter: 1374 loss: 2.56154635e-06
Iter: 1375 loss: 2.56326393e-06
Iter: 1376 loss: 2.56076964e-06
Iter: 1377 loss: 2.55982127e-06
Iter: 1378 loss: 2.55983741e-06
Iter: 1379 loss: 2.55892746e-06
Iter: 1380 loss: 2.56022759e-06
Iter: 1381 loss: 2.55848477e-06
Iter: 1382 loss: 2.55712075e-06
Iter: 1383 loss: 2.56373096e-06
Iter: 1384 loss: 2.55694613e-06
Iter: 1385 loss: 2.55601594e-06
Iter: 1386 loss: 2.55671921e-06
Iter: 1387 loss: 2.55550481e-06
Iter: 1388 loss: 2.55464079e-06
Iter: 1389 loss: 2.55375335e-06
Iter: 1390 loss: 2.55360897e-06
Iter: 1391 loss: 2.55207192e-06
Iter: 1392 loss: 2.56240514e-06
Iter: 1393 loss: 2.55185205e-06
Iter: 1394 loss: 2.55097439e-06
Iter: 1395 loss: 2.55073201e-06
Iter: 1396 loss: 2.55014561e-06
Iter: 1397 loss: 2.5482027e-06
Iter: 1398 loss: 2.5507004e-06
Iter: 1399 loss: 2.54718566e-06
Iter: 1400 loss: 2.54584961e-06
Iter: 1401 loss: 2.55262148e-06
Iter: 1402 loss: 2.5456111e-06
Iter: 1403 loss: 2.54428778e-06
Iter: 1404 loss: 2.54577708e-06
Iter: 1405 loss: 2.54345082e-06
Iter: 1406 loss: 2.54213501e-06
Iter: 1407 loss: 2.54469751e-06
Iter: 1408 loss: 2.5415975e-06
Iter: 1409 loss: 2.53995836e-06
Iter: 1410 loss: 2.54594988e-06
Iter: 1411 loss: 2.53958979e-06
Iter: 1412 loss: 2.5386189e-06
Iter: 1413 loss: 2.54782208e-06
Iter: 1414 loss: 2.53854296e-06
Iter: 1415 loss: 2.53781786e-06
Iter: 1416 loss: 2.54725364e-06
Iter: 1417 loss: 2.53785129e-06
Iter: 1418 loss: 2.53720259e-06
Iter: 1419 loss: 2.53783219e-06
Iter: 1420 loss: 2.53683038e-06
Iter: 1421 loss: 2.536171e-06
Iter: 1422 loss: 2.53525059e-06
Iter: 1423 loss: 2.53523649e-06
Iter: 1424 loss: 2.53390863e-06
Iter: 1425 loss: 2.53740382e-06
Iter: 1426 loss: 2.53345911e-06
Iter: 1427 loss: 2.53215148e-06
Iter: 1428 loss: 2.53478311e-06
Iter: 1429 loss: 2.53160488e-06
Iter: 1430 loss: 2.53007147e-06
Iter: 1431 loss: 2.53303961e-06
Iter: 1432 loss: 2.52942368e-06
Iter: 1433 loss: 2.52842437e-06
Iter: 1434 loss: 2.53281064e-06
Iter: 1435 loss: 2.5282261e-06
Iter: 1436 loss: 2.5270183e-06
Iter: 1437 loss: 2.52819609e-06
Iter: 1438 loss: 2.52630139e-06
Iter: 1439 loss: 2.52510063e-06
Iter: 1440 loss: 2.52594464e-06
Iter: 1441 loss: 2.52440532e-06
Iter: 1442 loss: 2.5226268e-06
Iter: 1443 loss: 2.53048211e-06
Iter: 1444 loss: 2.52226869e-06
Iter: 1445 loss: 2.52111113e-06
Iter: 1446 loss: 2.52207451e-06
Iter: 1447 loss: 2.52043401e-06
Iter: 1448 loss: 2.51870733e-06
Iter: 1449 loss: 2.52529617e-06
Iter: 1450 loss: 2.51822848e-06
Iter: 1451 loss: 2.51853498e-06
Iter: 1452 loss: 2.51765755e-06
Iter: 1453 loss: 2.51731444e-06
Iter: 1454 loss: 2.51642609e-06
Iter: 1455 loss: 2.52602695e-06
Iter: 1456 loss: 2.51635515e-06
Iter: 1457 loss: 2.51503252e-06
Iter: 1458 loss: 2.51672191e-06
Iter: 1459 loss: 2.51436813e-06
Iter: 1460 loss: 2.51328561e-06
Iter: 1461 loss: 2.51830852e-06
Iter: 1462 loss: 2.51303709e-06
Iter: 1463 loss: 2.51214556e-06
Iter: 1464 loss: 2.51061101e-06
Iter: 1465 loss: 2.51059555e-06
Iter: 1466 loss: 2.50909784e-06
Iter: 1467 loss: 2.52118912e-06
Iter: 1468 loss: 2.50902121e-06
Iter: 1469 loss: 2.50735457e-06
Iter: 1470 loss: 2.50983908e-06
Iter: 1471 loss: 2.50660878e-06
Iter: 1472 loss: 2.5054178e-06
Iter: 1473 loss: 2.50541325e-06
Iter: 1474 loss: 2.50469247e-06
Iter: 1475 loss: 2.5029276e-06
Iter: 1476 loss: 2.52726704e-06
Iter: 1477 loss: 2.50281892e-06
Iter: 1478 loss: 2.50164749e-06
Iter: 1479 loss: 2.50161202e-06
Iter: 1480 loss: 2.50048333e-06
Iter: 1481 loss: 2.50027392e-06
Iter: 1482 loss: 2.4994556e-06
Iter: 1483 loss: 2.49826553e-06
Iter: 1484 loss: 2.51137499e-06
Iter: 1485 loss: 2.49822688e-06
Iter: 1486 loss: 2.49784512e-06
Iter: 1487 loss: 2.49773211e-06
Iter: 1488 loss: 2.49731465e-06
Iter: 1489 loss: 2.49607183e-06
Iter: 1490 loss: 2.50173616e-06
Iter: 1491 loss: 2.49557593e-06
Iter: 1492 loss: 2.49460209e-06
Iter: 1493 loss: 2.49458321e-06
Iter: 1494 loss: 2.49363984e-06
Iter: 1495 loss: 2.49282061e-06
Iter: 1496 loss: 2.49267714e-06
Iter: 1497 loss: 2.49136019e-06
Iter: 1498 loss: 2.49764889e-06
Iter: 1499 loss: 2.49115192e-06
Iter: 1500 loss: 2.49008781e-06
Iter: 1501 loss: 2.48937022e-06
Iter: 1502 loss: 2.48901574e-06
Iter: 1503 loss: 2.48744209e-06
Iter: 1504 loss: 2.49763e-06
Iter: 1505 loss: 2.4872636e-06
Iter: 1506 loss: 2.48603237e-06
Iter: 1507 loss: 2.49035725e-06
Iter: 1508 loss: 2.4857186e-06
Iter: 1509 loss: 2.48450351e-06
Iter: 1510 loss: 2.48842207e-06
Iter: 1511 loss: 2.48414e-06
Iter: 1512 loss: 2.4826229e-06
Iter: 1513 loss: 2.48346896e-06
Iter: 1514 loss: 2.48154538e-06
Iter: 1515 loss: 2.48059541e-06
Iter: 1516 loss: 2.48977108e-06
Iter: 1517 loss: 2.48054857e-06
Iter: 1518 loss: 2.47961134e-06
Iter: 1519 loss: 2.47869116e-06
Iter: 1520 loss: 2.47843309e-06
Iter: 1521 loss: 2.47823482e-06
Iter: 1522 loss: 2.47785556e-06
Iter: 1523 loss: 2.47725529e-06
Iter: 1524 loss: 2.47801881e-06
Iter: 1525 loss: 2.4768633e-06
Iter: 1526 loss: 2.47622938e-06
Iter: 1527 loss: 2.4748781e-06
Iter: 1528 loss: 2.49947266e-06
Iter: 1529 loss: 2.47481466e-06
Iter: 1530 loss: 2.4737285e-06
Iter: 1531 loss: 2.48144102e-06
Iter: 1532 loss: 2.47364869e-06
Iter: 1533 loss: 2.47258322e-06
Iter: 1534 loss: 2.47234902e-06
Iter: 1535 loss: 2.47172125e-06
Iter: 1536 loss: 2.47086064e-06
Iter: 1537 loss: 2.47085859e-06
Iter: 1538 loss: 2.47009871e-06
Iter: 1539 loss: 2.46945319e-06
Iter: 1540 loss: 2.46918808e-06
Iter: 1541 loss: 2.4678252e-06
Iter: 1542 loss: 2.47299113e-06
Iter: 1543 loss: 2.46751347e-06
Iter: 1544 loss: 2.46653303e-06
Iter: 1545 loss: 2.46542504e-06
Iter: 1546 loss: 2.46533591e-06
Iter: 1547 loss: 2.46435775e-06
Iter: 1548 loss: 2.46425725e-06
Iter: 1549 loss: 2.46345644e-06
Iter: 1550 loss: 2.46355921e-06
Iter: 1551 loss: 2.46288732e-06
Iter: 1552 loss: 2.46146828e-06
Iter: 1553 loss: 2.46451032e-06
Iter: 1554 loss: 2.46095965e-06
Iter: 1555 loss: 2.46065633e-06
Iter: 1556 loss: 2.46047193e-06
Iter: 1557 loss: 2.45992896e-06
Iter: 1558 loss: 2.45891238e-06
Iter: 1559 loss: 2.48110155e-06
Iter: 1560 loss: 2.45889805e-06
Iter: 1561 loss: 2.45792808e-06
Iter: 1562 loss: 2.45864658e-06
Iter: 1563 loss: 2.45739079e-06
Iter: 1564 loss: 2.45626188e-06
Iter: 1565 loss: 2.4589508e-06
Iter: 1566 loss: 2.45577939e-06
Iter: 1567 loss: 2.45470937e-06
Iter: 1568 loss: 2.46043874e-06
Iter: 1569 loss: 2.45461069e-06
Iter: 1570 loss: 2.45371075e-06
Iter: 1571 loss: 2.45608726e-06
Iter: 1572 loss: 2.45336651e-06
Iter: 1573 loss: 2.45254887e-06
Iter: 1574 loss: 2.45828915e-06
Iter: 1575 loss: 2.4523697e-06
Iter: 1576 loss: 2.45171304e-06
Iter: 1577 loss: 2.45081014e-06
Iter: 1578 loss: 2.45077217e-06
Iter: 1579 loss: 2.44932903e-06
Iter: 1580 loss: 2.45495426e-06
Iter: 1581 loss: 2.4490123e-06
Iter: 1582 loss: 2.44777129e-06
Iter: 1583 loss: 2.44769899e-06
Iter: 1584 loss: 2.44685339e-06
Iter: 1585 loss: 2.44560078e-06
Iter: 1586 loss: 2.44549e-06
Iter: 1587 loss: 2.4449605e-06
Iter: 1588 loss: 2.4459589e-06
Iter: 1589 loss: 2.44468879e-06
Iter: 1590 loss: 2.44391049e-06
Iter: 1591 loss: 2.45169144e-06
Iter: 1592 loss: 2.44387729e-06
Iter: 1593 loss: 2.44323292e-06
Iter: 1594 loss: 2.44193052e-06
Iter: 1595 loss: 2.46438822e-06
Iter: 1596 loss: 2.44187345e-06
Iter: 1597 loss: 2.44085641e-06
Iter: 1598 loss: 2.44004696e-06
Iter: 1599 loss: 2.43971499e-06
Iter: 1600 loss: 2.43850718e-06
Iter: 1601 loss: 2.43848785e-06
Iter: 1602 loss: 2.43755335e-06
Iter: 1603 loss: 2.43791e-06
Iter: 1604 loss: 2.43688919e-06
Iter: 1605 loss: 2.4356209e-06
Iter: 1606 loss: 2.44513e-06
Iter: 1607 loss: 2.43551517e-06
Iter: 1608 loss: 2.43472914e-06
Iter: 1609 loss: 2.43776367e-06
Iter: 1610 loss: 2.43460863e-06
Iter: 1611 loss: 2.43376462e-06
Iter: 1612 loss: 2.43265958e-06
Iter: 1613 loss: 2.43261411e-06
Iter: 1614 loss: 2.43134537e-06
Iter: 1615 loss: 2.44219973e-06
Iter: 1616 loss: 2.43125464e-06
Iter: 1617 loss: 2.43023715e-06
Iter: 1618 loss: 2.43124055e-06
Iter: 1619 loss: 2.42965689e-06
Iter: 1620 loss: 2.42849046e-06
Iter: 1621 loss: 2.43568661e-06
Iter: 1622 loss: 2.42842066e-06
Iter: 1623 loss: 2.427661e-06
Iter: 1624 loss: 2.43785325e-06
Iter: 1625 loss: 2.42762644e-06
Iter: 1626 loss: 2.42685428e-06
Iter: 1627 loss: 2.427862e-06
Iter: 1628 loss: 2.42646411e-06
Iter: 1629 loss: 2.42587885e-06
Iter: 1630 loss: 2.42490523e-06
Iter: 1631 loss: 2.42492297e-06
Iter: 1632 loss: 2.42366468e-06
Iter: 1633 loss: 2.42671513e-06
Iter: 1634 loss: 2.42319197e-06
Iter: 1635 loss: 2.42218448e-06
Iter: 1636 loss: 2.4234314e-06
Iter: 1637 loss: 2.42164197e-06
Iter: 1638 loss: 2.42015e-06
Iter: 1639 loss: 2.42713622e-06
Iter: 1640 loss: 2.41992575e-06
Iter: 1641 loss: 2.41912926e-06
Iter: 1642 loss: 2.42683927e-06
Iter: 1643 loss: 2.4190349e-06
Iter: 1644 loss: 2.41807356e-06
Iter: 1645 loss: 2.41691941e-06
Iter: 1646 loss: 2.41680345e-06
Iter: 1647 loss: 2.41579255e-06
Iter: 1648 loss: 2.42594888e-06
Iter: 1649 loss: 2.41565658e-06
Iter: 1650 loss: 2.41463886e-06
Iter: 1651 loss: 2.41452153e-06
Iter: 1652 loss: 2.41387875e-06
Iter: 1653 loss: 2.41277598e-06
Iter: 1654 loss: 2.42287183e-06
Iter: 1655 loss: 2.41268026e-06
Iter: 1656 loss: 2.41189582e-06
Iter: 1657 loss: 2.41604585e-06
Iter: 1658 loss: 2.41178259e-06
Iter: 1659 loss: 2.41081671e-06
Iter: 1660 loss: 2.41379212e-06
Iter: 1661 loss: 2.4104952e-06
Iter: 1662 loss: 2.40980717e-06
Iter: 1663 loss: 2.41027055e-06
Iter: 1664 loss: 2.40929194e-06
Iter: 1665 loss: 2.40865711e-06
Iter: 1666 loss: 2.4075639e-06
Iter: 1667 loss: 2.40752547e-06
Iter: 1668 loss: 2.40609984e-06
Iter: 1669 loss: 2.41555085e-06
Iter: 1670 loss: 2.40596478e-06
Iter: 1671 loss: 2.40492e-06
Iter: 1672 loss: 2.40575719e-06
Iter: 1673 loss: 2.40429426e-06
Iter: 1674 loss: 2.40305849e-06
Iter: 1675 loss: 2.41023986e-06
Iter: 1676 loss: 2.40290956e-06
Iter: 1677 loss: 2.40169356e-06
Iter: 1678 loss: 2.40704344e-06
Iter: 1679 loss: 2.40148461e-06
Iter: 1680 loss: 2.40060672e-06
Iter: 1681 loss: 2.40234385e-06
Iter: 1682 loss: 2.4002959e-06
Iter: 1683 loss: 2.39933161e-06
Iter: 1684 loss: 2.39894257e-06
Iter: 1685 loss: 2.39848168e-06
Iter: 1686 loss: 2.39744531e-06
Iter: 1687 loss: 2.41144289e-06
Iter: 1688 loss: 2.39741757e-06
Iter: 1689 loss: 2.3965938e-06
Iter: 1690 loss: 2.3956668e-06
Iter: 1691 loss: 2.39555266e-06
Iter: 1692 loss: 2.39518795e-06
Iter: 1693 loss: 2.39470864e-06
Iter: 1694 loss: 2.39436417e-06
Iter: 1695 loss: 2.39392466e-06
Iter: 1696 loss: 2.39389465e-06
Iter: 1697 loss: 2.39319479e-06
Iter: 1698 loss: 2.39195651e-06
Iter: 1699 loss: 2.41871271e-06
Iter: 1700 loss: 2.3919315e-06
Iter: 1701 loss: 2.39070869e-06
Iter: 1702 loss: 2.4053079e-06
Iter: 1703 loss: 2.3907246e-06
Iter: 1704 loss: 2.38985831e-06
Iter: 1705 loss: 2.38887401e-06
Iter: 1706 loss: 2.3887028e-06
Iter: 1707 loss: 2.38749476e-06
Iter: 1708 loss: 2.39859128e-06
Iter: 1709 loss: 2.3874436e-06
Iter: 1710 loss: 2.38622943e-06
Iter: 1711 loss: 2.38742359e-06
Iter: 1712 loss: 2.38556322e-06
Iter: 1713 loss: 2.38444932e-06
Iter: 1714 loss: 2.38442908e-06
Iter: 1715 loss: 2.38380244e-06
Iter: 1716 loss: 2.38289522e-06
Iter: 1717 loss: 2.38287794e-06
Iter: 1718 loss: 2.38157895e-06
Iter: 1719 loss: 2.38683378e-06
Iter: 1720 loss: 2.38132952e-06
Iter: 1721 loss: 2.38036591e-06
Iter: 1722 loss: 2.38268876e-06
Iter: 1723 loss: 2.38008488e-06
Iter: 1724 loss: 2.37937161e-06
Iter: 1725 loss: 2.37939412e-06
Iter: 1726 loss: 2.37866857e-06
Iter: 1727 loss: 2.37945505e-06
Iter: 1728 loss: 2.37833751e-06
Iter: 1729 loss: 2.37773952e-06
Iter: 1730 loss: 2.3769021e-06
Iter: 1731 loss: 2.37681479e-06
Iter: 1732 loss: 2.37585527e-06
Iter: 1733 loss: 2.38278017e-06
Iter: 1734 loss: 2.37575728e-06
Iter: 1735 loss: 2.37505878e-06
Iter: 1736 loss: 2.37457607e-06
Iter: 1737 loss: 2.37434597e-06
Iter: 1738 loss: 2.37330369e-06
Iter: 1739 loss: 2.38077155e-06
Iter: 1740 loss: 2.37315862e-06
Iter: 1741 loss: 2.37246877e-06
Iter: 1742 loss: 2.37209952e-06
Iter: 1743 loss: 2.37168842e-06
Iter: 1744 loss: 2.37068707e-06
Iter: 1745 loss: 2.38094e-06
Iter: 1746 loss: 2.37062704e-06
Iter: 1747 loss: 2.36990763e-06
Iter: 1748 loss: 2.37052427e-06
Iter: 1749 loss: 2.36955339e-06
Iter: 1750 loss: 2.36854498e-06
Iter: 1751 loss: 2.3763132e-06
Iter: 1752 loss: 2.36852884e-06
Iter: 1753 loss: 2.36798905e-06
Iter: 1754 loss: 2.36772416e-06
Iter: 1755 loss: 2.36743654e-06
Iter: 1756 loss: 2.36640358e-06
Iter: 1757 loss: 2.36693e-06
Iter: 1758 loss: 2.36572214e-06
Iter: 1759 loss: 2.36544702e-06
Iter: 1760 loss: 2.36527171e-06
Iter: 1761 loss: 2.36476239e-06
Iter: 1762 loss: 2.36547476e-06
Iter: 1763 loss: 2.36453843e-06
Iter: 1764 loss: 2.36402548e-06
Iter: 1765 loss: 2.36323422e-06
Iter: 1766 loss: 2.36322e-06
Iter: 1767 loss: 2.36243886e-06
Iter: 1768 loss: 2.36672258e-06
Iter: 1769 loss: 2.3622847e-06
Iter: 1770 loss: 2.36161e-06
Iter: 1771 loss: 2.3623686e-06
Iter: 1772 loss: 2.36120627e-06
Iter: 1773 loss: 2.36046026e-06
Iter: 1774 loss: 2.36352071e-06
Iter: 1775 loss: 2.36035612e-06
Iter: 1776 loss: 2.35969674e-06
Iter: 1777 loss: 2.35991479e-06
Iter: 1778 loss: 2.35919424e-06
Iter: 1779 loss: 2.35831271e-06
Iter: 1780 loss: 2.35957486e-06
Iter: 1781 loss: 2.35794732e-06
Iter: 1782 loss: 2.35696734e-06
Iter: 1783 loss: 2.36330538e-06
Iter: 1784 loss: 2.35692505e-06
Iter: 1785 loss: 2.35622861e-06
Iter: 1786 loss: 2.3595087e-06
Iter: 1787 loss: 2.35612106e-06
Iter: 1788 loss: 2.35530342e-06
Iter: 1789 loss: 2.35662537e-06
Iter: 1790 loss: 2.35499192e-06
Iter: 1791 loss: 2.35449215e-06
Iter: 1792 loss: 2.35551443e-06
Iter: 1793 loss: 2.35430252e-06
Iter: 1794 loss: 2.35368839e-06
Iter: 1795 loss: 2.35503717e-06
Iter: 1796 loss: 2.35347579e-06
Iter: 1797 loss: 2.35289554e-06
Iter: 1798 loss: 2.35295511e-06
Iter: 1799 loss: 2.35269476e-06
Iter: 1800 loss: 2.35225502e-06
Iter: 1801 loss: 2.36013329e-06
Iter: 1802 loss: 2.35223797e-06
Iter: 1803 loss: 2.35151674e-06
Iter: 1804 loss: 2.35136145e-06
Iter: 1805 loss: 2.35087191e-06
Iter: 1806 loss: 2.35013931e-06
Iter: 1807 loss: 2.35957123e-06
Iter: 1808 loss: 2.35016182e-06
Iter: 1809 loss: 2.3496641e-06
Iter: 1810 loss: 2.34909157e-06
Iter: 1811 loss: 2.34904883e-06
Iter: 1812 loss: 2.34823938e-06
Iter: 1813 loss: 2.35654238e-06
Iter: 1814 loss: 2.34820936e-06
Iter: 1815 loss: 2.3476764e-06
Iter: 1816 loss: 2.34721438e-06
Iter: 1817 loss: 2.34708978e-06
Iter: 1818 loss: 2.34626e-06
Iter: 1819 loss: 2.35226594e-06
Iter: 1820 loss: 2.34622735e-06
Iter: 1821 loss: 2.3455334e-06
Iter: 1822 loss: 2.34623235e-06
Iter: 1823 loss: 2.34512413e-06
Iter: 1824 loss: 2.34438312e-06
Iter: 1825 loss: 2.3538264e-06
Iter: 1826 loss: 2.34436629e-06
Iter: 1827 loss: 2.34391291e-06
Iter: 1828 loss: 2.34329718e-06
Iter: 1829 loss: 2.34324193e-06
Iter: 1830 loss: 2.34264894e-06
Iter: 1831 loss: 2.34639856e-06
Iter: 1832 loss: 2.34248114e-06
Iter: 1833 loss: 2.34211666e-06
Iter: 1834 loss: 2.34212803e-06
Iter: 1835 loss: 2.34163599e-06
Iter: 1836 loss: 2.34111803e-06
Iter: 1837 loss: 2.34100548e-06
Iter: 1838 loss: 2.34070512e-06
Iter: 1839 loss: 2.34018216e-06
Iter: 1840 loss: 2.34016829e-06
Iter: 1841 loss: 2.33925402e-06
Iter: 1842 loss: 2.34233676e-06
Iter: 1843 loss: 2.33902983e-06
Iter: 1844 loss: 2.33848277e-06
Iter: 1845 loss: 2.34569779e-06
Iter: 1846 loss: 2.33847368e-06
Iter: 1847 loss: 2.33811807e-06
Iter: 1848 loss: 2.33733385e-06
Iter: 1849 loss: 2.35378434e-06
Iter: 1850 loss: 2.3373093e-06
Iter: 1851 loss: 2.33640662e-06
Iter: 1852 loss: 2.34678328e-06
Iter: 1853 loss: 2.33640435e-06
Iter: 1854 loss: 2.33593209e-06
Iter: 1855 loss: 2.33542778e-06
Iter: 1856 loss: 2.3352834e-06
Iter: 1857 loss: 2.33447599e-06
Iter: 1858 loss: 2.34259687e-06
Iter: 1859 loss: 2.33447122e-06
Iter: 1860 loss: 2.3338157e-06
Iter: 1861 loss: 2.33345e-06
Iter: 1862 loss: 2.33320816e-06
Iter: 1863 loss: 2.33237938e-06
Iter: 1864 loss: 2.34216441e-06
Iter: 1865 loss: 2.3323696e-06
Iter: 1866 loss: 2.3319476e-06
Iter: 1867 loss: 2.33289984e-06
Iter: 1868 loss: 2.33173841e-06
Iter: 1869 loss: 2.33113701e-06
Iter: 1870 loss: 2.33749824e-06
Iter: 1871 loss: 2.33112769e-06
Iter: 1872 loss: 2.33069113e-06
Iter: 1873 loss: 2.33183641e-06
Iter: 1874 loss: 2.33054107e-06
Iter: 1875 loss: 2.33027754e-06
Iter: 1876 loss: 2.32976049e-06
Iter: 1877 loss: 2.34045228e-06
Iter: 1878 loss: 2.32969296e-06
Iter: 1879 loss: 2.32887464e-06
Iter: 1880 loss: 2.33022138e-06
Iter: 1881 loss: 2.32847606e-06
Iter: 1882 loss: 2.32776733e-06
Iter: 1883 loss: 2.32807906e-06
Iter: 1884 loss: 2.32727984e-06
Iter: 1885 loss: 2.32629782e-06
Iter: 1886 loss: 2.33519177e-06
Iter: 1887 loss: 2.32630828e-06
Iter: 1888 loss: 2.32558818e-06
Iter: 1889 loss: 2.32768912e-06
Iter: 1890 loss: 2.32536922e-06
Iter: 1891 loss: 2.32471257e-06
Iter: 1892 loss: 2.32487355e-06
Iter: 1893 loss: 2.32415232e-06
Iter: 1894 loss: 2.32332422e-06
Iter: 1895 loss: 2.32556886e-06
Iter: 1896 loss: 2.3229793e-06
Iter: 1897 loss: 2.32212165e-06
Iter: 1898 loss: 2.32712773e-06
Iter: 1899 loss: 2.32210186e-06
Iter: 1900 loss: 2.32142202e-06
Iter: 1901 loss: 2.32159709e-06
Iter: 1902 loss: 2.32093544e-06
Iter: 1903 loss: 2.32009916e-06
Iter: 1904 loss: 2.32767547e-06
Iter: 1905 loss: 2.32006414e-06
Iter: 1906 loss: 2.3194666e-06
Iter: 1907 loss: 2.31965805e-06
Iter: 1908 loss: 2.31906961e-06
Iter: 1909 loss: 2.31850117e-06
Iter: 1910 loss: 2.31848162e-06
Iter: 1911 loss: 2.31812282e-06
Iter: 1912 loss: 2.31866693e-06
Iter: 1913 loss: 2.31797958e-06
Iter: 1914 loss: 2.31761123e-06
Iter: 1915 loss: 2.31715512e-06
Iter: 1916 loss: 2.31712238e-06
Iter: 1917 loss: 2.31625654e-06
Iter: 1918 loss: 2.31609397e-06
Iter: 1919 loss: 2.31553713e-06
Iter: 1920 loss: 2.31471904e-06
Iter: 1921 loss: 2.31684817e-06
Iter: 1922 loss: 2.31442505e-06
Iter: 1923 loss: 2.31340937e-06
Iter: 1924 loss: 2.31933473e-06
Iter: 1925 loss: 2.31335957e-06
Iter: 1926 loss: 2.31278204e-06
Iter: 1927 loss: 2.31539525e-06
Iter: 1928 loss: 2.31269519e-06
Iter: 1929 loss: 2.31199397e-06
Iter: 1930 loss: 2.31200556e-06
Iter: 1931 loss: 2.31147123e-06
Iter: 1932 loss: 2.31082322e-06
Iter: 1933 loss: 2.31218087e-06
Iter: 1934 loss: 2.31052263e-06
Iter: 1935 loss: 2.30950604e-06
Iter: 1936 loss: 2.31153763e-06
Iter: 1937 loss: 2.30917499e-06
Iter: 1938 loss: 2.30829482e-06
Iter: 1939 loss: 2.31215245e-06
Iter: 1940 loss: 2.30813521e-06
Iter: 1941 loss: 2.30732871e-06
Iter: 1942 loss: 2.30989349e-06
Iter: 1943 loss: 2.30707542e-06
Iter: 1944 loss: 2.30683872e-06
Iter: 1945 loss: 2.30664727e-06
Iter: 1946 loss: 2.30635419e-06
Iter: 1947 loss: 2.30588194e-06
Iter: 1948 loss: 2.30586375e-06
Iter: 1949 loss: 2.30526643e-06
Iter: 1950 loss: 2.30651e-06
Iter: 1951 loss: 2.30506475e-06
Iter: 1952 loss: 2.30458e-06
Iter: 1953 loss: 2.3046498e-06
Iter: 1954 loss: 2.30421074e-06
Iter: 1955 loss: 2.30331489e-06
Iter: 1956 loss: 2.30305341e-06
Iter: 1957 loss: 2.3025882e-06
Iter: 1958 loss: 2.30159981e-06
Iter: 1959 loss: 2.30581054e-06
Iter: 1960 loss: 2.30137448e-06
Iter: 1961 loss: 2.30049136e-06
Iter: 1962 loss: 2.30420892e-06
Iter: 1963 loss: 2.30024966e-06
Iter: 1964 loss: 2.29953184e-06
Iter: 1965 loss: 2.3014768e-06
Iter: 1966 loss: 2.29932e-06
Iter: 1967 loss: 2.29844318e-06
Iter: 1968 loss: 2.30149044e-06
Iter: 1969 loss: 2.29817397e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3/300_300_300_1
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0
+ date
Mon Oct 26 10:50:50 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b5dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b5d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b9ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b45510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b38a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b45268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b17488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b17048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b45c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b16268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8b16488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d89eb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8a062f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d89a42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8a060d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8a01a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8a01ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d891ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d88df9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d889c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d889c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d88b8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d886ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d881ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d883f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d883fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8812a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d87a9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d87a9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8776bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d87767b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8740620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8740510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d8706e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d86b6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1b4a01598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.56566602e-06
Iter: 2 loss: 4.61562922e-06
Iter: 3 loss: 4.46859758e-06
Iter: 4 loss: 4.10956909e-06
Iter: 5 loss: 3.8586586e-06
Iter: 6 loss: 3.730358e-06
Iter: 7 loss: 3.48926596e-06
Iter: 8 loss: 4.11287874e-06
Iter: 9 loss: 3.40697648e-06
Iter: 10 loss: 3.14498811e-06
Iter: 11 loss: 5.79871175e-06
Iter: 12 loss: 3.13699934e-06
Iter: 13 loss: 3.06997572e-06
Iter: 14 loss: 3.07066875e-06
Iter: 15 loss: 3.01644172e-06
Iter: 16 loss: 2.93549078e-06
Iter: 17 loss: 3.14610611e-06
Iter: 18 loss: 2.90791718e-06
Iter: 19 loss: 2.80454606e-06
Iter: 20 loss: 3.49091874e-06
Iter: 21 loss: 2.79393748e-06
Iter: 22 loss: 2.73880187e-06
Iter: 23 loss: 2.60043566e-06
Iter: 24 loss: 3.88329227e-06
Iter: 25 loss: 2.58041291e-06
Iter: 26 loss: 2.4743938e-06
Iter: 27 loss: 2.4588021e-06
Iter: 28 loss: 2.38237681e-06
Iter: 29 loss: 2.30874593e-06
Iter: 30 loss: 2.29189345e-06
Iter: 31 loss: 2.23328243e-06
Iter: 32 loss: 2.18828905e-06
Iter: 33 loss: 2.16960507e-06
Iter: 34 loss: 2.1263927e-06
Iter: 35 loss: 2.12463237e-06
Iter: 36 loss: 2.08959909e-06
Iter: 37 loss: 2.53273538e-06
Iter: 38 loss: 2.08931215e-06
Iter: 39 loss: 2.0660716e-06
Iter: 40 loss: 2.01187822e-06
Iter: 41 loss: 2.67007772e-06
Iter: 42 loss: 2.0075172e-06
Iter: 43 loss: 1.9877225e-06
Iter: 44 loss: 1.98198541e-06
Iter: 45 loss: 1.95131861e-06
Iter: 46 loss: 1.88601041e-06
Iter: 47 loss: 2.9354926e-06
Iter: 48 loss: 1.88401827e-06
Iter: 49 loss: 1.83113104e-06
Iter: 50 loss: 2.34328013e-06
Iter: 51 loss: 1.82916267e-06
Iter: 52 loss: 1.81282189e-06
Iter: 53 loss: 1.81199266e-06
Iter: 54 loss: 1.79646429e-06
Iter: 55 loss: 1.75612274e-06
Iter: 56 loss: 2.07134349e-06
Iter: 57 loss: 1.7483236e-06
Iter: 58 loss: 1.69280406e-06
Iter: 59 loss: 1.94118593e-06
Iter: 60 loss: 1.68193196e-06
Iter: 61 loss: 1.6298427e-06
Iter: 62 loss: 2.17085426e-06
Iter: 63 loss: 1.62842264e-06
Iter: 64 loss: 1.60511172e-06
Iter: 65 loss: 1.53914334e-06
Iter: 66 loss: 1.86412024e-06
Iter: 67 loss: 1.5168464e-06
Iter: 68 loss: 1.4687098e-06
Iter: 69 loss: 1.46867887e-06
Iter: 70 loss: 1.45034835e-06
Iter: 71 loss: 1.4493412e-06
Iter: 72 loss: 1.430623e-06
Iter: 73 loss: 1.45920512e-06
Iter: 74 loss: 1.42180738e-06
Iter: 75 loss: 1.41343446e-06
Iter: 76 loss: 1.40154566e-06
Iter: 77 loss: 1.40110637e-06
Iter: 78 loss: 1.37598227e-06
Iter: 79 loss: 1.47095727e-06
Iter: 80 loss: 1.36990741e-06
Iter: 81 loss: 1.35011464e-06
Iter: 82 loss: 1.3269314e-06
Iter: 83 loss: 1.32431683e-06
Iter: 84 loss: 1.29923387e-06
Iter: 85 loss: 1.60902687e-06
Iter: 86 loss: 1.29899888e-06
Iter: 87 loss: 1.27388466e-06
Iter: 88 loss: 1.33504932e-06
Iter: 89 loss: 1.26490295e-06
Iter: 90 loss: 1.25009456e-06
Iter: 91 loss: 1.26653617e-06
Iter: 92 loss: 1.24206645e-06
Iter: 93 loss: 1.2318618e-06
Iter: 94 loss: 1.23186032e-06
Iter: 95 loss: 1.22154415e-06
Iter: 96 loss: 1.20456366e-06
Iter: 97 loss: 1.20452125e-06
Iter: 98 loss: 1.19443837e-06
Iter: 99 loss: 1.18645448e-06
Iter: 100 loss: 1.18340517e-06
Iter: 101 loss: 1.16172669e-06
Iter: 102 loss: 1.23978327e-06
Iter: 103 loss: 1.15621845e-06
Iter: 104 loss: 1.15341095e-06
Iter: 105 loss: 1.14637919e-06
Iter: 106 loss: 1.14209251e-06
Iter: 107 loss: 1.12922191e-06
Iter: 108 loss: 1.16949059e-06
Iter: 109 loss: 1.12294731e-06
Iter: 110 loss: 1.12461589e-06
Iter: 111 loss: 1.11566806e-06
Iter: 112 loss: 1.11012946e-06
Iter: 113 loss: 1.09988741e-06
Iter: 114 loss: 1.33913079e-06
Iter: 115 loss: 1.09986854e-06
Iter: 116 loss: 1.08721088e-06
Iter: 117 loss: 1.07387768e-06
Iter: 118 loss: 1.07159121e-06
Iter: 119 loss: 1.08284235e-06
Iter: 120 loss: 1.06414802e-06
Iter: 121 loss: 1.05977e-06
Iter: 122 loss: 1.04866831e-06
Iter: 123 loss: 1.14006434e-06
Iter: 124 loss: 1.0466506e-06
Iter: 125 loss: 1.03129014e-06
Iter: 126 loss: 1.08517565e-06
Iter: 127 loss: 1.02733657e-06
Iter: 128 loss: 1.02745651e-06
Iter: 129 loss: 1.02441277e-06
Iter: 130 loss: 1.02168053e-06
Iter: 131 loss: 1.01603e-06
Iter: 132 loss: 1.11812278e-06
Iter: 133 loss: 1.01593082e-06
Iter: 134 loss: 1.01056753e-06
Iter: 135 loss: 1.00812406e-06
Iter: 136 loss: 1.00547413e-06
Iter: 137 loss: 9.95865094e-07
Iter: 138 loss: 1.02637659e-06
Iter: 139 loss: 9.93112849e-07
Iter: 140 loss: 9.78828439e-07
Iter: 141 loss: 1.03352363e-06
Iter: 142 loss: 9.75458875e-07
Iter: 143 loss: 9.69088e-07
Iter: 144 loss: 9.54865754e-07
Iter: 145 loss: 1.15025682e-06
Iter: 146 loss: 9.54107122e-07
Iter: 147 loss: 9.48205184e-07
Iter: 148 loss: 9.43845237e-07
Iter: 149 loss: 9.40161101e-07
Iter: 150 loss: 9.33513718e-07
Iter: 151 loss: 1.09691791e-06
Iter: 152 loss: 9.33522813e-07
Iter: 153 loss: 9.28034183e-07
Iter: 154 loss: 9.5840835e-07
Iter: 155 loss: 9.27241e-07
Iter: 156 loss: 9.23421283e-07
Iter: 157 loss: 9.23373364e-07
Iter: 158 loss: 9.21722062e-07
Iter: 159 loss: 9.16116164e-07
Iter: 160 loss: 9.14427687e-07
Iter: 161 loss: 9.09787957e-07
Iter: 162 loss: 8.97953782e-07
Iter: 163 loss: 1.04567334e-06
Iter: 164 loss: 8.97830319e-07
Iter: 165 loss: 8.94170853e-07
Iter: 166 loss: 8.93678589e-07
Iter: 167 loss: 8.90308797e-07
Iter: 168 loss: 8.81174174e-07
Iter: 169 loss: 9.43812495e-07
Iter: 170 loss: 8.79107461e-07
Iter: 171 loss: 8.70786948e-07
Iter: 172 loss: 9.49236096e-07
Iter: 173 loss: 8.70481585e-07
Iter: 174 loss: 8.67930908e-07
Iter: 175 loss: 8.678943e-07
Iter: 176 loss: 8.64720164e-07
Iter: 177 loss: 8.60235673e-07
Iter: 178 loss: 8.6005474e-07
Iter: 179 loss: 8.56587462e-07
Iter: 180 loss: 8.57331202e-07
Iter: 181 loss: 8.54058612e-07
Iter: 182 loss: 8.50436265e-07
Iter: 183 loss: 8.50275683e-07
Iter: 184 loss: 8.47991942e-07
Iter: 185 loss: 8.44288e-07
Iter: 186 loss: 8.44229362e-07
Iter: 187 loss: 8.4262e-07
Iter: 188 loss: 8.42567715e-07
Iter: 189 loss: 8.40388907e-07
Iter: 190 loss: 8.34791763e-07
Iter: 191 loss: 8.82059965e-07
Iter: 192 loss: 8.33865158e-07
Iter: 193 loss: 8.29229805e-07
Iter: 194 loss: 8.5356e-07
Iter: 195 loss: 8.28478733e-07
Iter: 196 loss: 8.24705808e-07
Iter: 197 loss: 8.43290195e-07
Iter: 198 loss: 8.24021527e-07
Iter: 199 loss: 8.18723038e-07
Iter: 200 loss: 8.25416862e-07
Iter: 201 loss: 8.16023e-07
Iter: 202 loss: 8.12066162e-07
Iter: 203 loss: 8.15934243e-07
Iter: 204 loss: 8.09818232e-07
Iter: 205 loss: 8.05548439e-07
Iter: 206 loss: 8.10787583e-07
Iter: 207 loss: 8.03332625e-07
Iter: 208 loss: 8.05665309e-07
Iter: 209 loss: 8.01982424e-07
Iter: 210 loss: 8.01397618e-07
Iter: 211 loss: 7.99424129e-07
Iter: 212 loss: 7.97308871e-07
Iter: 213 loss: 7.96552854e-07
Iter: 214 loss: 7.93234335e-07
Iter: 215 loss: 7.9314259e-07
Iter: 216 loss: 7.89912633e-07
Iter: 217 loss: 8.02671593e-07
Iter: 218 loss: 7.89184242e-07
Iter: 219 loss: 7.87265151e-07
Iter: 220 loss: 7.81787662e-07
Iter: 221 loss: 8.0764687e-07
Iter: 222 loss: 7.7984555e-07
Iter: 223 loss: 7.73885176e-07
Iter: 224 loss: 7.73414229e-07
Iter: 225 loss: 7.71559712e-07
Iter: 226 loss: 7.6814257e-07
Iter: 227 loss: 8.44482884e-07
Iter: 228 loss: 7.6812853e-07
Iter: 229 loss: 7.65278287e-07
Iter: 230 loss: 7.81633901e-07
Iter: 231 loss: 7.64880838e-07
Iter: 232 loss: 7.64250785e-07
Iter: 233 loss: 7.63802404e-07
Iter: 234 loss: 7.63156095e-07
Iter: 235 loss: 7.61251499e-07
Iter: 236 loss: 7.70075872e-07
Iter: 237 loss: 7.60566877e-07
Iter: 238 loss: 7.5803564e-07
Iter: 239 loss: 7.78529056e-07
Iter: 240 loss: 7.57863916e-07
Iter: 241 loss: 7.56599945e-07
Iter: 242 loss: 7.72610065e-07
Iter: 243 loss: 7.56596592e-07
Iter: 244 loss: 7.5489578e-07
Iter: 245 loss: 7.50826416e-07
Iter: 246 loss: 7.93889967e-07
Iter: 247 loss: 7.50339e-07
Iter: 248 loss: 7.47224306e-07
Iter: 249 loss: 7.65836944e-07
Iter: 250 loss: 7.46836292e-07
Iter: 251 loss: 7.45443117e-07
Iter: 252 loss: 7.45257125e-07
Iter: 253 loss: 7.43942337e-07
Iter: 254 loss: 7.40438452e-07
Iter: 255 loss: 7.65607524e-07
Iter: 256 loss: 7.39653728e-07
Iter: 257 loss: 7.38943925e-07
Iter: 258 loss: 7.38176709e-07
Iter: 259 loss: 7.36411607e-07
Iter: 260 loss: 7.32292563e-07
Iter: 261 loss: 7.80667165e-07
Iter: 262 loss: 7.31927457e-07
Iter: 263 loss: 7.28984901e-07
Iter: 264 loss: 7.45361945e-07
Iter: 265 loss: 7.28556643e-07
Iter: 266 loss: 7.26885332e-07
Iter: 267 loss: 7.45648094e-07
Iter: 268 loss: 7.26832354e-07
Iter: 269 loss: 7.24752908e-07
Iter: 270 loss: 7.23859841e-07
Iter: 271 loss: 7.22774416e-07
Iter: 272 loss: 7.21583206e-07
Iter: 273 loss: 7.2311218e-07
Iter: 274 loss: 7.210013e-07
Iter: 275 loss: 7.1923057e-07
Iter: 276 loss: 7.20291609e-07
Iter: 277 loss: 7.18060051e-07
Iter: 278 loss: 7.15137389e-07
Iter: 279 loss: 7.3809997e-07
Iter: 280 loss: 7.14960663e-07
Iter: 281 loss: 7.13413556e-07
Iter: 282 loss: 7.0935755e-07
Iter: 283 loss: 7.39772531e-07
Iter: 284 loss: 7.08540711e-07
Iter: 285 loss: 7.05968318e-07
Iter: 286 loss: 7.05591219e-07
Iter: 287 loss: 7.03231649e-07
Iter: 288 loss: 7.15392616e-07
Iter: 289 loss: 7.02840907e-07
Iter: 290 loss: 7.01934425e-07
Iter: 291 loss: 7.00258397e-07
Iter: 292 loss: 7.39642473e-07
Iter: 293 loss: 7.0026249e-07
Iter: 294 loss: 6.98917688e-07
Iter: 295 loss: 6.98742951e-07
Iter: 296 loss: 6.98368297e-07
Iter: 297 loss: 6.97432938e-07
Iter: 298 loss: 7.04199124e-07
Iter: 299 loss: 6.97199539e-07
Iter: 300 loss: 6.95675112e-07
Iter: 301 loss: 6.98174745e-07
Iter: 302 loss: 6.9495303e-07
Iter: 303 loss: 6.92813e-07
Iter: 304 loss: 7.07741492e-07
Iter: 305 loss: 6.92597609e-07
Iter: 306 loss: 6.91491664e-07
Iter: 307 loss: 6.88490559e-07
Iter: 308 loss: 7.07102e-07
Iter: 309 loss: 6.87705153e-07
Iter: 310 loss: 6.85066198e-07
Iter: 311 loss: 6.84921133e-07
Iter: 312 loss: 6.8363471e-07
Iter: 313 loss: 6.83579401e-07
Iter: 314 loss: 6.82815312e-07
Iter: 315 loss: 6.80914241e-07
Iter: 316 loss: 6.98770123e-07
Iter: 317 loss: 6.80633548e-07
Iter: 318 loss: 6.79191658e-07
Iter: 319 loss: 6.95176539e-07
Iter: 320 loss: 6.79137315e-07
Iter: 321 loss: 6.78525794e-07
Iter: 322 loss: 6.78428137e-07
Iter: 323 loss: 6.77941898e-07
Iter: 324 loss: 6.76260129e-07
Iter: 325 loss: 6.76289119e-07
Iter: 326 loss: 6.74546072e-07
Iter: 327 loss: 6.78048423e-07
Iter: 328 loss: 6.7369848e-07
Iter: 329 loss: 6.73182171e-07
Iter: 330 loss: 6.71738405e-07
Iter: 331 loss: 6.76936622e-07
Iter: 332 loss: 6.71104e-07
Iter: 333 loss: 6.68971211e-07
Iter: 334 loss: 6.7637643e-07
Iter: 335 loss: 6.68455243e-07
Iter: 336 loss: 6.67613222e-07
Iter: 337 loss: 6.6743263e-07
Iter: 338 loss: 6.66763754e-07
Iter: 339 loss: 6.64731374e-07
Iter: 340 loss: 6.70313852e-07
Iter: 341 loss: 6.63647484e-07
Iter: 342 loss: 6.61364e-07
Iter: 343 loss: 6.82613859e-07
Iter: 344 loss: 6.61263698e-07
Iter: 345 loss: 6.59676118e-07
Iter: 346 loss: 6.5967447e-07
Iter: 347 loss: 6.5821331e-07
Iter: 348 loss: 6.57119e-07
Iter: 349 loss: 6.56644943e-07
Iter: 350 loss: 6.55688609e-07
Iter: 351 loss: 6.58798854e-07
Iter: 352 loss: 6.55443841e-07
Iter: 353 loss: 6.54707492e-07
Iter: 354 loss: 6.64200684e-07
Iter: 355 loss: 6.54726136e-07
Iter: 356 loss: 6.53933853e-07
Iter: 357 loss: 6.53112238e-07
Iter: 358 loss: 6.52948529e-07
Iter: 359 loss: 6.52320523e-07
Iter: 360 loss: 6.54839482e-07
Iter: 361 loss: 6.52156928e-07
Iter: 362 loss: 6.51090488e-07
Iter: 363 loss: 6.50927348e-07
Iter: 364 loss: 6.50212087e-07
Iter: 365 loss: 6.48962782e-07
Iter: 366 loss: 6.47695174e-07
Iter: 367 loss: 6.4743017e-07
Iter: 368 loss: 6.46297508e-07
Iter: 369 loss: 6.46205365e-07
Iter: 370 loss: 6.44809461e-07
Iter: 371 loss: 6.4344465e-07
Iter: 372 loss: 6.43157534e-07
Iter: 373 loss: 6.42322277e-07
Iter: 374 loss: 6.43234614e-07
Iter: 375 loss: 6.41866734e-07
Iter: 376 loss: 6.41072518e-07
Iter: 377 loss: 6.52676e-07
Iter: 378 loss: 6.41056431e-07
Iter: 379 loss: 6.40420183e-07
Iter: 380 loss: 6.42549594e-07
Iter: 381 loss: 6.4023186e-07
Iter: 382 loss: 6.3987369e-07
Iter: 383 loss: 6.38989491e-07
Iter: 384 loss: 6.48565845e-07
Iter: 385 loss: 6.38890072e-07
Iter: 386 loss: 6.37515086e-07
Iter: 387 loss: 6.43625754e-07
Iter: 388 loss: 6.37251219e-07
Iter: 389 loss: 6.35738957e-07
Iter: 390 loss: 6.46565525e-07
Iter: 391 loss: 6.35578e-07
Iter: 392 loss: 6.34758578e-07
Iter: 393 loss: 6.32764568e-07
Iter: 394 loss: 6.52898734e-07
Iter: 395 loss: 6.32530771e-07
Iter: 396 loss: 6.31969442e-07
Iter: 397 loss: 6.31184037e-07
Iter: 398 loss: 6.30791419e-07
Iter: 399 loss: 6.29768238e-07
Iter: 400 loss: 6.39815653e-07
Iter: 401 loss: 6.2963619e-07
Iter: 402 loss: 6.28694465e-07
Iter: 403 loss: 6.38045321e-07
Iter: 404 loss: 6.28661041e-07
Iter: 405 loss: 6.2785864e-07
Iter: 406 loss: 6.35719289e-07
Iter: 407 loss: 6.27842553e-07
Iter: 408 loss: 6.27576298e-07
Iter: 409 loss: 6.26761675e-07
Iter: 410 loss: 6.29398414e-07
Iter: 411 loss: 6.26378096e-07
Iter: 412 loss: 6.25420171e-07
Iter: 413 loss: 6.2541028e-07
Iter: 414 loss: 6.24594804e-07
Iter: 415 loss: 6.29828605e-07
Iter: 416 loss: 6.24496579e-07
Iter: 417 loss: 6.2398982e-07
Iter: 418 loss: 6.22895527e-07
Iter: 419 loss: 6.39127734e-07
Iter: 420 loss: 6.22848574e-07
Iter: 421 loss: 6.21691e-07
Iter: 422 loss: 6.32635306e-07
Iter: 423 loss: 6.21642e-07
Iter: 424 loss: 6.21068239e-07
Iter: 425 loss: 6.21041181e-07
Iter: 426 loss: 6.20672722e-07
Iter: 427 loss: 6.19594e-07
Iter: 428 loss: 6.24179506e-07
Iter: 429 loss: 6.19146476e-07
Iter: 430 loss: 6.20012e-07
Iter: 431 loss: 6.18753347e-07
Iter: 432 loss: 6.18452191e-07
Iter: 433 loss: 6.17637227e-07
Iter: 434 loss: 6.23073845e-07
Iter: 435 loss: 6.17461581e-07
Iter: 436 loss: 6.16369562e-07
Iter: 437 loss: 6.15493718e-07
Iter: 438 loss: 6.15178351e-07
Iter: 439 loss: 6.14567853e-07
Iter: 440 loss: 6.14470594e-07
Iter: 441 loss: 6.13926602e-07
Iter: 442 loss: 6.16030491e-07
Iter: 443 loss: 6.1378023e-07
Iter: 444 loss: 6.13322413e-07
Iter: 445 loss: 6.12250801e-07
Iter: 446 loss: 6.23645633e-07
Iter: 447 loss: 6.12121312e-07
Iter: 448 loss: 6.12026724e-07
Iter: 449 loss: 6.1159966e-07
Iter: 450 loss: 6.11112739e-07
Iter: 451 loss: 6.10318182e-07
Iter: 452 loss: 6.10321081e-07
Iter: 453 loss: 6.09238782e-07
Iter: 454 loss: 6.09708763e-07
Iter: 455 loss: 6.08524431e-07
Iter: 456 loss: 6.07519439e-07
Iter: 457 loss: 6.18079184e-07
Iter: 458 loss: 6.07497327e-07
Iter: 459 loss: 6.06577828e-07
Iter: 460 loss: 6.11283e-07
Iter: 461 loss: 6.06467324e-07
Iter: 462 loss: 6.05877574e-07
Iter: 463 loss: 6.05383377e-07
Iter: 464 loss: 6.05221032e-07
Iter: 465 loss: 6.05319144e-07
Iter: 466 loss: 6.04954266e-07
Iter: 467 loss: 6.0481284e-07
Iter: 468 loss: 6.04308468e-07
Iter: 469 loss: 6.04209617e-07
Iter: 470 loss: 6.03773515e-07
Iter: 471 loss: 6.0304319e-07
Iter: 472 loss: 6.03048306e-07
Iter: 473 loss: 6.02426155e-07
Iter: 474 loss: 6.04412151e-07
Iter: 475 loss: 6.02275236e-07
Iter: 476 loss: 6.01565944e-07
Iter: 477 loss: 6.00531621e-07
Iter: 478 loss: 6.00497401e-07
Iter: 479 loss: 5.99389921e-07
Iter: 480 loss: 6.03619469e-07
Iter: 481 loss: 5.99107182e-07
Iter: 482 loss: 5.98797101e-07
Iter: 483 loss: 5.98627366e-07
Iter: 484 loss: 5.98253393e-07
Iter: 485 loss: 5.97377607e-07
Iter: 486 loss: 6.07662173e-07
Iter: 487 loss: 5.97297e-07
Iter: 488 loss: 5.9679445e-07
Iter: 489 loss: 6.033207e-07
Iter: 490 loss: 5.96788e-07
Iter: 491 loss: 5.96406835e-07
Iter: 492 loss: 5.97343728e-07
Iter: 493 loss: 5.96286384e-07
Iter: 494 loss: 5.9569561e-07
Iter: 495 loss: 5.95519964e-07
Iter: 496 loss: 5.95112624e-07
Iter: 497 loss: 5.94385654e-07
Iter: 498 loss: 5.9572011e-07
Iter: 499 loss: 5.94045446e-07
Iter: 500 loss: 5.93377308e-07
Iter: 501 loss: 5.9338538e-07
Iter: 502 loss: 5.92942456e-07
Iter: 503 loss: 5.91618118e-07
Iter: 504 loss: 5.95284405e-07
Iter: 505 loss: 5.90912407e-07
Iter: 506 loss: 5.90965101e-07
Iter: 507 loss: 5.90414686e-07
Iter: 508 loss: 5.89893432e-07
Iter: 509 loss: 5.90445e-07
Iter: 510 loss: 5.89572892e-07
Iter: 511 loss: 5.8905448e-07
Iter: 512 loss: 5.88712396e-07
Iter: 513 loss: 5.88518674e-07
Iter: 514 loss: 5.87961608e-07
Iter: 515 loss: 5.91392848e-07
Iter: 516 loss: 5.87920169e-07
Iter: 517 loss: 5.87227532e-07
Iter: 518 loss: 5.9011586e-07
Iter: 519 loss: 5.87098214e-07
Iter: 520 loss: 5.8669707e-07
Iter: 521 loss: 5.86453552e-07
Iter: 522 loss: 5.86285296e-07
Iter: 523 loss: 5.85897396e-07
Iter: 524 loss: 5.88185628e-07
Iter: 525 loss: 5.85851581e-07
Iter: 526 loss: 5.85480166e-07
Iter: 527 loss: 5.88212401e-07
Iter: 528 loss: 5.85456348e-07
Iter: 529 loss: 5.85147632e-07
Iter: 530 loss: 5.85113526e-07
Iter: 531 loss: 5.84879103e-07
Iter: 532 loss: 5.84610575e-07
Iter: 533 loss: 5.86391479e-07
Iter: 534 loss: 5.8459807e-07
Iter: 535 loss: 5.84189138e-07
Iter: 536 loss: 5.83327449e-07
Iter: 537 loss: 5.96703671e-07
Iter: 538 loss: 5.83294593e-07
Iter: 539 loss: 5.8236941e-07
Iter: 540 loss: 5.84066413e-07
Iter: 541 loss: 5.82005669e-07
Iter: 542 loss: 5.81641075e-07
Iter: 543 loss: 5.81532845e-07
Iter: 544 loss: 5.81088e-07
Iter: 545 loss: 5.80313554e-07
Iter: 546 loss: 5.99237069e-07
Iter: 547 loss: 5.80324354e-07
Iter: 548 loss: 5.80017058e-07
Iter: 549 loss: 5.83425503e-07
Iter: 550 loss: 5.80014671e-07
Iter: 551 loss: 5.79821e-07
Iter: 552 loss: 5.81989639e-07
Iter: 553 loss: 5.79824e-07
Iter: 554 loss: 5.79630068e-07
Iter: 555 loss: 5.79266384e-07
Iter: 556 loss: 5.85053613e-07
Iter: 557 loss: 5.79263769e-07
Iter: 558 loss: 5.78917138e-07
Iter: 559 loss: 5.80029109e-07
Iter: 560 loss: 5.78835227e-07
Iter: 561 loss: 5.78480922e-07
Iter: 562 loss: 5.81007e-07
Iter: 563 loss: 5.78444599e-07
Iter: 564 loss: 5.78028676e-07
Iter: 565 loss: 5.77535332e-07
Iter: 566 loss: 5.7745757e-07
Iter: 567 loss: 5.76928073e-07
Iter: 568 loss: 5.80936671e-07
Iter: 569 loss: 5.76892944e-07
Iter: 570 loss: 5.76580305e-07
Iter: 571 loss: 5.81402333e-07
Iter: 572 loss: 5.76585364e-07
Iter: 573 loss: 5.76374759e-07
Iter: 574 loss: 5.75885e-07
Iter: 575 loss: 5.80512165e-07
Iter: 576 loss: 5.75828039e-07
Iter: 577 loss: 5.75623289e-07
Iter: 578 loss: 5.75605668e-07
Iter: 579 loss: 5.75347258e-07
Iter: 580 loss: 5.751765e-07
Iter: 581 loss: 5.75082538e-07
Iter: 582 loss: 5.7472937e-07
Iter: 583 loss: 5.74743467e-07
Iter: 584 loss: 5.74448677e-07
Iter: 585 loss: 5.74370688e-07
Iter: 586 loss: 5.74302476e-07
Iter: 587 loss: 5.74122339e-07
Iter: 588 loss: 5.7376792e-07
Iter: 589 loss: 5.79955213e-07
Iter: 590 loss: 5.73762918e-07
Iter: 591 loss: 5.7343982e-07
Iter: 592 loss: 5.75008926e-07
Iter: 593 loss: 5.73375814e-07
Iter: 594 loss: 5.73184195e-07
Iter: 595 loss: 5.74880858e-07
Iter: 596 loss: 5.73143325e-07
Iter: 597 loss: 5.72876843e-07
Iter: 598 loss: 5.72881049e-07
Iter: 599 loss: 5.72683348e-07
Iter: 600 loss: 5.7238492e-07
Iter: 601 loss: 5.72930389e-07
Iter: 602 loss: 5.72263843e-07
Iter: 603 loss: 5.72018e-07
Iter: 604 loss: 5.75177864e-07
Iter: 605 loss: 5.71999635e-07
Iter: 606 loss: 5.7175032e-07
Iter: 607 loss: 5.71280964e-07
Iter: 608 loss: 5.82801e-07
Iter: 609 loss: 5.7129364e-07
Iter: 610 loss: 5.71063481e-07
Iter: 611 loss: 5.73139403e-07
Iter: 612 loss: 5.7105882e-07
Iter: 613 loss: 5.70892553e-07
Iter: 614 loss: 5.72544309e-07
Iter: 615 loss: 5.70905058e-07
Iter: 616 loss: 5.70773864e-07
Iter: 617 loss: 5.7051534e-07
Iter: 618 loss: 5.74413093e-07
Iter: 619 loss: 5.70474185e-07
Iter: 620 loss: 5.70284e-07
Iter: 621 loss: 5.72567558e-07
Iter: 622 loss: 5.70269265e-07
Iter: 623 loss: 5.70050361e-07
Iter: 624 loss: 5.70515e-07
Iter: 625 loss: 5.6994395e-07
Iter: 626 loss: 5.69757958e-07
Iter: 627 loss: 5.69488179e-07
Iter: 628 loss: 5.69470274e-07
Iter: 629 loss: 5.69171789e-07
Iter: 630 loss: 5.70850659e-07
Iter: 631 loss: 5.69132169e-07
Iter: 632 loss: 5.68823168e-07
Iter: 633 loss: 5.71583882e-07
Iter: 634 loss: 5.68777807e-07
Iter: 635 loss: 5.68648602e-07
Iter: 636 loss: 5.68684754e-07
Iter: 637 loss: 5.68572716e-07
Iter: 638 loss: 5.68400935e-07
Iter: 639 loss: 5.69331064e-07
Iter: 640 loss: 5.68369273e-07
Iter: 641 loss: 5.68156679e-07
Iter: 642 loss: 5.67891391e-07
Iter: 643 loss: 5.67847565e-07
Iter: 644 loss: 5.67567213e-07
Iter: 645 loss: 5.6810029e-07
Iter: 646 loss: 5.67467225e-07
Iter: 647 loss: 5.67258326e-07
Iter: 648 loss: 5.67263157e-07
Iter: 649 loss: 5.67045731e-07
Iter: 650 loss: 5.66733604e-07
Iter: 651 loss: 5.6673565e-07
Iter: 652 loss: 5.66527945e-07
Iter: 653 loss: 5.67011909e-07
Iter: 654 loss: 5.66442282e-07
Iter: 655 loss: 5.66177278e-07
Iter: 656 loss: 5.6815918e-07
Iter: 657 loss: 5.6614067e-07
Iter: 658 loss: 5.65965308e-07
Iter: 659 loss: 5.65709115e-07
Iter: 660 loss: 5.65674554e-07
Iter: 661 loss: 5.6535788e-07
Iter: 662 loss: 5.65283244e-07
Iter: 663 loss: 5.6508236e-07
Iter: 664 loss: 5.64749485e-07
Iter: 665 loss: 5.64720722e-07
Iter: 666 loss: 5.64576794e-07
Iter: 667 loss: 5.6431054e-07
Iter: 668 loss: 5.64315314e-07
Iter: 669 loss: 5.64042352e-07
Iter: 670 loss: 5.66399194e-07
Iter: 671 loss: 5.64020468e-07
Iter: 672 loss: 5.63806509e-07
Iter: 673 loss: 5.64714696e-07
Iter: 674 loss: 5.63751087e-07
Iter: 675 loss: 5.63636888e-07
Iter: 676 loss: 5.63448907e-07
Iter: 677 loss: 5.63442882e-07
Iter: 678 loss: 5.63180379e-07
Iter: 679 loss: 5.64510515e-07
Iter: 680 loss: 5.63112962e-07
Iter: 681 loss: 5.62695789e-07
Iter: 682 loss: 5.62649689e-07
Iter: 683 loss: 5.62348418e-07
Iter: 684 loss: 5.61945171e-07
Iter: 685 loss: 5.61223487e-07
Iter: 686 loss: 5.78058689e-07
Iter: 687 loss: 5.61222748e-07
Iter: 688 loss: 5.60674437e-07
Iter: 689 loss: 5.60563592e-07
Iter: 690 loss: 5.601417e-07
Iter: 691 loss: 5.59394209e-07
Iter: 692 loss: 5.59407795e-07
Iter: 693 loss: 5.58637623e-07
Iter: 694 loss: 5.58289344e-07
Iter: 695 loss: 5.5792259e-07
Iter: 696 loss: 5.58440149e-07
Iter: 697 loss: 5.57592728e-07
Iter: 698 loss: 5.5736939e-07
Iter: 699 loss: 5.56735074e-07
Iter: 700 loss: 5.60587694e-07
Iter: 701 loss: 5.56545331e-07
Iter: 702 loss: 5.55580471e-07
Iter: 703 loss: 5.5538078e-07
Iter: 704 loss: 5.547314e-07
Iter: 705 loss: 5.55715587e-07
Iter: 706 loss: 5.54325823e-07
Iter: 707 loss: 5.54037456e-07
Iter: 708 loss: 5.53231644e-07
Iter: 709 loss: 5.55344627e-07
Iter: 710 loss: 5.52762231e-07
Iter: 711 loss: 5.51885933e-07
Iter: 712 loss: 5.65027392e-07
Iter: 713 loss: 5.51888888e-07
Iter: 714 loss: 5.51016683e-07
Iter: 715 loss: 5.56860755e-07
Iter: 716 loss: 5.50908453e-07
Iter: 717 loss: 5.50223831e-07
Iter: 718 loss: 5.48890796e-07
Iter: 719 loss: 5.75582646e-07
Iter: 720 loss: 5.48857713e-07
Iter: 721 loss: 5.48501134e-07
Iter: 722 loss: 5.48268076e-07
Iter: 723 loss: 5.47652064e-07
Iter: 724 loss: 5.46941806e-07
Iter: 725 loss: 5.46884451e-07
Iter: 726 loss: 5.45954322e-07
Iter: 727 loss: 5.45565399e-07
Iter: 728 loss: 5.45082116e-07
Iter: 729 loss: 5.44992076e-07
Iter: 730 loss: 5.44781642e-07
Iter: 731 loss: 5.44407271e-07
Iter: 732 loss: 5.43840429e-07
Iter: 733 loss: 5.43837302e-07
Iter: 734 loss: 5.43162571e-07
Iter: 735 loss: 5.43387159e-07
Iter: 736 loss: 5.42688952e-07
Iter: 737 loss: 5.42301e-07
Iter: 738 loss: 5.42275643e-07
Iter: 739 loss: 5.41773545e-07
Iter: 740 loss: 5.41717213e-07
Iter: 741 loss: 5.4136467e-07
Iter: 742 loss: 5.40857e-07
Iter: 743 loss: 5.4033211e-07
Iter: 744 loss: 5.40245765e-07
Iter: 745 loss: 5.3956137e-07
Iter: 746 loss: 5.39564326e-07
Iter: 747 loss: 5.38841334e-07
Iter: 748 loss: 5.39659595e-07
Iter: 749 loss: 5.38473614e-07
Iter: 750 loss: 5.3812164e-07
Iter: 751 loss: 5.37849246e-07
Iter: 752 loss: 5.37717483e-07
Iter: 753 loss: 5.36991138e-07
Iter: 754 loss: 5.43989472e-07
Iter: 755 loss: 5.36942366e-07
Iter: 756 loss: 5.36568393e-07
Iter: 757 loss: 5.35990466e-07
Iter: 758 loss: 5.3599706e-07
Iter: 759 loss: 5.35327217e-07
Iter: 760 loss: 5.35480865e-07
Iter: 761 loss: 5.34848482e-07
Iter: 762 loss: 5.35044364e-07
Iter: 763 loss: 5.3454113e-07
Iter: 764 loss: 5.3431063e-07
Iter: 765 loss: 5.3391534e-07
Iter: 766 loss: 5.33913578e-07
Iter: 767 loss: 5.33404659e-07
Iter: 768 loss: 5.32943659e-07
Iter: 769 loss: 5.3280155e-07
Iter: 770 loss: 5.32180195e-07
Iter: 771 loss: 5.32293939e-07
Iter: 772 loss: 5.31734486e-07
Iter: 773 loss: 5.31589421e-07
Iter: 774 loss: 5.31213971e-07
Iter: 775 loss: 5.3091253e-07
Iter: 776 loss: 5.30263833e-07
Iter: 777 loss: 5.39904875e-07
Iter: 778 loss: 5.30238822e-07
Iter: 779 loss: 5.29449267e-07
Iter: 780 loss: 5.29798456e-07
Iter: 781 loss: 5.2891744e-07
Iter: 782 loss: 5.28451608e-07
Iter: 783 loss: 5.28384362e-07
Iter: 784 loss: 5.2787766e-07
Iter: 785 loss: 5.29159365e-07
Iter: 786 loss: 5.27715031e-07
Iter: 787 loss: 5.27252041e-07
Iter: 788 loss: 5.26475e-07
Iter: 789 loss: 5.26475787e-07
Iter: 790 loss: 5.26755855e-07
Iter: 791 loss: 5.26274675e-07
Iter: 792 loss: 5.26117219e-07
Iter: 793 loss: 5.25739665e-07
Iter: 794 loss: 5.30530883e-07
Iter: 795 loss: 5.25709765e-07
Iter: 796 loss: 5.25164864e-07
Iter: 797 loss: 5.24520374e-07
Iter: 798 loss: 5.24437041e-07
Iter: 799 loss: 5.24589609e-07
Iter: 800 loss: 5.24046129e-07
Iter: 801 loss: 5.23780386e-07
Iter: 802 loss: 5.22885898e-07
Iter: 803 loss: 5.27297288e-07
Iter: 804 loss: 5.22593155e-07
Iter: 805 loss: 5.2174488e-07
Iter: 806 loss: 5.26402e-07
Iter: 807 loss: 5.21623519e-07
Iter: 808 loss: 5.21194181e-07
Iter: 809 loss: 5.21179e-07
Iter: 810 loss: 5.20759613e-07
Iter: 811 loss: 5.20454e-07
Iter: 812 loss: 5.20314e-07
Iter: 813 loss: 5.2004151e-07
Iter: 814 loss: 5.20045432e-07
Iter: 815 loss: 5.19845912e-07
Iter: 816 loss: 5.19425782e-07
Iter: 817 loss: 5.21851575e-07
Iter: 818 loss: 5.19378432e-07
Iter: 819 loss: 5.18894296e-07
Iter: 820 loss: 5.20941512e-07
Iter: 821 loss: 5.18803745e-07
Iter: 822 loss: 5.18537604e-07
Iter: 823 loss: 5.18309548e-07
Iter: 824 loss: 5.18248e-07
Iter: 825 loss: 5.17925e-07
Iter: 826 loss: 5.17925855e-07
Iter: 827 loss: 5.17613955e-07
Iter: 828 loss: 5.17323656e-07
Iter: 829 loss: 5.17257718e-07
Iter: 830 loss: 5.16868568e-07
Iter: 831 loss: 5.16508294e-07
Iter: 832 loss: 5.16419391e-07
Iter: 833 loss: 5.16158138e-07
Iter: 834 loss: 5.16030411e-07
Iter: 835 loss: 5.15753072e-07
Iter: 836 loss: 5.15298211e-07
Iter: 837 loss: 5.15298325e-07
Iter: 838 loss: 5.1478645e-07
Iter: 839 loss: 5.13652196e-07
Iter: 840 loss: 5.2947837e-07
Iter: 841 loss: 5.13586087e-07
Iter: 842 loss: 5.13841485e-07
Iter: 843 loss: 5.13148507e-07
Iter: 844 loss: 5.12772431e-07
Iter: 845 loss: 5.15379043e-07
Iter: 846 loss: 5.1271229e-07
Iter: 847 loss: 5.12544e-07
Iter: 848 loss: 5.12023348e-07
Iter: 849 loss: 5.17834e-07
Iter: 850 loss: 5.11970541e-07
Iter: 851 loss: 5.11822805e-07
Iter: 852 loss: 5.11764085e-07
Iter: 853 loss: 5.11455767e-07
Iter: 854 loss: 5.10946109e-07
Iter: 855 loss: 5.1094878e-07
Iter: 856 loss: 5.10625114e-07
Iter: 857 loss: 5.12502538e-07
Iter: 858 loss: 5.10574296e-07
Iter: 859 loss: 5.10129e-07
Iter: 860 loss: 5.12116628e-07
Iter: 861 loss: 5.10079701e-07
Iter: 862 loss: 5.09600909e-07
Iter: 863 loss: 5.08723758e-07
Iter: 864 loss: 5.28052396e-07
Iter: 865 loss: 5.08724156e-07
Iter: 866 loss: 5.0824508e-07
Iter: 867 loss: 5.08231e-07
Iter: 868 loss: 5.07888103e-07
Iter: 869 loss: 5.10401094e-07
Iter: 870 loss: 5.07832397e-07
Iter: 871 loss: 5.07619859e-07
Iter: 872 loss: 5.07052619e-07
Iter: 873 loss: 5.13220755e-07
Iter: 874 loss: 5.06978154e-07
Iter: 875 loss: 5.06483332e-07
Iter: 876 loss: 5.07930508e-07
Iter: 877 loss: 5.06331673e-07
Iter: 878 loss: 5.06246806e-07
Iter: 879 loss: 5.06067693e-07
Iter: 880 loss: 5.05897106e-07
Iter: 881 loss: 5.05605385e-07
Iter: 882 loss: 5.05606579e-07
Iter: 883 loss: 5.05251819e-07
Iter: 884 loss: 5.04775926e-07
Iter: 885 loss: 5.04748357e-07
Iter: 886 loss: 5.04425941e-07
Iter: 887 loss: 5.04303216e-07
Iter: 888 loss: 5.04146215e-07
Iter: 889 loss: 5.03728359e-07
Iter: 890 loss: 5.06341678e-07
Iter: 891 loss: 5.03617116e-07
Iter: 892 loss: 5.03300043e-07
Iter: 893 loss: 5.03277704e-07
Iter: 894 loss: 5.02942157e-07
Iter: 895 loss: 5.0307392e-07
Iter: 896 loss: 5.02711032e-07
Iter: 897 loss: 5.02394414e-07
Iter: 898 loss: 5.01902491e-07
Iter: 899 loss: 5.01898967e-07
Iter: 900 loss: 5.01936825e-07
Iter: 901 loss: 5.0165022e-07
Iter: 902 loss: 5.01485601e-07
Iter: 903 loss: 5.01376462e-07
Iter: 904 loss: 5.01302054e-07
Iter: 905 loss: 5.01056093e-07
Iter: 906 loss: 5.00536771e-07
Iter: 907 loss: 5.09594429e-07
Iter: 908 loss: 5.00508463e-07
Iter: 909 loss: 5.00153078e-07
Iter: 910 loss: 5.04546961e-07
Iter: 911 loss: 5.00147792e-07
Iter: 912 loss: 4.99914279e-07
Iter: 913 loss: 4.9990706e-07
Iter: 914 loss: 4.99683551e-07
Iter: 915 loss: 4.99245857e-07
Iter: 916 loss: 5.08025323e-07
Iter: 917 loss: 4.99225678e-07
Iter: 918 loss: 4.98990119e-07
Iter: 919 loss: 4.98995462e-07
Iter: 920 loss: 4.98679924e-07
Iter: 921 loss: 4.98326358e-07
Iter: 922 loss: 4.9828725e-07
Iter: 923 loss: 4.98017812e-07
Iter: 924 loss: 4.98590907e-07
Iter: 925 loss: 4.97898327e-07
Iter: 926 loss: 4.97742349e-07
Iter: 927 loss: 5.00379713e-07
Iter: 928 loss: 4.97728195e-07
Iter: 929 loss: 4.974994e-07
Iter: 930 loss: 4.9727123e-07
Iter: 931 loss: 4.97230303e-07
Iter: 932 loss: 4.97046869e-07
Iter: 933 loss: 4.98145255e-07
Iter: 934 loss: 4.97027713e-07
Iter: 935 loss: 4.96850873e-07
Iter: 936 loss: 4.97522819e-07
Iter: 937 loss: 4.96798634e-07
Iter: 938 loss: 4.96594225e-07
Iter: 939 loss: 4.96285679e-07
Iter: 940 loss: 4.96279483e-07
Iter: 941 loss: 4.960566e-07
Iter: 942 loss: 4.97403e-07
Iter: 943 loss: 4.96001746e-07
Iter: 944 loss: 4.95803079e-07
Iter: 945 loss: 4.95837185e-07
Iter: 946 loss: 4.956662e-07
Iter: 947 loss: 4.95482368e-07
Iter: 948 loss: 4.95448035e-07
Iter: 949 loss: 4.95352197e-07
Iter: 950 loss: 4.95072186e-07
Iter: 951 loss: 4.96284e-07
Iter: 952 loss: 4.94954861e-07
Iter: 953 loss: 4.9460823e-07
Iter: 954 loss: 4.94596748e-07
Iter: 955 loss: 4.94420078e-07
Iter: 956 loss: 4.94193671e-07
Iter: 957 loss: 4.94160929e-07
Iter: 958 loss: 4.9393617e-07
Iter: 959 loss: 4.95278641e-07
Iter: 960 loss: 4.93901553e-07
Iter: 961 loss: 4.93662128e-07
Iter: 962 loss: 4.93915877e-07
Iter: 963 loss: 4.93512459e-07
Iter: 964 loss: 4.93352104e-07
Iter: 965 loss: 4.93580387e-07
Iter: 966 loss: 4.93273e-07
Iter: 967 loss: 4.93076527e-07
Iter: 968 loss: 4.95032282e-07
Iter: 969 loss: 4.93073401e-07
Iter: 970 loss: 4.92894912e-07
Iter: 971 loss: 4.94027518e-07
Iter: 972 loss: 4.92884055e-07
Iter: 973 loss: 4.92777247e-07
Iter: 974 loss: 4.92488425e-07
Iter: 975 loss: 4.9392338e-07
Iter: 976 loss: 4.9241828e-07
Iter: 977 loss: 4.92014465e-07
Iter: 978 loss: 4.94381652e-07
Iter: 979 loss: 4.9197638e-07
Iter: 980 loss: 4.91695346e-07
Iter: 981 loss: 4.92058575e-07
Iter: 982 loss: 4.91561423e-07
Iter: 983 loss: 4.9155193e-07
Iter: 984 loss: 4.91413743e-07
Iter: 985 loss: 4.9134735e-07
Iter: 986 loss: 4.91165565e-07
Iter: 987 loss: 4.92540494e-07
Iter: 988 loss: 4.91116452e-07
Iter: 989 loss: 4.91006119e-07
Iter: 990 loss: 4.9100106e-07
Iter: 991 loss: 4.90879074e-07
Iter: 992 loss: 4.9092489e-07
Iter: 993 loss: 4.90774255e-07
Iter: 994 loss: 4.90672846e-07
Iter: 995 loss: 4.90630327e-07
Iter: 996 loss: 4.90584853e-07
Iter: 997 loss: 4.90366858e-07
Iter: 998 loss: 4.91310857e-07
Iter: 999 loss: 4.90331e-07
Iter: 1000 loss: 4.90229809e-07
Iter: 1001 loss: 4.90599518e-07
Iter: 1002 loss: 4.90199284e-07
Iter: 1003 loss: 4.90126467e-07
Iter: 1004 loss: 4.89935246e-07
Iter: 1005 loss: 4.92680329e-07
Iter: 1006 loss: 4.89923195e-07
Iter: 1007 loss: 4.89684794e-07
Iter: 1008 loss: 4.89953834e-07
Iter: 1009 loss: 4.89559284e-07
Iter: 1010 loss: 4.89321565e-07
Iter: 1011 loss: 4.89741467e-07
Iter: 1012 loss: 4.89216632e-07
Iter: 1013 loss: 4.88835e-07
Iter: 1014 loss: 4.8947112e-07
Iter: 1015 loss: 4.88682304e-07
Iter: 1016 loss: 4.88259843e-07
Iter: 1017 loss: 4.88167302e-07
Iter: 1018 loss: 4.87918214e-07
Iter: 1019 loss: 4.87839e-07
Iter: 1020 loss: 4.87704597e-07
Iter: 1021 loss: 4.87583236e-07
Iter: 1022 loss: 4.89219e-07
Iter: 1023 loss: 4.87559475e-07
Iter: 1024 loss: 4.87513034e-07
Iter: 1025 loss: 4.87324087e-07
Iter: 1026 loss: 4.87943908e-07
Iter: 1027 loss: 4.87214493e-07
Iter: 1028 loss: 4.87261559e-07
Iter: 1029 loss: 4.871128e-07
Iter: 1030 loss: 4.87041063e-07
Iter: 1031 loss: 4.86791464e-07
Iter: 1032 loss: 4.87339946e-07
Iter: 1033 loss: 4.86605416e-07
Iter: 1034 loss: 4.86509862e-07
Iter: 1035 loss: 4.86405156e-07
Iter: 1036 loss: 4.86191311e-07
Iter: 1037 loss: 4.86386398e-07
Iter: 1038 loss: 4.86102522e-07
Iter: 1039 loss: 4.85901637e-07
Iter: 1040 loss: 4.85572059e-07
Iter: 1041 loss: 4.85584508e-07
Iter: 1042 loss: 4.85327689e-07
Iter: 1043 loss: 4.85277837e-07
Iter: 1044 loss: 4.85111855e-07
Iter: 1045 loss: 4.85042165e-07
Iter: 1046 loss: 4.84966108e-07
Iter: 1047 loss: 4.84745101e-07
Iter: 1048 loss: 4.84386192e-07
Iter: 1049 loss: 4.84385566e-07
Iter: 1050 loss: 4.83891e-07
Iter: 1051 loss: 4.86792828e-07
Iter: 1052 loss: 4.83822589e-07
Iter: 1053 loss: 4.83544056e-07
Iter: 1054 loss: 4.84683255e-07
Iter: 1055 loss: 4.83476185e-07
Iter: 1056 loss: 4.83120743e-07
Iter: 1057 loss: 4.85492933e-07
Iter: 1058 loss: 4.83090446e-07
Iter: 1059 loss: 4.82992846e-07
Iter: 1060 loss: 4.82880807e-07
Iter: 1061 loss: 4.8285068e-07
Iter: 1062 loss: 4.82666223e-07
Iter: 1063 loss: 4.85084172e-07
Iter: 1064 loss: 4.82668952e-07
Iter: 1065 loss: 4.82486e-07
Iter: 1066 loss: 4.82101711e-07
Iter: 1067 loss: 4.8630892e-07
Iter: 1068 loss: 4.82062319e-07
Iter: 1069 loss: 4.81915492e-07
Iter: 1070 loss: 4.81866323e-07
Iter: 1071 loss: 4.81645827e-07
Iter: 1072 loss: 4.81058e-07
Iter: 1073 loss: 4.87453121e-07
Iter: 1074 loss: 4.8101424e-07
Iter: 1075 loss: 4.80472465e-07
Iter: 1076 loss: 4.81133384e-07
Iter: 1077 loss: 4.80190693e-07
Iter: 1078 loss: 4.79913069e-07
Iter: 1079 loss: 4.79905452e-07
Iter: 1080 loss: 4.79723667e-07
Iter: 1081 loss: 4.81870188e-07
Iter: 1082 loss: 4.79721734e-07
Iter: 1083 loss: 4.79630046e-07
Iter: 1084 loss: 4.79572691e-07
Iter: 1085 loss: 4.79517553e-07
Iter: 1086 loss: 4.79374933e-07
Iter: 1087 loss: 4.79433481e-07
Iter: 1088 loss: 4.79311723e-07
Iter: 1089 loss: 4.79121582e-07
Iter: 1090 loss: 4.81131281e-07
Iter: 1091 loss: 4.79115215e-07
Iter: 1092 loss: 4.78910238e-07
Iter: 1093 loss: 4.78679e-07
Iter: 1094 loss: 4.78653817e-07
Iter: 1095 loss: 4.78440768e-07
Iter: 1096 loss: 4.79357e-07
Iter: 1097 loss: 4.78399841e-07
Iter: 1098 loss: 4.78014897e-07
Iter: 1099 loss: 4.77920594e-07
Iter: 1100 loss: 4.77686172e-07
Iter: 1101 loss: 4.77402693e-07
Iter: 1102 loss: 4.79345e-07
Iter: 1103 loss: 4.77387289e-07
Iter: 1104 loss: 4.77241542e-07
Iter: 1105 loss: 4.77242224e-07
Iter: 1106 loss: 4.7716361e-07
Iter: 1107 loss: 4.76980802e-07
Iter: 1108 loss: 4.77718231e-07
Iter: 1109 loss: 4.76895877e-07
Iter: 1110 loss: 4.76666798e-07
Iter: 1111 loss: 4.78199e-07
Iter: 1112 loss: 4.76622915e-07
Iter: 1113 loss: 4.76501612e-07
Iter: 1114 loss: 4.76496211e-07
Iter: 1115 loss: 4.76367518e-07
Iter: 1116 loss: 4.76225466e-07
Iter: 1117 loss: 4.76203553e-07
Iter: 1118 loss: 4.75999e-07
Iter: 1119 loss: 4.76590941e-07
Iter: 1120 loss: 4.75945626e-07
Iter: 1121 loss: 4.75769127e-07
Iter: 1122 loss: 4.76526736e-07
Iter: 1123 loss: 4.75741956e-07
Iter: 1124 loss: 4.7556253e-07
Iter: 1125 loss: 4.76134176e-07
Iter: 1126 loss: 4.75509097e-07
Iter: 1127 loss: 4.75381825e-07
Iter: 1128 loss: 4.7532248e-07
Iter: 1129 loss: 4.75246395e-07
Iter: 1130 loss: 4.75119577e-07
Iter: 1131 loss: 4.75127933e-07
Iter: 1132 loss: 4.74984347e-07
Iter: 1133 loss: 4.74596163e-07
Iter: 1134 loss: 4.75887873e-07
Iter: 1135 loss: 4.74411706e-07
Iter: 1136 loss: 4.7462666e-07
Iter: 1137 loss: 4.74256865e-07
Iter: 1138 loss: 4.74133145e-07
Iter: 1139 loss: 4.74011813e-07
Iter: 1140 loss: 4.74004565e-07
Iter: 1141 loss: 4.73822e-07
Iter: 1142 loss: 4.73730665e-07
Iter: 1143 loss: 4.73657337e-07
Iter: 1144 loss: 4.73644064e-07
Iter: 1145 loss: 4.73577188e-07
Iter: 1146 loss: 4.73521254e-07
Iter: 1147 loss: 4.73460943e-07
Iter: 1148 loss: 4.73449973e-07
Iter: 1149 loss: 4.73337593e-07
Iter: 1150 loss: 4.73504855e-07
Iter: 1151 loss: 4.73298087e-07
Iter: 1152 loss: 4.73166608e-07
Iter: 1153 loss: 4.73514575e-07
Iter: 1154 loss: 4.73119911e-07
Iter: 1155 loss: 4.72934e-07
Iter: 1156 loss: 4.73152284e-07
Iter: 1157 loss: 4.72830095e-07
Iter: 1158 loss: 4.72624464e-07
Iter: 1159 loss: 4.72447311e-07
Iter: 1160 loss: 4.72366651e-07
Iter: 1161 loss: 4.72174463e-07
Iter: 1162 loss: 4.72174435e-07
Iter: 1163 loss: 4.72017632e-07
Iter: 1164 loss: 4.71840167e-07
Iter: 1165 loss: 4.71820385e-07
Iter: 1166 loss: 4.71656023e-07
Iter: 1167 loss: 4.7239547e-07
Iter: 1168 loss: 4.71630671e-07
Iter: 1169 loss: 4.71429445e-07
Iter: 1170 loss: 4.7255611e-07
Iter: 1171 loss: 4.71401478e-07
Iter: 1172 loss: 4.71291116e-07
Iter: 1173 loss: 4.71041062e-07
Iter: 1174 loss: 4.74263743e-07
Iter: 1175 loss: 4.71024748e-07
Iter: 1176 loss: 4.70833328e-07
Iter: 1177 loss: 4.72132825e-07
Iter: 1178 loss: 4.70821504e-07
Iter: 1179 loss: 4.70601975e-07
Iter: 1180 loss: 4.71831981e-07
Iter: 1181 loss: 4.70569091e-07
Iter: 1182 loss: 4.70347942e-07
Iter: 1183 loss: 4.70048491e-07
Iter: 1184 loss: 4.70034138e-07
Iter: 1185 loss: 4.69788461e-07
Iter: 1186 loss: 4.72563e-07
Iter: 1187 loss: 4.69800398e-07
Iter: 1188 loss: 4.69605396e-07
Iter: 1189 loss: 4.71416058e-07
Iter: 1190 loss: 4.6961307e-07
Iter: 1191 loss: 4.6943191e-07
Iter: 1192 loss: 4.69118788e-07
Iter: 1193 loss: 4.76712103e-07
Iter: 1194 loss: 4.69112535e-07
Iter: 1195 loss: 4.68885275e-07
Iter: 1196 loss: 4.69290455e-07
Iter: 1197 loss: 4.68803194e-07
Iter: 1198 loss: 4.68493511e-07
Iter: 1199 loss: 4.72075016e-07
Iter: 1200 loss: 4.68486149e-07
Iter: 1201 loss: 4.68396706e-07
Iter: 1202 loss: 4.68271224e-07
Iter: 1203 loss: 4.68262783e-07
Iter: 1204 loss: 4.6814074e-07
Iter: 1205 loss: 4.68137216e-07
Iter: 1206 loss: 4.68021199e-07
Iter: 1207 loss: 4.67839357e-07
Iter: 1208 loss: 4.67845297e-07
Iter: 1209 loss: 4.67718934e-07
Iter: 1210 loss: 4.67701966e-07
Iter: 1211 loss: 4.67609567e-07
Iter: 1212 loss: 4.67425764e-07
Iter: 1213 loss: 4.68680923e-07
Iter: 1214 loss: 4.6743267e-07
Iter: 1215 loss: 4.67251709e-07
Iter: 1216 loss: 4.67121936e-07
Iter: 1217 loss: 4.67042526e-07
Iter: 1218 loss: 4.66856932e-07
Iter: 1219 loss: 4.67537063e-07
Iter: 1220 loss: 4.66802419e-07
Iter: 1221 loss: 4.66617223e-07
Iter: 1222 loss: 4.67624943e-07
Iter: 1223 loss: 4.66597669e-07
Iter: 1224 loss: 4.66382289e-07
Iter: 1225 loss: 4.67443442e-07
Iter: 1226 loss: 4.66346535e-07
Iter: 1227 loss: 4.66249077e-07
Iter: 1228 loss: 4.66060612e-07
Iter: 1229 loss: 4.66053052e-07
Iter: 1230 loss: 4.65968697e-07
Iter: 1231 loss: 4.65937092e-07
Iter: 1232 loss: 4.65843101e-07
Iter: 1233 loss: 4.65810558e-07
Iter: 1234 loss: 4.65758603e-07
Iter: 1235 loss: 4.65689794e-07
Iter: 1236 loss: 4.66082213e-07
Iter: 1237 loss: 4.65675555e-07
Iter: 1238 loss: 4.65553796e-07
Iter: 1239 loss: 4.65335859e-07
Iter: 1240 loss: 4.69834049e-07
Iter: 1241 loss: 4.65311132e-07
Iter: 1242 loss: 4.65105984e-07
Iter: 1243 loss: 4.6609e-07
Iter: 1244 loss: 4.65070229e-07
Iter: 1245 loss: 4.64873324e-07
Iter: 1246 loss: 4.66392123e-07
Iter: 1247 loss: 4.64870595e-07
Iter: 1248 loss: 4.64687247e-07
Iter: 1249 loss: 4.64751963e-07
Iter: 1250 loss: 4.64563755e-07
Iter: 1251 loss: 4.6443094e-07
Iter: 1252 loss: 4.64350762e-07
Iter: 1253 loss: 4.64263707e-07
Iter: 1254 loss: 4.6398236e-07
Iter: 1255 loss: 4.64861046e-07
Iter: 1256 loss: 4.63914944e-07
Iter: 1257 loss: 4.63773659e-07
Iter: 1258 loss: 4.6375402e-07
Iter: 1259 loss: 4.6366921e-07
Iter: 1260 loss: 4.63506979e-07
Iter: 1261 loss: 4.65567751e-07
Iter: 1262 loss: 4.63492256e-07
Iter: 1263 loss: 4.63276706e-07
Iter: 1264 loss: 4.64204788e-07
Iter: 1265 loss: 4.63239218e-07
Iter: 1266 loss: 4.62975493e-07
Iter: 1267 loss: 4.63951864e-07
Iter: 1268 loss: 4.62914954e-07
Iter: 1269 loss: 4.62793054e-07
Iter: 1270 loss: 4.62651542e-07
Iter: 1271 loss: 4.62638269e-07
Iter: 1272 loss: 4.62363289e-07
Iter: 1273 loss: 4.64745767e-07
Iter: 1274 loss: 4.62350386e-07
Iter: 1275 loss: 4.62229309e-07
Iter: 1276 loss: 4.62078162e-07
Iter: 1277 loss: 4.62070915e-07
Iter: 1278 loss: 4.61915789e-07
Iter: 1279 loss: 4.63526e-07
Iter: 1280 loss: 4.61923463e-07
Iter: 1281 loss: 4.61749494e-07
Iter: 1282 loss: 4.61959104e-07
Iter: 1283 loss: 4.61659454e-07
Iter: 1284 loss: 4.61542754e-07
Iter: 1285 loss: 4.6146485e-07
Iter: 1286 loss: 4.6141e-07
Iter: 1287 loss: 4.61157555e-07
Iter: 1288 loss: 4.61051911e-07
Iter: 1289 loss: 4.60918585e-07
Iter: 1290 loss: 4.60793927e-07
Iter: 1291 loss: 4.60712045e-07
Iter: 1292 loss: 4.60583465e-07
Iter: 1293 loss: 4.60564024e-07
Iter: 1294 loss: 4.60458068e-07
Iter: 1295 loss: 4.60318603e-07
Iter: 1296 loss: 4.60096885e-07
Iter: 1297 loss: 4.60099955e-07
Iter: 1298 loss: 4.60166547e-07
Iter: 1299 loss: 4.59979447e-07
Iter: 1300 loss: 4.59927e-07
Iter: 1301 loss: 4.59780154e-07
Iter: 1302 loss: 4.60519885e-07
Iter: 1303 loss: 4.59708303e-07
Iter: 1304 loss: 4.59553718e-07
Iter: 1305 loss: 4.61612103e-07
Iter: 1306 loss: 4.59539876e-07
Iter: 1307 loss: 4.59416299e-07
Iter: 1308 loss: 4.60781337e-07
Iter: 1309 loss: 4.59399e-07
Iter: 1310 loss: 4.59348314e-07
Iter: 1311 loss: 4.59120884e-07
Iter: 1312 loss: 4.59208252e-07
Iter: 1313 loss: 4.58899706e-07
Iter: 1314 loss: 4.59349394e-07
Iter: 1315 loss: 4.58802305e-07
Iter: 1316 loss: 4.58729517e-07
Iter: 1317 loss: 4.58834194e-07
Iter: 1318 loss: 4.58668808e-07
Iter: 1319 loss: 4.58552677e-07
Iter: 1320 loss: 4.58373393e-07
Iter: 1321 loss: 4.58370749e-07
Iter: 1322 loss: 4.58165744e-07
Iter: 1323 loss: 4.59936359e-07
Iter: 1324 loss: 4.58169779e-07
Iter: 1325 loss: 4.58036027e-07
Iter: 1326 loss: 4.58625834e-07
Iter: 1327 loss: 4.58001693e-07
Iter: 1328 loss: 4.57887154e-07
Iter: 1329 loss: 4.57758858e-07
Iter: 1330 loss: 4.57731261e-07
Iter: 1331 loss: 4.57600464e-07
Iter: 1332 loss: 4.58643e-07
Iter: 1333 loss: 4.57603e-07
Iter: 1334 loss: 4.57433e-07
Iter: 1335 loss: 4.58619354e-07
Iter: 1336 loss: 4.57433458e-07
Iter: 1337 loss: 4.57289474e-07
Iter: 1338 loss: 4.57052522e-07
Iter: 1339 loss: 4.57054853e-07
Iter: 1340 loss: 4.56886767e-07
Iter: 1341 loss: 4.57824399e-07
Iter: 1342 loss: 4.56851495e-07
Iter: 1343 loss: 4.56706488e-07
Iter: 1344 loss: 4.56719278e-07
Iter: 1345 loss: 4.56602947e-07
Iter: 1346 loss: 4.56518677e-07
Iter: 1347 loss: 4.5646712e-07
Iter: 1348 loss: 4.56415364e-07
Iter: 1349 loss: 4.56290365e-07
Iter: 1350 loss: 4.58381237e-07
Iter: 1351 loss: 4.56285107e-07
Iter: 1352 loss: 4.56157409e-07
Iter: 1353 loss: 4.5593282e-07
Iter: 1354 loss: 4.61655759e-07
Iter: 1355 loss: 4.55931314e-07
Iter: 1356 loss: 4.55785624e-07
Iter: 1357 loss: 4.55764763e-07
Iter: 1358 loss: 4.55547593e-07
Iter: 1359 loss: 4.56091328e-07
Iter: 1360 loss: 4.55494899e-07
Iter: 1361 loss: 4.55375016e-07
Iter: 1362 loss: 4.55235124e-07
Iter: 1363 loss: 4.55234243e-07
Iter: 1364 loss: 4.55198574e-07
Iter: 1365 loss: 4.55145369e-07
Iter: 1366 loss: 4.55065958e-07
Iter: 1367 loss: 4.54925612e-07
Iter: 1368 loss: 4.57844294e-07
Iter: 1369 loss: 4.54923168e-07
Iter: 1370 loss: 4.54786459e-07
Iter: 1371 loss: 4.55602418e-07
Iter: 1372 loss: 4.54765484e-07
Iter: 1373 loss: 4.54605328e-07
Iter: 1374 loss: 4.55424e-07
Iter: 1375 loss: 4.54580913e-07
Iter: 1376 loss: 4.54476464e-07
Iter: 1377 loss: 4.54233117e-07
Iter: 1378 loss: 4.56147262e-07
Iter: 1379 loss: 4.54191252e-07
Iter: 1380 loss: 4.53888561e-07
Iter: 1381 loss: 4.56940427e-07
Iter: 1382 loss: 4.53884809e-07
Iter: 1383 loss: 4.53671078e-07
Iter: 1384 loss: 4.54035415e-07
Iter: 1385 loss: 4.53573051e-07
Iter: 1386 loss: 4.5344126e-07
Iter: 1387 loss: 4.54685846e-07
Iter: 1388 loss: 4.53433955e-07
Iter: 1389 loss: 4.53349088e-07
Iter: 1390 loss: 4.54624711e-07
Iter: 1391 loss: 4.53350196e-07
Iter: 1392 loss: 4.53256e-07
Iter: 1393 loss: 4.53066036e-07
Iter: 1394 loss: 4.5505962e-07
Iter: 1395 loss: 4.5303895e-07
Iter: 1396 loss: 4.53006209e-07
Iter: 1397 loss: 4.52961928e-07
Iter: 1398 loss: 4.52902e-07
Iter: 1399 loss: 4.52780682e-07
Iter: 1400 loss: 4.52772724e-07
Iter: 1401 loss: 4.52675181e-07
Iter: 1402 loss: 4.5301465e-07
Iter: 1403 loss: 4.52659918e-07
Iter: 1404 loss: 4.52515252e-07
Iter: 1405 loss: 4.53246457e-07
Iter: 1406 loss: 4.52513e-07
Iter: 1407 loss: 4.52399519e-07
Iter: 1408 loss: 4.52293051e-07
Iter: 1409 loss: 4.55565839e-07
Iter: 1410 loss: 4.52306438e-07
Iter: 1411 loss: 4.52253857e-07
Iter: 1412 loss: 4.52232598e-07
Iter: 1413 loss: 4.52174618e-07
Iter: 1414 loss: 4.52086e-07
Iter: 1415 loss: 4.52067411e-07
Iter: 1416 loss: 4.51946619e-07
Iter: 1417 loss: 4.51805e-07
Iter: 1418 loss: 4.51790584e-07
Iter: 1419 loss: 4.51649413e-07
Iter: 1420 loss: 4.52183826e-07
Iter: 1421 loss: 4.51594047e-07
Iter: 1422 loss: 4.51515405e-07
Iter: 1423 loss: 4.51365139e-07
Iter: 1424 loss: 4.54411918e-07
Iter: 1425 loss: 4.51368436e-07
Iter: 1426 loss: 4.51320204e-07
Iter: 1427 loss: 4.51281949e-07
Iter: 1428 loss: 4.51206688e-07
Iter: 1429 loss: 4.51430424e-07
Iter: 1430 loss: 4.51180796e-07
Iter: 1431 loss: 4.51097e-07
Iter: 1432 loss: 4.51143137e-07
Iter: 1433 loss: 4.51043405e-07
Iter: 1434 loss: 4.5092105e-07
Iter: 1435 loss: 4.50954985e-07
Iter: 1436 loss: 4.50803128e-07
Iter: 1437 loss: 4.50748701e-07
Iter: 1438 loss: 4.5073341e-07
Iter: 1439 loss: 4.5064769e-07
Iter: 1440 loss: 4.5048256e-07
Iter: 1441 loss: 4.53978942e-07
Iter: 1442 loss: 4.50495577e-07
Iter: 1443 loss: 4.50338177e-07
Iter: 1444 loss: 4.50869607e-07
Iter: 1445 loss: 4.50291424e-07
Iter: 1446 loss: 4.50277355e-07
Iter: 1447 loss: 4.50243732e-07
Iter: 1448 loss: 4.50220597e-07
Iter: 1449 loss: 4.50119956e-07
Iter: 1450 loss: 4.50519082e-07
Iter: 1451 loss: 4.50079e-07
Iter: 1452 loss: 4.49959089e-07
Iter: 1453 loss: 4.50800115e-07
Iter: 1454 loss: 4.49947635e-07
Iter: 1455 loss: 4.4987911e-07
Iter: 1456 loss: 4.49888944e-07
Iter: 1457 loss: 4.49833493e-07
Iter: 1458 loss: 4.4975107e-07
Iter: 1459 loss: 4.51665301e-07
Iter: 1460 loss: 4.49755e-07
Iter: 1461 loss: 4.49624565e-07
Iter: 1462 loss: 4.50490234e-07
Iter: 1463 loss: 4.49614191e-07
Iter: 1464 loss: 4.49533246e-07
Iter: 1465 loss: 4.4994357e-07
Iter: 1466 loss: 4.49519405e-07
Iter: 1467 loss: 4.49417286e-07
Iter: 1468 loss: 4.49337222e-07
Iter: 1469 loss: 4.49308544e-07
Iter: 1470 loss: 4.4918761e-07
Iter: 1471 loss: 4.49409413e-07
Iter: 1472 loss: 4.49128862e-07
Iter: 1473 loss: 4.49001391e-07
Iter: 1474 loss: 4.50765469e-07
Iter: 1475 loss: 4.49006052e-07
Iter: 1476 loss: 4.48942785e-07
Iter: 1477 loss: 4.48731669e-07
Iter: 1478 loss: 4.49733875e-07
Iter: 1479 loss: 4.48674371e-07
Iter: 1480 loss: 4.48499861e-07
Iter: 1481 loss: 4.49003039e-07
Iter: 1482 loss: 4.48452226e-07
Iter: 1483 loss: 4.48371424e-07
Iter: 1484 loss: 4.48331747e-07
Iter: 1485 loss: 4.48258305e-07
Iter: 1486 loss: 4.48259698e-07
Iter: 1487 loss: 4.4817196e-07
Iter: 1488 loss: 4.48080812e-07
Iter: 1489 loss: 4.47872594e-07
Iter: 1490 loss: 4.50640016e-07
Iter: 1491 loss: 4.47848151e-07
Iter: 1492 loss: 4.4767026e-07
Iter: 1493 loss: 4.47650734e-07
Iter: 1494 loss: 4.47521586e-07
Iter: 1495 loss: 4.48886965e-07
Iter: 1496 loss: 4.47500724e-07
Iter: 1497 loss: 4.47366745e-07
Iter: 1498 loss: 4.47162137e-07
Iter: 1499 loss: 4.471637e-07
Iter: 1500 loss: 4.47069056e-07
Iter: 1501 loss: 4.47040861e-07
Iter: 1502 loss: 4.46983393e-07
Iter: 1503 loss: 4.46989105e-07
Iter: 1504 loss: 4.46935815e-07
Iter: 1505 loss: 4.46880847e-07
Iter: 1506 loss: 4.46906597e-07
Iter: 1507 loss: 4.46831365e-07
Iter: 1508 loss: 4.46701222e-07
Iter: 1509 loss: 4.46755109e-07
Iter: 1510 loss: 4.46618571e-07
Iter: 1511 loss: 4.46525434e-07
Iter: 1512 loss: 4.46336372e-07
Iter: 1513 loss: 4.49520684e-07
Iter: 1514 loss: 4.46342682e-07
Iter: 1515 loss: 4.46208162e-07
Iter: 1516 loss: 4.47894536e-07
Iter: 1517 loss: 4.46198555e-07
Iter: 1518 loss: 4.4608e-07
Iter: 1519 loss: 4.47313e-07
Iter: 1520 loss: 4.46087569e-07
Iter: 1521 loss: 4.46008244e-07
Iter: 1522 loss: 4.45862071e-07
Iter: 1523 loss: 4.45851754e-07
Iter: 1524 loss: 4.45699527e-07
Iter: 1525 loss: 4.46101808e-07
Iter: 1526 loss: 4.45648652e-07
Iter: 1527 loss: 4.45564126e-07
Iter: 1528 loss: 4.4712209e-07
Iter: 1529 loss: 4.45567252e-07
Iter: 1530 loss: 4.45418e-07
Iter: 1531 loss: 4.45255466e-07
Iter: 1532 loss: 4.45230484e-07
Iter: 1533 loss: 4.45139e-07
Iter: 1534 loss: 4.45134276e-07
Iter: 1535 loss: 4.4506794e-07
Iter: 1536 loss: 4.45099033e-07
Iter: 1537 loss: 4.45011437e-07
Iter: 1538 loss: 4.4492225e-07
Iter: 1539 loss: 4.44837497e-07
Iter: 1540 loss: 4.4480737e-07
Iter: 1541 loss: 4.44760019e-07
Iter: 1542 loss: 4.44729807e-07
Iter: 1543 loss: 4.44672082e-07
Iter: 1544 loss: 4.44589233e-07
Iter: 1545 loss: 4.46962503e-07
Iter: 1546 loss: 4.44594491e-07
Iter: 1547 loss: 4.44446471e-07
Iter: 1548 loss: 4.44312377e-07
Iter: 1549 loss: 4.44295324e-07
Iter: 1550 loss: 4.44226629e-07
Iter: 1551 loss: 4.4421185e-07
Iter: 1552 loss: 4.44095377e-07
Iter: 1553 loss: 4.43893725e-07
Iter: 1554 loss: 4.48269816e-07
Iter: 1555 loss: 4.43883209e-07
Iter: 1556 loss: 4.43719443e-07
Iter: 1557 loss: 4.44310103e-07
Iter: 1558 loss: 4.43648503e-07
Iter: 1559 loss: 4.43499175e-07
Iter: 1560 loss: 4.4335502e-07
Iter: 1561 loss: 4.43313411e-07
Iter: 1562 loss: 4.43166613e-07
Iter: 1563 loss: 4.43108206e-07
Iter: 1564 loss: 4.43058127e-07
Iter: 1565 loss: 4.43078619e-07
Iter: 1566 loss: 4.43005092e-07
Iter: 1567 loss: 4.42899506e-07
Iter: 1568 loss: 4.43329384e-07
Iter: 1569 loss: 4.42877649e-07
Iter: 1570 loss: 4.42808698e-07
Iter: 1571 loss: 4.42728322e-07
Iter: 1572 loss: 4.42716328e-07
Iter: 1573 loss: 4.42635752e-07
Iter: 1574 loss: 4.43673628e-07
Iter: 1575 loss: 4.42643369e-07
Iter: 1576 loss: 4.42571206e-07
Iter: 1577 loss: 4.42602698e-07
Iter: 1578 loss: 4.42531473e-07
Iter: 1579 loss: 4.42429865e-07
Iter: 1580 loss: 4.42231169e-07
Iter: 1581 loss: 4.42231851e-07
Iter: 1582 loss: 4.42053874e-07
Iter: 1583 loss: 4.42674434e-07
Iter: 1584 loss: 4.42015363e-07
Iter: 1585 loss: 4.41814336e-07
Iter: 1586 loss: 4.43692898e-07
Iter: 1587 loss: 4.41818713e-07
Iter: 1588 loss: 4.41589862e-07
Iter: 1589 loss: 4.41369366e-07
Iter: 1590 loss: 4.41336539e-07
Iter: 1591 loss: 4.4116274e-07
Iter: 1592 loss: 4.41019154e-07
Iter: 1593 loss: 4.40944632e-07
Iter: 1594 loss: 4.40814034e-07
Iter: 1595 loss: 4.40792405e-07
Iter: 1596 loss: 4.40645607e-07
Iter: 1597 loss: 4.41171835e-07
Iter: 1598 loss: 4.40614116e-07
Iter: 1599 loss: 4.40499662e-07
Iter: 1600 loss: 4.40398338e-07
Iter: 1601 loss: 4.4036517e-07
Iter: 1602 loss: 4.40229599e-07
Iter: 1603 loss: 4.40221072e-07
Iter: 1604 loss: 4.4017213e-07
Iter: 1605 loss: 4.40070579e-07
Iter: 1606 loss: 4.41965312e-07
Iter: 1607 loss: 4.40073222e-07
Iter: 1608 loss: 4.39929551e-07
Iter: 1609 loss: 4.40887703e-07
Iter: 1610 loss: 4.39925287e-07
Iter: 1611 loss: 4.39766154e-07
Iter: 1612 loss: 4.40104316e-07
Iter: 1613 loss: 4.39715308e-07
Iter: 1614 loss: 4.39642349e-07
Iter: 1615 loss: 4.39512604e-07
Iter: 1616 loss: 4.42641806e-07
Iter: 1617 loss: 4.3950098e-07
Iter: 1618 loss: 4.39320701e-07
Iter: 1619 loss: 4.39992249e-07
Iter: 1620 loss: 4.39277358e-07
Iter: 1621 loss: 4.39159521e-07
Iter: 1622 loss: 4.39146675e-07
Iter: 1623 loss: 4.39091821e-07
Iter: 1624 loss: 4.38961763e-07
Iter: 1625 loss: 4.41163166e-07
Iter: 1626 loss: 4.38945847e-07
Iter: 1627 loss: 4.38774236e-07
Iter: 1628 loss: 4.39132748e-07
Iter: 1629 loss: 4.38717677e-07
Iter: 1630 loss: 4.38683116e-07
Iter: 1631 loss: 4.38642303e-07
Iter: 1632 loss: 4.38568208e-07
Iter: 1633 loss: 4.38396285e-07
Iter: 1634 loss: 4.38956135e-07
Iter: 1635 loss: 4.38323639e-07
Iter: 1636 loss: 4.38315681e-07
Iter: 1637 loss: 4.38211089e-07
Iter: 1638 loss: 4.38135316e-07
Iter: 1639 loss: 4.38055679e-07
Iter: 1640 loss: 4.38009323e-07
Iter: 1641 loss: 4.37880203e-07
Iter: 1642 loss: 4.37651693e-07
Iter: 1643 loss: 4.37642598e-07
Iter: 1644 loss: 4.37886143e-07
Iter: 1645 loss: 4.37553894e-07
Iter: 1646 loss: 4.37477809e-07
Iter: 1647 loss: 4.37436427e-07
Iter: 1648 loss: 4.37417242e-07
Iter: 1649 loss: 4.37309211e-07
Iter: 1650 loss: 4.37091e-07
Iter: 1651 loss: 4.4183804e-07
Iter: 1652 loss: 4.37095053e-07
Iter: 1653 loss: 4.3698239e-07
Iter: 1654 loss: 4.36992764e-07
Iter: 1655 loss: 4.36863388e-07
Iter: 1656 loss: 4.37043099e-07
Iter: 1657 loss: 4.36801969e-07
Iter: 1658 loss: 4.3668058e-07
Iter: 1659 loss: 4.36731455e-07
Iter: 1660 loss: 4.36595968e-07
Iter: 1661 loss: 4.36487568e-07
Iter: 1662 loss: 4.36850257e-07
Iter: 1663 loss: 4.36463495e-07
Iter: 1664 loss: 4.36335057e-07
Iter: 1665 loss: 4.36747598e-07
Iter: 1666 loss: 4.36278356e-07
Iter: 1667 loss: 4.36147729e-07
Iter: 1668 loss: 4.36103278e-07
Iter: 1669 loss: 4.36027534e-07
Iter: 1670 loss: 4.35949516e-07
Iter: 1671 loss: 4.35953382e-07
Iter: 1672 loss: 4.35862376e-07
Iter: 1673 loss: 4.35631677e-07
Iter: 1674 loss: 4.36436352e-07
Iter: 1675 loss: 4.35517109e-07
Iter: 1676 loss: 4.35411948e-07
Iter: 1677 loss: 4.35386937e-07
Iter: 1678 loss: 4.35298034e-07
Iter: 1679 loss: 4.36296659e-07
Iter: 1680 loss: 4.35288797e-07
Iter: 1681 loss: 4.35218453e-07
Iter: 1682 loss: 4.35089134e-07
Iter: 1683 loss: 4.3727519e-07
Iter: 1684 loss: 4.35076572e-07
Iter: 1685 loss: 4.34972492e-07
Iter: 1686 loss: 4.35282402e-07
Iter: 1687 loss: 4.34908685e-07
Iter: 1688 loss: 4.34811341e-07
Iter: 1689 loss: 4.34818674e-07
Iter: 1690 loss: 4.34759556e-07
Iter: 1691 loss: 4.34697654e-07
Iter: 1692 loss: 4.34670255e-07
Iter: 1693 loss: 4.34615458e-07
Iter: 1694 loss: 4.34462038e-07
Iter: 1695 loss: 4.37608207e-07
Iter: 1696 loss: 4.34463686e-07
Iter: 1697 loss: 4.34366285e-07
Iter: 1698 loss: 4.34342496e-07
Iter: 1699 loss: 4.34261466e-07
Iter: 1700 loss: 4.34203031e-07
Iter: 1701 loss: 4.34178332e-07
Iter: 1702 loss: 4.34058563e-07
Iter: 1703 loss: 4.3456788e-07
Iter: 1704 loss: 4.34054897e-07
Iter: 1705 loss: 4.33913954e-07
Iter: 1706 loss: 4.33838977e-07
Iter: 1707 loss: 4.33779519e-07
Iter: 1708 loss: 4.33632408e-07
Iter: 1709 loss: 4.34251746e-07
Iter: 1710 loss: 4.33594039e-07
Iter: 1711 loss: 4.33529635e-07
Iter: 1712 loss: 4.33519943e-07
Iter: 1713 loss: 4.33434479e-07
Iter: 1714 loss: 4.33361322e-07
Iter: 1715 loss: 4.33332275e-07
Iter: 1716 loss: 4.33284839e-07
Iter: 1717 loss: 4.33203297e-07
Iter: 1718 loss: 4.33204463e-07
Iter: 1719 loss: 4.33142873e-07
Iter: 1720 loss: 4.33126047e-07
Iter: 1721 loss: 4.33075854e-07
Iter: 1722 loss: 4.33051724e-07
Iter: 1723 loss: 4.33028191e-07
Iter: 1724 loss: 4.32972115e-07
Iter: 1725 loss: 4.32874e-07
Iter: 1726 loss: 4.32886736e-07
Iter: 1727 loss: 4.32850555e-07
Iter: 1728 loss: 4.32822446e-07
Iter: 1729 loss: 4.32784731e-07
Iter: 1730 loss: 4.32736442e-07
Iter: 1731 loss: 4.32721663e-07
Iter: 1732 loss: 4.32623153e-07
Iter: 1733 loss: 4.32887106e-07
Iter: 1734 loss: 4.32589786e-07
Iter: 1735 loss: 4.3251e-07
Iter: 1736 loss: 4.32821935e-07
Iter: 1737 loss: 4.32482068e-07
Iter: 1738 loss: 4.3242153e-07
Iter: 1739 loss: 4.32421643e-07
Iter: 1740 loss: 4.3237452e-07
Iter: 1741 loss: 4.32277375e-07
Iter: 1742 loss: 4.32308866e-07
Iter: 1743 loss: 4.32228745e-07
Iter: 1744 loss: 4.32090928e-07
Iter: 1745 loss: 4.32536751e-07
Iter: 1746 loss: 4.32065349e-07
Iter: 1747 loss: 4.3198088e-07
Iter: 1748 loss: 4.31959762e-07
Iter: 1749 loss: 4.31913918e-07
Iter: 1750 loss: 4.3183087e-07
Iter: 1751 loss: 4.33062752e-07
Iter: 1752 loss: 4.31843262e-07
Iter: 1753 loss: 4.31752937e-07
Iter: 1754 loss: 4.32130946e-07
Iter: 1755 loss: 4.31745548e-07
Iter: 1756 loss: 4.31701835e-07
Iter: 1757 loss: 4.31585534e-07
Iter: 1758 loss: 4.32478544e-07
Iter: 1759 loss: 4.31558135e-07
Iter: 1760 loss: 4.3151536e-07
Iter: 1761 loss: 4.31506322e-07
Iter: 1762 loss: 4.31430095e-07
Iter: 1763 loss: 4.31523915e-07
Iter: 1764 loss: 4.31402185e-07
Iter: 1765 loss: 4.31319592e-07
Iter: 1766 loss: 4.31307029e-07
Iter: 1767 loss: 4.31263516e-07
Iter: 1768 loss: 4.31156195e-07
Iter: 1769 loss: 4.31601791e-07
Iter: 1770 loss: 4.31133429e-07
Iter: 1771 loss: 4.31066184e-07
Iter: 1772 loss: 4.31467527e-07
Iter: 1773 loss: 4.31065246e-07
Iter: 1774 loss: 4.30991378e-07
Iter: 1775 loss: 4.30963638e-07
Iter: 1776 loss: 4.30936211e-07
Iter: 1777 loss: 4.30859558e-07
Iter: 1778 loss: 4.31396188e-07
Iter: 1779 loss: 4.30853333e-07
Iter: 1780 loss: 4.30790806e-07
Iter: 1781 loss: 4.30699572e-07
Iter: 1782 loss: 4.30716455e-07
Iter: 1783 loss: 4.30568e-07
Iter: 1784 loss: 4.30993509e-07
Iter: 1785 loss: 4.30555758e-07
Iter: 1786 loss: 4.30542258e-07
Iter: 1787 loss: 4.30490957e-07
Iter: 1788 loss: 4.30472056e-07
Iter: 1789 loss: 4.30371074e-07
Iter: 1790 loss: 4.307106e-07
Iter: 1791 loss: 4.30329067e-07
Iter: 1792 loss: 4.30306955e-07
Iter: 1793 loss: 4.30271484e-07
Iter: 1794 loss: 4.30210378e-07
Iter: 1795 loss: 4.3036016e-07
Iter: 1796 loss: 4.30167319e-07
Iter: 1797 loss: 4.30109623e-07
Iter: 1798 loss: 4.30132388e-07
Iter: 1799 loss: 4.30083389e-07
Iter: 1800 loss: 4.30000426e-07
Iter: 1801 loss: 4.30351491e-07
Iter: 1802 loss: 4.29975699e-07
Iter: 1803 loss: 4.29900751e-07
Iter: 1804 loss: 4.30183263e-07
Iter: 1805 loss: 4.29900325e-07
Iter: 1806 loss: 4.29830152e-07
Iter: 1807 loss: 4.29716579e-07
Iter: 1808 loss: 4.29711292e-07
Iter: 1809 loss: 4.29579472e-07
Iter: 1810 loss: 4.30737686e-07
Iter: 1811 loss: 4.29572026e-07
Iter: 1812 loss: 4.29475108e-07
Iter: 1813 loss: 4.29523823e-07
Iter: 1814 loss: 4.29422641e-07
Iter: 1815 loss: 4.29320664e-07
Iter: 1816 loss: 4.2927303e-07
Iter: 1817 loss: 4.29231164e-07
Iter: 1818 loss: 4.29278458e-07
Iter: 1819 loss: 4.29184411e-07
Iter: 1820 loss: 4.29136179e-07
Iter: 1821 loss: 4.29059e-07
Iter: 1822 loss: 4.29788315e-07
Iter: 1823 loss: 4.29036561e-07
Iter: 1824 loss: 4.28919492e-07
Iter: 1825 loss: 4.29473147e-07
Iter: 1826 loss: 4.28898517e-07
Iter: 1827 loss: 4.28812314e-07
Iter: 1828 loss: 4.3015973e-07
Iter: 1829 loss: 4.28802622e-07
Iter: 1830 loss: 4.28755584e-07
Iter: 1831 loss: 4.28607393e-07
Iter: 1832 loss: 4.30832813e-07
Iter: 1833 loss: 4.28601425e-07
Iter: 1834 loss: 4.28456843e-07
Iter: 1835 loss: 4.30689312e-07
Iter: 1836 loss: 4.28453632e-07
Iter: 1837 loss: 4.28369503e-07
Iter: 1838 loss: 4.28586418e-07
Iter: 1839 loss: 4.28358788e-07
Iter: 1840 loss: 4.28291116e-07
Iter: 1841 loss: 4.28358589e-07
Iter: 1842 loss: 4.28282135e-07
Iter: 1843 loss: 4.2818408e-07
Iter: 1844 loss: 4.28292424e-07
Iter: 1845 loss: 4.28148752e-07
Iter: 1846 loss: 4.28086111e-07
Iter: 1847 loss: 4.28319538e-07
Iter: 1848 loss: 4.28068518e-07
Iter: 1849 loss: 4.27989619e-07
Iter: 1850 loss: 4.27834436e-07
Iter: 1851 loss: 4.3064091e-07
Iter: 1852 loss: 4.27839666e-07
Iter: 1853 loss: 4.2780519e-07
Iter: 1854 loss: 4.27756106e-07
Iter: 1855 loss: 4.27679083e-07
Iter: 1856 loss: 4.27618232e-07
Iter: 1857 loss: 4.27586116e-07
Iter: 1858 loss: 4.27452e-07
Iter: 1859 loss: 4.27205237e-07
Iter: 1860 loss: 4.27206089e-07
Iter: 1861 loss: 4.27393388e-07
Iter: 1862 loss: 4.27123837e-07
Iter: 1863 loss: 4.27055198e-07
Iter: 1864 loss: 4.26943927e-07
Iter: 1865 loss: 4.29383647e-07
Iter: 1866 loss: 4.26942648e-07
Iter: 1867 loss: 4.26808811e-07
Iter: 1868 loss: 4.28164981e-07
Iter: 1869 loss: 4.26803581e-07
Iter: 1870 loss: 4.26672329e-07
Iter: 1871 loss: 4.27319065e-07
Iter: 1872 loss: 4.26652889e-07
Iter: 1873 loss: 4.2656e-07
Iter: 1874 loss: 4.26730594e-07
Iter: 1875 loss: 4.26516976e-07
Iter: 1876 loss: 4.26410793e-07
Iter: 1877 loss: 4.26511235e-07
Iter: 1878 loss: 4.26355797e-07
Iter: 1879 loss: 4.26193651e-07
Iter: 1880 loss: 4.2604205e-07
Iter: 1881 loss: 4.26004846e-07
Iter: 1882 loss: 4.25764227e-07
Iter: 1883 loss: 4.26400106e-07
Iter: 1884 loss: 4.25676603e-07
Iter: 1885 loss: 4.25495699e-07
Iter: 1886 loss: 4.26010615e-07
Iter: 1887 loss: 4.25407478e-07
Iter: 1888 loss: 4.25322355e-07
Iter: 1889 loss: 4.25296605e-07
Iter: 1890 loss: 4.25249084e-07
Iter: 1891 loss: 4.25098165e-07
Iter: 1892 loss: 4.26116287e-07
Iter: 1893 loss: 4.25069175e-07
Iter: 1894 loss: 4.24891198e-07
Iter: 1895 loss: 4.2560572e-07
Iter: 1896 loss: 4.24834809e-07
Iter: 1897 loss: 4.24632105e-07
Iter: 1898 loss: 4.2650862e-07
Iter: 1899 loss: 4.24620907e-07
Iter: 1900 loss: 4.24524728e-07
Iter: 1901 loss: 4.24409336e-07
Iter: 1902 loss: 4.24372985e-07
Iter: 1903 loss: 4.24208537e-07
Iter: 1904 loss: 4.25936264e-07
Iter: 1905 loss: 4.24191626e-07
Iter: 1906 loss: 4.24111761e-07
Iter: 1907 loss: 4.24372246e-07
Iter: 1908 loss: 4.24070834e-07
Iter: 1909 loss: 4.23968913e-07
Iter: 1910 loss: 4.24282717e-07
Iter: 1911 loss: 4.23965588e-07
Iter: 1912 loss: 4.23888224e-07
Iter: 1913 loss: 4.23867192e-07
Iter: 1914 loss: 4.23815749e-07
Iter: 1915 loss: 4.2369436e-07
Iter: 1916 loss: 4.23850679e-07
Iter: 1917 loss: 4.23642689e-07
Iter: 1918 loss: 4.23505981e-07
Iter: 1919 loss: 4.23432823e-07
Iter: 1920 loss: 4.23393743e-07
Iter: 1921 loss: 4.2319715e-07
Iter: 1922 loss: 4.23209372e-07
Iter: 1923 loss: 4.22988535e-07
Iter: 1924 loss: 4.23028382e-07
Iter: 1925 loss: 4.22867e-07
Iter: 1926 loss: 4.22756131e-07
Iter: 1927 loss: 4.22643893e-07
Iter: 1928 loss: 4.22632127e-07
Iter: 1929 loss: 4.2256093e-07
Iter: 1930 loss: 4.2251736e-07
Iter: 1931 loss: 4.22430304e-07
Iter: 1932 loss: 4.22411233e-07
Iter: 1933 loss: 4.22380907e-07
Iter: 1934 loss: 4.2230846e-07
Iter: 1935 loss: 4.22815958e-07
Iter: 1936 loss: 4.22303856e-07
Iter: 1937 loss: 4.22232574e-07
Iter: 1938 loss: 4.22138754e-07
Iter: 1939 loss: 4.22128323e-07
Iter: 1940 loss: 4.21993263e-07
Iter: 1941 loss: 4.23245268e-07
Iter: 1942 loss: 4.22005144e-07
Iter: 1943 loss: 4.21923232e-07
Iter: 1944 loss: 4.21801872e-07
Iter: 1945 loss: 4.24512166e-07
Iter: 1946 loss: 4.21789224e-07
Iter: 1947 loss: 4.2164956e-07
Iter: 1948 loss: 4.22309e-07
Iter: 1949 loss: 4.21601783e-07
Iter: 1950 loss: 4.21521747e-07
Iter: 1951 loss: 4.21782659e-07
Iter: 1952 loss: 4.21484572e-07
Iter: 1953 loss: 4.21362984e-07
Iter: 1954 loss: 4.21462943e-07
Iter: 1955 loss: 4.21299518e-07
Iter: 1956 loss: 4.21206607e-07
Iter: 1957 loss: 4.21212889e-07
Iter: 1958 loss: 4.21151668e-07
Iter: 1959 loss: 4.21013681e-07
Iter: 1960 loss: 4.21843481e-07
Iter: 1961 loss: 4.20989096e-07
Iter: 1962 loss: 4.20857731e-07
Iter: 1963 loss: 4.20838546e-07
Iter: 1964 loss: 4.20709114e-07
Iter: 1965 loss: 4.20860317e-07
Iter: 1966 loss: 4.2065119e-07
Iter: 1967 loss: 4.20515e-07
Iter: 1968 loss: 4.2060185e-07
Iter: 1969 loss: 4.20436066e-07
Iter: 1970 loss: 4.20269885e-07
Iter: 1971 loss: 4.21677214e-07
Iter: 1972 loss: 4.20273977e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4
+ date
Mon Oct 26 11:17:10 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440719268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54407fbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54407fbea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54407fb400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54406cb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54406cb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440657e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440671d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440600510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54406008c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440600a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544058d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544058d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54405467b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440522400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54404fec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54404ef620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54404efd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54404b48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54404b4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440472488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54404721e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54403c66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544040e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544040e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544040e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544037c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544031a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544031ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440326510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440326840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54402a2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54402a1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544024fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5440264a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f544021ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.19355217e-06
Iter: 2 loss: 4.38326833e-06
Iter: 3 loss: 4.37343715e-06
Iter: 4 loss: 3.98788097e-06
Iter: 5 loss: 3.92719721e-06
Iter: 6 loss: 3.66037966e-06
Iter: 7 loss: 3.43112674e-06
Iter: 8 loss: 4.77048434e-06
Iter: 9 loss: 3.40112319e-06
Iter: 10 loss: 3.15096304e-06
Iter: 11 loss: 3.86886404e-06
Iter: 12 loss: 3.07254732e-06
Iter: 13 loss: 2.99222665e-06
Iter: 14 loss: 2.85777378e-06
Iter: 15 loss: 2.85737678e-06
Iter: 16 loss: 2.81081316e-06
Iter: 17 loss: 2.77082086e-06
Iter: 18 loss: 2.70581586e-06
Iter: 19 loss: 2.63321135e-06
Iter: 20 loss: 2.62315689e-06
Iter: 21 loss: 2.53429698e-06
Iter: 22 loss: 2.57625925e-06
Iter: 23 loss: 2.47431331e-06
Iter: 24 loss: 2.34328627e-06
Iter: 25 loss: 3.82048711e-06
Iter: 26 loss: 2.34093613e-06
Iter: 27 loss: 2.29220677e-06
Iter: 28 loss: 2.25524764e-06
Iter: 29 loss: 2.23945563e-06
Iter: 30 loss: 2.17586762e-06
Iter: 31 loss: 2.23813458e-06
Iter: 32 loss: 2.1398746e-06
Iter: 33 loss: 2.07596e-06
Iter: 34 loss: 2.49760842e-06
Iter: 35 loss: 2.06936102e-06
Iter: 36 loss: 2.0221164e-06
Iter: 37 loss: 1.96846e-06
Iter: 38 loss: 1.96164456e-06
Iter: 39 loss: 1.95840221e-06
Iter: 40 loss: 1.92842367e-06
Iter: 41 loss: 1.89747743e-06
Iter: 42 loss: 1.94045606e-06
Iter: 43 loss: 1.88213016e-06
Iter: 44 loss: 1.85199292e-06
Iter: 45 loss: 1.79138715e-06
Iter: 46 loss: 2.93335597e-06
Iter: 47 loss: 1.79060885e-06
Iter: 48 loss: 1.83044642e-06
Iter: 49 loss: 1.77280754e-06
Iter: 50 loss: 1.75916307e-06
Iter: 51 loss: 1.71730812e-06
Iter: 52 loss: 1.81248788e-06
Iter: 53 loss: 1.69249245e-06
Iter: 54 loss: 1.62056085e-06
Iter: 55 loss: 1.88093202e-06
Iter: 56 loss: 1.60249817e-06
Iter: 57 loss: 1.60297543e-06
Iter: 58 loss: 1.57724833e-06
Iter: 59 loss: 1.55891462e-06
Iter: 60 loss: 1.50685401e-06
Iter: 61 loss: 1.7528962e-06
Iter: 62 loss: 1.48846414e-06
Iter: 63 loss: 1.45126103e-06
Iter: 64 loss: 1.44973205e-06
Iter: 65 loss: 1.42296494e-06
Iter: 66 loss: 1.68734641e-06
Iter: 67 loss: 1.42203339e-06
Iter: 68 loss: 1.4109271e-06
Iter: 69 loss: 1.38503742e-06
Iter: 70 loss: 1.69911277e-06
Iter: 71 loss: 1.38293478e-06
Iter: 72 loss: 1.35916287e-06
Iter: 73 loss: 1.4622974e-06
Iter: 74 loss: 1.35430389e-06
Iter: 75 loss: 1.33058904e-06
Iter: 76 loss: 1.48463948e-06
Iter: 77 loss: 1.32800972e-06
Iter: 78 loss: 1.29597481e-06
Iter: 79 loss: 1.31432944e-06
Iter: 80 loss: 1.2750827e-06
Iter: 81 loss: 1.25004942e-06
Iter: 82 loss: 1.30049807e-06
Iter: 83 loss: 1.23991015e-06
Iter: 84 loss: 1.22159577e-06
Iter: 85 loss: 1.39650706e-06
Iter: 86 loss: 1.22090273e-06
Iter: 87 loss: 1.20043705e-06
Iter: 88 loss: 1.20825405e-06
Iter: 89 loss: 1.1861714e-06
Iter: 90 loss: 1.17538139e-06
Iter: 91 loss: 1.18373532e-06
Iter: 92 loss: 1.16882188e-06
Iter: 93 loss: 1.15910757e-06
Iter: 94 loss: 1.30854596e-06
Iter: 95 loss: 1.15911075e-06
Iter: 96 loss: 1.14897057e-06
Iter: 97 loss: 1.15009937e-06
Iter: 98 loss: 1.14123293e-06
Iter: 99 loss: 1.13254418e-06
Iter: 100 loss: 1.11801387e-06
Iter: 101 loss: 1.1180141e-06
Iter: 102 loss: 1.09287225e-06
Iter: 103 loss: 1.28974398e-06
Iter: 104 loss: 1.09107043e-06
Iter: 105 loss: 1.07811775e-06
Iter: 106 loss: 1.0655076e-06
Iter: 107 loss: 1.06272603e-06
Iter: 108 loss: 1.04659784e-06
Iter: 109 loss: 1.05205891e-06
Iter: 110 loss: 1.03522132e-06
Iter: 111 loss: 1.0272089e-06
Iter: 112 loss: 1.02609386e-06
Iter: 113 loss: 1.01884734e-06
Iter: 114 loss: 1.08403583e-06
Iter: 115 loss: 1.01851288e-06
Iter: 116 loss: 1.01391561e-06
Iter: 117 loss: 1.00405509e-06
Iter: 118 loss: 1.16022943e-06
Iter: 119 loss: 1.00373029e-06
Iter: 120 loss: 1.00083139e-06
Iter: 121 loss: 9.99369604e-07
Iter: 122 loss: 9.94246193e-07
Iter: 123 loss: 9.80820346e-07
Iter: 124 loss: 1.0823652e-06
Iter: 125 loss: 9.78162348e-07
Iter: 126 loss: 9.62702757e-07
Iter: 127 loss: 1.02960325e-06
Iter: 128 loss: 9.59527824e-07
Iter: 129 loss: 9.59191084e-07
Iter: 130 loss: 9.54899861e-07
Iter: 131 loss: 9.51621814e-07
Iter: 132 loss: 9.42520842e-07
Iter: 133 loss: 9.94121706e-07
Iter: 134 loss: 9.39896e-07
Iter: 135 loss: 9.30614419e-07
Iter: 136 loss: 1.06934715e-06
Iter: 137 loss: 9.30612487e-07
Iter: 138 loss: 9.25450252e-07
Iter: 139 loss: 9.94985385e-07
Iter: 140 loss: 9.25453833e-07
Iter: 141 loss: 9.22482911e-07
Iter: 142 loss: 9.13694635e-07
Iter: 143 loss: 9.44384567e-07
Iter: 144 loss: 9.09726509e-07
Iter: 145 loss: 8.94953814e-07
Iter: 146 loss: 9.61771e-07
Iter: 147 loss: 8.92150695e-07
Iter: 148 loss: 8.82054508e-07
Iter: 149 loss: 9.23719483e-07
Iter: 150 loss: 8.79851541e-07
Iter: 151 loss: 8.71137331e-07
Iter: 152 loss: 8.71107488e-07
Iter: 153 loss: 8.68642474e-07
Iter: 154 loss: 8.64562764e-07
Iter: 155 loss: 8.64543381e-07
Iter: 156 loss: 8.613315e-07
Iter: 157 loss: 8.61260673e-07
Iter: 158 loss: 8.5782608e-07
Iter: 159 loss: 8.50257038e-07
Iter: 160 loss: 9.62015406e-07
Iter: 161 loss: 8.49922912e-07
Iter: 162 loss: 8.44596968e-07
Iter: 163 loss: 8.67149538e-07
Iter: 164 loss: 8.43437704e-07
Iter: 165 loss: 8.36773495e-07
Iter: 166 loss: 8.75458795e-07
Iter: 167 loss: 8.3583393e-07
Iter: 168 loss: 8.30114288e-07
Iter: 169 loss: 8.19968193e-07
Iter: 170 loss: 8.19973138e-07
Iter: 171 loss: 8.17875e-07
Iter: 172 loss: 8.16241766e-07
Iter: 173 loss: 8.12634198e-07
Iter: 174 loss: 8.10468634e-07
Iter: 175 loss: 8.08960522e-07
Iter: 176 loss: 8.05232105e-07
Iter: 177 loss: 8.09499056e-07
Iter: 178 loss: 8.03199441e-07
Iter: 179 loss: 7.99872055e-07
Iter: 180 loss: 8.07188428e-07
Iter: 181 loss: 7.98585688e-07
Iter: 182 loss: 7.94237167e-07
Iter: 183 loss: 8.064452e-07
Iter: 184 loss: 7.92801757e-07
Iter: 185 loss: 7.87641284e-07
Iter: 186 loss: 8.34539833e-07
Iter: 187 loss: 7.87390832e-07
Iter: 188 loss: 7.84941221e-07
Iter: 189 loss: 7.78226422e-07
Iter: 190 loss: 8.17696e-07
Iter: 191 loss: 7.7635e-07
Iter: 192 loss: 7.72915769e-07
Iter: 193 loss: 7.70985594e-07
Iter: 194 loss: 7.67537074e-07
Iter: 195 loss: 7.62885406e-07
Iter: 196 loss: 7.62668776e-07
Iter: 197 loss: 7.58949113e-07
Iter: 198 loss: 7.67774168e-07
Iter: 199 loss: 7.57586349e-07
Iter: 200 loss: 7.5648336e-07
Iter: 201 loss: 7.55624569e-07
Iter: 202 loss: 7.54665962e-07
Iter: 203 loss: 7.52322933e-07
Iter: 204 loss: 7.7654056e-07
Iter: 205 loss: 7.52065603e-07
Iter: 206 loss: 7.49727747e-07
Iter: 207 loss: 7.80485152e-07
Iter: 208 loss: 7.49725245e-07
Iter: 209 loss: 7.47087938e-07
Iter: 210 loss: 7.43732812e-07
Iter: 211 loss: 7.43470878e-07
Iter: 212 loss: 7.40061864e-07
Iter: 213 loss: 7.33070749e-07
Iter: 214 loss: 8.56085194e-07
Iter: 215 loss: 7.32896865e-07
Iter: 216 loss: 7.24339316e-07
Iter: 217 loss: 8.17386876e-07
Iter: 218 loss: 7.24162248e-07
Iter: 219 loss: 7.22650384e-07
Iter: 220 loss: 7.21861397e-07
Iter: 221 loss: 7.19944e-07
Iter: 222 loss: 7.18114279e-07
Iter: 223 loss: 7.17669309e-07
Iter: 224 loss: 7.1485772e-07
Iter: 225 loss: 7.1862064e-07
Iter: 226 loss: 7.13476823e-07
Iter: 227 loss: 7.12292888e-07
Iter: 228 loss: 7.11952282e-07
Iter: 229 loss: 7.10854692e-07
Iter: 230 loss: 7.08329139e-07
Iter: 231 loss: 7.40783662e-07
Iter: 232 loss: 7.08114499e-07
Iter: 233 loss: 7.04931836e-07
Iter: 234 loss: 7.13036684e-07
Iter: 235 loss: 7.03816852e-07
Iter: 236 loss: 7.02906391e-07
Iter: 237 loss: 7.02315617e-07
Iter: 238 loss: 7.01306476e-07
Iter: 239 loss: 6.97992505e-07
Iter: 240 loss: 6.98154849e-07
Iter: 241 loss: 6.94570417e-07
Iter: 242 loss: 6.9767475e-07
Iter: 243 loss: 6.9254304e-07
Iter: 244 loss: 6.90977799e-07
Iter: 245 loss: 6.89292108e-07
Iter: 246 loss: 6.8904717e-07
Iter: 247 loss: 6.86869953e-07
Iter: 248 loss: 6.82894779e-07
Iter: 249 loss: 7.76651405e-07
Iter: 250 loss: 6.82905807e-07
Iter: 251 loss: 6.78246465e-07
Iter: 252 loss: 7.20124945e-07
Iter: 253 loss: 6.78034667e-07
Iter: 254 loss: 6.76235857e-07
Iter: 255 loss: 6.75832041e-07
Iter: 256 loss: 6.74369289e-07
Iter: 257 loss: 6.71487271e-07
Iter: 258 loss: 7.28705345e-07
Iter: 259 loss: 6.71450152e-07
Iter: 260 loss: 6.70080567e-07
Iter: 261 loss: 6.70085797e-07
Iter: 262 loss: 6.68676421e-07
Iter: 263 loss: 6.69630595e-07
Iter: 264 loss: 6.67791824e-07
Iter: 265 loss: 6.66193614e-07
Iter: 266 loss: 6.66279163e-07
Iter: 267 loss: 6.64933509e-07
Iter: 268 loss: 6.63412834e-07
Iter: 269 loss: 6.70260647e-07
Iter: 270 loss: 6.63108381e-07
Iter: 271 loss: 6.61315312e-07
Iter: 272 loss: 6.70066129e-07
Iter: 273 loss: 6.61007334e-07
Iter: 274 loss: 6.59114335e-07
Iter: 275 loss: 6.5427912e-07
Iter: 276 loss: 6.95803351e-07
Iter: 277 loss: 6.53464895e-07
Iter: 278 loss: 6.55105737e-07
Iter: 279 loss: 6.5184e-07
Iter: 280 loss: 6.5045208e-07
Iter: 281 loss: 6.47724164e-07
Iter: 282 loss: 7.01497072e-07
Iter: 283 loss: 6.477037e-07
Iter: 284 loss: 6.44930196e-07
Iter: 285 loss: 6.52163351e-07
Iter: 286 loss: 6.43998078e-07
Iter: 287 loss: 6.42675616e-07
Iter: 288 loss: 6.48364e-07
Iter: 289 loss: 6.4239515e-07
Iter: 290 loss: 6.41015845e-07
Iter: 291 loss: 6.5888122e-07
Iter: 292 loss: 6.40995609e-07
Iter: 293 loss: 6.40290182e-07
Iter: 294 loss: 6.39083055e-07
Iter: 295 loss: 6.39079872e-07
Iter: 296 loss: 6.37651738e-07
Iter: 297 loss: 6.42718646e-07
Iter: 298 loss: 6.37304879e-07
Iter: 299 loss: 6.34912681e-07
Iter: 300 loss: 6.3582462e-07
Iter: 301 loss: 6.33268542e-07
Iter: 302 loss: 6.31120201e-07
Iter: 303 loss: 6.33306968e-07
Iter: 304 loss: 6.29945532e-07
Iter: 305 loss: 6.28098576e-07
Iter: 306 loss: 6.54389737e-07
Iter: 307 loss: 6.2809039e-07
Iter: 308 loss: 6.26386225e-07
Iter: 309 loss: 6.27384964e-07
Iter: 310 loss: 6.25308871e-07
Iter: 311 loss: 6.23851804e-07
Iter: 312 loss: 6.25356677e-07
Iter: 313 loss: 6.2306043e-07
Iter: 314 loss: 6.22334596e-07
Iter: 315 loss: 6.22222103e-07
Iter: 316 loss: 6.2149428e-07
Iter: 317 loss: 6.19614184e-07
Iter: 318 loss: 6.34908417e-07
Iter: 319 loss: 6.19272782e-07
Iter: 320 loss: 6.17313958e-07
Iter: 321 loss: 6.22676566e-07
Iter: 322 loss: 6.16688567e-07
Iter: 323 loss: 6.14632654e-07
Iter: 324 loss: 6.25359917e-07
Iter: 325 loss: 6.14311148e-07
Iter: 326 loss: 6.11713858e-07
Iter: 327 loss: 6.23785922e-07
Iter: 328 loss: 6.11234952e-07
Iter: 329 loss: 6.10335e-07
Iter: 330 loss: 6.09641859e-07
Iter: 331 loss: 6.09295512e-07
Iter: 332 loss: 6.08251298e-07
Iter: 333 loss: 6.08269602e-07
Iter: 334 loss: 6.07223228e-07
Iter: 335 loss: 6.06105118e-07
Iter: 336 loss: 6.05910202e-07
Iter: 337 loss: 6.04855757e-07
Iter: 338 loss: 6.04761567e-07
Iter: 339 loss: 6.03959279e-07
Iter: 340 loss: 6.02927059e-07
Iter: 341 loss: 6.02851287e-07
Iter: 342 loss: 6.01929173e-07
Iter: 343 loss: 6.0158419e-07
Iter: 344 loss: 6.01071463e-07
Iter: 345 loss: 6.00037652e-07
Iter: 346 loss: 5.99845123e-07
Iter: 347 loss: 5.99191367e-07
Iter: 348 loss: 5.97631924e-07
Iter: 349 loss: 6.1783345e-07
Iter: 350 loss: 5.97626e-07
Iter: 351 loss: 5.96775067e-07
Iter: 352 loss: 5.9652524e-07
Iter: 353 loss: 5.96010636e-07
Iter: 354 loss: 5.95167648e-07
Iter: 355 loss: 5.9401566e-07
Iter: 356 loss: 5.93951484e-07
Iter: 357 loss: 5.92461333e-07
Iter: 358 loss: 6.11356597e-07
Iter: 359 loss: 5.92449794e-07
Iter: 360 loss: 5.9087256e-07
Iter: 361 loss: 5.975254e-07
Iter: 362 loss: 5.90543891e-07
Iter: 363 loss: 5.8956266e-07
Iter: 364 loss: 5.8719877e-07
Iter: 365 loss: 6.11400537e-07
Iter: 366 loss: 5.86924e-07
Iter: 367 loss: 5.878e-07
Iter: 368 loss: 5.85907458e-07
Iter: 369 loss: 5.852595e-07
Iter: 370 loss: 5.83940619e-07
Iter: 371 loss: 6.06140475e-07
Iter: 372 loss: 5.8389918e-07
Iter: 373 loss: 5.82433245e-07
Iter: 374 loss: 5.85186285e-07
Iter: 375 loss: 5.81771474e-07
Iter: 376 loss: 5.81779773e-07
Iter: 377 loss: 5.81156769e-07
Iter: 378 loss: 5.80856863e-07
Iter: 379 loss: 5.80096753e-07
Iter: 380 loss: 5.87898455e-07
Iter: 381 loss: 5.79999607e-07
Iter: 382 loss: 5.78844038e-07
Iter: 383 loss: 5.80089136e-07
Iter: 384 loss: 5.7820705e-07
Iter: 385 loss: 5.76262778e-07
Iter: 386 loss: 5.85094199e-07
Iter: 387 loss: 5.75879653e-07
Iter: 388 loss: 5.74860564e-07
Iter: 389 loss: 5.74632907e-07
Iter: 390 loss: 5.73963177e-07
Iter: 391 loss: 5.72396573e-07
Iter: 392 loss: 5.7078438e-07
Iter: 393 loss: 5.70467364e-07
Iter: 394 loss: 5.71452631e-07
Iter: 395 loss: 5.69777e-07
Iter: 396 loss: 5.69153485e-07
Iter: 397 loss: 5.68907e-07
Iter: 398 loss: 5.68565781e-07
Iter: 399 loss: 5.67879795e-07
Iter: 400 loss: 5.67447785e-07
Iter: 401 loss: 5.67163283e-07
Iter: 402 loss: 5.66591609e-07
Iter: 403 loss: 5.66499239e-07
Iter: 404 loss: 5.66047618e-07
Iter: 405 loss: 5.64932122e-07
Iter: 406 loss: 5.7216505e-07
Iter: 407 loss: 5.64610446e-07
Iter: 408 loss: 5.63159688e-07
Iter: 409 loss: 5.68695953e-07
Iter: 410 loss: 5.62804587e-07
Iter: 411 loss: 5.62279183e-07
Iter: 412 loss: 5.62226603e-07
Iter: 413 loss: 5.615031e-07
Iter: 414 loss: 5.60494698e-07
Iter: 415 loss: 5.60478611e-07
Iter: 416 loss: 5.59621867e-07
Iter: 417 loss: 5.61539196e-07
Iter: 418 loss: 5.59311218e-07
Iter: 419 loss: 5.58603233e-07
Iter: 420 loss: 5.66408403e-07
Iter: 421 loss: 5.58595389e-07
Iter: 422 loss: 5.57721251e-07
Iter: 423 loss: 5.56273676e-07
Iter: 424 loss: 5.56240707e-07
Iter: 425 loss: 5.55136296e-07
Iter: 426 loss: 5.59804e-07
Iter: 427 loss: 5.54875214e-07
Iter: 428 loss: 5.5396572e-07
Iter: 429 loss: 5.63387346e-07
Iter: 430 loss: 5.53931955e-07
Iter: 431 loss: 5.52955612e-07
Iter: 432 loss: 5.5314365e-07
Iter: 433 loss: 5.52213294e-07
Iter: 434 loss: 5.51586879e-07
Iter: 435 loss: 5.53563325e-07
Iter: 436 loss: 5.51407481e-07
Iter: 437 loss: 5.50908965e-07
Iter: 438 loss: 5.57897806e-07
Iter: 439 loss: 5.50913e-07
Iter: 440 loss: 5.50453763e-07
Iter: 441 loss: 5.49394599e-07
Iter: 442 loss: 5.58221814e-07
Iter: 443 loss: 5.49190759e-07
Iter: 444 loss: 5.48086291e-07
Iter: 445 loss: 5.49315e-07
Iter: 446 loss: 5.47485968e-07
Iter: 447 loss: 5.46224101e-07
Iter: 448 loss: 5.63913261e-07
Iter: 449 loss: 5.46207616e-07
Iter: 450 loss: 5.44824161e-07
Iter: 451 loss: 5.46538161e-07
Iter: 452 loss: 5.44066154e-07
Iter: 453 loss: 5.43291776e-07
Iter: 454 loss: 5.42471128e-07
Iter: 455 loss: 5.42308612e-07
Iter: 456 loss: 5.42031898e-07
Iter: 457 loss: 5.41685154e-07
Iter: 458 loss: 5.41261215e-07
Iter: 459 loss: 5.41097506e-07
Iter: 460 loss: 5.40856149e-07
Iter: 461 loss: 5.40465578e-07
Iter: 462 loss: 5.39830751e-07
Iter: 463 loss: 5.3982194e-07
Iter: 464 loss: 5.39279256e-07
Iter: 465 loss: 5.39197856e-07
Iter: 466 loss: 5.38768177e-07
Iter: 467 loss: 5.38264317e-07
Iter: 468 loss: 5.38218501e-07
Iter: 469 loss: 5.3738637e-07
Iter: 470 loss: 5.37246706e-07
Iter: 471 loss: 5.36678044e-07
Iter: 472 loss: 5.3483393e-07
Iter: 473 loss: 5.41616259e-07
Iter: 474 loss: 5.34386e-07
Iter: 475 loss: 5.33530454e-07
Iter: 476 loss: 5.33527214e-07
Iter: 477 loss: 5.3281542e-07
Iter: 478 loss: 5.31833223e-07
Iter: 479 loss: 5.33914886e-07
Iter: 480 loss: 5.31424178e-07
Iter: 481 loss: 5.31663943e-07
Iter: 482 loss: 5.31024284e-07
Iter: 483 loss: 5.30822774e-07
Iter: 484 loss: 5.30293732e-07
Iter: 485 loss: 5.33161767e-07
Iter: 486 loss: 5.30130308e-07
Iter: 487 loss: 5.29376848e-07
Iter: 488 loss: 5.32806212e-07
Iter: 489 loss: 5.29232523e-07
Iter: 490 loss: 5.28645955e-07
Iter: 491 loss: 5.28645501e-07
Iter: 492 loss: 5.28355315e-07
Iter: 493 loss: 5.2742439e-07
Iter: 494 loss: 5.28733608e-07
Iter: 495 loss: 5.26747101e-07
Iter: 496 loss: 5.2614962e-07
Iter: 497 loss: 5.25858354e-07
Iter: 498 loss: 5.25194878e-07
Iter: 499 loss: 5.28291594e-07
Iter: 500 loss: 5.2503708e-07
Iter: 501 loss: 5.24667485e-07
Iter: 502 loss: 5.24027769e-07
Iter: 503 loss: 5.24019583e-07
Iter: 504 loss: 5.23530957e-07
Iter: 505 loss: 5.23470419e-07
Iter: 506 loss: 5.23110828e-07
Iter: 507 loss: 5.22626351e-07
Iter: 508 loss: 5.22565585e-07
Iter: 509 loss: 5.21841116e-07
Iter: 510 loss: 5.21065942e-07
Iter: 511 loss: 5.2094191e-07
Iter: 512 loss: 5.20282697e-07
Iter: 513 loss: 5.20247625e-07
Iter: 514 loss: 5.19609614e-07
Iter: 515 loss: 5.21864536e-07
Iter: 516 loss: 5.19454034e-07
Iter: 517 loss: 5.19041e-07
Iter: 518 loss: 5.18108322e-07
Iter: 519 loss: 5.31636886e-07
Iter: 520 loss: 5.18053128e-07
Iter: 521 loss: 5.18214677e-07
Iter: 522 loss: 5.17701e-07
Iter: 523 loss: 5.17393346e-07
Iter: 524 loss: 5.16996522e-07
Iter: 525 loss: 5.16978616e-07
Iter: 526 loss: 5.16418311e-07
Iter: 527 loss: 5.15658598e-07
Iter: 528 loss: 5.15622219e-07
Iter: 529 loss: 5.15694296e-07
Iter: 530 loss: 5.15227271e-07
Iter: 531 loss: 5.14827946e-07
Iter: 532 loss: 5.13829377e-07
Iter: 533 loss: 5.2269e-07
Iter: 534 loss: 5.13650264e-07
Iter: 535 loss: 5.12547899e-07
Iter: 536 loss: 5.14999897e-07
Iter: 537 loss: 5.12118334e-07
Iter: 538 loss: 5.11988e-07
Iter: 539 loss: 5.11697863e-07
Iter: 540 loss: 5.11389089e-07
Iter: 541 loss: 5.10633527e-07
Iter: 542 loss: 5.1930175e-07
Iter: 543 loss: 5.1057259e-07
Iter: 544 loss: 5.10083964e-07
Iter: 545 loss: 5.16124146e-07
Iter: 546 loss: 5.1007811e-07
Iter: 547 loss: 5.09772576e-07
Iter: 548 loss: 5.12927841e-07
Iter: 549 loss: 5.09776442e-07
Iter: 550 loss: 5.09499046e-07
Iter: 551 loss: 5.08933454e-07
Iter: 552 loss: 5.17520903e-07
Iter: 553 loss: 5.08906396e-07
Iter: 554 loss: 5.08185906e-07
Iter: 555 loss: 5.11284782e-07
Iter: 556 loss: 5.08076141e-07
Iter: 557 loss: 5.07627533e-07
Iter: 558 loss: 5.07610537e-07
Iter: 559 loss: 5.07224513e-07
Iter: 560 loss: 5.06187575e-07
Iter: 561 loss: 5.12749e-07
Iter: 562 loss: 5.05904723e-07
Iter: 563 loss: 5.05071284e-07
Iter: 564 loss: 5.16625278e-07
Iter: 565 loss: 5.05078106e-07
Iter: 566 loss: 5.04743696e-07
Iter: 567 loss: 5.04705099e-07
Iter: 568 loss: 5.04454761e-07
Iter: 569 loss: 5.03755132e-07
Iter: 570 loss: 5.07672553e-07
Iter: 571 loss: 5.03566412e-07
Iter: 572 loss: 5.02953071e-07
Iter: 573 loss: 5.09375809e-07
Iter: 574 loss: 5.02937439e-07
Iter: 575 loss: 5.02556077e-07
Iter: 576 loss: 5.02550847e-07
Iter: 577 loss: 5.02224225e-07
Iter: 578 loss: 5.01351963e-07
Iter: 579 loss: 5.07696768e-07
Iter: 580 loss: 5.01167449e-07
Iter: 581 loss: 5.01019883e-07
Iter: 582 loss: 5.00762326e-07
Iter: 583 loss: 5.00406884e-07
Iter: 584 loss: 5.00148303e-07
Iter: 585 loss: 5.00024498e-07
Iter: 586 loss: 4.99523935e-07
Iter: 587 loss: 4.99845896e-07
Iter: 588 loss: 4.99177304e-07
Iter: 589 loss: 4.98842724e-07
Iter: 590 loss: 4.98836926e-07
Iter: 591 loss: 4.98516442e-07
Iter: 592 loss: 4.98388488e-07
Iter: 593 loss: 4.98182771e-07
Iter: 594 loss: 4.97704661e-07
Iter: 595 loss: 4.97142764e-07
Iter: 596 loss: 4.97033056e-07
Iter: 597 loss: 4.96706662e-07
Iter: 598 loss: 4.96659595e-07
Iter: 599 loss: 4.96173413e-07
Iter: 600 loss: 4.9565358e-07
Iter: 601 loss: 4.9558173e-07
Iter: 602 loss: 4.94875394e-07
Iter: 603 loss: 4.95522499e-07
Iter: 604 loss: 4.94466917e-07
Iter: 605 loss: 4.94258927e-07
Iter: 606 loss: 4.94199753e-07
Iter: 607 loss: 4.93908715e-07
Iter: 608 loss: 4.9366156e-07
Iter: 609 loss: 4.93600055e-07
Iter: 610 loss: 4.93231937e-07
Iter: 611 loss: 4.94174287e-07
Iter: 612 loss: 4.93143261e-07
Iter: 613 loss: 4.92841309e-07
Iter: 614 loss: 4.9714123e-07
Iter: 615 loss: 4.92830281e-07
Iter: 616 loss: 4.92626555e-07
Iter: 617 loss: 4.92010258e-07
Iter: 618 loss: 4.95748282e-07
Iter: 619 loss: 4.91852916e-07
Iter: 620 loss: 4.91080641e-07
Iter: 621 loss: 4.96846724e-07
Iter: 622 loss: 4.91004243e-07
Iter: 623 loss: 4.90484183e-07
Iter: 624 loss: 4.90479465e-07
Iter: 625 loss: 4.90150342e-07
Iter: 626 loss: 4.89429624e-07
Iter: 627 loss: 5.01320415e-07
Iter: 628 loss: 4.89402225e-07
Iter: 629 loss: 4.88852663e-07
Iter: 630 loss: 4.94553319e-07
Iter: 631 loss: 4.88832939e-07
Iter: 632 loss: 4.88668093e-07
Iter: 633 loss: 4.88636147e-07
Iter: 634 loss: 4.88479486e-07
Iter: 635 loss: 4.88114893e-07
Iter: 636 loss: 4.9121229e-07
Iter: 637 loss: 4.88058731e-07
Iter: 638 loss: 4.8772722e-07
Iter: 639 loss: 4.89448325e-07
Iter: 640 loss: 4.87683e-07
Iter: 641 loss: 4.87311354e-07
Iter: 642 loss: 4.89972081e-07
Iter: 643 loss: 4.87276566e-07
Iter: 644 loss: 4.86929139e-07
Iter: 645 loss: 4.8607393e-07
Iter: 646 loss: 4.94471e-07
Iter: 647 loss: 4.85944554e-07
Iter: 648 loss: 4.85804605e-07
Iter: 649 loss: 4.85558871e-07
Iter: 650 loss: 4.8519496e-07
Iter: 651 loss: 4.84738678e-07
Iter: 652 loss: 4.84706618e-07
Iter: 653 loss: 4.84148927e-07
Iter: 654 loss: 4.84396253e-07
Iter: 655 loss: 4.8373613e-07
Iter: 656 loss: 4.83729536e-07
Iter: 657 loss: 4.83527288e-07
Iter: 658 loss: 4.83364033e-07
Iter: 659 loss: 4.83125746e-07
Iter: 660 loss: 4.83111421e-07
Iter: 661 loss: 4.82773e-07
Iter: 662 loss: 4.82779399e-07
Iter: 663 loss: 4.82493647e-07
Iter: 664 loss: 4.82252517e-07
Iter: 665 loss: 4.82239955e-07
Iter: 666 loss: 4.81957215e-07
Iter: 667 loss: 4.8152765e-07
Iter: 668 loss: 4.81505481e-07
Iter: 669 loss: 4.80936308e-07
Iter: 670 loss: 4.80634299e-07
Iter: 671 loss: 4.80380891e-07
Iter: 672 loss: 4.80228834e-07
Iter: 673 loss: 4.80065808e-07
Iter: 674 loss: 4.79739811e-07
Iter: 675 loss: 4.79275798e-07
Iter: 676 loss: 4.79250389e-07
Iter: 677 loss: 4.78766879e-07
Iter: 678 loss: 4.80537665e-07
Iter: 679 loss: 4.78637219e-07
Iter: 680 loss: 4.78284903e-07
Iter: 681 loss: 4.78287745e-07
Iter: 682 loss: 4.78130744e-07
Iter: 683 loss: 4.77696062e-07
Iter: 684 loss: 4.80648055e-07
Iter: 685 loss: 4.77590788e-07
Iter: 686 loss: 4.77088292e-07
Iter: 687 loss: 4.82606197e-07
Iter: 688 loss: 4.77077549e-07
Iter: 689 loss: 4.76689138e-07
Iter: 690 loss: 4.80417839e-07
Iter: 691 loss: 4.76680526e-07
Iter: 692 loss: 4.76430131e-07
Iter: 693 loss: 4.75872866e-07
Iter: 694 loss: 4.82268604e-07
Iter: 695 loss: 4.75810765e-07
Iter: 696 loss: 4.75406409e-07
Iter: 697 loss: 4.75418148e-07
Iter: 698 loss: 4.7516221e-07
Iter: 699 loss: 4.78367042e-07
Iter: 700 loss: 4.75175739e-07
Iter: 701 loss: 4.74976446e-07
Iter: 702 loss: 4.74496233e-07
Iter: 703 loss: 4.76810783e-07
Iter: 704 loss: 4.74326981e-07
Iter: 705 loss: 4.73839862e-07
Iter: 706 loss: 4.8148388e-07
Iter: 707 loss: 4.7382872e-07
Iter: 708 loss: 4.73482089e-07
Iter: 709 loss: 4.77428273e-07
Iter: 710 loss: 4.73474358e-07
Iter: 711 loss: 4.73266084e-07
Iter: 712 loss: 4.72715641e-07
Iter: 713 loss: 4.77578737e-07
Iter: 714 loss: 4.7262489e-07
Iter: 715 loss: 4.72434209e-07
Iter: 716 loss: 4.72276781e-07
Iter: 717 loss: 4.72059696e-07
Iter: 718 loss: 4.71916024e-07
Iter: 719 loss: 4.71843066e-07
Iter: 720 loss: 4.71592045e-07
Iter: 721 loss: 4.71453063e-07
Iter: 722 loss: 4.71348756e-07
Iter: 723 loss: 4.71234216e-07
Iter: 724 loss: 4.71149065e-07
Iter: 725 loss: 4.70997918e-07
Iter: 726 loss: 4.70819572e-07
Iter: 727 loss: 4.70817412e-07
Iter: 728 loss: 4.70535838e-07
Iter: 729 loss: 4.703017e-07
Iter: 730 loss: 4.70225103e-07
Iter: 731 loss: 4.69788688e-07
Iter: 732 loss: 4.74201983e-07
Iter: 733 loss: 4.69784908e-07
Iter: 734 loss: 4.69366512e-07
Iter: 735 loss: 4.69280735e-07
Iter: 736 loss: 4.69020677e-07
Iter: 737 loss: 4.6852378e-07
Iter: 738 loss: 4.68022705e-07
Iter: 739 loss: 4.67893358e-07
Iter: 740 loss: 4.68270684e-07
Iter: 741 loss: 4.67661152e-07
Iter: 742 loss: 4.67471523e-07
Iter: 743 loss: 4.67100676e-07
Iter: 744 loss: 4.67106645e-07
Iter: 745 loss: 4.66785053e-07
Iter: 746 loss: 4.69384531e-07
Iter: 747 loss: 4.66747224e-07
Iter: 748 loss: 4.66459625e-07
Iter: 749 loss: 4.67846462e-07
Iter: 750 loss: 4.6641253e-07
Iter: 751 loss: 4.66259621e-07
Iter: 752 loss: 4.65939394e-07
Iter: 753 loss: 4.6981944e-07
Iter: 754 loss: 4.65913786e-07
Iter: 755 loss: 4.6545631e-07
Iter: 756 loss: 4.69373617e-07
Iter: 757 loss: 4.65432322e-07
Iter: 758 loss: 4.64992354e-07
Iter: 759 loss: 4.66686572e-07
Iter: 760 loss: 4.6490868e-07
Iter: 761 loss: 4.64649702e-07
Iter: 762 loss: 4.64816509e-07
Iter: 763 loss: 4.64501454e-07
Iter: 764 loss: 4.642325e-07
Iter: 765 loss: 4.65485641e-07
Iter: 766 loss: 4.64144904e-07
Iter: 767 loss: 4.63813592e-07
Iter: 768 loss: 4.64171848e-07
Iter: 769 loss: 4.63627316e-07
Iter: 770 loss: 4.6335748e-07
Iter: 771 loss: 4.63707352e-07
Iter: 772 loss: 4.63217958e-07
Iter: 773 loss: 4.62919502e-07
Iter: 774 loss: 4.63140395e-07
Iter: 775 loss: 4.62756191e-07
Iter: 776 loss: 4.62286891e-07
Iter: 777 loss: 4.65400745e-07
Iter: 778 loss: 4.6225216e-07
Iter: 779 loss: 4.62046e-07
Iter: 780 loss: 4.61750119e-07
Iter: 781 loss: 4.61734828e-07
Iter: 782 loss: 4.61299294e-07
Iter: 783 loss: 4.66022954e-07
Iter: 784 loss: 4.61294576e-07
Iter: 785 loss: 4.61051343e-07
Iter: 786 loss: 4.60776647e-07
Iter: 787 loss: 4.607368e-07
Iter: 788 loss: 4.60472677e-07
Iter: 789 loss: 4.61446263e-07
Iter: 790 loss: 4.60396222e-07
Iter: 791 loss: 4.6003845e-07
Iter: 792 loss: 4.61663035e-07
Iter: 793 loss: 4.60009829e-07
Iter: 794 loss: 4.59718535e-07
Iter: 795 loss: 4.59945056e-07
Iter: 796 loss: 4.59549511e-07
Iter: 797 loss: 4.59320688e-07
Iter: 798 loss: 4.61172931e-07
Iter: 799 loss: 4.59307756e-07
Iter: 800 loss: 4.59047641e-07
Iter: 801 loss: 4.59104086e-07
Iter: 802 loss: 4.58855084e-07
Iter: 803 loss: 4.58433249e-07
Iter: 804 loss: 4.57927825e-07
Iter: 805 loss: 4.57893776e-07
Iter: 806 loss: 4.57302576e-07
Iter: 807 loss: 4.60002411e-07
Iter: 808 loss: 4.57211115e-07
Iter: 809 loss: 4.56884635e-07
Iter: 810 loss: 4.56841519e-07
Iter: 811 loss: 4.56603118e-07
Iter: 812 loss: 4.56310346e-07
Iter: 813 loss: 4.56286614e-07
Iter: 814 loss: 4.56212035e-07
Iter: 815 loss: 4.56176394e-07
Iter: 816 loss: 4.56067937e-07
Iter: 817 loss: 4.55804411e-07
Iter: 818 loss: 4.58541678e-07
Iter: 819 loss: 4.55769054e-07
Iter: 820 loss: 4.55434872e-07
Iter: 821 loss: 4.5649827e-07
Iter: 822 loss: 4.55347788e-07
Iter: 823 loss: 4.55122631e-07
Iter: 824 loss: 4.55114673e-07
Iter: 825 loss: 4.54914925e-07
Iter: 826 loss: 4.5448968e-07
Iter: 827 loss: 4.61062427e-07
Iter: 828 loss: 4.54471518e-07
Iter: 829 loss: 4.54000201e-07
Iter: 830 loss: 4.5834372e-07
Iter: 831 loss: 4.53963565e-07
Iter: 832 loss: 4.53634243e-07
Iter: 833 loss: 4.55963203e-07
Iter: 834 loss: 4.53585216e-07
Iter: 835 loss: 4.53355824e-07
Iter: 836 loss: 4.53015105e-07
Iter: 837 loss: 4.53003963e-07
Iter: 838 loss: 4.52558595e-07
Iter: 839 loss: 4.53510836e-07
Iter: 840 loss: 4.52381698e-07
Iter: 841 loss: 4.52313799e-07
Iter: 842 loss: 4.52244706e-07
Iter: 843 loss: 4.52090433e-07
Iter: 844 loss: 4.51813207e-07
Iter: 845 loss: 4.57697126e-07
Iter: 846 loss: 4.51816874e-07
Iter: 847 loss: 4.51518645e-07
Iter: 848 loss: 4.52959682e-07
Iter: 849 loss: 4.51451143e-07
Iter: 850 loss: 4.51111589e-07
Iter: 851 loss: 4.52727221e-07
Iter: 852 loss: 4.51067081e-07
Iter: 853 loss: 4.50878531e-07
Iter: 854 loss: 4.50452433e-07
Iter: 855 loss: 4.56251769e-07
Iter: 856 loss: 4.50423897e-07
Iter: 857 loss: 4.50228185e-07
Iter: 858 loss: 4.50158552e-07
Iter: 859 loss: 4.49934021e-07
Iter: 860 loss: 4.50116886e-07
Iter: 861 loss: 4.4980888e-07
Iter: 862 loss: 4.4960322e-07
Iter: 863 loss: 4.49621467e-07
Iter: 864 loss: 4.49440279e-07
Iter: 865 loss: 4.49117209e-07
Iter: 866 loss: 4.51270978e-07
Iter: 867 loss: 4.4909612e-07
Iter: 868 loss: 4.48851438e-07
Iter: 869 loss: 4.48799966e-07
Iter: 870 loss: 4.48637564e-07
Iter: 871 loss: 4.48304235e-07
Iter: 872 loss: 4.48011946e-07
Iter: 873 loss: 4.47907354e-07
Iter: 874 loss: 4.47517891e-07
Iter: 875 loss: 4.47509024e-07
Iter: 876 loss: 4.47229269e-07
Iter: 877 loss: 4.50116545e-07
Iter: 878 loss: 4.47211363e-07
Iter: 879 loss: 4.47095516e-07
Iter: 880 loss: 4.46809651e-07
Iter: 881 loss: 4.50964592e-07
Iter: 882 loss: 4.46826846e-07
Iter: 883 loss: 4.46606123e-07
Iter: 884 loss: 4.46574063e-07
Iter: 885 loss: 4.46469187e-07
Iter: 886 loss: 4.46229706e-07
Iter: 887 loss: 4.50978803e-07
Iter: 888 loss: 4.4623539e-07
Iter: 889 loss: 4.46012223e-07
Iter: 890 loss: 4.46995188e-07
Iter: 891 loss: 4.45965e-07
Iter: 892 loss: 4.4563356e-07
Iter: 893 loss: 4.46136e-07
Iter: 894 loss: 4.45477156e-07
Iter: 895 loss: 4.45144e-07
Iter: 896 loss: 4.45472693e-07
Iter: 897 loss: 4.44951951e-07
Iter: 898 loss: 4.44600289e-07
Iter: 899 loss: 4.4697731e-07
Iter: 900 loss: 4.44561948e-07
Iter: 901 loss: 4.44222309e-07
Iter: 902 loss: 4.4410757e-07
Iter: 903 loss: 4.43893299e-07
Iter: 904 loss: 4.43555621e-07
Iter: 905 loss: 4.44714516e-07
Iter: 906 loss: 4.4345677e-07
Iter: 907 loss: 4.43217743e-07
Iter: 908 loss: 4.4380451e-07
Iter: 909 loss: 4.43124122e-07
Iter: 910 loss: 4.4292193e-07
Iter: 911 loss: 4.4292085e-07
Iter: 912 loss: 4.42818191e-07
Iter: 913 loss: 4.42673525e-07
Iter: 914 loss: 4.42677106e-07
Iter: 915 loss: 4.42506348e-07
Iter: 916 loss: 4.44398552e-07
Iter: 917 loss: 4.42506433e-07
Iter: 918 loss: 4.42302422e-07
Iter: 919 loss: 4.41788984e-07
Iter: 920 loss: 4.46851885e-07
Iter: 921 loss: 4.41759425e-07
Iter: 922 loss: 4.41392615e-07
Iter: 923 loss: 4.45946029e-07
Iter: 924 loss: 4.41385453e-07
Iter: 925 loss: 4.41043369e-07
Iter: 926 loss: 4.43298859e-07
Iter: 927 loss: 4.41012048e-07
Iter: 928 loss: 4.40752189e-07
Iter: 929 loss: 4.4059297e-07
Iter: 930 loss: 4.40485564e-07
Iter: 931 loss: 4.40260123e-07
Iter: 932 loss: 4.40260123e-07
Iter: 933 loss: 4.40117816e-07
Iter: 934 loss: 4.40189154e-07
Iter: 935 loss: 4.40019676e-07
Iter: 936 loss: 4.39851647e-07
Iter: 937 loss: 4.39784259e-07
Iter: 938 loss: 4.39677535e-07
Iter: 939 loss: 4.39445898e-07
Iter: 940 loss: 4.39962207e-07
Iter: 941 loss: 4.39349037e-07
Iter: 942 loss: 4.39131384e-07
Iter: 943 loss: 4.39132293e-07
Iter: 944 loss: 4.389222e-07
Iter: 945 loss: 4.38480157e-07
Iter: 946 loss: 4.4690097e-07
Iter: 947 loss: 4.384558e-07
Iter: 948 loss: 4.38201141e-07
Iter: 949 loss: 4.38191364e-07
Iter: 950 loss: 4.37888019e-07
Iter: 951 loss: 4.37618382e-07
Iter: 952 loss: 4.37550966e-07
Iter: 953 loss: 4.37144081e-07
Iter: 954 loss: 4.3769893e-07
Iter: 955 loss: 4.36955588e-07
Iter: 956 loss: 4.36832181e-07
Iter: 957 loss: 4.36776531e-07
Iter: 958 loss: 4.36649827e-07
Iter: 959 loss: 4.36466081e-07
Iter: 960 loss: 4.36456844e-07
Iter: 961 loss: 4.36216851e-07
Iter: 962 loss: 4.3843707e-07
Iter: 963 loss: 4.36208808e-07
Iter: 964 loss: 4.36044843e-07
Iter: 965 loss: 4.36241635e-07
Iter: 966 loss: 4.35973e-07
Iter: 967 loss: 4.35793766e-07
Iter: 968 loss: 4.35669023e-07
Iter: 969 loss: 4.35629602e-07
Iter: 970 loss: 4.3526137e-07
Iter: 971 loss: 4.35497839e-07
Iter: 972 loss: 4.3506418e-07
Iter: 973 loss: 4.34896151e-07
Iter: 974 loss: 4.3486375e-07
Iter: 975 loss: 4.34642914e-07
Iter: 976 loss: 4.34429495e-07
Iter: 977 loss: 4.34386777e-07
Iter: 978 loss: 4.34134932e-07
Iter: 979 loss: 4.35088339e-07
Iter: 980 loss: 4.34067033e-07
Iter: 981 loss: 4.33918871e-07
Iter: 982 loss: 4.33934815e-07
Iter: 983 loss: 4.33817036e-07
Iter: 984 loss: 4.3350741e-07
Iter: 985 loss: 4.34332406e-07
Iter: 986 loss: 4.33332787e-07
Iter: 987 loss: 4.33304876e-07
Iter: 988 loss: 4.33139917e-07
Iter: 989 loss: 4.32964839e-07
Iter: 990 loss: 4.32939203e-07
Iter: 991 loss: 4.32811532e-07
Iter: 992 loss: 4.32587399e-07
Iter: 993 loss: 4.33265399e-07
Iter: 994 loss: 4.32520835e-07
Iter: 995 loss: 4.32190092e-07
Iter: 996 loss: 4.32965436e-07
Iter: 997 loss: 4.32096357e-07
Iter: 998 loss: 4.31928328e-07
Iter: 999 loss: 4.32146237e-07
Iter: 1000 loss: 4.31849969e-07
Iter: 1001 loss: 4.31666734e-07
Iter: 1002 loss: 4.31682111e-07
Iter: 1003 loss: 4.31524597e-07
Iter: 1004 loss: 4.31325361e-07
Iter: 1005 loss: 4.32594788e-07
Iter: 1006 loss: 4.31319592e-07
Iter: 1007 loss: 4.31156082e-07
Iter: 1008 loss: 4.33203155e-07
Iter: 1009 loss: 4.31154945e-07
Iter: 1010 loss: 4.310279e-07
Iter: 1011 loss: 4.30675186e-07
Iter: 1012 loss: 4.32694321e-07
Iter: 1013 loss: 4.30585487e-07
Iter: 1014 loss: 4.30553172e-07
Iter: 1015 loss: 4.30396398e-07
Iter: 1016 loss: 4.30244341e-07
Iter: 1017 loss: 4.29842743e-07
Iter: 1018 loss: 4.3273252e-07
Iter: 1019 loss: 4.29754863e-07
Iter: 1020 loss: 4.29381686e-07
Iter: 1021 loss: 4.34734545e-07
Iter: 1022 loss: 4.29378872e-07
Iter: 1023 loss: 4.29140414e-07
Iter: 1024 loss: 4.30684679e-07
Iter: 1025 loss: 4.29129756e-07
Iter: 1026 loss: 4.28991797e-07
Iter: 1027 loss: 4.288691e-07
Iter: 1028 loss: 4.28848068e-07
Iter: 1029 loss: 4.28644881e-07
Iter: 1030 loss: 4.28653522e-07
Iter: 1031 loss: 4.28541284e-07
Iter: 1032 loss: 4.28497543e-07
Iter: 1033 loss: 4.28456531e-07
Iter: 1034 loss: 4.28319595e-07
Iter: 1035 loss: 4.28216879e-07
Iter: 1036 loss: 4.28187093e-07
Iter: 1037 loss: 4.2793846e-07
Iter: 1038 loss: 4.2823612e-07
Iter: 1039 loss: 4.27798426e-07
Iter: 1040 loss: 4.27796238e-07
Iter: 1041 loss: 4.27664816e-07
Iter: 1042 loss: 4.27574179e-07
Iter: 1043 loss: 4.27286551e-07
Iter: 1044 loss: 4.28501778e-07
Iter: 1045 loss: 4.27178e-07
Iter: 1046 loss: 4.26896548e-07
Iter: 1047 loss: 4.29897284e-07
Iter: 1048 loss: 4.26874919e-07
Iter: 1049 loss: 4.26719794e-07
Iter: 1050 loss: 4.26729457e-07
Iter: 1051 loss: 4.26601645e-07
Iter: 1052 loss: 4.26250892e-07
Iter: 1053 loss: 4.29221075e-07
Iter: 1054 loss: 4.26195271e-07
Iter: 1055 loss: 4.26173358e-07
Iter: 1056 loss: 4.260813e-07
Iter: 1057 loss: 4.25965709e-07
Iter: 1058 loss: 4.25619362e-07
Iter: 1059 loss: 4.27343878e-07
Iter: 1060 loss: 4.25496e-07
Iter: 1061 loss: 4.25441101e-07
Iter: 1062 loss: 4.25338584e-07
Iter: 1063 loss: 4.25202472e-07
Iter: 1064 loss: 4.25377266e-07
Iter: 1065 loss: 4.25140144e-07
Iter: 1066 loss: 4.25000849e-07
Iter: 1067 loss: 4.24764238e-07
Iter: 1068 loss: 4.30528587e-07
Iter: 1069 loss: 4.24769951e-07
Iter: 1070 loss: 4.24532828e-07
Iter: 1071 loss: 4.25771162e-07
Iter: 1072 loss: 4.24503924e-07
Iter: 1073 loss: 4.24321e-07
Iter: 1074 loss: 4.24096925e-07
Iter: 1075 loss: 4.24057248e-07
Iter: 1076 loss: 4.23851702e-07
Iter: 1077 loss: 4.23850508e-07
Iter: 1078 loss: 4.23606423e-07
Iter: 1079 loss: 4.23803215e-07
Iter: 1080 loss: 4.23458317e-07
Iter: 1081 loss: 4.2320147e-07
Iter: 1082 loss: 4.22806295e-07
Iter: 1083 loss: 4.22799673e-07
Iter: 1084 loss: 4.23103131e-07
Iter: 1085 loss: 4.22602767e-07
Iter: 1086 loss: 4.22511022e-07
Iter: 1087 loss: 4.22349444e-07
Iter: 1088 loss: 4.24896086e-07
Iter: 1089 loss: 4.22336456e-07
Iter: 1090 loss: 4.22149526e-07
Iter: 1091 loss: 4.24950656e-07
Iter: 1092 loss: 4.22158593e-07
Iter: 1093 loss: 4.22008299e-07
Iter: 1094 loss: 4.21723684e-07
Iter: 1095 loss: 4.27737518e-07
Iter: 1096 loss: 4.2172266e-07
Iter: 1097 loss: 4.21393651e-07
Iter: 1098 loss: 4.21288121e-07
Iter: 1099 loss: 4.21111906e-07
Iter: 1100 loss: 4.20768288e-07
Iter: 1101 loss: 4.2075672e-07
Iter: 1102 loss: 4.20526163e-07
Iter: 1103 loss: 4.23152443e-07
Iter: 1104 loss: 4.20509537e-07
Iter: 1105 loss: 4.20401761e-07
Iter: 1106 loss: 4.2011942e-07
Iter: 1107 loss: 4.23175095e-07
Iter: 1108 loss: 4.200825e-07
Iter: 1109 loss: 4.19949373e-07
Iter: 1110 loss: 4.19919274e-07
Iter: 1111 loss: 4.19826904e-07
Iter: 1112 loss: 4.19997889e-07
Iter: 1113 loss: 4.19776626e-07
Iter: 1114 loss: 4.19657567e-07
Iter: 1115 loss: 4.19503181e-07
Iter: 1116 loss: 4.19500537e-07
Iter: 1117 loss: 4.19242355e-07
Iter: 1118 loss: 4.19591629e-07
Iter: 1119 loss: 4.19146204e-07
Iter: 1120 loss: 4.18931e-07
Iter: 1121 loss: 4.18928863e-07
Iter: 1122 loss: 4.18803552e-07
Iter: 1123 loss: 4.18449076e-07
Iter: 1124 loss: 4.20712041e-07
Iter: 1125 loss: 4.1836546e-07
Iter: 1126 loss: 4.18451492e-07
Iter: 1127 loss: 4.18219742e-07
Iter: 1128 loss: 4.1810722e-07
Iter: 1129 loss: 4.18008852e-07
Iter: 1130 loss: 4.17978072e-07
Iter: 1131 loss: 4.17834343e-07
Iter: 1132 loss: 4.17784406e-07
Iter: 1133 loss: 4.17691581e-07
Iter: 1134 loss: 4.17658157e-07
Iter: 1135 loss: 4.17557516e-07
Iter: 1136 loss: 4.17463809e-07
Iter: 1137 loss: 4.17422797e-07
Iter: 1138 loss: 4.17364902e-07
Iter: 1139 loss: 4.17204944e-07
Iter: 1140 loss: 4.1685837e-07
Iter: 1141 loss: 4.21713906e-07
Iter: 1142 loss: 4.16835462e-07
Iter: 1143 loss: 4.16814686e-07
Iter: 1144 loss: 4.16645548e-07
Iter: 1145 loss: 4.16512393e-07
Iter: 1146 loss: 4.16463877e-07
Iter: 1147 loss: 4.16398478e-07
Iter: 1148 loss: 4.16240169e-07
Iter: 1149 loss: 4.16168035e-07
Iter: 1150 loss: 4.16076261e-07
Iter: 1151 loss: 4.15912353e-07
Iter: 1152 loss: 4.15922528e-07
Iter: 1153 loss: 4.15790339e-07
Iter: 1154 loss: 4.15997647e-07
Iter: 1155 loss: 4.15739379e-07
Iter: 1156 loss: 4.15654625e-07
Iter: 1157 loss: 4.15515302e-07
Iter: 1158 loss: 4.15506918e-07
Iter: 1159 loss: 4.15333488e-07
Iter: 1160 loss: 4.15343237e-07
Iter: 1161 loss: 4.15259166e-07
Iter: 1162 loss: 4.15080677e-07
Iter: 1163 loss: 4.1820249e-07
Iter: 1164 loss: 4.15089062e-07
Iter: 1165 loss: 4.14868225e-07
Iter: 1166 loss: 4.147129e-07
Iter: 1167 loss: 4.14639374e-07
Iter: 1168 loss: 4.14706903e-07
Iter: 1169 loss: 4.14512698e-07
Iter: 1170 loss: 4.14414473e-07
Iter: 1171 loss: 4.1427495e-07
Iter: 1172 loss: 4.14267703e-07
Iter: 1173 loss: 4.14088873e-07
Iter: 1174 loss: 4.13747159e-07
Iter: 1175 loss: 4.21642198e-07
Iter: 1176 loss: 4.13745568e-07
Iter: 1177 loss: 4.13429092e-07
Iter: 1178 loss: 4.15450955e-07
Iter: 1179 loss: 4.13380462e-07
Iter: 1180 loss: 4.13118386e-07
Iter: 1181 loss: 4.1425551e-07
Iter: 1182 loss: 4.13066743e-07
Iter: 1183 loss: 4.1301584e-07
Iter: 1184 loss: 4.12954847e-07
Iter: 1185 loss: 4.12868445e-07
Iter: 1186 loss: 4.12639423e-07
Iter: 1187 loss: 4.14864985e-07
Iter: 1188 loss: 4.12617766e-07
Iter: 1189 loss: 4.12464658e-07
Iter: 1190 loss: 4.14610497e-07
Iter: 1191 loss: 4.12468324e-07
Iter: 1192 loss: 4.12397753e-07
Iter: 1193 loss: 4.1333584e-07
Iter: 1194 loss: 4.12404034e-07
Iter: 1195 loss: 4.12332952e-07
Iter: 1196 loss: 4.121448e-07
Iter: 1197 loss: 4.14133922e-07
Iter: 1198 loss: 4.12105692e-07
Iter: 1199 loss: 4.11889516e-07
Iter: 1200 loss: 4.12692884e-07
Iter: 1201 loss: 4.11841427e-07
Iter: 1202 loss: 4.116892e-07
Iter: 1203 loss: 4.11885026e-07
Iter: 1204 loss: 4.1162491e-07
Iter: 1205 loss: 4.11394808e-07
Iter: 1206 loss: 4.13399675e-07
Iter: 1207 loss: 4.11402425e-07
Iter: 1208 loss: 4.11270207e-07
Iter: 1209 loss: 4.11134863e-07
Iter: 1210 loss: 4.11115138e-07
Iter: 1211 loss: 4.10948275e-07
Iter: 1212 loss: 4.11355927e-07
Iter: 1213 loss: 4.10892454e-07
Iter: 1214 loss: 4.10760606e-07
Iter: 1215 loss: 4.10745258e-07
Iter: 1216 loss: 4.1070723e-07
Iter: 1217 loss: 4.10595675e-07
Iter: 1218 loss: 4.11867688e-07
Iter: 1219 loss: 4.10583027e-07
Iter: 1220 loss: 4.10465219e-07
Iter: 1221 loss: 4.12185329e-07
Iter: 1222 loss: 4.10467891e-07
Iter: 1223 loss: 4.1037012e-07
Iter: 1224 loss: 4.10277721e-07
Iter: 1225 loss: 4.1021957e-07
Iter: 1226 loss: 4.10111625e-07
Iter: 1227 loss: 4.09893488e-07
Iter: 1228 loss: 4.13978228e-07
Iter: 1229 loss: 4.09882432e-07
Iter: 1230 loss: 4.09744274e-07
Iter: 1231 loss: 4.09694564e-07
Iter: 1232 loss: 4.09519458e-07
Iter: 1233 loss: 4.09612255e-07
Iter: 1234 loss: 4.09403043e-07
Iter: 1235 loss: 4.09285803e-07
Iter: 1236 loss: 4.09269092e-07
Iter: 1237 loss: 4.09194911e-07
Iter: 1238 loss: 4.09089e-07
Iter: 1239 loss: 4.09063915e-07
Iter: 1240 loss: 4.08951593e-07
Iter: 1241 loss: 4.09524517e-07
Iter: 1242 loss: 4.08932664e-07
Iter: 1243 loss: 4.08850923e-07
Iter: 1244 loss: 4.08678346e-07
Iter: 1245 loss: 4.10581634e-07
Iter: 1246 loss: 4.08674651e-07
Iter: 1247 loss: 4.08470868e-07
Iter: 1248 loss: 4.0987112e-07
Iter: 1249 loss: 4.08440314e-07
Iter: 1250 loss: 4.0834172e-07
Iter: 1251 loss: 4.08326741e-07
Iter: 1252 loss: 4.08254948e-07
Iter: 1253 loss: 4.08063897e-07
Iter: 1254 loss: 4.10363896e-07
Iter: 1255 loss: 4.08049345e-07
Iter: 1256 loss: 4.07896039e-07
Iter: 1257 loss: 4.09386416e-07
Iter: 1258 loss: 4.07891378e-07
Iter: 1259 loss: 4.07773769e-07
Iter: 1260 loss: 4.08958442e-07
Iter: 1261 loss: 4.07765867e-07
Iter: 1262 loss: 4.07679863e-07
Iter: 1263 loss: 4.07494781e-07
Iter: 1264 loss: 4.0901898e-07
Iter: 1265 loss: 4.07453115e-07
Iter: 1266 loss: 4.07209484e-07
Iter: 1267 loss: 4.0779662e-07
Iter: 1268 loss: 4.07134252e-07
Iter: 1269 loss: 4.06925267e-07
Iter: 1270 loss: 4.09422597e-07
Iter: 1271 loss: 4.06907645e-07
Iter: 1272 loss: 4.06693346e-07
Iter: 1273 loss: 4.07692482e-07
Iter: 1274 loss: 4.06651623e-07
Iter: 1275 loss: 4.06540465e-07
Iter: 1276 loss: 4.06333243e-07
Iter: 1277 loss: 4.10759355e-07
Iter: 1278 loss: 4.06323295e-07
Iter: 1279 loss: 4.0633509e-07
Iter: 1280 loss: 4.06232914e-07
Iter: 1281 loss: 4.06136422e-07
Iter: 1282 loss: 4.06086713e-07
Iter: 1283 loss: 4.06067102e-07
Iter: 1284 loss: 4.05978653e-07
Iter: 1285 loss: 4.05880286e-07
Iter: 1286 loss: 4.05862352e-07
Iter: 1287 loss: 4.05707794e-07
Iter: 1288 loss: 4.06505251e-07
Iter: 1289 loss: 4.05664792e-07
Iter: 1290 loss: 4.05495086e-07
Iter: 1291 loss: 4.05806702e-07
Iter: 1292 loss: 4.05416813e-07
Iter: 1293 loss: 4.05200637e-07
Iter: 1294 loss: 4.07272e-07
Iter: 1295 loss: 4.05188217e-07
Iter: 1296 loss: 4.05035e-07
Iter: 1297 loss: 4.04866427e-07
Iter: 1298 loss: 4.04847697e-07
Iter: 1299 loss: 4.04680691e-07
Iter: 1300 loss: 4.05169715e-07
Iter: 1301 loss: 4.04625979e-07
Iter: 1302 loss: 4.04435923e-07
Iter: 1303 loss: 4.07339769e-07
Iter: 1304 loss: 4.04432853e-07
Iter: 1305 loss: 4.04385048e-07
Iter: 1306 loss: 4.04327636e-07
Iter: 1307 loss: 4.04324624e-07
Iter: 1308 loss: 4.04235891e-07
Iter: 1309 loss: 4.05467404e-07
Iter: 1310 loss: 4.04239103e-07
Iter: 1311 loss: 4.04173761e-07
Iter: 1312 loss: 4.04055896e-07
Iter: 1313 loss: 4.05541812e-07
Iter: 1314 loss: 4.04038019e-07
Iter: 1315 loss: 4.03985041e-07
Iter: 1316 loss: 4.03972706e-07
Iter: 1317 loss: 4.03881216e-07
Iter: 1318 loss: 4.03672317e-07
Iter: 1319 loss: 4.05497815e-07
Iter: 1320 loss: 4.0365245e-07
Iter: 1321 loss: 4.03395234e-07
Iter: 1322 loss: 4.0390421e-07
Iter: 1323 loss: 4.03311049e-07
Iter: 1324 loss: 4.03143645e-07
Iter: 1325 loss: 4.03294848e-07
Iter: 1326 loss: 4.0304036e-07
Iter: 1327 loss: 4.02948075e-07
Iter: 1328 loss: 4.02915191e-07
Iter: 1329 loss: 4.02820632e-07
Iter: 1330 loss: 4.02968482e-07
Iter: 1331 loss: 4.02738721e-07
Iter: 1332 loss: 4.02670452e-07
Iter: 1333 loss: 4.02629155e-07
Iter: 1334 loss: 4.02584163e-07
Iter: 1335 loss: 4.02465901e-07
Iter: 1336 loss: 4.02552956e-07
Iter: 1337 loss: 4.02397916e-07
Iter: 1338 loss: 4.02220167e-07
Iter: 1339 loss: 4.03813033e-07
Iter: 1340 loss: 4.02209395e-07
Iter: 1341 loss: 4.0203571e-07
Iter: 1342 loss: 4.02098664e-07
Iter: 1343 loss: 4.01877628e-07
Iter: 1344 loss: 4.01795603e-07
Iter: 1345 loss: 4.0176792e-07
Iter: 1346 loss: 4.01698571e-07
Iter: 1347 loss: 4.01581445e-07
Iter: 1348 loss: 4.01580621e-07
Iter: 1349 loss: 4.01469038e-07
Iter: 1350 loss: 4.012864e-07
Iter: 1351 loss: 4.01302316e-07
Iter: 1352 loss: 4.0121239e-07
Iter: 1353 loss: 4.01202442e-07
Iter: 1354 loss: 4.01081365e-07
Iter: 1355 loss: 4.01021879e-07
Iter: 1356 loss: 4.00972965e-07
Iter: 1357 loss: 4.00853935e-07
Iter: 1358 loss: 4.01016052e-07
Iter: 1359 loss: 4.00796381e-07
Iter: 1360 loss: 4.00693608e-07
Iter: 1361 loss: 4.00690595e-07
Iter: 1362 loss: 4.00597884e-07
Iter: 1363 loss: 4.00454326e-07
Iter: 1364 loss: 4.03545215e-07
Iter: 1365 loss: 4.00461545e-07
Iter: 1366 loss: 4.0033089e-07
Iter: 1367 loss: 4.01064483e-07
Iter: 1368 loss: 4.00302525e-07
Iter: 1369 loss: 4.00190117e-07
Iter: 1370 loss: 4.00246819e-07
Iter: 1371 loss: 4.00104824e-07
Iter: 1372 loss: 3.99942536e-07
Iter: 1373 loss: 4.01998705e-07
Iter: 1374 loss: 3.99945179e-07
Iter: 1375 loss: 3.99863382e-07
Iter: 1376 loss: 3.99736138e-07
Iter: 1377 loss: 3.99740429e-07
Iter: 1378 loss: 3.9958644e-07
Iter: 1379 loss: 4.00355134e-07
Iter: 1380 loss: 3.99578653e-07
Iter: 1381 loss: 3.99412e-07
Iter: 1382 loss: 3.99540227e-07
Iter: 1383 loss: 3.99294322e-07
Iter: 1384 loss: 3.99178447e-07
Iter: 1385 loss: 3.99441291e-07
Iter: 1386 loss: 3.99108671e-07
Iter: 1387 loss: 3.99043273e-07
Iter: 1388 loss: 3.99040829e-07
Iter: 1389 loss: 3.9898066e-07
Iter: 1390 loss: 3.98872601e-07
Iter: 1391 loss: 4.00583076e-07
Iter: 1392 loss: 3.98859441e-07
Iter: 1393 loss: 3.98807799e-07
Iter: 1394 loss: 3.98796e-07
Iter: 1395 loss: 3.98728645e-07
Iter: 1396 loss: 3.98688343e-07
Iter: 1397 loss: 3.98659495e-07
Iter: 1398 loss: 3.98555187e-07
Iter: 1399 loss: 3.98442296e-07
Iter: 1400 loss: 3.98401426e-07
Iter: 1401 loss: 3.98207391e-07
Iter: 1402 loss: 3.98909208e-07
Iter: 1403 loss: 3.98148956e-07
Iter: 1404 loss: 3.97894155e-07
Iter: 1405 loss: 3.97776205e-07
Iter: 1406 loss: 3.97672e-07
Iter: 1407 loss: 3.97687103e-07
Iter: 1408 loss: 3.97544227e-07
Iter: 1409 loss: 3.97442022e-07
Iter: 1410 loss: 3.97441653e-07
Iter: 1411 loss: 3.97337658e-07
Iter: 1412 loss: 3.97234032e-07
Iter: 1413 loss: 3.97492414e-07
Iter: 1414 loss: 3.97189268e-07
Iter: 1415 loss: 3.97070352e-07
Iter: 1416 loss: 3.98078214e-07
Iter: 1417 loss: 3.97069641e-07
Iter: 1418 loss: 3.97007966e-07
Iter: 1419 loss: 3.96960246e-07
Iter: 1420 loss: 3.96952032e-07
Iter: 1421 loss: 3.96774283e-07
Iter: 1422 loss: 3.96840449e-07
Iter: 1423 loss: 3.96664632e-07
Iter: 1424 loss: 3.96510472e-07
Iter: 1425 loss: 3.96637716e-07
Iter: 1426 loss: 3.96407415e-07
Iter: 1427 loss: 3.96329028e-07
Iter: 1428 loss: 3.96310611e-07
Iter: 1429 loss: 3.96213522e-07
Iter: 1430 loss: 3.95936326e-07
Iter: 1431 loss: 3.97620283e-07
Iter: 1432 loss: 3.95878715e-07
Iter: 1433 loss: 3.95616894e-07
Iter: 1434 loss: 3.9769219e-07
Iter: 1435 loss: 3.95587e-07
Iter: 1436 loss: 3.95425928e-07
Iter: 1437 loss: 3.95706365e-07
Iter: 1438 loss: 3.95388781e-07
Iter: 1439 loss: 3.95187669e-07
Iter: 1440 loss: 3.95941726e-07
Iter: 1441 loss: 3.95149499e-07
Iter: 1442 loss: 3.9504269e-07
Iter: 1443 loss: 3.95035443e-07
Iter: 1444 loss: 3.9492619e-07
Iter: 1445 loss: 3.94718455e-07
Iter: 1446 loss: 3.98848044e-07
Iter: 1447 loss: 3.94717944e-07
Iter: 1448 loss: 3.94534652e-07
Iter: 1449 loss: 3.94533402e-07
Iter: 1450 loss: 3.94376883e-07
Iter: 1451 loss: 3.94515666e-07
Iter: 1452 loss: 3.94297871e-07
Iter: 1453 loss: 3.94178e-07
Iter: 1454 loss: 3.94862809e-07
Iter: 1455 loss: 3.94166307e-07
Iter: 1456 loss: 3.94035737e-07
Iter: 1457 loss: 3.93802537e-07
Iter: 1458 loss: 3.99210705e-07
Iter: 1459 loss: 3.93819903e-07
Iter: 1460 loss: 3.93663811e-07
Iter: 1461 loss: 3.94436938e-07
Iter: 1462 loss: 3.93623736e-07
Iter: 1463 loss: 3.93544809e-07
Iter: 1464 loss: 3.93543047e-07
Iter: 1465 loss: 3.93472135e-07
Iter: 1466 loss: 3.93254879e-07
Iter: 1467 loss: 3.94950064e-07
Iter: 1468 loss: 3.9323541e-07
Iter: 1469 loss: 3.930258e-07
Iter: 1470 loss: 3.93555581e-07
Iter: 1471 loss: 3.92956878e-07
Iter: 1472 loss: 3.92689827e-07
Iter: 1473 loss: 3.93062237e-07
Iter: 1474 loss: 3.92566335e-07
Iter: 1475 loss: 3.9238688e-07
Iter: 1476 loss: 3.94034515e-07
Iter: 1477 loss: 3.92358629e-07
Iter: 1478 loss: 3.92219306e-07
Iter: 1479 loss: 3.9235735e-07
Iter: 1480 loss: 3.92142141e-07
Iter: 1481 loss: 3.92036611e-07
Iter: 1482 loss: 3.92031239e-07
Iter: 1483 loss: 3.91912977e-07
Iter: 1484 loss: 3.92053238e-07
Iter: 1485 loss: 3.91848658e-07
Iter: 1486 loss: 3.91731533e-07
Iter: 1487 loss: 3.91585729e-07
Iter: 1488 loss: 3.91569756e-07
Iter: 1489 loss: 3.91301114e-07
Iter: 1490 loss: 3.93454968e-07
Iter: 1491 loss: 3.91266639e-07
Iter: 1492 loss: 3.91164633e-07
Iter: 1493 loss: 3.90932627e-07
Iter: 1494 loss: 3.94267374e-07
Iter: 1495 loss: 3.9091492e-07
Iter: 1496 loss: 3.90799755e-07
Iter: 1497 loss: 3.90761443e-07
Iter: 1498 loss: 3.90644857e-07
Iter: 1499 loss: 3.90554192e-07
Iter: 1500 loss: 3.90519858e-07
Iter: 1501 loss: 3.90402761e-07
Iter: 1502 loss: 3.90353847e-07
Iter: 1503 loss: 3.90285578e-07
Iter: 1504 loss: 3.90198238e-07
Iter: 1505 loss: 3.90154298e-07
Iter: 1506 loss: 3.9010277e-07
Iter: 1507 loss: 3.9003217e-07
Iter: 1508 loss: 3.90032056e-07
Iter: 1509 loss: 3.89875709e-07
Iter: 1510 loss: 3.89851238e-07
Iter: 1511 loss: 3.89746504e-07
Iter: 1512 loss: 3.8951589e-07
Iter: 1513 loss: 3.90037599e-07
Iter: 1514 loss: 3.89446825e-07
Iter: 1515 loss: 3.89225789e-07
Iter: 1516 loss: 3.89968193e-07
Iter: 1517 loss: 3.89180201e-07
Iter: 1518 loss: 3.89040679e-07
Iter: 1519 loss: 3.89038746e-07
Iter: 1520 loss: 3.88922672e-07
Iter: 1521 loss: 3.88953367e-07
Iter: 1522 loss: 3.88842835e-07
Iter: 1523 loss: 3.88752738e-07
Iter: 1524 loss: 3.89723198e-07
Iter: 1525 loss: 3.88755268e-07
Iter: 1526 loss: 3.88671708e-07
Iter: 1527 loss: 3.88535284e-07
Iter: 1528 loss: 3.88531589e-07
Iter: 1529 loss: 3.88414321e-07
Iter: 1530 loss: 3.88768342e-07
Iter: 1531 loss: 3.88383853e-07
Iter: 1532 loss: 3.882746e-07
Iter: 1533 loss: 3.88276703e-07
Iter: 1534 loss: 3.8819357e-07
Iter: 1535 loss: 3.87995783e-07
Iter: 1536 loss: 3.89610506e-07
Iter: 1537 loss: 3.87959e-07
Iter: 1538 loss: 3.87963269e-07
Iter: 1539 loss: 3.87855835e-07
Iter: 1540 loss: 3.87779721e-07
Iter: 1541 loss: 3.87640796e-07
Iter: 1542 loss: 3.90220919e-07
Iter: 1543 loss: 3.87640625e-07
Iter: 1544 loss: 3.87490957e-07
Iter: 1545 loss: 3.87965656e-07
Iter: 1546 loss: 3.87436273e-07
Iter: 1547 loss: 3.87308262e-07
Iter: 1548 loss: 3.87862372e-07
Iter: 1549 loss: 3.87274838e-07
Iter: 1550 loss: 3.87145718e-07
Iter: 1551 loss: 3.87531372e-07
Iter: 1552 loss: 3.87104819e-07
Iter: 1553 loss: 3.86949381e-07
Iter: 1554 loss: 3.87959602e-07
Iter: 1555 loss: 3.86915701e-07
Iter: 1556 loss: 3.86819607e-07
Iter: 1557 loss: 3.86857721e-07
Iter: 1558 loss: 3.86761315e-07
Iter: 1559 loss: 3.86664567e-07
Iter: 1560 loss: 3.87944567e-07
Iter: 1561 loss: 3.86666699e-07
Iter: 1562 loss: 3.86572196e-07
Iter: 1563 loss: 3.86409056e-07
Iter: 1564 loss: 3.86409113e-07
Iter: 1565 loss: 3.86321858e-07
Iter: 1566 loss: 3.87140631e-07
Iter: 1567 loss: 3.863085e-07
Iter: 1568 loss: 3.8620658e-07
Iter: 1569 loss: 3.86809177e-07
Iter: 1570 loss: 3.86198764e-07
Iter: 1571 loss: 3.86138709e-07
Iter: 1572 loss: 3.86002171e-07
Iter: 1573 loss: 3.88864692e-07
Iter: 1574 loss: 3.8600183e-07
Iter: 1575 loss: 3.85913552e-07
Iter: 1576 loss: 3.85901444e-07
Iter: 1577 loss: 3.85846249e-07
Iter: 1578 loss: 3.85677424e-07
Iter: 1579 loss: 3.86567024e-07
Iter: 1580 loss: 3.85632205e-07
Iter: 1581 loss: 3.85403553e-07
Iter: 1582 loss: 3.85773774e-07
Iter: 1583 loss: 3.85311694e-07
Iter: 1584 loss: 3.8514068e-07
Iter: 1585 loss: 3.85338069e-07
Iter: 1586 loss: 3.85049304e-07
Iter: 1587 loss: 3.84979273e-07
Iter: 1588 loss: 3.84944144e-07
Iter: 1589 loss: 3.84885197e-07
Iter: 1590 loss: 3.85070024e-07
Iter: 1591 loss: 3.84874113e-07
Iter: 1592 loss: 3.84819657e-07
Iter: 1593 loss: 3.84789217e-07
Iter: 1594 loss: 3.84762473e-07
Iter: 1595 loss: 3.84667885e-07
Iter: 1596 loss: 3.84939796e-07
Iter: 1597 loss: 3.84635371e-07
Iter: 1598 loss: 3.84541721e-07
Iter: 1599 loss: 3.84526629e-07
Iter: 1600 loss: 3.84472173e-07
Iter: 1601 loss: 3.84350301e-07
Iter: 1602 loss: 3.84794703e-07
Iter: 1603 loss: 3.84343025e-07
Iter: 1604 loss: 3.84151065e-07
Iter: 1605 loss: 3.84081147e-07
Iter: 1606 loss: 3.83985366e-07
Iter: 1607 loss: 3.83828734e-07
Iter: 1608 loss: 3.84490164e-07
Iter: 1609 loss: 3.83787665e-07
Iter: 1610 loss: 3.83688302e-07
Iter: 1611 loss: 3.83696033e-07
Iter: 1612 loss: 3.83635154e-07
Iter: 1613 loss: 3.83505892e-07
Iter: 1614 loss: 3.85118852e-07
Iter: 1615 loss: 3.83523513e-07
Iter: 1616 loss: 3.83415966e-07
Iter: 1617 loss: 3.84080749e-07
Iter: 1618 loss: 3.83398515e-07
Iter: 1619 loss: 3.83307338e-07
Iter: 1620 loss: 3.83407667e-07
Iter: 1621 loss: 3.8326445e-07
Iter: 1622 loss: 3.83175092e-07
Iter: 1623 loss: 3.84648558e-07
Iter: 1624 loss: 3.83163922e-07
Iter: 1625 loss: 3.8309912e-07
Iter: 1626 loss: 3.8306689e-07
Iter: 1627 loss: 3.83036564e-07
Iter: 1628 loss: 3.82918756e-07
Iter: 1629 loss: 3.83340307e-07
Iter: 1630 loss: 3.82889425e-07
Iter: 1631 loss: 3.82725545e-07
Iter: 1632 loss: 3.82613621e-07
Iter: 1633 loss: 3.82573091e-07
Iter: 1634 loss: 3.82408246e-07
Iter: 1635 loss: 3.82816921e-07
Iter: 1636 loss: 3.82360042e-07
Iter: 1637 loss: 3.82249482e-07
Iter: 1638 loss: 3.82674614e-07
Iter: 1639 loss: 3.82209066e-07
Iter: 1640 loss: 3.82063519e-07
Iter: 1641 loss: 3.83485883e-07
Iter: 1642 loss: 3.82054736e-07
Iter: 1643 loss: 3.82014719e-07
Iter: 1644 loss: 3.8193258e-07
Iter: 1645 loss: 3.83043243e-07
Iter: 1646 loss: 3.81921723e-07
Iter: 1647 loss: 3.81792063e-07
Iter: 1648 loss: 3.83036195e-07
Iter: 1649 loss: 3.81798287e-07
Iter: 1650 loss: 3.81713e-07
Iter: 1651 loss: 3.81574552e-07
Iter: 1652 loss: 3.8156827e-07
Iter: 1653 loss: 3.81408427e-07
Iter: 1654 loss: 3.81251255e-07
Iter: 1655 loss: 3.81187817e-07
Iter: 1656 loss: 3.81166302e-07
Iter: 1657 loss: 3.81084931e-07
Iter: 1658 loss: 3.80956976e-07
Iter: 1659 loss: 3.81181508e-07
Iter: 1660 loss: 3.80893027e-07
Iter: 1661 loss: 3.80788e-07
Iter: 1662 loss: 3.80976644e-07
Iter: 1663 loss: 3.80739777e-07
Iter: 1664 loss: 3.80601847e-07
Iter: 1665 loss: 3.81384041e-07
Iter: 1666 loss: 3.805944e-07
Iter: 1667 loss: 3.80526075e-07
Iter: 1668 loss: 3.80488416e-07
Iter: 1669 loss: 3.80453514e-07
Iter: 1670 loss: 3.8034463e-07
Iter: 1671 loss: 3.80236543e-07
Iter: 1672 loss: 3.8021625e-07
Iter: 1673 loss: 3.8006e-07
Iter: 1674 loss: 3.80058367e-07
Iter: 1675 loss: 3.79983192e-07
Iter: 1676 loss: 3.81235452e-07
Iter: 1677 loss: 3.79988649e-07
Iter: 1678 loss: 3.79941412e-07
Iter: 1679 loss: 3.79775599e-07
Iter: 1680 loss: 3.80872365e-07
Iter: 1681 loss: 3.79777873e-07
Iter: 1682 loss: 3.79718273e-07
Iter: 1683 loss: 3.79713867e-07
Iter: 1684 loss: 3.79623657e-07
Iter: 1685 loss: 3.79548425e-07
Iter: 1686 loss: 3.79538619e-07
Iter: 1687 loss: 3.79434482e-07
Iter: 1688 loss: 3.79392617e-07
Iter: 1689 loss: 3.79331198e-07
Iter: 1690 loss: 3.79178857e-07
Iter: 1691 loss: 3.79141568e-07
Iter: 1692 loss: 3.79080689e-07
Iter: 1693 loss: 3.78927723e-07
Iter: 1694 loss: 3.78885829e-07
Iter: 1695 loss: 3.78797438e-07
Iter: 1696 loss: 3.78739571e-07
Iter: 1697 loss: 3.78701372e-07
Iter: 1698 loss: 3.78652487e-07
Iter: 1699 loss: 3.78643335e-07
Iter: 1700 loss: 3.78599225e-07
Iter: 1701 loss: 3.78498527e-07
Iter: 1702 loss: 3.80116e-07
Iter: 1703 loss: 3.78497361e-07
Iter: 1704 loss: 3.78400273e-07
Iter: 1705 loss: 3.78856555e-07
Iter: 1706 loss: 3.78373329e-07
Iter: 1707 loss: 3.78307021e-07
Iter: 1708 loss: 3.78777884e-07
Iter: 1709 loss: 3.7830273e-07
Iter: 1710 loss: 3.78204049e-07
Iter: 1711 loss: 3.78147632e-07
Iter: 1712 loss: 3.78114805e-07
Iter: 1713 loss: 3.77986964e-07
Iter: 1714 loss: 3.77916962e-07
Iter: 1715 loss: 3.77862534e-07
Iter: 1716 loss: 3.77737422e-07
Iter: 1717 loss: 3.77737706e-07
Iter: 1718 loss: 3.77621802e-07
Iter: 1719 loss: 3.77676855e-07
Iter: 1720 loss: 3.77516045e-07
Iter: 1721 loss: 3.77436606e-07
Iter: 1722 loss: 3.77704907e-07
Iter: 1723 loss: 3.77414494e-07
Iter: 1724 loss: 3.77324341e-07
Iter: 1725 loss: 3.77182573e-07
Iter: 1726 loss: 3.77186041e-07
Iter: 1727 loss: 3.7705874e-07
Iter: 1728 loss: 3.77061554e-07
Iter: 1729 loss: 3.76978846e-07
Iter: 1730 loss: 3.78134416e-07
Iter: 1731 loss: 3.76980239e-07
Iter: 1732 loss: 3.76944e-07
Iter: 1733 loss: 3.76811215e-07
Iter: 1734 loss: 3.77546769e-07
Iter: 1735 loss: 3.7676881e-07
Iter: 1736 loss: 3.76670528e-07
Iter: 1737 loss: 3.76652309e-07
Iter: 1738 loss: 3.76568977e-07
Iter: 1739 loss: 3.76461827e-07
Iter: 1740 loss: 3.76467057e-07
Iter: 1741 loss: 3.76335436e-07
Iter: 1742 loss: 3.76264296e-07
Iter: 1743 loss: 3.76199665e-07
Iter: 1744 loss: 3.7623434e-07
Iter: 1745 loss: 3.76150155e-07
Iter: 1746 loss: 3.76065088e-07
Iter: 1747 loss: 3.75976356e-07
Iter: 1748 loss: 3.75968284e-07
Iter: 1749 loss: 3.75841751e-07
Iter: 1750 loss: 3.75652263e-07
Iter: 1751 loss: 3.75634386e-07
Iter: 1752 loss: 3.75572824e-07
Iter: 1753 loss: 3.75539258e-07
Iter: 1754 loss: 3.75421649e-07
Iter: 1755 loss: 3.75379358e-07
Iter: 1756 loss: 3.75337549e-07
Iter: 1757 loss: 3.75213432e-07
Iter: 1758 loss: 3.75276471e-07
Iter: 1759 loss: 3.75127513e-07
Iter: 1760 loss: 3.75015588e-07
Iter: 1761 loss: 3.7526064e-07
Iter: 1762 loss: 3.74987337e-07
Iter: 1763 loss: 3.74929868e-07
Iter: 1764 loss: 3.74921427e-07
Iter: 1765 loss: 3.74846877e-07
Iter: 1766 loss: 3.74840539e-07
Iter: 1767 loss: 3.74781052e-07
Iter: 1768 loss: 3.74706815e-07
Iter: 1769 loss: 3.74639228e-07
Iter: 1770 loss: 3.74619759e-07
Iter: 1771 loss: 3.74437036e-07
Iter: 1772 loss: 3.75560433e-07
Iter: 1773 loss: 3.74416061e-07
Iter: 1774 loss: 3.74300043e-07
Iter: 1775 loss: 3.74272418e-07
Iter: 1776 loss: 3.74200283e-07
Iter: 1777 loss: 3.74079e-07
Iter: 1778 loss: 3.74072698e-07
Iter: 1779 loss: 3.73966884e-07
Iter: 1780 loss: 3.73897223e-07
Iter: 1781 loss: 3.73862775e-07
Iter: 1782 loss: 3.73824946e-07
Iter: 1783 loss: 3.73730472e-07
Iter: 1784 loss: 3.7553059e-07
Iter: 1785 loss: 3.73727232e-07
Iter: 1786 loss: 3.73637533e-07
Iter: 1787 loss: 3.736709e-07
Iter: 1788 loss: 3.73567644e-07
Iter: 1789 loss: 3.73511227e-07
Iter: 1790 loss: 3.73486e-07
Iter: 1791 loss: 3.73441225e-07
Iter: 1792 loss: 3.7329167e-07
Iter: 1793 loss: 3.73990076e-07
Iter: 1794 loss: 3.73243552e-07
Iter: 1795 loss: 3.73002536e-07
Iter: 1796 loss: 3.74664637e-07
Iter: 1797 loss: 3.72999295e-07
Iter: 1798 loss: 3.72789145e-07
Iter: 1799 loss: 3.72774764e-07
Iter: 1800 loss: 3.72705784e-07
Iter: 1801 loss: 3.72528746e-07
Iter: 1802 loss: 3.76344275e-07
Iter: 1803 loss: 3.72521015e-07
Iter: 1804 loss: 3.72376576e-07
Iter: 1805 loss: 3.72379048e-07
Iter: 1806 loss: 3.72249474e-07
Iter: 1807 loss: 3.72325786e-07
Iter: 1808 loss: 3.72158e-07
Iter: 1809 loss: 3.72083321e-07
Iter: 1810 loss: 3.72118848e-07
Iter: 1811 loss: 3.72020594e-07
Iter: 1812 loss: 3.71921828e-07
Iter: 1813 loss: 3.7234571e-07
Iter: 1814 loss: 3.71894487e-07
Iter: 1815 loss: 3.71748229e-07
Iter: 1816 loss: 3.72251407e-07
Iter: 1817 loss: 3.71745557e-07
Iter: 1818 loss: 3.71633746e-07
Iter: 1819 loss: 3.71450142e-07
Iter: 1820 loss: 3.74097112e-07
Iter: 1821 loss: 3.71441047e-07
Iter: 1822 loss: 3.71238826e-07
Iter: 1823 loss: 3.73804369e-07
Iter: 1824 loss: 3.71243033e-07
Iter: 1825 loss: 3.71059571e-07
Iter: 1826 loss: 3.71925978e-07
Iter: 1827 loss: 3.71025294e-07
Iter: 1828 loss: 3.70949095e-07
Iter: 1829 loss: 3.70736956e-07
Iter: 1830 loss: 3.72972465e-07
Iter: 1831 loss: 3.70714361e-07
Iter: 1832 loss: 3.70618721e-07
Iter: 1833 loss: 3.70585525e-07
Iter: 1834 loss: 3.70482923e-07
Iter: 1835 loss: 3.70950772e-07
Iter: 1836 loss: 3.70467944e-07
Iter: 1837 loss: 3.7040175e-07
Iter: 1838 loss: 3.70262541e-07
Iter: 1839 loss: 3.72234325e-07
Iter: 1840 loss: 3.70259926e-07
Iter: 1841 loss: 3.70140526e-07
Iter: 1842 loss: 3.7013632e-07
Iter: 1843 loss: 3.70053158e-07
Iter: 1844 loss: 3.69957831e-07
Iter: 1845 loss: 3.69947799e-07
Iter: 1846 loss: 3.69838688e-07
Iter: 1847 loss: 3.70037384e-07
Iter: 1848 loss: 3.69786932e-07
Iter: 1849 loss: 3.6969675e-07
Iter: 1850 loss: 3.7094668e-07
Iter: 1851 loss: 3.69701155e-07
Iter: 1852 loss: 3.69615378e-07
Iter: 1853 loss: 3.69722e-07
Iter: 1854 loss: 3.69575616e-07
Iter: 1855 loss: 3.69494046e-07
Iter: 1856 loss: 3.69286624e-07
Iter: 1857 loss: 3.71434311e-07
Iter: 1858 loss: 3.69272243e-07
Iter: 1859 loss: 3.69273721e-07
Iter: 1860 loss: 3.69181549e-07
Iter: 1861 loss: 3.690879e-07
Iter: 1862 loss: 3.68952897e-07
Iter: 1863 loss: 3.68939027e-07
Iter: 1864 loss: 3.68756105e-07
Iter: 1865 loss: 3.68570198e-07
Iter: 1866 loss: 3.68523814e-07
Iter: 1867 loss: 3.68708982e-07
Iter: 1868 loss: 3.6840683e-07
Iter: 1869 loss: 3.68364908e-07
Iter: 1870 loss: 3.68277682e-07
Iter: 1871 loss: 3.68283224e-07
Iter: 1872 loss: 3.68213648e-07
Iter: 1873 loss: 3.68599956e-07
Iter: 1874 loss: 3.68203018e-07
Iter: 1875 loss: 3.68113376e-07
Iter: 1876 loss: 3.68034364e-07
Iter: 1877 loss: 3.68016e-07
Iter: 1878 loss: 3.67942079e-07
Iter: 1879 loss: 3.67944892e-07
Iter: 1880 loss: 3.67885264e-07
Iter: 1881 loss: 3.67726841e-07
Iter: 1882 loss: 3.67549973e-07
Iter: 1883 loss: 3.67538121e-07
Iter: 1884 loss: 3.67515099e-07
Iter: 1885 loss: 3.67417954e-07
Iter: 1886 loss: 3.67332348e-07
Iter: 1887 loss: 3.67229632e-07
Iter: 1888 loss: 3.67203313e-07
Iter: 1889 loss: 3.67054497e-07
Iter: 1890 loss: 3.67267859e-07
Iter: 1891 loss: 3.67003793e-07
Iter: 1892 loss: 3.66923899e-07
Iter: 1893 loss: 3.66913412e-07
Iter: 1894 loss: 3.66847758e-07
Iter: 1895 loss: 3.66747173e-07
Iter: 1896 loss: 3.68622864e-07
Iter: 1897 loss: 3.6674993e-07
Iter: 1898 loss: 3.66625898e-07
Iter: 1899 loss: 3.66799384e-07
Iter: 1900 loss: 3.66578831e-07
Iter: 1901 loss: 3.66570134e-07
Iter: 1902 loss: 3.66537677e-07
Iter: 1903 loss: 3.66487313e-07
Iter: 1904 loss: 3.66342761e-07
Iter: 1905 loss: 3.66641359e-07
Iter: 1906 loss: 3.66246582e-07
Iter: 1907 loss: 3.66197298e-07
Iter: 1908 loss: 3.66147901e-07
Iter: 1909 loss: 3.66053712e-07
Iter: 1910 loss: 3.65961029e-07
Iter: 1911 loss: 3.65928599e-07
Iter: 1912 loss: 3.65806045e-07
Iter: 1913 loss: 3.65707251e-07
Iter: 1914 loss: 3.65671411e-07
Iter: 1915 loss: 3.65565086e-07
Iter: 1916 loss: 3.67346644e-07
Iter: 1917 loss: 3.6556267e-07
Iter: 1918 loss: 3.65473596e-07
Iter: 1919 loss: 3.66282507e-07
Iter: 1920 loss: 3.65457083e-07
Iter: 1921 loss: 3.65358801e-07
Iter: 1922 loss: 3.6516991e-07
Iter: 1923 loss: 3.68183521e-07
Iter: 1924 loss: 3.65158883e-07
Iter: 1925 loss: 3.64996538e-07
Iter: 1926 loss: 3.66480748e-07
Iter: 1927 loss: 3.6500029e-07
Iter: 1928 loss: 3.64898483e-07
Iter: 1929 loss: 3.66185816e-07
Iter: 1930 loss: 3.64910193e-07
Iter: 1931 loss: 3.64787951e-07
Iter: 1932 loss: 3.64584309e-07
Iter: 1933 loss: 3.67240375e-07
Iter: 1934 loss: 3.64553358e-07
Iter: 1935 loss: 3.64440581e-07
Iter: 1936 loss: 3.65409647e-07
Iter: 1937 loss: 3.64420515e-07
Iter: 1938 loss: 3.643421e-07
Iter: 1939 loss: 3.65579e-07
Iter: 1940 loss: 3.64327548e-07
Iter: 1941 loss: 3.64285768e-07
Iter: 1942 loss: 3.64121661e-07
Iter: 1943 loss: 3.66147901e-07
Iter: 1944 loss: 3.64116545e-07
Iter: 1945 loss: 3.64038783e-07
Iter: 1946 loss: 3.6402858e-07
Iter: 1947 loss: 3.63935897e-07
Iter: 1948 loss: 3.63754623e-07
Iter: 1949 loss: 3.6586917e-07
Iter: 1950 loss: 3.63722762e-07
Iter: 1951 loss: 3.635258e-07
Iter: 1952 loss: 3.6429276e-07
Iter: 1953 loss: 3.63453466e-07
Iter: 1954 loss: 3.63298739e-07
Iter: 1955 loss: 3.63446077e-07
Iter: 1956 loss: 3.63226093e-07
Iter: 1957 loss: 3.6322291e-07
Iter: 1958 loss: 3.6314168e-07
Iter: 1959 loss: 3.63096802e-07
Iter: 1960 loss: 3.63046922e-07
Iter: 1961 loss: 3.63031347e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8
+ date
Mon Oct 26 11:43:25 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi0.8_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb40620d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb40b4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb40b4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb40b40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb4111268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa062b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa05ed158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0597840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0597c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa05ed6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa04e5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0503730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0503840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0526bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa048e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0482bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0482620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0475400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa042eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa042e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa03d6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa042e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa035cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa03216a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa03217b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa031c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa02e9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa02ab620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa02a0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa029d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0276ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa023c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa023e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa01d7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa01f7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa01b0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.26299152e-06
Iter: 2 loss: 4.93808511e-06
Iter: 3 loss: 2.49611312e-05
Iter: 4 loss: 4.93740208e-06
Iter: 5 loss: 4.31690478e-06
Iter: 6 loss: 6.34551e-06
Iter: 7 loss: 4.1437911e-06
Iter: 8 loss: 3.91585309e-06
Iter: 9 loss: 4.00650288e-06
Iter: 10 loss: 3.75836316e-06
Iter: 11 loss: 3.4731188e-06
Iter: 12 loss: 6.15882482e-06
Iter: 13 loss: 3.4616146e-06
Iter: 14 loss: 3.3121396e-06
Iter: 15 loss: 3.38603286e-06
Iter: 16 loss: 3.21223342e-06
Iter: 17 loss: 3.14040062e-06
Iter: 18 loss: 3.14026283e-06
Iter: 19 loss: 3.07173377e-06
Iter: 20 loss: 3.0741287e-06
Iter: 21 loss: 3.01745763e-06
Iter: 22 loss: 2.92263212e-06
Iter: 23 loss: 2.85047713e-06
Iter: 24 loss: 2.81969619e-06
Iter: 25 loss: 2.74343734e-06
Iter: 26 loss: 2.73125784e-06
Iter: 27 loss: 2.66745519e-06
Iter: 28 loss: 2.53327971e-06
Iter: 29 loss: 4.76064815e-06
Iter: 30 loss: 2.52967766e-06
Iter: 31 loss: 2.40597456e-06
Iter: 32 loss: 2.66611414e-06
Iter: 33 loss: 2.35704238e-06
Iter: 34 loss: 2.27393571e-06
Iter: 35 loss: 2.83603458e-06
Iter: 36 loss: 2.26571865e-06
Iter: 37 loss: 2.18993728e-06
Iter: 38 loss: 2.25185431e-06
Iter: 39 loss: 2.14461261e-06
Iter: 40 loss: 2.07267021e-06
Iter: 41 loss: 2.25693475e-06
Iter: 42 loss: 2.04787216e-06
Iter: 43 loss: 2.03146442e-06
Iter: 44 loss: 2.01000648e-06
Iter: 45 loss: 1.97572581e-06
Iter: 46 loss: 1.91774393e-06
Iter: 47 loss: 1.91764275e-06
Iter: 48 loss: 1.8658036e-06
Iter: 49 loss: 1.97883946e-06
Iter: 50 loss: 1.8457855e-06
Iter: 51 loss: 1.7848688e-06
Iter: 52 loss: 2.40543409e-06
Iter: 53 loss: 1.7830738e-06
Iter: 54 loss: 1.75290052e-06
Iter: 55 loss: 1.75770822e-06
Iter: 56 loss: 1.7302425e-06
Iter: 57 loss: 1.70733824e-06
Iter: 58 loss: 1.70738599e-06
Iter: 59 loss: 1.68375e-06
Iter: 60 loss: 1.63974391e-06
Iter: 61 loss: 2.62728213e-06
Iter: 62 loss: 1.63965296e-06
Iter: 63 loss: 1.60647733e-06
Iter: 64 loss: 1.76403148e-06
Iter: 65 loss: 1.60045238e-06
Iter: 66 loss: 1.55374983e-06
Iter: 67 loss: 1.63889285e-06
Iter: 68 loss: 1.53354858e-06
Iter: 69 loss: 1.50025551e-06
Iter: 70 loss: 1.50261576e-06
Iter: 71 loss: 1.47433343e-06
Iter: 72 loss: 1.42696877e-06
Iter: 73 loss: 1.45633533e-06
Iter: 74 loss: 1.39663962e-06
Iter: 75 loss: 1.35157552e-06
Iter: 76 loss: 1.76527692e-06
Iter: 77 loss: 1.34961385e-06
Iter: 78 loss: 1.32708794e-06
Iter: 79 loss: 1.46578509e-06
Iter: 80 loss: 1.32438663e-06
Iter: 81 loss: 1.30439832e-06
Iter: 82 loss: 1.5229416e-06
Iter: 83 loss: 1.30398848e-06
Iter: 84 loss: 1.29283467e-06
Iter: 85 loss: 1.27223041e-06
Iter: 86 loss: 1.74084585e-06
Iter: 87 loss: 1.27215799e-06
Iter: 88 loss: 1.25742918e-06
Iter: 89 loss: 1.44894409e-06
Iter: 90 loss: 1.25731094e-06
Iter: 91 loss: 1.23946563e-06
Iter: 92 loss: 1.23186919e-06
Iter: 93 loss: 1.22257427e-06
Iter: 94 loss: 1.20388677e-06
Iter: 95 loss: 1.24639723e-06
Iter: 96 loss: 1.19685751e-06
Iter: 97 loss: 1.17421303e-06
Iter: 98 loss: 1.36896074e-06
Iter: 99 loss: 1.17297509e-06
Iter: 100 loss: 1.16472256e-06
Iter: 101 loss: 1.1416505e-06
Iter: 102 loss: 1.26482803e-06
Iter: 103 loss: 1.13443218e-06
Iter: 104 loss: 1.1340851e-06
Iter: 105 loss: 1.11913664e-06
Iter: 106 loss: 1.113498e-06
Iter: 107 loss: 1.09980215e-06
Iter: 108 loss: 1.24580356e-06
Iter: 109 loss: 1.0982792e-06
Iter: 110 loss: 1.081699e-06
Iter: 111 loss: 1.12195016e-06
Iter: 112 loss: 1.07574533e-06
Iter: 113 loss: 1.0609325e-06
Iter: 114 loss: 1.11651434e-06
Iter: 115 loss: 1.05734512e-06
Iter: 116 loss: 1.04214189e-06
Iter: 117 loss: 1.07431515e-06
Iter: 118 loss: 1.03617458e-06
Iter: 119 loss: 1.02852425e-06
Iter: 120 loss: 1.02640649e-06
Iter: 121 loss: 1.02034528e-06
Iter: 122 loss: 1.01115268e-06
Iter: 123 loss: 1.01096248e-06
Iter: 124 loss: 9.99370513e-07
Iter: 125 loss: 1.00794296e-06
Iter: 126 loss: 9.92266905e-07
Iter: 127 loss: 9.88950887e-07
Iter: 128 loss: 9.85863721e-07
Iter: 129 loss: 9.81966e-07
Iter: 130 loss: 9.72448333e-07
Iter: 131 loss: 1.07081428e-06
Iter: 132 loss: 9.71333e-07
Iter: 133 loss: 9.69528855e-07
Iter: 134 loss: 9.66643938e-07
Iter: 135 loss: 9.62901595e-07
Iter: 136 loss: 9.54359166e-07
Iter: 137 loss: 1.06967173e-06
Iter: 138 loss: 9.53881681e-07
Iter: 139 loss: 9.44825274e-07
Iter: 140 loss: 9.73932856e-07
Iter: 141 loss: 9.422223e-07
Iter: 142 loss: 9.30986971e-07
Iter: 143 loss: 1.00306511e-06
Iter: 144 loss: 9.29733233e-07
Iter: 145 loss: 9.21323249e-07
Iter: 146 loss: 9.12947485e-07
Iter: 147 loss: 9.11187954e-07
Iter: 148 loss: 9.01338581e-07
Iter: 149 loss: 8.91472666e-07
Iter: 150 loss: 8.89474336e-07
Iter: 151 loss: 8.77202467e-07
Iter: 152 loss: 1.05987897e-06
Iter: 153 loss: 8.77217872e-07
Iter: 154 loss: 8.71032967e-07
Iter: 155 loss: 9.06453806e-07
Iter: 156 loss: 8.70231474e-07
Iter: 157 loss: 8.62175114e-07
Iter: 158 loss: 8.95090523e-07
Iter: 159 loss: 8.60427349e-07
Iter: 160 loss: 8.55963e-07
Iter: 161 loss: 8.54612267e-07
Iter: 162 loss: 8.519944e-07
Iter: 163 loss: 8.46203648e-07
Iter: 164 loss: 8.49831508e-07
Iter: 165 loss: 8.42527e-07
Iter: 166 loss: 8.34624529e-07
Iter: 167 loss: 9.37557331e-07
Iter: 168 loss: 8.34591674e-07
Iter: 169 loss: 8.30405327e-07
Iter: 170 loss: 8.23641585e-07
Iter: 171 loss: 8.2359054e-07
Iter: 172 loss: 8.18562057e-07
Iter: 173 loss: 8.18139483e-07
Iter: 174 loss: 8.14354621e-07
Iter: 175 loss: 8.07948e-07
Iter: 176 loss: 8.07944218e-07
Iter: 177 loss: 8.01004035e-07
Iter: 178 loss: 8.38705e-07
Iter: 179 loss: 8.00003875e-07
Iter: 180 loss: 7.964926e-07
Iter: 181 loss: 7.96399377e-07
Iter: 182 loss: 7.9424359e-07
Iter: 183 loss: 7.89371541e-07
Iter: 184 loss: 8.54531777e-07
Iter: 185 loss: 7.89040257e-07
Iter: 186 loss: 7.83425776e-07
Iter: 187 loss: 8.01126475e-07
Iter: 188 loss: 7.81809945e-07
Iter: 189 loss: 7.76471893e-07
Iter: 190 loss: 7.79063214e-07
Iter: 191 loss: 7.72886096e-07
Iter: 192 loss: 7.69489361e-07
Iter: 193 loss: 7.69020744e-07
Iter: 194 loss: 7.64403353e-07
Iter: 195 loss: 7.60591604e-07
Iter: 196 loss: 7.59213094e-07
Iter: 197 loss: 7.53292113e-07
Iter: 198 loss: 7.48132265e-07
Iter: 199 loss: 7.46514957e-07
Iter: 200 loss: 7.47265915e-07
Iter: 201 loss: 7.4398497e-07
Iter: 202 loss: 7.41614883e-07
Iter: 203 loss: 7.3950946e-07
Iter: 204 loss: 7.38901292e-07
Iter: 205 loss: 7.35647e-07
Iter: 206 loss: 7.46172816e-07
Iter: 207 loss: 7.34727394e-07
Iter: 208 loss: 7.31899945e-07
Iter: 209 loss: 7.64805804e-07
Iter: 210 loss: 7.31854811e-07
Iter: 211 loss: 7.3006828e-07
Iter: 212 loss: 7.24787697e-07
Iter: 213 loss: 7.43222358e-07
Iter: 214 loss: 7.22353604e-07
Iter: 215 loss: 7.2175618e-07
Iter: 216 loss: 7.18892636e-07
Iter: 217 loss: 7.16133e-07
Iter: 218 loss: 7.1272251e-07
Iter: 219 loss: 7.12442557e-07
Iter: 220 loss: 7.08423727e-07
Iter: 221 loss: 7.08422533e-07
Iter: 222 loss: 7.05264597e-07
Iter: 223 loss: 7.0122735e-07
Iter: 224 loss: 7.52172866e-07
Iter: 225 loss: 7.01185741e-07
Iter: 226 loss: 6.98632107e-07
Iter: 227 loss: 6.99124143e-07
Iter: 228 loss: 6.96735128e-07
Iter: 229 loss: 6.93715606e-07
Iter: 230 loss: 6.93668483e-07
Iter: 231 loss: 6.92021047e-07
Iter: 232 loss: 6.88969578e-07
Iter: 233 loss: 7.5761011e-07
Iter: 234 loss: 6.88986461e-07
Iter: 235 loss: 6.85454893e-07
Iter: 236 loss: 6.92753702e-07
Iter: 237 loss: 6.84024428e-07
Iter: 238 loss: 6.79706432e-07
Iter: 239 loss: 7.23104336e-07
Iter: 240 loss: 6.79591722e-07
Iter: 241 loss: 6.77034791e-07
Iter: 242 loss: 6.74278567e-07
Iter: 243 loss: 6.73861e-07
Iter: 244 loss: 6.72902161e-07
Iter: 245 loss: 6.72085889e-07
Iter: 246 loss: 6.71022633e-07
Iter: 247 loss: 6.67709912e-07
Iter: 248 loss: 6.70525594e-07
Iter: 249 loss: 6.64920094e-07
Iter: 250 loss: 6.65259506e-07
Iter: 251 loss: 6.62558e-07
Iter: 252 loss: 6.60722606e-07
Iter: 253 loss: 6.59735804e-07
Iter: 254 loss: 6.58906117e-07
Iter: 255 loss: 6.56413e-07
Iter: 256 loss: 6.55298663e-07
Iter: 257 loss: 6.54033784e-07
Iter: 258 loss: 6.50782738e-07
Iter: 259 loss: 6.54125699e-07
Iter: 260 loss: 6.48981768e-07
Iter: 261 loss: 6.44848569e-07
Iter: 262 loss: 6.69708527e-07
Iter: 263 loss: 6.44344482e-07
Iter: 264 loss: 6.43269686e-07
Iter: 265 loss: 6.42919645e-07
Iter: 266 loss: 6.41734459e-07
Iter: 267 loss: 6.43193687e-07
Iter: 268 loss: 6.41094402e-07
Iter: 269 loss: 6.39752272e-07
Iter: 270 loss: 6.36521463e-07
Iter: 271 loss: 6.73218381e-07
Iter: 272 loss: 6.36195523e-07
Iter: 273 loss: 6.34267451e-07
Iter: 274 loss: 6.34019159e-07
Iter: 275 loss: 6.31698754e-07
Iter: 276 loss: 6.32928277e-07
Iter: 277 loss: 6.30199565e-07
Iter: 278 loss: 6.27757686e-07
Iter: 279 loss: 6.29250223e-07
Iter: 280 loss: 6.26142764e-07
Iter: 281 loss: 6.23762446e-07
Iter: 282 loss: 6.23748e-07
Iter: 283 loss: 6.22383936e-07
Iter: 284 loss: 6.19341108e-07
Iter: 285 loss: 6.61775289e-07
Iter: 286 loss: 6.1919684e-07
Iter: 287 loss: 6.17903879e-07
Iter: 288 loss: 6.17596e-07
Iter: 289 loss: 6.15998374e-07
Iter: 290 loss: 6.14317628e-07
Iter: 291 loss: 6.14003739e-07
Iter: 292 loss: 6.12193e-07
Iter: 293 loss: 6.10792085e-07
Iter: 294 loss: 6.10203813e-07
Iter: 295 loss: 6.06842491e-07
Iter: 296 loss: 6.16615125e-07
Iter: 297 loss: 6.05758032e-07
Iter: 298 loss: 6.02921205e-07
Iter: 299 loss: 6.17786384e-07
Iter: 300 loss: 6.02474415e-07
Iter: 301 loss: 6.00142414e-07
Iter: 302 loss: 6.00149065e-07
Iter: 303 loss: 5.98831264e-07
Iter: 304 loss: 5.96720724e-07
Iter: 305 loss: 5.96692303e-07
Iter: 306 loss: 5.95598522e-07
Iter: 307 loss: 6.11197379e-07
Iter: 308 loss: 5.9559369e-07
Iter: 309 loss: 5.94303174e-07
Iter: 310 loss: 5.94734558e-07
Iter: 311 loss: 5.93384e-07
Iter: 312 loss: 5.91855439e-07
Iter: 313 loss: 5.95582833e-07
Iter: 314 loss: 5.91314915e-07
Iter: 315 loss: 5.90036393e-07
Iter: 316 loss: 6.0233765e-07
Iter: 317 loss: 5.89983529e-07
Iter: 318 loss: 5.88956595e-07
Iter: 319 loss: 5.86515853e-07
Iter: 320 loss: 6.1527885e-07
Iter: 321 loss: 5.86324688e-07
Iter: 322 loss: 5.83458814e-07
Iter: 323 loss: 6.08163873e-07
Iter: 324 loss: 5.83326e-07
Iter: 325 loss: 5.80431788e-07
Iter: 326 loss: 5.88707962e-07
Iter: 327 loss: 5.79535879e-07
Iter: 328 loss: 5.77782316e-07
Iter: 329 loss: 5.7687879e-07
Iter: 330 loss: 5.76043476e-07
Iter: 331 loss: 5.73547254e-07
Iter: 332 loss: 5.76770447e-07
Iter: 333 loss: 5.72256909e-07
Iter: 334 loss: 5.70397901e-07
Iter: 335 loss: 5.8312844e-07
Iter: 336 loss: 5.70185819e-07
Iter: 337 loss: 5.69678946e-07
Iter: 338 loss: 5.69416898e-07
Iter: 339 loss: 5.68698965e-07
Iter: 340 loss: 5.67049597e-07
Iter: 341 loss: 5.85055659e-07
Iter: 342 loss: 5.66883159e-07
Iter: 343 loss: 5.65201503e-07
Iter: 344 loss: 5.69707936e-07
Iter: 345 loss: 5.64662173e-07
Iter: 346 loss: 5.63205504e-07
Iter: 347 loss: 5.63202946e-07
Iter: 348 loss: 5.61897423e-07
Iter: 349 loss: 5.59323098e-07
Iter: 350 loss: 6.10615928e-07
Iter: 351 loss: 5.59306045e-07
Iter: 352 loss: 5.5832777e-07
Iter: 353 loss: 5.58052932e-07
Iter: 354 loss: 5.56913733e-07
Iter: 355 loss: 5.54677229e-07
Iter: 356 loss: 5.97501469e-07
Iter: 357 loss: 5.54634653e-07
Iter: 358 loss: 5.53130803e-07
Iter: 359 loss: 5.73692319e-07
Iter: 360 loss: 5.5310727e-07
Iter: 361 loss: 5.52067831e-07
Iter: 362 loss: 5.59453838e-07
Iter: 363 loss: 5.51961364e-07
Iter: 364 loss: 5.51000653e-07
Iter: 365 loss: 5.49505671e-07
Iter: 366 loss: 5.49514766e-07
Iter: 367 loss: 5.47885065e-07
Iter: 368 loss: 5.50636742e-07
Iter: 369 loss: 5.47159516e-07
Iter: 370 loss: 5.45076887e-07
Iter: 371 loss: 5.482338e-07
Iter: 372 loss: 5.4409395e-07
Iter: 373 loss: 5.4374766e-07
Iter: 374 loss: 5.43190311e-07
Iter: 375 loss: 5.42329531e-07
Iter: 376 loss: 5.41522354e-07
Iter: 377 loss: 5.41318627e-07
Iter: 378 loss: 5.40174824e-07
Iter: 379 loss: 5.38982761e-07
Iter: 380 loss: 5.38747429e-07
Iter: 381 loss: 5.39394478e-07
Iter: 382 loss: 5.38184224e-07
Iter: 383 loss: 5.3772095e-07
Iter: 384 loss: 5.36773882e-07
Iter: 385 loss: 5.52971471e-07
Iter: 386 loss: 5.36750235e-07
Iter: 387 loss: 5.35759341e-07
Iter: 388 loss: 5.41357394e-07
Iter: 389 loss: 5.35627862e-07
Iter: 390 loss: 5.34296532e-07
Iter: 391 loss: 5.35056586e-07
Iter: 392 loss: 5.33453317e-07
Iter: 393 loss: 5.32225044e-07
Iter: 394 loss: 5.34374408e-07
Iter: 395 loss: 5.31692478e-07
Iter: 396 loss: 5.3047529e-07
Iter: 397 loss: 5.44043871e-07
Iter: 398 loss: 5.30442435e-07
Iter: 399 loss: 5.29608428e-07
Iter: 400 loss: 5.27706277e-07
Iter: 401 loss: 5.54535e-07
Iter: 402 loss: 5.27590373e-07
Iter: 403 loss: 5.26102895e-07
Iter: 404 loss: 5.41293048e-07
Iter: 405 loss: 5.26065264e-07
Iter: 406 loss: 5.25035546e-07
Iter: 407 loss: 5.25894336e-07
Iter: 408 loss: 5.24402765e-07
Iter: 409 loss: 5.23267431e-07
Iter: 410 loss: 5.25236942e-07
Iter: 411 loss: 5.22767266e-07
Iter: 412 loss: 5.22020514e-07
Iter: 413 loss: 5.21887046e-07
Iter: 414 loss: 5.211038e-07
Iter: 415 loss: 5.19567e-07
Iter: 416 loss: 5.5101907e-07
Iter: 417 loss: 5.19552316e-07
Iter: 418 loss: 5.18385832e-07
Iter: 419 loss: 5.21273819e-07
Iter: 420 loss: 5.17915453e-07
Iter: 421 loss: 5.16500677e-07
Iter: 422 loss: 5.20043784e-07
Iter: 423 loss: 5.16024784e-07
Iter: 424 loss: 5.14462613e-07
Iter: 425 loss: 5.3450924e-07
Iter: 426 loss: 5.14443798e-07
Iter: 427 loss: 5.14064425e-07
Iter: 428 loss: 5.13288342e-07
Iter: 429 loss: 5.29380088e-07
Iter: 430 loss: 5.13279474e-07
Iter: 431 loss: 5.12512372e-07
Iter: 432 loss: 5.12503561e-07
Iter: 433 loss: 5.11970597e-07
Iter: 434 loss: 5.10763414e-07
Iter: 435 loss: 5.29585e-07
Iter: 436 loss: 5.10725101e-07
Iter: 437 loss: 5.09660595e-07
Iter: 438 loss: 5.2052053e-07
Iter: 439 loss: 5.09611141e-07
Iter: 440 loss: 5.08488483e-07
Iter: 441 loss: 5.11361463e-07
Iter: 442 loss: 5.08096264e-07
Iter: 443 loss: 5.07108496e-07
Iter: 444 loss: 5.05789103e-07
Iter: 445 loss: 5.05713786e-07
Iter: 446 loss: 5.04221475e-07
Iter: 447 loss: 5.08254459e-07
Iter: 448 loss: 5.0373e-07
Iter: 449 loss: 5.0328714e-07
Iter: 450 loss: 5.02905323e-07
Iter: 451 loss: 5.02379237e-07
Iter: 452 loss: 5.02018736e-07
Iter: 453 loss: 5.01838485e-07
Iter: 454 loss: 5.01178192e-07
Iter: 455 loss: 5.01194336e-07
Iter: 456 loss: 5.00668534e-07
Iter: 457 loss: 4.99642113e-07
Iter: 458 loss: 4.99382509e-07
Iter: 459 loss: 4.98769566e-07
Iter: 460 loss: 4.99023486e-07
Iter: 461 loss: 4.98167537e-07
Iter: 462 loss: 4.97789188e-07
Iter: 463 loss: 4.96605253e-07
Iter: 464 loss: 5.03160891e-07
Iter: 465 loss: 4.96259076e-07
Iter: 466 loss: 4.94766198e-07
Iter: 467 loss: 5.09107963e-07
Iter: 468 loss: 4.94719302e-07
Iter: 469 loss: 4.93499897e-07
Iter: 470 loss: 5.01092131e-07
Iter: 471 loss: 4.93369782e-07
Iter: 472 loss: 4.92818e-07
Iter: 473 loss: 4.91639753e-07
Iter: 474 loss: 5.11392557e-07
Iter: 475 loss: 4.91626338e-07
Iter: 476 loss: 4.91437618e-07
Iter: 477 loss: 4.90970365e-07
Iter: 478 loss: 4.90578259e-07
Iter: 479 loss: 4.89627951e-07
Iter: 480 loss: 4.98342331e-07
Iter: 481 loss: 4.89471631e-07
Iter: 482 loss: 4.88818557e-07
Iter: 483 loss: 4.88822479e-07
Iter: 484 loss: 4.88182764e-07
Iter: 485 loss: 4.90223e-07
Iter: 486 loss: 4.87990064e-07
Iter: 487 loss: 4.87445959e-07
Iter: 488 loss: 4.86629688e-07
Iter: 489 loss: 4.86619854e-07
Iter: 490 loss: 4.85557905e-07
Iter: 491 loss: 4.88215051e-07
Iter: 492 loss: 4.85192e-07
Iter: 493 loss: 4.84098e-07
Iter: 494 loss: 4.86295e-07
Iter: 495 loss: 4.83689064e-07
Iter: 496 loss: 4.82901896e-07
Iter: 497 loss: 4.94189919e-07
Iter: 498 loss: 4.82901328e-07
Iter: 499 loss: 4.82084488e-07
Iter: 500 loss: 4.83396207e-07
Iter: 501 loss: 4.81742518e-07
Iter: 502 loss: 4.81233315e-07
Iter: 503 loss: 4.80853771e-07
Iter: 504 loss: 4.80704e-07
Iter: 505 loss: 4.80033918e-07
Iter: 506 loss: 4.80045173e-07
Iter: 507 loss: 4.79596338e-07
Iter: 508 loss: 4.78462596e-07
Iter: 509 loss: 4.88662749e-07
Iter: 510 loss: 4.78276206e-07
Iter: 511 loss: 4.77935373e-07
Iter: 512 loss: 4.77720334e-07
Iter: 513 loss: 4.77154799e-07
Iter: 514 loss: 4.76577213e-07
Iter: 515 loss: 4.76429392e-07
Iter: 516 loss: 4.75833872e-07
Iter: 517 loss: 4.85521696e-07
Iter: 518 loss: 4.75819718e-07
Iter: 519 loss: 4.75351101e-07
Iter: 520 loss: 4.75458677e-07
Iter: 521 loss: 4.74983239e-07
Iter: 522 loss: 4.74492225e-07
Iter: 523 loss: 4.73826361e-07
Iter: 524 loss: 4.73789555e-07
Iter: 525 loss: 4.72961517e-07
Iter: 526 loss: 4.76878085e-07
Iter: 527 loss: 4.72762707e-07
Iter: 528 loss: 4.72040313e-07
Iter: 529 loss: 4.73772474e-07
Iter: 530 loss: 4.71770477e-07
Iter: 531 loss: 4.71093358e-07
Iter: 532 loss: 4.77219942e-07
Iter: 533 loss: 4.71050697e-07
Iter: 534 loss: 4.70229338e-07
Iter: 535 loss: 4.69793065e-07
Iter: 536 loss: 4.69397065e-07
Iter: 537 loss: 4.68631299e-07
Iter: 538 loss: 4.71653067e-07
Iter: 539 loss: 4.68461195e-07
Iter: 540 loss: 4.6775807e-07
Iter: 541 loss: 4.74103331e-07
Iter: 542 loss: 4.67703785e-07
Iter: 543 loss: 4.6734317e-07
Iter: 544 loss: 4.66638284e-07
Iter: 545 loss: 4.8256652e-07
Iter: 546 loss: 4.6663726e-07
Iter: 547 loss: 4.66082781e-07
Iter: 548 loss: 4.6608298e-07
Iter: 549 loss: 4.65521964e-07
Iter: 550 loss: 4.65751725e-07
Iter: 551 loss: 4.65141085e-07
Iter: 552 loss: 4.6450765e-07
Iter: 553 loss: 4.63990659e-07
Iter: 554 loss: 4.63809442e-07
Iter: 555 loss: 4.63154095e-07
Iter: 556 loss: 4.63079e-07
Iter: 557 loss: 4.62699688e-07
Iter: 558 loss: 4.61736164e-07
Iter: 559 loss: 4.69778684e-07
Iter: 560 loss: 4.61571403e-07
Iter: 561 loss: 4.60608305e-07
Iter: 562 loss: 4.66028325e-07
Iter: 563 loss: 4.60471767e-07
Iter: 564 loss: 4.59757615e-07
Iter: 565 loss: 4.65973471e-07
Iter: 566 loss: 4.59702676e-07
Iter: 567 loss: 4.59272513e-07
Iter: 568 loss: 4.65123179e-07
Iter: 569 loss: 4.59259951e-07
Iter: 570 loss: 4.58945607e-07
Iter: 571 loss: 4.58553416e-07
Iter: 572 loss: 4.58515842e-07
Iter: 573 loss: 4.58101738e-07
Iter: 574 loss: 4.60926657e-07
Iter: 575 loss: 4.58066495e-07
Iter: 576 loss: 4.57553483e-07
Iter: 577 loss: 4.58070474e-07
Iter: 578 loss: 4.57266452e-07
Iter: 579 loss: 4.56691652e-07
Iter: 580 loss: 4.55888937e-07
Iter: 581 loss: 4.55844969e-07
Iter: 582 loss: 4.55186466e-07
Iter: 583 loss: 4.55161342e-07
Iter: 584 loss: 4.54550502e-07
Iter: 585 loss: 4.53983546e-07
Iter: 586 loss: 4.53853687e-07
Iter: 587 loss: 4.53216842e-07
Iter: 588 loss: 4.56971406e-07
Iter: 589 loss: 4.53122823e-07
Iter: 590 loss: 4.52423421e-07
Iter: 591 loss: 4.55671284e-07
Iter: 592 loss: 4.52289413e-07
Iter: 593 loss: 4.51912797e-07
Iter: 594 loss: 4.51156808e-07
Iter: 595 loss: 4.6577469e-07
Iter: 596 loss: 4.51155586e-07
Iter: 597 loss: 4.5045806e-07
Iter: 598 loss: 4.54713472e-07
Iter: 599 loss: 4.50366656e-07
Iter: 600 loss: 4.49962812e-07
Iter: 601 loss: 4.56450238e-07
Iter: 602 loss: 4.49958208e-07
Iter: 603 loss: 4.49532138e-07
Iter: 604 loss: 4.49808084e-07
Iter: 605 loss: 4.49247239e-07
Iter: 606 loss: 4.48729509e-07
Iter: 607 loss: 4.48416813e-07
Iter: 608 loss: 4.48226103e-07
Iter: 609 loss: 4.47656248e-07
Iter: 610 loss: 4.47658351e-07
Iter: 611 loss: 4.47159493e-07
Iter: 612 loss: 4.47219378e-07
Iter: 613 loss: 4.46789045e-07
Iter: 614 loss: 4.46263186e-07
Iter: 615 loss: 4.46597028e-07
Iter: 616 loss: 4.45934461e-07
Iter: 617 loss: 4.45457715e-07
Iter: 618 loss: 4.45456863e-07
Iter: 619 loss: 4.45131434e-07
Iter: 620 loss: 4.44510732e-07
Iter: 621 loss: 4.57087907e-07
Iter: 622 loss: 4.44499733e-07
Iter: 623 loss: 4.44268778e-07
Iter: 624 loss: 4.44190391e-07
Iter: 625 loss: 4.43865389e-07
Iter: 626 loss: 4.43357578e-07
Iter: 627 loss: 4.43351951e-07
Iter: 628 loss: 4.42829759e-07
Iter: 629 loss: 4.42634786e-07
Iter: 630 loss: 4.42334482e-07
Iter: 631 loss: 4.41606517e-07
Iter: 632 loss: 4.46154388e-07
Iter: 633 loss: 4.41533501e-07
Iter: 634 loss: 4.41032e-07
Iter: 635 loss: 4.41038509e-07
Iter: 636 loss: 4.40650439e-07
Iter: 637 loss: 4.39954732e-07
Iter: 638 loss: 4.56368355e-07
Iter: 639 loss: 4.39961696e-07
Iter: 640 loss: 4.39509819e-07
Iter: 641 loss: 4.46964123e-07
Iter: 642 loss: 4.3952042e-07
Iter: 643 loss: 4.39167536e-07
Iter: 644 loss: 4.40546756e-07
Iter: 645 loss: 4.3909921e-07
Iter: 646 loss: 4.38801067e-07
Iter: 647 loss: 4.38494482e-07
Iter: 648 loss: 4.3844949e-07
Iter: 649 loss: 4.37894357e-07
Iter: 650 loss: 4.40220646e-07
Iter: 651 loss: 4.37779363e-07
Iter: 652 loss: 4.37167841e-07
Iter: 653 loss: 4.39499757e-07
Iter: 654 loss: 4.37034402e-07
Iter: 655 loss: 4.36675379e-07
Iter: 656 loss: 4.36609e-07
Iter: 657 loss: 4.36373654e-07
Iter: 658 loss: 4.35912654e-07
Iter: 659 loss: 4.35909953e-07
Iter: 660 loss: 4.35683887e-07
Iter: 661 loss: 4.35047184e-07
Iter: 662 loss: 4.40445604e-07
Iter: 663 loss: 4.34957173e-07
Iter: 664 loss: 4.34217327e-07
Iter: 665 loss: 4.36942258e-07
Iter: 666 loss: 4.3403503e-07
Iter: 667 loss: 4.33664468e-07
Iter: 668 loss: 4.33627e-07
Iter: 669 loss: 4.3320648e-07
Iter: 670 loss: 4.33301466e-07
Iter: 671 loss: 4.32893103e-07
Iter: 672 loss: 4.32525752e-07
Iter: 673 loss: 4.32661068e-07
Iter: 674 loss: 4.32227125e-07
Iter: 675 loss: 4.31741796e-07
Iter: 676 loss: 4.3757592e-07
Iter: 677 loss: 4.31732104e-07
Iter: 678 loss: 4.31358387e-07
Iter: 679 loss: 4.31008885e-07
Iter: 680 loss: 4.30890793e-07
Iter: 681 loss: 4.30323894e-07
Iter: 682 loss: 4.32874e-07
Iter: 683 loss: 4.30229335e-07
Iter: 684 loss: 4.29901974e-07
Iter: 685 loss: 4.35114885e-07
Iter: 686 loss: 4.29905299e-07
Iter: 687 loss: 4.29679e-07
Iter: 688 loss: 4.29288235e-07
Iter: 689 loss: 4.29274536e-07
Iter: 690 loss: 4.29000465e-07
Iter: 691 loss: 4.29004842e-07
Iter: 692 loss: 4.28708148e-07
Iter: 693 loss: 4.2827088e-07
Iter: 694 loss: 4.28298e-07
Iter: 695 loss: 4.27926864e-07
Iter: 696 loss: 4.27944713e-07
Iter: 697 loss: 4.27632074e-07
Iter: 698 loss: 4.27078589e-07
Iter: 699 loss: 4.28668642e-07
Iter: 700 loss: 4.26885066e-07
Iter: 701 loss: 4.26371457e-07
Iter: 702 loss: 4.26381291e-07
Iter: 703 loss: 4.26077548e-07
Iter: 704 loss: 4.25528185e-07
Iter: 705 loss: 4.36718352e-07
Iter: 706 loss: 4.25513832e-07
Iter: 707 loss: 4.24991697e-07
Iter: 708 loss: 4.2888496e-07
Iter: 709 loss: 4.24957477e-07
Iter: 710 loss: 4.24363492e-07
Iter: 711 loss: 4.26131862e-07
Iter: 712 loss: 4.24182417e-07
Iter: 713 loss: 4.23760923e-07
Iter: 714 loss: 4.24357069e-07
Iter: 715 loss: 4.23536733e-07
Iter: 716 loss: 4.23235633e-07
Iter: 717 loss: 4.26926221e-07
Iter: 718 loss: 4.2322489e-07
Iter: 719 loss: 4.22933056e-07
Iter: 720 loss: 4.22718841e-07
Iter: 721 loss: 4.22599356e-07
Iter: 722 loss: 4.22204607e-07
Iter: 723 loss: 4.2333761e-07
Iter: 724 loss: 4.22054086e-07
Iter: 725 loss: 4.21647144e-07
Iter: 726 loss: 4.27004636e-07
Iter: 727 loss: 4.2166522e-07
Iter: 728 loss: 4.21495713e-07
Iter: 729 loss: 4.21093858e-07
Iter: 730 loss: 4.24433694e-07
Iter: 731 loss: 4.2103926e-07
Iter: 732 loss: 4.20486316e-07
Iter: 733 loss: 4.21960209e-07
Iter: 734 loss: 4.20298647e-07
Iter: 735 loss: 4.20038845e-07
Iter: 736 loss: 4.20007325e-07
Iter: 737 loss: 4.19686501e-07
Iter: 738 loss: 4.19544904e-07
Iter: 739 loss: 4.19360077e-07
Iter: 740 loss: 4.18973173e-07
Iter: 741 loss: 4.18711096e-07
Iter: 742 loss: 4.18579305e-07
Iter: 743 loss: 4.18219315e-07
Iter: 744 loss: 4.18191348e-07
Iter: 745 loss: 4.17885076e-07
Iter: 746 loss: 4.17688227e-07
Iter: 747 loss: 4.17586136e-07
Iter: 748 loss: 4.17192581e-07
Iter: 749 loss: 4.18386321e-07
Iter: 750 loss: 4.17097e-07
Iter: 751 loss: 4.16678745e-07
Iter: 752 loss: 4.19291837e-07
Iter: 753 loss: 4.16631e-07
Iter: 754 loss: 4.16302726e-07
Iter: 755 loss: 4.16005662e-07
Iter: 756 loss: 4.15907749e-07
Iter: 757 loss: 4.15614636e-07
Iter: 758 loss: 4.15603353e-07
Iter: 759 loss: 4.15315071e-07
Iter: 760 loss: 4.14954e-07
Iter: 761 loss: 4.14899318e-07
Iter: 762 loss: 4.14546747e-07
Iter: 763 loss: 4.14500221e-07
Iter: 764 loss: 4.14235473e-07
Iter: 765 loss: 4.13793316e-07
Iter: 766 loss: 4.15611652e-07
Iter: 767 loss: 4.13696171e-07
Iter: 768 loss: 4.13472208e-07
Iter: 769 loss: 4.13436737e-07
Iter: 770 loss: 4.13257055e-07
Iter: 771 loss: 4.12848664e-07
Iter: 772 loss: 4.18922497e-07
Iter: 773 loss: 4.12829763e-07
Iter: 774 loss: 4.12449765e-07
Iter: 775 loss: 4.15105035e-07
Iter: 776 loss: 4.12422651e-07
Iter: 777 loss: 4.11962873e-07
Iter: 778 loss: 4.13129584e-07
Iter: 779 loss: 4.11817439e-07
Iter: 780 loss: 4.11405352e-07
Iter: 781 loss: 4.11328415e-07
Iter: 782 loss: 4.11070459e-07
Iter: 783 loss: 4.10735595e-07
Iter: 784 loss: 4.10735367e-07
Iter: 785 loss: 4.10460046e-07
Iter: 786 loss: 4.10587404e-07
Iter: 787 loss: 4.10283945e-07
Iter: 788 loss: 4.09969516e-07
Iter: 789 loss: 4.10154598e-07
Iter: 790 loss: 4.09757433e-07
Iter: 791 loss: 4.09387411e-07
Iter: 792 loss: 4.0938113e-07
Iter: 793 loss: 4.09232939e-07
Iter: 794 loss: 4.08867e-07
Iter: 795 loss: 4.14151486e-07
Iter: 796 loss: 4.0883188e-07
Iter: 797 loss: 4.08390889e-07
Iter: 798 loss: 4.08731438e-07
Iter: 799 loss: 4.08119291e-07
Iter: 800 loss: 4.0779787e-07
Iter: 801 loss: 4.07769789e-07
Iter: 802 loss: 4.07424125e-07
Iter: 803 loss: 4.07724542e-07
Iter: 804 loss: 4.07207409e-07
Iter: 805 loss: 4.06891274e-07
Iter: 806 loss: 4.06642471e-07
Iter: 807 loss: 4.06565533e-07
Iter: 808 loss: 4.06209438e-07
Iter: 809 loss: 4.06192157e-07
Iter: 810 loss: 4.05970809e-07
Iter: 811 loss: 4.057853e-07
Iter: 812 loss: 4.05719163e-07
Iter: 813 loss: 4.05471923e-07
Iter: 814 loss: 4.0697023e-07
Iter: 815 loss: 4.05444155e-07
Iter: 816 loss: 4.05222522e-07
Iter: 817 loss: 4.061433e-07
Iter: 818 loss: 4.0518421e-07
Iter: 819 loss: 4.04984377e-07
Iter: 820 loss: 4.04766496e-07
Iter: 821 loss: 4.04744867e-07
Iter: 822 loss: 4.04456074e-07
Iter: 823 loss: 4.0445326e-07
Iter: 824 loss: 4.04196783e-07
Iter: 825 loss: 4.03760907e-07
Iter: 826 loss: 4.03759202e-07
Iter: 827 loss: 4.03228881e-07
Iter: 828 loss: 4.03225073e-07
Iter: 829 loss: 4.02821314e-07
Iter: 830 loss: 4.02180149e-07
Iter: 831 loss: 4.05522258e-07
Iter: 832 loss: 4.020809e-07
Iter: 833 loss: 4.01884961e-07
Iter: 834 loss: 4.017935e-07
Iter: 835 loss: 4.01643632e-07
Iter: 836 loss: 4.01322154e-07
Iter: 837 loss: 4.07180579e-07
Iter: 838 loss: 4.0131485e-07
Iter: 839 loss: 4.01062408e-07
Iter: 840 loss: 4.03064632e-07
Iter: 841 loss: 4.01026e-07
Iter: 842 loss: 4.00736383e-07
Iter: 843 loss: 4.01890645e-07
Iter: 844 loss: 4.00674395e-07
Iter: 845 loss: 4.00513073e-07
Iter: 846 loss: 4.00293715e-07
Iter: 847 loss: 4.00275383e-07
Iter: 848 loss: 3.99995258e-07
Iter: 849 loss: 4.03970546e-07
Iter: 850 loss: 3.99998726e-07
Iter: 851 loss: 3.99743953e-07
Iter: 852 loss: 3.99588e-07
Iter: 853 loss: 3.99486282e-07
Iter: 854 loss: 3.99116033e-07
Iter: 855 loss: 4.00205295e-07
Iter: 856 loss: 3.99014482e-07
Iter: 857 loss: 3.98653611e-07
Iter: 858 loss: 4.02638818e-07
Iter: 859 loss: 3.98647359e-07
Iter: 860 loss: 3.9842476e-07
Iter: 861 loss: 3.98078924e-07
Iter: 862 loss: 4.06119426e-07
Iter: 863 loss: 3.98080886e-07
Iter: 864 loss: 3.97720072e-07
Iter: 865 loss: 3.98652276e-07
Iter: 866 loss: 3.97600274e-07
Iter: 867 loss: 3.97334134e-07
Iter: 868 loss: 3.99999379e-07
Iter: 869 loss: 3.97335782e-07
Iter: 870 loss: 3.97021921e-07
Iter: 871 loss: 3.97683976e-07
Iter: 872 loss: 3.96916107e-07
Iter: 873 loss: 3.96651586e-07
Iter: 874 loss: 3.96233276e-07
Iter: 875 loss: 3.96225516e-07
Iter: 876 loss: 3.9596307e-07
Iter: 877 loss: 3.9593624e-07
Iter: 878 loss: 3.95661431e-07
Iter: 879 loss: 3.95231808e-07
Iter: 880 loss: 3.95222401e-07
Iter: 881 loss: 3.94821285e-07
Iter: 882 loss: 3.96524797e-07
Iter: 883 loss: 3.9474665e-07
Iter: 884 loss: 3.94425058e-07
Iter: 885 loss: 3.99082865e-07
Iter: 886 loss: 3.94426365e-07
Iter: 887 loss: 3.94242079e-07
Iter: 888 loss: 3.94219967e-07
Iter: 889 loss: 3.94107133e-07
Iter: 890 loss: 3.93956071e-07
Iter: 891 loss: 3.93955531e-07
Iter: 892 loss: 3.93814616e-07
Iter: 893 loss: 3.93642267e-07
Iter: 894 loss: 3.93633883e-07
Iter: 895 loss: 3.93388234e-07
Iter: 896 loss: 3.93220347e-07
Iter: 897 loss: 3.93122065e-07
Iter: 898 loss: 3.9276506e-07
Iter: 899 loss: 3.93523521e-07
Iter: 900 loss: 3.92619512e-07
Iter: 901 loss: 3.92312472e-07
Iter: 902 loss: 3.9230207e-07
Iter: 903 loss: 3.92005177e-07
Iter: 904 loss: 3.91571518e-07
Iter: 905 loss: 3.91558132e-07
Iter: 906 loss: 3.91178e-07
Iter: 907 loss: 3.92261683e-07
Iter: 908 loss: 3.91037759e-07
Iter: 909 loss: 3.90706305e-07
Iter: 910 loss: 3.95729671e-07
Iter: 911 loss: 3.90693117e-07
Iter: 912 loss: 3.90455114e-07
Iter: 913 loss: 3.90008296e-07
Iter: 914 loss: 3.99532325e-07
Iter: 915 loss: 3.90016226e-07
Iter: 916 loss: 3.89725244e-07
Iter: 917 loss: 3.89722146e-07
Iter: 918 loss: 3.8947843e-07
Iter: 919 loss: 3.90678082e-07
Iter: 920 loss: 3.89419029e-07
Iter: 921 loss: 3.89240682e-07
Iter: 922 loss: 3.89005123e-07
Iter: 923 loss: 3.88989434e-07
Iter: 924 loss: 3.88677535e-07
Iter: 925 loss: 3.88675403e-07
Iter: 926 loss: 3.88496829e-07
Iter: 927 loss: 3.8831584e-07
Iter: 928 loss: 3.88279204e-07
Iter: 929 loss: 3.88011756e-07
Iter: 930 loss: 3.88117797e-07
Iter: 931 loss: 3.87837929e-07
Iter: 932 loss: 3.87535977e-07
Iter: 933 loss: 3.89153513e-07
Iter: 934 loss: 3.87477428e-07
Iter: 935 loss: 3.87270688e-07
Iter: 936 loss: 3.87262645e-07
Iter: 937 loss: 3.87144382e-07
Iter: 938 loss: 3.86824411e-07
Iter: 939 loss: 3.90351772e-07
Iter: 940 loss: 3.86797069e-07
Iter: 941 loss: 3.86521606e-07
Iter: 942 loss: 3.89822617e-07
Iter: 943 loss: 3.86519673e-07
Iter: 944 loss: 3.86248018e-07
Iter: 945 loss: 3.86722206e-07
Iter: 946 loss: 3.86105512e-07
Iter: 947 loss: 3.85863956e-07
Iter: 948 loss: 3.85577891e-07
Iter: 949 loss: 3.85562203e-07
Iter: 950 loss: 3.85224837e-07
Iter: 951 loss: 3.8937219e-07
Iter: 952 loss: 3.85214776e-07
Iter: 953 loss: 3.84883208e-07
Iter: 954 loss: 3.86017973e-07
Iter: 955 loss: 3.84799193e-07
Iter: 956 loss: 3.84627583e-07
Iter: 957 loss: 3.851261e-07
Iter: 958 loss: 3.84595467e-07
Iter: 959 loss: 3.84404188e-07
Iter: 960 loss: 3.85185757e-07
Iter: 961 loss: 3.84349221e-07
Iter: 962 loss: 3.84181874e-07
Iter: 963 loss: 3.83953079e-07
Iter: 964 loss: 3.83953534e-07
Iter: 965 loss: 3.83619522e-07
Iter: 966 loss: 3.84311903e-07
Iter: 967 loss: 3.83527123e-07
Iter: 968 loss: 3.83247453e-07
Iter: 969 loss: 3.84753434e-07
Iter: 970 loss: 3.83225114e-07
Iter: 971 loss: 3.82956159e-07
Iter: 972 loss: 3.85620581e-07
Iter: 973 loss: 3.82948087e-07
Iter: 974 loss: 3.82789892e-07
Iter: 975 loss: 3.82486235e-07
Iter: 976 loss: 3.89041759e-07
Iter: 977 loss: 3.82477083e-07
Iter: 978 loss: 3.82228706e-07
Iter: 979 loss: 3.84620449e-07
Iter: 980 loss: 3.82206395e-07
Iter: 981 loss: 3.81931756e-07
Iter: 982 loss: 3.82823885e-07
Iter: 983 loss: 3.81844359e-07
Iter: 984 loss: 3.81639779e-07
Iter: 985 loss: 3.81418715e-07
Iter: 986 loss: 3.81393107e-07
Iter: 987 loss: 3.81083851e-07
Iter: 988 loss: 3.81074756e-07
Iter: 989 loss: 3.80824076e-07
Iter: 990 loss: 3.80579081e-07
Iter: 991 loss: 3.80537756e-07
Iter: 992 loss: 3.80260673e-07
Iter: 993 loss: 3.8052994e-07
Iter: 994 loss: 3.80114557e-07
Iter: 995 loss: 3.79950507e-07
Iter: 996 loss: 3.80752738e-07
Iter: 997 loss: 3.79914184e-07
Iter: 998 loss: 3.79691585e-07
Iter: 999 loss: 3.79905828e-07
Iter: 1000 loss: 3.79590347e-07
Iter: 1001 loss: 3.79393185e-07
Iter: 1002 loss: 3.79247922e-07
Iter: 1003 loss: 3.79178971e-07
Iter: 1004 loss: 3.78953757e-07
Iter: 1005 loss: 3.80703511e-07
Iter: 1006 loss: 3.78928632e-07
Iter: 1007 loss: 3.78771858e-07
Iter: 1008 loss: 3.81085e-07
Iter: 1009 loss: 3.78766856e-07
Iter: 1010 loss: 3.78647513e-07
Iter: 1011 loss: 3.78418235e-07
Iter: 1012 loss: 3.78415962e-07
Iter: 1013 loss: 3.78159228e-07
Iter: 1014 loss: 3.78405332e-07
Iter: 1015 loss: 3.78016836e-07
Iter: 1016 loss: 3.77851791e-07
Iter: 1017 loss: 3.77817514e-07
Iter: 1018 loss: 3.77670801e-07
Iter: 1019 loss: 3.77368764e-07
Iter: 1020 loss: 3.83372139e-07
Iter: 1021 loss: 3.77348783e-07
Iter: 1022 loss: 3.77030801e-07
Iter: 1023 loss: 3.77365552e-07
Iter: 1024 loss: 3.76830769e-07
Iter: 1025 loss: 3.76580488e-07
Iter: 1026 loss: 3.76590606e-07
Iter: 1027 loss: 3.76338505e-07
Iter: 1028 loss: 3.7711024e-07
Iter: 1029 loss: 3.76260544e-07
Iter: 1030 loss: 3.76121449e-07
Iter: 1031 loss: 3.76279814e-07
Iter: 1032 loss: 3.76041726e-07
Iter: 1033 loss: 3.75866676e-07
Iter: 1034 loss: 3.77451357e-07
Iter: 1035 loss: 3.75844422e-07
Iter: 1036 loss: 3.75742616e-07
Iter: 1037 loss: 3.75460132e-07
Iter: 1038 loss: 3.77954223e-07
Iter: 1039 loss: 3.75432649e-07
Iter: 1040 loss: 3.75119271e-07
Iter: 1041 loss: 3.76765172e-07
Iter: 1042 loss: 3.75064616e-07
Iter: 1043 loss: 3.7492444e-07
Iter: 1044 loss: 3.74911764e-07
Iter: 1045 loss: 3.74746605e-07
Iter: 1046 loss: 3.74561978e-07
Iter: 1047 loss: 3.74573631e-07
Iter: 1048 loss: 3.74303909e-07
Iter: 1049 loss: 3.74421631e-07
Iter: 1050 loss: 3.74153785e-07
Iter: 1051 loss: 3.73955e-07
Iter: 1052 loss: 3.73946307e-07
Iter: 1053 loss: 3.73791e-07
Iter: 1054 loss: 3.73699407e-07
Iter: 1055 loss: 3.73630741e-07
Iter: 1056 loss: 3.73417606e-07
Iter: 1057 loss: 3.73218e-07
Iter: 1058 loss: 3.73166273e-07
Iter: 1059 loss: 3.72883164e-07
Iter: 1060 loss: 3.75856871e-07
Iter: 1061 loss: 3.72869891e-07
Iter: 1062 loss: 3.72673043e-07
Iter: 1063 loss: 3.75562905e-07
Iter: 1064 loss: 3.72676425e-07
Iter: 1065 loss: 3.72526245e-07
Iter: 1066 loss: 3.72210479e-07
Iter: 1067 loss: 3.77565101e-07
Iter: 1068 loss: 3.72210877e-07
Iter: 1069 loss: 3.7204461e-07
Iter: 1070 loss: 3.72009794e-07
Iter: 1071 loss: 3.71881868e-07
Iter: 1072 loss: 3.71627181e-07
Iter: 1073 loss: 3.76090497e-07
Iter: 1074 loss: 3.71618228e-07
Iter: 1075 loss: 3.71421265e-07
Iter: 1076 loss: 3.7237524e-07
Iter: 1077 loss: 3.71364166e-07
Iter: 1078 loss: 3.71160581e-07
Iter: 1079 loss: 3.73458505e-07
Iter: 1080 loss: 3.71160667e-07
Iter: 1081 loss: 3.71002727e-07
Iter: 1082 loss: 3.70825404e-07
Iter: 1083 loss: 3.70817645e-07
Iter: 1084 loss: 3.70620455e-07
Iter: 1085 loss: 3.71745898e-07
Iter: 1086 loss: 3.70603118e-07
Iter: 1087 loss: 3.70418149e-07
Iter: 1088 loss: 3.7149465e-07
Iter: 1089 loss: 3.70407e-07
Iter: 1090 loss: 3.70232669e-07
Iter: 1091 loss: 3.70040482e-07
Iter: 1092 loss: 3.7003133e-07
Iter: 1093 loss: 3.69728411e-07
Iter: 1094 loss: 3.69774227e-07
Iter: 1095 loss: 3.69490408e-07
Iter: 1096 loss: 3.69284578e-07
Iter: 1097 loss: 3.69261102e-07
Iter: 1098 loss: 3.69035092e-07
Iter: 1099 loss: 3.6919505e-07
Iter: 1100 loss: 3.68905859e-07
Iter: 1101 loss: 3.68695197e-07
Iter: 1102 loss: 3.69104242e-07
Iter: 1103 loss: 3.68607658e-07
Iter: 1104 loss: 3.68386225e-07
Iter: 1105 loss: 3.70308896e-07
Iter: 1106 loss: 3.68373691e-07
Iter: 1107 loss: 3.68247498e-07
Iter: 1108 loss: 3.68027315e-07
Iter: 1109 loss: 3.7257621e-07
Iter: 1110 loss: 3.68031408e-07
Iter: 1111 loss: 3.67857e-07
Iter: 1112 loss: 3.70378501e-07
Iter: 1113 loss: 3.67860878e-07
Iter: 1114 loss: 3.67682418e-07
Iter: 1115 loss: 3.68010035e-07
Iter: 1116 loss: 3.67579958e-07
Iter: 1117 loss: 3.67421421e-07
Iter: 1118 loss: 3.67290227e-07
Iter: 1119 loss: 3.6724694e-07
Iter: 1120 loss: 3.67059613e-07
Iter: 1121 loss: 3.69966529e-07
Iter: 1122 loss: 3.67061347e-07
Iter: 1123 loss: 3.66863162e-07
Iter: 1124 loss: 3.6672651e-07
Iter: 1125 loss: 3.66650966e-07
Iter: 1126 loss: 3.66336337e-07
Iter: 1127 loss: 3.66733303e-07
Iter: 1128 loss: 3.66187493e-07
Iter: 1129 loss: 3.65932436e-07
Iter: 1130 loss: 3.66473188e-07
Iter: 1131 loss: 3.65821165e-07
Iter: 1132 loss: 3.65691761e-07
Iter: 1133 loss: 3.65690425e-07
Iter: 1134 loss: 3.655245e-07
Iter: 1135 loss: 3.65382391e-07
Iter: 1136 loss: 3.65357664e-07
Iter: 1137 loss: 3.65188839e-07
Iter: 1138 loss: 3.67347866e-07
Iter: 1139 loss: 3.6520504e-07
Iter: 1140 loss: 3.65048948e-07
Iter: 1141 loss: 3.64927956e-07
Iter: 1142 loss: 3.64874751e-07
Iter: 1143 loss: 3.64674577e-07
Iter: 1144 loss: 3.64451182e-07
Iter: 1145 loss: 3.64420458e-07
Iter: 1146 loss: 3.64285768e-07
Iter: 1147 loss: 3.64214912e-07
Iter: 1148 loss: 3.64039067e-07
Iter: 1149 loss: 3.6370929e-07
Iter: 1150 loss: 3.63713752e-07
Iter: 1151 loss: 3.63415296e-07
Iter: 1152 loss: 3.64447885e-07
Iter: 1153 loss: 3.63335971e-07
Iter: 1154 loss: 3.63113941e-07
Iter: 1155 loss: 3.63103453e-07
Iter: 1156 loss: 3.62996872e-07
Iter: 1157 loss: 3.62896685e-07
Iter: 1158 loss: 3.6286724e-07
Iter: 1159 loss: 3.62653367e-07
Iter: 1160 loss: 3.62890063e-07
Iter: 1161 loss: 3.62552385e-07
Iter: 1162 loss: 3.62319099e-07
Iter: 1163 loss: 3.62997241e-07
Iter: 1164 loss: 3.62243497e-07
Iter: 1165 loss: 3.62043068e-07
Iter: 1166 loss: 3.65363519e-07
Iter: 1167 loss: 3.62042385e-07
Iter: 1168 loss: 3.61905279e-07
Iter: 1169 loss: 3.61730798e-07
Iter: 1170 loss: 3.61716815e-07
Iter: 1171 loss: 3.61474946e-07
Iter: 1172 loss: 3.64501886e-07
Iter: 1173 loss: 3.61455733e-07
Iter: 1174 loss: 3.61311947e-07
Iter: 1175 loss: 3.60986718e-07
Iter: 1176 loss: 3.67991419e-07
Iter: 1177 loss: 3.60997632e-07
Iter: 1178 loss: 3.60750136e-07
Iter: 1179 loss: 3.62447111e-07
Iter: 1180 loss: 3.60737033e-07
Iter: 1181 loss: 3.6060581e-07
Iter: 1182 loss: 3.60589638e-07
Iter: 1183 loss: 3.60525036e-07
Iter: 1184 loss: 3.60261481e-07
Iter: 1185 loss: 3.6144661e-07
Iter: 1186 loss: 3.60192502e-07
Iter: 1187 loss: 3.60072306e-07
Iter: 1188 loss: 3.60028253e-07
Iter: 1189 loss: 3.59900071e-07
Iter: 1190 loss: 3.59893875e-07
Iter: 1191 loss: 3.59783144e-07
Iter: 1192 loss: 3.59616763e-07
Iter: 1193 loss: 3.59549887e-07
Iter: 1194 loss: 3.59461922e-07
Iter: 1195 loss: 3.59220962e-07
Iter: 1196 loss: 3.60407313e-07
Iter: 1197 loss: 3.59172788e-07
Iter: 1198 loss: 3.59038211e-07
Iter: 1199 loss: 3.610823e-07
Iter: 1200 loss: 3.59041366e-07
Iter: 1201 loss: 3.58922364e-07
Iter: 1202 loss: 3.58958857e-07
Iter: 1203 loss: 3.58820614e-07
Iter: 1204 loss: 3.58673219e-07
Iter: 1205 loss: 3.59586664e-07
Iter: 1206 loss: 3.58660543e-07
Iter: 1207 loss: 3.58513091e-07
Iter: 1208 loss: 3.58308654e-07
Iter: 1209 loss: 3.58288105e-07
Iter: 1210 loss: 3.58041206e-07
Iter: 1211 loss: 3.58090972e-07
Iter: 1212 loss: 3.57862689e-07
Iter: 1213 loss: 3.5765413e-07
Iter: 1214 loss: 3.57643188e-07
Iter: 1215 loss: 3.57411608e-07
Iter: 1216 loss: 3.57357663e-07
Iter: 1217 loss: 3.57179715e-07
Iter: 1218 loss: 3.56967945e-07
Iter: 1219 loss: 3.57192789e-07
Iter: 1220 loss: 3.56859e-07
Iter: 1221 loss: 3.5666406e-07
Iter: 1222 loss: 3.56656813e-07
Iter: 1223 loss: 3.56554153e-07
Iter: 1224 loss: 3.56447543e-07
Iter: 1225 loss: 3.56427222e-07
Iter: 1226 loss: 3.5627022e-07
Iter: 1227 loss: 3.56372283e-07
Iter: 1228 loss: 3.56155766e-07
Iter: 1229 loss: 3.56006041e-07
Iter: 1230 loss: 3.57746501e-07
Iter: 1231 loss: 3.55999589e-07
Iter: 1232 loss: 3.55826728e-07
Iter: 1233 loss: 3.56368105e-07
Iter: 1234 loss: 3.55797255e-07
Iter: 1235 loss: 3.55652048e-07
Iter: 1236 loss: 3.55816553e-07
Iter: 1237 loss: 3.55588725e-07
Iter: 1238 loss: 3.55399209e-07
Iter: 1239 loss: 3.56476107e-07
Iter: 1240 loss: 3.55395741e-07
Iter: 1241 loss: 3.55209579e-07
Iter: 1242 loss: 3.54911549e-07
Iter: 1243 loss: 3.59771406e-07
Iter: 1244 loss: 3.54888613e-07
Iter: 1245 loss: 3.54605703e-07
Iter: 1246 loss: 3.57854418e-07
Iter: 1247 loss: 3.54609341e-07
Iter: 1248 loss: 3.54426e-07
Iter: 1249 loss: 3.56787439e-07
Iter: 1250 loss: 3.54426959e-07
Iter: 1251 loss: 3.54332457e-07
Iter: 1252 loss: 3.54123642e-07
Iter: 1253 loss: 3.57188298e-07
Iter: 1254 loss: 3.54123614e-07
Iter: 1255 loss: 3.53995745e-07
Iter: 1256 loss: 3.5398989e-07
Iter: 1257 loss: 3.5388581e-07
Iter: 1258 loss: 3.5378298e-07
Iter: 1259 loss: 3.53739551e-07
Iter: 1260 loss: 3.53584028e-07
Iter: 1261 loss: 3.5351502e-07
Iter: 1262 loss: 3.53449536e-07
Iter: 1263 loss: 3.53184589e-07
Iter: 1264 loss: 3.541e-07
Iter: 1265 loss: 3.53117173e-07
Iter: 1266 loss: 3.52944483e-07
Iter: 1267 loss: 3.52935189e-07
Iter: 1268 loss: 3.52816528e-07
Iter: 1269 loss: 3.52729273e-07
Iter: 1270 loss: 3.52689653e-07
Iter: 1271 loss: 3.5251378e-07
Iter: 1272 loss: 3.54140411e-07
Iter: 1273 loss: 3.52510824e-07
Iter: 1274 loss: 3.52366328e-07
Iter: 1275 loss: 3.52358086e-07
Iter: 1276 loss: 3.52269524e-07
Iter: 1277 loss: 3.52103598e-07
Iter: 1278 loss: 3.52344301e-07
Iter: 1279 loss: 3.52026e-07
Iter: 1280 loss: 3.51955691e-07
Iter: 1281 loss: 3.51941594e-07
Iter: 1282 loss: 3.51865935e-07
Iter: 1283 loss: 3.5170072e-07
Iter: 1284 loss: 3.54473229e-07
Iter: 1285 loss: 3.51683212e-07
Iter: 1286 loss: 3.51505633e-07
Iter: 1287 loss: 3.52299452e-07
Iter: 1288 loss: 3.5148355e-07
Iter: 1289 loss: 3.51285593e-07
Iter: 1290 loss: 3.52675443e-07
Iter: 1291 loss: 3.51255807e-07
Iter: 1292 loss: 3.51146753e-07
Iter: 1293 loss: 3.50869414e-07
Iter: 1294 loss: 3.54854478e-07
Iter: 1295 loss: 3.5087e-07
Iter: 1296 loss: 3.50509538e-07
Iter: 1297 loss: 3.51525e-07
Iter: 1298 loss: 3.50386017e-07
Iter: 1299 loss: 3.50199855e-07
Iter: 1300 loss: 3.50194455e-07
Iter: 1301 loss: 3.50053199e-07
Iter: 1302 loss: 3.50299388e-07
Iter: 1303 loss: 3.49984646e-07
Iter: 1304 loss: 3.49869254e-07
Iter: 1305 loss: 3.50306323e-07
Iter: 1306 loss: 3.49860386e-07
Iter: 1307 loss: 3.49711627e-07
Iter: 1308 loss: 3.49914188e-07
Iter: 1309 loss: 3.49652794e-07
Iter: 1310 loss: 3.49548969e-07
Iter: 1311 loss: 3.49501164e-07
Iter: 1312 loss: 3.49413938e-07
Iter: 1313 loss: 3.49279617e-07
Iter: 1314 loss: 3.50718437e-07
Iter: 1315 loss: 3.49255089e-07
Iter: 1316 loss: 3.49097689e-07
Iter: 1317 loss: 3.49212712e-07
Iter: 1318 loss: 3.4900188e-07
Iter: 1319 loss: 3.48865854e-07
Iter: 1320 loss: 3.48757567e-07
Iter: 1321 loss: 3.48698109e-07
Iter: 1322 loss: 3.48574531e-07
Iter: 1323 loss: 3.4855023e-07
Iter: 1324 loss: 3.48452886e-07
Iter: 1325 loss: 3.48280025e-07
Iter: 1326 loss: 3.52021971e-07
Iter: 1327 loss: 3.48275194e-07
Iter: 1328 loss: 3.48106198e-07
Iter: 1329 loss: 3.48440807e-07
Iter: 1330 loss: 3.48024e-07
Iter: 1331 loss: 3.47865523e-07
Iter: 1332 loss: 3.4937e-07
Iter: 1333 loss: 3.47853444e-07
Iter: 1334 loss: 3.4767541e-07
Iter: 1335 loss: 3.48288609e-07
Iter: 1336 loss: 3.47631186e-07
Iter: 1337 loss: 3.47492062e-07
Iter: 1338 loss: 3.47393666e-07
Iter: 1339 loss: 3.47306525e-07
Iter: 1340 loss: 3.47111865e-07
Iter: 1341 loss: 3.47126161e-07
Iter: 1342 loss: 3.47016282e-07
Iter: 1343 loss: 3.46851039e-07
Iter: 1344 loss: 3.46835122e-07
Iter: 1345 loss: 3.46649102e-07
Iter: 1346 loss: 3.48203201e-07
Iter: 1347 loss: 3.46641116e-07
Iter: 1348 loss: 3.4648798e-07
Iter: 1349 loss: 3.47453152e-07
Iter: 1350 loss: 3.46491731e-07
Iter: 1351 loss: 3.46393165e-07
Iter: 1352 loss: 3.46238437e-07
Iter: 1353 loss: 3.4623298e-07
Iter: 1354 loss: 3.46130207e-07
Iter: 1355 loss: 3.48015334e-07
Iter: 1356 loss: 3.46131515e-07
Iter: 1357 loss: 3.46009244e-07
Iter: 1358 loss: 3.45984e-07
Iter: 1359 loss: 3.45880721e-07
Iter: 1360 loss: 3.45770331e-07
Iter: 1361 loss: 3.45669037e-07
Iter: 1362 loss: 3.45619071e-07
Iter: 1363 loss: 3.45398178e-07
Iter: 1364 loss: 3.45802221e-07
Iter: 1365 loss: 3.45294268e-07
Iter: 1366 loss: 3.45130701e-07
Iter: 1367 loss: 3.45129081e-07
Iter: 1368 loss: 3.44982539e-07
Iter: 1369 loss: 3.44888122e-07
Iter: 1370 loss: 3.44832017e-07
Iter: 1371 loss: 3.44738311e-07
Iter: 1372 loss: 3.44730552e-07
Iter: 1373 loss: 3.44635765e-07
Iter: 1374 loss: 3.44543423e-07
Iter: 1375 loss: 3.44513523e-07
Iter: 1376 loss: 3.44365219e-07
Iter: 1377 loss: 3.44792568e-07
Iter: 1378 loss: 3.44331e-07
Iter: 1379 loss: 3.44191875e-07
Iter: 1380 loss: 3.46016748e-07
Iter: 1381 loss: 3.44195143e-07
Iter: 1382 loss: 3.44100044e-07
Iter: 1383 loss: 3.43974534e-07
Iter: 1384 loss: 3.43964103e-07
Iter: 1385 loss: 3.43811195e-07
Iter: 1386 loss: 3.44015746e-07
Iter: 1387 loss: 3.43721098e-07
Iter: 1388 loss: 3.43547441e-07
Iter: 1389 loss: 3.46210129e-07
Iter: 1390 loss: 3.43546503e-07
Iter: 1391 loss: 3.43441712e-07
Iter: 1392 loss: 3.43265697e-07
Iter: 1393 loss: 3.47445308e-07
Iter: 1394 loss: 3.43266493e-07
Iter: 1395 loss: 3.43052051e-07
Iter: 1396 loss: 3.43483691e-07
Iter: 1397 loss: 3.42983554e-07
Iter: 1398 loss: 3.42832124e-07
Iter: 1399 loss: 3.44800526e-07
Iter: 1400 loss: 3.42841588e-07
Iter: 1401 loss: 3.42676827e-07
Iter: 1402 loss: 3.4321269e-07
Iter: 1403 loss: 3.4262689e-07
Iter: 1404 loss: 3.42513147e-07
Iter: 1405 loss: 3.42490921e-07
Iter: 1406 loss: 3.42401e-07
Iter: 1407 loss: 3.42237e-07
Iter: 1408 loss: 3.43399051e-07
Iter: 1409 loss: 3.42205652e-07
Iter: 1410 loss: 3.42091255e-07
Iter: 1411 loss: 3.41918678e-07
Iter: 1412 loss: 3.41895799e-07
Iter: 1413 loss: 3.41684114e-07
Iter: 1414 loss: 3.43844874e-07
Iter: 1415 loss: 3.41671353e-07
Iter: 1416 loss: 3.4149997e-07
Iter: 1417 loss: 3.42093813e-07
Iter: 1418 loss: 3.41433974e-07
Iter: 1419 loss: 3.413287e-07
Iter: 1420 loss: 3.41130232e-07
Iter: 1421 loss: 3.4113134e-07
Iter: 1422 loss: 3.41026123e-07
Iter: 1423 loss: 3.41001396e-07
Iter: 1424 loss: 3.40888079e-07
Iter: 1425 loss: 3.40793576e-07
Iter: 1426 loss: 3.40768963e-07
Iter: 1427 loss: 3.4060082e-07
Iter: 1428 loss: 3.40574104e-07
Iter: 1429 loss: 3.40479659e-07
Iter: 1430 loss: 3.40254701e-07
Iter: 1431 loss: 3.40662183e-07
Iter: 1432 loss: 3.40159943e-07
Iter: 1433 loss: 3.40095767e-07
Iter: 1434 loss: 3.40021472e-07
Iter: 1435 loss: 3.39933507e-07
Iter: 1436 loss: 3.39780485e-07
Iter: 1437 loss: 3.39783071e-07
Iter: 1438 loss: 3.39683197e-07
Iter: 1439 loss: 3.39677115e-07
Iter: 1440 loss: 3.39589093e-07
Iter: 1441 loss: 3.39499252e-07
Iter: 1442 loss: 3.39489077e-07
Iter: 1443 loss: 3.39350095e-07
Iter: 1444 loss: 3.39659977e-07
Iter: 1445 loss: 3.39280291e-07
Iter: 1446 loss: 3.39151768e-07
Iter: 1447 loss: 3.3915336e-07
Iter: 1448 loss: 3.39075484e-07
Iter: 1449 loss: 3.3894429e-07
Iter: 1450 loss: 3.38954635e-07
Iter: 1451 loss: 3.38814488e-07
Iter: 1452 loss: 3.39375e-07
Iter: 1453 loss: 3.38800419e-07
Iter: 1454 loss: 3.38637278e-07
Iter: 1455 loss: 3.38908023e-07
Iter: 1456 loss: 3.38559204e-07
Iter: 1457 loss: 3.38402799e-07
Iter: 1458 loss: 3.3830085e-07
Iter: 1459 loss: 3.38221696e-07
Iter: 1460 loss: 3.38022e-07
Iter: 1461 loss: 3.38239687e-07
Iter: 1462 loss: 3.3792432e-07
Iter: 1463 loss: 3.37727016e-07
Iter: 1464 loss: 3.40094545e-07
Iter: 1465 loss: 3.37721758e-07
Iter: 1466 loss: 3.37546879e-07
Iter: 1467 loss: 3.38930363e-07
Iter: 1468 loss: 3.37539063e-07
Iter: 1469 loss: 3.3746133e-07
Iter: 1470 loss: 3.37373649e-07
Iter: 1471 loss: 3.37376349e-07
Iter: 1472 loss: 3.37189704e-07
Iter: 1473 loss: 3.38638586e-07
Iter: 1474 loss: 3.37186918e-07
Iter: 1475 loss: 3.37102904e-07
Iter: 1476 loss: 3.37046743e-07
Iter: 1477 loss: 3.36993736e-07
Iter: 1478 loss: 3.36906652e-07
Iter: 1479 loss: 3.37590564e-07
Iter: 1480 loss: 3.36890196e-07
Iter: 1481 loss: 3.36752692e-07
Iter: 1482 loss: 3.36948517e-07
Iter: 1483 loss: 3.36684138e-07
Iter: 1484 loss: 3.36519122e-07
Iter: 1485 loss: 3.36357942e-07
Iter: 1486 loss: 3.36320284e-07
Iter: 1487 loss: 3.36200117e-07
Iter: 1488 loss: 3.36180335e-07
Iter: 1489 loss: 3.36049965e-07
Iter: 1490 loss: 3.35936249e-07
Iter: 1491 loss: 3.35911238e-07
Iter: 1492 loss: 3.35724906e-07
Iter: 1493 loss: 3.35663316e-07
Iter: 1494 loss: 3.35560429e-07
Iter: 1495 loss: 3.35336665e-07
Iter: 1496 loss: 3.36140204e-07
Iter: 1497 loss: 3.35277e-07
Iter: 1498 loss: 3.35157324e-07
Iter: 1499 loss: 3.36986147e-07
Iter: 1500 loss: 3.35144648e-07
Iter: 1501 loss: 3.3501459e-07
Iter: 1502 loss: 3.35647286e-07
Iter: 1503 loss: 3.34990887e-07
Iter: 1504 loss: 3.34897038e-07
Iter: 1505 loss: 3.34838774e-07
Iter: 1506 loss: 3.34809101e-07
Iter: 1507 loss: 3.3466813e-07
Iter: 1508 loss: 3.36349899e-07
Iter: 1509 loss: 3.34673246e-07
Iter: 1510 loss: 3.34585536e-07
Iter: 1511 loss: 3.34421827e-07
Iter: 1512 loss: 3.38031555e-07
Iter: 1513 loss: 3.34426801e-07
Iter: 1514 loss: 3.34281538e-07
Iter: 1515 loss: 3.36416775e-07
Iter: 1516 loss: 3.34290576e-07
Iter: 1517 loss: 3.34108506e-07
Iter: 1518 loss: 3.34008547e-07
Iter: 1519 loss: 3.33935759e-07
Iter: 1520 loss: 3.33786176e-07
Iter: 1521 loss: 3.34443769e-07
Iter: 1522 loss: 3.33752155e-07
Iter: 1523 loss: 3.33651883e-07
Iter: 1524 loss: 3.34723268e-07
Iter: 1525 loss: 3.33646881e-07
Iter: 1526 loss: 3.33562127e-07
Iter: 1527 loss: 3.33484593e-07
Iter: 1528 loss: 3.33480443e-07
Iter: 1529 loss: 3.33330263e-07
Iter: 1530 loss: 3.33227774e-07
Iter: 1531 loss: 3.33178718e-07
Iter: 1532 loss: 3.3295936e-07
Iter: 1533 loss: 3.33630283e-07
Iter: 1534 loss: 3.32916841e-07
Iter: 1535 loss: 3.32726358e-07
Iter: 1536 loss: 3.34339e-07
Iter: 1537 loss: 3.32728519e-07
Iter: 1538 loss: 3.32568504e-07
Iter: 1539 loss: 3.33645062e-07
Iter: 1540 loss: 3.32546279e-07
Iter: 1541 loss: 3.3242992e-07
Iter: 1542 loss: 3.32271838e-07
Iter: 1543 loss: 3.32252455e-07
Iter: 1544 loss: 3.32170202e-07
Iter: 1545 loss: 3.32149654e-07
Iter: 1546 loss: 3.32074222e-07
Iter: 1547 loss: 3.31921683e-07
Iter: 1548 loss: 3.33430307e-07
Iter: 1549 loss: 3.31882489e-07
Iter: 1550 loss: 3.31700733e-07
Iter: 1551 loss: 3.32439669e-07
Iter: 1552 loss: 3.3165918e-07
Iter: 1553 loss: 3.31545834e-07
Iter: 1554 loss: 3.31534295e-07
Iter: 1555 loss: 3.31483335e-07
Iter: 1556 loss: 3.31368653e-07
Iter: 1557 loss: 3.32807076e-07
Iter: 1558 loss: 3.31361775e-07
Iter: 1559 loss: 3.31192155e-07
Iter: 1560 loss: 3.31215404e-07
Iter: 1561 loss: 3.31066161e-07
Iter: 1562 loss: 3.30849872e-07
Iter: 1563 loss: 3.32151615e-07
Iter: 1564 loss: 3.30820541e-07
Iter: 1565 loss: 3.30667234e-07
Iter: 1566 loss: 3.32899447e-07
Iter: 1567 loss: 3.30656349e-07
Iter: 1568 loss: 3.3052072e-07
Iter: 1569 loss: 3.30511284e-07
Iter: 1570 loss: 3.30407431e-07
Iter: 1571 loss: 3.30267795e-07
Iter: 1572 loss: 3.3036514e-07
Iter: 1573 loss: 3.30166671e-07
Iter: 1574 loss: 3.30052728e-07
Iter: 1575 loss: 3.30057e-07
Iter: 1576 loss: 3.29931936e-07
Iter: 1577 loss: 3.29916929e-07
Iter: 1578 loss: 3.29830584e-07
Iter: 1579 loss: 3.29729829e-07
Iter: 1580 loss: 3.29826037e-07
Iter: 1581 loss: 3.29662299e-07
Iter: 1582 loss: 3.29459453e-07
Iter: 1583 loss: 3.30129922e-07
Iter: 1584 loss: 3.29398574e-07
Iter: 1585 loss: 3.29270279e-07
Iter: 1586 loss: 3.2911197e-07
Iter: 1587 loss: 3.29097929e-07
Iter: 1588 loss: 3.28855833e-07
Iter: 1589 loss: 3.2959727e-07
Iter: 1590 loss: 3.28794215e-07
Iter: 1591 loss: 3.2877773e-07
Iter: 1592 loss: 3.2872822e-07
Iter: 1593 loss: 3.28637526e-07
Iter: 1594 loss: 3.28492746e-07
Iter: 1595 loss: 3.29866225e-07
Iter: 1596 loss: 3.28473e-07
Iter: 1597 loss: 3.28343447e-07
Iter: 1598 loss: 3.28396538e-07
Iter: 1599 loss: 3.2823948e-07
Iter: 1600 loss: 3.28096405e-07
Iter: 1601 loss: 3.28096405e-07
Iter: 1602 loss: 3.27956542e-07
Iter: 1603 loss: 3.28287342e-07
Iter: 1604 loss: 3.27903706e-07
Iter: 1605 loss: 3.27779134e-07
Iter: 1606 loss: 3.27509724e-07
Iter: 1607 loss: 3.32432592e-07
Iter: 1608 loss: 3.27508985e-07
Iter: 1609 loss: 3.27311398e-07
Iter: 1610 loss: 3.27311085e-07
Iter: 1611 loss: 3.27143937e-07
Iter: 1612 loss: 3.28186303e-07
Iter: 1613 loss: 3.27121114e-07
Iter: 1614 loss: 3.27026157e-07
Iter: 1615 loss: 3.26912e-07
Iter: 1616 loss: 3.26906274e-07
Iter: 1617 loss: 3.26812085e-07
Iter: 1618 loss: 3.26805264e-07
Iter: 1619 loss: 3.26746459e-07
Iter: 1620 loss: 3.26646e-07
Iter: 1621 loss: 3.26644624e-07
Iter: 1622 loss: 3.26499503e-07
Iter: 1623 loss: 3.26603441e-07
Iter: 1624 loss: 3.26417052e-07
Iter: 1625 loss: 3.26337528e-07
Iter: 1626 loss: 3.26305411e-07
Iter: 1627 loss: 3.26229781e-07
Iter: 1628 loss: 3.26070193e-07
Iter: 1629 loss: 3.27155135e-07
Iter: 1630 loss: 3.25997803e-07
Iter: 1631 loss: 3.25815904e-07
Iter: 1632 loss: 3.26702377e-07
Iter: 1633 loss: 3.25763324e-07
Iter: 1634 loss: 3.25605527e-07
Iter: 1635 loss: 3.2756202e-07
Iter: 1636 loss: 3.25597426e-07
Iter: 1637 loss: 3.2544915e-07
Iter: 1638 loss: 3.25876272e-07
Iter: 1639 loss: 3.25393557e-07
Iter: 1640 loss: 3.25273959e-07
Iter: 1641 loss: 3.2518966e-07
Iter: 1642 loss: 3.25155838e-07
Iter: 1643 loss: 3.25053577e-07
Iter: 1644 loss: 3.26442631e-07
Iter: 1645 loss: 3.25051701e-07
Iter: 1646 loss: 3.2492224e-07
Iter: 1647 loss: 3.2511997e-07
Iter: 1648 loss: 3.24861503e-07
Iter: 1649 loss: 3.24769729e-07
Iter: 1650 loss: 3.24761345e-07
Iter: 1651 loss: 3.24665109e-07
Iter: 1652 loss: 3.24494749e-07
Iter: 1653 loss: 3.25228569e-07
Iter: 1654 loss: 3.24469823e-07
Iter: 1655 loss: 3.24350452e-07
Iter: 1656 loss: 3.24365772e-07
Iter: 1657 loss: 3.24271866e-07
Iter: 1658 loss: 3.24126489e-07
Iter: 1659 loss: 3.24842802e-07
Iter: 1660 loss: 3.24119213e-07
Iter: 1661 loss: 3.23951497e-07
Iter: 1662 loss: 3.24439696e-07
Iter: 1663 loss: 3.23909262e-07
Iter: 1664 loss: 3.23822434e-07
Iter: 1665 loss: 3.23715511e-07
Iter: 1666 loss: 3.23689562e-07
Iter: 1667 loss: 3.23517156e-07
Iter: 1668 loss: 3.23824281e-07
Iter: 1669 loss: 3.23439963e-07
Iter: 1670 loss: 3.23283473e-07
Iter: 1671 loss: 3.24674431e-07
Iter: 1672 loss: 3.23293108e-07
Iter: 1673 loss: 3.2314307e-07
Iter: 1674 loss: 3.24135783e-07
Iter: 1675 loss: 3.23133207e-07
Iter: 1676 loss: 3.23023784e-07
Iter: 1677 loss: 3.22760798e-07
Iter: 1678 loss: 3.25134181e-07
Iter: 1679 loss: 3.22713333e-07
Iter: 1680 loss: 3.22498124e-07
Iter: 1681 loss: 3.25046926e-07
Iter: 1682 loss: 3.22501194e-07
Iter: 1683 loss: 3.22438325e-07
Iter: 1684 loss: 3.22416611e-07
Iter: 1685 loss: 3.22350445e-07
Iter: 1686 loss: 3.2224446e-07
Iter: 1687 loss: 3.22243864e-07
Iter: 1688 loss: 3.22146462e-07
Iter: 1689 loss: 3.2229218e-07
Iter: 1690 loss: 3.22095843e-07
Iter: 1691 loss: 3.21979712e-07
Iter: 1692 loss: 3.23428e-07
Iter: 1693 loss: 3.21982782e-07
Iter: 1694 loss: 3.21918264e-07
Iter: 1695 loss: 3.2168407e-07
Iter: 1696 loss: 3.23013211e-07
Iter: 1697 loss: 3.21645331e-07
Iter: 1698 loss: 3.21571292e-07
Iter: 1699 loss: 3.21542927e-07
Iter: 1700 loss: 3.21400535e-07
Iter: 1701 loss: 3.2134659e-07
Iter: 1702 loss: 3.21278065e-07
Iter: 1703 loss: 3.2115986e-07
Iter: 1704 loss: 3.21341588e-07
Iter: 1705 loss: 3.21100174e-07
Iter: 1706 loss: 3.20983276e-07
Iter: 1707 loss: 3.21433049e-07
Iter: 1708 loss: 3.20951926e-07
Iter: 1709 loss: 3.20848585e-07
Iter: 1710 loss: 3.21011555e-07
Iter: 1711 loss: 3.20814053e-07
Iter: 1712 loss: 3.20703577e-07
Iter: 1713 loss: 3.20738025e-07
Iter: 1714 loss: 3.20628828e-07
Iter: 1715 loss: 3.20483764e-07
Iter: 1716 loss: 3.20537964e-07
Iter: 1717 loss: 3.20378263e-07
Iter: 1718 loss: 3.20308118e-07
Iter: 1719 loss: 3.20264206e-07
Iter: 1720 loss: 3.20190424e-07
Iter: 1721 loss: 3.20017961e-07
Iter: 1722 loss: 3.23254596e-07
Iter: 1723 loss: 3.20024725e-07
Iter: 1724 loss: 3.19859168e-07
Iter: 1725 loss: 3.21181403e-07
Iter: 1726 loss: 3.19865535e-07
Iter: 1727 loss: 3.19734511e-07
Iter: 1728 loss: 3.2020256e-07
Iter: 1729 loss: 3.19693982e-07
Iter: 1730 loss: 3.19620682e-07
Iter: 1731 loss: 3.19566936e-07
Iter: 1732 loss: 3.19545109e-07
Iter: 1733 loss: 3.19458422e-07
Iter: 1734 loss: 3.1945379e-07
Iter: 1735 loss: 3.19385265e-07
Iter: 1736 loss: 3.19278968e-07
Iter: 1737 loss: 3.19282577e-07
Iter: 1738 loss: 3.19183044e-07
Iter: 1739 loss: 3.19140639e-07
Iter: 1740 loss: 3.19072512e-07
Iter: 1741 loss: 3.18980142e-07
Iter: 1742 loss: 3.18968233e-07
Iter: 1743 loss: 3.18835362e-07
Iter: 1744 loss: 3.18721732e-07
Iter: 1745 loss: 3.1868845e-07
Iter: 1746 loss: 3.18555692e-07
Iter: 1747 loss: 3.18798982e-07
Iter: 1748 loss: 3.18491715e-07
Iter: 1749 loss: 3.18322463e-07
Iter: 1750 loss: 3.18409946e-07
Iter: 1751 loss: 3.18202581e-07
Iter: 1752 loss: 3.18132834e-07
Iter: 1753 loss: 3.18107368e-07
Iter: 1754 loss: 3.18046716e-07
Iter: 1755 loss: 3.18625695e-07
Iter: 1756 loss: 3.18045068e-07
Iter: 1757 loss: 3.17992431e-07
Iter: 1758 loss: 3.17869876e-07
Iter: 1759 loss: 3.19255435e-07
Iter: 1760 loss: 3.17864504e-07
Iter: 1761 loss: 3.17754711e-07
Iter: 1762 loss: 3.19350818e-07
Iter: 1763 loss: 3.17755337e-07
Iter: 1764 loss: 3.17657367e-07
Iter: 1765 loss: 3.17660238e-07
Iter: 1766 loss: 3.17559426e-07
Iter: 1767 loss: 3.17453612e-07
Iter: 1768 loss: 3.17458756e-07
Iter: 1769 loss: 3.1736522e-07
Iter: 1770 loss: 3.17245167e-07
Iter: 1771 loss: 3.1725952e-07
Iter: 1772 loss: 3.17155809e-07
Iter: 1773 loss: 3.1704522e-07
Iter: 1774 loss: 3.2020057e-07
Iter: 1775 loss: 3.17047665e-07
Iter: 1776 loss: 3.16889782e-07
Iter: 1777 loss: 3.17113575e-07
Iter: 1778 loss: 3.16816852e-07
Iter: 1779 loss: 3.16675738e-07
Iter: 1780 loss: 3.17148306e-07
Iter: 1781 loss: 3.16642712e-07
Iter: 1782 loss: 3.16534738e-07
Iter: 1783 loss: 3.1693051e-07
Iter: 1784 loss: 3.16515241e-07
Iter: 1785 loss: 3.16426792e-07
Iter: 1786 loss: 3.16426679e-07
Iter: 1787 loss: 3.16351048e-07
Iter: 1788 loss: 3.16278772e-07
Iter: 1789 loss: 3.16265016e-07
Iter: 1790 loss: 3.16151954e-07
Iter: 1791 loss: 3.16515724e-07
Iter: 1792 loss: 3.16108981e-07
Iter: 1793 loss: 3.15994015e-07
Iter: 1794 loss: 3.16879039e-07
Iter: 1795 loss: 3.15992054e-07
Iter: 1796 loss: 3.15923756e-07
Iter: 1797 loss: 3.15843806e-07
Iter: 1798 loss: 3.15833972e-07
Iter: 1799 loss: 3.15715056e-07
Iter: 1800 loss: 3.16996307e-07
Iter: 1801 loss: 3.15726851e-07
Iter: 1802 loss: 3.15632292e-07
Iter: 1803 loss: 3.1559938e-07
Iter: 1804 loss: 3.15545208e-07
Iter: 1805 loss: 3.15476257e-07
Iter: 1806 loss: 3.15771985e-07
Iter: 1807 loss: 3.15444652e-07
Iter: 1808 loss: 3.15371977e-07
Iter: 1809 loss: 3.15851196e-07
Iter: 1810 loss: 3.15345176e-07
Iter: 1811 loss: 3.15285092e-07
Iter: 1812 loss: 3.15190732e-07
Iter: 1813 loss: 3.15183684e-07
Iter: 1814 loss: 3.15101119e-07
Iter: 1815 loss: 3.15075255e-07
Iter: 1816 loss: 3.1500565e-07
Iter: 1817 loss: 3.148063e-07
Iter: 1818 loss: 3.15104899e-07
Iter: 1819 loss: 3.1470654e-07
Iter: 1820 loss: 3.14619257e-07
Iter: 1821 loss: 3.14608513e-07
Iter: 1822 loss: 3.14515972e-07
Iter: 1823 loss: 3.14566e-07
Iter: 1824 loss: 3.14440456e-07
Iter: 1825 loss: 3.14325348e-07
Iter: 1826 loss: 3.1437429e-07
Iter: 1827 loss: 3.14261854e-07
Iter: 1828 loss: 3.14186451e-07
Iter: 1829 loss: 3.14190203e-07
Iter: 1830 loss: 3.14109229e-07
Iter: 1831 loss: 3.14025613e-07
Iter: 1832 loss: 3.14012681e-07
Iter: 1833 loss: 3.13924374e-07
Iter: 1834 loss: 3.14154533e-07
Iter: 1835 loss: 3.1389618e-07
Iter: 1836 loss: 3.13812279e-07
Iter: 1837 loss: 3.13813274e-07
Iter: 1838 loss: 3.13750064e-07
Iter: 1839 loss: 3.1363669e-07
Iter: 1840 loss: 3.16234775e-07
Iter: 1841 loss: 3.13642204e-07
Iter: 1842 loss: 3.13522065e-07
Iter: 1843 loss: 3.14167551e-07
Iter: 1844 loss: 3.13514931e-07
Iter: 1845 loss: 3.1337953e-07
Iter: 1846 loss: 3.1423312e-07
Iter: 1847 loss: 3.13379957e-07
Iter: 1848 loss: 3.13313279e-07
Iter: 1849 loss: 3.13181232e-07
Iter: 1850 loss: 3.13190156e-07
Iter: 1851 loss: 3.13044609e-07
Iter: 1852 loss: 3.13775161e-07
Iter: 1853 loss: 3.13024685e-07
Iter: 1854 loss: 3.12952409e-07
Iter: 1855 loss: 3.12963095e-07
Iter: 1856 loss: 3.12902159e-07
Iter: 1857 loss: 3.1285461e-07
Iter: 1858 loss: 3.12838949e-07
Iter: 1859 loss: 3.12739189e-07
Iter: 1860 loss: 3.12802854e-07
Iter: 1861 loss: 3.1267e-07
Iter: 1862 loss: 3.12605465e-07
Iter: 1863 loss: 3.12581875e-07
Iter: 1864 loss: 3.12553027e-07
Iter: 1865 loss: 3.12455654e-07
Iter: 1866 loss: 3.1245321e-07
Iter: 1867 loss: 3.12358907e-07
Iter: 1868 loss: 3.12524719e-07
Iter: 1869 loss: 3.12307435e-07
Iter: 1870 loss: 3.1214816e-07
Iter: 1871 loss: 3.12985094e-07
Iter: 1872 loss: 3.12121387e-07
Iter: 1873 loss: 3.12019893e-07
Iter: 1874 loss: 3.12056159e-07
Iter: 1875 loss: 3.11974588e-07
Iter: 1876 loss: 3.1189407e-07
Iter: 1877 loss: 3.12880275e-07
Iter: 1878 loss: 3.1189802e-07
Iter: 1879 loss: 3.1182131e-07
Iter: 1880 loss: 3.1173073e-07
Iter: 1881 loss: 3.11719759e-07
Iter: 1882 loss: 3.11629378e-07
Iter: 1883 loss: 3.11781378e-07
Iter: 1884 loss: 3.11583193e-07
Iter: 1885 loss: 3.11501026e-07
Iter: 1886 loss: 3.12357912e-07
Iter: 1887 loss: 3.11503982e-07
Iter: 1888 loss: 3.11409451e-07
Iter: 1889 loss: 3.1169418e-07
Iter: 1890 loss: 3.11389812e-07
Iter: 1891 loss: 3.11334134e-07
Iter: 1892 loss: 3.11275528e-07
Iter: 1893 loss: 3.1125694e-07
Iter: 1894 loss: 3.11178809e-07
Iter: 1895 loss: 3.12185733e-07
Iter: 1896 loss: 3.11174176e-07
Iter: 1897 loss: 3.11110284e-07
Iter: 1898 loss: 3.11166048e-07
Iter: 1899 loss: 3.11054492e-07
Iter: 1900 loss: 3.10963344e-07
Iter: 1901 loss: 3.10895473e-07
Iter: 1902 loss: 3.10870519e-07
Iter: 1903 loss: 3.107981e-07
Iter: 1904 loss: 3.10786845e-07
Iter: 1905 loss: 3.10734322e-07
Iter: 1906 loss: 3.10708486e-07
Iter: 1907 loss: 3.10671822e-07
Iter: 1908 loss: 3.10601195e-07
Iter: 1909 loss: 3.1084079e-07
Iter: 1910 loss: 3.10579054e-07
Iter: 1911 loss: 3.10492226e-07
Iter: 1912 loss: 3.1106552e-07
Iter: 1913 loss: 3.10480743e-07
Iter: 1914 loss: 3.10422564e-07
Iter: 1915 loss: 3.10343353e-07
Iter: 1916 loss: 3.10346536e-07
Iter: 1917 loss: 3.1024291e-07
Iter: 1918 loss: 3.1052295e-07
Iter: 1919 loss: 3.10202608e-07
Iter: 1920 loss: 3.10148209e-07
Iter: 1921 loss: 3.10145538e-07
Iter: 1922 loss: 3.10054361e-07
Iter: 1923 loss: 3.09927515e-07
Iter: 1924 loss: 3.09932062e-07
Iter: 1925 loss: 3.09835173e-07
Iter: 1926 loss: 3.10413867e-07
Iter: 1927 loss: 3.09817608e-07
Iter: 1928 loss: 3.09770769e-07
Iter: 1929 loss: 3.09752096e-07
Iter: 1930 loss: 3.09703125e-07
Iter: 1931 loss: 3.096e-07
Iter: 1932 loss: 3.10872082e-07
Iter: 1933 loss: 3.09594128e-07
Iter: 1934 loss: 3.09487376e-07
Iter: 1935 loss: 3.10296116e-07
Iter: 1936 loss: 3.09486836e-07
Iter: 1937 loss: 3.09395318e-07
Iter: 1938 loss: 3.10013718e-07
Iter: 1939 loss: 3.09398956e-07
Iter: 1940 loss: 3.09344415e-07
Iter: 1941 loss: 3.09195372e-07
Iter: 1942 loss: 3.11616816e-07
Iter: 1943 loss: 3.09185225e-07
Iter: 1944 loss: 3.09103655e-07
Iter: 1945 loss: 3.0911491e-07
Iter: 1946 loss: 3.09011341e-07
Iter: 1947 loss: 3.0898434e-07
Iter: 1948 loss: 3.08940741e-07
Iter: 1949 loss: 3.08836803e-07
Iter: 1950 loss: 3.08861019e-07
Iter: 1951 loss: 3.08766118e-07
Iter: 1952 loss: 3.08676761e-07
Iter: 1953 loss: 3.09300844e-07
Iter: 1954 loss: 3.08668547e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2
+ date
Mon Oct 26 12:09:48 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41c05158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41c05598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41c8c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41c79840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41b4c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41bcb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41af00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41abb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41abbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41af0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41a09ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41a2b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41a2b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41a33598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41a33f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41975b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41997488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41997840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b4196e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b4196ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41911950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b419118c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41880950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41911510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b419117b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b4185b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b41911ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15b6e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15b67510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15b67e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15b33ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15af91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15aec2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15a947b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15abb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b15aec620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.80437188e-06
Iter: 2 loss: 5.69688245e-06
Iter: 3 loss: 5.64638367e-06
Iter: 4 loss: 5.16069213e-06
Iter: 5 loss: 5.95539132e-06
Iter: 6 loss: 4.93851667e-06
Iter: 7 loss: 4.68968483e-06
Iter: 8 loss: 5.70390057e-06
Iter: 9 loss: 4.63505876e-06
Iter: 10 loss: 4.37734752e-06
Iter: 11 loss: 4.79603477e-06
Iter: 12 loss: 4.2588872e-06
Iter: 13 loss: 4.05915034e-06
Iter: 14 loss: 4.97964038e-06
Iter: 15 loss: 4.02161641e-06
Iter: 16 loss: 3.86109514e-06
Iter: 17 loss: 4.86923e-06
Iter: 18 loss: 3.84275199e-06
Iter: 19 loss: 3.7746313e-06
Iter: 20 loss: 3.62833566e-06
Iter: 21 loss: 5.9291051e-06
Iter: 22 loss: 3.62318701e-06
Iter: 23 loss: 3.41632426e-06
Iter: 24 loss: 4.48381388e-06
Iter: 25 loss: 3.38312248e-06
Iter: 26 loss: 3.25461542e-06
Iter: 27 loss: 3.25425935e-06
Iter: 28 loss: 3.17311651e-06
Iter: 29 loss: 2.98132e-06
Iter: 30 loss: 5.2130481e-06
Iter: 31 loss: 2.96421058e-06
Iter: 32 loss: 2.80651284e-06
Iter: 33 loss: 4.00386079e-06
Iter: 34 loss: 2.7945207e-06
Iter: 35 loss: 2.66801248e-06
Iter: 36 loss: 3.05329741e-06
Iter: 37 loss: 2.63030188e-06
Iter: 38 loss: 2.52617315e-06
Iter: 39 loss: 2.63809716e-06
Iter: 40 loss: 2.46897025e-06
Iter: 41 loss: 2.46896252e-06
Iter: 42 loss: 2.42284955e-06
Iter: 43 loss: 2.37696258e-06
Iter: 44 loss: 2.30829323e-06
Iter: 45 loss: 2.30685032e-06
Iter: 46 loss: 2.2496879e-06
Iter: 47 loss: 2.66396455e-06
Iter: 48 loss: 2.244901e-06
Iter: 49 loss: 2.17751017e-06
Iter: 50 loss: 2.20938364e-06
Iter: 51 loss: 2.13221301e-06
Iter: 52 loss: 2.08044821e-06
Iter: 53 loss: 2.47743492e-06
Iter: 54 loss: 2.07660059e-06
Iter: 55 loss: 2.03520517e-06
Iter: 56 loss: 2.14878696e-06
Iter: 57 loss: 2.02175124e-06
Iter: 58 loss: 1.98528e-06
Iter: 59 loss: 1.92528387e-06
Iter: 60 loss: 1.92502353e-06
Iter: 61 loss: 1.88236504e-06
Iter: 62 loss: 2.46791274e-06
Iter: 63 loss: 1.88222975e-06
Iter: 64 loss: 1.8467083e-06
Iter: 65 loss: 2.12021109e-06
Iter: 66 loss: 1.84410362e-06
Iter: 67 loss: 1.81977225e-06
Iter: 68 loss: 1.77680056e-06
Iter: 69 loss: 1.77677987e-06
Iter: 70 loss: 1.71932174e-06
Iter: 71 loss: 1.88232457e-06
Iter: 72 loss: 1.70107114e-06
Iter: 73 loss: 1.64461369e-06
Iter: 74 loss: 1.59730462e-06
Iter: 75 loss: 1.58140233e-06
Iter: 76 loss: 1.50609185e-06
Iter: 77 loss: 1.50591359e-06
Iter: 78 loss: 1.48797653e-06
Iter: 79 loss: 1.4827358e-06
Iter: 80 loss: 1.46538048e-06
Iter: 81 loss: 1.43920738e-06
Iter: 82 loss: 1.4387175e-06
Iter: 83 loss: 1.4169641e-06
Iter: 84 loss: 1.5341044e-06
Iter: 85 loss: 1.41371e-06
Iter: 86 loss: 1.38541236e-06
Iter: 87 loss: 1.42404429e-06
Iter: 88 loss: 1.37129541e-06
Iter: 89 loss: 1.3581971e-06
Iter: 90 loss: 1.4196437e-06
Iter: 91 loss: 1.35578864e-06
Iter: 92 loss: 1.33914898e-06
Iter: 93 loss: 1.33827575e-06
Iter: 94 loss: 1.3255144e-06
Iter: 95 loss: 1.30784861e-06
Iter: 96 loss: 1.31185925e-06
Iter: 97 loss: 1.29488785e-06
Iter: 98 loss: 1.26792406e-06
Iter: 99 loss: 1.35919447e-06
Iter: 100 loss: 1.260712e-06
Iter: 101 loss: 1.23479276e-06
Iter: 102 loss: 1.5116575e-06
Iter: 103 loss: 1.23413952e-06
Iter: 104 loss: 1.22092365e-06
Iter: 105 loss: 1.18933758e-06
Iter: 106 loss: 1.54708107e-06
Iter: 107 loss: 1.18624916e-06
Iter: 108 loss: 1.16234901e-06
Iter: 109 loss: 1.26938153e-06
Iter: 110 loss: 1.15766045e-06
Iter: 111 loss: 1.13641909e-06
Iter: 112 loss: 1.33069534e-06
Iter: 113 loss: 1.13549561e-06
Iter: 114 loss: 1.12606153e-06
Iter: 115 loss: 1.12590294e-06
Iter: 116 loss: 1.11589475e-06
Iter: 117 loss: 1.11388499e-06
Iter: 118 loss: 1.10719202e-06
Iter: 119 loss: 1.09666439e-06
Iter: 120 loss: 1.09152427e-06
Iter: 121 loss: 1.08639631e-06
Iter: 122 loss: 1.0713577e-06
Iter: 123 loss: 1.07137009e-06
Iter: 124 loss: 1.06326638e-06
Iter: 125 loss: 1.05354616e-06
Iter: 126 loss: 1.05261836e-06
Iter: 127 loss: 1.03788761e-06
Iter: 128 loss: 1.1161867e-06
Iter: 129 loss: 1.03559717e-06
Iter: 130 loss: 1.02208924e-06
Iter: 131 loss: 1.07025653e-06
Iter: 132 loss: 1.01862395e-06
Iter: 133 loss: 1.01060994e-06
Iter: 134 loss: 9.95288246e-07
Iter: 135 loss: 1.31929619e-06
Iter: 136 loss: 9.95202299e-07
Iter: 137 loss: 9.94133416e-07
Iter: 138 loss: 9.87182148e-07
Iter: 139 loss: 9.82306801e-07
Iter: 140 loss: 9.79163588e-07
Iter: 141 loss: 9.77236255e-07
Iter: 142 loss: 9.68687687e-07
Iter: 143 loss: 9.57373459e-07
Iter: 144 loss: 9.5669e-07
Iter: 145 loss: 9.42415966e-07
Iter: 146 loss: 9.7406e-07
Iter: 147 loss: 9.36935237e-07
Iter: 148 loss: 9.21589049e-07
Iter: 149 loss: 1.00108377e-06
Iter: 150 loss: 9.19159788e-07
Iter: 151 loss: 9.12063967e-07
Iter: 152 loss: 9.10350877e-07
Iter: 153 loss: 9.05148966e-07
Iter: 154 loss: 8.9758737e-07
Iter: 155 loss: 8.97352152e-07
Iter: 156 loss: 8.90753029e-07
Iter: 157 loss: 9.23918265e-07
Iter: 158 loss: 8.89645776e-07
Iter: 159 loss: 8.81916606e-07
Iter: 160 loss: 9.15370322e-07
Iter: 161 loss: 8.80327207e-07
Iter: 162 loss: 8.76174909e-07
Iter: 163 loss: 8.69174187e-07
Iter: 164 loss: 8.69180099e-07
Iter: 165 loss: 8.64915478e-07
Iter: 166 loss: 8.6389781e-07
Iter: 167 loss: 8.6115449e-07
Iter: 168 loss: 8.52572384e-07
Iter: 169 loss: 8.73802151e-07
Iter: 170 loss: 8.47726938e-07
Iter: 171 loss: 8.40517828e-07
Iter: 172 loss: 8.3961686e-07
Iter: 173 loss: 8.34601451e-07
Iter: 174 loss: 8.77321099e-07
Iter: 175 loss: 8.34304615e-07
Iter: 176 loss: 8.30374574e-07
Iter: 177 loss: 8.24184042e-07
Iter: 178 loss: 8.24148913e-07
Iter: 179 loss: 8.16968168e-07
Iter: 180 loss: 8.35984338e-07
Iter: 181 loss: 8.14564942e-07
Iter: 182 loss: 8.0864811e-07
Iter: 183 loss: 8.55811e-07
Iter: 184 loss: 8.08245204e-07
Iter: 185 loss: 8.04333354e-07
Iter: 186 loss: 8.04322553e-07
Iter: 187 loss: 8.01323949e-07
Iter: 188 loss: 7.94237394e-07
Iter: 189 loss: 8.77649768e-07
Iter: 190 loss: 7.93623258e-07
Iter: 191 loss: 7.88839316e-07
Iter: 192 loss: 8.62762818e-07
Iter: 193 loss: 7.88830675e-07
Iter: 194 loss: 7.83293217e-07
Iter: 195 loss: 7.83782866e-07
Iter: 196 loss: 7.79024504e-07
Iter: 197 loss: 7.73960664e-07
Iter: 198 loss: 7.74496584e-07
Iter: 199 loss: 7.70061547e-07
Iter: 200 loss: 7.66791459e-07
Iter: 201 loss: 7.66238315e-07
Iter: 202 loss: 7.64083609e-07
Iter: 203 loss: 7.60860303e-07
Iter: 204 loss: 7.60795615e-07
Iter: 205 loss: 7.55823294e-07
Iter: 206 loss: 7.57276723e-07
Iter: 207 loss: 7.52263418e-07
Iter: 208 loss: 7.4963441e-07
Iter: 209 loss: 7.49302217e-07
Iter: 210 loss: 7.46147123e-07
Iter: 211 loss: 7.42873681e-07
Iter: 212 loss: 7.42272277e-07
Iter: 213 loss: 7.37979917e-07
Iter: 214 loss: 7.3334536e-07
Iter: 215 loss: 7.32599688e-07
Iter: 216 loss: 7.26832582e-07
Iter: 217 loss: 7.26773067e-07
Iter: 218 loss: 7.22479399e-07
Iter: 219 loss: 7.67765414e-07
Iter: 220 loss: 7.223843e-07
Iter: 221 loss: 7.19926447e-07
Iter: 222 loss: 7.1366145e-07
Iter: 223 loss: 7.65055574e-07
Iter: 224 loss: 7.12543681e-07
Iter: 225 loss: 7.12636e-07
Iter: 226 loss: 7.09950655e-07
Iter: 227 loss: 7.07732397e-07
Iter: 228 loss: 7.06365142e-07
Iter: 229 loss: 7.05478101e-07
Iter: 230 loss: 7.03271326e-07
Iter: 231 loss: 7.01810791e-07
Iter: 232 loss: 7.00995656e-07
Iter: 233 loss: 6.96826589e-07
Iter: 234 loss: 7.32910166e-07
Iter: 235 loss: 6.96599386e-07
Iter: 236 loss: 6.93862376e-07
Iter: 237 loss: 7.00771579e-07
Iter: 238 loss: 6.92965273e-07
Iter: 239 loss: 6.90803745e-07
Iter: 240 loss: 6.85385658e-07
Iter: 241 loss: 7.33937384e-07
Iter: 242 loss: 6.84516408e-07
Iter: 243 loss: 6.81540314e-07
Iter: 244 loss: 6.80350865e-07
Iter: 245 loss: 6.77228172e-07
Iter: 246 loss: 6.81156109e-07
Iter: 247 loss: 6.7559e-07
Iter: 248 loss: 6.72595093e-07
Iter: 249 loss: 6.73249303e-07
Iter: 250 loss: 6.70387067e-07
Iter: 251 loss: 6.67396421e-07
Iter: 252 loss: 6.80024868e-07
Iter: 253 loss: 6.66759e-07
Iter: 254 loss: 6.62435355e-07
Iter: 255 loss: 6.7726404e-07
Iter: 256 loss: 6.61316164e-07
Iter: 257 loss: 6.59338752e-07
Iter: 258 loss: 6.58010435e-07
Iter: 259 loss: 6.57248506e-07
Iter: 260 loss: 6.54774908e-07
Iter: 261 loss: 6.85383611e-07
Iter: 262 loss: 6.54755581e-07
Iter: 263 loss: 6.5209764e-07
Iter: 264 loss: 6.5088318e-07
Iter: 265 loss: 6.49588969e-07
Iter: 266 loss: 6.46574676e-07
Iter: 267 loss: 6.48760192e-07
Iter: 268 loss: 6.44740567e-07
Iter: 269 loss: 6.42889745e-07
Iter: 270 loss: 6.42897135e-07
Iter: 271 loss: 6.40655855e-07
Iter: 272 loss: 6.36564153e-07
Iter: 273 loss: 7.28536861e-07
Iter: 274 loss: 6.36563641e-07
Iter: 275 loss: 6.33694526e-07
Iter: 276 loss: 6.44777799e-07
Iter: 277 loss: 6.32988701e-07
Iter: 278 loss: 6.30674037e-07
Iter: 279 loss: 6.615129e-07
Iter: 280 loss: 6.30639818e-07
Iter: 281 loss: 6.28476641e-07
Iter: 282 loss: 6.29822e-07
Iter: 283 loss: 6.2710285e-07
Iter: 284 loss: 6.2482934e-07
Iter: 285 loss: 6.22603693e-07
Iter: 286 loss: 6.22112566e-07
Iter: 287 loss: 6.20386174e-07
Iter: 288 loss: 6.20026753e-07
Iter: 289 loss: 6.17759667e-07
Iter: 290 loss: 6.1594352e-07
Iter: 291 loss: 6.15287945e-07
Iter: 292 loss: 6.13064856e-07
Iter: 293 loss: 6.12708448e-07
Iter: 294 loss: 6.11237e-07
Iter: 295 loss: 6.08567461e-07
Iter: 296 loss: 6.08548362e-07
Iter: 297 loss: 6.06708511e-07
Iter: 298 loss: 6.07080437e-07
Iter: 299 loss: 6.05326534e-07
Iter: 300 loss: 6.03716501e-07
Iter: 301 loss: 6.01945487e-07
Iter: 302 loss: 6.01680654e-07
Iter: 303 loss: 5.99863483e-07
Iter: 304 loss: 5.99719e-07
Iter: 305 loss: 5.98180577e-07
Iter: 306 loss: 5.97363908e-07
Iter: 307 loss: 5.96652058e-07
Iter: 308 loss: 5.94627636e-07
Iter: 309 loss: 5.98678241e-07
Iter: 310 loss: 5.93808863e-07
Iter: 311 loss: 5.92086e-07
Iter: 312 loss: 6.0428647e-07
Iter: 313 loss: 5.91907e-07
Iter: 314 loss: 5.90095112e-07
Iter: 315 loss: 5.95649e-07
Iter: 316 loss: 5.89579429e-07
Iter: 317 loss: 5.88344733e-07
Iter: 318 loss: 5.85832822e-07
Iter: 319 loss: 6.34316962e-07
Iter: 320 loss: 5.85805e-07
Iter: 321 loss: 5.85408486e-07
Iter: 322 loss: 5.84501663e-07
Iter: 323 loss: 5.83217229e-07
Iter: 324 loss: 5.82133225e-07
Iter: 325 loss: 5.81791085e-07
Iter: 326 loss: 5.80129722e-07
Iter: 327 loss: 5.81270285e-07
Iter: 328 loss: 5.79099492e-07
Iter: 329 loss: 5.78109734e-07
Iter: 330 loss: 5.77976436e-07
Iter: 331 loss: 5.77034029e-07
Iter: 332 loss: 5.74460557e-07
Iter: 333 loss: 5.89705508e-07
Iter: 334 loss: 5.73781563e-07
Iter: 335 loss: 5.71307226e-07
Iter: 336 loss: 5.8668877e-07
Iter: 337 loss: 5.71040061e-07
Iter: 338 loss: 5.68678615e-07
Iter: 339 loss: 5.86188548e-07
Iter: 340 loss: 5.68459313e-07
Iter: 341 loss: 5.66345875e-07
Iter: 342 loss: 5.68469375e-07
Iter: 343 loss: 5.65163532e-07
Iter: 344 loss: 5.63461242e-07
Iter: 345 loss: 5.65065136e-07
Iter: 346 loss: 5.62470632e-07
Iter: 347 loss: 5.61598824e-07
Iter: 348 loss: 5.61479055e-07
Iter: 349 loss: 5.60529315e-07
Iter: 350 loss: 5.58898421e-07
Iter: 351 loss: 5.58894499e-07
Iter: 352 loss: 5.57194483e-07
Iter: 353 loss: 5.68746373e-07
Iter: 354 loss: 5.57053795e-07
Iter: 355 loss: 5.56382361e-07
Iter: 356 loss: 5.56389523e-07
Iter: 357 loss: 5.55691429e-07
Iter: 358 loss: 5.53667462e-07
Iter: 359 loss: 5.62597677e-07
Iter: 360 loss: 5.52943959e-07
Iter: 361 loss: 5.51021344e-07
Iter: 362 loss: 5.78274125e-07
Iter: 363 loss: 5.51018388e-07
Iter: 364 loss: 5.49255446e-07
Iter: 365 loss: 5.57190958e-07
Iter: 366 loss: 5.48856065e-07
Iter: 367 loss: 5.47609034e-07
Iter: 368 loss: 5.45670446e-07
Iter: 369 loss: 5.4562895e-07
Iter: 370 loss: 5.43381816e-07
Iter: 371 loss: 5.53991526e-07
Iter: 372 loss: 5.42962084e-07
Iter: 373 loss: 5.42131e-07
Iter: 374 loss: 5.41988811e-07
Iter: 375 loss: 5.41209772e-07
Iter: 376 loss: 5.39193195e-07
Iter: 377 loss: 5.56438863e-07
Iter: 378 loss: 5.38855602e-07
Iter: 379 loss: 5.37541553e-07
Iter: 380 loss: 5.37537687e-07
Iter: 381 loss: 5.36547077e-07
Iter: 382 loss: 5.4255878e-07
Iter: 383 loss: 5.36430093e-07
Iter: 384 loss: 5.35424761e-07
Iter: 385 loss: 5.34478204e-07
Iter: 386 loss: 5.34237302e-07
Iter: 387 loss: 5.32760623e-07
Iter: 388 loss: 5.37493406e-07
Iter: 389 loss: 5.32348565e-07
Iter: 390 loss: 5.30552484e-07
Iter: 391 loss: 5.43688202e-07
Iter: 392 loss: 5.30391219e-07
Iter: 393 loss: 5.29428121e-07
Iter: 394 loss: 5.28235319e-07
Iter: 395 loss: 5.28118449e-07
Iter: 396 loss: 5.26505801e-07
Iter: 397 loss: 5.35155095e-07
Iter: 398 loss: 5.26261374e-07
Iter: 399 loss: 5.24535949e-07
Iter: 400 loss: 5.33847412e-07
Iter: 401 loss: 5.24316533e-07
Iter: 402 loss: 5.23494862e-07
Iter: 403 loss: 5.22384767e-07
Iter: 404 loss: 5.22325308e-07
Iter: 405 loss: 5.21050254e-07
Iter: 406 loss: 5.23814379e-07
Iter: 407 loss: 5.20568506e-07
Iter: 408 loss: 5.19151058e-07
Iter: 409 loss: 5.3876721e-07
Iter: 410 loss: 5.19137188e-07
Iter: 411 loss: 5.18372758e-07
Iter: 412 loss: 5.17623619e-07
Iter: 413 loss: 5.17474916e-07
Iter: 414 loss: 5.15825718e-07
Iter: 415 loss: 5.14859153e-07
Iter: 416 loss: 5.14203123e-07
Iter: 417 loss: 5.13158909e-07
Iter: 418 loss: 5.12747533e-07
Iter: 419 loss: 5.12012662e-07
Iter: 420 loss: 5.10831114e-07
Iter: 421 loss: 5.10828215e-07
Iter: 422 loss: 5.10316681e-07
Iter: 423 loss: 5.10158202e-07
Iter: 424 loss: 5.09500296e-07
Iter: 425 loss: 5.0850349e-07
Iter: 426 loss: 5.08472567e-07
Iter: 427 loss: 5.07471896e-07
Iter: 428 loss: 5.10288316e-07
Iter: 429 loss: 5.07128e-07
Iter: 430 loss: 5.06438369e-07
Iter: 431 loss: 5.16786258e-07
Iter: 432 loss: 5.06432116e-07
Iter: 433 loss: 5.05743344e-07
Iter: 434 loss: 5.04830837e-07
Iter: 435 loss: 5.0478684e-07
Iter: 436 loss: 5.03668161e-07
Iter: 437 loss: 5.02760145e-07
Iter: 438 loss: 5.02455919e-07
Iter: 439 loss: 5.00803822e-07
Iter: 440 loss: 5.19147704e-07
Iter: 441 loss: 5.00769261e-07
Iter: 442 loss: 4.99666498e-07
Iter: 443 loss: 5.09904e-07
Iter: 444 loss: 4.99626708e-07
Iter: 445 loss: 4.98761e-07
Iter: 446 loss: 4.97074438e-07
Iter: 447 loss: 5.34489288e-07
Iter: 448 loss: 4.97064434e-07
Iter: 449 loss: 4.95812856e-07
Iter: 450 loss: 5.05092771e-07
Iter: 451 loss: 4.95676488e-07
Iter: 452 loss: 4.94381e-07
Iter: 453 loss: 5.03567719e-07
Iter: 454 loss: 4.9428e-07
Iter: 455 loss: 4.93586356e-07
Iter: 456 loss: 4.93489495e-07
Iter: 457 loss: 4.9297546e-07
Iter: 458 loss: 4.92165896e-07
Iter: 459 loss: 4.92160211e-07
Iter: 460 loss: 4.9154005e-07
Iter: 461 loss: 4.90403352e-07
Iter: 462 loss: 5.17514763e-07
Iter: 463 loss: 4.90407e-07
Iter: 464 loss: 4.89178774e-07
Iter: 465 loss: 4.89469e-07
Iter: 466 loss: 4.88299179e-07
Iter: 467 loss: 4.8753833e-07
Iter: 468 loss: 4.87238424e-07
Iter: 469 loss: 4.86759291e-07
Iter: 470 loss: 4.85658802e-07
Iter: 471 loss: 5.01085481e-07
Iter: 472 loss: 4.85611281e-07
Iter: 473 loss: 4.84155521e-07
Iter: 474 loss: 4.88411388e-07
Iter: 475 loss: 4.83728229e-07
Iter: 476 loss: 4.82666394e-07
Iter: 477 loss: 4.89131708e-07
Iter: 478 loss: 4.82547819e-07
Iter: 479 loss: 4.8140771e-07
Iter: 480 loss: 4.86200634e-07
Iter: 481 loss: 4.81161578e-07
Iter: 482 loss: 4.8047e-07
Iter: 483 loss: 4.79831101e-07
Iter: 484 loss: 4.79655228e-07
Iter: 485 loss: 4.78800928e-07
Iter: 486 loss: 4.87331761e-07
Iter: 487 loss: 4.78777e-07
Iter: 488 loss: 4.78012225e-07
Iter: 489 loss: 4.81965174e-07
Iter: 490 loss: 4.77894105e-07
Iter: 491 loss: 4.77170033e-07
Iter: 492 loss: 4.76683311e-07
Iter: 493 loss: 4.76390369e-07
Iter: 494 loss: 4.76101235e-07
Iter: 495 loss: 4.75888442e-07
Iter: 496 loss: 4.75584017e-07
Iter: 497 loss: 4.74635954e-07
Iter: 498 loss: 4.75332342e-07
Iter: 499 loss: 4.7380334e-07
Iter: 500 loss: 4.73353936e-07
Iter: 501 loss: 4.73115222e-07
Iter: 502 loss: 4.72484942e-07
Iter: 503 loss: 4.74346081e-07
Iter: 504 loss: 4.72282352e-07
Iter: 505 loss: 4.71627374e-07
Iter: 506 loss: 4.70330974e-07
Iter: 507 loss: 4.96555572e-07
Iter: 508 loss: 4.70325176e-07
Iter: 509 loss: 4.68946894e-07
Iter: 510 loss: 4.73940361e-07
Iter: 511 loss: 4.68612399e-07
Iter: 512 loss: 4.67920103e-07
Iter: 513 loss: 4.67877385e-07
Iter: 514 loss: 4.67155701e-07
Iter: 515 loss: 4.6581772e-07
Iter: 516 loss: 4.95269489e-07
Iter: 517 loss: 4.65807403e-07
Iter: 518 loss: 4.64638731e-07
Iter: 519 loss: 4.74974428e-07
Iter: 520 loss: 4.64591778e-07
Iter: 521 loss: 4.63895702e-07
Iter: 522 loss: 4.68146936e-07
Iter: 523 loss: 4.63819219e-07
Iter: 524 loss: 4.63130334e-07
Iter: 525 loss: 4.65863252e-07
Iter: 526 loss: 4.62956393e-07
Iter: 527 loss: 4.6249022e-07
Iter: 528 loss: 4.63158898e-07
Iter: 529 loss: 4.62238233e-07
Iter: 530 loss: 4.61336356e-07
Iter: 531 loss: 4.61175773e-07
Iter: 532 loss: 4.6058e-07
Iter: 533 loss: 4.5991942e-07
Iter: 534 loss: 4.61163268e-07
Iter: 535 loss: 4.59655212e-07
Iter: 536 loss: 4.59019049e-07
Iter: 537 loss: 4.62283595e-07
Iter: 538 loss: 4.58930572e-07
Iter: 539 loss: 4.58059e-07
Iter: 540 loss: 4.58504331e-07
Iter: 541 loss: 4.57454064e-07
Iter: 542 loss: 4.56823784e-07
Iter: 543 loss: 4.56563441e-07
Iter: 544 loss: 4.56201917e-07
Iter: 545 loss: 4.55413669e-07
Iter: 546 loss: 4.58455816e-07
Iter: 547 loss: 4.55221596e-07
Iter: 548 loss: 4.54509234e-07
Iter: 549 loss: 4.64452825e-07
Iter: 550 loss: 4.54508609e-07
Iter: 551 loss: 4.54024786e-07
Iter: 552 loss: 4.5396e-07
Iter: 553 loss: 4.5362242e-07
Iter: 554 loss: 4.52961672e-07
Iter: 555 loss: 4.52738476e-07
Iter: 556 loss: 4.52365043e-07
Iter: 557 loss: 4.5176148e-07
Iter: 558 loss: 4.51718449e-07
Iter: 559 loss: 4.51191909e-07
Iter: 560 loss: 4.50682222e-07
Iter: 561 loss: 4.50587891e-07
Iter: 562 loss: 4.50009082e-07
Iter: 563 loss: 4.49992058e-07
Iter: 564 loss: 4.49545126e-07
Iter: 565 loss: 4.48939119e-07
Iter: 566 loss: 4.48916e-07
Iter: 567 loss: 4.48063474e-07
Iter: 568 loss: 4.47620465e-07
Iter: 569 loss: 4.47206105e-07
Iter: 570 loss: 4.46622494e-07
Iter: 571 loss: 4.4659987e-07
Iter: 572 loss: 4.46001536e-07
Iter: 573 loss: 4.48082687e-07
Iter: 574 loss: 4.45822877e-07
Iter: 575 loss: 4.45481646e-07
Iter: 576 loss: 4.44883852e-07
Iter: 577 loss: 4.44888542e-07
Iter: 578 loss: 4.44074942e-07
Iter: 579 loss: 4.46098397e-07
Iter: 580 loss: 4.43772763e-07
Iter: 581 loss: 4.4309914e-07
Iter: 582 loss: 4.50436914e-07
Iter: 583 loss: 4.43085725e-07
Iter: 584 loss: 4.42343833e-07
Iter: 585 loss: 4.4247065e-07
Iter: 586 loss: 4.41781708e-07
Iter: 587 loss: 4.41186273e-07
Iter: 588 loss: 4.41154157e-07
Iter: 589 loss: 4.40689291e-07
Iter: 590 loss: 4.40112331e-07
Iter: 591 loss: 4.40073791e-07
Iter: 592 loss: 4.39579594e-07
Iter: 593 loss: 4.38794643e-07
Iter: 594 loss: 4.38775402e-07
Iter: 595 loss: 4.38078359e-07
Iter: 596 loss: 4.38065058e-07
Iter: 597 loss: 4.37708195e-07
Iter: 598 loss: 4.37537153e-07
Iter: 599 loss: 4.37352412e-07
Iter: 600 loss: 4.36910113e-07
Iter: 601 loss: 4.35990785e-07
Iter: 602 loss: 4.53055549e-07
Iter: 603 loss: 4.35971458e-07
Iter: 604 loss: 4.36076817e-07
Iter: 605 loss: 4.3555346e-07
Iter: 606 loss: 4.35129493e-07
Iter: 607 loss: 4.34664827e-07
Iter: 608 loss: 4.34595961e-07
Iter: 609 loss: 4.33889284e-07
Iter: 610 loss: 4.34435179e-07
Iter: 611 loss: 4.33462816e-07
Iter: 612 loss: 4.32686363e-07
Iter: 613 loss: 4.33034018e-07
Iter: 614 loss: 4.32159084e-07
Iter: 615 loss: 4.313207e-07
Iter: 616 loss: 4.43697274e-07
Iter: 617 loss: 4.31327351e-07
Iter: 618 loss: 4.3070122e-07
Iter: 619 loss: 4.34988664e-07
Iter: 620 loss: 4.30658133e-07
Iter: 621 loss: 4.30315481e-07
Iter: 622 loss: 4.30275946e-07
Iter: 623 loss: 4.30028422e-07
Iter: 624 loss: 4.29582883e-07
Iter: 625 loss: 4.30912337e-07
Iter: 626 loss: 4.29459135e-07
Iter: 627 loss: 4.28828287e-07
Iter: 628 loss: 4.31084345e-07
Iter: 629 loss: 4.28693738e-07
Iter: 630 loss: 4.28374449e-07
Iter: 631 loss: 4.3050207e-07
Iter: 632 loss: 4.28345459e-07
Iter: 633 loss: 4.27997463e-07
Iter: 634 loss: 4.2718105e-07
Iter: 635 loss: 4.37364179e-07
Iter: 636 loss: 4.27103146e-07
Iter: 637 loss: 4.2618467e-07
Iter: 638 loss: 4.28847102e-07
Iter: 639 loss: 4.25873623e-07
Iter: 640 loss: 4.24977799e-07
Iter: 641 loss: 4.26190354e-07
Iter: 642 loss: 4.24487837e-07
Iter: 643 loss: 4.24379778e-07
Iter: 644 loss: 4.24005094e-07
Iter: 645 loss: 4.23718177e-07
Iter: 646 loss: 4.23074056e-07
Iter: 647 loss: 4.31665654e-07
Iter: 648 loss: 4.2302247e-07
Iter: 649 loss: 4.22496328e-07
Iter: 650 loss: 4.25131446e-07
Iter: 651 loss: 4.22394351e-07
Iter: 652 loss: 4.21904417e-07
Iter: 653 loss: 4.22850349e-07
Iter: 654 loss: 4.21692391e-07
Iter: 655 loss: 4.21227469e-07
Iter: 656 loss: 4.28276394e-07
Iter: 657 loss: 4.21223689e-07
Iter: 658 loss: 4.20834624e-07
Iter: 659 loss: 4.20403637e-07
Iter: 660 loss: 4.20333492e-07
Iter: 661 loss: 4.19840234e-07
Iter: 662 loss: 4.24321115e-07
Iter: 663 loss: 4.19833356e-07
Iter: 664 loss: 4.19312755e-07
Iter: 665 loss: 4.19908787e-07
Iter: 666 loss: 4.19035757e-07
Iter: 667 loss: 4.18466186e-07
Iter: 668 loss: 4.19889574e-07
Iter: 669 loss: 4.18259162e-07
Iter: 670 loss: 4.17746492e-07
Iter: 671 loss: 4.20896924e-07
Iter: 672 loss: 4.17661909e-07
Iter: 673 loss: 4.17317437e-07
Iter: 674 loss: 4.16420647e-07
Iter: 675 loss: 4.23013176e-07
Iter: 676 loss: 4.1618938e-07
Iter: 677 loss: 4.15329282e-07
Iter: 678 loss: 4.26528601e-07
Iter: 679 loss: 4.15324791e-07
Iter: 680 loss: 4.14688202e-07
Iter: 681 loss: 4.16127e-07
Iter: 682 loss: 4.14477029e-07
Iter: 683 loss: 4.14026488e-07
Iter: 684 loss: 4.1403095e-07
Iter: 685 loss: 4.13534138e-07
Iter: 686 loss: 4.1330091e-07
Iter: 687 loss: 4.13091414e-07
Iter: 688 loss: 4.12655254e-07
Iter: 689 loss: 4.12363903e-07
Iter: 690 loss: 4.12218384e-07
Iter: 691 loss: 4.1160834e-07
Iter: 692 loss: 4.19884742e-07
Iter: 693 loss: 4.1159791e-07
Iter: 694 loss: 4.11096266e-07
Iter: 695 loss: 4.11935616e-07
Iter: 696 loss: 4.10866278e-07
Iter: 697 loss: 4.10391436e-07
Iter: 698 loss: 4.10227187e-07
Iter: 699 loss: 4.09966532e-07
Iter: 700 loss: 4.09618735e-07
Iter: 701 loss: 4.0959921e-07
Iter: 702 loss: 4.09218e-07
Iter: 703 loss: 4.09531339e-07
Iter: 704 loss: 4.08986438e-07
Iter: 705 loss: 4.0863e-07
Iter: 706 loss: 4.10127825e-07
Iter: 707 loss: 4.08548829e-07
Iter: 708 loss: 4.0815911e-07
Iter: 709 loss: 4.0853098e-07
Iter: 710 loss: 4.07935744e-07
Iter: 711 loss: 4.07484407e-07
Iter: 712 loss: 4.06882464e-07
Iter: 713 loss: 4.06827837e-07
Iter: 714 loss: 4.06143954e-07
Iter: 715 loss: 4.06550186e-07
Iter: 716 loss: 4.05683352e-07
Iter: 717 loss: 4.0503005e-07
Iter: 718 loss: 4.05016522e-07
Iter: 719 loss: 4.04681458e-07
Iter: 720 loss: 4.0468035e-07
Iter: 721 loss: 4.04415061e-07
Iter: 722 loss: 4.03918961e-07
Iter: 723 loss: 4.14738679e-07
Iter: 724 loss: 4.03898298e-07
Iter: 725 loss: 4.03358598e-07
Iter: 726 loss: 4.03483426e-07
Iter: 727 loss: 4.02972688e-07
Iter: 728 loss: 4.02771377e-07
Iter: 729 loss: 4.02641547e-07
Iter: 730 loss: 4.02358694e-07
Iter: 731 loss: 4.02094628e-07
Iter: 732 loss: 4.02034289e-07
Iter: 733 loss: 4.01622799e-07
Iter: 734 loss: 4.02404339e-07
Iter: 735 loss: 4.01455509e-07
Iter: 736 loss: 4.01075397e-07
Iter: 737 loss: 4.01078637e-07
Iter: 738 loss: 4.0079783e-07
Iter: 739 loss: 4.00443241e-07
Iter: 740 loss: 4.00420532e-07
Iter: 741 loss: 4.00054716e-07
Iter: 742 loss: 4.05470189e-07
Iter: 743 loss: 4.0006978e-07
Iter: 744 loss: 3.99770471e-07
Iter: 745 loss: 3.9915534e-07
Iter: 746 loss: 4.0834783e-07
Iter: 747 loss: 3.99132688e-07
Iter: 748 loss: 3.9855297e-07
Iter: 749 loss: 4.02732297e-07
Iter: 750 loss: 3.9849624e-07
Iter: 751 loss: 3.98045813e-07
Iter: 752 loss: 3.9808441e-07
Iter: 753 loss: 3.97720754e-07
Iter: 754 loss: 3.97515322e-07
Iter: 755 loss: 3.97381285e-07
Iter: 756 loss: 3.97145726e-07
Iter: 757 loss: 3.96867e-07
Iter: 758 loss: 3.96828739e-07
Iter: 759 loss: 3.96477617e-07
Iter: 760 loss: 3.96473695e-07
Iter: 761 loss: 3.96179871e-07
Iter: 762 loss: 3.95686641e-07
Iter: 763 loss: 3.99163355e-07
Iter: 764 loss: 3.95644207e-07
Iter: 765 loss: 3.95179029e-07
Iter: 766 loss: 3.95715659e-07
Iter: 767 loss: 3.94912746e-07
Iter: 768 loss: 3.9457575e-07
Iter: 769 loss: 3.94529707e-07
Iter: 770 loss: 3.94285962e-07
Iter: 771 loss: 3.94077773e-07
Iter: 772 loss: 3.93999471e-07
Iter: 773 loss: 3.93812627e-07
Iter: 774 loss: 3.93675975e-07
Iter: 775 loss: 3.93603727e-07
Iter: 776 loss: 3.93375331e-07
Iter: 777 loss: 3.94350195e-07
Iter: 778 loss: 3.93312234e-07
Iter: 779 loss: 3.92959379e-07
Iter: 780 loss: 3.92691931e-07
Iter: 781 loss: 3.92568381e-07
Iter: 782 loss: 3.92082285e-07
Iter: 783 loss: 3.91901551e-07
Iter: 784 loss: 3.91630067e-07
Iter: 785 loss: 3.91076441e-07
Iter: 786 loss: 3.97836402e-07
Iter: 787 loss: 3.91066209e-07
Iter: 788 loss: 3.90782134e-07
Iter: 789 loss: 3.93735661e-07
Iter: 790 loss: 3.90779462e-07
Iter: 791 loss: 3.90394291e-07
Iter: 792 loss: 3.89982119e-07
Iter: 793 loss: 3.89936588e-07
Iter: 794 loss: 3.89557869e-07
Iter: 795 loss: 3.90446615e-07
Iter: 796 loss: 3.89400498e-07
Iter: 797 loss: 3.891208e-07
Iter: 798 loss: 3.89122334e-07
Iter: 799 loss: 3.88864834e-07
Iter: 800 loss: 3.88699618e-07
Iter: 801 loss: 3.8860307e-07
Iter: 802 loss: 3.88191523e-07
Iter: 803 loss: 3.88565866e-07
Iter: 804 loss: 3.87951644e-07
Iter: 805 loss: 3.87894318e-07
Iter: 806 loss: 3.87772673e-07
Iter: 807 loss: 3.875993e-07
Iter: 808 loss: 3.87134662e-07
Iter: 809 loss: 3.89362015e-07
Iter: 810 loss: 3.86998465e-07
Iter: 811 loss: 3.86546134e-07
Iter: 812 loss: 3.86529138e-07
Iter: 813 loss: 3.86188248e-07
Iter: 814 loss: 3.86139192e-07
Iter: 815 loss: 3.85903149e-07
Iter: 816 loss: 3.85520167e-07
Iter: 817 loss: 3.86042529e-07
Iter: 818 loss: 3.85344549e-07
Iter: 819 loss: 3.84990244e-07
Iter: 820 loss: 3.85224666e-07
Iter: 821 loss: 3.84761677e-07
Iter: 822 loss: 3.84511679e-07
Iter: 823 loss: 3.84483968e-07
Iter: 824 loss: 3.84223142e-07
Iter: 825 loss: 3.84036838e-07
Iter: 826 loss: 3.83940289e-07
Iter: 827 loss: 3.83615202e-07
Iter: 828 loss: 3.83910219e-07
Iter: 829 loss: 3.83414147e-07
Iter: 830 loss: 3.83049496e-07
Iter: 831 loss: 3.85007638e-07
Iter: 832 loss: 3.83014481e-07
Iter: 833 loss: 3.82553026e-07
Iter: 834 loss: 3.82812061e-07
Iter: 835 loss: 3.82244e-07
Iter: 836 loss: 3.81808917e-07
Iter: 837 loss: 3.82004373e-07
Iter: 838 loss: 3.81503469e-07
Iter: 839 loss: 3.81335155e-07
Iter: 840 loss: 3.81238181e-07
Iter: 841 loss: 3.81030361e-07
Iter: 842 loss: 3.80862332e-07
Iter: 843 loss: 3.80810775e-07
Iter: 844 loss: 3.80567428e-07
Iter: 845 loss: 3.80937877e-07
Iter: 846 loss: 3.80426968e-07
Iter: 847 loss: 3.80066837e-07
Iter: 848 loss: 3.8177086e-07
Iter: 849 loss: 3.8000087e-07
Iter: 850 loss: 3.79800952e-07
Iter: 851 loss: 3.79398898e-07
Iter: 852 loss: 3.86383192e-07
Iter: 853 loss: 3.79393e-07
Iter: 854 loss: 3.78904019e-07
Iter: 855 loss: 3.81096e-07
Iter: 856 loss: 3.78825803e-07
Iter: 857 loss: 3.78417354e-07
Iter: 858 loss: 3.8348162e-07
Iter: 859 loss: 3.78411471e-07
Iter: 860 loss: 3.78071547e-07
Iter: 861 loss: 3.7907526e-07
Iter: 862 loss: 3.77982843e-07
Iter: 863 loss: 3.77700985e-07
Iter: 864 loss: 3.77049901e-07
Iter: 865 loss: 3.84412488e-07
Iter: 866 loss: 3.76988709e-07
Iter: 867 loss: 3.76528817e-07
Iter: 868 loss: 3.76490533e-07
Iter: 869 loss: 3.76204042e-07
Iter: 870 loss: 3.79171524e-07
Iter: 871 loss: 3.76208192e-07
Iter: 872 loss: 3.75998354e-07
Iter: 873 loss: 3.75759e-07
Iter: 874 loss: 3.75740569e-07
Iter: 875 loss: 3.75378534e-07
Iter: 876 loss: 3.75429238e-07
Iter: 877 loss: 3.75117594e-07
Iter: 878 loss: 3.74787248e-07
Iter: 879 loss: 3.78504581e-07
Iter: 880 loss: 3.74793814e-07
Iter: 881 loss: 3.74394517e-07
Iter: 882 loss: 3.75357956e-07
Iter: 883 loss: 3.74235071e-07
Iter: 884 loss: 3.74019635e-07
Iter: 885 loss: 3.73853197e-07
Iter: 886 loss: 3.73799821e-07
Iter: 887 loss: 3.73439718e-07
Iter: 888 loss: 3.75571517e-07
Iter: 889 loss: 3.73369204e-07
Iter: 890 loss: 3.72983948e-07
Iter: 891 loss: 3.7389691e-07
Iter: 892 loss: 3.7283354e-07
Iter: 893 loss: 3.72576352e-07
Iter: 894 loss: 3.72198656e-07
Iter: 895 loss: 3.72190641e-07
Iter: 896 loss: 3.71971709e-07
Iter: 897 loss: 3.71944964e-07
Iter: 898 loss: 3.71638833e-07
Iter: 899 loss: 3.71455855e-07
Iter: 900 loss: 3.71348165e-07
Iter: 901 loss: 3.71019098e-07
Iter: 902 loss: 3.71098395e-07
Iter: 903 loss: 3.70784676e-07
Iter: 904 loss: 3.70388136e-07
Iter: 905 loss: 3.7219138e-07
Iter: 906 loss: 3.70325608e-07
Iter: 907 loss: 3.700344e-07
Iter: 908 loss: 3.72979741e-07
Iter: 909 loss: 3.70030705e-07
Iter: 910 loss: 3.69700331e-07
Iter: 911 loss: 3.69386072e-07
Iter: 912 loss: 3.69335908e-07
Iter: 913 loss: 3.69068715e-07
Iter: 914 loss: 3.69778945e-07
Iter: 915 loss: 3.69002322e-07
Iter: 916 loss: 3.68801352e-07
Iter: 917 loss: 3.68783049e-07
Iter: 918 loss: 3.68650319e-07
Iter: 919 loss: 3.68459382e-07
Iter: 920 loss: 3.68434939e-07
Iter: 921 loss: 3.68187671e-07
Iter: 922 loss: 3.68178405e-07
Iter: 923 loss: 3.68002759e-07
Iter: 924 loss: 3.67727921e-07
Iter: 925 loss: 3.72405964e-07
Iter: 926 loss: 3.67707685e-07
Iter: 927 loss: 3.67462064e-07
Iter: 928 loss: 3.67134021e-07
Iter: 929 loss: 3.67115575e-07
Iter: 930 loss: 3.66747e-07
Iter: 931 loss: 3.68837e-07
Iter: 932 loss: 3.66718552e-07
Iter: 933 loss: 3.66469123e-07
Iter: 934 loss: 3.69208465e-07
Iter: 935 loss: 3.66464747e-07
Iter: 936 loss: 3.66200766e-07
Iter: 937 loss: 3.65690028e-07
Iter: 938 loss: 3.75681168e-07
Iter: 939 loss: 3.65698497e-07
Iter: 940 loss: 3.65312019e-07
Iter: 941 loss: 3.65743517e-07
Iter: 942 loss: 3.65116449e-07
Iter: 943 loss: 3.64691459e-07
Iter: 944 loss: 3.66810411e-07
Iter: 945 loss: 3.64629841e-07
Iter: 946 loss: 3.64334198e-07
Iter: 947 loss: 3.6433164e-07
Iter: 948 loss: 3.64090283e-07
Iter: 949 loss: 3.64023464e-07
Iter: 950 loss: 3.63903638e-07
Iter: 951 loss: 3.63646e-07
Iter: 952 loss: 3.65467457e-07
Iter: 953 loss: 3.63606148e-07
Iter: 954 loss: 3.63319486e-07
Iter: 955 loss: 3.63631955e-07
Iter: 956 loss: 3.63148644e-07
Iter: 957 loss: 3.62942558e-07
Iter: 958 loss: 3.62535e-07
Iter: 959 loss: 3.7129098e-07
Iter: 960 loss: 3.6253752e-07
Iter: 961 loss: 3.62306821e-07
Iter: 962 loss: 3.62291246e-07
Iter: 963 loss: 3.61997195e-07
Iter: 964 loss: 3.62468313e-07
Iter: 965 loss: 3.61873958e-07
Iter: 966 loss: 3.61568311e-07
Iter: 967 loss: 3.61694049e-07
Iter: 968 loss: 3.61361117e-07
Iter: 969 loss: 3.61199568e-07
Iter: 970 loss: 3.61178053e-07
Iter: 971 loss: 3.60999877e-07
Iter: 972 loss: 3.60677461e-07
Iter: 973 loss: 3.68738938e-07
Iter: 974 loss: 3.60684112e-07
Iter: 975 loss: 3.60328585e-07
Iter: 976 loss: 3.6011329e-07
Iter: 977 loss: 3.59961518e-07
Iter: 978 loss: 3.59463741e-07
Iter: 979 loss: 3.62575747e-07
Iter: 980 loss: 3.59420682e-07
Iter: 981 loss: 3.59057026e-07
Iter: 982 loss: 3.61952971e-07
Iter: 983 loss: 3.59043952e-07
Iter: 984 loss: 3.58839458e-07
Iter: 985 loss: 3.58829709e-07
Iter: 986 loss: 3.58699509e-07
Iter: 987 loss: 3.58413359e-07
Iter: 988 loss: 3.63953404e-07
Iter: 989 loss: 3.58408442e-07
Iter: 990 loss: 3.58142302e-07
Iter: 991 loss: 3.58134088e-07
Iter: 992 loss: 3.58035379e-07
Iter: 993 loss: 3.57844442e-07
Iter: 994 loss: 3.5784808e-07
Iter: 995 loss: 3.57596292e-07
Iter: 996 loss: 3.57306902e-07
Iter: 997 loss: 3.57250883e-07
Iter: 998 loss: 3.56783858e-07
Iter: 999 loss: 3.58509908e-07
Iter: 1000 loss: 3.56678868e-07
Iter: 1001 loss: 3.56298415e-07
Iter: 1002 loss: 3.56285739e-07
Iter: 1003 loss: 3.5610725e-07
Iter: 1004 loss: 3.55755503e-07
Iter: 1005 loss: 3.63762837e-07
Iter: 1006 loss: 3.55771419e-07
Iter: 1007 loss: 3.55385907e-07
Iter: 1008 loss: 3.57120882e-07
Iter: 1009 loss: 3.55309822e-07
Iter: 1010 loss: 3.5509413e-07
Iter: 1011 loss: 3.55096375e-07
Iter: 1012 loss: 3.54895633e-07
Iter: 1013 loss: 3.54754889e-07
Iter: 1014 loss: 3.54658169e-07
Iter: 1015 loss: 3.54434519e-07
Iter: 1016 loss: 3.54016748e-07
Iter: 1017 loss: 3.54024053e-07
Iter: 1018 loss: 3.5377397e-07
Iter: 1019 loss: 3.53735231e-07
Iter: 1020 loss: 3.53473979e-07
Iter: 1021 loss: 3.54026156e-07
Iter: 1022 loss: 3.53382802e-07
Iter: 1023 loss: 3.53125586e-07
Iter: 1024 loss: 3.5347864e-07
Iter: 1025 loss: 3.529845e-07
Iter: 1026 loss: 3.52693263e-07
Iter: 1027 loss: 3.55247039e-07
Iter: 1028 loss: 3.52698464e-07
Iter: 1029 loss: 3.52524296e-07
Iter: 1030 loss: 3.52180962e-07
Iter: 1031 loss: 3.57265719e-07
Iter: 1032 loss: 3.52181303e-07
Iter: 1033 loss: 3.51815459e-07
Iter: 1034 loss: 3.5356868e-07
Iter: 1035 loss: 3.51764015e-07
Iter: 1036 loss: 3.51452087e-07
Iter: 1037 loss: 3.52489678e-07
Iter: 1038 loss: 3.5137e-07
Iter: 1039 loss: 3.51147975e-07
Iter: 1040 loss: 3.52465747e-07
Iter: 1041 loss: 3.51107559e-07
Iter: 1042 loss: 3.50822063e-07
Iter: 1043 loss: 3.50989893e-07
Iter: 1044 loss: 3.50636356e-07
Iter: 1045 loss: 3.50385761e-07
Iter: 1046 loss: 3.50862138e-07
Iter: 1047 loss: 3.50294385e-07
Iter: 1048 loss: 3.50019775e-07
Iter: 1049 loss: 3.52806353e-07
Iter: 1050 loss: 3.50000278e-07
Iter: 1051 loss: 3.49761933e-07
Iter: 1052 loss: 3.49343622e-07
Iter: 1053 loss: 3.49352575e-07
Iter: 1054 loss: 3.48920452e-07
Iter: 1055 loss: 3.49880423e-07
Iter: 1056 loss: 3.48759329e-07
Iter: 1057 loss: 3.48709875e-07
Iter: 1058 loss: 3.48589595e-07
Iter: 1059 loss: 3.48471161e-07
Iter: 1060 loss: 3.48198853e-07
Iter: 1061 loss: 3.53912441e-07
Iter: 1062 loss: 3.48212865e-07
Iter: 1063 loss: 3.47918245e-07
Iter: 1064 loss: 3.47933e-07
Iter: 1065 loss: 3.47816666e-07
Iter: 1066 loss: 3.47617174e-07
Iter: 1067 loss: 3.47607653e-07
Iter: 1068 loss: 3.47387243e-07
Iter: 1069 loss: 3.47680214e-07
Iter: 1070 loss: 3.47274238e-07
Iter: 1071 loss: 3.46971802e-07
Iter: 1072 loss: 3.46675904e-07
Iter: 1073 loss: 3.46609283e-07
Iter: 1074 loss: 3.46377362e-07
Iter: 1075 loss: 3.4631816e-07
Iter: 1076 loss: 3.46067139e-07
Iter: 1077 loss: 3.46657515e-07
Iter: 1078 loss: 3.4598736e-07
Iter: 1079 loss: 3.45758281e-07
Iter: 1080 loss: 3.4573344e-07
Iter: 1081 loss: 3.4557911e-07
Iter: 1082 loss: 3.45307342e-07
Iter: 1083 loss: 3.48169635e-07
Iter: 1084 loss: 3.45313822e-07
Iter: 1085 loss: 3.45026876e-07
Iter: 1086 loss: 3.4506067e-07
Iter: 1087 loss: 3.44828038e-07
Iter: 1088 loss: 3.44643695e-07
Iter: 1089 loss: 3.44304226e-07
Iter: 1090 loss: 3.44301952e-07
Iter: 1091 loss: 3.4400955e-07
Iter: 1092 loss: 3.43995282e-07
Iter: 1093 loss: 3.4379616e-07
Iter: 1094 loss: 3.45394369e-07
Iter: 1095 loss: 3.43762736e-07
Iter: 1096 loss: 3.43621537e-07
Iter: 1097 loss: 3.43483066e-07
Iter: 1098 loss: 3.4343509e-07
Iter: 1099 loss: 3.43142517e-07
Iter: 1100 loss: 3.45065473e-07
Iter: 1101 loss: 3.43126317e-07
Iter: 1102 loss: 3.42947573e-07
Iter: 1103 loss: 3.42577664e-07
Iter: 1104 loss: 3.49563e-07
Iter: 1105 loss: 3.42584173e-07
Iter: 1106 loss: 3.422291e-07
Iter: 1107 loss: 3.43232955e-07
Iter: 1108 loss: 3.4211115e-07
Iter: 1109 loss: 3.4177711e-07
Iter: 1110 loss: 3.45449564e-07
Iter: 1111 loss: 3.41781544e-07
Iter: 1112 loss: 3.4158586e-07
Iter: 1113 loss: 3.43580183e-07
Iter: 1114 loss: 3.4157506e-07
Iter: 1115 loss: 3.41445514e-07
Iter: 1116 loss: 3.41260943e-07
Iter: 1117 loss: 3.41243663e-07
Iter: 1118 loss: 3.41107409e-07
Iter: 1119 loss: 3.41093852e-07
Iter: 1120 loss: 3.40925851e-07
Iter: 1121 loss: 3.40633733e-07
Iter: 1122 loss: 3.47932968e-07
Iter: 1123 loss: 3.40633e-07
Iter: 1124 loss: 3.40313647e-07
Iter: 1125 loss: 3.41528448e-07
Iter: 1126 loss: 3.40210505e-07
Iter: 1127 loss: 3.39934132e-07
Iter: 1128 loss: 3.40419035e-07
Iter: 1129 loss: 3.39830677e-07
Iter: 1130 loss: 3.39431892e-07
Iter: 1131 loss: 3.42622968e-07
Iter: 1132 loss: 3.39413617e-07
Iter: 1133 loss: 3.39251557e-07
Iter: 1134 loss: 3.39459973e-07
Iter: 1135 loss: 3.39178371e-07
Iter: 1136 loss: 3.3895256e-07
Iter: 1137 loss: 3.39341568e-07
Iter: 1138 loss: 3.38847371e-07
Iter: 1139 loss: 3.38643247e-07
Iter: 1140 loss: 3.38533965e-07
Iter: 1141 loss: 3.3845771e-07
Iter: 1142 loss: 3.3820433e-07
Iter: 1143 loss: 3.39039445e-07
Iter: 1144 loss: 3.381368e-07
Iter: 1145 loss: 3.37912496e-07
Iter: 1146 loss: 3.37787668e-07
Iter: 1147 loss: 3.37692541e-07
Iter: 1148 loss: 3.37358586e-07
Iter: 1149 loss: 3.40339454e-07
Iter: 1150 loss: 3.37345512e-07
Iter: 1151 loss: 3.37081218e-07
Iter: 1152 loss: 3.39837328e-07
Iter: 1153 loss: 3.37066695e-07
Iter: 1154 loss: 3.36869419e-07
Iter: 1155 loss: 3.36838866e-07
Iter: 1156 loss: 3.36721314e-07
Iter: 1157 loss: 3.3653447e-07
Iter: 1158 loss: 3.38099539e-07
Iter: 1159 loss: 3.36526625e-07
Iter: 1160 loss: 3.36303088e-07
Iter: 1161 loss: 3.36360472e-07
Iter: 1162 loss: 3.36120365e-07
Iter: 1163 loss: 3.35938694e-07
Iter: 1164 loss: 3.3578462e-07
Iter: 1165 loss: 3.35723456e-07
Iter: 1166 loss: 3.355876e-07
Iter: 1167 loss: 3.35541472e-07
Iter: 1168 loss: 3.35386801e-07
Iter: 1169 loss: 3.35424318e-07
Iter: 1170 loss: 3.35290395e-07
Iter: 1171 loss: 3.35092352e-07
Iter: 1172 loss: 3.34850597e-07
Iter: 1173 loss: 3.34830872e-07
Iter: 1174 loss: 3.34607478e-07
Iter: 1175 loss: 3.34595825e-07
Iter: 1176 loss: 3.34423703e-07
Iter: 1177 loss: 3.34183824e-07
Iter: 1178 loss: 3.40187967e-07
Iter: 1179 loss: 3.34187604e-07
Iter: 1180 loss: 3.33879257e-07
Iter: 1181 loss: 3.34984122e-07
Iter: 1182 loss: 3.3380195e-07
Iter: 1183 loss: 3.33531915e-07
Iter: 1184 loss: 3.33657567e-07
Iter: 1185 loss: 3.33348112e-07
Iter: 1186 loss: 3.33103628e-07
Iter: 1187 loss: 3.35552841e-07
Iter: 1188 loss: 3.33097603e-07
Iter: 1189 loss: 3.32880063e-07
Iter: 1190 loss: 3.34527158e-07
Iter: 1191 loss: 3.32865142e-07
Iter: 1192 loss: 3.32726046e-07
Iter: 1193 loss: 3.3245658e-07
Iter: 1194 loss: 3.32457716e-07
Iter: 1195 loss: 3.32225625e-07
Iter: 1196 loss: 3.35952421e-07
Iter: 1197 loss: 3.32233014e-07
Iter: 1198 loss: 3.32019397e-07
Iter: 1199 loss: 3.32778029e-07
Iter: 1200 loss: 3.31979322e-07
Iter: 1201 loss: 3.31823173e-07
Iter: 1202 loss: 3.314222e-07
Iter: 1203 loss: 3.35122365e-07
Iter: 1204 loss: 3.31382779e-07
Iter: 1205 loss: 3.31526792e-07
Iter: 1206 loss: 3.31211197e-07
Iter: 1207 loss: 3.3107159e-07
Iter: 1208 loss: 3.30763697e-07
Iter: 1209 loss: 3.35495656e-07
Iter: 1210 loss: 3.30760031e-07
Iter: 1211 loss: 3.30442049e-07
Iter: 1212 loss: 3.32119725e-07
Iter: 1213 loss: 3.30406579e-07
Iter: 1214 loss: 3.30225106e-07
Iter: 1215 loss: 3.30232581e-07
Iter: 1216 loss: 3.30114659e-07
Iter: 1217 loss: 3.29993554e-07
Iter: 1218 loss: 3.29982754e-07
Iter: 1219 loss: 3.29801907e-07
Iter: 1220 loss: 3.29667046e-07
Iter: 1221 loss: 3.29587579e-07
Iter: 1222 loss: 3.29336387e-07
Iter: 1223 loss: 3.31630929e-07
Iter: 1224 loss: 3.29327293e-07
Iter: 1225 loss: 3.29103557e-07
Iter: 1226 loss: 3.29179784e-07
Iter: 1227 loss: 3.28962983e-07
Iter: 1228 loss: 3.28752691e-07
Iter: 1229 loss: 3.31514968e-07
Iter: 1230 loss: 3.28744193e-07
Iter: 1231 loss: 3.28535123e-07
Iter: 1232 loss: 3.28649833e-07
Iter: 1233 loss: 3.28369424e-07
Iter: 1234 loss: 3.28223564e-07
Iter: 1235 loss: 3.29628733e-07
Iter: 1236 loss: 3.28242834e-07
Iter: 1237 loss: 3.28098395e-07
Iter: 1238 loss: 3.28054938e-07
Iter: 1239 loss: 3.27963818e-07
Iter: 1240 loss: 3.27777826e-07
Iter: 1241 loss: 3.27593256e-07
Iter: 1242 loss: 3.27537379e-07
Iter: 1243 loss: 3.27457286e-07
Iter: 1244 loss: 3.27397856e-07
Iter: 1245 loss: 3.27257226e-07
Iter: 1246 loss: 3.27005296e-07
Iter: 1247 loss: 3.31609272e-07
Iter: 1248 loss: 3.26992875e-07
Iter: 1249 loss: 3.26759334e-07
Iter: 1250 loss: 3.27120574e-07
Iter: 1251 loss: 3.2666091e-07
Iter: 1252 loss: 3.2629589e-07
Iter: 1253 loss: 3.29033071e-07
Iter: 1254 loss: 3.2626275e-07
Iter: 1255 loss: 3.26139684e-07
Iter: 1256 loss: 3.25827102e-07
Iter: 1257 loss: 3.30015439e-07
Iter: 1258 loss: 3.25819428e-07
Iter: 1259 loss: 3.25496387e-07
Iter: 1260 loss: 3.27693357e-07
Iter: 1261 loss: 3.25455034e-07
Iter: 1262 loss: 3.25202876e-07
Iter: 1263 loss: 3.26450163e-07
Iter: 1264 loss: 3.25160386e-07
Iter: 1265 loss: 3.24984683e-07
Iter: 1266 loss: 3.25586228e-07
Iter: 1267 loss: 3.24940601e-07
Iter: 1268 loss: 3.24705354e-07
Iter: 1269 loss: 3.25375e-07
Iter: 1270 loss: 3.24628104e-07
Iter: 1271 loss: 3.24444187e-07
Iter: 1272 loss: 3.24547159e-07
Iter: 1273 loss: 3.24307393e-07
Iter: 1274 loss: 3.24122539e-07
Iter: 1275 loss: 3.26069085e-07
Iter: 1276 loss: 3.24110374e-07
Iter: 1277 loss: 3.23914833e-07
Iter: 1278 loss: 3.24046084e-07
Iter: 1279 loss: 3.23786082e-07
Iter: 1280 loss: 3.23635845e-07
Iter: 1281 loss: 3.2372418e-07
Iter: 1282 loss: 3.23531196e-07
Iter: 1283 loss: 3.23310445e-07
Iter: 1284 loss: 3.25378892e-07
Iter: 1285 loss: 3.23301094e-07
Iter: 1286 loss: 3.23195792e-07
Iter: 1287 loss: 3.22999313e-07
Iter: 1288 loss: 3.23000506e-07
Iter: 1289 loss: 3.22765715e-07
Iter: 1290 loss: 3.2313e-07
Iter: 1291 loss: 3.22648305e-07
Iter: 1292 loss: 3.22484823e-07
Iter: 1293 loss: 3.24513195e-07
Iter: 1294 loss: 3.22472829e-07
Iter: 1295 loss: 3.22266771e-07
Iter: 1296 loss: 3.22271546e-07
Iter: 1297 loss: 3.22092433e-07
Iter: 1298 loss: 3.21850962e-07
Iter: 1299 loss: 3.21618984e-07
Iter: 1300 loss: 3.21559e-07
Iter: 1301 loss: 3.21307652e-07
Iter: 1302 loss: 3.24098494e-07
Iter: 1303 loss: 3.21291907e-07
Iter: 1304 loss: 3.21053136e-07
Iter: 1305 loss: 3.21201071e-07
Iter: 1306 loss: 3.20885306e-07
Iter: 1307 loss: 3.20822949e-07
Iter: 1308 loss: 3.2076872e-07
Iter: 1309 loss: 3.20635507e-07
Iter: 1310 loss: 3.20474328e-07
Iter: 1311 loss: 3.2046529e-07
Iter: 1312 loss: 3.20308089e-07
Iter: 1313 loss: 3.21657751e-07
Iter: 1314 loss: 3.20316445e-07
Iter: 1315 loss: 3.20142021e-07
Iter: 1316 loss: 3.20296579e-07
Iter: 1317 loss: 3.20023105e-07
Iter: 1318 loss: 3.19856042e-07
Iter: 1319 loss: 3.2062394e-07
Iter: 1320 loss: 3.19831543e-07
Iter: 1321 loss: 3.19679543e-07
Iter: 1322 loss: 3.20417939e-07
Iter: 1323 loss: 3.19637309e-07
Iter: 1324 loss: 3.1953067e-07
Iter: 1325 loss: 3.19255662e-07
Iter: 1326 loss: 3.22829464e-07
Iter: 1327 loss: 3.19230651e-07
Iter: 1328 loss: 3.18931654e-07
Iter: 1329 loss: 3.20723927e-07
Iter: 1330 loss: 3.18898259e-07
Iter: 1331 loss: 3.18592356e-07
Iter: 1332 loss: 3.2082869e-07
Iter: 1333 loss: 3.18576809e-07
Iter: 1334 loss: 3.18440584e-07
Iter: 1335 loss: 3.18509535e-07
Iter: 1336 loss: 3.18327778e-07
Iter: 1337 loss: 3.18137438e-07
Iter: 1338 loss: 3.17911486e-07
Iter: 1339 loss: 3.17892557e-07
Iter: 1340 loss: 3.17700682e-07
Iter: 1341 loss: 3.20400773e-07
Iter: 1342 loss: 3.17701e-07
Iter: 1343 loss: 3.17531686e-07
Iter: 1344 loss: 3.19498469e-07
Iter: 1345 loss: 3.17544249e-07
Iter: 1346 loss: 3.1740538e-07
Iter: 1347 loss: 3.17224163e-07
Iter: 1348 loss: 3.17231354e-07
Iter: 1349 loss: 3.17021545e-07
Iter: 1350 loss: 3.19573815e-07
Iter: 1351 loss: 3.17023762e-07
Iter: 1352 loss: 3.16845927e-07
Iter: 1353 loss: 3.17142394e-07
Iter: 1354 loss: 3.16772201e-07
Iter: 1355 loss: 3.16661101e-07
Iter: 1356 loss: 3.17680929e-07
Iter: 1357 loss: 3.16652603e-07
Iter: 1358 loss: 3.16547386e-07
Iter: 1359 loss: 3.16335957e-07
Iter: 1360 loss: 3.21123707e-07
Iter: 1361 loss: 3.16322712e-07
Iter: 1362 loss: 3.16142859e-07
Iter: 1363 loss: 3.16372962e-07
Iter: 1364 loss: 3.16052592e-07
Iter: 1365 loss: 3.15838719e-07
Iter: 1366 loss: 3.18388885e-07
Iter: 1367 loss: 3.15834654e-07
Iter: 1368 loss: 3.15689761e-07
Iter: 1369 loss: 3.1582158e-07
Iter: 1370 loss: 3.1562854e-07
Iter: 1371 loss: 3.15437063e-07
Iter: 1372 loss: 3.15213981e-07
Iter: 1373 loss: 3.15201021e-07
Iter: 1374 loss: 3.14920214e-07
Iter: 1375 loss: 3.15755699e-07
Iter: 1376 loss: 3.1483637e-07
Iter: 1377 loss: 3.14637902e-07
Iter: 1378 loss: 3.14643728e-07
Iter: 1379 loss: 3.14475358e-07
Iter: 1380 loss: 3.15476086e-07
Iter: 1381 loss: 3.14454212e-07
Iter: 1382 loss: 3.14354736e-07
Iter: 1383 loss: 3.14214276e-07
Iter: 1384 loss: 3.14218681e-07
Iter: 1385 loss: 3.14101158e-07
Iter: 1386 loss: 3.14094223e-07
Iter: 1387 loss: 3.13992928e-07
Iter: 1388 loss: 3.13839e-07
Iter: 1389 loss: 3.13828252e-07
Iter: 1390 loss: 3.13654027e-07
Iter: 1391 loss: 3.16186743e-07
Iter: 1392 loss: 3.13648286e-07
Iter: 1393 loss: 3.13574674e-07
Iter: 1394 loss: 3.13404087e-07
Iter: 1395 loss: 3.15525909e-07
Iter: 1396 loss: 3.13387972e-07
Iter: 1397 loss: 3.13125383e-07
Iter: 1398 loss: 3.13814752e-07
Iter: 1399 loss: 3.13046257e-07
Iter: 1400 loss: 3.12865808e-07
Iter: 1401 loss: 3.12865922e-07
Iter: 1402 loss: 3.12723841e-07
Iter: 1403 loss: 3.12420923e-07
Iter: 1404 loss: 3.17106412e-07
Iter: 1405 loss: 3.12410464e-07
Iter: 1406 loss: 3.12102401e-07
Iter: 1407 loss: 3.12924556e-07
Iter: 1408 loss: 3.12009888e-07
Iter: 1409 loss: 3.11782344e-07
Iter: 1410 loss: 3.13884783e-07
Iter: 1411 loss: 3.11782571e-07
Iter: 1412 loss: 3.11645039e-07
Iter: 1413 loss: 3.11651149e-07
Iter: 1414 loss: 3.11533512e-07
Iter: 1415 loss: 3.11470302e-07
Iter: 1416 loss: 3.11399418e-07
Iter: 1417 loss: 3.11283912e-07
Iter: 1418 loss: 3.11674512e-07
Iter: 1419 loss: 3.11248272e-07
Iter: 1420 loss: 3.11113581e-07
Iter: 1421 loss: 3.11501964e-07
Iter: 1422 loss: 3.1105742e-07
Iter: 1423 loss: 3.10922189e-07
Iter: 1424 loss: 3.11630345e-07
Iter: 1425 loss: 3.10921621e-07
Iter: 1426 loss: 3.1078892e-07
Iter: 1427 loss: 3.10751261e-07
Iter: 1428 loss: 3.10674125e-07
Iter: 1429 loss: 3.10492112e-07
Iter: 1430 loss: 3.10303847e-07
Iter: 1431 loss: 3.10262493e-07
Iter: 1432 loss: 3.10076189e-07
Iter: 1433 loss: 3.11828217e-07
Iter: 1434 loss: 3.10077638e-07
Iter: 1435 loss: 3.09873542e-07
Iter: 1436 loss: 3.10733554e-07
Iter: 1437 loss: 3.09857853e-07
Iter: 1438 loss: 3.09720576e-07
Iter: 1439 loss: 3.0958023e-07
Iter: 1440 loss: 3.09539871e-07
Iter: 1441 loss: 3.09337793e-07
Iter: 1442 loss: 3.0977958e-07
Iter: 1443 loss: 3.09240107e-07
Iter: 1444 loss: 3.0903584e-07
Iter: 1445 loss: 3.09454492e-07
Iter: 1446 loss: 3.08948216e-07
Iter: 1447 loss: 3.08822251e-07
Iter: 1448 loss: 3.08799798e-07
Iter: 1449 loss: 3.0868739e-07
Iter: 1450 loss: 3.0847491e-07
Iter: 1451 loss: 3.11518164e-07
Iter: 1452 loss: 3.08452343e-07
Iter: 1453 loss: 3.08307477e-07
Iter: 1454 loss: 3.08294716e-07
Iter: 1455 loss: 3.08186287e-07
Iter: 1456 loss: 3.083168e-07
Iter: 1457 loss: 3.08121031e-07
Iter: 1458 loss: 3.07993446e-07
Iter: 1459 loss: 3.0843222e-07
Iter: 1460 loss: 3.07957492e-07
Iter: 1461 loss: 3.07837638e-07
Iter: 1462 loss: 3.07686946e-07
Iter: 1463 loss: 3.07691579e-07
Iter: 1464 loss: 3.07515535e-07
Iter: 1465 loss: 3.07503456e-07
Iter: 1466 loss: 3.07357396e-07
Iter: 1467 loss: 3.07182574e-07
Iter: 1468 loss: 3.09762584e-07
Iter: 1469 loss: 3.07191385e-07
Iter: 1470 loss: 3.07026482e-07
Iter: 1471 loss: 3.08063193e-07
Iter: 1472 loss: 3.07008293e-07
Iter: 1473 loss: 3.06901427e-07
Iter: 1474 loss: 3.06833726e-07
Iter: 1475 loss: 3.06777793e-07
Iter: 1476 loss: 3.06597116e-07
Iter: 1477 loss: 3.06465722e-07
Iter: 1478 loss: 3.06398931e-07
Iter: 1479 loss: 3.06159336e-07
Iter: 1480 loss: 3.08202601e-07
Iter: 1481 loss: 3.06148564e-07
Iter: 1482 loss: 3.05962772e-07
Iter: 1483 loss: 3.06424681e-07
Iter: 1484 loss: 3.0589166e-07
Iter: 1485 loss: 3.05800938e-07
Iter: 1486 loss: 3.05771437e-07
Iter: 1487 loss: 3.05697142e-07
Iter: 1488 loss: 3.05532467e-07
Iter: 1489 loss: 3.08873183e-07
Iter: 1490 loss: 3.05528545e-07
Iter: 1491 loss: 3.05406644e-07
Iter: 1492 loss: 3.05412613e-07
Iter: 1493 loss: 3.0527363e-07
Iter: 1494 loss: 3.05165145e-07
Iter: 1495 loss: 3.05133028e-07
Iter: 1496 loss: 3.04942603e-07
Iter: 1497 loss: 3.04999276e-07
Iter: 1498 loss: 3.04844548e-07
Iter: 1499 loss: 3.04631698e-07
Iter: 1500 loss: 3.05092556e-07
Iter: 1501 loss: 3.04549729e-07
Iter: 1502 loss: 3.04402192e-07
Iter: 1503 loss: 3.0438585e-07
Iter: 1504 loss: 3.04304677e-07
Iter: 1505 loss: 3.04111865e-07
Iter: 1506 loss: 3.06261086e-07
Iter: 1507 loss: 3.04078725e-07
Iter: 1508 loss: 3.0397706e-07
Iter: 1509 loss: 3.03977401e-07
Iter: 1510 loss: 3.03870934e-07
Iter: 1511 loss: 3.04097142e-07
Iter: 1512 loss: 3.03843763e-07
Iter: 1513 loss: 3.0370748e-07
Iter: 1514 loss: 3.03591037e-07
Iter: 1515 loss: 3.03587399e-07
Iter: 1516 loss: 3.03408171e-07
Iter: 1517 loss: 3.03504805e-07
Iter: 1518 loss: 3.03259583e-07
Iter: 1519 loss: 3.03180627e-07
Iter: 1520 loss: 3.03132708e-07
Iter: 1521 loss: 3.030176e-07
Iter: 1522 loss: 3.02864066e-07
Iter: 1523 loss: 3.02839567e-07
Iter: 1524 loss: 3.02664716e-07
Iter: 1525 loss: 3.03119975e-07
Iter: 1526 loss: 3.02578e-07
Iter: 1527 loss: 3.0242478e-07
Iter: 1528 loss: 3.02421455e-07
Iter: 1529 loss: 3.02331017e-07
Iter: 1530 loss: 3.02128285e-07
Iter: 1531 loss: 3.04734385e-07
Iter: 1532 loss: 3.02099e-07
Iter: 1533 loss: 3.01932459e-07
Iter: 1534 loss: 3.03333e-07
Iter: 1535 loss: 3.01928225e-07
Iter: 1536 loss: 3.01798764e-07
Iter: 1537 loss: 3.01919698e-07
Iter: 1538 loss: 3.01752664e-07
Iter: 1539 loss: 3.01670696e-07
Iter: 1540 loss: 3.01673964e-07
Iter: 1541 loss: 3.01583896e-07
Iter: 1542 loss: 3.01399268e-07
Iter: 1543 loss: 3.04846424e-07
Iter: 1544 loss: 3.0140319e-07
Iter: 1545 loss: 3.01197787e-07
Iter: 1546 loss: 3.01459835e-07
Iter: 1547 loss: 3.01109651e-07
Iter: 1548 loss: 3.00896147e-07
Iter: 1549 loss: 3.01797115e-07
Iter: 1550 loss: 3.00855902e-07
Iter: 1551 loss: 3.00674458e-07
Iter: 1552 loss: 3.01194063e-07
Iter: 1553 loss: 3.00615966e-07
Iter: 1554 loss: 3.00520952e-07
Iter: 1555 loss: 3.00510749e-07
Iter: 1556 loss: 3.00448335e-07
Iter: 1557 loss: 3.00308017e-07
Iter: 1558 loss: 3.01186873e-07
Iter: 1559 loss: 3.00257454e-07
Iter: 1560 loss: 3.00143654e-07
Iter: 1561 loss: 3.00134388e-07
Iter: 1562 loss: 3.00032184e-07
Iter: 1563 loss: 3.00252452e-07
Iter: 1564 loss: 2.99991939e-07
Iter: 1565 loss: 2.99914774e-07
Iter: 1566 loss: 2.99767493e-07
Iter: 1567 loss: 3.02915595e-07
Iter: 1568 loss: 2.99768e-07
Iter: 1569 loss: 2.995599e-07
Iter: 1570 loss: 3.01757808e-07
Iter: 1571 loss: 2.99568853e-07
Iter: 1572 loss: 2.99433964e-07
Iter: 1573 loss: 2.99393037e-07
Iter: 1574 loss: 2.99306095e-07
Iter: 1575 loss: 2.99155744e-07
Iter: 1576 loss: 3.00680853e-07
Iter: 1577 loss: 2.9915779e-07
Iter: 1578 loss: 2.99052772e-07
Iter: 1579 loss: 2.99222677e-07
Iter: 1580 loss: 2.99008121e-07
Iter: 1581 loss: 2.9889361e-07
Iter: 1582 loss: 2.98861863e-07
Iter: 1583 loss: 2.98783959e-07
Iter: 1584 loss: 2.98646967e-07
Iter: 1585 loss: 2.98963073e-07
Iter: 1586 loss: 2.98593164e-07
Iter: 1587 loss: 2.98438096e-07
Iter: 1588 loss: 2.99108649e-07
Iter: 1589 loss: 2.98403336e-07
Iter: 1590 loss: 2.98256964e-07
Iter: 1591 loss: 2.98129748e-07
Iter: 1592 loss: 2.9808109e-07
Iter: 1593 loss: 2.97912948e-07
Iter: 1594 loss: 2.97899362e-07
Iter: 1595 loss: 2.97695891e-07
Iter: 1596 loss: 2.98569915e-07
Iter: 1597 loss: 2.97661302e-07
Iter: 1598 loss: 2.97493443e-07
Iter: 1599 loss: 2.97312738e-07
Iter: 1600 loss: 2.97280025e-07
Iter: 1601 loss: 2.97147949e-07
Iter: 1602 loss: 2.97138115e-07
Iter: 1603 loss: 2.97021643e-07
Iter: 1604 loss: 2.9718862e-07
Iter: 1605 loss: 2.96970398e-07
Iter: 1606 loss: 2.96873282e-07
Iter: 1607 loss: 2.97252342e-07
Iter: 1608 loss: 2.96864414e-07
Iter: 1609 loss: 2.96759936e-07
Iter: 1610 loss: 2.96860151e-07
Iter: 1611 loss: 2.96695305e-07
Iter: 1612 loss: 2.96611e-07
Iter: 1613 loss: 2.96684703e-07
Iter: 1614 loss: 2.96551065e-07
Iter: 1615 loss: 2.96446274e-07
Iter: 1616 loss: 2.97048757e-07
Iter: 1617 loss: 2.96445222e-07
Iter: 1618 loss: 2.96322753e-07
Iter: 1619 loss: 2.9655817e-07
Iter: 1620 loss: 2.96275516e-07
Iter: 1621 loss: 2.96187807e-07
Iter: 1622 loss: 2.96012303e-07
Iter: 1623 loss: 3.00036163e-07
Iter: 1624 loss: 2.96008096e-07
Iter: 1625 loss: 2.95776118e-07
Iter: 1626 loss: 2.96908524e-07
Iter: 1627 loss: 2.95710635e-07
Iter: 1628 loss: 2.95555935e-07
Iter: 1629 loss: 2.95972654e-07
Iter: 1630 loss: 2.95495937e-07
Iter: 1631 loss: 2.95446227e-07
Iter: 1632 loss: 2.95410047e-07
Iter: 1633 loss: 2.95356699e-07
Iter: 1634 loss: 2.95227125e-07
Iter: 1635 loss: 2.96323435e-07
Iter: 1636 loss: 2.95216722e-07
Iter: 1637 loss: 2.95054804e-07
Iter: 1638 loss: 2.95265323e-07
Iter: 1639 loss: 2.94952258e-07
Iter: 1640 loss: 2.94823906e-07
Iter: 1641 loss: 2.96697266e-07
Iter: 1642 loss: 2.94823451e-07
Iter: 1643 loss: 2.94721531e-07
Iter: 1644 loss: 2.95555367e-07
Iter: 1645 loss: 2.94725083e-07
Iter: 1646 loss: 2.94647805e-07
Iter: 1647 loss: 2.94492565e-07
Iter: 1648 loss: 2.97457717e-07
Iter: 1649 loss: 2.9449285e-07
Iter: 1650 loss: 2.94296569e-07
Iter: 1651 loss: 2.95848793e-07
Iter: 1652 loss: 2.94297934e-07
Iter: 1653 loss: 2.94156507e-07
Iter: 1654 loss: 2.94373194e-07
Iter: 1655 loss: 2.94088863e-07
Iter: 1656 loss: 2.93955679e-07
Iter: 1657 loss: 2.94099e-07
Iter: 1658 loss: 2.93884085e-07
Iter: 1659 loss: 2.93777305e-07
Iter: 1660 loss: 2.9377648e-07
Iter: 1661 loss: 2.93706421e-07
Iter: 1662 loss: 2.93625106e-07
Iter: 1663 loss: 2.93624566e-07
Iter: 1664 loss: 2.93481435e-07
Iter: 1665 loss: 2.93586538e-07
Iter: 1666 loss: 2.93394578e-07
Iter: 1667 loss: 2.93241499e-07
Iter: 1668 loss: 2.94022243e-07
Iter: 1669 loss: 2.93219671e-07
Iter: 1670 loss: 2.93097628e-07
Iter: 1671 loss: 2.93094359e-07
Iter: 1672 loss: 2.93026773e-07
Iter: 1673 loss: 2.92837484e-07
Iter: 1674 loss: 2.94120639e-07
Iter: 1675 loss: 2.92785558e-07
Iter: 1676 loss: 2.92579756e-07
Iter: 1677 loss: 2.93959857e-07
Iter: 1678 loss: 2.92570945e-07
Iter: 1679 loss: 2.92433754e-07
Iter: 1680 loss: 2.94478099e-07
Iter: 1681 loss: 2.92426648e-07
Iter: 1682 loss: 2.92277662e-07
Iter: 1683 loss: 2.92138679e-07
Iter: 1684 loss: 2.92132142e-07
Iter: 1685 loss: 2.9199964e-07
Iter: 1686 loss: 2.93137703e-07
Iter: 1687 loss: 2.91992933e-07
Iter: 1688 loss: 2.91891752e-07
Iter: 1689 loss: 2.92188588e-07
Iter: 1690 loss: 2.91850739e-07
Iter: 1691 loss: 2.91782555e-07
Iter: 1692 loss: 2.91699507e-07
Iter: 1693 loss: 2.91672876e-07
Iter: 1694 loss: 2.91541511e-07
Iter: 1695 loss: 2.92075271e-07
Iter: 1696 loss: 2.91507035e-07
Iter: 1697 loss: 2.91388716e-07
Iter: 1698 loss: 2.92737184e-07
Iter: 1699 loss: 2.91390677e-07
Iter: 1700 loss: 2.91315104e-07
Iter: 1701 loss: 2.91204685e-07
Iter: 1702 loss: 2.91188485e-07
Iter: 1703 loss: 2.91038361e-07
Iter: 1704 loss: 2.91465597e-07
Iter: 1705 loss: 2.90994848e-07
Iter: 1706 loss: 2.90885225e-07
Iter: 1707 loss: 2.90878603e-07
Iter: 1708 loss: 2.9079257e-07
Iter: 1709 loss: 2.90643271e-07
Iter: 1710 loss: 2.9425496e-07
Iter: 1711 loss: 2.90618402e-07
Iter: 1712 loss: 2.90492494e-07
Iter: 1713 loss: 2.90634887e-07
Iter: 1714 loss: 2.90408423e-07
Iter: 1715 loss: 2.90336175e-07
Iter: 1716 loss: 2.90326057e-07
Iter: 1717 loss: 2.90244969e-07
Iter: 1718 loss: 2.90142e-07
Iter: 1719 loss: 2.90147852e-07
Iter: 1720 loss: 2.90011883e-07
Iter: 1721 loss: 2.9031014e-07
Iter: 1722 loss: 2.89966493e-07
Iter: 1723 loss: 2.8987634e-07
Iter: 1724 loss: 2.91379195e-07
Iter: 1725 loss: 2.89866819e-07
Iter: 1726 loss: 2.89788574e-07
Iter: 1727 loss: 2.89700864e-07
Iter: 1728 loss: 2.89689666e-07
Iter: 1729 loss: 2.89539742e-07
Iter: 1730 loss: 2.89424207e-07
Iter: 1731 loss: 2.8939661e-07
Iter: 1732 loss: 2.89269281e-07
Iter: 1733 loss: 2.89261408e-07
Iter: 1734 loss: 2.89157612e-07
Iter: 1735 loss: 2.89789284e-07
Iter: 1736 loss: 2.89152496e-07
Iter: 1737 loss: 2.89073796e-07
Iter: 1738 loss: 2.88973808e-07
Iter: 1739 loss: 2.88968351e-07
Iter: 1740 loss: 2.88862509e-07
Iter: 1741 loss: 2.88876379e-07
Iter: 1742 loss: 2.88788385e-07
Iter: 1743 loss: 2.88802653e-07
Iter: 1744 loss: 2.88724465e-07
Iter: 1745 loss: 2.88651506e-07
Iter: 1746 loss: 2.88568401e-07
Iter: 1747 loss: 2.88548705e-07
Iter: 1748 loss: 2.88407932e-07
Iter: 1749 loss: 2.89196805e-07
Iter: 1750 loss: 2.88368398e-07
Iter: 1751 loss: 2.88222225e-07
Iter: 1752 loss: 2.8913e-07
Iter: 1753 loss: 2.88193036e-07
Iter: 1754 loss: 2.88113512e-07
Iter: 1755 loss: 2.87944715e-07
Iter: 1756 loss: 2.90240678e-07
Iter: 1757 loss: 2.8791024e-07
Iter: 1758 loss: 2.87785781e-07
Iter: 1759 loss: 2.8777319e-07
Iter: 1760 loss: 2.87666438e-07
Iter: 1761 loss: 2.88088927e-07
Iter: 1762 loss: 2.87629518e-07
Iter: 1763 loss: 2.87516855e-07
Iter: 1764 loss: 2.87492924e-07
Iter: 1765 loss: 2.87432727e-07
Iter: 1766 loss: 2.87339248e-07
Iter: 1767 loss: 2.87490593e-07
Iter: 1768 loss: 2.87295137e-07
Iter: 1769 loss: 2.87204557e-07
Iter: 1770 loss: 2.88407676e-07
Iter: 1771 loss: 2.87198077e-07
Iter: 1772 loss: 2.87107611e-07
Iter: 1773 loss: 2.87076119e-07
Iter: 1774 loss: 2.87030502e-07
Iter: 1775 loss: 2.86952286e-07
Iter: 1776 loss: 2.88211425e-07
Iter: 1777 loss: 2.86950296e-07
Iter: 1778 loss: 2.86874581e-07
Iter: 1779 loss: 2.86839736e-07
Iter: 1780 loss: 2.86788634e-07
Iter: 1781 loss: 2.86673412e-07
Iter: 1782 loss: 2.86523743e-07
Iter: 1783 loss: 2.86507429e-07
Iter: 1784 loss: 2.86409147e-07
Iter: 1785 loss: 2.86404571e-07
Iter: 1786 loss: 2.86309557e-07
Iter: 1787 loss: 2.86375808e-07
Iter: 1788 loss: 2.86248508e-07
Iter: 1789 loss: 2.86156364e-07
Iter: 1790 loss: 2.86151817e-07
Iter: 1791 loss: 2.86078972e-07
Iter: 1792 loss: 2.85966337e-07
Iter: 1793 loss: 2.86244216e-07
Iter: 1794 loss: 2.8592703e-07
Iter: 1795 loss: 2.85810472e-07
Iter: 1796 loss: 2.87035107e-07
Iter: 1797 loss: 2.8580331e-07
Iter: 1798 loss: 2.85714833e-07
Iter: 1799 loss: 2.85625731e-07
Iter: 1800 loss: 2.85625617e-07
Iter: 1801 loss: 2.85527904e-07
Iter: 1802 loss: 2.85580654e-07
Iter: 1803 loss: 2.85443e-07
Iter: 1804 loss: 2.85285353e-07
Iter: 1805 loss: 2.86745717e-07
Iter: 1806 loss: 2.85287371e-07
Iter: 1807 loss: 2.85188122e-07
Iter: 1808 loss: 2.8607792e-07
Iter: 1809 loss: 2.85186161e-07
Iter: 1810 loss: 2.85114709e-07
Iter: 1811 loss: 2.85146797e-07
Iter: 1812 loss: 2.85064061e-07
Iter: 1813 loss: 2.84964415e-07
Iter: 1814 loss: 2.85446305e-07
Iter: 1815 loss: 2.84939546e-07
Iter: 1816 loss: 2.84873124e-07
Iter: 1817 loss: 2.84769357e-07
Iter: 1818 loss: 2.87284507e-07
Iter: 1819 loss: 2.84773819e-07
Iter: 1820 loss: 2.84615879e-07
Iter: 1821 loss: 2.84945884e-07
Iter: 1822 loss: 2.84560656e-07
Iter: 1823 loss: 2.84437021e-07
Iter: 1824 loss: 2.86187912e-07
Iter: 1825 loss: 2.84431621e-07
Iter: 1826 loss: 2.84335385e-07
Iter: 1827 loss: 2.84632591e-07
Iter: 1828 loss: 2.84300199e-07
Iter: 1829 loss: 2.84210842e-07
Iter: 1830 loss: 2.84075327e-07
Iter: 1831 loss: 2.84067312e-07
Iter: 1832 loss: 2.83908889e-07
Iter: 1833 loss: 2.84491279e-07
Iter: 1834 loss: 2.83864154e-07
Iter: 1835 loss: 2.83727616e-07
Iter: 1836 loss: 2.83981478e-07
Iter: 1837 loss: 2.83650195e-07
Iter: 1838 loss: 2.83540089e-07
Iter: 1839 loss: 2.84731811e-07
Iter: 1840 loss: 2.83530824e-07
Iter: 1841 loss: 2.83412305e-07
Iter: 1842 loss: 2.84036133e-07
Iter: 1843 loss: 2.83391e-07
Iter: 1844 loss: 2.83322208e-07
Iter: 1845 loss: 2.83249847e-07
Iter: 1846 loss: 2.83214689e-07
Iter: 1847 loss: 2.83155089e-07
Iter: 1848 loss: 2.83155572e-07
Iter: 1849 loss: 2.83085257e-07
Iter: 1850 loss: 2.82976544e-07
Iter: 1851 loss: 2.82962247e-07
Iter: 1852 loss: 2.82868683e-07
Iter: 1853 loss: 2.82937549e-07
Iter: 1854 loss: 2.82795696e-07
Iter: 1855 loss: 2.82704889e-07
Iter: 1856 loss: 2.82704605e-07
Iter: 1857 loss: 2.82658732e-07
Iter: 1858 loss: 2.82550445e-07
Iter: 1859 loss: 2.84573048e-07
Iter: 1860 loss: 2.82549934e-07
Iter: 1861 loss: 2.82411548e-07
Iter: 1862 loss: 2.8278231e-07
Iter: 1863 loss: 2.82344672e-07
Iter: 1864 loss: 2.82225386e-07
Iter: 1865 loss: 2.82632953e-07
Iter: 1866 loss: 2.8219165e-07
Iter: 1867 loss: 2.82084159e-07
Iter: 1868 loss: 2.82084784e-07
Iter: 1869 loss: 2.81992925e-07
Iter: 1870 loss: 2.81983318e-07
Iter: 1871 loss: 2.81915277e-07
Iter: 1872 loss: 2.81807843e-07
Iter: 1873 loss: 2.81902402e-07
Iter: 1874 loss: 2.81736561e-07
Iter: 1875 loss: 2.81655673e-07
Iter: 1876 loss: 2.81650898e-07
Iter: 1877 loss: 2.81588541e-07
Iter: 1878 loss: 2.81457062e-07
Iter: 1879 loss: 2.84275018e-07
Iter: 1880 loss: 2.81450127e-07
Iter: 1881 loss: 2.81352015e-07
Iter: 1882 loss: 2.82062246e-07
Iter: 1883 loss: 2.81349884e-07
Iter: 1884 loss: 2.81265159e-07
Iter: 1885 loss: 2.81264875e-07
Iter: 1886 loss: 2.81224601e-07
Iter: 1887 loss: 2.81147607e-07
Iter: 1888 loss: 2.83141276e-07
Iter: 1889 loss: 2.81141951e-07
Iter: 1890 loss: 2.81061091e-07
Iter: 1891 loss: 2.8127954e-07
Iter: 1892 loss: 2.81025e-07
Iter: 1893 loss: 2.80943425e-07
Iter: 1894 loss: 2.82009125e-07
Iter: 1895 loss: 2.80937911e-07
Iter: 1896 loss: 2.80867539e-07
Iter: 1897 loss: 2.80724237e-07
Iter: 1898 loss: 2.82715035e-07
Iter: 1899 loss: 2.80713294e-07
Iter: 1900 loss: 2.80565871e-07
Iter: 1901 loss: 2.80951753e-07
Iter: 1902 loss: 2.8052375e-07
Iter: 1903 loss: 2.80376412e-07
Iter: 1904 loss: 2.82037092e-07
Iter: 1905 loss: 2.80376611e-07
Iter: 1906 loss: 2.80286713e-07
Iter: 1907 loss: 2.81107e-07
Iter: 1908 loss: 2.80279437e-07
Iter: 1909 loss: 2.8020051e-07
Iter: 1910 loss: 2.80029781e-07
Iter: 1911 loss: 2.8251722e-07
Iter: 1912 loss: 2.80027791e-07
Iter: 1913 loss: 2.79906629e-07
Iter: 1914 loss: 2.81785077e-07
Iter: 1915 loss: 2.79908306e-07
Iter: 1916 loss: 2.79814685e-07
Iter: 1917 loss: 2.80399945e-07
Iter: 1918 loss: 2.79802634e-07
Iter: 1919 loss: 2.79746928e-07
Iter: 1920 loss: 2.79668939e-07
Iter: 1921 loss: 2.79663738e-07
Iter: 1922 loss: 2.79569292e-07
Iter: 1923 loss: 2.80978071e-07
Iter: 1924 loss: 2.79573158e-07
Iter: 1925 loss: 2.79478058e-07
Iter: 1926 loss: 2.79404361e-07
Iter: 1927 loss: 2.79374916e-07
Iter: 1928 loss: 2.79253385e-07
Iter: 1929 loss: 2.79155159e-07
Iter: 1930 loss: 2.79127789e-07
Iter: 1931 loss: 2.79011317e-07
Iter: 1932 loss: 2.79002194e-07
Iter: 1933 loss: 2.78899e-07
Iter: 1934 loss: 2.79321227e-07
Iter: 1935 loss: 2.78882396e-07
Iter: 1936 loss: 2.78804293e-07
Iter: 1937 loss: 2.78735513e-07
Iter: 1938 loss: 2.7871755e-07
Iter: 1939 loss: 2.78619154e-07
Iter: 1940 loss: 2.78716925e-07
Iter: 1941 loss: 2.78560748e-07
Iter: 1942 loss: 2.78459879e-07
Iter: 1943 loss: 2.8010578e-07
Iter: 1944 loss: 2.78450898e-07
Iter: 1945 loss: 2.78348352e-07
Iter: 1946 loss: 2.78298756e-07
Iter: 1947 loss: 2.7823333e-07
Iter: 1948 loss: 2.7812618e-07
Iter: 1949 loss: 2.78260529e-07
Iter: 1950 loss: 2.78068768e-07
Iter: 1951 loss: 2.7793655e-07
Iter: 1952 loss: 2.78793237e-07
Iter: 1953 loss: 2.7792521e-07
Iter: 1954 loss: 2.77796715e-07
Iter: 1955 loss: 2.77880474e-07
Iter: 1956 loss: 2.777156e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6
+ date
Mon Oct 26 12:35:47 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi1.6_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe2334158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe22fea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe22fed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe23c0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe23e12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe23e18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe22506a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe2290b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe21f5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe21f5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe21f5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe218ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe218fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe213c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe213c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe20a7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe20d5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe20c9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe20837b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe2083c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe20457b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe2055e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1fa66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1ffabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1ffa620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1f65598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1f43840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1f08598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1ee6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fe1f0e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fc551c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fc5518c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fc5518950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fc5479730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fc5497400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9fc5465d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.0758e-05
Iter: 2 loss: 8.36481649e-06
Iter: 3 loss: 8.34577e-06
Iter: 4 loss: 7.42699103e-06
Iter: 5 loss: 1.03253224e-05
Iter: 6 loss: 7.16260547e-06
Iter: 7 loss: 6.67580252e-06
Iter: 8 loss: 1.0382747e-05
Iter: 9 loss: 6.63912624e-06
Iter: 10 loss: 6.25151552e-06
Iter: 11 loss: 7.3057995e-06
Iter: 12 loss: 6.12459644e-06
Iter: 13 loss: 5.89210913e-06
Iter: 14 loss: 6.85868372e-06
Iter: 15 loss: 5.84233112e-06
Iter: 16 loss: 5.61382649e-06
Iter: 17 loss: 5.3291551e-06
Iter: 18 loss: 5.30538819e-06
Iter: 19 loss: 5.10241398e-06
Iter: 20 loss: 6.50398943e-06
Iter: 21 loss: 5.08312814e-06
Iter: 22 loss: 4.88371279e-06
Iter: 23 loss: 5.61819888e-06
Iter: 24 loss: 4.83429676e-06
Iter: 25 loss: 4.64374898e-06
Iter: 26 loss: 4.8107886e-06
Iter: 27 loss: 4.53183202e-06
Iter: 28 loss: 4.30983391e-06
Iter: 29 loss: 4.30864065e-06
Iter: 30 loss: 4.13197449e-06
Iter: 31 loss: 3.90823425e-06
Iter: 32 loss: 4.39683845e-06
Iter: 33 loss: 3.82204871e-06
Iter: 34 loss: 3.63208392e-06
Iter: 35 loss: 6.20002675e-06
Iter: 36 loss: 3.63136178e-06
Iter: 37 loss: 3.51452832e-06
Iter: 38 loss: 3.42198518e-06
Iter: 39 loss: 3.38619247e-06
Iter: 40 loss: 3.2697385e-06
Iter: 41 loss: 3.26884469e-06
Iter: 42 loss: 3.18146385e-06
Iter: 43 loss: 4.30278033e-06
Iter: 44 loss: 3.18082357e-06
Iter: 45 loss: 3.13596092e-06
Iter: 46 loss: 3.21402877e-06
Iter: 47 loss: 3.11617191e-06
Iter: 48 loss: 3.04490368e-06
Iter: 49 loss: 2.99210274e-06
Iter: 50 loss: 2.96841063e-06
Iter: 51 loss: 2.87692228e-06
Iter: 52 loss: 3.22645428e-06
Iter: 53 loss: 2.85528472e-06
Iter: 54 loss: 2.77526442e-06
Iter: 55 loss: 3.06103084e-06
Iter: 56 loss: 2.75485854e-06
Iter: 57 loss: 2.67225369e-06
Iter: 58 loss: 2.58786531e-06
Iter: 59 loss: 2.57167312e-06
Iter: 60 loss: 2.50482753e-06
Iter: 61 loss: 3.3521892e-06
Iter: 62 loss: 2.50429639e-06
Iter: 63 loss: 2.4420417e-06
Iter: 64 loss: 2.61942341e-06
Iter: 65 loss: 2.42237184e-06
Iter: 66 loss: 2.36840083e-06
Iter: 67 loss: 2.41641e-06
Iter: 68 loss: 2.33685387e-06
Iter: 69 loss: 2.27350847e-06
Iter: 70 loss: 2.31433387e-06
Iter: 71 loss: 2.23335155e-06
Iter: 72 loss: 2.16937133e-06
Iter: 73 loss: 2.19553431e-06
Iter: 74 loss: 2.12523264e-06
Iter: 75 loss: 2.05891e-06
Iter: 76 loss: 2.41521457e-06
Iter: 77 loss: 2.04895605e-06
Iter: 78 loss: 1.97267718e-06
Iter: 79 loss: 2.3133266e-06
Iter: 80 loss: 1.95762414e-06
Iter: 81 loss: 1.93121264e-06
Iter: 82 loss: 1.93103028e-06
Iter: 83 loss: 1.8986492e-06
Iter: 84 loss: 1.90287653e-06
Iter: 85 loss: 1.87402304e-06
Iter: 86 loss: 1.84792702e-06
Iter: 87 loss: 2.09983409e-06
Iter: 88 loss: 1.84697103e-06
Iter: 89 loss: 1.82272618e-06
Iter: 90 loss: 1.78183791e-06
Iter: 91 loss: 1.78176276e-06
Iter: 92 loss: 1.75641594e-06
Iter: 93 loss: 2.09676386e-06
Iter: 94 loss: 1.75627463e-06
Iter: 95 loss: 1.73617809e-06
Iter: 96 loss: 1.76479875e-06
Iter: 97 loss: 1.72636669e-06
Iter: 98 loss: 1.69706743e-06
Iter: 99 loss: 1.666e-06
Iter: 100 loss: 1.66067809e-06
Iter: 101 loss: 1.63535924e-06
Iter: 102 loss: 1.83666089e-06
Iter: 103 loss: 1.63364302e-06
Iter: 104 loss: 1.60679724e-06
Iter: 105 loss: 1.72495606e-06
Iter: 106 loss: 1.60146169e-06
Iter: 107 loss: 1.58587454e-06
Iter: 108 loss: 1.56432611e-06
Iter: 109 loss: 1.5633259e-06
Iter: 110 loss: 1.52460416e-06
Iter: 111 loss: 1.60583818e-06
Iter: 112 loss: 1.50928122e-06
Iter: 113 loss: 1.47822584e-06
Iter: 114 loss: 1.53989947e-06
Iter: 115 loss: 1.46553407e-06
Iter: 116 loss: 1.43978821e-06
Iter: 117 loss: 1.7101961e-06
Iter: 118 loss: 1.4390987e-06
Iter: 119 loss: 1.42292743e-06
Iter: 120 loss: 1.59452611e-06
Iter: 121 loss: 1.42247688e-06
Iter: 122 loss: 1.40588804e-06
Iter: 123 loss: 1.45773265e-06
Iter: 124 loss: 1.40096517e-06
Iter: 125 loss: 1.3931251e-06
Iter: 126 loss: 1.3943054e-06
Iter: 127 loss: 1.38727523e-06
Iter: 128 loss: 1.36960603e-06
Iter: 129 loss: 1.35373784e-06
Iter: 130 loss: 1.34919355e-06
Iter: 131 loss: 1.33684489e-06
Iter: 132 loss: 1.34458423e-06
Iter: 133 loss: 1.32895957e-06
Iter: 134 loss: 1.30702779e-06
Iter: 135 loss: 1.41945816e-06
Iter: 136 loss: 1.30343e-06
Iter: 137 loss: 1.29218074e-06
Iter: 138 loss: 1.31837567e-06
Iter: 139 loss: 1.28804595e-06
Iter: 140 loss: 1.27580142e-06
Iter: 141 loss: 1.2620219e-06
Iter: 142 loss: 1.26018472e-06
Iter: 143 loss: 1.24651069e-06
Iter: 144 loss: 1.24566009e-06
Iter: 145 loss: 1.23506516e-06
Iter: 146 loss: 1.22381857e-06
Iter: 147 loss: 1.22194433e-06
Iter: 148 loss: 1.20668642e-06
Iter: 149 loss: 1.23160635e-06
Iter: 150 loss: 1.19968468e-06
Iter: 151 loss: 1.1813205e-06
Iter: 152 loss: 1.25445126e-06
Iter: 153 loss: 1.1771607e-06
Iter: 154 loss: 1.16532476e-06
Iter: 155 loss: 1.17605305e-06
Iter: 156 loss: 1.15832768e-06
Iter: 157 loss: 1.15146679e-06
Iter: 158 loss: 1.1508389e-06
Iter: 159 loss: 1.14217494e-06
Iter: 160 loss: 1.15879948e-06
Iter: 161 loss: 1.1385215e-06
Iter: 162 loss: 1.13270994e-06
Iter: 163 loss: 1.13125543e-06
Iter: 164 loss: 1.12754401e-06
Iter: 165 loss: 1.11922736e-06
Iter: 166 loss: 1.19188144e-06
Iter: 167 loss: 1.11881013e-06
Iter: 168 loss: 1.11208749e-06
Iter: 169 loss: 1.10499695e-06
Iter: 170 loss: 1.10381256e-06
Iter: 171 loss: 1.0947565e-06
Iter: 172 loss: 1.08885013e-06
Iter: 173 loss: 1.08534232e-06
Iter: 174 loss: 1.06858442e-06
Iter: 175 loss: 1.26891655e-06
Iter: 176 loss: 1.06838661e-06
Iter: 177 loss: 1.06252537e-06
Iter: 178 loss: 1.05314155e-06
Iter: 179 loss: 1.05304696e-06
Iter: 180 loss: 1.03999878e-06
Iter: 181 loss: 1.11584177e-06
Iter: 182 loss: 1.03829439e-06
Iter: 183 loss: 1.02975469e-06
Iter: 184 loss: 1.11574991e-06
Iter: 185 loss: 1.02949025e-06
Iter: 186 loss: 1.02219883e-06
Iter: 187 loss: 1.01517594e-06
Iter: 188 loss: 1.013516e-06
Iter: 189 loss: 1.00508896e-06
Iter: 190 loss: 1.02632725e-06
Iter: 191 loss: 1.00213185e-06
Iter: 192 loss: 9.91332172e-07
Iter: 193 loss: 1.01252249e-06
Iter: 194 loss: 9.86941814e-07
Iter: 195 loss: 9.86808345e-07
Iter: 196 loss: 9.83050199e-07
Iter: 197 loss: 9.79192123e-07
Iter: 198 loss: 9.70130486e-07
Iter: 199 loss: 1.08312588e-06
Iter: 200 loss: 9.69493158e-07
Iter: 201 loss: 9.63466846e-07
Iter: 202 loss: 1.0027461e-06
Iter: 203 loss: 9.6284441e-07
Iter: 204 loss: 9.54530606e-07
Iter: 205 loss: 9.53529593e-07
Iter: 206 loss: 9.47589115e-07
Iter: 207 loss: 9.41745554e-07
Iter: 208 loss: 9.49698233e-07
Iter: 209 loss: 9.38777077e-07
Iter: 210 loss: 9.30959118e-07
Iter: 211 loss: 9.61823844e-07
Iter: 212 loss: 9.29268822e-07
Iter: 213 loss: 9.23062942e-07
Iter: 214 loss: 9.81274866e-07
Iter: 215 loss: 9.22851427e-07
Iter: 216 loss: 9.19581908e-07
Iter: 217 loss: 9.11296866e-07
Iter: 218 loss: 9.82009624e-07
Iter: 219 loss: 9.09863843e-07
Iter: 220 loss: 9.04176773e-07
Iter: 221 loss: 9.03854584e-07
Iter: 222 loss: 8.98962526e-07
Iter: 223 loss: 9.19019044e-07
Iter: 224 loss: 8.97867096e-07
Iter: 225 loss: 8.93606853e-07
Iter: 226 loss: 8.95584662e-07
Iter: 227 loss: 8.90707724e-07
Iter: 228 loss: 8.84619908e-07
Iter: 229 loss: 8.80002119e-07
Iter: 230 loss: 8.78101503e-07
Iter: 231 loss: 8.85524742e-07
Iter: 232 loss: 8.76271486e-07
Iter: 233 loss: 8.74358534e-07
Iter: 234 loss: 8.6909904e-07
Iter: 235 loss: 8.95427e-07
Iter: 236 loss: 8.67279255e-07
Iter: 237 loss: 8.61989918e-07
Iter: 238 loss: 9.01922476e-07
Iter: 239 loss: 8.61610715e-07
Iter: 240 loss: 8.57046757e-07
Iter: 241 loss: 8.96818733e-07
Iter: 242 loss: 8.56816314e-07
Iter: 243 loss: 8.54150869e-07
Iter: 244 loss: 8.5099208e-07
Iter: 245 loss: 8.50665174e-07
Iter: 246 loss: 8.45240606e-07
Iter: 247 loss: 8.46589273e-07
Iter: 248 loss: 8.41316592e-07
Iter: 249 loss: 8.39248798e-07
Iter: 250 loss: 8.38359597e-07
Iter: 251 loss: 8.35665958e-07
Iter: 252 loss: 8.30061197e-07
Iter: 253 loss: 9.29094654e-07
Iter: 254 loss: 8.29950181e-07
Iter: 255 loss: 8.23818937e-07
Iter: 256 loss: 8.55050871e-07
Iter: 257 loss: 8.22798768e-07
Iter: 258 loss: 8.17932857e-07
Iter: 259 loss: 8.24836661e-07
Iter: 260 loss: 8.1548319e-07
Iter: 261 loss: 8.12337191e-07
Iter: 262 loss: 8.12173084e-07
Iter: 263 loss: 8.09344e-07
Iter: 264 loss: 8.05127797e-07
Iter: 265 loss: 8.05013656e-07
Iter: 266 loss: 8.02465195e-07
Iter: 267 loss: 8.02375041e-07
Iter: 268 loss: 7.99477561e-07
Iter: 269 loss: 8.04503e-07
Iter: 270 loss: 7.98213591e-07
Iter: 271 loss: 7.9550307e-07
Iter: 272 loss: 7.93529352e-07
Iter: 273 loss: 7.92701826e-07
Iter: 274 loss: 7.89826913e-07
Iter: 275 loss: 7.9475484e-07
Iter: 276 loss: 7.88558793e-07
Iter: 277 loss: 7.8338735e-07
Iter: 278 loss: 7.94547304e-07
Iter: 279 loss: 7.81357869e-07
Iter: 280 loss: 7.78891604e-07
Iter: 281 loss: 7.78089884e-07
Iter: 282 loss: 7.76670163e-07
Iter: 283 loss: 7.71675559e-07
Iter: 284 loss: 7.68389555e-07
Iter: 285 loss: 7.66558401e-07
Iter: 286 loss: 7.63684909e-07
Iter: 287 loss: 7.63065941e-07
Iter: 288 loss: 7.59748332e-07
Iter: 289 loss: 7.60626108e-07
Iter: 290 loss: 7.57348e-07
Iter: 291 loss: 7.54485086e-07
Iter: 292 loss: 7.60426133e-07
Iter: 293 loss: 7.533651e-07
Iter: 294 loss: 7.50261961e-07
Iter: 295 loss: 7.54798521e-07
Iter: 296 loss: 7.48689899e-07
Iter: 297 loss: 7.46002854e-07
Iter: 298 loss: 7.6665583e-07
Iter: 299 loss: 7.45771899e-07
Iter: 300 loss: 7.43200189e-07
Iter: 301 loss: 7.55870133e-07
Iter: 302 loss: 7.42728957e-07
Iter: 303 loss: 7.40957603e-07
Iter: 304 loss: 7.49734795e-07
Iter: 305 loss: 7.40648829e-07
Iter: 306 loss: 7.38028746e-07
Iter: 307 loss: 7.33900606e-07
Iter: 308 loss: 7.33877528e-07
Iter: 309 loss: 7.30990394e-07
Iter: 310 loss: 7.38998e-07
Iter: 311 loss: 7.30062141e-07
Iter: 312 loss: 7.26945132e-07
Iter: 313 loss: 7.26720828e-07
Iter: 314 loss: 7.24407187e-07
Iter: 315 loss: 7.22200753e-07
Iter: 316 loss: 7.21655908e-07
Iter: 317 loss: 7.19878699e-07
Iter: 318 loss: 7.15629312e-07
Iter: 319 loss: 7.66975859e-07
Iter: 320 loss: 7.15283136e-07
Iter: 321 loss: 7.11648624e-07
Iter: 322 loss: 7.15664783e-07
Iter: 323 loss: 7.09678034e-07
Iter: 324 loss: 7.06145215e-07
Iter: 325 loss: 7.509e-07
Iter: 326 loss: 7.06071546e-07
Iter: 327 loss: 7.03079365e-07
Iter: 328 loss: 7.05136131e-07
Iter: 329 loss: 7.01207284e-07
Iter: 330 loss: 6.99417797e-07
Iter: 331 loss: 6.99123916e-07
Iter: 332 loss: 6.97918324e-07
Iter: 333 loss: 6.94790856e-07
Iter: 334 loss: 7.16265959e-07
Iter: 335 loss: 6.94028586e-07
Iter: 336 loss: 6.90933234e-07
Iter: 337 loss: 7.38365827e-07
Iter: 338 loss: 6.90933518e-07
Iter: 339 loss: 6.88932516e-07
Iter: 340 loss: 6.94251753e-07
Iter: 341 loss: 6.8829803e-07
Iter: 342 loss: 6.85969894e-07
Iter: 343 loss: 7.0307533e-07
Iter: 344 loss: 6.85745704e-07
Iter: 345 loss: 6.8441534e-07
Iter: 346 loss: 6.97378e-07
Iter: 347 loss: 6.84384e-07
Iter: 348 loss: 6.8320071e-07
Iter: 349 loss: 6.80237463e-07
Iter: 350 loss: 7.03773537e-07
Iter: 351 loss: 6.79699838e-07
Iter: 352 loss: 6.76893535e-07
Iter: 353 loss: 6.89951435e-07
Iter: 354 loss: 6.76383706e-07
Iter: 355 loss: 6.7375629e-07
Iter: 356 loss: 7.02374109e-07
Iter: 357 loss: 6.73686827e-07
Iter: 358 loss: 6.71899784e-07
Iter: 359 loss: 6.73721104e-07
Iter: 360 loss: 6.70863187e-07
Iter: 361 loss: 6.69213705e-07
Iter: 362 loss: 6.66094422e-07
Iter: 363 loss: 7.28976772e-07
Iter: 364 loss: 6.66057758e-07
Iter: 365 loss: 6.62062234e-07
Iter: 366 loss: 6.79616392e-07
Iter: 367 loss: 6.61266199e-07
Iter: 368 loss: 6.58965178e-07
Iter: 369 loss: 6.58948466e-07
Iter: 370 loss: 6.56710768e-07
Iter: 371 loss: 6.61130684e-07
Iter: 372 loss: 6.55829922e-07
Iter: 373 loss: 6.53709208e-07
Iter: 374 loss: 6.56388579e-07
Iter: 375 loss: 6.52555059e-07
Iter: 376 loss: 6.50719e-07
Iter: 377 loss: 6.48503658e-07
Iter: 378 loss: 6.48300102e-07
Iter: 379 loss: 6.47791808e-07
Iter: 380 loss: 6.46727131e-07
Iter: 381 loss: 6.45436387e-07
Iter: 382 loss: 6.49194362e-07
Iter: 383 loss: 6.45006935e-07
Iter: 384 loss: 6.4370056e-07
Iter: 385 loss: 6.44427701e-07
Iter: 386 loss: 6.42830855e-07
Iter: 387 loss: 6.41239353e-07
Iter: 388 loss: 6.42575685e-07
Iter: 389 loss: 6.40326164e-07
Iter: 390 loss: 6.3855282e-07
Iter: 391 loss: 6.36832283e-07
Iter: 392 loss: 6.36413e-07
Iter: 393 loss: 6.33879154e-07
Iter: 394 loss: 6.44081751e-07
Iter: 395 loss: 6.33314698e-07
Iter: 396 loss: 6.30662385e-07
Iter: 397 loss: 6.66291214e-07
Iter: 398 loss: 6.30646809e-07
Iter: 399 loss: 6.29513e-07
Iter: 400 loss: 6.2907452e-07
Iter: 401 loss: 6.28442251e-07
Iter: 402 loss: 6.26531573e-07
Iter: 403 loss: 6.23143251e-07
Iter: 404 loss: 6.23092319e-07
Iter: 405 loss: 6.21014237e-07
Iter: 406 loss: 6.51040807e-07
Iter: 407 loss: 6.20980074e-07
Iter: 408 loss: 6.19207412e-07
Iter: 409 loss: 6.35993331e-07
Iter: 410 loss: 6.1910049e-07
Iter: 411 loss: 6.1788694e-07
Iter: 412 loss: 6.19378341e-07
Iter: 413 loss: 6.17264618e-07
Iter: 414 loss: 6.15759348e-07
Iter: 415 loss: 6.14094915e-07
Iter: 416 loss: 6.13829172e-07
Iter: 417 loss: 6.12051053e-07
Iter: 418 loss: 6.36998436e-07
Iter: 419 loss: 6.12062081e-07
Iter: 420 loss: 6.10303175e-07
Iter: 421 loss: 6.22182e-07
Iter: 422 loss: 6.10115535e-07
Iter: 423 loss: 6.09411245e-07
Iter: 424 loss: 6.07836853e-07
Iter: 425 loss: 6.30955753e-07
Iter: 426 loss: 6.07824632e-07
Iter: 427 loss: 6.05530317e-07
Iter: 428 loss: 6.07517336e-07
Iter: 429 loss: 6.0423281e-07
Iter: 430 loss: 6.02078785e-07
Iter: 431 loss: 6.12451e-07
Iter: 432 loss: 6.0167622e-07
Iter: 433 loss: 5.99488317e-07
Iter: 434 loss: 6.21396566e-07
Iter: 435 loss: 5.99463704e-07
Iter: 436 loss: 5.98104862e-07
Iter: 437 loss: 5.98956717e-07
Iter: 438 loss: 5.9725437e-07
Iter: 439 loss: 5.95621373e-07
Iter: 440 loss: 6.07044853e-07
Iter: 441 loss: 5.95475626e-07
Iter: 442 loss: 5.94509345e-07
Iter: 443 loss: 5.94118092e-07
Iter: 444 loss: 5.9365658e-07
Iter: 445 loss: 5.92254366e-07
Iter: 446 loss: 5.9443272e-07
Iter: 447 loss: 5.91550531e-07
Iter: 448 loss: 5.90368131e-07
Iter: 449 loss: 5.96290874e-07
Iter: 450 loss: 5.9019311e-07
Iter: 451 loss: 5.88511057e-07
Iter: 452 loss: 5.88875878e-07
Iter: 453 loss: 5.87238162e-07
Iter: 454 loss: 5.86120279e-07
Iter: 455 loss: 5.88622584e-07
Iter: 456 loss: 5.85683892e-07
Iter: 457 loss: 5.84567829e-07
Iter: 458 loss: 6.00726935e-07
Iter: 459 loss: 5.84543159e-07
Iter: 460 loss: 5.83359e-07
Iter: 461 loss: 5.81679615e-07
Iter: 462 loss: 5.8162351e-07
Iter: 463 loss: 5.80277117e-07
Iter: 464 loss: 5.79499101e-07
Iter: 465 loss: 5.78970742e-07
Iter: 466 loss: 5.77451317e-07
Iter: 467 loss: 5.91245907e-07
Iter: 468 loss: 5.77380661e-07
Iter: 469 loss: 5.76035745e-07
Iter: 470 loss: 5.78457957e-07
Iter: 471 loss: 5.75439799e-07
Iter: 472 loss: 5.74570947e-07
Iter: 473 loss: 5.74547e-07
Iter: 474 loss: 5.73807597e-07
Iter: 475 loss: 5.72329668e-07
Iter: 476 loss: 6.03293188e-07
Iter: 477 loss: 5.72326087e-07
Iter: 478 loss: 5.71122143e-07
Iter: 479 loss: 5.71133739e-07
Iter: 480 loss: 5.70438829e-07
Iter: 481 loss: 5.68430096e-07
Iter: 482 loss: 5.78158279e-07
Iter: 483 loss: 5.6775832e-07
Iter: 484 loss: 5.66313702e-07
Iter: 485 loss: 5.66183473e-07
Iter: 486 loss: 5.65115045e-07
Iter: 487 loss: 5.7172e-07
Iter: 488 loss: 5.6498709e-07
Iter: 489 loss: 5.64123127e-07
Iter: 490 loss: 5.63558615e-07
Iter: 491 loss: 5.63204367e-07
Iter: 492 loss: 5.62542368e-07
Iter: 493 loss: 5.62503828e-07
Iter: 494 loss: 5.61697334e-07
Iter: 495 loss: 5.60651074e-07
Iter: 496 loss: 5.60643628e-07
Iter: 497 loss: 5.59656e-07
Iter: 498 loss: 5.57919861e-07
Iter: 499 loss: 5.97150461e-07
Iter: 500 loss: 5.5789377e-07
Iter: 501 loss: 5.56388557e-07
Iter: 502 loss: 5.71437909e-07
Iter: 503 loss: 5.56350471e-07
Iter: 504 loss: 5.54843496e-07
Iter: 505 loss: 5.56918337e-07
Iter: 506 loss: 5.54097483e-07
Iter: 507 loss: 5.53342886e-07
Iter: 508 loss: 5.53211464e-07
Iter: 509 loss: 5.52514621e-07
Iter: 510 loss: 5.51278504e-07
Iter: 511 loss: 5.51291123e-07
Iter: 512 loss: 5.50022492e-07
Iter: 513 loss: 5.67734332e-07
Iter: 514 loss: 5.50031359e-07
Iter: 515 loss: 5.49347703e-07
Iter: 516 loss: 5.48256935e-07
Iter: 517 loss: 5.48264438e-07
Iter: 518 loss: 5.46635135e-07
Iter: 519 loss: 5.50529137e-07
Iter: 520 loss: 5.46075114e-07
Iter: 521 loss: 5.44832744e-07
Iter: 522 loss: 5.47177e-07
Iter: 523 loss: 5.44286763e-07
Iter: 524 loss: 5.43510509e-07
Iter: 525 loss: 5.43475551e-07
Iter: 526 loss: 5.42759892e-07
Iter: 527 loss: 5.4140753e-07
Iter: 528 loss: 5.71116402e-07
Iter: 529 loss: 5.41422537e-07
Iter: 530 loss: 5.40318183e-07
Iter: 531 loss: 5.5375358e-07
Iter: 532 loss: 5.40299595e-07
Iter: 533 loss: 5.39601047e-07
Iter: 534 loss: 5.39545567e-07
Iter: 535 loss: 5.39008624e-07
Iter: 536 loss: 5.37703158e-07
Iter: 537 loss: 5.49141873e-07
Iter: 538 loss: 5.37594588e-07
Iter: 539 loss: 5.37177698e-07
Iter: 540 loss: 5.36611822e-07
Iter: 541 loss: 5.36569701e-07
Iter: 542 loss: 5.35643494e-07
Iter: 543 loss: 5.39237931e-07
Iter: 544 loss: 5.35468473e-07
Iter: 545 loss: 5.34452283e-07
Iter: 546 loss: 5.37474e-07
Iter: 547 loss: 5.3419285e-07
Iter: 548 loss: 5.33506636e-07
Iter: 549 loss: 5.3536769e-07
Iter: 550 loss: 5.33326045e-07
Iter: 551 loss: 5.32437639e-07
Iter: 552 loss: 5.32095328e-07
Iter: 553 loss: 5.31673152e-07
Iter: 554 loss: 5.30731938e-07
Iter: 555 loss: 5.32716911e-07
Iter: 556 loss: 5.30376496e-07
Iter: 557 loss: 5.29395379e-07
Iter: 558 loss: 5.31908313e-07
Iter: 559 loss: 5.29080694e-07
Iter: 560 loss: 5.28059445e-07
Iter: 561 loss: 5.28041539e-07
Iter: 562 loss: 5.27284669e-07
Iter: 563 loss: 5.267608e-07
Iter: 564 loss: 5.26583335e-07
Iter: 565 loss: 5.25876146e-07
Iter: 566 loss: 5.24606662e-07
Iter: 567 loss: 5.52983067e-07
Iter: 568 loss: 5.24623488e-07
Iter: 569 loss: 5.23509129e-07
Iter: 570 loss: 5.37345045e-07
Iter: 571 loss: 5.23519e-07
Iter: 572 loss: 5.22456787e-07
Iter: 573 loss: 5.28148348e-07
Iter: 574 loss: 5.22301491e-07
Iter: 575 loss: 5.21660525e-07
Iter: 576 loss: 5.2023222e-07
Iter: 577 loss: 5.4296396e-07
Iter: 578 loss: 5.20230174e-07
Iter: 579 loss: 5.18832621e-07
Iter: 580 loss: 5.26923827e-07
Iter: 581 loss: 5.18657373e-07
Iter: 582 loss: 5.17592866e-07
Iter: 583 loss: 5.17601e-07
Iter: 584 loss: 5.17289322e-07
Iter: 585 loss: 5.16617661e-07
Iter: 586 loss: 5.31248588e-07
Iter: 587 loss: 5.16609589e-07
Iter: 588 loss: 5.15585839e-07
Iter: 589 loss: 5.20470905e-07
Iter: 590 loss: 5.15396e-07
Iter: 591 loss: 5.14701242e-07
Iter: 592 loss: 5.15435545e-07
Iter: 593 loss: 5.14312205e-07
Iter: 594 loss: 5.13294083e-07
Iter: 595 loss: 5.12126576e-07
Iter: 596 loss: 5.12004476e-07
Iter: 597 loss: 5.10762391e-07
Iter: 598 loss: 5.15676788e-07
Iter: 599 loss: 5.10455493e-07
Iter: 600 loss: 5.0967526e-07
Iter: 601 loss: 5.09671509e-07
Iter: 602 loss: 5.08950279e-07
Iter: 603 loss: 5.09258825e-07
Iter: 604 loss: 5.08504456e-07
Iter: 605 loss: 5.07718482e-07
Iter: 606 loss: 5.1379e-07
Iter: 607 loss: 5.07680454e-07
Iter: 608 loss: 5.06938875e-07
Iter: 609 loss: 5.08883147e-07
Iter: 610 loss: 5.06688593e-07
Iter: 611 loss: 5.0626511e-07
Iter: 612 loss: 5.05283197e-07
Iter: 613 loss: 5.16934733e-07
Iter: 614 loss: 5.05204468e-07
Iter: 615 loss: 5.047782e-07
Iter: 616 loss: 5.04680088e-07
Iter: 617 loss: 5.04049581e-07
Iter: 618 loss: 5.03126898e-07
Iter: 619 loss: 5.03098136e-07
Iter: 620 loss: 5.01981731e-07
Iter: 621 loss: 5.07889581e-07
Iter: 622 loss: 5.01813133e-07
Iter: 623 loss: 5.01172508e-07
Iter: 624 loss: 5.05068044e-07
Iter: 625 loss: 5.01101908e-07
Iter: 626 loss: 5.0039921e-07
Iter: 627 loss: 4.99880571e-07
Iter: 628 loss: 4.99648081e-07
Iter: 629 loss: 4.98791906e-07
Iter: 630 loss: 4.97657425e-07
Iter: 631 loss: 4.97591884e-07
Iter: 632 loss: 4.96312509e-07
Iter: 633 loss: 5.11346343e-07
Iter: 634 loss: 4.96264363e-07
Iter: 635 loss: 4.95262555e-07
Iter: 636 loss: 5.00851e-07
Iter: 637 loss: 4.95174731e-07
Iter: 638 loss: 4.94669166e-07
Iter: 639 loss: 5.02569776e-07
Iter: 640 loss: 4.94685764e-07
Iter: 641 loss: 4.94176732e-07
Iter: 642 loss: 4.94807068e-07
Iter: 643 loss: 4.93949358e-07
Iter: 644 loss: 4.93345112e-07
Iter: 645 loss: 4.96611449e-07
Iter: 646 loss: 4.93304583e-07
Iter: 647 loss: 4.92966876e-07
Iter: 648 loss: 4.92099502e-07
Iter: 649 loss: 5.00337478e-07
Iter: 650 loss: 4.91978426e-07
Iter: 651 loss: 4.9107723e-07
Iter: 652 loss: 4.98158442e-07
Iter: 653 loss: 4.90962179e-07
Iter: 654 loss: 4.90383513e-07
Iter: 655 loss: 4.98051e-07
Iter: 656 loss: 4.90368677e-07
Iter: 657 loss: 4.89799106e-07
Iter: 658 loss: 4.88987155e-07
Iter: 659 loss: 4.88937303e-07
Iter: 660 loss: 4.88043497e-07
Iter: 661 loss: 4.89309457e-07
Iter: 662 loss: 4.87604098e-07
Iter: 663 loss: 4.86858085e-07
Iter: 664 loss: 4.86840861e-07
Iter: 665 loss: 4.86344391e-07
Iter: 666 loss: 4.85298415e-07
Iter: 667 loss: 5.00599754e-07
Iter: 668 loss: 4.85285909e-07
Iter: 669 loss: 4.84181783e-07
Iter: 670 loss: 4.94455776e-07
Iter: 671 loss: 4.8414006e-07
Iter: 672 loss: 4.83467772e-07
Iter: 673 loss: 4.82646669e-07
Iter: 674 loss: 4.82571352e-07
Iter: 675 loss: 4.82584937e-07
Iter: 676 loss: 4.82134624e-07
Iter: 677 loss: 4.81642e-07
Iter: 678 loss: 4.8155789e-07
Iter: 679 loss: 4.8125554e-07
Iter: 680 loss: 4.80668e-07
Iter: 681 loss: 4.83754e-07
Iter: 682 loss: 4.80566769e-07
Iter: 683 loss: 4.80117933e-07
Iter: 684 loss: 4.80354345e-07
Iter: 685 loss: 4.79766925e-07
Iter: 686 loss: 4.79092193e-07
Iter: 687 loss: 4.78700372e-07
Iter: 688 loss: 4.78444349e-07
Iter: 689 loss: 4.7766855e-07
Iter: 690 loss: 4.77299579e-07
Iter: 691 loss: 4.76939874e-07
Iter: 692 loss: 4.76219356e-07
Iter: 693 loss: 4.76131049e-07
Iter: 694 loss: 4.75637023e-07
Iter: 695 loss: 4.78776542e-07
Iter: 696 loss: 4.75537604e-07
Iter: 697 loss: 4.74948422e-07
Iter: 698 loss: 4.74569674e-07
Iter: 699 loss: 4.74323e-07
Iter: 700 loss: 4.73770086e-07
Iter: 701 loss: 4.75385633e-07
Iter: 702 loss: 4.73608338e-07
Iter: 703 loss: 4.72918657e-07
Iter: 704 loss: 4.76333412e-07
Iter: 705 loss: 4.72819806e-07
Iter: 706 loss: 4.72266436e-07
Iter: 707 loss: 4.71419526e-07
Iter: 708 loss: 4.71381099e-07
Iter: 709 loss: 4.70724075e-07
Iter: 710 loss: 4.70716941e-07
Iter: 711 loss: 4.7022175e-07
Iter: 712 loss: 4.77085848e-07
Iter: 713 loss: 4.70229537e-07
Iter: 714 loss: 4.69855024e-07
Iter: 715 loss: 4.69408405e-07
Iter: 716 loss: 4.69387203e-07
Iter: 717 loss: 4.6888394e-07
Iter: 718 loss: 4.73250054e-07
Iter: 719 loss: 4.68830734e-07
Iter: 720 loss: 4.6844886e-07
Iter: 721 loss: 4.67796923e-07
Iter: 722 loss: 4.67781149e-07
Iter: 723 loss: 4.6710619e-07
Iter: 724 loss: 4.69126206e-07
Iter: 725 loss: 4.66927105e-07
Iter: 726 loss: 4.66143831e-07
Iter: 727 loss: 4.6777933e-07
Iter: 728 loss: 4.65804078e-07
Iter: 729 loss: 4.65125481e-07
Iter: 730 loss: 4.65817607e-07
Iter: 731 loss: 4.64705721e-07
Iter: 732 loss: 4.64158177e-07
Iter: 733 loss: 4.64093205e-07
Iter: 734 loss: 4.63767094e-07
Iter: 735 loss: 4.63017074e-07
Iter: 736 loss: 4.7253593e-07
Iter: 737 loss: 4.62957928e-07
Iter: 738 loss: 4.621931e-07
Iter: 739 loss: 4.69088178e-07
Iter: 740 loss: 4.62153082e-07
Iter: 741 loss: 4.61694015e-07
Iter: 742 loss: 4.62334839e-07
Iter: 743 loss: 4.61490714e-07
Iter: 744 loss: 4.60801346e-07
Iter: 745 loss: 4.63656932e-07
Iter: 746 loss: 4.6064568e-07
Iter: 747 loss: 4.60272304e-07
Iter: 748 loss: 4.60521306e-07
Iter: 749 loss: 4.60060903e-07
Iter: 750 loss: 4.5959996e-07
Iter: 751 loss: 4.66675232e-07
Iter: 752 loss: 4.59614853e-07
Iter: 753 loss: 4.5925978e-07
Iter: 754 loss: 4.58604859e-07
Iter: 755 loss: 4.73239481e-07
Iter: 756 loss: 4.58589028e-07
Iter: 757 loss: 4.57997686e-07
Iter: 758 loss: 4.59016917e-07
Iter: 759 loss: 4.57754e-07
Iter: 760 loss: 4.57204976e-07
Iter: 761 loss: 4.57224701e-07
Iter: 762 loss: 4.56858e-07
Iter: 763 loss: 4.55950271e-07
Iter: 764 loss: 4.67676415e-07
Iter: 765 loss: 4.5586691e-07
Iter: 766 loss: 4.55093499e-07
Iter: 767 loss: 4.62052384e-07
Iter: 768 loss: 4.55069738e-07
Iter: 769 loss: 4.54490646e-07
Iter: 770 loss: 4.61302392e-07
Iter: 771 loss: 4.54473195e-07
Iter: 772 loss: 4.5401805e-07
Iter: 773 loss: 4.53850646e-07
Iter: 774 loss: 4.53612586e-07
Iter: 775 loss: 4.5309821e-07
Iter: 776 loss: 4.5345206e-07
Iter: 777 loss: 4.52782785e-07
Iter: 778 loss: 4.52276254e-07
Iter: 779 loss: 4.52543702e-07
Iter: 780 loss: 4.51902e-07
Iter: 781 loss: 4.51358375e-07
Iter: 782 loss: 4.51382647e-07
Iter: 783 loss: 4.51009726e-07
Iter: 784 loss: 4.52381357e-07
Iter: 785 loss: 4.50921846e-07
Iter: 786 loss: 4.50576039e-07
Iter: 787 loss: 4.51132252e-07
Iter: 788 loss: 4.50370891e-07
Iter: 789 loss: 4.49756499e-07
Iter: 790 loss: 4.51060203e-07
Iter: 791 loss: 4.4951156e-07
Iter: 792 loss: 4.49179026e-07
Iter: 793 loss: 4.48285959e-07
Iter: 794 loss: 4.52409779e-07
Iter: 795 loss: 4.47968318e-07
Iter: 796 loss: 4.47730486e-07
Iter: 797 loss: 4.47462469e-07
Iter: 798 loss: 4.47037934e-07
Iter: 799 loss: 4.48144419e-07
Iter: 800 loss: 4.46912139e-07
Iter: 801 loss: 4.46474473e-07
Iter: 802 loss: 4.46516822e-07
Iter: 803 loss: 4.46152256e-07
Iter: 804 loss: 4.45666615e-07
Iter: 805 loss: 4.46383751e-07
Iter: 806 loss: 4.45409626e-07
Iter: 807 loss: 4.45161419e-07
Iter: 808 loss: 4.45095054e-07
Iter: 809 loss: 4.4488462e-07
Iter: 810 loss: 4.44514797e-07
Iter: 811 loss: 4.52554985e-07
Iter: 812 loss: 4.44516701e-07
Iter: 813 loss: 4.43945964e-07
Iter: 814 loss: 4.43393219e-07
Iter: 815 loss: 4.43260205e-07
Iter: 816 loss: 4.42530734e-07
Iter: 817 loss: 4.44179307e-07
Iter: 818 loss: 4.42268117e-07
Iter: 819 loss: 4.41684676e-07
Iter: 820 loss: 4.46757952e-07
Iter: 821 loss: 4.4164247e-07
Iter: 822 loss: 4.41177406e-07
Iter: 823 loss: 4.46306302e-07
Iter: 824 loss: 4.41152054e-07
Iter: 825 loss: 4.40830036e-07
Iter: 826 loss: 4.42516239e-07
Iter: 827 loss: 4.40768929e-07
Iter: 828 loss: 4.40513247e-07
Iter: 829 loss: 4.40228e-07
Iter: 830 loss: 4.4017645e-07
Iter: 831 loss: 4.39737647e-07
Iter: 832 loss: 4.39616343e-07
Iter: 833 loss: 4.39343722e-07
Iter: 834 loss: 4.38721202e-07
Iter: 835 loss: 4.3870989e-07
Iter: 836 loss: 4.38278022e-07
Iter: 837 loss: 4.37609174e-07
Iter: 838 loss: 4.41142504e-07
Iter: 839 loss: 4.37514757e-07
Iter: 840 loss: 4.36933249e-07
Iter: 841 loss: 4.43992207e-07
Iter: 842 loss: 4.36927337e-07
Iter: 843 loss: 4.36455366e-07
Iter: 844 loss: 4.37562676e-07
Iter: 845 loss: 4.36291913e-07
Iter: 846 loss: 4.35780834e-07
Iter: 847 loss: 4.35234881e-07
Iter: 848 loss: 4.35115822e-07
Iter: 849 loss: 4.34608808e-07
Iter: 850 loss: 4.3460804e-07
Iter: 851 loss: 4.34096137e-07
Iter: 852 loss: 4.34847834e-07
Iter: 853 loss: 4.3381641e-07
Iter: 854 loss: 4.33414783e-07
Iter: 855 loss: 4.33973071e-07
Iter: 856 loss: 4.33225154e-07
Iter: 857 loss: 4.32859338e-07
Iter: 858 loss: 4.36463523e-07
Iter: 859 loss: 4.32839329e-07
Iter: 860 loss: 4.32445916e-07
Iter: 861 loss: 4.33449571e-07
Iter: 862 loss: 4.323268e-07
Iter: 863 loss: 4.3212691e-07
Iter: 864 loss: 4.33041e-07
Iter: 865 loss: 4.32093088e-07
Iter: 866 loss: 4.31892545e-07
Iter: 867 loss: 4.31306574e-07
Iter: 868 loss: 4.35107381e-07
Iter: 869 loss: 4.31149147e-07
Iter: 870 loss: 4.30572925e-07
Iter: 871 loss: 4.34393343e-07
Iter: 872 loss: 4.30489592e-07
Iter: 873 loss: 4.29876422e-07
Iter: 874 loss: 4.30564228e-07
Iter: 875 loss: 4.2954531e-07
Iter: 876 loss: 4.28870948e-07
Iter: 877 loss: 4.31134652e-07
Iter: 878 loss: 4.28679243e-07
Iter: 879 loss: 4.2807244e-07
Iter: 880 loss: 4.3717074e-07
Iter: 881 loss: 4.28089493e-07
Iter: 882 loss: 4.27754458e-07
Iter: 883 loss: 4.27229509e-07
Iter: 884 loss: 4.27197563e-07
Iter: 885 loss: 4.2680216e-07
Iter: 886 loss: 4.2678414e-07
Iter: 887 loss: 4.26466954e-07
Iter: 888 loss: 4.2764475e-07
Iter: 889 loss: 4.26377909e-07
Iter: 890 loss: 4.26084711e-07
Iter: 891 loss: 4.25755758e-07
Iter: 892 loss: 4.25717303e-07
Iter: 893 loss: 4.25481744e-07
Iter: 894 loss: 4.2544454e-07
Iter: 895 loss: 4.25180701e-07
Iter: 896 loss: 4.25020175e-07
Iter: 897 loss: 4.24904385e-07
Iter: 898 loss: 4.24619031e-07
Iter: 899 loss: 4.25930381e-07
Iter: 900 loss: 4.24613177e-07
Iter: 901 loss: 4.24287293e-07
Iter: 902 loss: 4.23575329e-07
Iter: 903 loss: 4.34381519e-07
Iter: 904 loss: 4.23538097e-07
Iter: 905 loss: 4.22912564e-07
Iter: 906 loss: 4.29303867e-07
Iter: 907 loss: 4.22903895e-07
Iter: 908 loss: 4.2244011e-07
Iter: 909 loss: 4.21954098e-07
Iter: 910 loss: 4.21864286e-07
Iter: 911 loss: 4.21336381e-07
Iter: 912 loss: 4.29533e-07
Iter: 913 loss: 4.21348375e-07
Iter: 914 loss: 4.20807339e-07
Iter: 915 loss: 4.22681637e-07
Iter: 916 loss: 4.20693e-07
Iter: 917 loss: 4.20364898e-07
Iter: 918 loss: 4.21065721e-07
Iter: 919 loss: 4.20243595e-07
Iter: 920 loss: 4.19936384e-07
Iter: 921 loss: 4.21156301e-07
Iter: 922 loss: 4.19839779e-07
Iter: 923 loss: 4.19471348e-07
Iter: 924 loss: 4.2012266e-07
Iter: 925 loss: 4.19273761e-07
Iter: 926 loss: 4.18985564e-07
Iter: 927 loss: 4.18906438e-07
Iter: 928 loss: 4.18718514e-07
Iter: 929 loss: 4.18545739e-07
Iter: 930 loss: 4.18439612e-07
Iter: 931 loss: 4.18311345e-07
Iter: 932 loss: 4.17954368e-07
Iter: 933 loss: 4.21213258e-07
Iter: 934 loss: 4.1786393e-07
Iter: 935 loss: 4.17421546e-07
Iter: 936 loss: 4.21609968e-07
Iter: 937 loss: 4.17411172e-07
Iter: 938 loss: 4.17060789e-07
Iter: 939 loss: 4.1678129e-07
Iter: 940 loss: 4.16670503e-07
Iter: 941 loss: 4.16127961e-07
Iter: 942 loss: 4.17660544e-07
Iter: 943 loss: 4.15921818e-07
Iter: 944 loss: 4.15461699e-07
Iter: 945 loss: 4.15767431e-07
Iter: 946 loss: 4.15170092e-07
Iter: 947 loss: 4.14664726e-07
Iter: 948 loss: 4.1798441e-07
Iter: 949 loss: 4.14613424e-07
Iter: 950 loss: 4.14078812e-07
Iter: 951 loss: 4.15781869e-07
Iter: 952 loss: 4.13975783e-07
Iter: 953 loss: 4.13543489e-07
Iter: 954 loss: 4.18619123e-07
Iter: 955 loss: 4.13543603e-07
Iter: 956 loss: 4.13332259e-07
Iter: 957 loss: 4.12858839e-07
Iter: 958 loss: 4.19312158e-07
Iter: 959 loss: 4.12829962e-07
Iter: 960 loss: 4.1243598e-07
Iter: 961 loss: 4.18406643e-07
Iter: 962 loss: 4.1242464e-07
Iter: 963 loss: 4.12022985e-07
Iter: 964 loss: 4.13651946e-07
Iter: 965 loss: 4.11939538e-07
Iter: 966 loss: 4.1158421e-07
Iter: 967 loss: 4.12525139e-07
Iter: 968 loss: 4.11446706e-07
Iter: 969 loss: 4.1110917e-07
Iter: 970 loss: 4.14208841e-07
Iter: 971 loss: 4.11110932e-07
Iter: 972 loss: 4.10971836e-07
Iter: 973 loss: 4.10503219e-07
Iter: 974 loss: 4.12120613e-07
Iter: 975 loss: 4.10320922e-07
Iter: 976 loss: 4.09761014e-07
Iter: 977 loss: 4.14722507e-07
Iter: 978 loss: 4.0972472e-07
Iter: 979 loss: 4.09249367e-07
Iter: 980 loss: 4.12471053e-07
Iter: 981 loss: 4.09178824e-07
Iter: 982 loss: 4.0884e-07
Iter: 983 loss: 4.09859183e-07
Iter: 984 loss: 4.08734309e-07
Iter: 985 loss: 4.08397227e-07
Iter: 986 loss: 4.07649708e-07
Iter: 987 loss: 4.15842464e-07
Iter: 988 loss: 4.07554978e-07
Iter: 989 loss: 4.0694124e-07
Iter: 990 loss: 4.14691499e-07
Iter: 991 loss: 4.0691333e-07
Iter: 992 loss: 4.06405405e-07
Iter: 993 loss: 4.09541684e-07
Iter: 994 loss: 4.06329207e-07
Iter: 995 loss: 4.05946082e-07
Iter: 996 loss: 4.0580511e-07
Iter: 997 loss: 4.05594875e-07
Iter: 998 loss: 4.05461151e-07
Iter: 999 loss: 4.05330979e-07
Iter: 1000 loss: 4.05148796e-07
Iter: 1001 loss: 4.0537202e-07
Iter: 1002 loss: 4.05043863e-07
Iter: 1003 loss: 4.04780167e-07
Iter: 1004 loss: 4.06168084e-07
Iter: 1005 loss: 4.0479685e-07
Iter: 1006 loss: 4.04553646e-07
Iter: 1007 loss: 4.04372344e-07
Iter: 1008 loss: 4.04290489e-07
Iter: 1009 loss: 4.04028356e-07
Iter: 1010 loss: 4.04498167e-07
Iter: 1011 loss: 4.03923593e-07
Iter: 1012 loss: 4.03541065e-07
Iter: 1013 loss: 4.03952583e-07
Iter: 1014 loss: 4.0331733e-07
Iter: 1015 loss: 4.02987752e-07
Iter: 1016 loss: 4.02625545e-07
Iter: 1017 loss: 4.02571743e-07
Iter: 1018 loss: 4.02066718e-07
Iter: 1019 loss: 4.05660074e-07
Iter: 1020 loss: 4.02024341e-07
Iter: 1021 loss: 4.01654177e-07
Iter: 1022 loss: 4.03807604e-07
Iter: 1023 loss: 4.01582497e-07
Iter: 1024 loss: 4.01277958e-07
Iter: 1025 loss: 4.03529214e-07
Iter: 1026 loss: 4.0125974e-07
Iter: 1027 loss: 4.01017047e-07
Iter: 1028 loss: 4.00463819e-07
Iter: 1029 loss: 4.10040968e-07
Iter: 1030 loss: 4.0046686e-07
Iter: 1031 loss: 3.99921731e-07
Iter: 1032 loss: 4.0291755e-07
Iter: 1033 loss: 3.99820237e-07
Iter: 1034 loss: 3.99427165e-07
Iter: 1035 loss: 4.04727757e-07
Iter: 1036 loss: 3.99423755e-07
Iter: 1037 loss: 3.99124133e-07
Iter: 1038 loss: 4.01021566e-07
Iter: 1039 loss: 3.99079454e-07
Iter: 1040 loss: 3.98895793e-07
Iter: 1041 loss: 3.99592068e-07
Iter: 1042 loss: 3.98845174e-07
Iter: 1043 loss: 3.98604101e-07
Iter: 1044 loss: 3.98186216e-07
Iter: 1045 loss: 3.98188632e-07
Iter: 1046 loss: 3.97951368e-07
Iter: 1047 loss: 4.01030292e-07
Iter: 1048 loss: 3.97962197e-07
Iter: 1049 loss: 3.97774414e-07
Iter: 1050 loss: 3.97650581e-07
Iter: 1051 loss: 3.9755821e-07
Iter: 1052 loss: 3.97217974e-07
Iter: 1053 loss: 3.97766087e-07
Iter: 1054 loss: 3.97050798e-07
Iter: 1055 loss: 3.96720623e-07
Iter: 1056 loss: 3.96269797e-07
Iter: 1057 loss: 3.96232736e-07
Iter: 1058 loss: 3.95760594e-07
Iter: 1059 loss: 3.95737061e-07
Iter: 1060 loss: 3.95382074e-07
Iter: 1061 loss: 3.9730466e-07
Iter: 1062 loss: 3.9531821e-07
Iter: 1063 loss: 3.95058407e-07
Iter: 1064 loss: 3.95479674e-07
Iter: 1065 loss: 3.94905726e-07
Iter: 1066 loss: 3.94587516e-07
Iter: 1067 loss: 3.94079052e-07
Iter: 1068 loss: 3.94075528e-07
Iter: 1069 loss: 3.94179608e-07
Iter: 1070 loss: 3.93810694e-07
Iter: 1071 loss: 3.93670092e-07
Iter: 1072 loss: 3.93819874e-07
Iter: 1073 loss: 3.93612481e-07
Iter: 1074 loss: 3.93422852e-07
Iter: 1075 loss: 3.9390153e-07
Iter: 1076 loss: 3.93358761e-07
Iter: 1077 loss: 3.93162622e-07
Iter: 1078 loss: 3.92885511e-07
Iter: 1079 loss: 3.92876302e-07
Iter: 1080 loss: 3.92596178e-07
Iter: 1081 loss: 3.94717233e-07
Iter: 1082 loss: 3.9258839e-07
Iter: 1083 loss: 3.9230116e-07
Iter: 1084 loss: 3.93149691e-07
Iter: 1085 loss: 3.92220841e-07
Iter: 1086 loss: 3.92009724e-07
Iter: 1087 loss: 3.91646921e-07
Iter: 1088 loss: 3.91674917e-07
Iter: 1089 loss: 3.91169834e-07
Iter: 1090 loss: 3.93213782e-07
Iter: 1091 loss: 3.9108312e-07
Iter: 1092 loss: 3.90679503e-07
Iter: 1093 loss: 3.91818759e-07
Iter: 1094 loss: 3.90546916e-07
Iter: 1095 loss: 3.90194515e-07
Iter: 1096 loss: 3.94876423e-07
Iter: 1097 loss: 3.90171351e-07
Iter: 1098 loss: 3.89936872e-07
Iter: 1099 loss: 3.89404448e-07
Iter: 1100 loss: 3.98014038e-07
Iter: 1101 loss: 3.89385832e-07
Iter: 1102 loss: 3.89059323e-07
Iter: 1103 loss: 3.89045908e-07
Iter: 1104 loss: 3.88787441e-07
Iter: 1105 loss: 3.91283891e-07
Iter: 1106 loss: 3.88770275e-07
Iter: 1107 loss: 3.88548557e-07
Iter: 1108 loss: 3.88499757e-07
Iter: 1109 loss: 3.88377515e-07
Iter: 1110 loss: 3.88068912e-07
Iter: 1111 loss: 3.89964327e-07
Iter: 1112 loss: 3.88032305e-07
Iter: 1113 loss: 3.87862741e-07
Iter: 1114 loss: 3.87566331e-07
Iter: 1115 loss: 3.93931174e-07
Iter: 1116 loss: 3.87562579e-07
Iter: 1117 loss: 3.87317471e-07
Iter: 1118 loss: 3.87299679e-07
Iter: 1119 loss: 3.87140403e-07
Iter: 1120 loss: 3.87221206e-07
Iter: 1121 loss: 3.87009663e-07
Iter: 1122 loss: 3.86746649e-07
Iter: 1123 loss: 3.86340048e-07
Iter: 1124 loss: 3.86340361e-07
Iter: 1125 loss: 3.85873307e-07
Iter: 1126 loss: 3.86688782e-07
Iter: 1127 loss: 3.85689304e-07
Iter: 1128 loss: 3.85416e-07
Iter: 1129 loss: 3.85394458e-07
Iter: 1130 loss: 3.85153385e-07
Iter: 1131 loss: 3.85349239e-07
Iter: 1132 loss: 3.84991154e-07
Iter: 1133 loss: 3.84630596e-07
Iter: 1134 loss: 3.84809198e-07
Iter: 1135 loss: 3.84440597e-07
Iter: 1136 loss: 3.84222574e-07
Iter: 1137 loss: 3.84216548e-07
Iter: 1138 loss: 3.83999378e-07
Iter: 1139 loss: 3.84273505e-07
Iter: 1140 loss: 3.83910873e-07
Iter: 1141 loss: 3.83719623e-07
Iter: 1142 loss: 3.8494602e-07
Iter: 1143 loss: 3.83717861e-07
Iter: 1144 loss: 3.83584876e-07
Iter: 1145 loss: 3.83351505e-07
Iter: 1146 loss: 3.83358582e-07
Iter: 1147 loss: 3.83077378e-07
Iter: 1148 loss: 3.83812448e-07
Iter: 1149 loss: 3.8298549e-07
Iter: 1150 loss: 3.82731884e-07
Iter: 1151 loss: 3.84164e-07
Iter: 1152 loss: 3.82693543e-07
Iter: 1153 loss: 3.82381444e-07
Iter: 1154 loss: 3.82014122e-07
Iter: 1155 loss: 3.82005965e-07
Iter: 1156 loss: 3.81590837e-07
Iter: 1157 loss: 3.83069192e-07
Iter: 1158 loss: 3.81479254e-07
Iter: 1159 loss: 3.81162e-07
Iter: 1160 loss: 3.83064616e-07
Iter: 1161 loss: 3.81119605e-07
Iter: 1162 loss: 3.80856136e-07
Iter: 1163 loss: 3.81569407e-07
Iter: 1164 loss: 3.80790397e-07
Iter: 1165 loss: 3.80439246e-07
Iter: 1166 loss: 3.81317932e-07
Iter: 1167 loss: 3.80341532e-07
Iter: 1168 loss: 3.80103245e-07
Iter: 1169 loss: 3.79858818e-07
Iter: 1170 loss: 3.79807432e-07
Iter: 1171 loss: 3.79493827e-07
Iter: 1172 loss: 3.79479616e-07
Iter: 1173 loss: 3.79230812e-07
Iter: 1174 loss: 3.79410466e-07
Iter: 1175 loss: 3.79089784e-07
Iter: 1176 loss: 3.78809403e-07
Iter: 1177 loss: 3.80136157e-07
Iter: 1178 loss: 3.78781635e-07
Iter: 1179 loss: 3.78532206e-07
Iter: 1180 loss: 3.78187877e-07
Iter: 1181 loss: 3.78172217e-07
Iter: 1182 loss: 3.7789556e-07
Iter: 1183 loss: 3.79661088e-07
Iter: 1184 loss: 3.77848068e-07
Iter: 1185 loss: 3.77554386e-07
Iter: 1186 loss: 3.78688185e-07
Iter: 1187 loss: 3.77490267e-07
Iter: 1188 loss: 3.77260562e-07
Iter: 1189 loss: 3.77695812e-07
Iter: 1190 loss: 3.77142811e-07
Iter: 1191 loss: 3.76916574e-07
Iter: 1192 loss: 3.7673027e-07
Iter: 1193 loss: 3.76664929e-07
Iter: 1194 loss: 3.76357292e-07
Iter: 1195 loss: 3.77651645e-07
Iter: 1196 loss: 3.76285641e-07
Iter: 1197 loss: 3.75950236e-07
Iter: 1198 loss: 3.78890689e-07
Iter: 1199 loss: 3.75936253e-07
Iter: 1200 loss: 3.75726302e-07
Iter: 1201 loss: 3.75963452e-07
Iter: 1202 loss: 3.75598574e-07
Iter: 1203 loss: 3.75362333e-07
Iter: 1204 loss: 3.76107494e-07
Iter: 1205 loss: 3.75314386e-07
Iter: 1206 loss: 3.75145532e-07
Iter: 1207 loss: 3.78232642e-07
Iter: 1208 loss: 3.75136835e-07
Iter: 1209 loss: 3.75026502e-07
Iter: 1210 loss: 3.74860406e-07
Iter: 1211 loss: 3.74844149e-07
Iter: 1212 loss: 3.74565644e-07
Iter: 1213 loss: 3.75548609e-07
Iter: 1214 loss: 3.74479669e-07
Iter: 1215 loss: 3.74292597e-07
Iter: 1216 loss: 3.74127694e-07
Iter: 1217 loss: 3.74098363e-07
Iter: 1218 loss: 3.73831028e-07
Iter: 1219 loss: 3.7641405e-07
Iter: 1220 loss: 3.73809598e-07
Iter: 1221 loss: 3.73630513e-07
Iter: 1222 loss: 3.73899809e-07
Iter: 1223 loss: 3.7354161e-07
Iter: 1224 loss: 3.73337258e-07
Iter: 1225 loss: 3.73212771e-07
Iter: 1226 loss: 3.73078535e-07
Iter: 1227 loss: 3.72795455e-07
Iter: 1228 loss: 3.73312048e-07
Iter: 1229 loss: 3.72645985e-07
Iter: 1230 loss: 3.72359409e-07
Iter: 1231 loss: 3.75624495e-07
Iter: 1232 loss: 3.72369584e-07
Iter: 1233 loss: 3.72144257e-07
Iter: 1234 loss: 3.73160105e-07
Iter: 1235 loss: 3.72113561e-07
Iter: 1236 loss: 3.71884482e-07
Iter: 1237 loss: 3.71606546e-07
Iter: 1238 loss: 3.71569683e-07
Iter: 1239 loss: 3.71426154e-07
Iter: 1240 loss: 3.71392844e-07
Iter: 1241 loss: 3.7115376e-07
Iter: 1242 loss: 3.7086653e-07
Iter: 1243 loss: 3.70852121e-07
Iter: 1244 loss: 3.70614941e-07
Iter: 1245 loss: 3.7061767e-07
Iter: 1246 loss: 3.70447339e-07
Iter: 1247 loss: 3.70239263e-07
Iter: 1248 loss: 3.70206067e-07
Iter: 1249 loss: 3.6990383e-07
Iter: 1250 loss: 3.70320606e-07
Iter: 1251 loss: 3.69760954e-07
Iter: 1252 loss: 3.69581016e-07
Iter: 1253 loss: 3.69573627e-07
Iter: 1254 loss: 3.6939926e-07
Iter: 1255 loss: 3.69139116e-07
Iter: 1256 loss: 3.6913309e-07
Iter: 1257 loss: 3.6882e-07
Iter: 1258 loss: 3.69226882e-07
Iter: 1259 loss: 3.68657254e-07
Iter: 1260 loss: 3.68337169e-07
Iter: 1261 loss: 3.705876e-07
Iter: 1262 loss: 3.68307724e-07
Iter: 1263 loss: 3.68092742e-07
Iter: 1264 loss: 3.68617123e-07
Iter: 1265 loss: 3.68007875e-07
Iter: 1266 loss: 3.6773605e-07
Iter: 1267 loss: 3.69649854e-07
Iter: 1268 loss: 3.67711834e-07
Iter: 1269 loss: 3.67516577e-07
Iter: 1270 loss: 3.67275504e-07
Iter: 1271 loss: 3.67264164e-07
Iter: 1272 loss: 3.67095794e-07
Iter: 1273 loss: 3.67040144e-07
Iter: 1274 loss: 3.66927566e-07
Iter: 1275 loss: 3.66782189e-07
Iter: 1276 loss: 3.66775964e-07
Iter: 1277 loss: 3.66503912e-07
Iter: 1278 loss: 3.66919437e-07
Iter: 1279 loss: 3.66376867e-07
Iter: 1280 loss: 3.6615387e-07
Iter: 1281 loss: 3.66279352e-07
Iter: 1282 loss: 3.66074914e-07
Iter: 1283 loss: 3.65807409e-07
Iter: 1284 loss: 3.66148299e-07
Iter: 1285 loss: 3.65704921e-07
Iter: 1286 loss: 3.65573186e-07
Iter: 1287 loss: 3.65539364e-07
Iter: 1288 loss: 3.65447079e-07
Iter: 1289 loss: 3.65139414e-07
Iter: 1290 loss: 3.66370614e-07
Iter: 1291 loss: 3.65007793e-07
Iter: 1292 loss: 3.64674946e-07
Iter: 1293 loss: 3.69213069e-07
Iter: 1294 loss: 3.64657524e-07
Iter: 1295 loss: 3.64378877e-07
Iter: 1296 loss: 3.64634218e-07
Iter: 1297 loss: 3.64221478e-07
Iter: 1298 loss: 3.63973527e-07
Iter: 1299 loss: 3.67153149e-07
Iter: 1300 loss: 3.63946754e-07
Iter: 1301 loss: 3.63741634e-07
Iter: 1302 loss: 3.63546491e-07
Iter: 1303 loss: 3.63459833e-07
Iter: 1304 loss: 3.63268526e-07
Iter: 1305 loss: 3.63272306e-07
Iter: 1306 loss: 3.63087395e-07
Iter: 1307 loss: 3.63742458e-07
Iter: 1308 loss: 3.63034644e-07
Iter: 1309 loss: 3.62901631e-07
Iter: 1310 loss: 3.62860789e-07
Iter: 1311 loss: 3.62763785e-07
Iter: 1312 loss: 3.62583876e-07
Iter: 1313 loss: 3.63539527e-07
Iter: 1314 loss: 3.62548121e-07
Iter: 1315 loss: 3.62375602e-07
Iter: 1316 loss: 3.62079248e-07
Iter: 1317 loss: 3.66793131e-07
Iter: 1318 loss: 3.62053129e-07
Iter: 1319 loss: 3.61670601e-07
Iter: 1320 loss: 3.63358197e-07
Iter: 1321 loss: 3.6158707e-07
Iter: 1322 loss: 3.61424298e-07
Iter: 1323 loss: 3.61427823e-07
Iter: 1324 loss: 3.61255047e-07
Iter: 1325 loss: 3.61091793e-07
Iter: 1326 loss: 3.61085313e-07
Iter: 1327 loss: 3.60771821e-07
Iter: 1328 loss: 3.60779438e-07
Iter: 1329 loss: 3.60546323e-07
Iter: 1330 loss: 3.60252386e-07
Iter: 1331 loss: 3.61297793e-07
Iter: 1332 loss: 3.60161664e-07
Iter: 1333 loss: 3.59947535e-07
Iter: 1334 loss: 3.62802382e-07
Iter: 1335 loss: 3.59937872e-07
Iter: 1336 loss: 3.59714051e-07
Iter: 1337 loss: 3.60102888e-07
Iter: 1338 loss: 3.59633418e-07
Iter: 1339 loss: 3.59425854e-07
Iter: 1340 loss: 3.60512303e-07
Iter: 1341 loss: 3.59380124e-07
Iter: 1342 loss: 3.59191233e-07
Iter: 1343 loss: 3.608192e-07
Iter: 1344 loss: 3.59190352e-07
Iter: 1345 loss: 3.59092468e-07
Iter: 1346 loss: 3.58876832e-07
Iter: 1347 loss: 3.62188501e-07
Iter: 1348 loss: 3.58870921e-07
Iter: 1349 loss: 3.58651278e-07
Iter: 1350 loss: 3.58652272e-07
Iter: 1351 loss: 3.58541257e-07
Iter: 1352 loss: 3.58316299e-07
Iter: 1353 loss: 3.60472484e-07
Iter: 1354 loss: 3.5827415e-07
Iter: 1355 loss: 3.57926069e-07
Iter: 1356 loss: 3.59023886e-07
Iter: 1357 loss: 3.57780266e-07
Iter: 1358 loss: 3.57507815e-07
Iter: 1359 loss: 3.57615932e-07
Iter: 1360 loss: 3.57303918e-07
Iter: 1361 loss: 3.57043263e-07
Iter: 1362 loss: 3.57026408e-07
Iter: 1363 loss: 3.56810631e-07
Iter: 1364 loss: 3.57028853e-07
Iter: 1365 loss: 3.56708625e-07
Iter: 1366 loss: 3.56490773e-07
Iter: 1367 loss: 3.5652215e-07
Iter: 1368 loss: 3.56319589e-07
Iter: 1369 loss: 3.56075645e-07
Iter: 1370 loss: 3.56753674e-07
Iter: 1371 loss: 3.55972531e-07
Iter: 1372 loss: 3.55781651e-07
Iter: 1373 loss: 3.55777217e-07
Iter: 1374 loss: 3.55661086e-07
Iter: 1375 loss: 3.55830736e-07
Iter: 1376 loss: 3.55621296e-07
Iter: 1377 loss: 3.55483962e-07
Iter: 1378 loss: 3.56356509e-07
Iter: 1379 loss: 3.55444058e-07
Iter: 1380 loss: 3.55315933e-07
Iter: 1381 loss: 3.55147478e-07
Iter: 1382 loss: 3.55151656e-07
Iter: 1383 loss: 3.54996615e-07
Iter: 1384 loss: 3.57216265e-07
Iter: 1385 loss: 3.55019949e-07
Iter: 1386 loss: 3.54899896e-07
Iter: 1387 loss: 3.54740791e-07
Iter: 1388 loss: 3.54725927e-07
Iter: 1389 loss: 3.54506398e-07
Iter: 1390 loss: 3.54517454e-07
Iter: 1391 loss: 3.54305485e-07
Iter: 1392 loss: 3.53997734e-07
Iter: 1393 loss: 3.55826e-07
Iter: 1394 loss: 3.53966044e-07
Iter: 1395 loss: 3.53746259e-07
Iter: 1396 loss: 3.53476196e-07
Iter: 1397 loss: 3.53459143e-07
Iter: 1398 loss: 3.53249675e-07
Iter: 1399 loss: 3.53233133e-07
Iter: 1400 loss: 3.53051917e-07
Iter: 1401 loss: 3.5346963e-07
Iter: 1402 loss: 3.52987399e-07
Iter: 1403 loss: 3.5281596e-07
Iter: 1404 loss: 3.52842562e-07
Iter: 1405 loss: 3.52672458e-07
Iter: 1406 loss: 3.5244932e-07
Iter: 1407 loss: 3.52663022e-07
Iter: 1408 loss: 3.52339242e-07
Iter: 1409 loss: 3.52173743e-07
Iter: 1410 loss: 3.52167405e-07
Iter: 1411 loss: 3.52025097e-07
Iter: 1412 loss: 3.52303317e-07
Iter: 1413 loss: 3.51969533e-07
Iter: 1414 loss: 3.51783513e-07
Iter: 1415 loss: 3.52690932e-07
Iter: 1416 loss: 3.51762935e-07
Iter: 1417 loss: 3.51590188e-07
Iter: 1418 loss: 3.51534737e-07
Iter: 1419 loss: 3.51412723e-07
Iter: 1420 loss: 3.51245262e-07
Iter: 1421 loss: 3.52903186e-07
Iter: 1422 loss: 3.51235855e-07
Iter: 1423 loss: 3.51050346e-07
Iter: 1424 loss: 3.50729408e-07
Iter: 1425 loss: 3.57773189e-07
Iter: 1426 loss: 3.50746063e-07
Iter: 1427 loss: 3.50424443e-07
Iter: 1428 loss: 3.51275219e-07
Iter: 1429 loss: 3.5033014e-07
Iter: 1430 loss: 3.50000363e-07
Iter: 1431 loss: 3.50398153e-07
Iter: 1432 loss: 3.49819629e-07
Iter: 1433 loss: 3.49481354e-07
Iter: 1434 loss: 3.5140306e-07
Iter: 1435 loss: 3.4942741e-07
Iter: 1436 loss: 3.49196682e-07
Iter: 1437 loss: 3.49837563e-07
Iter: 1438 loss: 3.49124321e-07
Iter: 1439 loss: 3.48864489e-07
Iter: 1440 loss: 3.50445646e-07
Iter: 1441 loss: 3.48813273e-07
Iter: 1442 loss: 3.48603209e-07
Iter: 1443 loss: 3.49382248e-07
Iter: 1444 loss: 3.48533149e-07
Iter: 1445 loss: 3.48387744e-07
Iter: 1446 loss: 3.48165599e-07
Iter: 1447 loss: 3.48155254e-07
Iter: 1448 loss: 3.47950106e-07
Iter: 1449 loss: 3.47927141e-07
Iter: 1450 loss: 3.47800892e-07
Iter: 1451 loss: 3.48118306e-07
Iter: 1452 loss: 3.47723869e-07
Iter: 1453 loss: 3.4755567e-07
Iter: 1454 loss: 3.48332179e-07
Iter: 1455 loss: 3.47488822e-07
Iter: 1456 loss: 3.47372634e-07
Iter: 1457 loss: 3.47436384e-07
Iter: 1458 loss: 3.47278274e-07
Iter: 1459 loss: 3.47092595e-07
Iter: 1460 loss: 3.47720231e-07
Iter: 1461 loss: 3.47049081e-07
Iter: 1462 loss: 3.46849845e-07
Iter: 1463 loss: 3.46702819e-07
Iter: 1464 loss: 3.46636455e-07
Iter: 1465 loss: 3.46458819e-07
Iter: 1466 loss: 3.46500514e-07
Iter: 1467 loss: 3.46299544e-07
Iter: 1468 loss: 3.4600302e-07
Iter: 1469 loss: 3.47055135e-07
Iter: 1470 loss: 3.45915112e-07
Iter: 1471 loss: 3.45673755e-07
Iter: 1472 loss: 3.46074899e-07
Iter: 1473 loss: 3.45554156e-07
Iter: 1474 loss: 3.45258286e-07
Iter: 1475 loss: 3.45880039e-07
Iter: 1476 loss: 3.45136755e-07
Iter: 1477 loss: 3.44872319e-07
Iter: 1478 loss: 3.48295487e-07
Iter: 1479 loss: 3.44882324e-07
Iter: 1480 loss: 3.4465603e-07
Iter: 1481 loss: 3.45289834e-07
Iter: 1482 loss: 3.44619878e-07
Iter: 1483 loss: 3.44410694e-07
Iter: 1484 loss: 3.44441077e-07
Iter: 1485 loss: 3.44260229e-07
Iter: 1486 loss: 3.44228511e-07
Iter: 1487 loss: 3.44179227e-07
Iter: 1488 loss: 3.44089585e-07
Iter: 1489 loss: 3.43895863e-07
Iter: 1490 loss: 3.465627e-07
Iter: 1491 loss: 3.4385863e-07
Iter: 1492 loss: 3.4365388e-07
Iter: 1493 loss: 3.45540144e-07
Iter: 1494 loss: 3.43659167e-07
Iter: 1495 loss: 3.43486704e-07
Iter: 1496 loss: 3.43750685e-07
Iter: 1497 loss: 3.43376854e-07
Iter: 1498 loss: 3.43229487e-07
Iter: 1499 loss: 3.43301735e-07
Iter: 1500 loss: 3.43143313e-07
Iter: 1501 loss: 3.4292492e-07
Iter: 1502 loss: 3.4443525e-07
Iter: 1503 loss: 3.42934385e-07
Iter: 1504 loss: 3.42807652e-07
Iter: 1505 loss: 3.42525823e-07
Iter: 1506 loss: 3.47199659e-07
Iter: 1507 loss: 3.42530029e-07
Iter: 1508 loss: 3.42281965e-07
Iter: 1509 loss: 3.44348933e-07
Iter: 1510 loss: 3.42285148e-07
Iter: 1511 loss: 3.4208017e-07
Iter: 1512 loss: 3.42060673e-07
Iter: 1513 loss: 3.41911573e-07
Iter: 1514 loss: 3.41678174e-07
Iter: 1515 loss: 3.43545e-07
Iter: 1516 loss: 3.41659444e-07
Iter: 1517 loss: 3.41485588e-07
Iter: 1518 loss: 3.42137184e-07
Iter: 1519 loss: 3.41446821e-07
Iter: 1520 loss: 3.41261114e-07
Iter: 1521 loss: 3.41836113e-07
Iter: 1522 loss: 3.41181249e-07
Iter: 1523 loss: 3.41088764e-07
Iter: 1524 loss: 3.42449255e-07
Iter: 1525 loss: 3.41088906e-07
Iter: 1526 loss: 3.40993921e-07
Iter: 1527 loss: 3.40843258e-07
Iter: 1528 loss: 3.40848828e-07
Iter: 1529 loss: 3.40716667e-07
Iter: 1530 loss: 3.41825e-07
Iter: 1531 loss: 3.40719481e-07
Iter: 1532 loss: 3.40596443e-07
Iter: 1533 loss: 3.40750546e-07
Iter: 1534 loss: 3.40533518e-07
Iter: 1535 loss: 3.40404483e-07
Iter: 1536 loss: 3.40333429e-07
Iter: 1537 loss: 3.40287045e-07
Iter: 1538 loss: 3.40093663e-07
Iter: 1539 loss: 3.41596774e-07
Iter: 1540 loss: 3.40066094e-07
Iter: 1541 loss: 3.39910173e-07
Iter: 1542 loss: 3.39990834e-07
Iter: 1543 loss: 3.39795122e-07
Iter: 1544 loss: 3.39626524e-07
Iter: 1545 loss: 3.39734868e-07
Iter: 1546 loss: 3.39486718e-07
Iter: 1547 loss: 3.39315932e-07
Iter: 1548 loss: 3.40361169e-07
Iter: 1549 loss: 3.39274834e-07
Iter: 1550 loss: 3.3907844e-07
Iter: 1551 loss: 3.39065963e-07
Iter: 1552 loss: 3.38921836e-07
Iter: 1553 loss: 3.38717683e-07
Iter: 1554 loss: 3.38725755e-07
Iter: 1555 loss: 3.38576399e-07
Iter: 1556 loss: 3.39645339e-07
Iter: 1557 loss: 3.38574296e-07
Iter: 1558 loss: 3.38456914e-07
Iter: 1559 loss: 3.39004373e-07
Iter: 1560 loss: 3.38445659e-07
Iter: 1561 loss: 3.38335042e-07
Iter: 1562 loss: 3.38271775e-07
Iter: 1563 loss: 3.3823531e-07
Iter: 1564 loss: 3.3808891e-07
Iter: 1565 loss: 3.38197e-07
Iter: 1566 loss: 3.37977667e-07
Iter: 1567 loss: 3.37734292e-07
Iter: 1568 loss: 3.39262868e-07
Iter: 1569 loss: 3.37721872e-07
Iter: 1570 loss: 3.37631434e-07
Iter: 1571 loss: 3.37516781e-07
Iter: 1572 loss: 3.37511352e-07
Iter: 1573 loss: 3.37306972e-07
Iter: 1574 loss: 3.38412065e-07
Iter: 1575 loss: 3.37291226e-07
Iter: 1576 loss: 3.37097731e-07
Iter: 1577 loss: 3.3745971e-07
Iter: 1578 loss: 3.37023266e-07
Iter: 1579 loss: 3.36870897e-07
Iter: 1580 loss: 3.36931095e-07
Iter: 1581 loss: 3.36778328e-07
Iter: 1582 loss: 3.36575e-07
Iter: 1583 loss: 3.36878628e-07
Iter: 1584 loss: 3.36484845e-07
Iter: 1585 loss: 3.36277964e-07
Iter: 1586 loss: 3.37142978e-07
Iter: 1587 loss: 3.36231835e-07
Iter: 1588 loss: 3.36093137e-07
Iter: 1589 loss: 3.36098736e-07
Iter: 1590 loss: 3.3597297e-07
Iter: 1591 loss: 3.36170302e-07
Iter: 1592 loss: 3.35895e-07
Iter: 1593 loss: 3.35787945e-07
Iter: 1594 loss: 3.36465632e-07
Iter: 1595 loss: 3.35774956e-07
Iter: 1596 loss: 3.35656e-07
Iter: 1597 loss: 3.35514869e-07
Iter: 1598 loss: 3.35505604e-07
Iter: 1599 loss: 3.35400387e-07
Iter: 1600 loss: 3.35406355e-07
Iter: 1601 loss: 3.35302957e-07
Iter: 1602 loss: 3.3513723e-07
Iter: 1603 loss: 3.3514624e-07
Iter: 1604 loss: 3.35005069e-07
Iter: 1605 loss: 3.35454899e-07
Iter: 1606 loss: 3.34961896e-07
Iter: 1607 loss: 3.3483289e-07
Iter: 1608 loss: 3.35632649e-07
Iter: 1609 loss: 3.34806032e-07
Iter: 1610 loss: 3.34635672e-07
Iter: 1611 loss: 3.34751945e-07
Iter: 1612 loss: 3.3453108e-07
Iter: 1613 loss: 3.34356798e-07
Iter: 1614 loss: 3.34509195e-07
Iter: 1615 loss: 3.34264797e-07
Iter: 1616 loss: 3.34022843e-07
Iter: 1617 loss: 3.34146137e-07
Iter: 1618 loss: 3.33885197e-07
Iter: 1619 loss: 3.33635626e-07
Iter: 1620 loss: 3.35442792e-07
Iter: 1621 loss: 3.33611609e-07
Iter: 1622 loss: 3.33458104e-07
Iter: 1623 loss: 3.33478e-07
Iter: 1624 loss: 3.33330405e-07
Iter: 1625 loss: 3.33285925e-07
Iter: 1626 loss: 3.33233089e-07
Iter: 1627 loss: 3.33045023e-07
Iter: 1628 loss: 3.33703696e-07
Iter: 1629 loss: 3.32995768e-07
Iter: 1630 loss: 3.32856416e-07
Iter: 1631 loss: 3.32961605e-07
Iter: 1632 loss: 3.32807645e-07
Iter: 1633 loss: 3.32652291e-07
Iter: 1634 loss: 3.34002323e-07
Iter: 1635 loss: 3.32632027e-07
Iter: 1636 loss: 3.32540196e-07
Iter: 1637 loss: 3.32472098e-07
Iter: 1638 loss: 3.32448e-07
Iter: 1639 loss: 3.32340562e-07
Iter: 1640 loss: 3.32568789e-07
Iter: 1641 loss: 3.32259219e-07
Iter: 1642 loss: 3.32125495e-07
Iter: 1643 loss: 3.33534729e-07
Iter: 1644 loss: 3.32132743e-07
Iter: 1645 loss: 3.32015873e-07
Iter: 1646 loss: 3.31839402e-07
Iter: 1647 loss: 3.31834826e-07
Iter: 1648 loss: 3.31617571e-07
Iter: 1649 loss: 3.32344285e-07
Iter: 1650 loss: 3.31548364e-07
Iter: 1651 loss: 3.31342562e-07
Iter: 1652 loss: 3.31749419e-07
Iter: 1653 loss: 3.31286031e-07
Iter: 1654 loss: 3.31136221e-07
Iter: 1655 loss: 3.33582847e-07
Iter: 1656 loss: 3.31126671e-07
Iter: 1657 loss: 3.3097e-07
Iter: 1658 loss: 3.31439054e-07
Iter: 1659 loss: 3.30928401e-07
Iter: 1660 loss: 3.30813435e-07
Iter: 1661 loss: 3.31140086e-07
Iter: 1662 loss: 3.30786406e-07
Iter: 1663 loss: 3.30674794e-07
Iter: 1664 loss: 3.30614171e-07
Iter: 1665 loss: 3.30558862e-07
Iter: 1666 loss: 3.30433267e-07
Iter: 1667 loss: 3.31814931e-07
Iter: 1668 loss: 3.30445118e-07
Iter: 1669 loss: 3.30337457e-07
Iter: 1670 loss: 3.30288145e-07
Iter: 1671 loss: 3.30219279e-07
Iter: 1672 loss: 3.30088113e-07
Iter: 1673 loss: 3.300147e-07
Iter: 1674 loss: 3.29945465e-07
Iter: 1675 loss: 3.29785536e-07
Iter: 1676 loss: 3.31930607e-07
Iter: 1677 loss: 3.29779823e-07
Iter: 1678 loss: 3.29617023e-07
Iter: 1679 loss: 3.29827344e-07
Iter: 1680 loss: 3.29551142e-07
Iter: 1681 loss: 3.29380157e-07
Iter: 1682 loss: 3.29411705e-07
Iter: 1683 loss: 3.29261411e-07
Iter: 1684 loss: 3.29042621e-07
Iter: 1685 loss: 3.29318539e-07
Iter: 1686 loss: 3.28897528e-07
Iter: 1687 loss: 3.28699372e-07
Iter: 1688 loss: 3.30069781e-07
Iter: 1689 loss: 3.28665237e-07
Iter: 1690 loss: 3.28546406e-07
Iter: 1691 loss: 3.28525459e-07
Iter: 1692 loss: 3.28431e-07
Iter: 1693 loss: 3.28379542e-07
Iter: 1694 loss: 3.28349245e-07
Iter: 1695 loss: 3.28186815e-07
Iter: 1696 loss: 3.28957924e-07
Iter: 1697 loss: 3.28194091e-07
Iter: 1698 loss: 3.28073412e-07
Iter: 1699 loss: 3.28082677e-07
Iter: 1700 loss: 3.27989028e-07
Iter: 1701 loss: 3.27841178e-07
Iter: 1702 loss: 3.2895062e-07
Iter: 1703 loss: 3.27820629e-07
Iter: 1704 loss: 3.27697592e-07
Iter: 1705 loss: 3.27510435e-07
Iter: 1706 loss: 3.275062e-07
Iter: 1707 loss: 3.27308555e-07
Iter: 1708 loss: 3.27716521e-07
Iter: 1709 loss: 3.27209023e-07
Iter: 1710 loss: 3.27026896e-07
Iter: 1711 loss: 3.29501859e-07
Iter: 1712 loss: 3.27028175e-07
Iter: 1713 loss: 3.26911788e-07
Iter: 1714 loss: 3.26996883e-07
Iter: 1715 loss: 3.26826296e-07
Iter: 1716 loss: 3.26644681e-07
Iter: 1717 loss: 3.26545234e-07
Iter: 1718 loss: 3.26491204e-07
Iter: 1719 loss: 3.26247942e-07
Iter: 1720 loss: 3.27217691e-07
Iter: 1721 loss: 3.26171602e-07
Iter: 1722 loss: 3.26121722e-07
Iter: 1723 loss: 3.26061411e-07
Iter: 1724 loss: 3.25962e-07
Iter: 1725 loss: 3.2592277e-07
Iter: 1726 loss: 3.25860071e-07
Iter: 1727 loss: 3.25754911e-07
Iter: 1728 loss: 3.26206845e-07
Iter: 1729 loss: 3.25730639e-07
Iter: 1730 loss: 3.25601093e-07
Iter: 1731 loss: 3.25626701e-07
Iter: 1732 loss: 3.25533875e-07
Iter: 1733 loss: 3.25376902e-07
Iter: 1734 loss: 3.26205651e-07
Iter: 1735 loss: 3.25340409e-07
Iter: 1736 loss: 3.25194605e-07
Iter: 1737 loss: 3.25239739e-07
Iter: 1738 loss: 3.25069891e-07
Iter: 1739 loss: 3.24912293e-07
Iter: 1740 loss: 3.24934518e-07
Iter: 1741 loss: 3.24783059e-07
Iter: 1742 loss: 3.24567623e-07
Iter: 1743 loss: 3.25711795e-07
Iter: 1744 loss: 3.24544089e-07
Iter: 1745 loss: 3.24374184e-07
Iter: 1746 loss: 3.25369228e-07
Iter: 1747 loss: 3.2431646e-07
Iter: 1748 loss: 3.24168866e-07
Iter: 1749 loss: 3.24122936e-07
Iter: 1750 loss: 3.2404202e-07
Iter: 1751 loss: 3.23837583e-07
Iter: 1752 loss: 3.23925775e-07
Iter: 1753 loss: 3.23710594e-07
Iter: 1754 loss: 3.23596851e-07
Iter: 1755 loss: 3.23592e-07
Iter: 1756 loss: 3.23466395e-07
Iter: 1757 loss: 3.23945983e-07
Iter: 1758 loss: 3.23416145e-07
Iter: 1759 loss: 3.23332387e-07
Iter: 1760 loss: 3.23390964e-07
Iter: 1761 loss: 3.23289385e-07
Iter: 1762 loss: 3.23181268e-07
Iter: 1763 loss: 3.23445136e-07
Iter: 1764 loss: 3.23103137e-07
Iter: 1765 loss: 3.23021794e-07
Iter: 1766 loss: 3.23092451e-07
Iter: 1767 loss: 3.22938916e-07
Iter: 1768 loss: 3.22809854e-07
Iter: 1769 loss: 3.24056657e-07
Iter: 1770 loss: 3.2280235e-07
Iter: 1771 loss: 3.22727203e-07
Iter: 1772 loss: 3.22553262e-07
Iter: 1773 loss: 3.25879569e-07
Iter: 1774 loss: 3.22562528e-07
Iter: 1775 loss: 3.22362382e-07
Iter: 1776 loss: 3.23108736e-07
Iter: 1777 loss: 3.22315344e-07
Iter: 1778 loss: 3.22152175e-07
Iter: 1779 loss: 3.24300743e-07
Iter: 1780 loss: 3.22151493e-07
Iter: 1781 loss: 3.22025102e-07
Iter: 1782 loss: 3.22071827e-07
Iter: 1783 loss: 3.21918947e-07
Iter: 1784 loss: 3.21783972e-07
Iter: 1785 loss: 3.21617506e-07
Iter: 1786 loss: 3.21584196e-07
Iter: 1787 loss: 3.21434158e-07
Iter: 1788 loss: 3.21417872e-07
Iter: 1789 loss: 3.21312768e-07
Iter: 1790 loss: 3.21318396e-07
Iter: 1791 loss: 3.21249786e-07
Iter: 1792 loss: 3.2109682e-07
Iter: 1793 loss: 3.23287452e-07
Iter: 1794 loss: 3.21089232e-07
Iter: 1795 loss: 3.20922311e-07
Iter: 1796 loss: 3.22917913e-07
Iter: 1797 loss: 3.20924926e-07
Iter: 1798 loss: 3.20819368e-07
Iter: 1799 loss: 3.20729725e-07
Iter: 1800 loss: 3.20700451e-07
Iter: 1801 loss: 3.2058432e-07
Iter: 1802 loss: 3.20578778e-07
Iter: 1803 loss: 3.20478733e-07
Iter: 1804 loss: 3.20332e-07
Iter: 1805 loss: 3.20313205e-07
Iter: 1806 loss: 3.20159103e-07
Iter: 1807 loss: 3.20331111e-07
Iter: 1808 loss: 3.20071081e-07
Iter: 1809 loss: 3.198858e-07
Iter: 1810 loss: 3.21183535e-07
Iter: 1811 loss: 3.19851068e-07
Iter: 1812 loss: 3.19665787e-07
Iter: 1813 loss: 3.20577215e-07
Iter: 1814 loss: 3.19667947e-07
Iter: 1815 loss: 3.19535729e-07
Iter: 1816 loss: 3.19436708e-07
Iter: 1817 loss: 3.1940678e-07
Iter: 1818 loss: 3.19206436e-07
Iter: 1819 loss: 3.19655385e-07
Iter: 1820 loss: 3.19146068e-07
Iter: 1821 loss: 3.19003618e-07
Iter: 1822 loss: 3.18996456e-07
Iter: 1823 loss: 3.18866512e-07
Iter: 1824 loss: 3.18785908e-07
Iter: 1825 loss: 3.18709056e-07
Iter: 1826 loss: 3.18608045e-07
Iter: 1827 loss: 3.19350761e-07
Iter: 1828 loss: 3.18595397e-07
Iter: 1829 loss: 3.18473212e-07
Iter: 1830 loss: 3.18382e-07
Iter: 1831 loss: 3.18320048e-07
Iter: 1832 loss: 3.18183766e-07
Iter: 1833 loss: 3.19779019e-07
Iter: 1834 loss: 3.18173164e-07
Iter: 1835 loss: 3.18038502e-07
Iter: 1836 loss: 3.18095829e-07
Iter: 1837 loss: 3.17952328e-07
Iter: 1838 loss: 3.17806467e-07
Iter: 1839 loss: 3.17769434e-07
Iter: 1840 loss: 3.17680133e-07
Iter: 1841 loss: 3.17484449e-07
Iter: 1842 loss: 3.18298163e-07
Iter: 1843 loss: 3.17423712e-07
Iter: 1844 loss: 3.1725574e-07
Iter: 1845 loss: 3.19119209e-07
Iter: 1846 loss: 3.17260628e-07
Iter: 1847 loss: 3.17130599e-07
Iter: 1848 loss: 3.17008642e-07
Iter: 1849 loss: 3.169975e-07
Iter: 1850 loss: 3.16804034e-07
Iter: 1851 loss: 3.17518243e-07
Iter: 1852 loss: 3.16757365e-07
Iter: 1853 loss: 3.16639813e-07
Iter: 1854 loss: 3.16635465e-07
Iter: 1855 loss: 3.16502394e-07
Iter: 1856 loss: 3.16678808e-07
Iter: 1857 loss: 3.16465844e-07
Iter: 1858 loss: 3.16348974e-07
Iter: 1859 loss: 3.16284968e-07
Iter: 1860 loss: 3.16235514e-07
Iter: 1861 loss: 3.16034715e-07
Iter: 1862 loss: 3.16852152e-07
Iter: 1863 loss: 3.1601553e-07
Iter: 1864 loss: 3.15892635e-07
Iter: 1865 loss: 3.16166535e-07
Iter: 1866 loss: 3.15850087e-07
Iter: 1867 loss: 3.15680268e-07
Iter: 1868 loss: 3.16110288e-07
Iter: 1869 loss: 3.15633571e-07
Iter: 1870 loss: 3.15510562e-07
Iter: 1871 loss: 3.15544639e-07
Iter: 1872 loss: 3.15421971e-07
Iter: 1873 loss: 3.15284296e-07
Iter: 1874 loss: 3.15475603e-07
Iter: 1875 loss: 3.15217562e-07
Iter: 1876 loss: 3.15063119e-07
Iter: 1877 loss: 3.16864458e-07
Iter: 1878 loss: 3.15069087e-07
Iter: 1879 loss: 3.14969299e-07
Iter: 1880 loss: 3.14932606e-07
Iter: 1881 loss: 3.14843192e-07
Iter: 1882 loss: 3.14695939e-07
Iter: 1883 loss: 3.14834494e-07
Iter: 1884 loss: 3.14626504e-07
Iter: 1885 loss: 3.14482918e-07
Iter: 1886 loss: 3.14481554e-07
Iter: 1887 loss: 3.14375768e-07
Iter: 1888 loss: 3.14983339e-07
Iter: 1889 loss: 3.14356015e-07
Iter: 1890 loss: 3.14273848e-07
Iter: 1891 loss: 3.14118921e-07
Iter: 1892 loss: 3.17468619e-07
Iter: 1893 loss: 3.14106416e-07
Iter: 1894 loss: 3.13989517e-07
Iter: 1895 loss: 3.15763884e-07
Iter: 1896 loss: 3.13998669e-07
Iter: 1897 loss: 3.13878218e-07
Iter: 1898 loss: 3.13762484e-07
Iter: 1899 loss: 3.13764e-07
Iter: 1900 loss: 3.13609888e-07
Iter: 1901 loss: 3.15758456e-07
Iter: 1902 loss: 3.13596132e-07
Iter: 1903 loss: 3.13509759e-07
Iter: 1904 loss: 3.13454507e-07
Iter: 1905 loss: 3.13432054e-07
Iter: 1906 loss: 3.13301882e-07
Iter: 1907 loss: 3.13155965e-07
Iter: 1908 loss: 3.13117482e-07
Iter: 1909 loss: 3.12942291e-07
Iter: 1910 loss: 3.15239276e-07
Iter: 1911 loss: 3.12933366e-07
Iter: 1912 loss: 3.12787336e-07
Iter: 1913 loss: 3.13295345e-07
Iter: 1914 loss: 3.12742145e-07
Iter: 1915 loss: 3.12620926e-07
Iter: 1916 loss: 3.1256053e-07
Iter: 1917 loss: 3.12501186e-07
Iter: 1918 loss: 3.12392132e-07
Iter: 1919 loss: 3.12375875e-07
Iter: 1920 loss: 3.12289586e-07
Iter: 1921 loss: 3.12938198e-07
Iter: 1922 loss: 3.12282793e-07
Iter: 1923 loss: 3.12204435e-07
Iter: 1924 loss: 3.12075713e-07
Iter: 1925 loss: 3.15280829e-07
Iter: 1926 loss: 3.12090663e-07
Iter: 1927 loss: 3.11945541e-07
Iter: 1928 loss: 3.11956285e-07
Iter: 1929 loss: 3.1187443e-07
Iter: 1930 loss: 3.11751819e-07
Iter: 1931 loss: 3.11736386e-07
Iter: 1932 loss: 3.11603486e-07
Iter: 1933 loss: 3.13352871e-07
Iter: 1934 loss: 3.11605561e-07
Iter: 1935 loss: 3.11496905e-07
Iter: 1936 loss: 3.11367216e-07
Iter: 1937 loss: 3.11349027e-07
Iter: 1938 loss: 3.1115718e-07
Iter: 1939 loss: 3.11541783e-07
Iter: 1940 loss: 3.11053839e-07
Iter: 1941 loss: 3.10901953e-07
Iter: 1942 loss: 3.11320036e-07
Iter: 1943 loss: 3.1084528e-07
Iter: 1944 loss: 3.10703683e-07
Iter: 1945 loss: 3.12827524e-07
Iter: 1946 loss: 3.10702205e-07
Iter: 1947 loss: 3.1061245e-07
Iter: 1948 loss: 3.10569106e-07
Iter: 1949 loss: 3.10514167e-07
Iter: 1950 loss: 3.10376663e-07
Iter: 1951 loss: 3.10936e-07
Iter: 1952 loss: 3.10370723e-07
Iter: 1953 loss: 3.10273606e-07
Iter: 1954 loss: 3.10264e-07
Iter: 1955 loss: 3.10200903e-07
Iter: 1956 loss: 3.10071698e-07
Iter: 1957 loss: 3.12486492e-07
Iter: 1958 loss: 3.10082953e-07
Iter: 1959 loss: 3.09970886e-07
Iter: 1960 loss: 3.10899e-07
Iter: 1961 loss: 3.0997947e-07
Iter: 1962 loss: 3.09888776e-07
Iter: 1963 loss: 3.09890169e-07
Iter: 1964 loss: 3.09809138e-07
Iter: 1965 loss: 3.09715375e-07
Iter: 1966 loss: 3.10565724e-07
Iter: 1967 loss: 3.09708724e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2
+ date
Mon Oct 26 13:03:51 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd79407df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7941768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd79416e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7940b8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd794015730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd794015d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7807c4488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7807aa510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7807c4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78074c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780715840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78073a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78073a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7806ec598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78067f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78065a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780647268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780665b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780623730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7805f81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7805f8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78059e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780551840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780577620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7805772f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd78052d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7804f99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780496268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780496158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7804a5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780467950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7803ff730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7803ffbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd780436ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7803e5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7803f90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.4138466e-05
Iter: 2 loss: 3.27880189e-05
Iter: 3 loss: 1.83083521e-05
Iter: 4 loss: 1.6535123e-05
Iter: 5 loss: 1.84313831e-05
Iter: 6 loss: 1.5563739e-05
Iter: 7 loss: 1.4835945e-05
Iter: 8 loss: 1.74429078e-05
Iter: 9 loss: 1.46508955e-05
Iter: 10 loss: 1.39491895e-05
Iter: 11 loss: 1.32864025e-05
Iter: 12 loss: 1.31254665e-05
Iter: 13 loss: 1.24759736e-05
Iter: 14 loss: 2.03521395e-05
Iter: 15 loss: 1.24683756e-05
Iter: 16 loss: 1.18906064e-05
Iter: 17 loss: 1.11143781e-05
Iter: 18 loss: 1.10725496e-05
Iter: 19 loss: 1.0240582e-05
Iter: 20 loss: 1.65914462e-05
Iter: 21 loss: 1.01782498e-05
Iter: 22 loss: 9.51063e-06
Iter: 23 loss: 9.74865907e-06
Iter: 24 loss: 9.04134413e-06
Iter: 25 loss: 8.42383179e-06
Iter: 26 loss: 1.62876931e-05
Iter: 27 loss: 8.41861e-06
Iter: 28 loss: 7.97044777e-06
Iter: 29 loss: 8.20261266e-06
Iter: 30 loss: 7.67297934e-06
Iter: 31 loss: 7.31113505e-06
Iter: 32 loss: 7.71476789e-06
Iter: 33 loss: 7.11543089e-06
Iter: 34 loss: 6.80145195e-06
Iter: 35 loss: 7.67193615e-06
Iter: 36 loss: 6.69987458e-06
Iter: 37 loss: 6.58405679e-06
Iter: 38 loss: 6.53569441e-06
Iter: 39 loss: 6.4286719e-06
Iter: 40 loss: 6.17610203e-06
Iter: 41 loss: 9.1093616e-06
Iter: 42 loss: 6.15315093e-06
Iter: 43 loss: 5.90985201e-06
Iter: 44 loss: 9.25586846e-06
Iter: 45 loss: 5.90901618e-06
Iter: 46 loss: 5.78867503e-06
Iter: 47 loss: 5.98424958e-06
Iter: 48 loss: 5.73308262e-06
Iter: 49 loss: 5.58897909e-06
Iter: 50 loss: 5.35765867e-06
Iter: 51 loss: 5.35613435e-06
Iter: 52 loss: 5.13958184e-06
Iter: 53 loss: 5.13513351e-06
Iter: 54 loss: 5.03483716e-06
Iter: 55 loss: 4.79072423e-06
Iter: 56 loss: 7.33960678e-06
Iter: 57 loss: 4.76276182e-06
Iter: 58 loss: 4.55823465e-06
Iter: 59 loss: 4.55255849e-06
Iter: 60 loss: 4.42246437e-06
Iter: 61 loss: 4.5252068e-06
Iter: 62 loss: 4.34420053e-06
Iter: 63 loss: 4.17110732e-06
Iter: 64 loss: 5.12098723e-06
Iter: 65 loss: 4.14593433e-06
Iter: 66 loss: 4.05197352e-06
Iter: 67 loss: 4.11680867e-06
Iter: 68 loss: 3.99346618e-06
Iter: 69 loss: 3.95997449e-06
Iter: 70 loss: 3.93282426e-06
Iter: 71 loss: 3.88486387e-06
Iter: 72 loss: 3.85078783e-06
Iter: 73 loss: 3.83410952e-06
Iter: 74 loss: 3.77674542e-06
Iter: 75 loss: 3.75964873e-06
Iter: 76 loss: 3.72560476e-06
Iter: 77 loss: 3.63913659e-06
Iter: 78 loss: 4.50227799e-06
Iter: 79 loss: 3.63643403e-06
Iter: 80 loss: 3.58201123e-06
Iter: 81 loss: 3.57613203e-06
Iter: 82 loss: 3.5365224e-06
Iter: 83 loss: 3.4614568e-06
Iter: 84 loss: 3.63948811e-06
Iter: 85 loss: 3.43415786e-06
Iter: 86 loss: 3.36466474e-06
Iter: 87 loss: 3.75909599e-06
Iter: 88 loss: 3.35507025e-06
Iter: 89 loss: 3.2926514e-06
Iter: 90 loss: 3.23264953e-06
Iter: 91 loss: 3.21885182e-06
Iter: 92 loss: 3.14395629e-06
Iter: 93 loss: 3.51006702e-06
Iter: 94 loss: 3.13109854e-06
Iter: 95 loss: 3.04471087e-06
Iter: 96 loss: 3.3496e-06
Iter: 97 loss: 3.02247417e-06
Iter: 98 loss: 2.97115412e-06
Iter: 99 loss: 3.33474804e-06
Iter: 100 loss: 2.9667076e-06
Iter: 101 loss: 2.92108371e-06
Iter: 102 loss: 2.92228e-06
Iter: 103 loss: 2.88486194e-06
Iter: 104 loss: 2.84627231e-06
Iter: 105 loss: 2.83925738e-06
Iter: 106 loss: 2.82490782e-06
Iter: 107 loss: 2.79042888e-06
Iter: 108 loss: 3.16280375e-06
Iter: 109 loss: 2.78671837e-06
Iter: 110 loss: 2.74314971e-06
Iter: 111 loss: 2.89760897e-06
Iter: 112 loss: 2.73197656e-06
Iter: 113 loss: 2.69124257e-06
Iter: 114 loss: 2.98008285e-06
Iter: 115 loss: 2.6875573e-06
Iter: 116 loss: 2.6589646e-06
Iter: 117 loss: 2.60990282e-06
Iter: 118 loss: 2.6098387e-06
Iter: 119 loss: 2.55952227e-06
Iter: 120 loss: 3.19537889e-06
Iter: 121 loss: 2.5591728e-06
Iter: 122 loss: 2.5242025e-06
Iter: 123 loss: 2.56534395e-06
Iter: 124 loss: 2.50572475e-06
Iter: 125 loss: 2.469837e-06
Iter: 126 loss: 2.577038e-06
Iter: 127 loss: 2.45891738e-06
Iter: 128 loss: 2.42671967e-06
Iter: 129 loss: 2.44161606e-06
Iter: 130 loss: 2.4050039e-06
Iter: 131 loss: 2.37603535e-06
Iter: 132 loss: 2.83283725e-06
Iter: 133 loss: 2.37596055e-06
Iter: 134 loss: 2.34931667e-06
Iter: 135 loss: 2.31086892e-06
Iter: 136 loss: 2.30966475e-06
Iter: 137 loss: 2.30481419e-06
Iter: 138 loss: 2.28687213e-06
Iter: 139 loss: 2.26745783e-06
Iter: 140 loss: 2.27739565e-06
Iter: 141 loss: 2.25448775e-06
Iter: 142 loss: 2.23554161e-06
Iter: 143 loss: 2.18955984e-06
Iter: 144 loss: 2.68265308e-06
Iter: 145 loss: 2.18459036e-06
Iter: 146 loss: 2.19292838e-06
Iter: 147 loss: 2.16812805e-06
Iter: 148 loss: 2.1570329e-06
Iter: 149 loss: 2.13650537e-06
Iter: 150 loss: 2.61127116e-06
Iter: 151 loss: 2.13653038e-06
Iter: 152 loss: 2.10425765e-06
Iter: 153 loss: 2.13849398e-06
Iter: 154 loss: 2.08639926e-06
Iter: 155 loss: 2.0694938e-06
Iter: 156 loss: 2.06937239e-06
Iter: 157 loss: 2.05320384e-06
Iter: 158 loss: 2.01624607e-06
Iter: 159 loss: 2.49405639e-06
Iter: 160 loss: 2.01380089e-06
Iter: 161 loss: 1.97706277e-06
Iter: 162 loss: 2.34495519e-06
Iter: 163 loss: 1.97577378e-06
Iter: 164 loss: 1.94980748e-06
Iter: 165 loss: 2.03745799e-06
Iter: 166 loss: 1.94274298e-06
Iter: 167 loss: 1.92451694e-06
Iter: 168 loss: 2.05985725e-06
Iter: 169 loss: 1.92310335e-06
Iter: 170 loss: 1.90565606e-06
Iter: 171 loss: 1.92701873e-06
Iter: 172 loss: 1.89645584e-06
Iter: 173 loss: 1.87936212e-06
Iter: 174 loss: 1.87903447e-06
Iter: 175 loss: 1.8717376e-06
Iter: 176 loss: 1.85373597e-06
Iter: 177 loss: 2.04004982e-06
Iter: 178 loss: 1.85166425e-06
Iter: 179 loss: 1.83043755e-06
Iter: 180 loss: 1.89834464e-06
Iter: 181 loss: 1.82448e-06
Iter: 182 loss: 1.80963548e-06
Iter: 183 loss: 2.0153193e-06
Iter: 184 loss: 1.80961933e-06
Iter: 185 loss: 1.79611902e-06
Iter: 186 loss: 1.77741936e-06
Iter: 187 loss: 1.77660468e-06
Iter: 188 loss: 1.76486992e-06
Iter: 189 loss: 1.83894986e-06
Iter: 190 loss: 1.76358071e-06
Iter: 191 loss: 1.7479706e-06
Iter: 192 loss: 1.73309513e-06
Iter: 193 loss: 1.72967577e-06
Iter: 194 loss: 1.70904013e-06
Iter: 195 loss: 1.99545866e-06
Iter: 196 loss: 1.70907492e-06
Iter: 197 loss: 1.69895804e-06
Iter: 198 loss: 1.67845906e-06
Iter: 199 loss: 2.06140066e-06
Iter: 200 loss: 1.67828898e-06
Iter: 201 loss: 1.66226903e-06
Iter: 202 loss: 1.66180064e-06
Iter: 203 loss: 1.65021402e-06
Iter: 204 loss: 1.68001839e-06
Iter: 205 loss: 1.64620485e-06
Iter: 206 loss: 1.63912568e-06
Iter: 207 loss: 1.63870504e-06
Iter: 208 loss: 1.63164032e-06
Iter: 209 loss: 1.62333697e-06
Iter: 210 loss: 1.62244942e-06
Iter: 211 loss: 1.61123842e-06
Iter: 212 loss: 1.59560113e-06
Iter: 213 loss: 1.59496551e-06
Iter: 214 loss: 1.58246758e-06
Iter: 215 loss: 1.58246246e-06
Iter: 216 loss: 1.57058105e-06
Iter: 217 loss: 1.59343688e-06
Iter: 218 loss: 1.56568922e-06
Iter: 219 loss: 1.55526959e-06
Iter: 220 loss: 1.56791475e-06
Iter: 221 loss: 1.54976419e-06
Iter: 222 loss: 1.53825158e-06
Iter: 223 loss: 1.53954704e-06
Iter: 224 loss: 1.52935183e-06
Iter: 225 loss: 1.52085477e-06
Iter: 226 loss: 1.52024472e-06
Iter: 227 loss: 1.51375252e-06
Iter: 228 loss: 1.49774291e-06
Iter: 229 loss: 1.65555366e-06
Iter: 230 loss: 1.49563323e-06
Iter: 231 loss: 1.47904552e-06
Iter: 232 loss: 1.730441e-06
Iter: 233 loss: 1.47907417e-06
Iter: 234 loss: 1.46905768e-06
Iter: 235 loss: 1.46509501e-06
Iter: 236 loss: 1.45963577e-06
Iter: 237 loss: 1.45668218e-06
Iter: 238 loss: 1.45277795e-06
Iter: 239 loss: 1.4489616e-06
Iter: 240 loss: 1.49439302e-06
Iter: 241 loss: 1.44891737e-06
Iter: 242 loss: 1.44664091e-06
Iter: 243 loss: 1.439176e-06
Iter: 244 loss: 1.44158321e-06
Iter: 245 loss: 1.43214072e-06
Iter: 246 loss: 1.41921578e-06
Iter: 247 loss: 1.54128884e-06
Iter: 248 loss: 1.41872624e-06
Iter: 249 loss: 1.40954603e-06
Iter: 250 loss: 1.47256208e-06
Iter: 251 loss: 1.40867382e-06
Iter: 252 loss: 1.4004022e-06
Iter: 253 loss: 1.41722899e-06
Iter: 254 loss: 1.39702615e-06
Iter: 255 loss: 1.38909797e-06
Iter: 256 loss: 1.37325276e-06
Iter: 257 loss: 1.67958842e-06
Iter: 258 loss: 1.37308598e-06
Iter: 259 loss: 1.36977508e-06
Iter: 260 loss: 1.36660356e-06
Iter: 261 loss: 1.36104927e-06
Iter: 262 loss: 1.35615892e-06
Iter: 263 loss: 1.35466939e-06
Iter: 264 loss: 1.34612026e-06
Iter: 265 loss: 1.4026682e-06
Iter: 266 loss: 1.34523839e-06
Iter: 267 loss: 1.33897061e-06
Iter: 268 loss: 1.33028425e-06
Iter: 269 loss: 1.32984792e-06
Iter: 270 loss: 1.3245874e-06
Iter: 271 loss: 1.32326431e-06
Iter: 272 loss: 1.31938782e-06
Iter: 273 loss: 1.36083008e-06
Iter: 274 loss: 1.31926754e-06
Iter: 275 loss: 1.31550723e-06
Iter: 276 loss: 1.30917897e-06
Iter: 277 loss: 1.30919102e-06
Iter: 278 loss: 1.30254057e-06
Iter: 279 loss: 1.31745537e-06
Iter: 280 loss: 1.29998887e-06
Iter: 281 loss: 1.29481168e-06
Iter: 282 loss: 1.2975504e-06
Iter: 283 loss: 1.29144848e-06
Iter: 284 loss: 1.28383772e-06
Iter: 285 loss: 1.35276537e-06
Iter: 286 loss: 1.28362444e-06
Iter: 287 loss: 1.27902274e-06
Iter: 288 loss: 1.27762678e-06
Iter: 289 loss: 1.27486032e-06
Iter: 290 loss: 1.26770647e-06
Iter: 291 loss: 1.27323949e-06
Iter: 292 loss: 1.26337204e-06
Iter: 293 loss: 1.25663519e-06
Iter: 294 loss: 1.29916464e-06
Iter: 295 loss: 1.25583824e-06
Iter: 296 loss: 1.24997655e-06
Iter: 297 loss: 1.28621241e-06
Iter: 298 loss: 1.24924702e-06
Iter: 299 loss: 1.24490316e-06
Iter: 300 loss: 1.23584528e-06
Iter: 301 loss: 1.38771657e-06
Iter: 302 loss: 1.2355523e-06
Iter: 303 loss: 1.22736128e-06
Iter: 304 loss: 1.22731785e-06
Iter: 305 loss: 1.22404253e-06
Iter: 306 loss: 1.22397842e-06
Iter: 307 loss: 1.21986955e-06
Iter: 308 loss: 1.2137682e-06
Iter: 309 loss: 1.21362689e-06
Iter: 310 loss: 1.20620825e-06
Iter: 311 loss: 1.2312529e-06
Iter: 312 loss: 1.20422396e-06
Iter: 313 loss: 1.20030131e-06
Iter: 314 loss: 1.19723086e-06
Iter: 315 loss: 1.1961115e-06
Iter: 316 loss: 1.18967228e-06
Iter: 317 loss: 1.25436702e-06
Iter: 318 loss: 1.18936146e-06
Iter: 319 loss: 1.18493733e-06
Iter: 320 loss: 1.20575942e-06
Iter: 321 loss: 1.18411083e-06
Iter: 322 loss: 1.18045159e-06
Iter: 323 loss: 1.17293825e-06
Iter: 324 loss: 1.30569822e-06
Iter: 325 loss: 1.17281161e-06
Iter: 326 loss: 1.1655236e-06
Iter: 327 loss: 1.22728704e-06
Iter: 328 loss: 1.16508932e-06
Iter: 329 loss: 1.15796661e-06
Iter: 330 loss: 1.17032528e-06
Iter: 331 loss: 1.15483056e-06
Iter: 332 loss: 1.14850411e-06
Iter: 333 loss: 1.21019355e-06
Iter: 334 loss: 1.14829561e-06
Iter: 335 loss: 1.14454895e-06
Iter: 336 loss: 1.13943361e-06
Iter: 337 loss: 1.13915189e-06
Iter: 338 loss: 1.134081e-06
Iter: 339 loss: 1.2045698e-06
Iter: 340 loss: 1.13405281e-06
Iter: 341 loss: 1.13005422e-06
Iter: 342 loss: 1.18747971e-06
Iter: 343 loss: 1.13003443e-06
Iter: 344 loss: 1.12799103e-06
Iter: 345 loss: 1.12599821e-06
Iter: 346 loss: 1.1256891e-06
Iter: 347 loss: 1.12271584e-06
Iter: 348 loss: 1.12152532e-06
Iter: 349 loss: 1.12001726e-06
Iter: 350 loss: 1.11467079e-06
Iter: 351 loss: 1.12811313e-06
Iter: 352 loss: 1.11283566e-06
Iter: 353 loss: 1.11004101e-06
Iter: 354 loss: 1.11003214e-06
Iter: 355 loss: 1.10711233e-06
Iter: 356 loss: 1.09964753e-06
Iter: 357 loss: 1.16411502e-06
Iter: 358 loss: 1.09843768e-06
Iter: 359 loss: 1.09237089e-06
Iter: 360 loss: 1.17067782e-06
Iter: 361 loss: 1.09232565e-06
Iter: 362 loss: 1.08762788e-06
Iter: 363 loss: 1.09258747e-06
Iter: 364 loss: 1.08505105e-06
Iter: 365 loss: 1.08031304e-06
Iter: 366 loss: 1.11604857e-06
Iter: 367 loss: 1.07996811e-06
Iter: 368 loss: 1.07514893e-06
Iter: 369 loss: 1.07507674e-06
Iter: 370 loss: 1.07127141e-06
Iter: 371 loss: 1.06735069e-06
Iter: 372 loss: 1.09580242e-06
Iter: 373 loss: 1.06703806e-06
Iter: 374 loss: 1.06532707e-06
Iter: 375 loss: 1.06514699e-06
Iter: 376 loss: 1.063436e-06
Iter: 377 loss: 1.06141511e-06
Iter: 378 loss: 1.06111725e-06
Iter: 379 loss: 1.05876609e-06
Iter: 380 loss: 1.0580477e-06
Iter: 381 loss: 1.05660342e-06
Iter: 382 loss: 1.0526112e-06
Iter: 383 loss: 1.06747348e-06
Iter: 384 loss: 1.05164168e-06
Iter: 385 loss: 1.04902983e-06
Iter: 386 loss: 1.05647882e-06
Iter: 387 loss: 1.04820947e-06
Iter: 388 loss: 1.0442119e-06
Iter: 389 loss: 1.04449509e-06
Iter: 390 loss: 1.04100559e-06
Iter: 391 loss: 1.03557795e-06
Iter: 392 loss: 1.05293873e-06
Iter: 393 loss: 1.03397406e-06
Iter: 394 loss: 1.03074797e-06
Iter: 395 loss: 1.02837532e-06
Iter: 396 loss: 1.0273402e-06
Iter: 397 loss: 1.02379158e-06
Iter: 398 loss: 1.02375566e-06
Iter: 399 loss: 1.02111767e-06
Iter: 400 loss: 1.02490048e-06
Iter: 401 loss: 1.01981948e-06
Iter: 402 loss: 1.01668672e-06
Iter: 403 loss: 1.02448018e-06
Iter: 404 loss: 1.01560988e-06
Iter: 405 loss: 1.01308751e-06
Iter: 406 loss: 1.02791023e-06
Iter: 407 loss: 1.01262071e-06
Iter: 408 loss: 1.00928469e-06
Iter: 409 loss: 1.02011597e-06
Iter: 410 loss: 1.00826242e-06
Iter: 411 loss: 1.00651584e-06
Iter: 412 loss: 1.0039073e-06
Iter: 413 loss: 1.00386933e-06
Iter: 414 loss: 1.00022521e-06
Iter: 415 loss: 1.01555656e-06
Iter: 416 loss: 9.99415079e-07
Iter: 417 loss: 9.96865765e-07
Iter: 418 loss: 1.00448187e-06
Iter: 419 loss: 9.96127255e-07
Iter: 420 loss: 9.93047479e-07
Iter: 421 loss: 9.9956651e-07
Iter: 422 loss: 9.91832394e-07
Iter: 423 loss: 9.88225452e-07
Iter: 424 loss: 9.98959e-07
Iter: 425 loss: 9.87029125e-07
Iter: 426 loss: 9.84377721e-07
Iter: 427 loss: 9.80655614e-07
Iter: 428 loss: 9.80496338e-07
Iter: 429 loss: 9.76234332e-07
Iter: 430 loss: 1.02880233e-06
Iter: 431 loss: 9.76181e-07
Iter: 432 loss: 9.7361567e-07
Iter: 433 loss: 9.77170771e-07
Iter: 434 loss: 9.72304861e-07
Iter: 435 loss: 9.69074904e-07
Iter: 436 loss: 9.90366289e-07
Iter: 437 loss: 9.68658696e-07
Iter: 438 loss: 9.66698735e-07
Iter: 439 loss: 9.67035248e-07
Iter: 440 loss: 9.65230583e-07
Iter: 441 loss: 9.63322805e-07
Iter: 442 loss: 9.63120556e-07
Iter: 443 loss: 9.618e-07
Iter: 444 loss: 9.587975e-07
Iter: 445 loss: 1.00250713e-06
Iter: 446 loss: 9.58710189e-07
Iter: 447 loss: 9.55590849e-07
Iter: 448 loss: 9.629847e-07
Iter: 449 loss: 9.54427833e-07
Iter: 450 loss: 9.52586e-07
Iter: 451 loss: 9.78573e-07
Iter: 452 loss: 9.525819e-07
Iter: 453 loss: 9.51123866e-07
Iter: 454 loss: 9.49215632e-07
Iter: 455 loss: 9.49090634e-07
Iter: 456 loss: 9.45997726e-07
Iter: 457 loss: 9.77587888e-07
Iter: 458 loss: 9.46000341e-07
Iter: 459 loss: 9.44514341e-07
Iter: 460 loss: 9.42090082e-07
Iter: 461 loss: 9.42064673e-07
Iter: 462 loss: 9.38693461e-07
Iter: 463 loss: 9.54139409e-07
Iter: 464 loss: 9.38063408e-07
Iter: 465 loss: 9.3516627e-07
Iter: 466 loss: 9.35222374e-07
Iter: 467 loss: 9.32851492e-07
Iter: 468 loss: 9.29974703e-07
Iter: 469 loss: 9.29935425e-07
Iter: 470 loss: 9.28014572e-07
Iter: 471 loss: 9.26719508e-07
Iter: 472 loss: 9.26014536e-07
Iter: 473 loss: 9.25389827e-07
Iter: 474 loss: 9.24615335e-07
Iter: 475 loss: 9.23505581e-07
Iter: 476 loss: 9.20930916e-07
Iter: 477 loss: 9.53896e-07
Iter: 478 loss: 9.20772e-07
Iter: 479 loss: 9.1768203e-07
Iter: 480 loss: 9.21740479e-07
Iter: 481 loss: 9.16088084e-07
Iter: 482 loss: 9.13894951e-07
Iter: 483 loss: 9.30460033e-07
Iter: 484 loss: 9.13748408e-07
Iter: 485 loss: 9.11363941e-07
Iter: 486 loss: 9.10103495e-07
Iter: 487 loss: 9.08990387e-07
Iter: 488 loss: 9.07063963e-07
Iter: 489 loss: 9.06940954e-07
Iter: 490 loss: 9.05543e-07
Iter: 491 loss: 9.04246576e-07
Iter: 492 loss: 9.03928537e-07
Iter: 493 loss: 9.01276394e-07
Iter: 494 loss: 9.03592877e-07
Iter: 495 loss: 8.99710358e-07
Iter: 496 loss: 8.974298e-07
Iter: 497 loss: 9.0326597e-07
Iter: 498 loss: 8.96689073e-07
Iter: 499 loss: 8.94067057e-07
Iter: 500 loss: 9.07606875e-07
Iter: 501 loss: 8.93679271e-07
Iter: 502 loss: 8.91362333e-07
Iter: 503 loss: 8.96858069e-07
Iter: 504 loss: 8.90475917e-07
Iter: 505 loss: 8.88540228e-07
Iter: 506 loss: 9.12980795e-07
Iter: 507 loss: 8.88520958e-07
Iter: 508 loss: 8.86940938e-07
Iter: 509 loss: 8.95367748e-07
Iter: 510 loss: 8.86649104e-07
Iter: 511 loss: 8.85684358e-07
Iter: 512 loss: 8.83246287e-07
Iter: 513 loss: 9.00551925e-07
Iter: 514 loss: 8.82665745e-07
Iter: 515 loss: 8.80493303e-07
Iter: 516 loss: 9.07276785e-07
Iter: 517 loss: 8.80504274e-07
Iter: 518 loss: 8.78416813e-07
Iter: 519 loss: 8.80118876e-07
Iter: 520 loss: 8.77288e-07
Iter: 521 loss: 8.75333342e-07
Iter: 522 loss: 8.96302708e-07
Iter: 523 loss: 8.75317369e-07
Iter: 524 loss: 8.73870135e-07
Iter: 525 loss: 8.75378419e-07
Iter: 526 loss: 8.73066483e-07
Iter: 527 loss: 8.70983285e-07
Iter: 528 loss: 8.71173825e-07
Iter: 529 loss: 8.69435894e-07
Iter: 530 loss: 8.67456151e-07
Iter: 531 loss: 8.67987069e-07
Iter: 532 loss: 8.66099185e-07
Iter: 533 loss: 8.63322384e-07
Iter: 534 loss: 8.80797813e-07
Iter: 535 loss: 8.62998832e-07
Iter: 536 loss: 8.60718046e-07
Iter: 537 loss: 8.68290954e-07
Iter: 538 loss: 8.60095838e-07
Iter: 539 loss: 8.58055728e-07
Iter: 540 loss: 8.74661623e-07
Iter: 541 loss: 8.57896111e-07
Iter: 542 loss: 8.56522036e-07
Iter: 543 loss: 8.75227272e-07
Iter: 544 loss: 8.56553243e-07
Iter: 545 loss: 8.55474241e-07
Iter: 546 loss: 8.52503547e-07
Iter: 547 loss: 8.67163294e-07
Iter: 548 loss: 8.51513619e-07
Iter: 549 loss: 8.49208561e-07
Iter: 550 loss: 8.78339847e-07
Iter: 551 loss: 8.49148e-07
Iter: 552 loss: 8.47400315e-07
Iter: 553 loss: 8.48261948e-07
Iter: 554 loss: 8.46189096e-07
Iter: 555 loss: 8.44060196e-07
Iter: 556 loss: 8.64371032e-07
Iter: 557 loss: 8.43944406e-07
Iter: 558 loss: 8.42667703e-07
Iter: 559 loss: 8.4821761e-07
Iter: 560 loss: 8.42426857e-07
Iter: 561 loss: 8.41092969e-07
Iter: 562 loss: 8.39953486e-07
Iter: 563 loss: 8.39503116e-07
Iter: 564 loss: 8.37544292e-07
Iter: 565 loss: 8.39957465e-07
Iter: 566 loss: 8.36580341e-07
Iter: 567 loss: 8.34294724e-07
Iter: 568 loss: 8.43289513e-07
Iter: 569 loss: 8.33804506e-07
Iter: 570 loss: 8.31770762e-07
Iter: 571 loss: 8.33096237e-07
Iter: 572 loss: 8.3052862e-07
Iter: 573 loss: 8.28729469e-07
Iter: 574 loss: 8.28729696e-07
Iter: 575 loss: 8.27889e-07
Iter: 576 loss: 8.27880399e-07
Iter: 577 loss: 8.27101587e-07
Iter: 578 loss: 8.25494851e-07
Iter: 579 loss: 8.51473658e-07
Iter: 580 loss: 8.25417487e-07
Iter: 581 loss: 8.23865093e-07
Iter: 582 loss: 8.28081738e-07
Iter: 583 loss: 8.23296546e-07
Iter: 584 loss: 8.21826177e-07
Iter: 585 loss: 8.20037485e-07
Iter: 586 loss: 8.19835691e-07
Iter: 587 loss: 8.18171884e-07
Iter: 588 loss: 8.17999535e-07
Iter: 589 loss: 8.16876195e-07
Iter: 590 loss: 8.17985438e-07
Iter: 591 loss: 8.16288434e-07
Iter: 592 loss: 8.14539362e-07
Iter: 593 loss: 8.17255625e-07
Iter: 594 loss: 8.13769e-07
Iter: 595 loss: 8.12385224e-07
Iter: 596 loss: 8.14754e-07
Iter: 597 loss: 8.1179968e-07
Iter: 598 loss: 8.10307483e-07
Iter: 599 loss: 8.11092264e-07
Iter: 600 loss: 8.09254345e-07
Iter: 601 loss: 8.07278923e-07
Iter: 602 loss: 8.09155495e-07
Iter: 603 loss: 8.06106868e-07
Iter: 604 loss: 8.0416396e-07
Iter: 605 loss: 8.3253542e-07
Iter: 606 loss: 8.04149749e-07
Iter: 607 loss: 8.03019532e-07
Iter: 608 loss: 8.16813156e-07
Iter: 609 loss: 8.02999352e-07
Iter: 610 loss: 8.01768749e-07
Iter: 611 loss: 8.02011414e-07
Iter: 612 loss: 8.0089103e-07
Iter: 613 loss: 7.99693566e-07
Iter: 614 loss: 8.00903649e-07
Iter: 615 loss: 7.99056465e-07
Iter: 616 loss: 7.98089616e-07
Iter: 617 loss: 7.9645e-07
Iter: 618 loss: 7.96442123e-07
Iter: 619 loss: 7.94222046e-07
Iter: 620 loss: 8.14104283e-07
Iter: 621 loss: 7.94136554e-07
Iter: 622 loss: 7.92648848e-07
Iter: 623 loss: 8.00464477e-07
Iter: 624 loss: 7.92455694e-07
Iter: 625 loss: 7.91074e-07
Iter: 626 loss: 7.94585844e-07
Iter: 627 loss: 7.90547404e-07
Iter: 628 loss: 7.89222611e-07
Iter: 629 loss: 7.92192168e-07
Iter: 630 loss: 7.88705734e-07
Iter: 631 loss: 7.87203703e-07
Iter: 632 loss: 7.86166652e-07
Iter: 633 loss: 7.85636587e-07
Iter: 634 loss: 7.84094084e-07
Iter: 635 loss: 7.90149102e-07
Iter: 636 loss: 7.8372409e-07
Iter: 637 loss: 7.82048232e-07
Iter: 638 loss: 7.89143257e-07
Iter: 639 loss: 7.81653569e-07
Iter: 640 loss: 7.80463779e-07
Iter: 641 loss: 7.92224171e-07
Iter: 642 loss: 7.80460255e-07
Iter: 643 loss: 7.79078391e-07
Iter: 644 loss: 7.8307329e-07
Iter: 645 loss: 7.78655e-07
Iter: 646 loss: 7.77610467e-07
Iter: 647 loss: 7.78717606e-07
Iter: 648 loss: 7.76935167e-07
Iter: 649 loss: 7.76109e-07
Iter: 650 loss: 7.74026034e-07
Iter: 651 loss: 7.97861503e-07
Iter: 652 loss: 7.73878355e-07
Iter: 653 loss: 7.71643954e-07
Iter: 654 loss: 8.02419436e-07
Iter: 655 loss: 7.71613657e-07
Iter: 656 loss: 7.70457859e-07
Iter: 657 loss: 7.76618833e-07
Iter: 658 loss: 7.70310635e-07
Iter: 659 loss: 7.69159954e-07
Iter: 660 loss: 7.72705675e-07
Iter: 661 loss: 7.68807467e-07
Iter: 662 loss: 7.67663607e-07
Iter: 663 loss: 7.69141e-07
Iter: 664 loss: 7.67107736e-07
Iter: 665 loss: 7.65636628e-07
Iter: 666 loss: 7.67632e-07
Iter: 667 loss: 7.64893684e-07
Iter: 668 loss: 7.6384174e-07
Iter: 669 loss: 7.64450306e-07
Iter: 670 loss: 7.6311926e-07
Iter: 671 loss: 7.61321871e-07
Iter: 672 loss: 7.64565698e-07
Iter: 673 loss: 7.60569037e-07
Iter: 674 loss: 7.5952272e-07
Iter: 675 loss: 7.70075474e-07
Iter: 676 loss: 7.59459624e-07
Iter: 677 loss: 7.58426609e-07
Iter: 678 loss: 7.69416886e-07
Iter: 679 loss: 7.58415581e-07
Iter: 680 loss: 7.57630403e-07
Iter: 681 loss: 7.56919064e-07
Iter: 682 loss: 7.56763257e-07
Iter: 683 loss: 7.55587166e-07
Iter: 684 loss: 7.55379119e-07
Iter: 685 loss: 7.54644645e-07
Iter: 686 loss: 7.53041093e-07
Iter: 687 loss: 7.57989312e-07
Iter: 688 loss: 7.52584299e-07
Iter: 689 loss: 7.5138172e-07
Iter: 690 loss: 7.53818881e-07
Iter: 691 loss: 7.50919185e-07
Iter: 692 loss: 7.49495143e-07
Iter: 693 loss: 7.58996237e-07
Iter: 694 loss: 7.49367643e-07
Iter: 695 loss: 7.48325e-07
Iter: 696 loss: 7.51190669e-07
Iter: 697 loss: 7.4797947e-07
Iter: 698 loss: 7.46943442e-07
Iter: 699 loss: 7.47599756e-07
Iter: 700 loss: 7.46251601e-07
Iter: 701 loss: 7.45096258e-07
Iter: 702 loss: 7.47465094e-07
Iter: 703 loss: 7.44690112e-07
Iter: 704 loss: 7.43225712e-07
Iter: 705 loss: 7.42116185e-07
Iter: 706 loss: 7.41609e-07
Iter: 707 loss: 7.3981397e-07
Iter: 708 loss: 7.4916818e-07
Iter: 709 loss: 7.39575171e-07
Iter: 710 loss: 7.38716892e-07
Iter: 711 loss: 7.38589392e-07
Iter: 712 loss: 7.37678192e-07
Iter: 713 loss: 7.39375764e-07
Iter: 714 loss: 7.37270284e-07
Iter: 715 loss: 7.36754032e-07
Iter: 716 loss: 7.36311e-07
Iter: 717 loss: 7.36120796e-07
Iter: 718 loss: 7.35078515e-07
Iter: 719 loss: 7.35809067e-07
Iter: 720 loss: 7.34443233e-07
Iter: 721 loss: 7.33310685e-07
Iter: 722 loss: 7.34537252e-07
Iter: 723 loss: 7.32709111e-07
Iter: 724 loss: 7.31672571e-07
Iter: 725 loss: 7.45278612e-07
Iter: 726 loss: 7.31660748e-07
Iter: 727 loss: 7.30810541e-07
Iter: 728 loss: 7.32610829e-07
Iter: 729 loss: 7.30461579e-07
Iter: 730 loss: 7.29389399e-07
Iter: 731 loss: 7.29819362e-07
Iter: 732 loss: 7.28623036e-07
Iter: 733 loss: 7.27666134e-07
Iter: 734 loss: 7.34664241e-07
Iter: 735 loss: 7.27563588e-07
Iter: 736 loss: 7.26680923e-07
Iter: 737 loss: 7.2474478e-07
Iter: 738 loss: 7.56827944e-07
Iter: 739 loss: 7.24707888e-07
Iter: 740 loss: 7.23364337e-07
Iter: 741 loss: 7.23337394e-07
Iter: 742 loss: 7.22212349e-07
Iter: 743 loss: 7.243043e-07
Iter: 744 loss: 7.21688707e-07
Iter: 745 loss: 7.20863454e-07
Iter: 746 loss: 7.20798369e-07
Iter: 747 loss: 7.20439061e-07
Iter: 748 loss: 7.19565833e-07
Iter: 749 loss: 7.31874707e-07
Iter: 750 loss: 7.19497336e-07
Iter: 751 loss: 7.18426122e-07
Iter: 752 loss: 7.22486e-07
Iter: 753 loss: 7.18228762e-07
Iter: 754 loss: 7.17437388e-07
Iter: 755 loss: 7.17953128e-07
Iter: 756 loss: 7.16922557e-07
Iter: 757 loss: 7.15907845e-07
Iter: 758 loss: 7.18644969e-07
Iter: 759 loss: 7.15572639e-07
Iter: 760 loss: 7.14771204e-07
Iter: 761 loss: 7.22596212e-07
Iter: 762 loss: 7.14706971e-07
Iter: 763 loss: 7.13843178e-07
Iter: 764 loss: 7.14715952e-07
Iter: 765 loss: 7.13360748e-07
Iter: 766 loss: 7.12510769e-07
Iter: 767 loss: 7.13792929e-07
Iter: 768 loss: 7.1218966e-07
Iter: 769 loss: 7.10922905e-07
Iter: 770 loss: 7.10335e-07
Iter: 771 loss: 7.09712253e-07
Iter: 772 loss: 7.08525931e-07
Iter: 773 loss: 7.17465582e-07
Iter: 774 loss: 7.08452603e-07
Iter: 775 loss: 7.07405206e-07
Iter: 776 loss: 7.07483935e-07
Iter: 777 loss: 7.06606841e-07
Iter: 778 loss: 7.06828814e-07
Iter: 779 loss: 7.06063361e-07
Iter: 780 loss: 7.05606851e-07
Iter: 781 loss: 7.04584295e-07
Iter: 782 loss: 7.20961e-07
Iter: 783 loss: 7.04536433e-07
Iter: 784 loss: 7.03633873e-07
Iter: 785 loss: 7.07347908e-07
Iter: 786 loss: 7.03458454e-07
Iter: 787 loss: 7.02576585e-07
Iter: 788 loss: 7.02934358e-07
Iter: 789 loss: 7.0197359e-07
Iter: 790 loss: 7.00628902e-07
Iter: 791 loss: 7.04204126e-07
Iter: 792 loss: 7.00210308e-07
Iter: 793 loss: 6.99522616e-07
Iter: 794 loss: 7.01770773e-07
Iter: 795 loss: 6.99268639e-07
Iter: 796 loss: 6.98382848e-07
Iter: 797 loss: 7.03619492e-07
Iter: 798 loss: 6.98213853e-07
Iter: 799 loss: 6.97633538e-07
Iter: 800 loss: 6.98015413e-07
Iter: 801 loss: 6.97271673e-07
Iter: 802 loss: 6.96407938e-07
Iter: 803 loss: 6.97097562e-07
Iter: 804 loss: 6.95904191e-07
Iter: 805 loss: 6.94825644e-07
Iter: 806 loss: 6.99306781e-07
Iter: 807 loss: 6.94563255e-07
Iter: 808 loss: 6.93607717e-07
Iter: 809 loss: 6.92836693e-07
Iter: 810 loss: 6.92502e-07
Iter: 811 loss: 6.91616208e-07
Iter: 812 loss: 6.9154521e-07
Iter: 813 loss: 6.90764409e-07
Iter: 814 loss: 6.96510426e-07
Iter: 815 loss: 6.9062e-07
Iter: 816 loss: 6.90110312e-07
Iter: 817 loss: 6.89313595e-07
Iter: 818 loss: 6.89317176e-07
Iter: 819 loss: 6.88453e-07
Iter: 820 loss: 6.89032788e-07
Iter: 821 loss: 6.87885745e-07
Iter: 822 loss: 6.86758199e-07
Iter: 823 loss: 6.96218763e-07
Iter: 824 loss: 6.86679527e-07
Iter: 825 loss: 6.8599104e-07
Iter: 826 loss: 6.8482575e-07
Iter: 827 loss: 7.12506335e-07
Iter: 828 loss: 6.84791758e-07
Iter: 829 loss: 6.83750841e-07
Iter: 830 loss: 6.83732878e-07
Iter: 831 loss: 6.83033647e-07
Iter: 832 loss: 6.85720465e-07
Iter: 833 loss: 6.82914276e-07
Iter: 834 loss: 6.82351e-07
Iter: 835 loss: 6.81561858e-07
Iter: 836 loss: 6.81493248e-07
Iter: 837 loss: 6.80653841e-07
Iter: 838 loss: 6.89015224e-07
Iter: 839 loss: 6.80625249e-07
Iter: 840 loss: 6.79850871e-07
Iter: 841 loss: 6.79913683e-07
Iter: 842 loss: 6.79270329e-07
Iter: 843 loss: 6.78299443e-07
Iter: 844 loss: 6.79381913e-07
Iter: 845 loss: 6.77717367e-07
Iter: 846 loss: 6.77457137e-07
Iter: 847 loss: 6.77059347e-07
Iter: 848 loss: 6.7654446e-07
Iter: 849 loss: 6.75892181e-07
Iter: 850 loss: 6.75776789e-07
Iter: 851 loss: 6.7533648e-07
Iter: 852 loss: 6.74662317e-07
Iter: 853 loss: 6.7458808e-07
Iter: 854 loss: 6.73814498e-07
Iter: 855 loss: 6.85061764e-07
Iter: 856 loss: 6.73766522e-07
Iter: 857 loss: 6.73143518e-07
Iter: 858 loss: 6.73146644e-07
Iter: 859 loss: 6.7264773e-07
Iter: 860 loss: 6.7181395e-07
Iter: 861 loss: 6.74934711e-07
Iter: 862 loss: 6.71644784e-07
Iter: 863 loss: 6.71024281e-07
Iter: 864 loss: 6.77325886e-07
Iter: 865 loss: 6.71009388e-07
Iter: 866 loss: 6.70332611e-07
Iter: 867 loss: 6.69665951e-07
Iter: 868 loss: 6.69523558e-07
Iter: 869 loss: 6.68760549e-07
Iter: 870 loss: 6.72242e-07
Iter: 871 loss: 6.68567679e-07
Iter: 872 loss: 6.67774771e-07
Iter: 873 loss: 6.69752126e-07
Iter: 874 loss: 6.6748521e-07
Iter: 875 loss: 6.6667053e-07
Iter: 876 loss: 6.68017719e-07
Iter: 877 loss: 6.66306505e-07
Iter: 878 loss: 6.65341759e-07
Iter: 879 loss: 6.7002793e-07
Iter: 880 loss: 6.65207949e-07
Iter: 881 loss: 6.64465233e-07
Iter: 882 loss: 6.64490813e-07
Iter: 883 loss: 6.64250365e-07
Iter: 884 loss: 6.63520495e-07
Iter: 885 loss: 6.63794594e-07
Iter: 886 loss: 6.62865091e-07
Iter: 887 loss: 6.61931097e-07
Iter: 888 loss: 6.61912168e-07
Iter: 889 loss: 6.61322872e-07
Iter: 890 loss: 6.64353195e-07
Iter: 891 loss: 6.61198328e-07
Iter: 892 loss: 6.60648e-07
Iter: 893 loss: 6.60848514e-07
Iter: 894 loss: 6.60267119e-07
Iter: 895 loss: 6.59548732e-07
Iter: 896 loss: 6.61647505e-07
Iter: 897 loss: 6.5937985e-07
Iter: 898 loss: 6.58735416e-07
Iter: 899 loss: 6.6510944e-07
Iter: 900 loss: 6.58738259e-07
Iter: 901 loss: 6.5827885e-07
Iter: 902 loss: 6.57577459e-07
Iter: 903 loss: 6.57561202e-07
Iter: 904 loss: 6.56617772e-07
Iter: 905 loss: 6.59665602e-07
Iter: 906 loss: 6.56348391e-07
Iter: 907 loss: 6.55562e-07
Iter: 908 loss: 6.61735839e-07
Iter: 909 loss: 6.55515578e-07
Iter: 910 loss: 6.54813221e-07
Iter: 911 loss: 6.54838232e-07
Iter: 912 loss: 6.54263e-07
Iter: 913 loss: 6.54150654e-07
Iter: 914 loss: 6.53778784e-07
Iter: 915 loss: 6.53564939e-07
Iter: 916 loss: 6.52840299e-07
Iter: 917 loss: 6.55196686e-07
Iter: 918 loss: 6.52448364e-07
Iter: 919 loss: 6.51512892e-07
Iter: 920 loss: 6.5733343e-07
Iter: 921 loss: 6.51383289e-07
Iter: 922 loss: 6.50734364e-07
Iter: 923 loss: 6.5219092e-07
Iter: 924 loss: 6.50507786e-07
Iter: 925 loss: 6.49800825e-07
Iter: 926 loss: 6.54171117e-07
Iter: 927 loss: 6.49687e-07
Iter: 928 loss: 6.49076924e-07
Iter: 929 loss: 6.49047138e-07
Iter: 930 loss: 6.48580055e-07
Iter: 931 loss: 6.47775153e-07
Iter: 932 loss: 6.55612268e-07
Iter: 933 loss: 6.47762647e-07
Iter: 934 loss: 6.47086438e-07
Iter: 935 loss: 6.49719141e-07
Iter: 936 loss: 6.46935064e-07
Iter: 937 loss: 6.46465651e-07
Iter: 938 loss: 6.45828095e-07
Iter: 939 loss: 6.45825878e-07
Iter: 940 loss: 6.44991e-07
Iter: 941 loss: 6.48352852e-07
Iter: 942 loss: 6.44832255e-07
Iter: 943 loss: 6.43886096e-07
Iter: 944 loss: 6.47197055e-07
Iter: 945 loss: 6.43653038e-07
Iter: 946 loss: 6.43159183e-07
Iter: 947 loss: 6.43158103e-07
Iter: 948 loss: 6.42675445e-07
Iter: 949 loss: 6.42155214e-07
Iter: 950 loss: 6.42069779e-07
Iter: 951 loss: 6.41454903e-07
Iter: 952 loss: 6.40959513e-07
Iter: 953 loss: 6.40789949e-07
Iter: 954 loss: 6.39902851e-07
Iter: 955 loss: 6.41577685e-07
Iter: 956 loss: 6.39562586e-07
Iter: 957 loss: 6.39018367e-07
Iter: 958 loss: 6.38982897e-07
Iter: 959 loss: 6.38552365e-07
Iter: 960 loss: 6.38143092e-07
Iter: 961 loss: 6.38029462e-07
Iter: 962 loss: 6.37219102e-07
Iter: 963 loss: 6.42808459e-07
Iter: 964 loss: 6.37150094e-07
Iter: 965 loss: 6.36712798e-07
Iter: 966 loss: 6.4042672e-07
Iter: 967 loss: 6.36691539e-07
Iter: 968 loss: 6.36248615e-07
Iter: 969 loss: 6.35627089e-07
Iter: 970 loss: 6.35569336e-07
Iter: 971 loss: 6.34896878e-07
Iter: 972 loss: 6.37074663e-07
Iter: 973 loss: 6.34733055e-07
Iter: 974 loss: 6.34057869e-07
Iter: 975 loss: 6.36815685e-07
Iter: 976 loss: 6.33891204e-07
Iter: 977 loss: 6.33393199e-07
Iter: 978 loss: 6.33448622e-07
Iter: 979 loss: 6.32988872e-07
Iter: 980 loss: 6.33666502e-07
Iter: 981 loss: 6.32784e-07
Iter: 982 loss: 6.32326874e-07
Iter: 983 loss: 6.31492753e-07
Iter: 984 loss: 6.52306312e-07
Iter: 985 loss: 6.31474677e-07
Iter: 986 loss: 6.30543525e-07
Iter: 987 loss: 6.3114021e-07
Iter: 988 loss: 6.29883914e-07
Iter: 989 loss: 6.29154613e-07
Iter: 990 loss: 6.40362259e-07
Iter: 991 loss: 6.2916763e-07
Iter: 992 loss: 6.28535304e-07
Iter: 993 loss: 6.28993121e-07
Iter: 994 loss: 6.28199246e-07
Iter: 995 loss: 6.2739025e-07
Iter: 996 loss: 6.32202273e-07
Iter: 997 loss: 6.2725735e-07
Iter: 998 loss: 6.26813858e-07
Iter: 999 loss: 6.2848585e-07
Iter: 1000 loss: 6.26715575e-07
Iter: 1001 loss: 6.26116275e-07
Iter: 1002 loss: 6.26590349e-07
Iter: 1003 loss: 6.25771747e-07
Iter: 1004 loss: 6.25171197e-07
Iter: 1005 loss: 6.25706e-07
Iter: 1006 loss: 6.24813538e-07
Iter: 1007 loss: 6.24134259e-07
Iter: 1008 loss: 6.25520272e-07
Iter: 1009 loss: 6.23867e-07
Iter: 1010 loss: 6.23325946e-07
Iter: 1011 loss: 6.30629359e-07
Iter: 1012 loss: 6.23327253e-07
Iter: 1013 loss: 6.22795596e-07
Iter: 1014 loss: 6.24526592e-07
Iter: 1015 loss: 6.22651328e-07
Iter: 1016 loss: 6.22219318e-07
Iter: 1017 loss: 6.22238304e-07
Iter: 1018 loss: 6.21884908e-07
Iter: 1019 loss: 6.21432889e-07
Iter: 1020 loss: 6.21144522e-07
Iter: 1021 loss: 6.20973822e-07
Iter: 1022 loss: 6.20217122e-07
Iter: 1023 loss: 6.22001494e-07
Iter: 1024 loss: 6.19988157e-07
Iter: 1025 loss: 6.19208492e-07
Iter: 1026 loss: 6.20391461e-07
Iter: 1027 loss: 6.18863e-07
Iter: 1028 loss: 6.18149613e-07
Iter: 1029 loss: 6.27925715e-07
Iter: 1030 loss: 6.18098625e-07
Iter: 1031 loss: 6.17625176e-07
Iter: 1032 loss: 6.18124318e-07
Iter: 1033 loss: 6.17298269e-07
Iter: 1034 loss: 6.1674092e-07
Iter: 1035 loss: 6.20016067e-07
Iter: 1036 loss: 6.1664e-07
Iter: 1037 loss: 6.16100124e-07
Iter: 1038 loss: 6.16433681e-07
Iter: 1039 loss: 6.15780039e-07
Iter: 1040 loss: 6.15090244e-07
Iter: 1041 loss: 6.14920964e-07
Iter: 1042 loss: 6.145e-07
Iter: 1043 loss: 6.13652787e-07
Iter: 1044 loss: 6.16481771e-07
Iter: 1045 loss: 6.13478733e-07
Iter: 1046 loss: 6.12972258e-07
Iter: 1047 loss: 6.128829e-07
Iter: 1048 loss: 6.12636882e-07
Iter: 1049 loss: 6.12415306e-07
Iter: 1050 loss: 6.12336294e-07
Iter: 1051 loss: 6.11935661e-07
Iter: 1052 loss: 6.11683504e-07
Iter: 1053 loss: 6.11541338e-07
Iter: 1054 loss: 6.10924531e-07
Iter: 1055 loss: 6.12379949e-07
Iter: 1056 loss: 6.10726545e-07
Iter: 1057 loss: 6.10086659e-07
Iter: 1058 loss: 6.10504117e-07
Iter: 1059 loss: 6.09757876e-07
Iter: 1060 loss: 6.09025278e-07
Iter: 1061 loss: 6.15852912e-07
Iter: 1062 loss: 6.08991172e-07
Iter: 1063 loss: 6.08470373e-07
Iter: 1064 loss: 6.1091697e-07
Iter: 1065 loss: 6.08408072e-07
Iter: 1066 loss: 6.07938091e-07
Iter: 1067 loss: 6.09146696e-07
Iter: 1068 loss: 6.07805e-07
Iter: 1069 loss: 6.07341633e-07
Iter: 1070 loss: 6.08252776e-07
Iter: 1071 loss: 6.07163315e-07
Iter: 1072 loss: 6.06594313e-07
Iter: 1073 loss: 6.06462379e-07
Iter: 1074 loss: 6.06117396e-07
Iter: 1075 loss: 6.05593414e-07
Iter: 1076 loss: 6.05977618e-07
Iter: 1077 loss: 6.05244338e-07
Iter: 1078 loss: 6.05321475e-07
Iter: 1079 loss: 6.04938464e-07
Iter: 1080 loss: 6.04698926e-07
Iter: 1081 loss: 6.04284196e-07
Iter: 1082 loss: 6.04284537e-07
Iter: 1083 loss: 6.0373759e-07
Iter: 1084 loss: 6.03646413e-07
Iter: 1085 loss: 6.03346564e-07
Iter: 1086 loss: 6.02604132e-07
Iter: 1087 loss: 6.04801357e-07
Iter: 1088 loss: 6.02386535e-07
Iter: 1089 loss: 6.01750685e-07
Iter: 1090 loss: 6.02008413e-07
Iter: 1091 loss: 6.01314298e-07
Iter: 1092 loss: 6.00605688e-07
Iter: 1093 loss: 6.04884349e-07
Iter: 1094 loss: 6.00535429e-07
Iter: 1095 loss: 5.99949828e-07
Iter: 1096 loss: 6.03115666e-07
Iter: 1097 loss: 5.99897533e-07
Iter: 1098 loss: 5.99464443e-07
Iter: 1099 loss: 6.0116497e-07
Iter: 1100 loss: 5.99326711e-07
Iter: 1101 loss: 5.9891795e-07
Iter: 1102 loss: 5.99244117e-07
Iter: 1103 loss: 5.98690804e-07
Iter: 1104 loss: 5.98063366e-07
Iter: 1105 loss: 5.98822908e-07
Iter: 1106 loss: 5.97747089e-07
Iter: 1107 loss: 5.97201165e-07
Iter: 1108 loss: 5.98050462e-07
Iter: 1109 loss: 5.96989764e-07
Iter: 1110 loss: 5.96474308e-07
Iter: 1111 loss: 6.02701959e-07
Iter: 1112 loss: 5.96492441e-07
Iter: 1113 loss: 5.96015639e-07
Iter: 1114 loss: 5.98106112e-07
Iter: 1115 loss: 5.95881829e-07
Iter: 1116 loss: 5.95658662e-07
Iter: 1117 loss: 5.95125357e-07
Iter: 1118 loss: 6.0247487e-07
Iter: 1119 loss: 5.95064876e-07
Iter: 1120 loss: 5.94441e-07
Iter: 1121 loss: 5.99752752e-07
Iter: 1122 loss: 5.94399921e-07
Iter: 1123 loss: 5.93914592e-07
Iter: 1124 loss: 5.93454047e-07
Iter: 1125 loss: 5.93325581e-07
Iter: 1126 loss: 5.92709171e-07
Iter: 1127 loss: 5.96791779e-07
Iter: 1128 loss: 5.925707e-07
Iter: 1129 loss: 5.91986179e-07
Iter: 1130 loss: 5.93012714e-07
Iter: 1131 loss: 5.91703952e-07
Iter: 1132 loss: 5.91330036e-07
Iter: 1133 loss: 5.91330206e-07
Iter: 1134 loss: 5.91055368e-07
Iter: 1135 loss: 5.90691627e-07
Iter: 1136 loss: 5.90635068e-07
Iter: 1137 loss: 5.90130753e-07
Iter: 1138 loss: 5.93151867e-07
Iter: 1139 loss: 5.90032528e-07
Iter: 1140 loss: 5.89643548e-07
Iter: 1141 loss: 5.90326692e-07
Iter: 1142 loss: 5.89457841e-07
Iter: 1143 loss: 5.89129172e-07
Iter: 1144 loss: 5.91084756e-07
Iter: 1145 loss: 5.89050501e-07
Iter: 1146 loss: 5.88752414e-07
Iter: 1147 loss: 5.91965033e-07
Iter: 1148 loss: 5.88712624e-07
Iter: 1149 loss: 5.88530611e-07
Iter: 1150 loss: 5.87995146e-07
Iter: 1151 loss: 5.91927517e-07
Iter: 1152 loss: 5.87879413e-07
Iter: 1153 loss: 5.87228783e-07
Iter: 1154 loss: 5.90950265e-07
Iter: 1155 loss: 5.87148747e-07
Iter: 1156 loss: 5.86500107e-07
Iter: 1157 loss: 5.87426257e-07
Iter: 1158 loss: 5.86232e-07
Iter: 1159 loss: 5.85673433e-07
Iter: 1160 loss: 5.89109391e-07
Iter: 1161 loss: 5.85583223e-07
Iter: 1162 loss: 5.85204702e-07
Iter: 1163 loss: 5.84524741e-07
Iter: 1164 loss: 5.84509849e-07
Iter: 1165 loss: 5.84199825e-07
Iter: 1166 loss: 5.84087275e-07
Iter: 1167 loss: 5.83716655e-07
Iter: 1168 loss: 5.83604844e-07
Iter: 1169 loss: 5.83381336e-07
Iter: 1170 loss: 5.82859343e-07
Iter: 1171 loss: 5.85168664e-07
Iter: 1172 loss: 5.82795678e-07
Iter: 1173 loss: 5.82308303e-07
Iter: 1174 loss: 5.83696078e-07
Iter: 1175 loss: 5.82111966e-07
Iter: 1176 loss: 5.81716336e-07
Iter: 1177 loss: 5.82438474e-07
Iter: 1178 loss: 5.81506811e-07
Iter: 1179 loss: 5.81409381e-07
Iter: 1180 loss: 5.81297968e-07
Iter: 1181 loss: 5.81145287e-07
Iter: 1182 loss: 5.80618632e-07
Iter: 1183 loss: 5.845489e-07
Iter: 1184 loss: 5.80567871e-07
Iter: 1185 loss: 5.80065716e-07
Iter: 1186 loss: 5.8130513e-07
Iter: 1187 loss: 5.79890866e-07
Iter: 1188 loss: 5.79377456e-07
Iter: 1189 loss: 5.80774554e-07
Iter: 1190 loss: 5.79143716e-07
Iter: 1191 loss: 5.78656284e-07
Iter: 1192 loss: 5.8117422e-07
Iter: 1193 loss: 5.78605182e-07
Iter: 1194 loss: 5.78232971e-07
Iter: 1195 loss: 5.77951e-07
Iter: 1196 loss: 5.77783169e-07
Iter: 1197 loss: 5.77265723e-07
Iter: 1198 loss: 5.81512438e-07
Iter: 1199 loss: 5.77199671e-07
Iter: 1200 loss: 5.76679668e-07
Iter: 1201 loss: 5.79673156e-07
Iter: 1202 loss: 5.76582e-07
Iter: 1203 loss: 5.76204911e-07
Iter: 1204 loss: 5.76854745e-07
Iter: 1205 loss: 5.76052116e-07
Iter: 1206 loss: 5.75622266e-07
Iter: 1207 loss: 5.76763682e-07
Iter: 1208 loss: 5.7552063e-07
Iter: 1209 loss: 5.75125341e-07
Iter: 1210 loss: 5.75568833e-07
Iter: 1211 loss: 5.74876253e-07
Iter: 1212 loss: 5.7471982e-07
Iter: 1213 loss: 5.74680143e-07
Iter: 1214 loss: 5.7445169e-07
Iter: 1215 loss: 5.74156218e-07
Iter: 1216 loss: 5.74155479e-07
Iter: 1217 loss: 5.73808791e-07
Iter: 1218 loss: 5.73797706e-07
Iter: 1219 loss: 5.73534578e-07
Iter: 1220 loss: 5.73065847e-07
Iter: 1221 loss: 5.73805664e-07
Iter: 1222 loss: 5.72903843e-07
Iter: 1223 loss: 5.7238e-07
Iter: 1224 loss: 5.75308832e-07
Iter: 1225 loss: 5.72328418e-07
Iter: 1226 loss: 5.71874807e-07
Iter: 1227 loss: 5.71491739e-07
Iter: 1228 loss: 5.71369412e-07
Iter: 1229 loss: 5.70741065e-07
Iter: 1230 loss: 5.76073376e-07
Iter: 1231 loss: 5.70715542e-07
Iter: 1232 loss: 5.70175075e-07
Iter: 1233 loss: 5.72991098e-07
Iter: 1234 loss: 5.70125e-07
Iter: 1235 loss: 5.69702649e-07
Iter: 1236 loss: 5.7102e-07
Iter: 1237 loss: 5.6959243e-07
Iter: 1238 loss: 5.69255803e-07
Iter: 1239 loss: 5.69706287e-07
Iter: 1240 loss: 5.69087206e-07
Iter: 1241 loss: 5.68628138e-07
Iter: 1242 loss: 5.69376482e-07
Iter: 1243 loss: 5.6839e-07
Iter: 1244 loss: 5.68105293e-07
Iter: 1245 loss: 5.68104838e-07
Iter: 1246 loss: 5.67790892e-07
Iter: 1247 loss: 5.68260077e-07
Iter: 1248 loss: 5.67636278e-07
Iter: 1249 loss: 5.67448183e-07
Iter: 1250 loss: 5.67085863e-07
Iter: 1251 loss: 5.67078132e-07
Iter: 1252 loss: 5.66576887e-07
Iter: 1253 loss: 5.66916867e-07
Iter: 1254 loss: 5.6624333e-07
Iter: 1255 loss: 5.65732307e-07
Iter: 1256 loss: 5.70752832e-07
Iter: 1257 loss: 5.65692517e-07
Iter: 1258 loss: 5.65294386e-07
Iter: 1259 loss: 5.65390224e-07
Iter: 1260 loss: 5.65006189e-07
Iter: 1261 loss: 5.64504262e-07
Iter: 1262 loss: 5.66760889e-07
Iter: 1263 loss: 5.644265e-07
Iter: 1264 loss: 5.64032405e-07
Iter: 1265 loss: 5.6623071e-07
Iter: 1266 loss: 5.63955609e-07
Iter: 1267 loss: 5.63573508e-07
Iter: 1268 loss: 5.64575032e-07
Iter: 1269 loss: 5.63454194e-07
Iter: 1270 loss: 5.63111e-07
Iter: 1271 loss: 5.63419576e-07
Iter: 1272 loss: 5.62922196e-07
Iter: 1273 loss: 5.6247012e-07
Iter: 1274 loss: 5.64004552e-07
Iter: 1275 loss: 5.62349499e-07
Iter: 1276 loss: 5.61985473e-07
Iter: 1277 loss: 5.63712206e-07
Iter: 1278 loss: 5.61897195e-07
Iter: 1279 loss: 5.61541526e-07
Iter: 1280 loss: 5.64074071e-07
Iter: 1281 loss: 5.61460354e-07
Iter: 1282 loss: 5.61204388e-07
Iter: 1283 loss: 5.60896069e-07
Iter: 1284 loss: 5.60892033e-07
Iter: 1285 loss: 5.60536478e-07
Iter: 1286 loss: 5.60544834e-07
Iter: 1287 loss: 5.6026181e-07
Iter: 1288 loss: 5.59792e-07
Iter: 1289 loss: 5.64308436e-07
Iter: 1290 loss: 5.59811042e-07
Iter: 1291 loss: 5.5947396e-07
Iter: 1292 loss: 5.59702812e-07
Iter: 1293 loss: 5.59274326e-07
Iter: 1294 loss: 5.58835723e-07
Iter: 1295 loss: 5.5970213e-07
Iter: 1296 loss: 5.58681e-07
Iter: 1297 loss: 5.58223121e-07
Iter: 1298 loss: 5.59663931e-07
Iter: 1299 loss: 5.58061231e-07
Iter: 1300 loss: 5.57623423e-07
Iter: 1301 loss: 5.60709964e-07
Iter: 1302 loss: 5.57575618e-07
Iter: 1303 loss: 5.57234614e-07
Iter: 1304 loss: 5.57239332e-07
Iter: 1305 loss: 5.56944e-07
Iter: 1306 loss: 5.56465125e-07
Iter: 1307 loss: 5.58694637e-07
Iter: 1308 loss: 5.56419877e-07
Iter: 1309 loss: 5.56042323e-07
Iter: 1310 loss: 5.57761155e-07
Iter: 1311 loss: 5.56043e-07
Iter: 1312 loss: 5.55740939e-07
Iter: 1313 loss: 5.60049898e-07
Iter: 1314 loss: 5.55720248e-07
Iter: 1315 loss: 5.5550629e-07
Iter: 1316 loss: 5.55106055e-07
Iter: 1317 loss: 5.62097455e-07
Iter: 1318 loss: 5.55047563e-07
Iter: 1319 loss: 5.54702183e-07
Iter: 1320 loss: 5.5497992e-07
Iter: 1321 loss: 5.54448775e-07
Iter: 1322 loss: 5.5398948e-07
Iter: 1323 loss: 5.5708432e-07
Iter: 1324 loss: 5.5395418e-07
Iter: 1325 loss: 5.53618577e-07
Iter: 1326 loss: 5.54384371e-07
Iter: 1327 loss: 5.5344259e-07
Iter: 1328 loss: 5.53039968e-07
Iter: 1329 loss: 5.5405684e-07
Iter: 1330 loss: 5.52928554e-07
Iter: 1331 loss: 5.52569247e-07
Iter: 1332 loss: 5.52815322e-07
Iter: 1333 loss: 5.52318511e-07
Iter: 1334 loss: 5.51854e-07
Iter: 1335 loss: 5.57356202e-07
Iter: 1336 loss: 5.51832443e-07
Iter: 1337 loss: 5.51550102e-07
Iter: 1338 loss: 5.51687322e-07
Iter: 1339 loss: 5.51387586e-07
Iter: 1340 loss: 5.50981326e-07
Iter: 1341 loss: 5.51353651e-07
Iter: 1342 loss: 5.50752134e-07
Iter: 1343 loss: 5.50309096e-07
Iter: 1344 loss: 5.52568679e-07
Iter: 1345 loss: 5.50187792e-07
Iter: 1346 loss: 5.49935351e-07
Iter: 1347 loss: 5.49917218e-07
Iter: 1348 loss: 5.49677338e-07
Iter: 1349 loss: 5.49351228e-07
Iter: 1350 loss: 5.49335766e-07
Iter: 1351 loss: 5.49014658e-07
Iter: 1352 loss: 5.4875585e-07
Iter: 1353 loss: 5.48641879e-07
Iter: 1354 loss: 5.48250114e-07
Iter: 1355 loss: 5.51461824e-07
Iter: 1356 loss: 5.48178377e-07
Iter: 1357 loss: 5.47804859e-07
Iter: 1358 loss: 5.48119147e-07
Iter: 1359 loss: 5.47597665e-07
Iter: 1360 loss: 5.47059699e-07
Iter: 1361 loss: 5.49325364e-07
Iter: 1362 loss: 5.46945273e-07
Iter: 1363 loss: 5.46577894e-07
Iter: 1364 loss: 5.47246827e-07
Iter: 1365 loss: 5.46442948e-07
Iter: 1366 loss: 5.46084152e-07
Iter: 1367 loss: 5.49808874e-07
Iter: 1368 loss: 5.46120077e-07
Iter: 1369 loss: 5.45845921e-07
Iter: 1370 loss: 5.4597831e-07
Iter: 1371 loss: 5.4564623e-07
Iter: 1372 loss: 5.45274418e-07
Iter: 1373 loss: 5.45487467e-07
Iter: 1374 loss: 5.45063131e-07
Iter: 1375 loss: 5.44626346e-07
Iter: 1376 loss: 5.46513377e-07
Iter: 1377 loss: 5.44522038e-07
Iter: 1378 loss: 5.44245552e-07
Iter: 1379 loss: 5.48844923e-07
Iter: 1380 loss: 5.4424936e-07
Iter: 1381 loss: 5.43964177e-07
Iter: 1382 loss: 5.4387931e-07
Iter: 1383 loss: 5.43690192e-07
Iter: 1384 loss: 5.43381134e-07
Iter: 1385 loss: 5.43131932e-07
Iter: 1386 loss: 5.4304212e-07
Iter: 1387 loss: 5.42610337e-07
Iter: 1388 loss: 5.44220597e-07
Iter: 1389 loss: 5.42484486e-07
Iter: 1390 loss: 5.42171506e-07
Iter: 1391 loss: 5.43607598e-07
Iter: 1392 loss: 5.42106e-07
Iter: 1393 loss: 5.41752e-07
Iter: 1394 loss: 5.42647797e-07
Iter: 1395 loss: 5.41617965e-07
Iter: 1396 loss: 5.41296117e-07
Iter: 1397 loss: 5.4183846e-07
Iter: 1398 loss: 5.41178906e-07
Iter: 1399 loss: 5.40882866e-07
Iter: 1400 loss: 5.43611e-07
Iter: 1401 loss: 5.40861947e-07
Iter: 1402 loss: 5.40633152e-07
Iter: 1403 loss: 5.41365409e-07
Iter: 1404 loss: 5.40553515e-07
Iter: 1405 loss: 5.40299538e-07
Iter: 1406 loss: 5.40035103e-07
Iter: 1407 loss: 5.40008557e-07
Iter: 1408 loss: 5.39656867e-07
Iter: 1409 loss: 5.43566955e-07
Iter: 1410 loss: 5.39667099e-07
Iter: 1411 loss: 5.39440464e-07
Iter: 1412 loss: 5.40726944e-07
Iter: 1413 loss: 5.39380835e-07
Iter: 1414 loss: 5.3914664e-07
Iter: 1415 loss: 5.39601558e-07
Iter: 1416 loss: 5.38992e-07
Iter: 1417 loss: 5.3882934e-07
Iter: 1418 loss: 5.38567178e-07
Iter: 1419 loss: 5.38578092e-07
Iter: 1420 loss: 5.38155746e-07
Iter: 1421 loss: 5.38838151e-07
Iter: 1422 loss: 5.38009601e-07
Iter: 1423 loss: 5.37637789e-07
Iter: 1424 loss: 5.38245047e-07
Iter: 1425 loss: 5.3745373e-07
Iter: 1426 loss: 5.36980906e-07
Iter: 1427 loss: 5.40077281e-07
Iter: 1428 loss: 5.36910534e-07
Iter: 1429 loss: 5.36548328e-07
Iter: 1430 loss: 5.37127448e-07
Iter: 1431 loss: 5.36445441e-07
Iter: 1432 loss: 5.36134678e-07
Iter: 1433 loss: 5.38251697e-07
Iter: 1434 loss: 5.36054472e-07
Iter: 1435 loss: 5.35788672e-07
Iter: 1436 loss: 5.36796222e-07
Iter: 1437 loss: 5.35736604e-07
Iter: 1438 loss: 5.35450454e-07
Iter: 1439 loss: 5.35525146e-07
Iter: 1440 loss: 5.35191873e-07
Iter: 1441 loss: 5.34911578e-07
Iter: 1442 loss: 5.36661219e-07
Iter: 1443 loss: 5.34894184e-07
Iter: 1444 loss: 5.34636e-07
Iter: 1445 loss: 5.36292532e-07
Iter: 1446 loss: 5.34606102e-07
Iter: 1447 loss: 5.34378842e-07
Iter: 1448 loss: 5.3549843e-07
Iter: 1449 loss: 5.34293747e-07
Iter: 1450 loss: 5.3415414e-07
Iter: 1451 loss: 5.33861964e-07
Iter: 1452 loss: 5.40732799e-07
Iter: 1453 loss: 5.33870946e-07
Iter: 1454 loss: 5.33519085e-07
Iter: 1455 loss: 5.33775676e-07
Iter: 1456 loss: 5.33304842e-07
Iter: 1457 loss: 5.32933427e-07
Iter: 1458 loss: 5.34763046e-07
Iter: 1459 loss: 5.32860668e-07
Iter: 1460 loss: 5.32534273e-07
Iter: 1461 loss: 5.33866967e-07
Iter: 1462 loss: 5.3244878e-07
Iter: 1463 loss: 5.32156776e-07
Iter: 1464 loss: 5.32702757e-07
Iter: 1465 loss: 5.3204468e-07
Iter: 1466 loss: 5.31703677e-07
Iter: 1467 loss: 5.32527793e-07
Iter: 1468 loss: 5.31615115e-07
Iter: 1469 loss: 5.31260525e-07
Iter: 1470 loss: 5.33911134e-07
Iter: 1471 loss: 5.31308615e-07
Iter: 1472 loss: 5.3104668e-07
Iter: 1473 loss: 5.30841362e-07
Iter: 1474 loss: 5.30739385e-07
Iter: 1475 loss: 5.30403895e-07
Iter: 1476 loss: 5.32405465e-07
Iter: 1477 loss: 5.3038e-07
Iter: 1478 loss: 5.30099555e-07
Iter: 1479 loss: 5.31283604e-07
Iter: 1480 loss: 5.30034072e-07
Iter: 1481 loss: 5.29747e-07
Iter: 1482 loss: 5.32573267e-07
Iter: 1483 loss: 5.29780323e-07
Iter: 1484 loss: 5.2959723e-07
Iter: 1485 loss: 5.29347176e-07
Iter: 1486 loss: 5.29353e-07
Iter: 1487 loss: 5.28974283e-07
Iter: 1488 loss: 5.28907435e-07
Iter: 1489 loss: 5.28673468e-07
Iter: 1490 loss: 5.28239696e-07
Iter: 1491 loss: 5.29916e-07
Iter: 1492 loss: 5.28185353e-07
Iter: 1493 loss: 5.27801035e-07
Iter: 1494 loss: 5.29906458e-07
Iter: 1495 loss: 5.27737257e-07
Iter: 1496 loss: 5.27377665e-07
Iter: 1497 loss: 5.27812631e-07
Iter: 1498 loss: 5.2724e-07
Iter: 1499 loss: 5.26842143e-07
Iter: 1500 loss: 5.28024032e-07
Iter: 1501 loss: 5.26735448e-07
Iter: 1502 loss: 5.26490282e-07
Iter: 1503 loss: 5.2941823e-07
Iter: 1504 loss: 5.26514668e-07
Iter: 1505 loss: 5.26266035e-07
Iter: 1506 loss: 5.26245799e-07
Iter: 1507 loss: 5.26086183e-07
Iter: 1508 loss: 5.25825328e-07
Iter: 1509 loss: 5.26348572e-07
Iter: 1510 loss: 5.25686346e-07
Iter: 1511 loss: 5.25395762e-07
Iter: 1512 loss: 5.27182237e-07
Iter: 1513 loss: 5.25336645e-07
Iter: 1514 loss: 5.25112227e-07
Iter: 1515 loss: 5.2509688e-07
Iter: 1516 loss: 5.24943e-07
Iter: 1517 loss: 5.2476895e-07
Iter: 1518 loss: 5.2478606e-07
Iter: 1519 loss: 5.24501957e-07
Iter: 1520 loss: 5.24264351e-07
Iter: 1521 loss: 5.24209781e-07
Iter: 1522 loss: 5.2387503e-07
Iter: 1523 loss: 5.25456585e-07
Iter: 1524 loss: 5.23744234e-07
Iter: 1525 loss: 5.23419089e-07
Iter: 1526 loss: 5.24361e-07
Iter: 1527 loss: 5.23334847e-07
Iter: 1528 loss: 5.23007088e-07
Iter: 1529 loss: 5.24447842e-07
Iter: 1530 loss: 5.22930577e-07
Iter: 1531 loss: 5.22554615e-07
Iter: 1532 loss: 5.22849803e-07
Iter: 1533 loss: 5.22364303e-07
Iter: 1534 loss: 5.22091227e-07
Iter: 1535 loss: 5.25310782e-07
Iter: 1536 loss: 5.22099185e-07
Iter: 1537 loss: 5.2185851e-07
Iter: 1538 loss: 5.22341395e-07
Iter: 1539 loss: 5.21807465e-07
Iter: 1540 loss: 5.21578045e-07
Iter: 1541 loss: 5.21661093e-07
Iter: 1542 loss: 5.21441e-07
Iter: 1543 loss: 5.21151094e-07
Iter: 1544 loss: 5.21971288e-07
Iter: 1545 loss: 5.2099864e-07
Iter: 1546 loss: 5.2079622e-07
Iter: 1547 loss: 5.20793e-07
Iter: 1548 loss: 5.20656499e-07
Iter: 1549 loss: 5.20587264e-07
Iter: 1550 loss: 5.20513879e-07
Iter: 1551 loss: 5.2027076e-07
Iter: 1552 loss: 5.1994607e-07
Iter: 1553 loss: 5.19925607e-07
Iter: 1554 loss: 5.19611376e-07
Iter: 1555 loss: 5.2165e-07
Iter: 1556 loss: 5.19547655e-07
Iter: 1557 loss: 5.19181754e-07
Iter: 1558 loss: 5.19718867e-07
Iter: 1559 loss: 5.1901e-07
Iter: 1560 loss: 5.18689035e-07
Iter: 1561 loss: 5.20588912e-07
Iter: 1562 loss: 5.18660784e-07
Iter: 1563 loss: 5.18360935e-07
Iter: 1564 loss: 5.18843535e-07
Iter: 1565 loss: 5.18230081e-07
Iter: 1566 loss: 5.17959222e-07
Iter: 1567 loss: 5.18705292e-07
Iter: 1568 loss: 5.17858894e-07
Iter: 1569 loss: 5.17541821e-07
Iter: 1570 loss: 5.19122068e-07
Iter: 1571 loss: 5.17498961e-07
Iter: 1572 loss: 5.17247202e-07
Iter: 1573 loss: 5.17470824e-07
Iter: 1574 loss: 5.1707e-07
Iter: 1575 loss: 5.1681252e-07
Iter: 1576 loss: 5.17412786e-07
Iter: 1577 loss: 5.16705e-07
Iter: 1578 loss: 5.1655411e-07
Iter: 1579 loss: 5.16533078e-07
Iter: 1580 loss: 5.16412342e-07
Iter: 1581 loss: 5.16331e-07
Iter: 1582 loss: 5.16302748e-07
Iter: 1583 loss: 5.16063892e-07
Iter: 1584 loss: 5.15832426e-07
Iter: 1585 loss: 5.15790248e-07
Iter: 1586 loss: 5.15508248e-07
Iter: 1587 loss: 5.15976922e-07
Iter: 1588 loss: 5.15370516e-07
Iter: 1589 loss: 5.14989893e-07
Iter: 1590 loss: 5.16214527e-07
Iter: 1591 loss: 5.14888825e-07
Iter: 1592 loss: 5.14603187e-07
Iter: 1593 loss: 5.15853174e-07
Iter: 1594 loss: 5.14561179e-07
Iter: 1595 loss: 5.14236149e-07
Iter: 1596 loss: 5.1511023e-07
Iter: 1597 loss: 5.14175611e-07
Iter: 1598 loss: 5.13870077e-07
Iter: 1599 loss: 5.13943633e-07
Iter: 1600 loss: 5.13724217e-07
Iter: 1601 loss: 5.13415955e-07
Iter: 1602 loss: 5.13454e-07
Iter: 1603 loss: 5.13235591e-07
Iter: 1604 loss: 5.13352063e-07
Iter: 1605 loss: 5.13115197e-07
Iter: 1606 loss: 5.12879694e-07
Iter: 1607 loss: 5.12961037e-07
Iter: 1608 loss: 5.12713484e-07
Iter: 1609 loss: 5.12656186e-07
Iter: 1610 loss: 5.12629526e-07
Iter: 1611 loss: 5.12454619e-07
Iter: 1612 loss: 5.12371e-07
Iter: 1613 loss: 5.12351335e-07
Iter: 1614 loss: 5.12158067e-07
Iter: 1615 loss: 5.12170288e-07
Iter: 1616 loss: 5.11995722e-07
Iter: 1617 loss: 5.11795861e-07
Iter: 1618 loss: 5.11819223e-07
Iter: 1619 loss: 5.11611461e-07
Iter: 1620 loss: 5.11276539e-07
Iter: 1621 loss: 5.12280621e-07
Iter: 1622 loss: 5.11188432e-07
Iter: 1623 loss: 5.10906034e-07
Iter: 1624 loss: 5.12009365e-07
Iter: 1625 loss: 5.10842881e-07
Iter: 1626 loss: 5.10576228e-07
Iter: 1627 loss: 5.11720032e-07
Iter: 1628 loss: 5.10537461e-07
Iter: 1629 loss: 5.10306336e-07
Iter: 1630 loss: 5.10495852e-07
Iter: 1631 loss: 5.10168661e-07
Iter: 1632 loss: 5.09874098e-07
Iter: 1633 loss: 5.11577241e-07
Iter: 1634 loss: 5.09837719e-07
Iter: 1635 loss: 5.09617053e-07
Iter: 1636 loss: 5.10821451e-07
Iter: 1637 loss: 5.09574249e-07
Iter: 1638 loss: 5.0941037e-07
Iter: 1639 loss: 5.09142524e-07
Iter: 1640 loss: 5.09122629e-07
Iter: 1641 loss: 5.09060783e-07
Iter: 1642 loss: 5.08991434e-07
Iter: 1643 loss: 5.0884978e-07
Iter: 1644 loss: 5.08973358e-07
Iter: 1645 loss: 5.08722337e-07
Iter: 1646 loss: 5.08597623e-07
Iter: 1647 loss: 5.08520827e-07
Iter: 1648 loss: 5.08424705e-07
Iter: 1649 loss: 5.08222229e-07
Iter: 1650 loss: 5.0852384e-07
Iter: 1651 loss: 5.08132e-07
Iter: 1652 loss: 5.07880713e-07
Iter: 1653 loss: 5.08069093e-07
Iter: 1654 loss: 5.07701543e-07
Iter: 1655 loss: 5.07414e-07
Iter: 1656 loss: 5.07913569e-07
Iter: 1657 loss: 5.07292896e-07
Iter: 1658 loss: 5.06971901e-07
Iter: 1659 loss: 5.09026449e-07
Iter: 1660 loss: 5.06888455e-07
Iter: 1661 loss: 5.06635843e-07
Iter: 1662 loss: 5.07159029e-07
Iter: 1663 loss: 5.06560298e-07
Iter: 1664 loss: 5.06271931e-07
Iter: 1665 loss: 5.07282039e-07
Iter: 1666 loss: 5.06197466e-07
Iter: 1667 loss: 5.05977823e-07
Iter: 1668 loss: 5.07953132e-07
Iter: 1669 loss: 5.05937408e-07
Iter: 1670 loss: 5.05783532e-07
Iter: 1671 loss: 5.05588105e-07
Iter: 1672 loss: 5.05579692e-07
Iter: 1673 loss: 5.05352659e-07
Iter: 1674 loss: 5.08028108e-07
Iter: 1675 loss: 5.0536346e-07
Iter: 1676 loss: 5.05173375e-07
Iter: 1677 loss: 5.05900516e-07
Iter: 1678 loss: 5.05137564e-07
Iter: 1679 loss: 5.04971695e-07
Iter: 1680 loss: 5.04802529e-07
Iter: 1681 loss: 5.04768252e-07
Iter: 1682 loss: 5.04600962e-07
Iter: 1683 loss: 5.05550872e-07
Iter: 1684 loss: 5.04507057e-07
Iter: 1685 loss: 5.04387117e-07
Iter: 1686 loss: 5.04213517e-07
Iter: 1687 loss: 5.04156446e-07
Iter: 1688 loss: 5.03869273e-07
Iter: 1689 loss: 5.04788318e-07
Iter: 1690 loss: 5.03773094e-07
Iter: 1691 loss: 5.03502633e-07
Iter: 1692 loss: 5.05788421e-07
Iter: 1693 loss: 5.03515764e-07
Iter: 1694 loss: 5.03330625e-07
Iter: 1695 loss: 5.03426236e-07
Iter: 1696 loss: 5.03174e-07
Iter: 1697 loss: 5.0286792e-07
Iter: 1698 loss: 5.03703234e-07
Iter: 1699 loss: 5.02825969e-07
Iter: 1700 loss: 5.02584328e-07
Iter: 1701 loss: 5.05145636e-07
Iter: 1702 loss: 5.02596436e-07
Iter: 1703 loss: 5.02412718e-07
Iter: 1704 loss: 5.02246053e-07
Iter: 1705 loss: 5.02213084e-07
Iter: 1706 loss: 5.01975478e-07
Iter: 1707 loss: 5.02879175e-07
Iter: 1708 loss: 5.01893851e-07
Iter: 1709 loss: 5.01748787e-07
Iter: 1710 loss: 5.01743e-07
Iter: 1711 loss: 5.01614522e-07
Iter: 1712 loss: 5.01389309e-07
Iter: 1713 loss: 5.0617632e-07
Iter: 1714 loss: 5.01394084e-07
Iter: 1715 loss: 5.01216732e-07
Iter: 1716 loss: 5.02310741e-07
Iter: 1717 loss: 5.01172849e-07
Iter: 1718 loss: 5.0099635e-07
Iter: 1719 loss: 5.00898182e-07
Iter: 1720 loss: 5.0081951e-07
Iter: 1721 loss: 5.00595e-07
Iter: 1722 loss: 5.00894089e-07
Iter: 1723 loss: 5.00488852e-07
Iter: 1724 loss: 5.00186616e-07
Iter: 1725 loss: 5.02314947e-07
Iter: 1726 loss: 5.00176952e-07
Iter: 1727 loss: 4.9992434e-07
Iter: 1728 loss: 5.00417286e-07
Iter: 1729 loss: 4.99853172e-07
Iter: 1730 loss: 4.99609541e-07
Iter: 1731 loss: 5.00426097e-07
Iter: 1732 loss: 4.99522571e-07
Iter: 1733 loss: 4.99329e-07
Iter: 1734 loss: 5.00384431e-07
Iter: 1735 loss: 4.99320663e-07
Iter: 1736 loss: 4.99086127e-07
Iter: 1737 loss: 4.99223461e-07
Iter: 1738 loss: 4.98904285e-07
Iter: 1739 loss: 4.98694419e-07
Iter: 1740 loss: 4.99244777e-07
Iter: 1741 loss: 4.98644795e-07
Iter: 1742 loss: 4.98487736e-07
Iter: 1743 loss: 4.98477448e-07
Iter: 1744 loss: 4.98314193e-07
Iter: 1745 loss: 4.98232453e-07
Iter: 1746 loss: 4.98183454e-07
Iter: 1747 loss: 4.98047712e-07
Iter: 1748 loss: 4.98022587e-07
Iter: 1749 loss: 4.9790907e-07
Iter: 1750 loss: 4.97691701e-07
Iter: 1751 loss: 4.98690724e-07
Iter: 1752 loss: 4.97636e-07
Iter: 1753 loss: 4.9748536e-07
Iter: 1754 loss: 4.97286e-07
Iter: 1755 loss: 4.97242866e-07
Iter: 1756 loss: 4.96938128e-07
Iter: 1757 loss: 4.992811e-07
Iter: 1758 loss: 4.96907148e-07
Iter: 1759 loss: 4.96692564e-07
Iter: 1760 loss: 4.97255883e-07
Iter: 1761 loss: 4.96629184e-07
Iter: 1762 loss: 4.96382086e-07
Iter: 1763 loss: 4.97164763e-07
Iter: 1764 loss: 4.9633195e-07
Iter: 1765 loss: 4.96143571e-07
Iter: 1766 loss: 4.96369921e-07
Iter: 1767 loss: 4.95972586e-07
Iter: 1768 loss: 4.95703148e-07
Iter: 1769 loss: 4.97885594e-07
Iter: 1770 loss: 4.95689619e-07
Iter: 1771 loss: 4.95544214e-07
Iter: 1772 loss: 4.95463496e-07
Iter: 1773 loss: 4.9541211e-07
Iter: 1774 loss: 4.95194627e-07
Iter: 1775 loss: 4.95217e-07
Iter: 1776 loss: 4.95029326e-07
Iter: 1777 loss: 4.95352253e-07
Iter: 1778 loss: 4.94941105e-07
Iter: 1779 loss: 4.94839696e-07
Iter: 1780 loss: 4.94658366e-07
Iter: 1781 loss: 4.94650862e-07
Iter: 1782 loss: 4.944186e-07
Iter: 1783 loss: 4.96798634e-07
Iter: 1784 loss: 4.94416781e-07
Iter: 1785 loss: 4.94262736e-07
Iter: 1786 loss: 4.94186963e-07
Iter: 1787 loss: 4.94099254e-07
Iter: 1788 loss: 4.93875291e-07
Iter: 1789 loss: 4.94674964e-07
Iter: 1790 loss: 4.93790765e-07
Iter: 1791 loss: 4.93584594e-07
Iter: 1792 loss: 4.94289736e-07
Iter: 1793 loss: 4.93520474e-07
Iter: 1794 loss: 4.93261439e-07
Iter: 1795 loss: 4.94079416e-07
Iter: 1796 loss: 4.93203061e-07
Iter: 1797 loss: 4.93020082e-07
Iter: 1798 loss: 4.93319533e-07
Iter: 1799 loss: 4.92946185e-07
Iter: 1800 loss: 4.92723757e-07
Iter: 1801 loss: 4.94183837e-07
Iter: 1802 loss: 4.92676065e-07
Iter: 1803 loss: 4.92502522e-07
Iter: 1804 loss: 4.92521224e-07
Iter: 1805 loss: 4.92394747e-07
Iter: 1806 loss: 4.9218346e-07
Iter: 1807 loss: 4.93584594e-07
Iter: 1808 loss: 4.92122865e-07
Iter: 1809 loss: 4.91982178e-07
Iter: 1810 loss: 4.94363e-07
Iter: 1811 loss: 4.91963362e-07
Iter: 1812 loss: 4.91897481e-07
Iter: 1813 loss: 4.91660217e-07
Iter: 1814 loss: 4.93199195e-07
Iter: 1815 loss: 4.91635433e-07
Iter: 1816 loss: 4.91331889e-07
Iter: 1817 loss: 4.93632683e-07
Iter: 1818 loss: 4.91329502e-07
Iter: 1819 loss: 4.91148683e-07
Iter: 1820 loss: 4.91420224e-07
Iter: 1821 loss: 4.91045512e-07
Iter: 1822 loss: 4.90822742e-07
Iter: 1823 loss: 4.91097921e-07
Iter: 1824 loss: 4.90741115e-07
Iter: 1825 loss: 4.90501066e-07
Iter: 1826 loss: 4.91194555e-07
Iter: 1827 loss: 4.9046389e-07
Iter: 1828 loss: 4.90181606e-07
Iter: 1829 loss: 4.91228832e-07
Iter: 1830 loss: 4.90154378e-07
Iter: 1831 loss: 4.89986576e-07
Iter: 1832 loss: 4.90157504e-07
Iter: 1833 loss: 4.89857598e-07
Iter: 1834 loss: 4.89648471e-07
Iter: 1835 loss: 4.91405e-07
Iter: 1836 loss: 4.89614649e-07
Iter: 1837 loss: 4.89462536e-07
Iter: 1838 loss: 4.89746412e-07
Iter: 1839 loss: 4.89399e-07
Iter: 1840 loss: 4.89179911e-07
Iter: 1841 loss: 4.89105787e-07
Iter: 1842 loss: 4.89013132e-07
Iter: 1843 loss: 4.88902515e-07
Iter: 1844 loss: 4.88848e-07
Iter: 1845 loss: 4.88728688e-07
Iter: 1846 loss: 4.88494038e-07
Iter: 1847 loss: 4.9076607e-07
Iter: 1848 loss: 4.88438957e-07
Iter: 1849 loss: 4.88146611e-07
Iter: 1850 loss: 4.89128865e-07
Iter: 1851 loss: 4.88039575e-07
Iter: 1852 loss: 4.87828345e-07
Iter: 1853 loss: 4.88798605e-07
Iter: 1854 loss: 4.87799298e-07
Iter: 1855 loss: 4.87522072e-07
Iter: 1856 loss: 4.87852446e-07
Iter: 1857 loss: 4.87408101e-07
Iter: 1858 loss: 4.87234729e-07
Iter: 1859 loss: 4.87402758e-07
Iter: 1860 loss: 4.871182e-07
Iter: 1861 loss: 4.86904e-07
Iter: 1862 loss: 4.88730223e-07
Iter: 1863 loss: 4.86892759e-07
Iter: 1864 loss: 4.86740248e-07
Iter: 1865 loss: 4.87179591e-07
Iter: 1866 loss: 4.86667659e-07
Iter: 1867 loss: 4.86472061e-07
Iter: 1868 loss: 4.86573356e-07
Iter: 1869 loss: 4.86372e-07
Iter: 1870 loss: 4.86106842e-07
Iter: 1871 loss: 4.87387069e-07
Iter: 1872 loss: 4.86034594e-07
Iter: 1873 loss: 4.85850592e-07
Iter: 1874 loss: 4.85732471e-07
Iter: 1875 loss: 4.85639362e-07
Iter: 1876 loss: 4.85662611e-07
Iter: 1877 loss: 4.85504813e-07
Iter: 1878 loss: 4.85407782e-07
Iter: 1879 loss: 4.85210421e-07
Iter: 1880 loss: 4.88362616e-07
Iter: 1881 loss: 4.85186547e-07
Iter: 1882 loss: 4.85023293e-07
Iter: 1883 loss: 4.85297505e-07
Iter: 1884 loss: 4.84898351e-07
Iter: 1885 loss: 4.84663587e-07
Iter: 1886 loss: 4.85530506e-07
Iter: 1887 loss: 4.84612883e-07
Iter: 1888 loss: 4.84332645e-07
Iter: 1889 loss: 4.8496031e-07
Iter: 1890 loss: 4.84264319e-07
Iter: 1891 loss: 4.83995791e-07
Iter: 1892 loss: 4.84099587e-07
Iter: 1893 loss: 4.83853796e-07
Iter: 1894 loss: 4.83586348e-07
Iter: 1895 loss: 4.85306e-07
Iter: 1896 loss: 4.83567362e-07
Iter: 1897 loss: 4.83366421e-07
Iter: 1898 loss: 4.84068437e-07
Iter: 1899 loss: 4.83312533e-07
Iter: 1900 loss: 4.83079191e-07
Iter: 1901 loss: 4.83821054e-07
Iter: 1902 loss: 4.83045881e-07
Iter: 1903 loss: 4.82879955e-07
Iter: 1904 loss: 4.83735107e-07
Iter: 1905 loss: 4.82835446e-07
Iter: 1906 loss: 4.82688961e-07
Iter: 1907 loss: 4.82557539e-07
Iter: 1908 loss: 4.82466703e-07
Iter: 1909 loss: 4.82384166e-07
Iter: 1910 loss: 4.82365522e-07
Iter: 1911 loss: 4.82221253e-07
Iter: 1912 loss: 4.82209771e-07
Iter: 1913 loss: 4.82079031e-07
Iter: 1914 loss: 4.81959546e-07
Iter: 1915 loss: 4.81700852e-07
Iter: 1916 loss: 4.81700567e-07
Iter: 1917 loss: 4.81445909e-07
Iter: 1918 loss: 4.83325152e-07
Iter: 1919 loss: 4.81427321e-07
Iter: 1920 loss: 4.81247923e-07
Iter: 1921 loss: 4.81810275e-07
Iter: 1922 loss: 4.81149812e-07
Iter: 1923 loss: 4.8094995e-07
Iter: 1924 loss: 4.81239226e-07
Iter: 1925 loss: 4.80830863e-07
Iter: 1926 loss: 4.80562107e-07
Iter: 1927 loss: 4.80984852e-07
Iter: 1928 loss: 4.80416873e-07
Iter: 1929 loss: 4.8018677e-07
Iter: 1930 loss: 4.81582447e-07
Iter: 1931 loss: 4.80140102e-07
Iter: 1932 loss: 4.79927564e-07
Iter: 1933 loss: 4.80624578e-07
Iter: 1934 loss: 4.79849461e-07
Iter: 1935 loss: 4.79671485e-07
Iter: 1936 loss: 4.81251163e-07
Iter: 1937 loss: 4.79673872e-07
Iter: 1938 loss: 4.79448e-07
Iter: 1939 loss: 4.79413814e-07
Iter: 1940 loss: 4.79313883e-07
Iter: 1941 loss: 4.79063544e-07
Iter: 1942 loss: 4.8002903e-07
Iter: 1943 loss: 4.79048936e-07
Iter: 1944 loss: 4.78937e-07
Iter: 1945 loss: 4.78897505e-07
Iter: 1946 loss: 4.78845891e-07
Iter: 1947 loss: 4.7861e-07
Iter: 1948 loss: 4.794897e-07
Iter: 1949 loss: 4.78511708e-07
Iter: 1950 loss: 4.78256766e-07
Iter: 1951 loss: 4.78521827e-07
Iter: 1952 loss: 4.78099253e-07
Iter: 1953 loss: 4.77763365e-07
Iter: 1954 loss: 4.81774293e-07
Iter: 1955 loss: 4.77754384e-07
Iter: 1956 loss: 4.77570552e-07
Iter: 1957 loss: 4.7784539e-07
Iter: 1958 loss: 4.77466301e-07
Iter: 1959 loss: 4.77276103e-07
Iter: 1960 loss: 4.7738547e-07
Iter: 1961 loss: 4.77108415e-07
Iter: 1962 loss: 4.76846537e-07
Iter: 1963 loss: 4.77924e-07
Iter: 1964 loss: 4.76735494e-07
Iter: 1965 loss: 4.76517158e-07
Iter: 1966 loss: 4.7836312e-07
Iter: 1967 loss: 4.76504596e-07
Iter: 1968 loss: 4.76364278e-07
Iter: 1969 loss: 4.76635194e-07
Iter: 1970 loss: 4.76284185e-07
Iter: 1971 loss: 4.76080913e-07
Iter: 1972 loss: 4.76465971e-07
Iter: 1973 loss: 4.75950799e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4
+ date
Mon Oct 26 13:30:23 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71ce4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71ce42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71c48d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71d6dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71bf6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71c18378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71bd0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71bcd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71b8c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71b8cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71b8c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71b202f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71b0a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71ad3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71a95d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71ad3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71a5e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71a5b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71a27c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71a5b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f719f19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f719f1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71981c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f7196fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f71953488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69f90b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69f67b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69f2a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69f21488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69f21620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69ef4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69ec7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69ec7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69e54730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69e69400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f69e1fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.81299314e-05
Iter: 2 loss: 5.61392117e-05
Iter: 3 loss: 5.32347804e-05
Iter: 4 loss: 5.85583184e-05
Iter: 5 loss: 5.04550953e-05
Iter: 6 loss: 4.90955135e-05
Iter: 7 loss: 4.51988308e-05
Iter: 8 loss: 6.25027387e-05
Iter: 9 loss: 4.37589697e-05
Iter: 10 loss: 4.01230391e-05
Iter: 11 loss: 7.70764527e-05
Iter: 12 loss: 4.00153804e-05
Iter: 13 loss: 3.76056414e-05
Iter: 14 loss: 4.01186e-05
Iter: 15 loss: 3.62708597e-05
Iter: 16 loss: 3.44602122e-05
Iter: 17 loss: 3.14503923e-05
Iter: 18 loss: 3.14403405e-05
Iter: 19 loss: 2.78305706e-05
Iter: 20 loss: 3.14884528e-05
Iter: 21 loss: 2.57958654e-05
Iter: 22 loss: 2.42153e-05
Iter: 23 loss: 3.01928012e-05
Iter: 24 loss: 2.38360299e-05
Iter: 25 loss: 2.22470062e-05
Iter: 26 loss: 2.16949356e-05
Iter: 27 loss: 2.07934117e-05
Iter: 28 loss: 1.97542104e-05
Iter: 29 loss: 3.10478245e-05
Iter: 30 loss: 1.97321679e-05
Iter: 31 loss: 1.88446065e-05
Iter: 32 loss: 1.80109164e-05
Iter: 33 loss: 1.78031951e-05
Iter: 34 loss: 1.6900125e-05
Iter: 35 loss: 2.66723036e-05
Iter: 36 loss: 1.68792285e-05
Iter: 37 loss: 1.64035846e-05
Iter: 38 loss: 1.60619784e-05
Iter: 39 loss: 1.58982475e-05
Iter: 40 loss: 1.57707473e-05
Iter: 41 loss: 1.54715508e-05
Iter: 42 loss: 1.52004732e-05
Iter: 43 loss: 1.45994181e-05
Iter: 44 loss: 2.3139135e-05
Iter: 45 loss: 1.45696758e-05
Iter: 46 loss: 1.41546307e-05
Iter: 47 loss: 1.93354899e-05
Iter: 48 loss: 1.41503233e-05
Iter: 49 loss: 1.38156392e-05
Iter: 50 loss: 1.49903935e-05
Iter: 51 loss: 1.37288789e-05
Iter: 52 loss: 1.33633439e-05
Iter: 53 loss: 1.28736156e-05
Iter: 54 loss: 1.28471147e-05
Iter: 55 loss: 1.24875442e-05
Iter: 56 loss: 1.48474683e-05
Iter: 57 loss: 1.2450676e-05
Iter: 58 loss: 1.2008476e-05
Iter: 59 loss: 1.17441632e-05
Iter: 60 loss: 1.15610965e-05
Iter: 61 loss: 1.12204771e-05
Iter: 62 loss: 1.11993231e-05
Iter: 63 loss: 1.09656303e-05
Iter: 64 loss: 1.0819841e-05
Iter: 65 loss: 1.07258984e-05
Iter: 66 loss: 1.0429043e-05
Iter: 67 loss: 1.35651026e-05
Iter: 68 loss: 1.04209785e-05
Iter: 69 loss: 1.02228514e-05
Iter: 70 loss: 1.0178821e-05
Iter: 71 loss: 1.00496827e-05
Iter: 72 loss: 9.79036486e-06
Iter: 73 loss: 1.30334665e-05
Iter: 74 loss: 9.78712524e-06
Iter: 75 loss: 9.51253e-06
Iter: 76 loss: 1.08186023e-05
Iter: 77 loss: 9.46221189e-06
Iter: 78 loss: 9.40076643e-06
Iter: 79 loss: 9.29769249e-06
Iter: 80 loss: 9.29747512e-06
Iter: 81 loss: 9.13510758e-06
Iter: 82 loss: 9.10579183e-06
Iter: 83 loss: 8.99547376e-06
Iter: 84 loss: 8.80285279e-06
Iter: 85 loss: 8.7975277e-06
Iter: 86 loss: 8.71346765e-06
Iter: 87 loss: 8.57288433e-06
Iter: 88 loss: 8.57268697e-06
Iter: 89 loss: 8.33431477e-06
Iter: 90 loss: 8.58542171e-06
Iter: 91 loss: 8.20251717e-06
Iter: 92 loss: 8.01760143e-06
Iter: 93 loss: 1.07346987e-05
Iter: 94 loss: 8.01715669e-06
Iter: 95 loss: 7.85953216e-06
Iter: 96 loss: 7.92210631e-06
Iter: 97 loss: 7.74979253e-06
Iter: 98 loss: 7.57304178e-06
Iter: 99 loss: 8.46724e-06
Iter: 100 loss: 7.54337907e-06
Iter: 101 loss: 7.44114914e-06
Iter: 102 loss: 7.53042696e-06
Iter: 103 loss: 7.38067456e-06
Iter: 104 loss: 7.2707785e-06
Iter: 105 loss: 7.27074257e-06
Iter: 106 loss: 7.18878755e-06
Iter: 107 loss: 8.32060323e-06
Iter: 108 loss: 7.18848878e-06
Iter: 109 loss: 7.15815213e-06
Iter: 110 loss: 7.08018524e-06
Iter: 111 loss: 7.72611929e-06
Iter: 112 loss: 7.06651781e-06
Iter: 113 loss: 6.95848348e-06
Iter: 114 loss: 7.08318339e-06
Iter: 115 loss: 6.90074512e-06
Iter: 116 loss: 6.85157784e-06
Iter: 117 loss: 6.83711096e-06
Iter: 118 loss: 6.78738888e-06
Iter: 119 loss: 6.75695082e-06
Iter: 120 loss: 6.73639215e-06
Iter: 121 loss: 6.65065909e-06
Iter: 122 loss: 6.47783509e-06
Iter: 123 loss: 9.72232283e-06
Iter: 124 loss: 6.47500656e-06
Iter: 125 loss: 6.33853142e-06
Iter: 126 loss: 6.33661557e-06
Iter: 127 loss: 6.25885468e-06
Iter: 128 loss: 6.44604e-06
Iter: 129 loss: 6.23018968e-06
Iter: 130 loss: 6.14080454e-06
Iter: 131 loss: 6.65227162e-06
Iter: 132 loss: 6.12901476e-06
Iter: 133 loss: 6.07897164e-06
Iter: 134 loss: 6.15068348e-06
Iter: 135 loss: 6.05410605e-06
Iter: 136 loss: 5.98706174e-06
Iter: 137 loss: 6.00359408e-06
Iter: 138 loss: 5.9374197e-06
Iter: 139 loss: 5.91851403e-06
Iter: 140 loss: 5.8857936e-06
Iter: 141 loss: 5.85674388e-06
Iter: 142 loss: 5.78795562e-06
Iter: 143 loss: 6.63167e-06
Iter: 144 loss: 5.78271556e-06
Iter: 145 loss: 5.73010902e-06
Iter: 146 loss: 5.67323e-06
Iter: 147 loss: 5.66431e-06
Iter: 148 loss: 5.57540716e-06
Iter: 149 loss: 6.93293805e-06
Iter: 150 loss: 5.57519616e-06
Iter: 151 loss: 5.51922631e-06
Iter: 152 loss: 6.15991621e-06
Iter: 153 loss: 5.51805169e-06
Iter: 154 loss: 5.49242895e-06
Iter: 155 loss: 5.45114744e-06
Iter: 156 loss: 5.45076909e-06
Iter: 157 loss: 5.3885592e-06
Iter: 158 loss: 5.51744688e-06
Iter: 159 loss: 5.36397783e-06
Iter: 160 loss: 5.30517082e-06
Iter: 161 loss: 5.43468923e-06
Iter: 162 loss: 5.28251712e-06
Iter: 163 loss: 5.21746642e-06
Iter: 164 loss: 5.55284487e-06
Iter: 165 loss: 5.20738513e-06
Iter: 166 loss: 5.15625561e-06
Iter: 167 loss: 5.3091635e-06
Iter: 168 loss: 5.14080148e-06
Iter: 169 loss: 5.08871562e-06
Iter: 170 loss: 5.18508568e-06
Iter: 171 loss: 5.06649e-06
Iter: 172 loss: 5.06276456e-06
Iter: 173 loss: 5.04113768e-06
Iter: 174 loss: 5.02001922e-06
Iter: 175 loss: 4.98367945e-06
Iter: 176 loss: 4.98370355e-06
Iter: 177 loss: 4.95339918e-06
Iter: 178 loss: 4.88911246e-06
Iter: 179 loss: 5.91053595e-06
Iter: 180 loss: 4.88696696e-06
Iter: 181 loss: 4.83337635e-06
Iter: 182 loss: 4.83270242e-06
Iter: 183 loss: 4.80656672e-06
Iter: 184 loss: 4.80636845e-06
Iter: 185 loss: 4.78524225e-06
Iter: 186 loss: 4.72627926e-06
Iter: 187 loss: 5.05799198e-06
Iter: 188 loss: 4.70863961e-06
Iter: 189 loss: 4.63828565e-06
Iter: 190 loss: 5.45124476e-06
Iter: 191 loss: 4.63668403e-06
Iter: 192 loss: 4.60534e-06
Iter: 193 loss: 4.6829955e-06
Iter: 194 loss: 4.59393323e-06
Iter: 195 loss: 4.56131556e-06
Iter: 196 loss: 4.63798187e-06
Iter: 197 loss: 4.54915698e-06
Iter: 198 loss: 4.5151678e-06
Iter: 199 loss: 4.6248233e-06
Iter: 200 loss: 4.50514653e-06
Iter: 201 loss: 4.47363527e-06
Iter: 202 loss: 4.55960708e-06
Iter: 203 loss: 4.46363447e-06
Iter: 204 loss: 4.45553e-06
Iter: 205 loss: 4.44965826e-06
Iter: 206 loss: 4.43615318e-06
Iter: 207 loss: 4.43110548e-06
Iter: 208 loss: 4.42349528e-06
Iter: 209 loss: 4.40876738e-06
Iter: 210 loss: 4.37058679e-06
Iter: 211 loss: 4.72069496e-06
Iter: 212 loss: 4.36540131e-06
Iter: 213 loss: 4.32558227e-06
Iter: 214 loss: 4.68173675e-06
Iter: 215 loss: 4.32393972e-06
Iter: 216 loss: 4.3014611e-06
Iter: 217 loss: 4.30120235e-06
Iter: 218 loss: 4.27843861e-06
Iter: 219 loss: 4.23938263e-06
Iter: 220 loss: 4.2394031e-06
Iter: 221 loss: 4.20929882e-06
Iter: 222 loss: 4.51656e-06
Iter: 223 loss: 4.20842298e-06
Iter: 224 loss: 4.18983927e-06
Iter: 225 loss: 4.18203081e-06
Iter: 226 loss: 4.17199408e-06
Iter: 227 loss: 4.13990347e-06
Iter: 228 loss: 4.31053832e-06
Iter: 229 loss: 4.13482894e-06
Iter: 230 loss: 4.1131766e-06
Iter: 231 loss: 4.2620677e-06
Iter: 232 loss: 4.11086603e-06
Iter: 233 loss: 4.09303948e-06
Iter: 234 loss: 4.0921168e-06
Iter: 235 loss: 4.07808784e-06
Iter: 236 loss: 4.06667914e-06
Iter: 237 loss: 4.06418576e-06
Iter: 238 loss: 4.04957382e-06
Iter: 239 loss: 4.05300671e-06
Iter: 240 loss: 4.03832064e-06
Iter: 241 loss: 4.02192836e-06
Iter: 242 loss: 3.98902466e-06
Iter: 243 loss: 4.60147339e-06
Iter: 244 loss: 3.98838e-06
Iter: 245 loss: 3.95987e-06
Iter: 246 loss: 4.08686e-06
Iter: 247 loss: 3.95451298e-06
Iter: 248 loss: 3.93744358e-06
Iter: 249 loss: 3.93762866e-06
Iter: 250 loss: 3.92043421e-06
Iter: 251 loss: 3.91501726e-06
Iter: 252 loss: 3.90474725e-06
Iter: 253 loss: 3.88667286e-06
Iter: 254 loss: 3.92989614e-06
Iter: 255 loss: 3.88006811e-06
Iter: 256 loss: 3.86090142e-06
Iter: 257 loss: 3.8568528e-06
Iter: 258 loss: 3.84421855e-06
Iter: 259 loss: 3.81342875e-06
Iter: 260 loss: 3.98244447e-06
Iter: 261 loss: 3.80886627e-06
Iter: 262 loss: 3.79443213e-06
Iter: 263 loss: 3.95937604e-06
Iter: 264 loss: 3.79428138e-06
Iter: 265 loss: 3.78130972e-06
Iter: 266 loss: 3.77588299e-06
Iter: 267 loss: 3.76903472e-06
Iter: 268 loss: 3.75845866e-06
Iter: 269 loss: 3.75771606e-06
Iter: 270 loss: 3.74644696e-06
Iter: 271 loss: 3.77612128e-06
Iter: 272 loss: 3.7426571e-06
Iter: 273 loss: 3.73507828e-06
Iter: 274 loss: 3.71788042e-06
Iter: 275 loss: 3.9513825e-06
Iter: 276 loss: 3.71666283e-06
Iter: 277 loss: 3.6975905e-06
Iter: 278 loss: 3.73716762e-06
Iter: 279 loss: 3.68985252e-06
Iter: 280 loss: 3.67708935e-06
Iter: 281 loss: 3.86840657e-06
Iter: 282 loss: 3.67706252e-06
Iter: 283 loss: 3.66330232e-06
Iter: 284 loss: 3.66868767e-06
Iter: 285 loss: 3.65376172e-06
Iter: 286 loss: 3.63921e-06
Iter: 287 loss: 3.64976722e-06
Iter: 288 loss: 3.63055415e-06
Iter: 289 loss: 3.61109869e-06
Iter: 290 loss: 3.61440925e-06
Iter: 291 loss: 3.59635328e-06
Iter: 292 loss: 3.57236399e-06
Iter: 293 loss: 3.79418771e-06
Iter: 294 loss: 3.57142108e-06
Iter: 295 loss: 3.56004057e-06
Iter: 296 loss: 3.61237107e-06
Iter: 297 loss: 3.55780958e-06
Iter: 298 loss: 3.5438668e-06
Iter: 299 loss: 3.54238728e-06
Iter: 300 loss: 3.53201017e-06
Iter: 301 loss: 3.52400684e-06
Iter: 302 loss: 3.52271422e-06
Iter: 303 loss: 3.51420067e-06
Iter: 304 loss: 3.54933331e-06
Iter: 305 loss: 3.51219933e-06
Iter: 306 loss: 3.50713208e-06
Iter: 307 loss: 3.49487777e-06
Iter: 308 loss: 3.65810638e-06
Iter: 309 loss: 3.49432548e-06
Iter: 310 loss: 3.48135382e-06
Iter: 311 loss: 3.50252e-06
Iter: 312 loss: 3.4754928e-06
Iter: 313 loss: 3.4652885e-06
Iter: 314 loss: 3.55015027e-06
Iter: 315 loss: 3.46421189e-06
Iter: 316 loss: 3.45195667e-06
Iter: 317 loss: 3.47091145e-06
Iter: 318 loss: 3.44605678e-06
Iter: 319 loss: 3.43495731e-06
Iter: 320 loss: 3.43791157e-06
Iter: 321 loss: 3.42718567e-06
Iter: 322 loss: 3.41185751e-06
Iter: 323 loss: 3.42282624e-06
Iter: 324 loss: 3.4025129e-06
Iter: 325 loss: 3.38769246e-06
Iter: 326 loss: 3.55615612e-06
Iter: 327 loss: 3.38739892e-06
Iter: 328 loss: 3.37931874e-06
Iter: 329 loss: 3.39146095e-06
Iter: 330 loss: 3.37521578e-06
Iter: 331 loss: 3.3618785e-06
Iter: 332 loss: 3.39338067e-06
Iter: 333 loss: 3.35723325e-06
Iter: 334 loss: 3.35115828e-06
Iter: 335 loss: 3.35083223e-06
Iter: 336 loss: 3.34567949e-06
Iter: 337 loss: 3.3712854e-06
Iter: 338 loss: 3.34477318e-06
Iter: 339 loss: 3.34085053e-06
Iter: 340 loss: 3.33203889e-06
Iter: 341 loss: 3.41714826e-06
Iter: 342 loss: 3.33069602e-06
Iter: 343 loss: 3.31882416e-06
Iter: 344 loss: 3.33233629e-06
Iter: 345 loss: 3.31275442e-06
Iter: 346 loss: 3.30326088e-06
Iter: 347 loss: 3.3993972e-06
Iter: 348 loss: 3.30315379e-06
Iter: 349 loss: 3.29341424e-06
Iter: 350 loss: 3.33067783e-06
Iter: 351 loss: 3.29111913e-06
Iter: 352 loss: 3.28446777e-06
Iter: 353 loss: 3.28325359e-06
Iter: 354 loss: 3.278642e-06
Iter: 355 loss: 3.2696355e-06
Iter: 356 loss: 3.27709404e-06
Iter: 357 loss: 3.26394274e-06
Iter: 358 loss: 3.2536168e-06
Iter: 359 loss: 3.32902732e-06
Iter: 360 loss: 3.25263045e-06
Iter: 361 loss: 3.24469715e-06
Iter: 362 loss: 3.25151859e-06
Iter: 363 loss: 3.23984273e-06
Iter: 364 loss: 3.22766846e-06
Iter: 365 loss: 3.26819941e-06
Iter: 366 loss: 3.22439337e-06
Iter: 367 loss: 3.21867878e-06
Iter: 368 loss: 3.21853577e-06
Iter: 369 loss: 3.21413381e-06
Iter: 370 loss: 3.24497887e-06
Iter: 371 loss: 3.21378911e-06
Iter: 372 loss: 3.21090056e-06
Iter: 373 loss: 3.20367735e-06
Iter: 374 loss: 3.28882334e-06
Iter: 375 loss: 3.20327399e-06
Iter: 376 loss: 3.19465812e-06
Iter: 377 loss: 3.19581932e-06
Iter: 378 loss: 3.1880561e-06
Iter: 379 loss: 3.1809318e-06
Iter: 380 loss: 3.26408826e-06
Iter: 381 loss: 3.18079037e-06
Iter: 382 loss: 3.17423564e-06
Iter: 383 loss: 3.20856452e-06
Iter: 384 loss: 3.17286572e-06
Iter: 385 loss: 3.16778051e-06
Iter: 386 loss: 3.16523892e-06
Iter: 387 loss: 3.16294359e-06
Iter: 388 loss: 3.15528769e-06
Iter: 389 loss: 3.15534407e-06
Iter: 390 loss: 3.14920817e-06
Iter: 391 loss: 3.13760756e-06
Iter: 392 loss: 3.19757646e-06
Iter: 393 loss: 3.13566579e-06
Iter: 394 loss: 3.1265663e-06
Iter: 395 loss: 3.15231387e-06
Iter: 396 loss: 3.12368138e-06
Iter: 397 loss: 3.11290432e-06
Iter: 398 loss: 3.15611828e-06
Iter: 399 loss: 3.11069743e-06
Iter: 400 loss: 3.10574796e-06
Iter: 401 loss: 3.18275715e-06
Iter: 402 loss: 3.10537098e-06
Iter: 403 loss: 3.10186761e-06
Iter: 404 loss: 3.14243903e-06
Iter: 405 loss: 3.10165206e-06
Iter: 406 loss: 3.09978032e-06
Iter: 407 loss: 3.0938877e-06
Iter: 408 loss: 3.12771613e-06
Iter: 409 loss: 3.09272218e-06
Iter: 410 loss: 3.08308381e-06
Iter: 411 loss: 3.08234553e-06
Iter: 412 loss: 3.07548817e-06
Iter: 413 loss: 3.06846209e-06
Iter: 414 loss: 3.16994237e-06
Iter: 415 loss: 3.06846187e-06
Iter: 416 loss: 3.06223819e-06
Iter: 417 loss: 3.09852203e-06
Iter: 418 loss: 3.06147172e-06
Iter: 419 loss: 3.05618732e-06
Iter: 420 loss: 3.05093317e-06
Iter: 421 loss: 3.05003232e-06
Iter: 422 loss: 3.04149057e-06
Iter: 423 loss: 3.04315972e-06
Iter: 424 loss: 3.03469278e-06
Iter: 425 loss: 3.02138233e-06
Iter: 426 loss: 3.08692415e-06
Iter: 427 loss: 3.01905e-06
Iter: 428 loss: 3.00935471e-06
Iter: 429 loss: 3.05856929e-06
Iter: 430 loss: 3.0077374e-06
Iter: 431 loss: 2.99872045e-06
Iter: 432 loss: 3.03548541e-06
Iter: 433 loss: 2.9967623e-06
Iter: 434 loss: 2.99207159e-06
Iter: 435 loss: 2.99200724e-06
Iter: 436 loss: 2.98887244e-06
Iter: 437 loss: 3.01954105e-06
Iter: 438 loss: 2.98872328e-06
Iter: 439 loss: 2.98639134e-06
Iter: 440 loss: 2.98026953e-06
Iter: 441 loss: 3.01961586e-06
Iter: 442 loss: 2.97874271e-06
Iter: 443 loss: 2.96911935e-06
Iter: 444 loss: 2.96970575e-06
Iter: 445 loss: 2.96171629e-06
Iter: 446 loss: 2.95452492e-06
Iter: 447 loss: 3.02929811e-06
Iter: 448 loss: 2.95413247e-06
Iter: 449 loss: 2.94810411e-06
Iter: 450 loss: 2.99190515e-06
Iter: 451 loss: 2.94739402e-06
Iter: 452 loss: 2.94204483e-06
Iter: 453 loss: 2.93452899e-06
Iter: 454 loss: 2.93413586e-06
Iter: 455 loss: 2.92442087e-06
Iter: 456 loss: 2.92950244e-06
Iter: 457 loss: 2.91820675e-06
Iter: 458 loss: 2.90431376e-06
Iter: 459 loss: 2.96457392e-06
Iter: 460 loss: 2.90155413e-06
Iter: 461 loss: 2.89203717e-06
Iter: 462 loss: 2.95608606e-06
Iter: 463 loss: 2.89125e-06
Iter: 464 loss: 2.88364618e-06
Iter: 465 loss: 2.92363234e-06
Iter: 466 loss: 2.88221759e-06
Iter: 467 loss: 2.87805801e-06
Iter: 468 loss: 2.92347977e-06
Iter: 469 loss: 2.87793864e-06
Iter: 470 loss: 2.87494913e-06
Iter: 471 loss: 2.9112241e-06
Iter: 472 loss: 2.87489252e-06
Iter: 473 loss: 2.87312696e-06
Iter: 474 loss: 2.86786644e-06
Iter: 475 loss: 2.89720765e-06
Iter: 476 loss: 2.86638283e-06
Iter: 477 loss: 2.85786496e-06
Iter: 478 loss: 2.85625083e-06
Iter: 479 loss: 2.85029682e-06
Iter: 480 loss: 2.84302905e-06
Iter: 481 loss: 2.9285452e-06
Iter: 482 loss: 2.84303883e-06
Iter: 483 loss: 2.83808708e-06
Iter: 484 loss: 2.88452384e-06
Iter: 485 loss: 2.83794839e-06
Iter: 486 loss: 2.83268855e-06
Iter: 487 loss: 2.82285077e-06
Iter: 488 loss: 3.02858098e-06
Iter: 489 loss: 2.8228169e-06
Iter: 490 loss: 2.81258281e-06
Iter: 491 loss: 2.84912949e-06
Iter: 492 loss: 2.80982795e-06
Iter: 493 loss: 2.79912774e-06
Iter: 494 loss: 2.81450048e-06
Iter: 495 loss: 2.79403275e-06
Iter: 496 loss: 2.78502694e-06
Iter: 497 loss: 2.91463e-06
Iter: 498 loss: 2.7850424e-06
Iter: 499 loss: 2.78005814e-06
Iter: 500 loss: 2.79819596e-06
Iter: 501 loss: 2.77860568e-06
Iter: 502 loss: 2.7747767e-06
Iter: 503 loss: 2.80989843e-06
Iter: 504 loss: 2.77456456e-06
Iter: 505 loss: 2.77204981e-06
Iter: 506 loss: 2.79402684e-06
Iter: 507 loss: 2.77199024e-06
Iter: 508 loss: 2.76977244e-06
Iter: 509 loss: 2.76447486e-06
Iter: 510 loss: 2.82654855e-06
Iter: 511 loss: 2.76391938e-06
Iter: 512 loss: 2.75708931e-06
Iter: 513 loss: 2.75187745e-06
Iter: 514 loss: 2.74955096e-06
Iter: 515 loss: 2.74294189e-06
Iter: 516 loss: 2.83357258e-06
Iter: 517 loss: 2.74289141e-06
Iter: 518 loss: 2.73863088e-06
Iter: 519 loss: 2.77648905e-06
Iter: 520 loss: 2.73827504e-06
Iter: 521 loss: 2.73346677e-06
Iter: 522 loss: 2.72423449e-06
Iter: 523 loss: 2.92933328e-06
Iter: 524 loss: 2.72426473e-06
Iter: 525 loss: 2.71566205e-06
Iter: 526 loss: 2.74699914e-06
Iter: 527 loss: 2.71373642e-06
Iter: 528 loss: 2.70453211e-06
Iter: 529 loss: 2.71336876e-06
Iter: 530 loss: 2.69948805e-06
Iter: 531 loss: 2.69169891e-06
Iter: 532 loss: 2.78362313e-06
Iter: 533 loss: 2.69160819e-06
Iter: 534 loss: 2.68681151e-06
Iter: 535 loss: 2.71518775e-06
Iter: 536 loss: 2.68617077e-06
Iter: 537 loss: 2.68257509e-06
Iter: 538 loss: 2.70794544e-06
Iter: 539 loss: 2.6822679e-06
Iter: 540 loss: 2.67976429e-06
Iter: 541 loss: 2.71346653e-06
Iter: 542 loss: 2.67990026e-06
Iter: 543 loss: 2.67785231e-06
Iter: 544 loss: 2.67341784e-06
Iter: 545 loss: 2.71773774e-06
Iter: 546 loss: 2.67295172e-06
Iter: 547 loss: 2.66623647e-06
Iter: 548 loss: 2.66463121e-06
Iter: 549 loss: 2.66060806e-06
Iter: 550 loss: 2.65514927e-06
Iter: 551 loss: 2.7134065e-06
Iter: 552 loss: 2.65490235e-06
Iter: 553 loss: 2.65104609e-06
Iter: 554 loss: 2.68261238e-06
Iter: 555 loss: 2.65077324e-06
Iter: 556 loss: 2.64646951e-06
Iter: 557 loss: 2.63829497e-06
Iter: 558 loss: 2.6384173e-06
Iter: 559 loss: 2.63144784e-06
Iter: 560 loss: 2.65981862e-06
Iter: 561 loss: 2.62954836e-06
Iter: 562 loss: 2.62233198e-06
Iter: 563 loss: 2.62464437e-06
Iter: 564 loss: 2.61694186e-06
Iter: 565 loss: 2.61041782e-06
Iter: 566 loss: 2.61050445e-06
Iter: 567 loss: 2.60646448e-06
Iter: 568 loss: 2.61615787e-06
Iter: 569 loss: 2.60487013e-06
Iter: 570 loss: 2.60123966e-06
Iter: 571 loss: 2.64869823e-06
Iter: 572 loss: 2.60139268e-06
Iter: 573 loss: 2.59927356e-06
Iter: 574 loss: 2.62295248e-06
Iter: 575 loss: 2.59918625e-06
Iter: 576 loss: 2.59762692e-06
Iter: 577 loss: 2.59382e-06
Iter: 578 loss: 2.63785682e-06
Iter: 579 loss: 2.59323429e-06
Iter: 580 loss: 2.588087e-06
Iter: 581 loss: 2.58882483e-06
Iter: 582 loss: 2.58430646e-06
Iter: 583 loss: 2.57996771e-06
Iter: 584 loss: 2.61034643e-06
Iter: 585 loss: 2.57956754e-06
Iter: 586 loss: 2.57596889e-06
Iter: 587 loss: 2.59482408e-06
Iter: 588 loss: 2.57540432e-06
Iter: 589 loss: 2.57034344e-06
Iter: 590 loss: 2.56560816e-06
Iter: 591 loss: 2.56444218e-06
Iter: 592 loss: 2.5592708e-06
Iter: 593 loss: 2.573e-06
Iter: 594 loss: 2.55735449e-06
Iter: 595 loss: 2.55143573e-06
Iter: 596 loss: 2.55480768e-06
Iter: 597 loss: 2.54732731e-06
Iter: 598 loss: 2.54185625e-06
Iter: 599 loss: 2.60795468e-06
Iter: 600 loss: 2.54197948e-06
Iter: 601 loss: 2.53799908e-06
Iter: 602 loss: 2.55435089e-06
Iter: 603 loss: 2.5370955e-06
Iter: 604 loss: 2.53406847e-06
Iter: 605 loss: 2.56287694e-06
Iter: 606 loss: 2.53393546e-06
Iter: 607 loss: 2.5322795e-06
Iter: 608 loss: 2.55662053e-06
Iter: 609 loss: 2.53218491e-06
Iter: 610 loss: 2.531051e-06
Iter: 611 loss: 2.52755808e-06
Iter: 612 loss: 2.55571672e-06
Iter: 613 loss: 2.52701966e-06
Iter: 614 loss: 2.52252312e-06
Iter: 615 loss: 2.52483051e-06
Iter: 616 loss: 2.51944721e-06
Iter: 617 loss: 2.51546817e-06
Iter: 618 loss: 2.53663666e-06
Iter: 619 loss: 2.51480924e-06
Iter: 620 loss: 2.51117058e-06
Iter: 621 loss: 2.53283724e-06
Iter: 622 loss: 2.51091933e-06
Iter: 623 loss: 2.50640073e-06
Iter: 624 loss: 2.5039908e-06
Iter: 625 loss: 2.5018935e-06
Iter: 626 loss: 2.49772802e-06
Iter: 627 loss: 2.51298184e-06
Iter: 628 loss: 2.49672735e-06
Iter: 629 loss: 2.49272466e-06
Iter: 630 loss: 2.49221421e-06
Iter: 631 loss: 2.4893734e-06
Iter: 632 loss: 2.4846006e-06
Iter: 633 loss: 2.54221231e-06
Iter: 634 loss: 2.48444894e-06
Iter: 635 loss: 2.48119818e-06
Iter: 636 loss: 2.49227787e-06
Iter: 637 loss: 2.48030119e-06
Iter: 638 loss: 2.47775506e-06
Iter: 639 loss: 2.50410358e-06
Iter: 640 loss: 2.47761659e-06
Iter: 641 loss: 2.47565595e-06
Iter: 642 loss: 2.49475806e-06
Iter: 643 loss: 2.47571097e-06
Iter: 644 loss: 2.47432467e-06
Iter: 645 loss: 2.4716644e-06
Iter: 646 loss: 2.5283075e-06
Iter: 647 loss: 2.47161574e-06
Iter: 648 loss: 2.46889203e-06
Iter: 649 loss: 2.46764102e-06
Iter: 650 loss: 2.46605032e-06
Iter: 651 loss: 2.4622725e-06
Iter: 652 loss: 2.4828164e-06
Iter: 653 loss: 2.46179616e-06
Iter: 654 loss: 2.4591e-06
Iter: 655 loss: 2.47359435e-06
Iter: 656 loss: 2.45819456e-06
Iter: 657 loss: 2.45439765e-06
Iter: 658 loss: 2.45461229e-06
Iter: 659 loss: 2.45149749e-06
Iter: 660 loss: 2.44830744e-06
Iter: 661 loss: 2.45747879e-06
Iter: 662 loss: 2.44735566e-06
Iter: 663 loss: 2.44417743e-06
Iter: 664 loss: 2.44262765e-06
Iter: 665 loss: 2.44118837e-06
Iter: 666 loss: 2.43634213e-06
Iter: 667 loss: 2.47220214e-06
Iter: 668 loss: 2.43570958e-06
Iter: 669 loss: 2.43225509e-06
Iter: 670 loss: 2.46299965e-06
Iter: 671 loss: 2.4320309e-06
Iter: 672 loss: 2.42993019e-06
Iter: 673 loss: 2.44033481e-06
Iter: 674 loss: 2.4295407e-06
Iter: 675 loss: 2.42810597e-06
Iter: 676 loss: 2.45043361e-06
Iter: 677 loss: 2.42816895e-06
Iter: 678 loss: 2.42696797e-06
Iter: 679 loss: 2.42486158e-06
Iter: 680 loss: 2.42484793e-06
Iter: 681 loss: 2.42266651e-06
Iter: 682 loss: 2.42099873e-06
Iter: 683 loss: 2.42011333e-06
Iter: 684 loss: 2.41716634e-06
Iter: 685 loss: 2.43377553e-06
Iter: 686 loss: 2.41642147e-06
Iter: 687 loss: 2.4140063e-06
Iter: 688 loss: 2.42586611e-06
Iter: 689 loss: 2.41352336e-06
Iter: 690 loss: 2.41024418e-06
Iter: 691 loss: 2.41449902e-06
Iter: 692 loss: 2.40849295e-06
Iter: 693 loss: 2.40632926e-06
Iter: 694 loss: 2.41005091e-06
Iter: 695 loss: 2.40508189e-06
Iter: 696 loss: 2.4023991e-06
Iter: 697 loss: 2.39852557e-06
Iter: 698 loss: 2.39847418e-06
Iter: 699 loss: 2.39334668e-06
Iter: 700 loss: 2.44937678e-06
Iter: 701 loss: 2.39311657e-06
Iter: 702 loss: 2.39015412e-06
Iter: 703 loss: 2.41666271e-06
Iter: 704 loss: 2.39013116e-06
Iter: 705 loss: 2.38799157e-06
Iter: 706 loss: 2.39948531e-06
Iter: 707 loss: 2.3875798e-06
Iter: 708 loss: 2.38633675e-06
Iter: 709 loss: 2.40392774e-06
Iter: 710 loss: 2.38632128e-06
Iter: 711 loss: 2.38512143e-06
Iter: 712 loss: 2.38338657e-06
Iter: 713 loss: 2.383229e-06
Iter: 714 loss: 2.3811192e-06
Iter: 715 loss: 2.37935319e-06
Iter: 716 loss: 2.37866561e-06
Iter: 717 loss: 2.37547738e-06
Iter: 718 loss: 2.39309475e-06
Iter: 719 loss: 2.37502627e-06
Iter: 720 loss: 2.37227277e-06
Iter: 721 loss: 2.38093e-06
Iter: 722 loss: 2.37188442e-06
Iter: 723 loss: 2.36820188e-06
Iter: 724 loss: 2.37744257e-06
Iter: 725 loss: 2.36684173e-06
Iter: 726 loss: 2.36504411e-06
Iter: 727 loss: 2.36512369e-06
Iter: 728 loss: 2.36359938e-06
Iter: 729 loss: 2.36027086e-06
Iter: 730 loss: 2.356403e-06
Iter: 731 loss: 2.3556604e-06
Iter: 732 loss: 2.35103334e-06
Iter: 733 loss: 2.41200269e-06
Iter: 734 loss: 2.35091102e-06
Iter: 735 loss: 2.34804793e-06
Iter: 736 loss: 2.3705004e-06
Iter: 737 loss: 2.34784056e-06
Iter: 738 loss: 2.3456264e-06
Iter: 739 loss: 2.35680545e-06
Iter: 740 loss: 2.34513845e-06
Iter: 741 loss: 2.34384652e-06
Iter: 742 loss: 2.3645398e-06
Iter: 743 loss: 2.34379831e-06
Iter: 744 loss: 2.34252434e-06
Iter: 745 loss: 2.34048457e-06
Iter: 746 loss: 2.3404973e-06
Iter: 747 loss: 2.33805054e-06
Iter: 748 loss: 2.33638275e-06
Iter: 749 loss: 2.33560377e-06
Iter: 750 loss: 2.3322757e-06
Iter: 751 loss: 2.34904383e-06
Iter: 752 loss: 2.33175933e-06
Iter: 753 loss: 2.32875391e-06
Iter: 754 loss: 2.34099161e-06
Iter: 755 loss: 2.3281018e-06
Iter: 756 loss: 2.32483126e-06
Iter: 757 loss: 2.33861419e-06
Iter: 758 loss: 2.32406e-06
Iter: 759 loss: 2.32245634e-06
Iter: 760 loss: 2.32224488e-06
Iter: 761 loss: 2.32117827e-06
Iter: 762 loss: 2.31840886e-06
Iter: 763 loss: 2.31495687e-06
Iter: 764 loss: 2.31470153e-06
Iter: 765 loss: 2.31102422e-06
Iter: 766 loss: 2.36695269e-06
Iter: 767 loss: 2.31099602e-06
Iter: 768 loss: 2.30896057e-06
Iter: 769 loss: 2.31905415e-06
Iter: 770 loss: 2.30845626e-06
Iter: 771 loss: 2.30631895e-06
Iter: 772 loss: 2.3187622e-06
Iter: 773 loss: 2.30609271e-06
Iter: 774 loss: 2.30484966e-06
Iter: 775 loss: 2.31973718e-06
Iter: 776 loss: 2.30490946e-06
Iter: 777 loss: 2.30371415e-06
Iter: 778 loss: 2.30214027e-06
Iter: 779 loss: 2.30218575e-06
Iter: 780 loss: 2.30026899e-06
Iter: 781 loss: 2.29799093e-06
Iter: 782 loss: 2.29766465e-06
Iter: 783 loss: 2.29427155e-06
Iter: 784 loss: 2.30993373e-06
Iter: 785 loss: 2.29376451e-06
Iter: 786 loss: 2.29089619e-06
Iter: 787 loss: 2.31210447e-06
Iter: 788 loss: 2.29061447e-06
Iter: 789 loss: 2.28793465e-06
Iter: 790 loss: 2.30127034e-06
Iter: 791 loss: 2.28773888e-06
Iter: 792 loss: 2.2864308e-06
Iter: 793 loss: 2.28547742e-06
Iter: 794 loss: 2.28498857e-06
Iter: 795 loss: 2.28239605e-06
Iter: 796 loss: 2.27995315e-06
Iter: 797 loss: 2.27923283e-06
Iter: 798 loss: 2.27636701e-06
Iter: 799 loss: 2.32360344e-06
Iter: 800 loss: 2.27629789e-06
Iter: 801 loss: 2.27423425e-06
Iter: 802 loss: 2.28622548e-06
Iter: 803 loss: 2.27397072e-06
Iter: 804 loss: 2.27199939e-06
Iter: 805 loss: 2.2801928e-06
Iter: 806 loss: 2.27183727e-06
Iter: 807 loss: 2.27072496e-06
Iter: 808 loss: 2.27065402e-06
Iter: 809 loss: 2.26956945e-06
Iter: 810 loss: 2.26788188e-06
Iter: 811 loss: 2.26786756e-06
Iter: 812 loss: 2.2659558e-06
Iter: 813 loss: 2.26327597e-06
Iter: 814 loss: 2.26342e-06
Iter: 815 loss: 2.25971326e-06
Iter: 816 loss: 2.27199234e-06
Iter: 817 loss: 2.25885378e-06
Iter: 818 loss: 2.25630606e-06
Iter: 819 loss: 2.28176714e-06
Iter: 820 loss: 2.25612575e-06
Iter: 821 loss: 2.25374288e-06
Iter: 822 loss: 2.26560769e-06
Iter: 823 loss: 2.25360736e-06
Iter: 824 loss: 2.25230519e-06
Iter: 825 loss: 2.2512429e-06
Iter: 826 loss: 2.25097074e-06
Iter: 827 loss: 2.24794417e-06
Iter: 828 loss: 2.24631776e-06
Iter: 829 loss: 2.24501855e-06
Iter: 830 loss: 2.24226324e-06
Iter: 831 loss: 2.28046383e-06
Iter: 832 loss: 2.24205519e-06
Iter: 833 loss: 2.23998222e-06
Iter: 834 loss: 2.24818518e-06
Iter: 835 loss: 2.23941333e-06
Iter: 836 loss: 2.23707e-06
Iter: 837 loss: 2.25064264e-06
Iter: 838 loss: 2.23683082e-06
Iter: 839 loss: 2.23521056e-06
Iter: 840 loss: 2.25295116e-06
Iter: 841 loss: 2.23514166e-06
Iter: 842 loss: 2.23379948e-06
Iter: 843 loss: 2.23258166e-06
Iter: 844 loss: 2.2323411e-06
Iter: 845 loss: 2.23046982e-06
Iter: 846 loss: 2.22718654e-06
Iter: 847 loss: 2.22721042e-06
Iter: 848 loss: 2.22312815e-06
Iter: 849 loss: 2.24346604e-06
Iter: 850 loss: 2.22232029e-06
Iter: 851 loss: 2.21944e-06
Iter: 852 loss: 2.24490509e-06
Iter: 853 loss: 2.21940832e-06
Iter: 854 loss: 2.21708751e-06
Iter: 855 loss: 2.23458392e-06
Iter: 856 loss: 2.21688151e-06
Iter: 857 loss: 2.21557684e-06
Iter: 858 loss: 2.21346454e-06
Iter: 859 loss: 2.21361779e-06
Iter: 860 loss: 2.21020309e-06
Iter: 861 loss: 2.21148525e-06
Iter: 862 loss: 2.20803258e-06
Iter: 863 loss: 2.20536e-06
Iter: 864 loss: 2.24009045e-06
Iter: 865 loss: 2.20541233e-06
Iter: 866 loss: 2.20366042e-06
Iter: 867 loss: 2.20883931e-06
Iter: 868 loss: 2.20329821e-06
Iter: 869 loss: 2.20135121e-06
Iter: 870 loss: 2.20918218e-06
Iter: 871 loss: 2.20092807e-06
Iter: 872 loss: 2.19968456e-06
Iter: 873 loss: 2.1997073e-06
Iter: 874 loss: 2.19870526e-06
Iter: 875 loss: 2.19805452e-06
Iter: 876 loss: 2.19765798e-06
Iter: 877 loss: 2.1964463e-06
Iter: 878 loss: 2.19426715e-06
Iter: 879 loss: 2.1943456e-06
Iter: 880 loss: 2.19168987e-06
Iter: 881 loss: 2.20493348e-06
Iter: 882 loss: 2.19162e-06
Iter: 883 loss: 2.18996638e-06
Iter: 884 loss: 2.20082734e-06
Iter: 885 loss: 2.1897763e-06
Iter: 886 loss: 2.18816035e-06
Iter: 887 loss: 2.19632716e-06
Iter: 888 loss: 2.18789182e-06
Iter: 889 loss: 2.1869987e-06
Iter: 890 loss: 2.18624928e-06
Iter: 891 loss: 2.18596597e-06
Iter: 892 loss: 2.18423202e-06
Iter: 893 loss: 2.18417199e-06
Iter: 894 loss: 2.18272203e-06
Iter: 895 loss: 2.18122341e-06
Iter: 896 loss: 2.18115542e-06
Iter: 897 loss: 2.18002651e-06
Iter: 898 loss: 2.18038076e-06
Iter: 899 loss: 2.17930938e-06
Iter: 900 loss: 2.17746879e-06
Iter: 901 loss: 2.19229969e-06
Iter: 902 loss: 2.17727643e-06
Iter: 903 loss: 2.1765818e-06
Iter: 904 loss: 2.18702417e-06
Iter: 905 loss: 2.17651177e-06
Iter: 906 loss: 2.17543788e-06
Iter: 907 loss: 2.1753151e-06
Iter: 908 loss: 2.17469142e-06
Iter: 909 loss: 2.17368233e-06
Iter: 910 loss: 2.17191041e-06
Iter: 911 loss: 2.17190563e-06
Iter: 912 loss: 2.16989929e-06
Iter: 913 loss: 2.17783122e-06
Iter: 914 loss: 2.16957051e-06
Iter: 915 loss: 2.16786839e-06
Iter: 916 loss: 2.17706338e-06
Iter: 917 loss: 2.16748776e-06
Iter: 918 loss: 2.16594526e-06
Iter: 919 loss: 2.1822425e-06
Iter: 920 loss: 2.16586614e-06
Iter: 921 loss: 2.16482749e-06
Iter: 922 loss: 2.16362037e-06
Iter: 923 loss: 2.1635251e-06
Iter: 924 loss: 2.16144622e-06
Iter: 925 loss: 2.160554e-06
Iter: 926 loss: 2.15934824e-06
Iter: 927 loss: 2.15717273e-06
Iter: 928 loss: 2.17778552e-06
Iter: 929 loss: 2.15709429e-06
Iter: 930 loss: 2.15508771e-06
Iter: 931 loss: 2.15855835e-06
Iter: 932 loss: 2.15418231e-06
Iter: 933 loss: 2.15188334e-06
Iter: 934 loss: 2.1736746e-06
Iter: 935 loss: 2.15164391e-06
Iter: 936 loss: 2.15054274e-06
Iter: 937 loss: 2.16676494e-06
Iter: 938 loss: 2.15047498e-06
Iter: 939 loss: 2.14952661e-06
Iter: 940 loss: 2.14857573e-06
Iter: 941 loss: 2.14828538e-06
Iter: 942 loss: 2.14676766e-06
Iter: 943 loss: 2.14490956e-06
Iter: 944 loss: 2.14461306e-06
Iter: 945 loss: 2.14248735e-06
Iter: 946 loss: 2.15016325e-06
Iter: 947 loss: 2.14178885e-06
Iter: 948 loss: 2.1396645e-06
Iter: 949 loss: 2.14987813e-06
Iter: 950 loss: 2.13928388e-06
Iter: 951 loss: 2.1374176e-06
Iter: 952 loss: 2.15767932e-06
Iter: 953 loss: 2.13736826e-06
Iter: 954 loss: 2.13615726e-06
Iter: 955 loss: 2.13461612e-06
Iter: 956 loss: 2.13455428e-06
Iter: 957 loss: 2.1320825e-06
Iter: 958 loss: 2.13227531e-06
Iter: 959 loss: 2.13012072e-06
Iter: 960 loss: 2.12800774e-06
Iter: 961 loss: 2.14792522e-06
Iter: 962 loss: 2.12789746e-06
Iter: 963 loss: 2.12616055e-06
Iter: 964 loss: 2.12812984e-06
Iter: 965 loss: 2.1250944e-06
Iter: 966 loss: 2.12309737e-06
Iter: 967 loss: 2.15076807e-06
Iter: 968 loss: 2.12301416e-06
Iter: 969 loss: 2.1221615e-06
Iter: 970 loss: 2.13370458e-06
Iter: 971 loss: 2.12227542e-06
Iter: 972 loss: 2.12141663e-06
Iter: 973 loss: 2.12098143e-06
Iter: 974 loss: 2.12059126e-06
Iter: 975 loss: 2.11948782e-06
Iter: 976 loss: 2.11799897e-06
Iter: 977 loss: 2.11792144e-06
Iter: 978 loss: 2.11602355e-06
Iter: 979 loss: 2.11965471e-06
Iter: 980 loss: 2.11524639e-06
Iter: 981 loss: 2.11303677e-06
Iter: 982 loss: 2.1234805e-06
Iter: 983 loss: 2.11267343e-06
Iter: 984 loss: 2.11094584e-06
Iter: 985 loss: 2.13343628e-06
Iter: 986 loss: 2.11094e-06
Iter: 987 loss: 2.1099936e-06
Iter: 988 loss: 2.10865846e-06
Iter: 989 loss: 2.10857411e-06
Iter: 990 loss: 2.10619464e-06
Iter: 991 loss: 2.10743497e-06
Iter: 992 loss: 2.1046867e-06
Iter: 993 loss: 2.10267058e-06
Iter: 994 loss: 2.11135693e-06
Iter: 995 loss: 2.10224607e-06
Iter: 996 loss: 2.09978543e-06
Iter: 997 loss: 2.10667758e-06
Iter: 998 loss: 2.09885729e-06
Iter: 999 loss: 2.09672953e-06
Iter: 1000 loss: 2.11913903e-06
Iter: 1001 loss: 2.0967957e-06
Iter: 1002 loss: 2.09561085e-06
Iter: 1003 loss: 2.11166343e-06
Iter: 1004 loss: 2.09566633e-06
Iter: 1005 loss: 2.09487507e-06
Iter: 1006 loss: 2.09433119e-06
Iter: 1007 loss: 2.09412406e-06
Iter: 1008 loss: 2.09276777e-06
Iter: 1009 loss: 2.09076893e-06
Iter: 1010 loss: 2.09068867e-06
Iter: 1011 loss: 2.08826941e-06
Iter: 1012 loss: 2.09387417e-06
Iter: 1013 loss: 2.08735742e-06
Iter: 1014 loss: 2.08505071e-06
Iter: 1015 loss: 2.09621362e-06
Iter: 1016 loss: 2.08446249e-06
Iter: 1017 loss: 2.08259826e-06
Iter: 1018 loss: 2.11024826e-06
Iter: 1019 loss: 2.08253209e-06
Iter: 1020 loss: 2.08135361e-06
Iter: 1021 loss: 2.07993071e-06
Iter: 1022 loss: 2.07984817e-06
Iter: 1023 loss: 2.07733319e-06
Iter: 1024 loss: 2.07842231e-06
Iter: 1025 loss: 2.07573657e-06
Iter: 1026 loss: 2.07329754e-06
Iter: 1027 loss: 2.08822121e-06
Iter: 1028 loss: 2.07293124e-06
Iter: 1029 loss: 2.07066887e-06
Iter: 1030 loss: 2.07472385e-06
Iter: 1031 loss: 2.0694406e-06
Iter: 1032 loss: 2.06748814e-06
Iter: 1033 loss: 2.06723166e-06
Iter: 1034 loss: 2.06611185e-06
Iter: 1035 loss: 2.08064148e-06
Iter: 1036 loss: 2.0662128e-06
Iter: 1037 loss: 2.06563186e-06
Iter: 1038 loss: 2.06582035e-06
Iter: 1039 loss: 2.06523532e-06
Iter: 1040 loss: 2.06440109e-06
Iter: 1041 loss: 2.06301297e-06
Iter: 1042 loss: 2.08741631e-06
Iter: 1043 loss: 2.06292702e-06
Iter: 1044 loss: 2.06100458e-06
Iter: 1045 loss: 2.065442e-06
Iter: 1046 loss: 2.06021969e-06
Iter: 1047 loss: 2.05872675e-06
Iter: 1048 loss: 2.06528603e-06
Iter: 1049 loss: 2.05832112e-06
Iter: 1050 loss: 2.0570767e-06
Iter: 1051 loss: 2.07567109e-06
Iter: 1052 loss: 2.05703122e-06
Iter: 1053 loss: 2.05638071e-06
Iter: 1054 loss: 2.05533888e-06
Iter: 1055 loss: 2.05524316e-06
Iter: 1056 loss: 2.05348715e-06
Iter: 1057 loss: 2.05328047e-06
Iter: 1058 loss: 2.05215019e-06
Iter: 1059 loss: 2.04995149e-06
Iter: 1060 loss: 2.06308323e-06
Iter: 1061 loss: 2.04961179e-06
Iter: 1062 loss: 2.04794333e-06
Iter: 1063 loss: 2.04918342e-06
Iter: 1064 loss: 2.0467894e-06
Iter: 1065 loss: 2.04526623e-06
Iter: 1066 loss: 2.04519347e-06
Iter: 1067 loss: 2.04455728e-06
Iter: 1068 loss: 2.04444632e-06
Iter: 1069 loss: 2.04406524e-06
Iter: 1070 loss: 2.0440234e-06
Iter: 1071 loss: 2.04361368e-06
Iter: 1072 loss: 2.04277922e-06
Iter: 1073 loss: 2.04144521e-06
Iter: 1074 loss: 2.06880236e-06
Iter: 1075 loss: 2.04146545e-06
Iter: 1076 loss: 2.03941363e-06
Iter: 1077 loss: 2.04533535e-06
Iter: 1078 loss: 2.03889522e-06
Iter: 1079 loss: 2.03752052e-06
Iter: 1080 loss: 2.04111893e-06
Iter: 1081 loss: 2.03701234e-06
Iter: 1082 loss: 2.03574587e-06
Iter: 1083 loss: 2.03569471e-06
Iter: 1084 loss: 2.03477475e-06
Iter: 1085 loss: 2.03377704e-06
Iter: 1086 loss: 2.03356967e-06
Iter: 1087 loss: 2.03187346e-06
Iter: 1088 loss: 2.03229274e-06
Iter: 1089 loss: 2.03064269e-06
Iter: 1090 loss: 2.02848082e-06
Iter: 1091 loss: 2.04225762e-06
Iter: 1092 loss: 2.0283303e-06
Iter: 1093 loss: 2.02663978e-06
Iter: 1094 loss: 2.0251241e-06
Iter: 1095 loss: 2.02448086e-06
Iter: 1096 loss: 2.02368165e-06
Iter: 1097 loss: 2.02287811e-06
Iter: 1098 loss: 2.02201272e-06
Iter: 1099 loss: 2.03420063e-06
Iter: 1100 loss: 2.02210072e-06
Iter: 1101 loss: 2.02150136e-06
Iter: 1102 loss: 2.02116871e-06
Iter: 1103 loss: 2.02101069e-06
Iter: 1104 loss: 2.01997727e-06
Iter: 1105 loss: 2.01841249e-06
Iter: 1106 loss: 2.05451101e-06
Iter: 1107 loss: 2.01828198e-06
Iter: 1108 loss: 2.01628291e-06
Iter: 1109 loss: 2.02235583e-06
Iter: 1110 loss: 2.01577018e-06
Iter: 1111 loss: 2.01430066e-06
Iter: 1112 loss: 2.02091496e-06
Iter: 1113 loss: 2.01383182e-06
Iter: 1114 loss: 2.01289913e-06
Iter: 1115 loss: 2.0128582e-06
Iter: 1116 loss: 2.01200146e-06
Iter: 1117 loss: 2.01132161e-06
Iter: 1118 loss: 2.01100602e-06
Iter: 1119 loss: 2.00982481e-06
Iter: 1120 loss: 2.00945397e-06
Iter: 1121 loss: 2.00887507e-06
Iter: 1122 loss: 2.00734985e-06
Iter: 1123 loss: 2.01765488e-06
Iter: 1124 loss: 2.00719978e-06
Iter: 1125 loss: 2.00616182e-06
Iter: 1126 loss: 2.00673094e-06
Iter: 1127 loss: 2.00533327e-06
Iter: 1128 loss: 2.00440354e-06
Iter: 1129 loss: 2.00426689e-06
Iter: 1130 loss: 2.0039306e-06
Iter: 1131 loss: 2.00389081e-06
Iter: 1132 loss: 2.0035975e-06
Iter: 1133 loss: 2.00316799e-06
Iter: 1134 loss: 2.01284274e-06
Iter: 1135 loss: 2.00321165e-06
Iter: 1136 loss: 2.00242857e-06
Iter: 1137 loss: 2.0020052e-06
Iter: 1138 loss: 2.00166733e-06
Iter: 1139 loss: 2.00075738e-06
Iter: 1140 loss: 2.00215914e-06
Iter: 1141 loss: 2.0001271e-06
Iter: 1142 loss: 1.99930741e-06
Iter: 1143 loss: 2.00041563e-06
Iter: 1144 loss: 1.99872375e-06
Iter: 1145 loss: 1.997666e-06
Iter: 1146 loss: 2.00487602e-06
Iter: 1147 loss: 1.99750684e-06
Iter: 1148 loss: 1.99616e-06
Iter: 1149 loss: 1.99966667e-06
Iter: 1150 loss: 1.9957215e-06
Iter: 1151 loss: 1.99492729e-06
Iter: 1152 loss: 1.99350734e-06
Iter: 1153 loss: 2.02580622e-06
Iter: 1154 loss: 1.99355964e-06
Iter: 1155 loss: 1.991918e-06
Iter: 1156 loss: 2.00583463e-06
Iter: 1157 loss: 1.99178066e-06
Iter: 1158 loss: 1.99052192e-06
Iter: 1159 loss: 1.9896961e-06
Iter: 1160 loss: 1.98940347e-06
Iter: 1161 loss: 1.98777889e-06
Iter: 1162 loss: 2.01117609e-06
Iter: 1163 loss: 1.9877607e-06
Iter: 1164 loss: 1.9877707e-06
Iter: 1165 loss: 1.98739508e-06
Iter: 1166 loss: 1.98708449e-06
Iter: 1167 loss: 1.9865679e-06
Iter: 1168 loss: 1.98653834e-06
Iter: 1169 loss: 1.98602675e-06
Iter: 1170 loss: 1.98610633e-06
Iter: 1171 loss: 1.98558928e-06
Iter: 1172 loss: 1.98490193e-06
Iter: 1173 loss: 1.98672114e-06
Iter: 1174 loss: 1.98465068e-06
Iter: 1175 loss: 1.98419093e-06
Iter: 1176 loss: 1.98375028e-06
Iter: 1177 loss: 1.98369867e-06
Iter: 1178 loss: 1.98275256e-06
Iter: 1179 loss: 1.99031774e-06
Iter: 1180 loss: 1.98284533e-06
Iter: 1181 loss: 1.98203634e-06
Iter: 1182 loss: 1.98898329e-06
Iter: 1183 loss: 1.98211046e-06
Iter: 1184 loss: 1.9817885e-06
Iter: 1185 loss: 1.98105454e-06
Iter: 1186 loss: 1.98114162e-06
Iter: 1187 loss: 1.98050975e-06
Iter: 1188 loss: 1.98208681e-06
Iter: 1189 loss: 1.98031853e-06
Iter: 1190 loss: 1.97966415e-06
Iter: 1191 loss: 1.97926579e-06
Iter: 1192 loss: 1.97895224e-06
Iter: 1193 loss: 1.97765e-06
Iter: 1194 loss: 1.97726899e-06
Iter: 1195 loss: 1.9764791e-06
Iter: 1196 loss: 1.97656254e-06
Iter: 1197 loss: 1.9754998e-06
Iter: 1198 loss: 1.97441659e-06
Iter: 1199 loss: 1.97419013e-06
Iter: 1200 loss: 1.97354893e-06
Iter: 1201 loss: 1.97208624e-06
Iter: 1202 loss: 1.96982614e-06
Iter: 1203 loss: 1.96975452e-06
Iter: 1204 loss: 1.96753717e-06
Iter: 1205 loss: 1.98561065e-06
Iter: 1206 loss: 1.96736119e-06
Iter: 1207 loss: 1.96544693e-06
Iter: 1208 loss: 1.96336737e-06
Iter: 1209 loss: 1.96307815e-06
Iter: 1210 loss: 1.96137444e-06
Iter: 1211 loss: 1.96133851e-06
Iter: 1212 loss: 1.96006567e-06
Iter: 1213 loss: 1.97913391e-06
Iter: 1214 loss: 1.96006681e-06
Iter: 1215 loss: 1.95889834e-06
Iter: 1216 loss: 1.95638086e-06
Iter: 1217 loss: 1.98882844e-06
Iter: 1218 loss: 1.95623534e-06
Iter: 1219 loss: 1.95278153e-06
Iter: 1220 loss: 1.96021756e-06
Iter: 1221 loss: 1.95161078e-06
Iter: 1222 loss: 1.94887275e-06
Iter: 1223 loss: 1.96196311e-06
Iter: 1224 loss: 1.94867357e-06
Iter: 1225 loss: 1.94697554e-06
Iter: 1226 loss: 1.95127677e-06
Iter: 1227 loss: 1.94619338e-06
Iter: 1228 loss: 1.94564586e-06
Iter: 1229 loss: 1.94557697e-06
Iter: 1230 loss: 1.94468657e-06
Iter: 1231 loss: 1.94696258e-06
Iter: 1232 loss: 1.94425661e-06
Iter: 1233 loss: 1.94376253e-06
Iter: 1234 loss: 1.94236145e-06
Iter: 1235 loss: 1.9675856e-06
Iter: 1236 loss: 1.94239055e-06
Iter: 1237 loss: 1.9410395e-06
Iter: 1238 loss: 1.94378845e-06
Iter: 1239 loss: 1.94043923e-06
Iter: 1240 loss: 1.93848791e-06
Iter: 1241 loss: 1.93884034e-06
Iter: 1242 loss: 1.93696042e-06
Iter: 1243 loss: 1.9352542e-06
Iter: 1244 loss: 1.9436111e-06
Iter: 1245 loss: 1.9349045e-06
Iter: 1246 loss: 1.93372261e-06
Iter: 1247 loss: 1.95010193e-06
Iter: 1248 loss: 1.93365668e-06
Iter: 1249 loss: 1.93238247e-06
Iter: 1250 loss: 1.93238384e-06
Iter: 1251 loss: 1.93145615e-06
Iter: 1252 loss: 1.93026881e-06
Iter: 1253 loss: 1.93127312e-06
Iter: 1254 loss: 1.92971015e-06
Iter: 1255 loss: 1.92806328e-06
Iter: 1256 loss: 1.92677658e-06
Iter: 1257 loss: 1.92624498e-06
Iter: 1258 loss: 1.9245424e-06
Iter: 1259 loss: 1.94872769e-06
Iter: 1260 loss: 1.92451898e-06
Iter: 1261 loss: 1.92344282e-06
Iter: 1262 loss: 1.92332664e-06
Iter: 1263 loss: 1.92268453e-06
Iter: 1264 loss: 1.92470043e-06
Iter: 1265 loss: 1.92239213e-06
Iter: 1266 loss: 1.92193465e-06
Iter: 1267 loss: 1.92133211e-06
Iter: 1268 loss: 1.93046571e-06
Iter: 1269 loss: 1.9212514e-06
Iter: 1270 loss: 1.92043171e-06
Iter: 1271 loss: 1.91913387e-06
Iter: 1272 loss: 1.91919571e-06
Iter: 1273 loss: 1.91747949e-06
Iter: 1274 loss: 1.92725247e-06
Iter: 1275 loss: 1.91704089e-06
Iter: 1276 loss: 1.91591766e-06
Iter: 1277 loss: 1.91694812e-06
Iter: 1278 loss: 1.91523259e-06
Iter: 1279 loss: 1.91342178e-06
Iter: 1280 loss: 1.91221147e-06
Iter: 1281 loss: 1.91160734e-06
Iter: 1282 loss: 1.91044478e-06
Iter: 1283 loss: 1.91013442e-06
Iter: 1284 loss: 1.90885658e-06
Iter: 1285 loss: 1.90724938e-06
Iter: 1286 loss: 1.90710125e-06
Iter: 1287 loss: 1.9048573e-06
Iter: 1288 loss: 1.90600247e-06
Iter: 1289 loss: 1.90329388e-06
Iter: 1290 loss: 1.90099843e-06
Iter: 1291 loss: 1.90450123e-06
Iter: 1292 loss: 1.89980574e-06
Iter: 1293 loss: 1.89668458e-06
Iter: 1294 loss: 1.90684057e-06
Iter: 1295 loss: 1.89576872e-06
Iter: 1296 loss: 1.89450714e-06
Iter: 1297 loss: 1.89432205e-06
Iter: 1298 loss: 1.89253092e-06
Iter: 1299 loss: 1.89487309e-06
Iter: 1300 loss: 1.89185539e-06
Iter: 1301 loss: 1.89045329e-06
Iter: 1302 loss: 1.88693332e-06
Iter: 1303 loss: 1.91715117e-06
Iter: 1304 loss: 1.88620493e-06
Iter: 1305 loss: 1.88458512e-06
Iter: 1306 loss: 1.90735614e-06
Iter: 1307 loss: 1.88452418e-06
Iter: 1308 loss: 1.88271645e-06
Iter: 1309 loss: 1.88263152e-06
Iter: 1310 loss: 1.88127274e-06
Iter: 1311 loss: 1.87927367e-06
Iter: 1312 loss: 1.89794491e-06
Iter: 1313 loss: 1.87921569e-06
Iter: 1314 loss: 1.87838918e-06
Iter: 1315 loss: 1.88174704e-06
Iter: 1316 loss: 1.87818216e-06
Iter: 1317 loss: 1.87685453e-06
Iter: 1318 loss: 1.88038553e-06
Iter: 1319 loss: 1.87671981e-06
Iter: 1320 loss: 1.8754497e-06
Iter: 1321 loss: 1.87479168e-06
Iter: 1322 loss: 1.8741822e-06
Iter: 1323 loss: 1.87292437e-06
Iter: 1324 loss: 1.87225032e-06
Iter: 1325 loss: 1.87177523e-06
Iter: 1326 loss: 1.86929651e-06
Iter: 1327 loss: 1.88201113e-06
Iter: 1328 loss: 1.8688869e-06
Iter: 1329 loss: 1.86771467e-06
Iter: 1330 loss: 1.87432045e-06
Iter: 1331 loss: 1.86744569e-06
Iter: 1332 loss: 1.86642956e-06
Iter: 1333 loss: 1.86641068e-06
Iter: 1334 loss: 1.86577097e-06
Iter: 1335 loss: 1.86384955e-06
Iter: 1336 loss: 1.87157855e-06
Iter: 1337 loss: 1.86288457e-06
Iter: 1338 loss: 1.86109378e-06
Iter: 1339 loss: 1.8657397e-06
Iter: 1340 loss: 1.86054694e-06
Iter: 1341 loss: 1.85848614e-06
Iter: 1342 loss: 1.85816043e-06
Iter: 1343 loss: 1.85679994e-06
Iter: 1344 loss: 1.8548327e-06
Iter: 1345 loss: 1.88496347e-06
Iter: 1346 loss: 1.85475221e-06
Iter: 1347 loss: 1.8533641e-06
Iter: 1348 loss: 1.85393787e-06
Iter: 1349 loss: 1.85249928e-06
Iter: 1350 loss: 1.85103636e-06
Iter: 1351 loss: 1.8509902e-06
Iter: 1352 loss: 1.85016722e-06
Iter: 1353 loss: 1.85361603e-06
Iter: 1354 loss: 1.84997646e-06
Iter: 1355 loss: 1.84903865e-06
Iter: 1356 loss: 1.84770113e-06
Iter: 1357 loss: 1.84775149e-06
Iter: 1358 loss: 1.84625924e-06
Iter: 1359 loss: 1.85636236e-06
Iter: 1360 loss: 1.84625321e-06
Iter: 1361 loss: 1.84538476e-06
Iter: 1362 loss: 1.84488158e-06
Iter: 1363 loss: 1.84452404e-06
Iter: 1364 loss: 1.84294117e-06
Iter: 1365 loss: 1.84909095e-06
Iter: 1366 loss: 1.84255987e-06
Iter: 1367 loss: 1.84295891e-06
Iter: 1368 loss: 1.84227656e-06
Iter: 1369 loss: 1.84197415e-06
Iter: 1370 loss: 1.84071337e-06
Iter: 1371 loss: 1.84205578e-06
Iter: 1372 loss: 1.83956217e-06
Iter: 1373 loss: 1.83765485e-06
Iter: 1374 loss: 1.84314069e-06
Iter: 1375 loss: 1.83709039e-06
Iter: 1376 loss: 1.83593613e-06
Iter: 1377 loss: 1.83638917e-06
Iter: 1378 loss: 1.83509701e-06
Iter: 1379 loss: 1.83313921e-06
Iter: 1380 loss: 1.83751581e-06
Iter: 1381 loss: 1.83223062e-06
Iter: 1382 loss: 1.83100985e-06
Iter: 1383 loss: 1.83617146e-06
Iter: 1384 loss: 1.8306323e-06
Iter: 1385 loss: 1.82936719e-06
Iter: 1386 loss: 1.84289979e-06
Iter: 1387 loss: 1.82937083e-06
Iter: 1388 loss: 1.82832014e-06
Iter: 1389 loss: 1.83192765e-06
Iter: 1390 loss: 1.82795679e-06
Iter: 1391 loss: 1.82735221e-06
Iter: 1392 loss: 1.82670215e-06
Iter: 1393 loss: 1.82656095e-06
Iter: 1394 loss: 1.8251676e-06
Iter: 1395 loss: 1.82550343e-06
Iter: 1396 loss: 1.82385497e-06
Iter: 1397 loss: 1.82256e-06
Iter: 1398 loss: 1.83299085e-06
Iter: 1399 loss: 1.8224606e-06
Iter: 1400 loss: 1.82155122e-06
Iter: 1401 loss: 1.82411668e-06
Iter: 1402 loss: 1.82132499e-06
Iter: 1403 loss: 1.82001509e-06
Iter: 1404 loss: 1.8277866e-06
Iter: 1405 loss: 1.81968812e-06
Iter: 1406 loss: 1.8192336e-06
Iter: 1407 loss: 1.81830183e-06
Iter: 1408 loss: 1.83118073e-06
Iter: 1409 loss: 1.81815312e-06
Iter: 1410 loss: 1.81703399e-06
Iter: 1411 loss: 1.81574387e-06
Iter: 1412 loss: 1.81552036e-06
Iter: 1413 loss: 1.81356506e-06
Iter: 1414 loss: 1.8308582e-06
Iter: 1415 loss: 1.81347423e-06
Iter: 1416 loss: 1.81187602e-06
Iter: 1417 loss: 1.81191717e-06
Iter: 1418 loss: 1.81080418e-06
Iter: 1419 loss: 1.80967072e-06
Iter: 1420 loss: 1.80943493e-06
Iter: 1421 loss: 1.80868892e-06
Iter: 1422 loss: 1.81797066e-06
Iter: 1423 loss: 1.80863958e-06
Iter: 1424 loss: 1.80794177e-06
Iter: 1425 loss: 1.80655218e-06
Iter: 1426 loss: 1.81848077e-06
Iter: 1427 loss: 1.80630286e-06
Iter: 1428 loss: 1.80472648e-06
Iter: 1429 loss: 1.8243054e-06
Iter: 1430 loss: 1.80470909e-06
Iter: 1431 loss: 1.80382949e-06
Iter: 1432 loss: 1.80557163e-06
Iter: 1433 loss: 1.80339089e-06
Iter: 1434 loss: 1.80240568e-06
Iter: 1435 loss: 1.80814868e-06
Iter: 1436 loss: 1.80227335e-06
Iter: 1437 loss: 1.80135271e-06
Iter: 1438 loss: 1.80143616e-06
Iter: 1439 loss: 1.80121128e-06
Iter: 1440 loss: 1.800321e-06
Iter: 1441 loss: 1.80346137e-06
Iter: 1442 loss: 1.79994959e-06
Iter: 1443 loss: 1.79887536e-06
Iter: 1444 loss: 1.79831159e-06
Iter: 1445 loss: 1.79765811e-06
Iter: 1446 loss: 1.79652625e-06
Iter: 1447 loss: 1.8078664e-06
Iter: 1448 loss: 1.79648384e-06
Iter: 1449 loss: 1.79536835e-06
Iter: 1450 loss: 1.79538915e-06
Iter: 1451 loss: 1.79472238e-06
Iter: 1452 loss: 1.79348149e-06
Iter: 1453 loss: 1.80527468e-06
Iter: 1454 loss: 1.79342248e-06
Iter: 1455 loss: 1.79272422e-06
Iter: 1456 loss: 1.80343841e-06
Iter: 1457 loss: 1.79277401e-06
Iter: 1458 loss: 1.79200742e-06
Iter: 1459 loss: 1.79074345e-06
Iter: 1460 loss: 1.81615519e-06
Iter: 1461 loss: 1.79071719e-06
Iter: 1462 loss: 1.78961341e-06
Iter: 1463 loss: 1.79813753e-06
Iter: 1464 loss: 1.78958055e-06
Iter: 1465 loss: 1.78869368e-06
Iter: 1466 loss: 1.78951609e-06
Iter: 1467 loss: 1.78808216e-06
Iter: 1468 loss: 1.78688197e-06
Iter: 1469 loss: 1.79251219e-06
Iter: 1470 loss: 1.78659366e-06
Iter: 1471 loss: 1.78638481e-06
Iter: 1472 loss: 1.78596292e-06
Iter: 1473 loss: 1.78570463e-06
Iter: 1474 loss: 1.7850839e-06
Iter: 1475 loss: 1.78557264e-06
Iter: 1476 loss: 1.78458026e-06
Iter: 1477 loss: 1.7832383e-06
Iter: 1478 loss: 1.78442735e-06
Iter: 1479 loss: 1.78226492e-06
Iter: 1480 loss: 1.78123128e-06
Iter: 1481 loss: 1.78873324e-06
Iter: 1482 loss: 1.78126834e-06
Iter: 1483 loss: 1.78020491e-06
Iter: 1484 loss: 1.77972788e-06
Iter: 1485 loss: 1.77938227e-06
Iter: 1486 loss: 1.77813172e-06
Iter: 1487 loss: 1.79314111e-06
Iter: 1488 loss: 1.77816833e-06
Iter: 1489 loss: 1.77755351e-06
Iter: 1490 loss: 1.78449159e-06
Iter: 1491 loss: 1.77758579e-06
Iter: 1492 loss: 1.77714105e-06
Iter: 1493 loss: 1.77724723e-06
Iter: 1494 loss: 1.77686184e-06
Iter: 1495 loss: 1.77638753e-06
Iter: 1496 loss: 1.77610457e-06
Iter: 1497 loss: 1.7757576e-06
Iter: 1498 loss: 1.77504853e-06
Iter: 1499 loss: 1.77754555e-06
Iter: 1500 loss: 1.77471861e-06
Iter: 1501 loss: 1.7743771e-06
Iter: 1502 loss: 1.774407e-06
Iter: 1503 loss: 1.77431923e-06
Iter: 1504 loss: 1.77423192e-06
Iter: 1505 loss: 1.77416882e-06
Iter: 1506 loss: 1.77369225e-06
Iter: 1507 loss: 1.77296261e-06
Iter: 1508 loss: 1.77296329e-06
Iter: 1509 loss: 1.77190441e-06
Iter: 1510 loss: 1.77906486e-06
Iter: 1511 loss: 1.77191077e-06
Iter: 1512 loss: 1.77129846e-06
Iter: 1513 loss: 1.77128879e-06
Iter: 1514 loss: 1.77100515e-06
Iter: 1515 loss: 1.76974027e-06
Iter: 1516 loss: 1.77258926e-06
Iter: 1517 loss: 1.76927711e-06
Iter: 1518 loss: 1.76844014e-06
Iter: 1519 loss: 1.77122479e-06
Iter: 1520 loss: 1.76820276e-06
Iter: 1521 loss: 1.76731442e-06
Iter: 1522 loss: 1.77356105e-06
Iter: 1523 loss: 1.7672894e-06
Iter: 1524 loss: 1.766482e-06
Iter: 1525 loss: 1.77173843e-06
Iter: 1526 loss: 1.76646745e-06
Iter: 1527 loss: 1.76598837e-06
Iter: 1528 loss: 1.76495041e-06
Iter: 1529 loss: 1.7774563e-06
Iter: 1530 loss: 1.76480899e-06
Iter: 1531 loss: 1.76363278e-06
Iter: 1532 loss: 1.76950971e-06
Iter: 1533 loss: 1.76345873e-06
Iter: 1534 loss: 1.76251422e-06
Iter: 1535 loss: 1.76800165e-06
Iter: 1536 loss: 1.7623604e-06
Iter: 1537 loss: 1.7622765e-06
Iter: 1538 loss: 1.76199319e-06
Iter: 1539 loss: 1.76174353e-06
Iter: 1540 loss: 1.76062554e-06
Iter: 1541 loss: 1.76696801e-06
Iter: 1542 loss: 1.76034871e-06
Iter: 1543 loss: 1.75972423e-06
Iter: 1544 loss: 1.7611693e-06
Iter: 1545 loss: 1.75951538e-06
Iter: 1546 loss: 1.7584639e-06
Iter: 1547 loss: 1.75767275e-06
Iter: 1548 loss: 1.75749688e-06
Iter: 1549 loss: 1.75613582e-06
Iter: 1550 loss: 1.77305458e-06
Iter: 1551 loss: 1.75626724e-06
Iter: 1552 loss: 1.75557e-06
Iter: 1553 loss: 1.75489504e-06
Iter: 1554 loss: 1.75475975e-06
Iter: 1555 loss: 1.75339096e-06
Iter: 1556 loss: 1.76828667e-06
Iter: 1557 loss: 1.75333525e-06
Iter: 1558 loss: 1.75302353e-06
Iter: 1559 loss: 1.75291257e-06
Iter: 1560 loss: 1.75262596e-06
Iter: 1561 loss: 1.75183823e-06
Iter: 1562 loss: 1.75400987e-06
Iter: 1563 loss: 1.75152763e-06
Iter: 1564 loss: 1.75053424e-06
Iter: 1565 loss: 1.75708874e-06
Iter: 1566 loss: 1.75044443e-06
Iter: 1567 loss: 1.74966272e-06
Iter: 1568 loss: 1.75118782e-06
Iter: 1569 loss: 1.74931915e-06
Iter: 1570 loss: 1.74889965e-06
Iter: 1571 loss: 1.74873139e-06
Iter: 1572 loss: 1.74807724e-06
Iter: 1573 loss: 1.74801505e-06
Iter: 1574 loss: 1.74769036e-06
Iter: 1575 loss: 1.74726688e-06
Iter: 1576 loss: 1.74676484e-06
Iter: 1577 loss: 1.7605978e-06
Iter: 1578 loss: 1.7467612e-06
Iter: 1579 loss: 1.74556567e-06
Iter: 1580 loss: 1.74720753e-06
Iter: 1581 loss: 1.74511945e-06
Iter: 1582 loss: 1.74389493e-06
Iter: 1583 loss: 1.74975094e-06
Iter: 1584 loss: 1.74354727e-06
Iter: 1585 loss: 1.74258105e-06
Iter: 1586 loss: 1.7441771e-06
Iter: 1587 loss: 1.74206957e-06
Iter: 1588 loss: 1.74098432e-06
Iter: 1589 loss: 1.74513309e-06
Iter: 1590 loss: 1.74067418e-06
Iter: 1591 loss: 1.73983108e-06
Iter: 1592 loss: 1.74666332e-06
Iter: 1593 loss: 1.73969431e-06
Iter: 1594 loss: 1.73882768e-06
Iter: 1595 loss: 1.74311833e-06
Iter: 1596 loss: 1.73867898e-06
Iter: 1597 loss: 1.73818171e-06
Iter: 1598 loss: 1.73703415e-06
Iter: 1599 loss: 1.74540583e-06
Iter: 1600 loss: 1.73669446e-06
Iter: 1601 loss: 1.73556737e-06
Iter: 1602 loss: 1.74802017e-06
Iter: 1603 loss: 1.73553872e-06
Iter: 1604 loss: 1.73505043e-06
Iter: 1605 loss: 1.74081924e-06
Iter: 1606 loss: 1.73503122e-06
Iter: 1607 loss: 1.73447506e-06
Iter: 1608 loss: 1.73888168e-06
Iter: 1609 loss: 1.73439173e-06
Iter: 1610 loss: 1.7341838e-06
Iter: 1611 loss: 1.73371109e-06
Iter: 1612 loss: 1.73372723e-06
Iter: 1613 loss: 1.7333607e-06
Iter: 1614 loss: 1.73254909e-06
Iter: 1615 loss: 1.7325076e-06
Iter: 1616 loss: 1.73155513e-06
Iter: 1617 loss: 1.73631872e-06
Iter: 1618 loss: 1.73116371e-06
Iter: 1619 loss: 1.73010778e-06
Iter: 1620 loss: 1.73020271e-06
Iter: 1621 loss: 1.72943703e-06
Iter: 1622 loss: 1.72784894e-06
Iter: 1623 loss: 1.7389691e-06
Iter: 1624 loss: 1.72778959e-06
Iter: 1625 loss: 1.72675811e-06
Iter: 1626 loss: 1.72788828e-06
Iter: 1627 loss: 1.72625153e-06
Iter: 1628 loss: 1.72493958e-06
Iter: 1629 loss: 1.73675858e-06
Iter: 1630 loss: 1.725022e-06
Iter: 1631 loss: 1.72408954e-06
Iter: 1632 loss: 1.72678551e-06
Iter: 1633 loss: 1.72382306e-06
Iter: 1634 loss: 1.72338287e-06
Iter: 1635 loss: 1.72248974e-06
Iter: 1636 loss: 1.73487354e-06
Iter: 1637 loss: 1.72244222e-06
Iter: 1638 loss: 1.72158661e-06
Iter: 1639 loss: 1.72151886e-06
Iter: 1640 loss: 1.72028285e-06
Iter: 1641 loss: 1.7203264e-06
Iter: 1642 loss: 1.72013392e-06
Iter: 1643 loss: 1.7195664e-06
Iter: 1644 loss: 1.72535397e-06
Iter: 1645 loss: 1.71948386e-06
Iter: 1646 loss: 1.71854117e-06
Iter: 1647 loss: 1.71754186e-06
Iter: 1648 loss: 1.7174375e-06
Iter: 1649 loss: 1.71618058e-06
Iter: 1650 loss: 1.72622958e-06
Iter: 1651 loss: 1.71618876e-06
Iter: 1652 loss: 1.71523197e-06
Iter: 1653 loss: 1.71643e-06
Iter: 1654 loss: 1.71473766e-06
Iter: 1655 loss: 1.71370016e-06
Iter: 1656 loss: 1.71754755e-06
Iter: 1657 loss: 1.71362569e-06
Iter: 1658 loss: 1.71262582e-06
Iter: 1659 loss: 1.71519036e-06
Iter: 1660 loss: 1.71243096e-06
Iter: 1661 loss: 1.71170382e-06
Iter: 1662 loss: 1.71475904e-06
Iter: 1663 loss: 1.71157626e-06
Iter: 1664 loss: 1.71110037e-06
Iter: 1665 loss: 1.71101033e-06
Iter: 1666 loss: 1.71067416e-06
Iter: 1667 loss: 1.71004069e-06
Iter: 1668 loss: 1.72441287e-06
Iter: 1669 loss: 1.71000033e-06
Iter: 1670 loss: 1.70947567e-06
Iter: 1671 loss: 1.71292777e-06
Iter: 1672 loss: 1.70956127e-06
Iter: 1673 loss: 1.70934788e-06
Iter: 1674 loss: 1.70917599e-06
Iter: 1675 loss: 1.70901603e-06
Iter: 1676 loss: 1.70863962e-06
Iter: 1677 loss: 1.71071963e-06
Iter: 1678 loss: 1.7084252e-06
Iter: 1679 loss: 1.70803708e-06
Iter: 1680 loss: 1.70796352e-06
Iter: 1681 loss: 1.70749968e-06
Iter: 1682 loss: 1.70681733e-06
Iter: 1683 loss: 1.70886346e-06
Iter: 1684 loss: 1.70660348e-06
Iter: 1685 loss: 1.70605222e-06
Iter: 1686 loss: 1.70795443e-06
Iter: 1687 loss: 1.70594637e-06
Iter: 1688 loss: 1.7052721e-06
Iter: 1689 loss: 1.7061659e-06
Iter: 1690 loss: 1.70502562e-06
Iter: 1691 loss: 1.7044249e-06
Iter: 1692 loss: 1.70866031e-06
Iter: 1693 loss: 1.70431031e-06
Iter: 1694 loss: 1.70383703e-06
Iter: 1695 loss: 1.70474823e-06
Iter: 1696 loss: 1.70359328e-06
Iter: 1697 loss: 1.70324279e-06
Iter: 1698 loss: 1.70332851e-06
Iter: 1699 loss: 1.70298085e-06
Iter: 1700 loss: 1.70273461e-06
Iter: 1701 loss: 1.70276348e-06
Iter: 1702 loss: 1.70234375e-06
Iter: 1703 loss: 1.70154408e-06
Iter: 1704 loss: 1.70142732e-06
Iter: 1705 loss: 1.70102112e-06
Iter: 1706 loss: 1.70102453e-06
Iter: 1707 loss: 1.70063879e-06
Iter: 1708 loss: 1.70165265e-06
Iter: 1709 loss: 1.70028488e-06
Iter: 1710 loss: 1.6999436e-06
Iter: 1711 loss: 1.69886118e-06
Iter: 1712 loss: 1.70364183e-06
Iter: 1713 loss: 1.69830582e-06
Iter: 1714 loss: 1.69733516e-06
Iter: 1715 loss: 1.7123923e-06
Iter: 1716 loss: 1.69735722e-06
Iter: 1717 loss: 1.69663792e-06
Iter: 1718 loss: 1.69734471e-06
Iter: 1719 loss: 1.69631892e-06
Iter: 1720 loss: 1.69578016e-06
Iter: 1721 loss: 1.69877387e-06
Iter: 1722 loss: 1.69563077e-06
Iter: 1723 loss: 1.69519058e-06
Iter: 1724 loss: 1.69494e-06
Iter: 1725 loss: 1.69465534e-06
Iter: 1726 loss: 1.69397595e-06
Iter: 1727 loss: 1.69718783e-06
Iter: 1728 loss: 1.6939025e-06
Iter: 1729 loss: 1.69328371e-06
Iter: 1730 loss: 1.69397333e-06
Iter: 1731 loss: 1.69316286e-06
Iter: 1732 loss: 1.69259022e-06
Iter: 1733 loss: 1.69259783e-06
Iter: 1734 loss: 1.69227292e-06
Iter: 1735 loss: 1.69215195e-06
Iter: 1736 loss: 1.69195675e-06
Iter: 1737 loss: 1.69162035e-06
Iter: 1738 loss: 1.69169334e-06
Iter: 1739 loss: 1.69129453e-06
Iter: 1740 loss: 1.69473606e-06
Iter: 1741 loss: 1.69124826e-06
Iter: 1742 loss: 1.69120642e-06
Iter: 1743 loss: 1.69080442e-06
Iter: 1744 loss: 1.6955147e-06
Iter: 1745 loss: 1.69082e-06
Iter: 1746 loss: 1.69037253e-06
Iter: 1747 loss: 1.69043233e-06
Iter: 1748 loss: 1.69022439e-06
Iter: 1749 loss: 1.6896887e-06
Iter: 1750 loss: 1.691894e-06
Iter: 1751 loss: 1.68961833e-06
Iter: 1752 loss: 1.68924942e-06
Iter: 1753 loss: 1.68980387e-06
Iter: 1754 loss: 1.68902523e-06
Iter: 1755 loss: 1.68833731e-06
Iter: 1756 loss: 1.68776023e-06
Iter: 1757 loss: 1.68763074e-06
Iter: 1758 loss: 1.68709812e-06
Iter: 1759 loss: 1.69530506e-06
Iter: 1760 loss: 1.68711495e-06
Iter: 1761 loss: 1.6865431e-06
Iter: 1762 loss: 1.68589065e-06
Iter: 1763 loss: 1.68575957e-06
Iter: 1764 loss: 1.68546262e-06
Iter: 1765 loss: 1.68533063e-06
Iter: 1766 loss: 1.68500958e-06
Iter: 1767 loss: 1.68622273e-06
Iter: 1768 loss: 1.68484439e-06
Iter: 1769 loss: 1.68443148e-06
Iter: 1770 loss: 1.68398901e-06
Iter: 1771 loss: 1.68398356e-06
Iter: 1772 loss: 1.68397128e-06
Iter: 1773 loss: 1.68364181e-06
Iter: 1774 loss: 1.68342308e-06
Iter: 1775 loss: 1.6831375e-06
Iter: 1776 loss: 1.68483075e-06
Iter: 1777 loss: 1.68281645e-06
Iter: 1778 loss: 1.68227371e-06
Iter: 1779 loss: 1.68199972e-06
Iter: 1780 loss: 1.68170459e-06
Iter: 1781 loss: 1.68082715e-06
Iter: 1782 loss: 1.68821896e-06
Iter: 1783 loss: 1.68075189e-06
Iter: 1784 loss: 1.68039401e-06
Iter: 1785 loss: 1.67938606e-06
Iter: 1786 loss: 1.69993416e-06
Iter: 1787 loss: 1.67943494e-06
Iter: 1788 loss: 1.67850953e-06
Iter: 1789 loss: 1.67852784e-06
Iter: 1790 loss: 1.67814801e-06
Iter: 1791 loss: 1.67862504e-06
Iter: 1792 loss: 1.67788767e-06
Iter: 1793 loss: 1.67727842e-06
Iter: 1794 loss: 1.67665428e-06
Iter: 1795 loss: 1.67646476e-06
Iter: 1796 loss: 1.67574262e-06
Iter: 1797 loss: 1.68564793e-06
Iter: 1798 loss: 1.67571591e-06
Iter: 1799 loss: 1.67501332e-06
Iter: 1800 loss: 1.6778215e-06
Iter: 1801 loss: 1.67495591e-06
Iter: 1802 loss: 1.67422945e-06
Iter: 1803 loss: 1.67828603e-06
Iter: 1804 loss: 1.67409848e-06
Iter: 1805 loss: 1.67378948e-06
Iter: 1806 loss: 1.67375742e-06
Iter: 1807 loss: 1.67370513e-06
Iter: 1808 loss: 1.67324708e-06
Iter: 1809 loss: 1.67869439e-06
Iter: 1810 loss: 1.67327516e-06
Iter: 1811 loss: 1.67279916e-06
Iter: 1812 loss: 1.67209009e-06
Iter: 1813 loss: 1.6721018e-06
Iter: 1814 loss: 1.67156077e-06
Iter: 1815 loss: 1.67808048e-06
Iter: 1816 loss: 1.67148039e-06
Iter: 1817 loss: 1.67102246e-06
Iter: 1818 loss: 1.67051348e-06
Iter: 1819 loss: 1.67033511e-06
Iter: 1820 loss: 1.66972836e-06
Iter: 1821 loss: 1.67838562e-06
Iter: 1822 loss: 1.66958046e-06
Iter: 1823 loss: 1.66910104e-06
Iter: 1824 loss: 1.66889458e-06
Iter: 1825 loss: 1.66853465e-06
Iter: 1826 loss: 1.66760401e-06
Iter: 1827 loss: 1.67255155e-06
Iter: 1828 loss: 1.66750738e-06
Iter: 1829 loss: 1.66697055e-06
Iter: 1830 loss: 1.66676227e-06
Iter: 1831 loss: 1.66643167e-06
Iter: 1832 loss: 1.66591951e-06
Iter: 1833 loss: 1.66590223e-06
Iter: 1834 loss: 1.66552672e-06
Iter: 1835 loss: 1.66761e-06
Iter: 1836 loss: 1.66549978e-06
Iter: 1837 loss: 1.66504253e-06
Iter: 1838 loss: 1.66486961e-06
Iter: 1839 loss: 1.66465566e-06
Iter: 1840 loss: 1.66408495e-06
Iter: 1841 loss: 1.66398013e-06
Iter: 1842 loss: 1.66390214e-06
Iter: 1843 loss: 1.66317329e-06
Iter: 1844 loss: 1.66559016e-06
Iter: 1845 loss: 1.66297559e-06
Iter: 1846 loss: 1.66205109e-06
Iter: 1847 loss: 1.66435063e-06
Iter: 1848 loss: 1.66189295e-06
Iter: 1849 loss: 1.66110635e-06
Iter: 1850 loss: 1.66158486e-06
Iter: 1851 loss: 1.66057885e-06
Iter: 1852 loss: 1.65954884e-06
Iter: 1853 loss: 1.66465543e-06
Iter: 1854 loss: 1.65936285e-06
Iter: 1855 loss: 1.6586074e-06
Iter: 1856 loss: 1.66176801e-06
Iter: 1857 loss: 1.65846177e-06
Iter: 1858 loss: 1.65775691e-06
Iter: 1859 loss: 1.65762515e-06
Iter: 1860 loss: 1.65708718e-06
Iter: 1861 loss: 1.65618599e-06
Iter: 1862 loss: 1.65923473e-06
Iter: 1863 loss: 1.65579058e-06
Iter: 1864 loss: 1.65492304e-06
Iter: 1865 loss: 1.6556736e-06
Iter: 1866 loss: 1.65430424e-06
Iter: 1867 loss: 1.65356607e-06
Iter: 1868 loss: 1.65366782e-06
Iter: 1869 loss: 1.65290908e-06
Iter: 1870 loss: 1.65262315e-06
Iter: 1871 loss: 1.65206279e-06
Iter: 1872 loss: 1.65177414e-06
Iter: 1873 loss: 1.65158497e-06
Iter: 1874 loss: 1.65103324e-06
Iter: 1875 loss: 1.64999528e-06
Iter: 1876 loss: 1.65929987e-06
Iter: 1877 loss: 1.64969924e-06
Iter: 1878 loss: 1.64883602e-06
Iter: 1879 loss: 1.64998642e-06
Iter: 1880 loss: 1.64836342e-06
Iter: 1881 loss: 1.64724349e-06
Iter: 1882 loss: 1.64837354e-06
Iter: 1883 loss: 1.6466156e-06
Iter: 1884 loss: 1.64584708e-06
Iter: 1885 loss: 1.65610686e-06
Iter: 1886 loss: 1.64587027e-06
Iter: 1887 loss: 1.64508515e-06
Iter: 1888 loss: 1.64368942e-06
Iter: 1889 loss: 1.67065946e-06
Iter: 1890 loss: 1.64346159e-06
Iter: 1891 loss: 1.64259359e-06
Iter: 1892 loss: 1.64255607e-06
Iter: 1893 loss: 1.64170024e-06
Iter: 1894 loss: 1.64153471e-06
Iter: 1895 loss: 1.6409457e-06
Iter: 1896 loss: 1.63977529e-06
Iter: 1897 loss: 1.64713424e-06
Iter: 1898 loss: 1.63963637e-06
Iter: 1899 loss: 1.63878838e-06
Iter: 1900 loss: 1.64031701e-06
Iter: 1901 loss: 1.63844459e-06
Iter: 1902 loss: 1.63776258e-06
Iter: 1903 loss: 1.64159758e-06
Iter: 1904 loss: 1.63774143e-06
Iter: 1905 loss: 1.63728487e-06
Iter: 1906 loss: 1.63669063e-06
Iter: 1907 loss: 1.63655795e-06
Iter: 1908 loss: 1.63708739e-06
Iter: 1909 loss: 1.63633854e-06
Iter: 1910 loss: 1.63614413e-06
Iter: 1911 loss: 1.63568325e-06
Iter: 1912 loss: 1.63652885e-06
Iter: 1913 loss: 1.63525192e-06
Iter: 1914 loss: 1.63395202e-06
Iter: 1915 loss: 1.63857658e-06
Iter: 1916 loss: 1.63367713e-06
Iter: 1917 loss: 1.63247796e-06
Iter: 1918 loss: 1.63894697e-06
Iter: 1919 loss: 1.63235359e-06
Iter: 1920 loss: 1.63150821e-06
Iter: 1921 loss: 1.63291588e-06
Iter: 1922 loss: 1.63122843e-06
Iter: 1923 loss: 1.63041352e-06
Iter: 1924 loss: 1.63055188e-06
Iter: 1925 loss: 1.62973265e-06
Iter: 1926 loss: 1.62889296e-06
Iter: 1927 loss: 1.63212155e-06
Iter: 1928 loss: 1.6286308e-06
Iter: 1929 loss: 1.62799211e-06
Iter: 1930 loss: 1.62818299e-06
Iter: 1931 loss: 1.62747654e-06
Iter: 1932 loss: 1.6267245e-06
Iter: 1933 loss: 1.63496827e-06
Iter: 1934 loss: 1.62678589e-06
Iter: 1935 loss: 1.62668312e-06
Iter: 1936 loss: 1.62640276e-06
Iter: 1937 loss: 1.62620904e-06
Iter: 1938 loss: 1.62578749e-06
Iter: 1939 loss: 1.63222796e-06
Iter: 1940 loss: 1.62567744e-06
Iter: 1941 loss: 1.62558388e-06
Iter: 1942 loss: 1.62549827e-06
Iter: 1943 loss: 1.6253681e-06
Iter: 1944 loss: 1.62478545e-06
Iter: 1945 loss: 1.62655033e-06
Iter: 1946 loss: 1.62441506e-06
Iter: 1947 loss: 1.62376682e-06
Iter: 1948 loss: 1.62506035e-06
Iter: 1949 loss: 1.62355923e-06
Iter: 1950 loss: 1.62281663e-06
Iter: 1951 loss: 1.62441756e-06
Iter: 1952 loss: 1.62258084e-06
Iter: 1953 loss: 1.62198933e-06
Iter: 1954 loss: 1.62307799e-06
Iter: 1955 loss: 1.62162235e-06
Iter: 1956 loss: 1.6207166e-06
Iter: 1957 loss: 1.62149991e-06
Iter: 1958 loss: 1.62022877e-06
Iter: 1959 loss: 1.61925107e-06
Iter: 1960 loss: 1.62922947e-06
Iter: 1961 loss: 1.61918376e-06
Iter: 1962 loss: 1.61877165e-06
Iter: 1963 loss: 1.61877529e-06
Iter: 1964 loss: 1.61834055e-06
Iter: 1965 loss: 1.61722085e-06
Iter: 1966 loss: 1.61787216e-06
Iter: 1967 loss: 1.61693879e-06
Iter: 1968 loss: 1.6162121e-06
Iter: 1969 loss: 1.62416086e-06
Iter: 1970 loss: 1.61624143e-06
Iter: 1971 loss: 1.6158624e-06
Iter: 1972 loss: 1.62028198e-06
Iter: 1973 loss: 1.61579089e-06
Iter: 1974 loss: 1.61558296e-06
Iter: 1975 loss: 1.61838534e-06
Iter: 1976 loss: 1.61557102e-06
Iter: 1977 loss: 1.61535081e-06
Iter: 1978 loss: 1.61485059e-06
Iter: 1979 loss: 1.6160709e-06
Iter: 1980 loss: 1.61450134e-06
Iter: 1981 loss: 1.61362811e-06
Iter: 1982 loss: 1.61486037e-06
Iter: 1983 loss: 1.61325852e-06
Iter: 1984 loss: 1.61252422e-06
Iter: 1985 loss: 1.61555954e-06
Iter: 1986 loss: 1.61214234e-06
Iter: 1987 loss: 1.61140065e-06
Iter: 1988 loss: 1.61569062e-06
Iter: 1989 loss: 1.61132334e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8
+ date
Mon Oct 26 13:56:22 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 2.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi2.8_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97d93f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97d9458e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97d9458400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97d9470e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97d95049d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b44b7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b449ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b44b7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b443e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b443eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b43ce730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b43d2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b439e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4378378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b432c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b42e5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b42e2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4317158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4270620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b42e2e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b42777b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4277730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4220c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b421a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b421aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b418c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b41b6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b414b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4138400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4138a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4116510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b40af158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b40af378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4087730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b404e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97b4020048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.75648917e-05
Iter: 2 loss: 5.64439615e-05
Iter: 3 loss: 0.000138931762
Iter: 4 loss: 5.55853185e-05
Iter: 5 loss: 5.28114178e-05
Iter: 6 loss: 5.23959388e-05
Iter: 7 loss: 4.94762317e-05
Iter: 8 loss: 4.2066582e-05
Iter: 9 loss: 0.00010734002
Iter: 10 loss: 4.08952619e-05
Iter: 11 loss: 3.7438138e-05
Iter: 12 loss: 8.12992948e-05
Iter: 13 loss: 3.74113151e-05
Iter: 14 loss: 3.49621369e-05
Iter: 15 loss: 3.12907505e-05
Iter: 16 loss: 3.12140837e-05
Iter: 17 loss: 2.8844519e-05
Iter: 18 loss: 2.87061957e-05
Iter: 19 loss: 2.70306391e-05
Iter: 20 loss: 2.44346666e-05
Iter: 21 loss: 2.43974755e-05
Iter: 22 loss: 2.25717431e-05
Iter: 23 loss: 3.59087426e-05
Iter: 24 loss: 2.24183386e-05
Iter: 25 loss: 2.11716542e-05
Iter: 26 loss: 2.47066237e-05
Iter: 27 loss: 2.07782959e-05
Iter: 28 loss: 1.98564849e-05
Iter: 29 loss: 2.02679512e-05
Iter: 30 loss: 1.92289208e-05
Iter: 31 loss: 1.84654928e-05
Iter: 32 loss: 1.83784032e-05
Iter: 33 loss: 1.78269729e-05
Iter: 34 loss: 1.67064172e-05
Iter: 35 loss: 2.5560701e-05
Iter: 36 loss: 1.66291502e-05
Iter: 37 loss: 1.59368647e-05
Iter: 38 loss: 1.51978074e-05
Iter: 39 loss: 1.50772357e-05
Iter: 40 loss: 1.45533977e-05
Iter: 41 loss: 1.45320191e-05
Iter: 42 loss: 1.40458969e-05
Iter: 43 loss: 1.52405719e-05
Iter: 44 loss: 1.38729993e-05
Iter: 45 loss: 1.33966023e-05
Iter: 46 loss: 1.33963113e-05
Iter: 47 loss: 1.32636433e-05
Iter: 48 loss: 1.29458404e-05
Iter: 49 loss: 1.64256e-05
Iter: 50 loss: 1.2912391e-05
Iter: 51 loss: 1.23613499e-05
Iter: 52 loss: 1.27946751e-05
Iter: 53 loss: 1.20281966e-05
Iter: 54 loss: 1.16289984e-05
Iter: 55 loss: 1.5279551e-05
Iter: 56 loss: 1.16110568e-05
Iter: 57 loss: 1.1186964e-05
Iter: 58 loss: 1.09275461e-05
Iter: 59 loss: 1.07551277e-05
Iter: 60 loss: 1.04859382e-05
Iter: 61 loss: 1.0482996e-05
Iter: 62 loss: 1.02656768e-05
Iter: 63 loss: 9.84222515e-06
Iter: 64 loss: 1.83600641e-05
Iter: 65 loss: 9.83864629e-06
Iter: 66 loss: 9.81011362e-06
Iter: 67 loss: 9.63987259e-06
Iter: 68 loss: 9.5144369e-06
Iter: 69 loss: 9.27406381e-06
Iter: 70 loss: 1.4375375e-05
Iter: 71 loss: 9.27323435e-06
Iter: 72 loss: 9.03796445e-06
Iter: 73 loss: 1.2131798e-05
Iter: 74 loss: 9.0363319e-06
Iter: 75 loss: 8.87747683e-06
Iter: 76 loss: 8.67717426e-06
Iter: 77 loss: 8.6611326e-06
Iter: 78 loss: 8.76445e-06
Iter: 79 loss: 8.55676626e-06
Iter: 80 loss: 8.48529089e-06
Iter: 81 loss: 8.4329713e-06
Iter: 82 loss: 8.40895336e-06
Iter: 83 loss: 8.28988777e-06
Iter: 84 loss: 8.12405e-06
Iter: 85 loss: 8.11754398e-06
Iter: 86 loss: 7.93507934e-06
Iter: 87 loss: 1.01863161e-05
Iter: 88 loss: 7.93271829e-06
Iter: 89 loss: 7.79189304e-06
Iter: 90 loss: 7.83512223e-06
Iter: 91 loss: 7.69132203e-06
Iter: 92 loss: 7.54246594e-06
Iter: 93 loss: 8.79938398e-06
Iter: 94 loss: 7.53423683e-06
Iter: 95 loss: 7.37884238e-06
Iter: 96 loss: 7.40214e-06
Iter: 97 loss: 7.26123835e-06
Iter: 98 loss: 7.16869545e-06
Iter: 99 loss: 7.16492377e-06
Iter: 100 loss: 7.09336427e-06
Iter: 101 loss: 6.99574548e-06
Iter: 102 loss: 6.99094198e-06
Iter: 103 loss: 6.84954e-06
Iter: 104 loss: 8.1762746e-06
Iter: 105 loss: 6.84382849e-06
Iter: 106 loss: 6.78255128e-06
Iter: 107 loss: 6.81305301e-06
Iter: 108 loss: 6.74152579e-06
Iter: 109 loss: 6.65834068e-06
Iter: 110 loss: 7.35375215e-06
Iter: 111 loss: 6.65329071e-06
Iter: 112 loss: 6.57302871e-06
Iter: 113 loss: 7.12439305e-06
Iter: 114 loss: 6.56513839e-06
Iter: 115 loss: 6.53841653e-06
Iter: 116 loss: 6.46096396e-06
Iter: 117 loss: 6.7865617e-06
Iter: 118 loss: 6.43068097e-06
Iter: 119 loss: 6.3010184e-06
Iter: 120 loss: 7.1291438e-06
Iter: 121 loss: 6.28643284e-06
Iter: 122 loss: 6.22431207e-06
Iter: 123 loss: 6.20852234e-06
Iter: 124 loss: 6.16972375e-06
Iter: 125 loss: 6.07087486e-06
Iter: 126 loss: 6.75036608e-06
Iter: 127 loss: 6.06152616e-06
Iter: 128 loss: 6.00094972e-06
Iter: 129 loss: 5.9182812e-06
Iter: 130 loss: 5.9146505e-06
Iter: 131 loss: 5.83290603e-06
Iter: 132 loss: 5.82924e-06
Iter: 133 loss: 5.78466506e-06
Iter: 134 loss: 5.85343196e-06
Iter: 135 loss: 5.76365437e-06
Iter: 136 loss: 5.69323674e-06
Iter: 137 loss: 5.87705426e-06
Iter: 138 loss: 5.66939116e-06
Iter: 139 loss: 5.62224159e-06
Iter: 140 loss: 5.91113348e-06
Iter: 141 loss: 5.61663182e-06
Iter: 142 loss: 5.5772548e-06
Iter: 143 loss: 5.60915259e-06
Iter: 144 loss: 5.55362e-06
Iter: 145 loss: 5.51478479e-06
Iter: 146 loss: 5.51415269e-06
Iter: 147 loss: 5.49506603e-06
Iter: 148 loss: 5.45971579e-06
Iter: 149 loss: 6.27222562e-06
Iter: 150 loss: 5.45953026e-06
Iter: 151 loss: 5.41029885e-06
Iter: 152 loss: 5.37141295e-06
Iter: 153 loss: 5.35636764e-06
Iter: 154 loss: 5.30393481e-06
Iter: 155 loss: 5.64609218e-06
Iter: 156 loss: 5.29880435e-06
Iter: 157 loss: 5.23726612e-06
Iter: 158 loss: 5.22552637e-06
Iter: 159 loss: 5.18381148e-06
Iter: 160 loss: 5.12783299e-06
Iter: 161 loss: 5.33350249e-06
Iter: 162 loss: 5.11387407e-06
Iter: 163 loss: 5.05926801e-06
Iter: 164 loss: 5.55168663e-06
Iter: 165 loss: 5.05708613e-06
Iter: 166 loss: 5.02718876e-06
Iter: 167 loss: 5.02933563e-06
Iter: 168 loss: 5.00389842e-06
Iter: 169 loss: 4.95416862e-06
Iter: 170 loss: 5.15987176e-06
Iter: 171 loss: 4.94333563e-06
Iter: 172 loss: 4.91736409e-06
Iter: 173 loss: 5.1990246e-06
Iter: 174 loss: 4.91697938e-06
Iter: 175 loss: 4.89111426e-06
Iter: 176 loss: 4.9043e-06
Iter: 177 loss: 4.87408488e-06
Iter: 178 loss: 4.85237342e-06
Iter: 179 loss: 4.85149576e-06
Iter: 180 loss: 4.83800841e-06
Iter: 181 loss: 4.82112591e-06
Iter: 182 loss: 4.82004361e-06
Iter: 183 loss: 4.79510163e-06
Iter: 184 loss: 4.75356546e-06
Iter: 185 loss: 4.7534395e-06
Iter: 186 loss: 4.72036845e-06
Iter: 187 loss: 4.72036754e-06
Iter: 188 loss: 4.69205e-06
Iter: 189 loss: 4.64948334e-06
Iter: 190 loss: 4.64864024e-06
Iter: 191 loss: 4.60830552e-06
Iter: 192 loss: 4.89245258e-06
Iter: 193 loss: 4.60422098e-06
Iter: 194 loss: 4.56925773e-06
Iter: 195 loss: 4.81224652e-06
Iter: 196 loss: 4.56575162e-06
Iter: 197 loss: 4.54294e-06
Iter: 198 loss: 4.50915923e-06
Iter: 199 loss: 4.50847392e-06
Iter: 200 loss: 4.47108232e-06
Iter: 201 loss: 4.47068487e-06
Iter: 202 loss: 4.45347814e-06
Iter: 203 loss: 4.48520768e-06
Iter: 204 loss: 4.44608486e-06
Iter: 205 loss: 4.4227113e-06
Iter: 206 loss: 4.5285924e-06
Iter: 207 loss: 4.41833618e-06
Iter: 208 loss: 4.40543045e-06
Iter: 209 loss: 4.40554595e-06
Iter: 210 loss: 4.39570704e-06
Iter: 211 loss: 4.38676534e-06
Iter: 212 loss: 4.38439247e-06
Iter: 213 loss: 4.36876735e-06
Iter: 214 loss: 4.34307458e-06
Iter: 215 loss: 4.34282e-06
Iter: 216 loss: 4.31556418e-06
Iter: 217 loss: 4.51112237e-06
Iter: 218 loss: 4.31318313e-06
Iter: 219 loss: 4.2861484e-06
Iter: 220 loss: 4.26851557e-06
Iter: 221 loss: 4.25784037e-06
Iter: 222 loss: 4.23359143e-06
Iter: 223 loss: 4.51630194e-06
Iter: 224 loss: 4.23356232e-06
Iter: 225 loss: 4.20920878e-06
Iter: 226 loss: 4.21759341e-06
Iter: 227 loss: 4.19225944e-06
Iter: 228 loss: 4.1686344e-06
Iter: 229 loss: 4.20564356e-06
Iter: 230 loss: 4.15785689e-06
Iter: 231 loss: 4.12715735e-06
Iter: 232 loss: 4.32195566e-06
Iter: 233 loss: 4.12377494e-06
Iter: 234 loss: 4.10709e-06
Iter: 235 loss: 4.18053241e-06
Iter: 236 loss: 4.10386838e-06
Iter: 237 loss: 4.08757751e-06
Iter: 238 loss: 4.17204274e-06
Iter: 239 loss: 4.08479082e-06
Iter: 240 loss: 4.07481184e-06
Iter: 241 loss: 4.0747741e-06
Iter: 242 loss: 4.06796107e-06
Iter: 243 loss: 4.06477466e-06
Iter: 244 loss: 4.06125855e-06
Iter: 245 loss: 4.04986531e-06
Iter: 246 loss: 4.02216074e-06
Iter: 247 loss: 4.33423293e-06
Iter: 248 loss: 4.01935313e-06
Iter: 249 loss: 3.99939745e-06
Iter: 250 loss: 3.99938563e-06
Iter: 251 loss: 3.98354314e-06
Iter: 252 loss: 3.96161158e-06
Iter: 253 loss: 3.96057067e-06
Iter: 254 loss: 3.94190647e-06
Iter: 255 loss: 3.94202652e-06
Iter: 256 loss: 3.92655329e-06
Iter: 257 loss: 3.90684818e-06
Iter: 258 loss: 3.90555033e-06
Iter: 259 loss: 3.88640137e-06
Iter: 260 loss: 4.03481636e-06
Iter: 261 loss: 3.88513354e-06
Iter: 262 loss: 3.86370857e-06
Iter: 263 loss: 3.88137141e-06
Iter: 264 loss: 3.85091153e-06
Iter: 265 loss: 3.83522138e-06
Iter: 266 loss: 3.97525127e-06
Iter: 267 loss: 3.8344956e-06
Iter: 268 loss: 3.82151666e-06
Iter: 269 loss: 3.87203363e-06
Iter: 270 loss: 3.81807968e-06
Iter: 271 loss: 3.81080076e-06
Iter: 272 loss: 3.81029577e-06
Iter: 273 loss: 3.80361962e-06
Iter: 274 loss: 3.8050207e-06
Iter: 275 loss: 3.79897301e-06
Iter: 276 loss: 3.79008679e-06
Iter: 277 loss: 3.76901903e-06
Iter: 278 loss: 3.99210921e-06
Iter: 279 loss: 3.76661728e-06
Iter: 280 loss: 3.74849878e-06
Iter: 281 loss: 4.01672969e-06
Iter: 282 loss: 3.74855745e-06
Iter: 283 loss: 3.73525654e-06
Iter: 284 loss: 3.72196541e-06
Iter: 285 loss: 3.71933947e-06
Iter: 286 loss: 3.70587713e-06
Iter: 287 loss: 3.7057041e-06
Iter: 288 loss: 3.69544568e-06
Iter: 289 loss: 3.67578e-06
Iter: 290 loss: 4.11687552e-06
Iter: 291 loss: 3.6759734e-06
Iter: 292 loss: 3.65846927e-06
Iter: 293 loss: 3.65849291e-06
Iter: 294 loss: 3.64320499e-06
Iter: 295 loss: 3.64524408e-06
Iter: 296 loss: 3.63172308e-06
Iter: 297 loss: 3.62135916e-06
Iter: 298 loss: 3.62111359e-06
Iter: 299 loss: 3.61277125e-06
Iter: 300 loss: 3.60724698e-06
Iter: 301 loss: 3.60417334e-06
Iter: 302 loss: 3.59567184e-06
Iter: 303 loss: 3.59467936e-06
Iter: 304 loss: 3.58792909e-06
Iter: 305 loss: 3.59713863e-06
Iter: 306 loss: 3.58454508e-06
Iter: 307 loss: 3.57767726e-06
Iter: 308 loss: 3.56635542e-06
Iter: 309 loss: 3.56622377e-06
Iter: 310 loss: 3.55055272e-06
Iter: 311 loss: 3.59345449e-06
Iter: 312 loss: 3.54545318e-06
Iter: 313 loss: 3.53523274e-06
Iter: 314 loss: 3.53666383e-06
Iter: 315 loss: 3.52766187e-06
Iter: 316 loss: 3.51230619e-06
Iter: 317 loss: 3.61670527e-06
Iter: 318 loss: 3.51032304e-06
Iter: 319 loss: 3.50033065e-06
Iter: 320 loss: 3.49863467e-06
Iter: 321 loss: 3.49163975e-06
Iter: 322 loss: 3.47726746e-06
Iter: 323 loss: 3.60343506e-06
Iter: 324 loss: 3.47653281e-06
Iter: 325 loss: 3.46862021e-06
Iter: 326 loss: 3.46205934e-06
Iter: 327 loss: 3.46009074e-06
Iter: 328 loss: 3.44797e-06
Iter: 329 loss: 3.61085449e-06
Iter: 330 loss: 3.4476891e-06
Iter: 331 loss: 3.44130012e-06
Iter: 332 loss: 3.44144314e-06
Iter: 333 loss: 3.43616921e-06
Iter: 334 loss: 3.42791827e-06
Iter: 335 loss: 3.56191504e-06
Iter: 336 loss: 3.42773774e-06
Iter: 337 loss: 3.42114481e-06
Iter: 338 loss: 3.45016178e-06
Iter: 339 loss: 3.41977102e-06
Iter: 340 loss: 3.41599457e-06
Iter: 341 loss: 3.41234863e-06
Iter: 342 loss: 3.41141458e-06
Iter: 343 loss: 3.40391671e-06
Iter: 344 loss: 3.39757162e-06
Iter: 345 loss: 3.39553344e-06
Iter: 346 loss: 3.3854069e-06
Iter: 347 loss: 3.46159823e-06
Iter: 348 loss: 3.38453538e-06
Iter: 349 loss: 3.37506208e-06
Iter: 350 loss: 3.37067513e-06
Iter: 351 loss: 3.36600669e-06
Iter: 352 loss: 3.35617779e-06
Iter: 353 loss: 3.50378218e-06
Iter: 354 loss: 3.3560666e-06
Iter: 355 loss: 3.34893161e-06
Iter: 356 loss: 3.33627509e-06
Iter: 357 loss: 3.33649268e-06
Iter: 358 loss: 3.3265e-06
Iter: 359 loss: 3.32628451e-06
Iter: 360 loss: 3.31918454e-06
Iter: 361 loss: 3.31092156e-06
Iter: 362 loss: 3.31012916e-06
Iter: 363 loss: 3.30248963e-06
Iter: 364 loss: 3.3023573e-06
Iter: 365 loss: 3.2976568e-06
Iter: 366 loss: 3.31298634e-06
Iter: 367 loss: 3.29614886e-06
Iter: 368 loss: 3.29015666e-06
Iter: 369 loss: 3.33655498e-06
Iter: 370 loss: 3.28959845e-06
Iter: 371 loss: 3.28640135e-06
Iter: 372 loss: 3.28508327e-06
Iter: 373 loss: 3.28327633e-06
Iter: 374 loss: 3.27898601e-06
Iter: 375 loss: 3.27250132e-06
Iter: 376 loss: 3.27244106e-06
Iter: 377 loss: 3.26249506e-06
Iter: 378 loss: 3.32973173e-06
Iter: 379 loss: 3.2617163e-06
Iter: 380 loss: 3.2553e-06
Iter: 381 loss: 3.25701762e-06
Iter: 382 loss: 3.25059182e-06
Iter: 383 loss: 3.24061148e-06
Iter: 384 loss: 3.289912e-06
Iter: 385 loss: 3.23915788e-06
Iter: 386 loss: 3.23265704e-06
Iter: 387 loss: 3.23379209e-06
Iter: 388 loss: 3.22814185e-06
Iter: 389 loss: 3.21733273e-06
Iter: 390 loss: 3.2498665e-06
Iter: 391 loss: 3.21397556e-06
Iter: 392 loss: 3.20726622e-06
Iter: 393 loss: 3.23221593e-06
Iter: 394 loss: 3.20573e-06
Iter: 395 loss: 3.19750393e-06
Iter: 396 loss: 3.21688776e-06
Iter: 397 loss: 3.19458604e-06
Iter: 398 loss: 3.18959974e-06
Iter: 399 loss: 3.24229131e-06
Iter: 400 loss: 3.18948833e-06
Iter: 401 loss: 3.18538901e-06
Iter: 402 loss: 3.22433834e-06
Iter: 403 loss: 3.18522916e-06
Iter: 404 loss: 3.18152797e-06
Iter: 405 loss: 3.17462172e-06
Iter: 406 loss: 3.32181685e-06
Iter: 407 loss: 3.17450667e-06
Iter: 408 loss: 3.16908381e-06
Iter: 409 loss: 3.19576611e-06
Iter: 410 loss: 3.16813703e-06
Iter: 411 loss: 3.16298315e-06
Iter: 412 loss: 3.15631496e-06
Iter: 413 loss: 3.15596867e-06
Iter: 414 loss: 3.15015654e-06
Iter: 415 loss: 3.15006969e-06
Iter: 416 loss: 3.14496492e-06
Iter: 417 loss: 3.14061845e-06
Iter: 418 loss: 3.13911596e-06
Iter: 419 loss: 3.13359942e-06
Iter: 420 loss: 3.18355205e-06
Iter: 421 loss: 3.13328792e-06
Iter: 422 loss: 3.12757265e-06
Iter: 423 loss: 3.1280681e-06
Iter: 424 loss: 3.12317206e-06
Iter: 425 loss: 3.11795657e-06
Iter: 426 loss: 3.14144131e-06
Iter: 427 loss: 3.11695703e-06
Iter: 428 loss: 3.11015e-06
Iter: 429 loss: 3.1143e-06
Iter: 430 loss: 3.10561882e-06
Iter: 431 loss: 3.10221185e-06
Iter: 432 loss: 3.10192218e-06
Iter: 433 loss: 3.09887469e-06
Iter: 434 loss: 3.12268958e-06
Iter: 435 loss: 3.09863458e-06
Iter: 436 loss: 3.09556845e-06
Iter: 437 loss: 3.09049483e-06
Iter: 438 loss: 3.0905021e-06
Iter: 439 loss: 3.08655581e-06
Iter: 440 loss: 3.09430607e-06
Iter: 441 loss: 3.08498102e-06
Iter: 442 loss: 3.07935716e-06
Iter: 443 loss: 3.07247365e-06
Iter: 444 loss: 3.07211667e-06
Iter: 445 loss: 3.06577886e-06
Iter: 446 loss: 3.06599304e-06
Iter: 447 loss: 3.06029233e-06
Iter: 448 loss: 3.05659842e-06
Iter: 449 loss: 3.05454478e-06
Iter: 450 loss: 3.04763739e-06
Iter: 451 loss: 3.10487394e-06
Iter: 452 loss: 3.04705645e-06
Iter: 453 loss: 3.04049718e-06
Iter: 454 loss: 3.03874276e-06
Iter: 455 loss: 3.03469324e-06
Iter: 456 loss: 3.02845183e-06
Iter: 457 loss: 3.09205416e-06
Iter: 458 loss: 3.02828062e-06
Iter: 459 loss: 3.02239278e-06
Iter: 460 loss: 3.02287026e-06
Iter: 461 loss: 3.01783075e-06
Iter: 462 loss: 3.01323735e-06
Iter: 463 loss: 3.01330374e-06
Iter: 464 loss: 3.01099544e-06
Iter: 465 loss: 3.01081e-06
Iter: 466 loss: 3.0085148e-06
Iter: 467 loss: 3.00414285e-06
Iter: 468 loss: 3.0974013e-06
Iter: 469 loss: 3.00397028e-06
Iter: 470 loss: 3.00069e-06
Iter: 471 loss: 3.01521413e-06
Iter: 472 loss: 3.00010515e-06
Iter: 473 loss: 2.99704402e-06
Iter: 474 loss: 2.99076987e-06
Iter: 475 loss: 3.10931546e-06
Iter: 476 loss: 2.99062413e-06
Iter: 477 loss: 2.9855878e-06
Iter: 478 loss: 2.98554073e-06
Iter: 479 loss: 2.98180612e-06
Iter: 480 loss: 2.97566157e-06
Iter: 481 loss: 2.97559791e-06
Iter: 482 loss: 2.96944108e-06
Iter: 483 loss: 2.96943608e-06
Iter: 484 loss: 2.96552116e-06
Iter: 485 loss: 2.9602304e-06
Iter: 486 loss: 2.95997233e-06
Iter: 487 loss: 2.95483801e-06
Iter: 488 loss: 2.95486234e-06
Iter: 489 loss: 2.94998972e-06
Iter: 490 loss: 2.94001961e-06
Iter: 491 loss: 3.11650797e-06
Iter: 492 loss: 2.9397554e-06
Iter: 493 loss: 2.93310359e-06
Iter: 494 loss: 2.93217363e-06
Iter: 495 loss: 2.92937148e-06
Iter: 496 loss: 2.92944765e-06
Iter: 497 loss: 2.92641562e-06
Iter: 498 loss: 2.92293589e-06
Iter: 499 loss: 2.92244658e-06
Iter: 500 loss: 2.91939114e-06
Iter: 501 loss: 2.92739674e-06
Iter: 502 loss: 2.91831907e-06
Iter: 503 loss: 2.91519427e-06
Iter: 504 loss: 2.91221704e-06
Iter: 505 loss: 2.91139713e-06
Iter: 506 loss: 2.9066382e-06
Iter: 507 loss: 2.97051838e-06
Iter: 508 loss: 2.90664843e-06
Iter: 509 loss: 2.90382786e-06
Iter: 510 loss: 2.90033336e-06
Iter: 511 loss: 2.90010121e-06
Iter: 512 loss: 2.89609579e-06
Iter: 513 loss: 2.89616855e-06
Iter: 514 loss: 2.89329432e-06
Iter: 515 loss: 2.89172067e-06
Iter: 516 loss: 2.89053605e-06
Iter: 517 loss: 2.8872505e-06
Iter: 518 loss: 2.92187724e-06
Iter: 519 loss: 2.8870686e-06
Iter: 520 loss: 2.88445085e-06
Iter: 521 loss: 2.88034425e-06
Iter: 522 loss: 2.87995454e-06
Iter: 523 loss: 2.87577495e-06
Iter: 524 loss: 2.94070037e-06
Iter: 525 loss: 2.87570924e-06
Iter: 526 loss: 2.87294051e-06
Iter: 527 loss: 2.90096841e-06
Iter: 528 loss: 2.87279636e-06
Iter: 529 loss: 2.8695008e-06
Iter: 530 loss: 2.87044691e-06
Iter: 531 loss: 2.86692102e-06
Iter: 532 loss: 2.86449e-06
Iter: 533 loss: 2.86505497e-06
Iter: 534 loss: 2.86259842e-06
Iter: 535 loss: 2.85861688e-06
Iter: 536 loss: 2.84954558e-06
Iter: 537 loss: 2.96289363e-06
Iter: 538 loss: 2.84874659e-06
Iter: 539 loss: 2.83986697e-06
Iter: 540 loss: 2.83999407e-06
Iter: 541 loss: 2.83455574e-06
Iter: 542 loss: 2.8293216e-06
Iter: 543 loss: 2.82814267e-06
Iter: 544 loss: 2.82068345e-06
Iter: 545 loss: 2.91764218e-06
Iter: 546 loss: 2.82060114e-06
Iter: 547 loss: 2.81566713e-06
Iter: 548 loss: 2.80779864e-06
Iter: 549 loss: 2.80769927e-06
Iter: 550 loss: 2.79877395e-06
Iter: 551 loss: 2.93382141e-06
Iter: 552 loss: 2.79862297e-06
Iter: 553 loss: 2.79420487e-06
Iter: 554 loss: 2.79384858e-06
Iter: 555 loss: 2.79061351e-06
Iter: 556 loss: 2.78577363e-06
Iter: 557 loss: 2.83151076e-06
Iter: 558 loss: 2.78559082e-06
Iter: 559 loss: 2.78322977e-06
Iter: 560 loss: 2.81221878e-06
Iter: 561 loss: 2.7832707e-06
Iter: 562 loss: 2.78065136e-06
Iter: 563 loss: 2.79103324e-06
Iter: 564 loss: 2.77983781e-06
Iter: 565 loss: 2.77828485e-06
Iter: 566 loss: 2.77663685e-06
Iter: 567 loss: 2.77643539e-06
Iter: 568 loss: 2.7734759e-06
Iter: 569 loss: 2.76818673e-06
Iter: 570 loss: 2.76821675e-06
Iter: 571 loss: 2.76492392e-06
Iter: 572 loss: 2.76471451e-06
Iter: 573 loss: 2.76233459e-06
Iter: 574 loss: 2.75945081e-06
Iter: 575 loss: 2.75923435e-06
Iter: 576 loss: 2.75536627e-06
Iter: 577 loss: 2.79734923e-06
Iter: 578 loss: 2.75546722e-06
Iter: 579 loss: 2.75253319e-06
Iter: 580 loss: 2.74706963e-06
Iter: 581 loss: 2.8720051e-06
Iter: 582 loss: 2.74705781e-06
Iter: 583 loss: 2.74221134e-06
Iter: 584 loss: 2.74204899e-06
Iter: 585 loss: 2.73946034e-06
Iter: 586 loss: 2.73869705e-06
Iter: 587 loss: 2.73711794e-06
Iter: 588 loss: 2.73239766e-06
Iter: 589 loss: 2.75452794e-06
Iter: 590 loss: 2.73175101e-06
Iter: 591 loss: 2.72799252e-06
Iter: 592 loss: 2.72606894e-06
Iter: 593 loss: 2.72467969e-06
Iter: 594 loss: 2.72080524e-06
Iter: 595 loss: 2.71996078e-06
Iter: 596 loss: 2.71794124e-06
Iter: 597 loss: 2.71554904e-06
Iter: 598 loss: 2.71523118e-06
Iter: 599 loss: 2.71246199e-06
Iter: 600 loss: 2.70967894e-06
Iter: 601 loss: 2.70902638e-06
Iter: 602 loss: 2.70547571e-06
Iter: 603 loss: 2.76143e-06
Iter: 604 loss: 2.70551277e-06
Iter: 605 loss: 2.70272972e-06
Iter: 606 loss: 2.70167038e-06
Iter: 607 loss: 2.70042665e-06
Iter: 608 loss: 2.69729526e-06
Iter: 609 loss: 2.74037029e-06
Iter: 610 loss: 2.69717225e-06
Iter: 611 loss: 2.69415841e-06
Iter: 612 loss: 2.68914391e-06
Iter: 613 loss: 2.68905796e-06
Iter: 614 loss: 2.68651502e-06
Iter: 615 loss: 2.68601025e-06
Iter: 616 loss: 2.6836251e-06
Iter: 617 loss: 2.68237773e-06
Iter: 618 loss: 2.68130771e-06
Iter: 619 loss: 2.67873065e-06
Iter: 620 loss: 2.68742747e-06
Iter: 621 loss: 2.67809651e-06
Iter: 622 loss: 2.67537484e-06
Iter: 623 loss: 2.66923098e-06
Iter: 624 loss: 2.73680848e-06
Iter: 625 loss: 2.66857091e-06
Iter: 626 loss: 2.68202029e-06
Iter: 627 loss: 2.66644224e-06
Iter: 628 loss: 2.66521e-06
Iter: 629 loss: 2.66331335e-06
Iter: 630 loss: 2.66320944e-06
Iter: 631 loss: 2.65954e-06
Iter: 632 loss: 2.66093275e-06
Iter: 633 loss: 2.65720109e-06
Iter: 634 loss: 2.65377139e-06
Iter: 635 loss: 2.66784e-06
Iter: 636 loss: 2.65319613e-06
Iter: 637 loss: 2.64871778e-06
Iter: 638 loss: 2.6533819e-06
Iter: 639 loss: 2.64632013e-06
Iter: 640 loss: 2.64270898e-06
Iter: 641 loss: 2.66028201e-06
Iter: 642 loss: 2.64202322e-06
Iter: 643 loss: 2.63786751e-06
Iter: 644 loss: 2.64489745e-06
Iter: 645 loss: 2.63592119e-06
Iter: 646 loss: 2.6335947e-06
Iter: 647 loss: 2.65697417e-06
Iter: 648 loss: 2.63359266e-06
Iter: 649 loss: 2.63154584e-06
Iter: 650 loss: 2.6295279e-06
Iter: 651 loss: 2.62901608e-06
Iter: 652 loss: 2.62493768e-06
Iter: 653 loss: 2.62958747e-06
Iter: 654 loss: 2.62270692e-06
Iter: 655 loss: 2.61982882e-06
Iter: 656 loss: 2.61963828e-06
Iter: 657 loss: 2.61797459e-06
Iter: 658 loss: 2.62328649e-06
Iter: 659 loss: 2.61735863e-06
Iter: 660 loss: 2.61454352e-06
Iter: 661 loss: 2.62304707e-06
Iter: 662 loss: 2.6135674e-06
Iter: 663 loss: 2.61163223e-06
Iter: 664 loss: 2.61034575e-06
Iter: 665 loss: 2.60940715e-06
Iter: 666 loss: 2.60699562e-06
Iter: 667 loss: 2.60261845e-06
Iter: 668 loss: 2.60264324e-06
Iter: 669 loss: 2.59911212e-06
Iter: 670 loss: 2.59909234e-06
Iter: 671 loss: 2.59656736e-06
Iter: 672 loss: 2.59262015e-06
Iter: 673 loss: 2.59243893e-06
Iter: 674 loss: 2.588e-06
Iter: 675 loss: 2.65654035e-06
Iter: 676 loss: 2.58806881e-06
Iter: 677 loss: 2.58558703e-06
Iter: 678 loss: 2.58998261e-06
Iter: 679 loss: 2.58457885e-06
Iter: 680 loss: 2.58162072e-06
Iter: 681 loss: 2.59014769e-06
Iter: 682 loss: 2.5805416e-06
Iter: 683 loss: 2.57835973e-06
Iter: 684 loss: 2.59281114e-06
Iter: 685 loss: 2.57803345e-06
Iter: 686 loss: 2.57590477e-06
Iter: 687 loss: 2.5760437e-06
Iter: 688 loss: 2.57412489e-06
Iter: 689 loss: 2.5708996e-06
Iter: 690 loss: 2.57921602e-06
Iter: 691 loss: 2.56995577e-06
Iter: 692 loss: 2.57058355e-06
Iter: 693 loss: 2.56854082e-06
Iter: 694 loss: 2.56790645e-06
Iter: 695 loss: 2.5665986e-06
Iter: 696 loss: 2.56650446e-06
Iter: 697 loss: 2.56504222e-06
Iter: 698 loss: 2.56162662e-06
Iter: 699 loss: 2.59771832e-06
Iter: 700 loss: 2.56112048e-06
Iter: 701 loss: 2.5580523e-06
Iter: 702 loss: 2.55802388e-06
Iter: 703 loss: 2.55583132e-06
Iter: 704 loss: 2.5526424e-06
Iter: 705 loss: 2.55265286e-06
Iter: 706 loss: 2.55095392e-06
Iter: 707 loss: 2.55080249e-06
Iter: 708 loss: 2.5492493e-06
Iter: 709 loss: 2.54587053e-06
Iter: 710 loss: 2.59175772e-06
Iter: 711 loss: 2.54539782e-06
Iter: 712 loss: 2.54332826e-06
Iter: 713 loss: 2.54925044e-06
Iter: 714 loss: 2.54250449e-06
Iter: 715 loss: 2.54116185e-06
Iter: 716 loss: 2.53753979e-06
Iter: 717 loss: 2.57337229e-06
Iter: 718 loss: 2.53709641e-06
Iter: 719 loss: 2.53396365e-06
Iter: 720 loss: 2.55242389e-06
Iter: 721 loss: 2.53346025e-06
Iter: 722 loss: 2.53194389e-06
Iter: 723 loss: 2.52903919e-06
Iter: 724 loss: 2.52901964e-06
Iter: 725 loss: 2.52753716e-06
Iter: 726 loss: 2.52691234e-06
Iter: 727 loss: 2.52569407e-06
Iter: 728 loss: 2.52862537e-06
Iter: 729 loss: 2.52532436e-06
Iter: 730 loss: 2.52351242e-06
Iter: 731 loss: 2.52118934e-06
Iter: 732 loss: 2.52116615e-06
Iter: 733 loss: 2.51859274e-06
Iter: 734 loss: 2.5356776e-06
Iter: 735 loss: 2.51833626e-06
Iter: 736 loss: 2.51618326e-06
Iter: 737 loss: 2.51386723e-06
Iter: 738 loss: 2.51356028e-06
Iter: 739 loss: 2.5110869e-06
Iter: 740 loss: 2.51106985e-06
Iter: 741 loss: 2.50910921e-06
Iter: 742 loss: 2.506996e-06
Iter: 743 loss: 2.50678113e-06
Iter: 744 loss: 2.50409494e-06
Iter: 745 loss: 2.53048916e-06
Iter: 746 loss: 2.50408493e-06
Iter: 747 loss: 2.50176276e-06
Iter: 748 loss: 2.51118331e-06
Iter: 749 loss: 2.50132052e-06
Iter: 750 loss: 2.49950267e-06
Iter: 751 loss: 2.51872325e-06
Iter: 752 loss: 2.49928371e-06
Iter: 753 loss: 2.49840878e-06
Iter: 754 loss: 2.49843652e-06
Iter: 755 loss: 2.49761865e-06
Iter: 756 loss: 2.49562163e-06
Iter: 757 loss: 2.49262871e-06
Iter: 758 loss: 2.49256186e-06
Iter: 759 loss: 2.49166351e-06
Iter: 760 loss: 2.49075356e-06
Iter: 761 loss: 2.48965193e-06
Iter: 762 loss: 2.48842161e-06
Iter: 763 loss: 2.48818606e-06
Iter: 764 loss: 2.4857668e-06
Iter: 765 loss: 2.48730589e-06
Iter: 766 loss: 2.48405104e-06
Iter: 767 loss: 2.48211973e-06
Iter: 768 loss: 2.48662036e-06
Iter: 769 loss: 2.48144033e-06
Iter: 770 loss: 2.47875255e-06
Iter: 771 loss: 2.47915978e-06
Iter: 772 loss: 2.47678781e-06
Iter: 773 loss: 2.47441517e-06
Iter: 774 loss: 2.49551385e-06
Iter: 775 loss: 2.47444495e-06
Iter: 776 loss: 2.47230651e-06
Iter: 777 loss: 2.47243247e-06
Iter: 778 loss: 2.47065509e-06
Iter: 779 loss: 2.46814898e-06
Iter: 780 loss: 2.47575326e-06
Iter: 781 loss: 2.46755917e-06
Iter: 782 loss: 2.46520267e-06
Iter: 783 loss: 2.48791366e-06
Iter: 784 loss: 2.46522086e-06
Iter: 785 loss: 2.46377863e-06
Iter: 786 loss: 2.47959906e-06
Iter: 787 loss: 2.46368472e-06
Iter: 788 loss: 2.46301033e-06
Iter: 789 loss: 2.46124227e-06
Iter: 790 loss: 2.48068068e-06
Iter: 791 loss: 2.46121135e-06
Iter: 792 loss: 2.45847218e-06
Iter: 793 loss: 2.46715e-06
Iter: 794 loss: 2.45774777e-06
Iter: 795 loss: 2.45577849e-06
Iter: 796 loss: 2.45575984e-06
Iter: 797 loss: 2.45483216e-06
Iter: 798 loss: 2.45329989e-06
Iter: 799 loss: 2.45343927e-06
Iter: 800 loss: 2.45103274e-06
Iter: 801 loss: 2.4579258e-06
Iter: 802 loss: 2.45037745e-06
Iter: 803 loss: 2.44852617e-06
Iter: 804 loss: 2.44761577e-06
Iter: 805 loss: 2.44669e-06
Iter: 806 loss: 2.44447392e-06
Iter: 807 loss: 2.47088e-06
Iter: 808 loss: 2.44427633e-06
Iter: 809 loss: 2.44290777e-06
Iter: 810 loss: 2.44016269e-06
Iter: 811 loss: 2.44022249e-06
Iter: 812 loss: 2.43801401e-06
Iter: 813 loss: 2.4379508e-06
Iter: 814 loss: 2.43618115e-06
Iter: 815 loss: 2.4391245e-06
Iter: 816 loss: 2.43547674e-06
Iter: 817 loss: 2.43376599e-06
Iter: 818 loss: 2.45783895e-06
Iter: 819 loss: 2.43368186e-06
Iter: 820 loss: 2.4329081e-06
Iter: 821 loss: 2.43320619e-06
Iter: 822 loss: 2.43236309e-06
Iter: 823 loss: 2.43114687e-06
Iter: 824 loss: 2.42949272e-06
Iter: 825 loss: 2.42943088e-06
Iter: 826 loss: 2.42692568e-06
Iter: 827 loss: 2.45231467e-06
Iter: 828 loss: 2.42693886e-06
Iter: 829 loss: 2.42536726e-06
Iter: 830 loss: 2.43311433e-06
Iter: 831 loss: 2.42514307e-06
Iter: 832 loss: 2.42419219e-06
Iter: 833 loss: 2.42192209e-06
Iter: 834 loss: 2.45485762e-06
Iter: 835 loss: 2.42207261e-06
Iter: 836 loss: 2.41890893e-06
Iter: 837 loss: 2.43986e-06
Iter: 838 loss: 2.41883708e-06
Iter: 839 loss: 2.41749831e-06
Iter: 840 loss: 2.41625594e-06
Iter: 841 loss: 2.41588532e-06
Iter: 842 loss: 2.41311363e-06
Iter: 843 loss: 2.4288056e-06
Iter: 844 loss: 2.41295083e-06
Iter: 845 loss: 2.41152202e-06
Iter: 846 loss: 2.40968166e-06
Iter: 847 loss: 2.40951226e-06
Iter: 848 loss: 2.4063404e-06
Iter: 849 loss: 2.43855015e-06
Iter: 850 loss: 2.40625332e-06
Iter: 851 loss: 2.40509053e-06
Iter: 852 loss: 2.40503459e-06
Iter: 853 loss: 2.40390909e-06
Iter: 854 loss: 2.40248369e-06
Iter: 855 loss: 2.40232e-06
Iter: 856 loss: 2.4005e-06
Iter: 857 loss: 2.40949703e-06
Iter: 858 loss: 2.40006898e-06
Iter: 859 loss: 2.39882434e-06
Iter: 860 loss: 2.40310669e-06
Iter: 861 loss: 2.39847577e-06
Iter: 862 loss: 2.39692827e-06
Iter: 863 loss: 2.39879614e-06
Iter: 864 loss: 2.39601172e-06
Iter: 865 loss: 2.39432029e-06
Iter: 866 loss: 2.39675865e-06
Iter: 867 loss: 2.39343649e-06
Iter: 868 loss: 2.39152087e-06
Iter: 869 loss: 2.39175847e-06
Iter: 870 loss: 2.39001383e-06
Iter: 871 loss: 2.38715961e-06
Iter: 872 loss: 2.40402414e-06
Iter: 873 loss: 2.38686425e-06
Iter: 874 loss: 2.38524945e-06
Iter: 875 loss: 2.38388861e-06
Iter: 876 loss: 2.38342386e-06
Iter: 877 loss: 2.38050757e-06
Iter: 878 loss: 2.40267445e-06
Iter: 879 loss: 2.38036773e-06
Iter: 880 loss: 2.37878044e-06
Iter: 881 loss: 2.37768609e-06
Iter: 882 loss: 2.37719223e-06
Iter: 883 loss: 2.37456152e-06
Iter: 884 loss: 2.40037207e-06
Iter: 885 loss: 2.37450558e-06
Iter: 886 loss: 2.37314043e-06
Iter: 887 loss: 2.3879943e-06
Iter: 888 loss: 2.37308382e-06
Iter: 889 loss: 2.37139579e-06
Iter: 890 loss: 2.36853566e-06
Iter: 891 loss: 2.36856704e-06
Iter: 892 loss: 2.36610344e-06
Iter: 893 loss: 2.39066367e-06
Iter: 894 loss: 2.36595451e-06
Iter: 895 loss: 2.36495475e-06
Iter: 896 loss: 2.37277436e-06
Iter: 897 loss: 2.36483356e-06
Iter: 898 loss: 2.36350365e-06
Iter: 899 loss: 2.36125084e-06
Iter: 900 loss: 2.41421139e-06
Iter: 901 loss: 2.36133337e-06
Iter: 902 loss: 2.35912376e-06
Iter: 903 loss: 2.37667882e-06
Iter: 904 loss: 2.3588932e-06
Iter: 905 loss: 2.35756261e-06
Iter: 906 loss: 2.35838297e-06
Iter: 907 loss: 2.35676771e-06
Iter: 908 loss: 2.35434914e-06
Iter: 909 loss: 2.3556172e-06
Iter: 910 loss: 2.35289417e-06
Iter: 911 loss: 2.35067864e-06
Iter: 912 loss: 2.35378661e-06
Iter: 913 loss: 2.34978484e-06
Iter: 914 loss: 2.34685604e-06
Iter: 915 loss: 2.35616881e-06
Iter: 916 loss: 2.34592744e-06
Iter: 917 loss: 2.34395475e-06
Iter: 918 loss: 2.34455933e-06
Iter: 919 loss: 2.34249546e-06
Iter: 920 loss: 2.3401326e-06
Iter: 921 loss: 2.34018034e-06
Iter: 922 loss: 2.33894252e-06
Iter: 923 loss: 2.35942412e-06
Iter: 924 loss: 2.33879246e-06
Iter: 925 loss: 2.33820492e-06
Iter: 926 loss: 2.33659648e-06
Iter: 927 loss: 2.35012794e-06
Iter: 928 loss: 2.33632068e-06
Iter: 929 loss: 2.33383298e-06
Iter: 930 loss: 2.34600088e-06
Iter: 931 loss: 2.33331184e-06
Iter: 932 loss: 2.33185847e-06
Iter: 933 loss: 2.33190667e-06
Iter: 934 loss: 2.33093169e-06
Iter: 935 loss: 2.3289283e-06
Iter: 936 loss: 2.36098685e-06
Iter: 937 loss: 2.32875527e-06
Iter: 938 loss: 2.32671937e-06
Iter: 939 loss: 2.34056552e-06
Iter: 940 loss: 2.32654816e-06
Iter: 941 loss: 2.32462662e-06
Iter: 942 loss: 2.32449e-06
Iter: 943 loss: 2.32304956e-06
Iter: 944 loss: 2.32026878e-06
Iter: 945 loss: 2.33674677e-06
Iter: 946 loss: 2.31993727e-06
Iter: 947 loss: 2.31809099e-06
Iter: 948 loss: 2.31631884e-06
Iter: 949 loss: 2.31598074e-06
Iter: 950 loss: 2.31296985e-06
Iter: 951 loss: 2.34379672e-06
Iter: 952 loss: 2.31281706e-06
Iter: 953 loss: 2.31115155e-06
Iter: 954 loss: 2.31189279e-06
Iter: 955 loss: 2.31009381e-06
Iter: 956 loss: 2.30868022e-06
Iter: 957 loss: 2.30847081e-06
Iter: 958 loss: 2.30729188e-06
Iter: 959 loss: 2.30943238e-06
Iter: 960 loss: 2.30687601e-06
Iter: 961 loss: 2.30580099e-06
Iter: 962 loss: 2.30381488e-06
Iter: 963 loss: 2.34263098e-06
Iter: 964 loss: 2.3038051e-06
Iter: 965 loss: 2.30108731e-06
Iter: 966 loss: 2.32914249e-06
Iter: 967 loss: 2.30116234e-06
Iter: 968 loss: 2.29983107e-06
Iter: 969 loss: 2.30601427e-06
Iter: 970 loss: 2.29956049e-06
Iter: 971 loss: 2.29849888e-06
Iter: 972 loss: 2.29577358e-06
Iter: 973 loss: 2.32227603e-06
Iter: 974 loss: 2.29555917e-06
Iter: 975 loss: 2.29291936e-06
Iter: 976 loss: 2.29294437e-06
Iter: 977 loss: 2.29169382e-06
Iter: 978 loss: 2.29119178e-06
Iter: 979 loss: 2.2905042e-06
Iter: 980 loss: 2.28836825e-06
Iter: 981 loss: 2.29488023e-06
Iter: 982 loss: 2.28749468e-06
Iter: 983 loss: 2.28560884e-06
Iter: 984 loss: 2.28619683e-06
Iter: 985 loss: 2.28411045e-06
Iter: 986 loss: 2.28178783e-06
Iter: 987 loss: 2.30091405e-06
Iter: 988 loss: 2.28153704e-06
Iter: 989 loss: 2.28018143e-06
Iter: 990 loss: 2.28955878e-06
Iter: 991 loss: 2.28005865e-06
Iter: 992 loss: 2.27845248e-06
Iter: 993 loss: 2.28200952e-06
Iter: 994 loss: 2.27781288e-06
Iter: 995 loss: 2.27673445e-06
Iter: 996 loss: 2.27824603e-06
Iter: 997 loss: 2.27618648e-06
Iter: 998 loss: 2.27510577e-06
Iter: 999 loss: 2.27589862e-06
Iter: 1000 loss: 2.27426472e-06
Iter: 1001 loss: 2.27251121e-06
Iter: 1002 loss: 2.28463273e-06
Iter: 1003 loss: 2.27228406e-06
Iter: 1004 loss: 2.27127703e-06
Iter: 1005 loss: 2.27127703e-06
Iter: 1006 loss: 2.27053556e-06
Iter: 1007 loss: 2.26867473e-06
Iter: 1008 loss: 2.26745397e-06
Iter: 1009 loss: 2.26686643e-06
Iter: 1010 loss: 2.26523071e-06
Iter: 1011 loss: 2.26522116e-06
Iter: 1012 loss: 2.26404518e-06
Iter: 1013 loss: 2.26197562e-06
Iter: 1014 loss: 2.2620261e-06
Iter: 1015 loss: 2.2604811e-06
Iter: 1016 loss: 2.26056295e-06
Iter: 1017 loss: 2.25933e-06
Iter: 1018 loss: 2.25707299e-06
Iter: 1019 loss: 2.30280784e-06
Iter: 1020 loss: 2.25707663e-06
Iter: 1021 loss: 2.25566646e-06
Iter: 1022 loss: 2.2555364e-06
Iter: 1023 loss: 2.25464692e-06
Iter: 1024 loss: 2.26568159e-06
Iter: 1025 loss: 2.25460735e-06
Iter: 1026 loss: 2.25352e-06
Iter: 1027 loss: 2.25251506e-06
Iter: 1028 loss: 2.25245049e-06
Iter: 1029 loss: 2.25120766e-06
Iter: 1030 loss: 2.25690064e-06
Iter: 1031 loss: 2.25099279e-06
Iter: 1032 loss: 2.25025565e-06
Iter: 1033 loss: 2.25076201e-06
Iter: 1034 loss: 2.24972564e-06
Iter: 1035 loss: 2.2483157e-06
Iter: 1036 loss: 2.24862333e-06
Iter: 1037 loss: 2.2472484e-06
Iter: 1038 loss: 2.24620089e-06
Iter: 1039 loss: 2.25262988e-06
Iter: 1040 loss: 2.24598375e-06
Iter: 1041 loss: 2.24491441e-06
Iter: 1042 loss: 2.24328505e-06
Iter: 1043 loss: 2.24334099e-06
Iter: 1044 loss: 2.24204928e-06
Iter: 1045 loss: 2.24202222e-06
Iter: 1046 loss: 2.24097357e-06
Iter: 1047 loss: 2.23949451e-06
Iter: 1048 loss: 2.2394911e-06
Iter: 1049 loss: 2.23813868e-06
Iter: 1050 loss: 2.25839153e-06
Iter: 1051 loss: 2.23799975e-06
Iter: 1052 loss: 2.2368406e-06
Iter: 1053 loss: 2.23575262e-06
Iter: 1054 loss: 2.23545567e-06
Iter: 1055 loss: 2.23526445e-06
Iter: 1056 loss: 2.23462e-06
Iter: 1057 loss: 2.23408097e-06
Iter: 1058 loss: 2.23626694e-06
Iter: 1059 loss: 2.23387497e-06
Iter: 1060 loss: 2.23326037e-06
Iter: 1061 loss: 2.23174629e-06
Iter: 1062 loss: 2.24779069e-06
Iter: 1063 loss: 2.23144798e-06
Iter: 1064 loss: 2.23000916e-06
Iter: 1065 loss: 2.24644577e-06
Iter: 1066 loss: 2.22996914e-06
Iter: 1067 loss: 2.22904168e-06
Iter: 1068 loss: 2.23034431e-06
Iter: 1069 loss: 2.22877361e-06
Iter: 1070 loss: 2.22734593e-06
Iter: 1071 loss: 2.22467452e-06
Iter: 1072 loss: 2.224637e-06
Iter: 1073 loss: 2.22347444e-06
Iter: 1074 loss: 2.22342715e-06
Iter: 1075 loss: 2.22235963e-06
Iter: 1076 loss: 2.22137714e-06
Iter: 1077 loss: 2.22117251e-06
Iter: 1078 loss: 2.21968389e-06
Iter: 1079 loss: 2.23648613e-06
Iter: 1080 loss: 2.21977507e-06
Iter: 1081 loss: 2.21849677e-06
Iter: 1082 loss: 2.21613436e-06
Iter: 1083 loss: 2.26345946e-06
Iter: 1084 loss: 2.21602272e-06
Iter: 1085 loss: 2.21509799e-06
Iter: 1086 loss: 2.21477558e-06
Iter: 1087 loss: 2.21392884e-06
Iter: 1088 loss: 2.21228152e-06
Iter: 1089 loss: 2.21241044e-06
Iter: 1090 loss: 2.21185337e-06
Iter: 1091 loss: 2.21167193e-06
Iter: 1092 loss: 2.21099754e-06
Iter: 1093 loss: 2.21401615e-06
Iter: 1094 loss: 2.21084474e-06
Iter: 1095 loss: 2.21004234e-06
Iter: 1096 loss: 2.20940728e-06
Iter: 1097 loss: 2.20910306e-06
Iter: 1098 loss: 2.20820061e-06
Iter: 1099 loss: 2.21729e-06
Iter: 1100 loss: 2.20819493e-06
Iter: 1101 loss: 2.20729225e-06
Iter: 1102 loss: 2.20656e-06
Iter: 1103 loss: 2.20611651e-06
Iter: 1104 loss: 2.20444645e-06
Iter: 1105 loss: 2.2122249e-06
Iter: 1106 loss: 2.20429911e-06
Iter: 1107 loss: 2.20311153e-06
Iter: 1108 loss: 2.20251286e-06
Iter: 1109 loss: 2.20204788e-06
Iter: 1110 loss: 2.20027664e-06
Iter: 1111 loss: 2.21414598e-06
Iter: 1112 loss: 2.20015e-06
Iter: 1113 loss: 2.19899084e-06
Iter: 1114 loss: 2.19773256e-06
Iter: 1115 loss: 2.19744447e-06
Iter: 1116 loss: 2.19524281e-06
Iter: 1117 loss: 2.21394157e-06
Iter: 1118 loss: 2.1951364e-06
Iter: 1119 loss: 2.19391336e-06
Iter: 1120 loss: 2.19543972e-06
Iter: 1121 loss: 2.19332946e-06
Iter: 1122 loss: 2.19191975e-06
Iter: 1123 loss: 2.20181801e-06
Iter: 1124 loss: 2.19173853e-06
Iter: 1125 loss: 2.19075537e-06
Iter: 1126 loss: 2.19870435e-06
Iter: 1127 loss: 2.1906485e-06
Iter: 1128 loss: 2.19017693e-06
Iter: 1129 loss: 2.18882269e-06
Iter: 1130 loss: 2.19835442e-06
Iter: 1131 loss: 2.18852756e-06
Iter: 1132 loss: 2.18692276e-06
Iter: 1133 loss: 2.201298e-06
Iter: 1134 loss: 2.18683272e-06
Iter: 1135 loss: 2.18573791e-06
Iter: 1136 loss: 2.18695141e-06
Iter: 1137 loss: 2.18526088e-06
Iter: 1138 loss: 2.18331456e-06
Iter: 1139 loss: 2.18839023e-06
Iter: 1140 loss: 2.18271794e-06
Iter: 1141 loss: 2.18175228e-06
Iter: 1142 loss: 2.1853125e-06
Iter: 1143 loss: 2.18155901e-06
Iter: 1144 loss: 2.18038508e-06
Iter: 1145 loss: 2.17922434e-06
Iter: 1146 loss: 2.17899014e-06
Iter: 1147 loss: 2.17782735e-06
Iter: 1148 loss: 2.19502726e-06
Iter: 1149 loss: 2.17790762e-06
Iter: 1150 loss: 2.17678462e-06
Iter: 1151 loss: 2.17583806e-06
Iter: 1152 loss: 2.17549e-06
Iter: 1153 loss: 2.17436286e-06
Iter: 1154 loss: 2.18930245e-06
Iter: 1155 loss: 2.17418915e-06
Iter: 1156 loss: 2.1730973e-06
Iter: 1157 loss: 2.17894171e-06
Iter: 1158 loss: 2.17304068e-06
Iter: 1159 loss: 2.17207366e-06
Iter: 1160 loss: 2.18111654e-06
Iter: 1161 loss: 2.1720075e-06
Iter: 1162 loss: 2.17145089e-06
Iter: 1163 loss: 2.17017987e-06
Iter: 1164 loss: 2.1873534e-06
Iter: 1165 loss: 2.17007937e-06
Iter: 1166 loss: 2.16840544e-06
Iter: 1167 loss: 2.17363095e-06
Iter: 1168 loss: 2.16799344e-06
Iter: 1169 loss: 2.16722e-06
Iter: 1170 loss: 2.16880471e-06
Iter: 1171 loss: 2.16667058e-06
Iter: 1172 loss: 2.16583567e-06
Iter: 1173 loss: 2.1812964e-06
Iter: 1174 loss: 2.16573585e-06
Iter: 1175 loss: 2.16511785e-06
Iter: 1176 loss: 2.16426133e-06
Iter: 1177 loss: 2.16419016e-06
Iter: 1178 loss: 2.16265516e-06
Iter: 1179 loss: 2.16514468e-06
Iter: 1180 loss: 2.16201443e-06
Iter: 1181 loss: 2.16085346e-06
Iter: 1182 loss: 2.16231979e-06
Iter: 1183 loss: 2.16009153e-06
Iter: 1184 loss: 2.15822524e-06
Iter: 1185 loss: 2.16236572e-06
Iter: 1186 loss: 2.15755585e-06
Iter: 1187 loss: 2.15626e-06
Iter: 1188 loss: 2.16148192e-06
Iter: 1189 loss: 2.15609316e-06
Iter: 1190 loss: 2.1548185e-06
Iter: 1191 loss: 2.16962781e-06
Iter: 1192 loss: 2.1548442e-06
Iter: 1193 loss: 2.15420687e-06
Iter: 1194 loss: 2.1619353e-06
Iter: 1195 loss: 2.15414912e-06
Iter: 1196 loss: 2.15369937e-06
Iter: 1197 loss: 2.15247383e-06
Iter: 1198 loss: 2.1622177e-06
Iter: 1199 loss: 2.15231466e-06
Iter: 1200 loss: 2.15023556e-06
Iter: 1201 loss: 2.15739965e-06
Iter: 1202 loss: 2.14991928e-06
Iter: 1203 loss: 2.149e-06
Iter: 1204 loss: 2.14994407e-06
Iter: 1205 loss: 2.14839429e-06
Iter: 1206 loss: 2.14698866e-06
Iter: 1207 loss: 2.15591399e-06
Iter: 1208 loss: 2.14686315e-06
Iter: 1209 loss: 2.14590523e-06
Iter: 1210 loss: 2.15475711e-06
Iter: 1211 loss: 2.14596457e-06
Iter: 1212 loss: 2.14513921e-06
Iter: 1213 loss: 2.14419583e-06
Iter: 1214 loss: 2.14404076e-06
Iter: 1215 loss: 2.14308193e-06
Iter: 1216 loss: 2.14591523e-06
Iter: 1217 loss: 2.14265424e-06
Iter: 1218 loss: 2.14117495e-06
Iter: 1219 loss: 2.14321881e-06
Iter: 1220 loss: 2.14045986e-06
Iter: 1221 loss: 2.13931844e-06
Iter: 1222 loss: 2.14348506e-06
Iter: 1223 loss: 2.13903058e-06
Iter: 1224 loss: 2.13781118e-06
Iter: 1225 loss: 2.14317242e-06
Iter: 1226 loss: 2.13749013e-06
Iter: 1227 loss: 2.13694489e-06
Iter: 1228 loss: 2.13684416e-06
Iter: 1229 loss: 2.1363453e-06
Iter: 1230 loss: 2.13501744e-06
Iter: 1231 loss: 2.14728425e-06
Iter: 1232 loss: 2.13499925e-06
Iter: 1233 loss: 2.13335056e-06
Iter: 1234 loss: 2.13576095e-06
Iter: 1235 loss: 2.132389e-06
Iter: 1236 loss: 2.13156045e-06
Iter: 1237 loss: 2.13469639e-06
Iter: 1238 loss: 2.13120506e-06
Iter: 1239 loss: 2.12982059e-06
Iter: 1240 loss: 2.1294868e-06
Iter: 1241 loss: 2.12868895e-06
Iter: 1242 loss: 2.12799e-06
Iter: 1243 loss: 2.12793952e-06
Iter: 1244 loss: 2.12707141e-06
Iter: 1245 loss: 2.12564464e-06
Iter: 1246 loss: 2.15795399e-06
Iter: 1247 loss: 2.12557188e-06
Iter: 1248 loss: 2.12417399e-06
Iter: 1249 loss: 2.13549401e-06
Iter: 1250 loss: 2.12403438e-06
Iter: 1251 loss: 2.12287978e-06
Iter: 1252 loss: 2.12313603e-06
Iter: 1253 loss: 2.12189798e-06
Iter: 1254 loss: 2.12080249e-06
Iter: 1255 loss: 2.12950499e-06
Iter: 1256 loss: 2.12071586e-06
Iter: 1257 loss: 2.11966017e-06
Iter: 1258 loss: 2.12086911e-06
Iter: 1259 loss: 2.11902807e-06
Iter: 1260 loss: 2.11854058e-06
Iter: 1261 loss: 2.11855377e-06
Iter: 1262 loss: 2.11783572e-06
Iter: 1263 loss: 2.11681436e-06
Iter: 1264 loss: 2.11690349e-06
Iter: 1265 loss: 2.11540851e-06
Iter: 1266 loss: 2.11837414e-06
Iter: 1267 loss: 2.11484712e-06
Iter: 1268 loss: 2.11382053e-06
Iter: 1269 loss: 2.11389511e-06
Iter: 1270 loss: 2.11308293e-06
Iter: 1271 loss: 2.11131078e-06
Iter: 1272 loss: 2.11622682e-06
Iter: 1273 loss: 2.1109056e-06
Iter: 1274 loss: 2.10996814e-06
Iter: 1275 loss: 2.12054101e-06
Iter: 1276 loss: 2.10977623e-06
Iter: 1277 loss: 2.10893177e-06
Iter: 1278 loss: 2.10849794e-06
Iter: 1279 loss: 2.10787016e-06
Iter: 1280 loss: 2.10637131e-06
Iter: 1281 loss: 2.11622273e-06
Iter: 1282 loss: 2.10626899e-06
Iter: 1283 loss: 2.10537519e-06
Iter: 1284 loss: 2.10373037e-06
Iter: 1285 loss: 2.13420162e-06
Iter: 1286 loss: 2.10365056e-06
Iter: 1287 loss: 2.102e-06
Iter: 1288 loss: 2.10203643e-06
Iter: 1289 loss: 2.10083272e-06
Iter: 1290 loss: 2.10001781e-06
Iter: 1291 loss: 2.09951713e-06
Iter: 1292 loss: 2.09789323e-06
Iter: 1293 loss: 2.10080816e-06
Iter: 1294 loss: 2.09721588e-06
Iter: 1295 loss: 2.09522227e-06
Iter: 1296 loss: 2.12075929e-06
Iter: 1297 loss: 2.09518271e-06
Iter: 1298 loss: 2.09367499e-06
Iter: 1299 loss: 2.10503e-06
Iter: 1300 loss: 2.09352811e-06
Iter: 1301 loss: 2.09294785e-06
Iter: 1302 loss: 2.09174891e-06
Iter: 1303 loss: 2.09739619e-06
Iter: 1304 loss: 2.0913908e-06
Iter: 1305 loss: 2.08927099e-06
Iter: 1306 loss: 2.1050846e-06
Iter: 1307 loss: 2.08912388e-06
Iter: 1308 loss: 2.0882735e-06
Iter: 1309 loss: 2.08790493e-06
Iter: 1310 loss: 2.08737561e-06
Iter: 1311 loss: 2.08563119e-06
Iter: 1312 loss: 2.09301879e-06
Iter: 1313 loss: 2.08509209e-06
Iter: 1314 loss: 2.08424945e-06
Iter: 1315 loss: 2.09569771e-06
Iter: 1316 loss: 2.08432766e-06
Iter: 1317 loss: 2.08355323e-06
Iter: 1318 loss: 2.08189567e-06
Iter: 1319 loss: 2.11539555e-06
Iter: 1320 loss: 2.08206484e-06
Iter: 1321 loss: 2.0807347e-06
Iter: 1322 loss: 2.09771633e-06
Iter: 1323 loss: 2.08069901e-06
Iter: 1324 loss: 2.0796524e-06
Iter: 1325 loss: 2.07807398e-06
Iter: 1326 loss: 2.07811354e-06
Iter: 1327 loss: 2.07702328e-06
Iter: 1328 loss: 2.07690641e-06
Iter: 1329 loss: 2.07624498e-06
Iter: 1330 loss: 2.07507037e-06
Iter: 1331 loss: 2.07478524e-06
Iter: 1332 loss: 2.07451717e-06
Iter: 1333 loss: 2.07419248e-06
Iter: 1334 loss: 2.07350649e-06
Iter: 1335 loss: 2.0770849e-06
Iter: 1336 loss: 2.07347784e-06
Iter: 1337 loss: 2.07285802e-06
Iter: 1338 loss: 2.07152516e-06
Iter: 1339 loss: 2.08794359e-06
Iter: 1340 loss: 2.07157564e-06
Iter: 1341 loss: 2.07037e-06
Iter: 1342 loss: 2.08062147e-06
Iter: 1343 loss: 2.07033077e-06
Iter: 1344 loss: 2.06951108e-06
Iter: 1345 loss: 2.06837512e-06
Iter: 1346 loss: 2.06840105e-06
Iter: 1347 loss: 2.0669338e-06
Iter: 1348 loss: 2.08470328e-06
Iter: 1349 loss: 2.06691448e-06
Iter: 1350 loss: 2.06632603e-06
Iter: 1351 loss: 2.0700345e-06
Iter: 1352 loss: 2.06625e-06
Iter: 1353 loss: 2.06545019e-06
Iter: 1354 loss: 2.06585219e-06
Iter: 1355 loss: 2.06497452e-06
Iter: 1356 loss: 2.06420691e-06
Iter: 1357 loss: 2.06354071e-06
Iter: 1358 loss: 2.0634227e-06
Iter: 1359 loss: 2.06201776e-06
Iter: 1360 loss: 2.06693949e-06
Iter: 1361 loss: 2.06169489e-06
Iter: 1362 loss: 2.06069217e-06
Iter: 1363 loss: 2.05977449e-06
Iter: 1364 loss: 2.05965944e-06
Iter: 1365 loss: 2.05844162e-06
Iter: 1366 loss: 2.05841388e-06
Iter: 1367 loss: 2.05785864e-06
Iter: 1368 loss: 2.06434174e-06
Iter: 1369 loss: 2.0578193e-06
Iter: 1370 loss: 2.05731635e-06
Iter: 1371 loss: 2.05583456e-06
Iter: 1372 loss: 2.07246603e-06
Iter: 1373 loss: 2.05567176e-06
Iter: 1374 loss: 2.05444144e-06
Iter: 1375 loss: 2.06450864e-06
Iter: 1376 loss: 2.05446236e-06
Iter: 1377 loss: 2.05367542e-06
Iter: 1378 loss: 2.05219476e-06
Iter: 1379 loss: 2.08518622e-06
Iter: 1380 loss: 2.05221545e-06
Iter: 1381 loss: 2.05106517e-06
Iter: 1382 loss: 2.05097058e-06
Iter: 1383 loss: 2.05021638e-06
Iter: 1384 loss: 2.04969774e-06
Iter: 1385 loss: 2.04963135e-06
Iter: 1386 loss: 2.04809817e-06
Iter: 1387 loss: 2.05647484e-06
Iter: 1388 loss: 2.04796788e-06
Iter: 1389 loss: 2.0473085e-06
Iter: 1390 loss: 2.05081824e-06
Iter: 1391 loss: 2.04722892e-06
Iter: 1392 loss: 2.04653429e-06
Iter: 1393 loss: 2.04612797e-06
Iter: 1394 loss: 2.04578373e-06
Iter: 1395 loss: 2.04493426e-06
Iter: 1396 loss: 2.05158267e-06
Iter: 1397 loss: 2.04491289e-06
Iter: 1398 loss: 2.04422327e-06
Iter: 1399 loss: 2.0439179e-06
Iter: 1400 loss: 2.04349931e-06
Iter: 1401 loss: 2.04312391e-06
Iter: 1402 loss: 2.04302728e-06
Iter: 1403 loss: 2.0425714e-06
Iter: 1404 loss: 2.04379376e-06
Iter: 1405 loss: 2.04246226e-06
Iter: 1406 loss: 2.04192452e-06
Iter: 1407 loss: 2.04109892e-06
Iter: 1408 loss: 2.06259506e-06
Iter: 1409 loss: 2.0410971e-06
Iter: 1410 loss: 2.04046137e-06
Iter: 1411 loss: 2.04629032e-06
Iter: 1412 loss: 2.04044773e-06
Iter: 1413 loss: 2.03982449e-06
Iter: 1414 loss: 2.03889135e-06
Iter: 1415 loss: 2.03880199e-06
Iter: 1416 loss: 2.03817444e-06
Iter: 1417 loss: 2.04671187e-06
Iter: 1418 loss: 2.0381442e-06
Iter: 1419 loss: 2.03720856e-06
Iter: 1420 loss: 2.03741229e-06
Iter: 1421 loss: 2.03659374e-06
Iter: 1422 loss: 2.03586933e-06
Iter: 1423 loss: 2.04472872e-06
Iter: 1424 loss: 2.03586524e-06
Iter: 1425 loss: 2.03514833e-06
Iter: 1426 loss: 2.0365303e-06
Iter: 1427 loss: 2.03515037e-06
Iter: 1428 loss: 2.03420427e-06
Iter: 1429 loss: 2.03552554e-06
Iter: 1430 loss: 2.03380614e-06
Iter: 1431 loss: 2.03331638e-06
Iter: 1432 loss: 2.03372792e-06
Iter: 1433 loss: 2.03320906e-06
Iter: 1434 loss: 2.03243326e-06
Iter: 1435 loss: 2.03272589e-06
Iter: 1436 loss: 2.03180525e-06
Iter: 1437 loss: 2.03205673e-06
Iter: 1438 loss: 2.03141735e-06
Iter: 1439 loss: 2.03129207e-06
Iter: 1440 loss: 2.03082664e-06
Iter: 1441 loss: 2.03982586e-06
Iter: 1442 loss: 2.03078798e-06
Iter: 1443 loss: 2.03017908e-06
Iter: 1444 loss: 2.02993124e-06
Iter: 1445 loss: 2.02953925e-06
Iter: 1446 loss: 2.02878232e-06
Iter: 1447 loss: 2.02943897e-06
Iter: 1448 loss: 2.02814681e-06
Iter: 1449 loss: 2.02747378e-06
Iter: 1450 loss: 2.02737647e-06
Iter: 1451 loss: 2.02680053e-06
Iter: 1452 loss: 2.02591195e-06
Iter: 1453 loss: 2.02589899e-06
Iter: 1454 loss: 2.02504089e-06
Iter: 1455 loss: 2.02508659e-06
Iter: 1456 loss: 2.02444198e-06
Iter: 1457 loss: 2.02386514e-06
Iter: 1458 loss: 2.02373076e-06
Iter: 1459 loss: 2.02256479e-06
Iter: 1460 loss: 2.03077479e-06
Iter: 1461 loss: 2.02255592e-06
Iter: 1462 loss: 2.02193405e-06
Iter: 1463 loss: 2.02365163e-06
Iter: 1464 loss: 2.0216421e-06
Iter: 1465 loss: 2.02108e-06
Iter: 1466 loss: 2.01950661e-06
Iter: 1467 loss: 2.036144e-06
Iter: 1468 loss: 2.01945022e-06
Iter: 1469 loss: 2.01918465e-06
Iter: 1470 loss: 2.01867897e-06
Iter: 1471 loss: 2.01820671e-06
Iter: 1472 loss: 2.02315391e-06
Iter: 1473 loss: 2.01826288e-06
Iter: 1474 loss: 2.01759212e-06
Iter: 1475 loss: 2.01662374e-06
Iter: 1476 loss: 2.029808e-06
Iter: 1477 loss: 2.01659236e-06
Iter: 1478 loss: 2.01574267e-06
Iter: 1479 loss: 2.02256115e-06
Iter: 1480 loss: 2.01571629e-06
Iter: 1481 loss: 2.01493026e-06
Iter: 1482 loss: 2.01362354e-06
Iter: 1483 loss: 2.03913214e-06
Iter: 1484 loss: 2.01352259e-06
Iter: 1485 loss: 2.01262264e-06
Iter: 1486 loss: 2.01260764e-06
Iter: 1487 loss: 2.01177477e-06
Iter: 1488 loss: 2.01091393e-06
Iter: 1489 loss: 2.01075386e-06
Iter: 1490 loss: 2.00973182e-06
Iter: 1491 loss: 2.01564353e-06
Iter: 1492 loss: 2.00964564e-06
Iter: 1493 loss: 2.0087698e-06
Iter: 1494 loss: 2.00825752e-06
Iter: 1495 loss: 2.00805698e-06
Iter: 1496 loss: 2.00752015e-06
Iter: 1497 loss: 2.0073403e-06
Iter: 1498 loss: 2.00683371e-06
Iter: 1499 loss: 2.00714931e-06
Iter: 1500 loss: 2.00643353e-06
Iter: 1501 loss: 2.00558861e-06
Iter: 1502 loss: 2.00583986e-06
Iter: 1503 loss: 2.00495606e-06
Iter: 1504 loss: 2.00444742e-06
Iter: 1505 loss: 2.00871227e-06
Iter: 1506 loss: 2.00433897e-06
Iter: 1507 loss: 2.00381828e-06
Iter: 1508 loss: 2.00528348e-06
Iter: 1509 loss: 2.00349132e-06
Iter: 1510 loss: 2.00299064e-06
Iter: 1511 loss: 2.00239492e-06
Iter: 1512 loss: 2.00210525e-06
Iter: 1513 loss: 2.00148088e-06
Iter: 1514 loss: 2.00223485e-06
Iter: 1515 loss: 2.00117393e-06
Iter: 1516 loss: 2.00030922e-06
Iter: 1517 loss: 2.00354407e-06
Iter: 1518 loss: 2.00010913e-06
Iter: 1519 loss: 1.99940587e-06
Iter: 1520 loss: 1.99889678e-06
Iter: 1521 loss: 1.99863052e-06
Iter: 1522 loss: 1.99759552e-06
Iter: 1523 loss: 2.01238527e-06
Iter: 1524 loss: 1.99748297e-06
Iter: 1525 loss: 1.99683655e-06
Iter: 1526 loss: 1.99675105e-06
Iter: 1527 loss: 1.99625788e-06
Iter: 1528 loss: 1.99553028e-06
Iter: 1529 loss: 2.00668796e-06
Iter: 1530 loss: 1.99561e-06
Iter: 1531 loss: 1.99522788e-06
Iter: 1532 loss: 1.99674787e-06
Iter: 1533 loss: 1.9952613e-06
Iter: 1534 loss: 1.9947845e-06
Iter: 1535 loss: 1.99519036e-06
Iter: 1536 loss: 1.99471333e-06
Iter: 1537 loss: 1.99417309e-06
Iter: 1538 loss: 1.99655142e-06
Iter: 1539 loss: 1.99414353e-06
Iter: 1540 loss: 1.99393162e-06
Iter: 1541 loss: 1.99570422e-06
Iter: 1542 loss: 1.99389092e-06
Iter: 1543 loss: 1.99361716e-06
Iter: 1544 loss: 1.99332612e-06
Iter: 1545 loss: 1.99327496e-06
Iter: 1546 loss: 1.99289479e-06
Iter: 1547 loss: 1.99266606e-06
Iter: 1548 loss: 1.99239093e-06
Iter: 1549 loss: 1.99191936e-06
Iter: 1550 loss: 1.99369106e-06
Iter: 1551 loss: 1.99166516e-06
Iter: 1552 loss: 1.99113492e-06
Iter: 1553 loss: 1.99261603e-06
Iter: 1554 loss: 1.99107171e-06
Iter: 1555 loss: 1.9905824e-06
Iter: 1556 loss: 1.99076067e-06
Iter: 1557 loss: 1.99018223e-06
Iter: 1558 loss: 1.98933e-06
Iter: 1559 loss: 1.9931058e-06
Iter: 1560 loss: 1.98923317e-06
Iter: 1561 loss: 1.98881071e-06
Iter: 1562 loss: 1.99229885e-06
Iter: 1563 loss: 1.98884027e-06
Iter: 1564 loss: 1.98857083e-06
Iter: 1565 loss: 1.98904354e-06
Iter: 1566 loss: 1.98837324e-06
Iter: 1567 loss: 1.987818e-06
Iter: 1568 loss: 1.99064743e-06
Iter: 1569 loss: 1.98774273e-06
Iter: 1570 loss: 1.98760972e-06
Iter: 1571 loss: 1.98837438e-06
Iter: 1572 loss: 1.98749535e-06
Iter: 1573 loss: 1.98715202e-06
Iter: 1574 loss: 1.98782891e-06
Iter: 1575 loss: 1.98713724e-06
Iter: 1576 loss: 1.9867764e-06
Iter: 1577 loss: 1.9871768e-06
Iter: 1578 loss: 1.98662337e-06
Iter: 1579 loss: 1.98627299e-06
Iter: 1580 loss: 1.98634848e-06
Iter: 1581 loss: 1.98605949e-06
Iter: 1582 loss: 1.98553744e-06
Iter: 1583 loss: 1.98539851e-06
Iter: 1584 loss: 1.98501812e-06
Iter: 1585 loss: 1.98442058e-06
Iter: 1586 loss: 1.98891803e-06
Iter: 1587 loss: 1.98447583e-06
Iter: 1588 loss: 1.98395628e-06
Iter: 1589 loss: 1.98316138e-06
Iter: 1590 loss: 1.98303724e-06
Iter: 1591 loss: 1.98247881e-06
Iter: 1592 loss: 1.99302758e-06
Iter: 1593 loss: 1.98249404e-06
Iter: 1594 loss: 1.98183943e-06
Iter: 1595 loss: 1.98247426e-06
Iter: 1596 loss: 1.98141879e-06
Iter: 1597 loss: 1.9809554e-06
Iter: 1598 loss: 1.98109183e-06
Iter: 1599 loss: 1.98084399e-06
Iter: 1600 loss: 1.98096927e-06
Iter: 1601 loss: 1.98056409e-06
Iter: 1602 loss: 1.98007729e-06
Iter: 1603 loss: 1.98086036e-06
Iter: 1604 loss: 1.97990789e-06
Iter: 1605 loss: 1.97942722e-06
Iter: 1606 loss: 1.97937334e-06
Iter: 1607 loss: 1.97920781e-06
Iter: 1608 loss: 1.97930649e-06
Iter: 1609 loss: 1.97900044e-06
Iter: 1610 loss: 1.97860072e-06
Iter: 1611 loss: 1.9780407e-06
Iter: 1612 loss: 1.99118722e-06
Iter: 1613 loss: 1.97793429e-06
Iter: 1614 loss: 1.97709733e-06
Iter: 1615 loss: 1.98536736e-06
Iter: 1616 loss: 1.97710074e-06
Iter: 1617 loss: 1.97666395e-06
Iter: 1618 loss: 1.97598138e-06
Iter: 1619 loss: 1.97599093e-06
Iter: 1620 loss: 1.97526469e-06
Iter: 1621 loss: 1.98580574e-06
Iter: 1622 loss: 1.97536792e-06
Iter: 1623 loss: 1.97477675e-06
Iter: 1624 loss: 1.97482632e-06
Iter: 1625 loss: 1.97442205e-06
Iter: 1626 loss: 1.97374811e-06
Iter: 1627 loss: 1.97991949e-06
Iter: 1628 loss: 1.97377449e-06
Iter: 1629 loss: 1.97330064e-06
Iter: 1630 loss: 1.97613144e-06
Iter: 1631 loss: 1.973287e-06
Iter: 1632 loss: 1.972993e-06
Iter: 1633 loss: 1.97252075e-06
Iter: 1634 loss: 1.97257259e-06
Iter: 1635 loss: 1.97201052e-06
Iter: 1636 loss: 1.97609984e-06
Iter: 1637 loss: 1.97205986e-06
Iter: 1638 loss: 1.97175905e-06
Iter: 1639 loss: 1.97400641e-06
Iter: 1640 loss: 1.97167856e-06
Iter: 1641 loss: 1.9714148e-06
Iter: 1642 loss: 1.97112945e-06
Iter: 1643 loss: 1.97104e-06
Iter: 1644 loss: 1.97037457e-06
Iter: 1645 loss: 1.97276177e-06
Iter: 1646 loss: 1.97040754e-06
Iter: 1647 loss: 1.96999054e-06
Iter: 1648 loss: 1.96970154e-06
Iter: 1649 loss: 1.96965539e-06
Iter: 1650 loss: 1.96891438e-06
Iter: 1651 loss: 1.97240161e-06
Iter: 1652 loss: 1.96888595e-06
Iter: 1653 loss: 1.96832798e-06
Iter: 1654 loss: 1.96858855e-06
Iter: 1655 loss: 1.96803171e-06
Iter: 1656 loss: 1.96758197e-06
Iter: 1657 loss: 1.97135728e-06
Iter: 1658 loss: 1.96744531e-06
Iter: 1659 loss: 1.96704605e-06
Iter: 1660 loss: 1.96838801e-06
Iter: 1661 loss: 1.96697965e-06
Iter: 1662 loss: 1.96665178e-06
Iter: 1663 loss: 1.96803649e-06
Iter: 1664 loss: 1.96661927e-06
Iter: 1665 loss: 1.96615338e-06
Iter: 1666 loss: 1.96874771e-06
Iter: 1667 loss: 1.96624114e-06
Iter: 1668 loss: 1.96597807e-06
Iter: 1669 loss: 1.96607061e-06
Iter: 1670 loss: 1.96590054e-06
Iter: 1671 loss: 1.9656195e-06
Iter: 1672 loss: 1.96747078e-06
Iter: 1673 loss: 1.96563951e-06
Iter: 1674 loss: 1.96519181e-06
Iter: 1675 loss: 1.96660267e-06
Iter: 1676 loss: 1.96520614e-06
Iter: 1677 loss: 1.96510359e-06
Iter: 1678 loss: 1.96476776e-06
Iter: 1679 loss: 1.96493e-06
Iter: 1680 loss: 1.96444353e-06
Iter: 1681 loss: 1.96429073e-06
Iter: 1682 loss: 1.96416522e-06
Iter: 1683 loss: 1.96360293e-06
Iter: 1684 loss: 1.96604014e-06
Iter: 1685 loss: 1.96365727e-06
Iter: 1686 loss: 1.96302653e-06
Iter: 1687 loss: 1.96298288e-06
Iter: 1688 loss: 1.96274141e-06
Iter: 1689 loss: 1.96232031e-06
Iter: 1690 loss: 1.96824749e-06
Iter: 1691 loss: 1.96231326e-06
Iter: 1692 loss: 1.96203109e-06
Iter: 1693 loss: 1.96189103e-06
Iter: 1694 loss: 1.96174369e-06
Iter: 1695 loss: 1.9614e-06
Iter: 1696 loss: 1.9657366e-06
Iter: 1697 loss: 1.96142446e-06
Iter: 1698 loss: 1.96111364e-06
Iter: 1699 loss: 1.96123551e-06
Iter: 1700 loss: 1.9609397e-06
Iter: 1701 loss: 1.96044471e-06
Iter: 1702 loss: 1.96122346e-06
Iter: 1703 loss: 1.96034352e-06
Iter: 1704 loss: 1.9601016e-06
Iter: 1705 loss: 1.96003793e-06
Iter: 1706 loss: 1.95987968e-06
Iter: 1707 loss: 1.96014594e-06
Iter: 1708 loss: 1.95978464e-06
Iter: 1709 loss: 1.95944222e-06
Iter: 1710 loss: 1.9591273e-06
Iter: 1711 loss: 1.95918233e-06
Iter: 1712 loss: 1.95879397e-06
Iter: 1713 loss: 1.96199085e-06
Iter: 1714 loss: 1.95879375e-06
Iter: 1715 loss: 1.95837742e-06
Iter: 1716 loss: 1.95785015e-06
Iter: 1717 loss: 1.95777466e-06
Iter: 1718 loss: 1.95734015e-06
Iter: 1719 loss: 1.96416886e-06
Iter: 1720 loss: 1.95729604e-06
Iter: 1721 loss: 1.95709663e-06
Iter: 1722 loss: 1.95682378e-06
Iter: 1723 loss: 1.95671e-06
Iter: 1724 loss: 1.95616326e-06
Iter: 1725 loss: 1.9611773e-06
Iter: 1726 loss: 1.95618486e-06
Iter: 1727 loss: 1.9557333e-06
Iter: 1728 loss: 1.95715597e-06
Iter: 1729 loss: 1.95564667e-06
Iter: 1730 loss: 1.95527537e-06
Iter: 1731 loss: 1.95596022e-06
Iter: 1732 loss: 1.95511757e-06
Iter: 1733 loss: 1.95455596e-06
Iter: 1734 loss: 1.95541361e-06
Iter: 1735 loss: 1.95449684e-06
Iter: 1736 loss: 1.95400912e-06
Iter: 1737 loss: 1.95453276e-06
Iter: 1738 loss: 1.95383245e-06
Iter: 1739 loss: 1.9532381e-06
Iter: 1740 loss: 1.95793177e-06
Iter: 1741 loss: 1.9532747e-06
Iter: 1742 loss: 1.95289977e-06
Iter: 1743 loss: 1.95322718e-06
Iter: 1744 loss: 1.95267103e-06
Iter: 1745 loss: 1.95244274e-06
Iter: 1746 loss: 1.95185157e-06
Iter: 1747 loss: 1.95183588e-06
Iter: 1748 loss: 1.95100779e-06
Iter: 1749 loss: 1.9569593e-06
Iter: 1750 loss: 1.95091e-06
Iter: 1751 loss: 1.95040775e-06
Iter: 1752 loss: 1.95027383e-06
Iter: 1753 loss: 1.9499978e-06
Iter: 1754 loss: 1.94935046e-06
Iter: 1755 loss: 1.95413759e-06
Iter: 1756 loss: 1.94933023e-06
Iter: 1757 loss: 1.94868358e-06
Iter: 1758 loss: 1.94827157e-06
Iter: 1759 loss: 1.94815334e-06
Iter: 1760 loss: 1.94700669e-06
Iter: 1761 loss: 1.95677762e-06
Iter: 1762 loss: 1.94702875e-06
Iter: 1763 loss: 1.94644986e-06
Iter: 1764 loss: 1.94649874e-06
Iter: 1765 loss: 1.94605559e-06
Iter: 1766 loss: 1.94576e-06
Iter: 1767 loss: 1.94582208e-06
Iter: 1768 loss: 1.9452043e-06
Iter: 1769 loss: 1.94681979e-06
Iter: 1770 loss: 1.94494532e-06
Iter: 1771 loss: 1.94469476e-06
Iter: 1772 loss: 1.94452809e-06
Iter: 1773 loss: 1.94434597e-06
Iter: 1774 loss: 1.94406812e-06
Iter: 1775 loss: 1.94400627e-06
Iter: 1776 loss: 1.9435638e-06
Iter: 1777 loss: 1.94472022e-06
Iter: 1778 loss: 1.9434051e-06
Iter: 1779 loss: 1.94298627e-06
Iter: 1780 loss: 1.94370614e-06
Iter: 1781 loss: 1.94288691e-06
Iter: 1782 loss: 1.94244944e-06
Iter: 1783 loss: 1.9422705e-06
Iter: 1784 loss: 1.94189579e-06
Iter: 1785 loss: 1.94149334e-06
Iter: 1786 loss: 1.94286599e-06
Iter: 1787 loss: 1.94134532e-06
Iter: 1788 loss: 1.94052836e-06
Iter: 1789 loss: 1.94168729e-06
Iter: 1790 loss: 1.94007839e-06
Iter: 1791 loss: 1.93960659e-06
Iter: 1792 loss: 1.94319227e-06
Iter: 1793 loss: 1.93949245e-06
Iter: 1794 loss: 1.93903315e-06
Iter: 1795 loss: 1.9438703e-06
Iter: 1796 loss: 1.93904407e-06
Iter: 1797 loss: 1.9386689e-06
Iter: 1798 loss: 1.939306e-06
Iter: 1799 loss: 1.93861683e-06
Iter: 1800 loss: 1.93829305e-06
Iter: 1801 loss: 1.93781716e-06
Iter: 1802 loss: 1.93771803e-06
Iter: 1803 loss: 1.93704568e-06
Iter: 1804 loss: 1.94315339e-06
Iter: 1805 loss: 1.93708206e-06
Iter: 1806 loss: 1.93641677e-06
Iter: 1807 loss: 1.93789128e-06
Iter: 1808 loss: 1.93613664e-06
Iter: 1809 loss: 1.93582559e-06
Iter: 1810 loss: 1.935917e-06
Iter: 1811 loss: 1.93552228e-06
Iter: 1812 loss: 1.93489313e-06
Iter: 1813 loss: 1.93481151e-06
Iter: 1814 loss: 1.93427286e-06
Iter: 1815 loss: 1.9336353e-06
Iter: 1816 loss: 1.93596088e-06
Iter: 1817 loss: 1.93347637e-06
Iter: 1818 loss: 1.93242909e-06
Iter: 1819 loss: 1.93313667e-06
Iter: 1820 loss: 1.93191704e-06
Iter: 1821 loss: 1.93133383e-06
Iter: 1822 loss: 1.93327242e-06
Iter: 1823 loss: 1.93105575e-06
Iter: 1824 loss: 1.93007099e-06
Iter: 1825 loss: 1.93094252e-06
Iter: 1826 loss: 1.92955918e-06
Iter: 1827 loss: 1.92916946e-06
Iter: 1828 loss: 1.92908169e-06
Iter: 1829 loss: 1.92868833e-06
Iter: 1830 loss: 1.92820221e-06
Iter: 1831 loss: 1.92805055e-06
Iter: 1832 loss: 1.92733978e-06
Iter: 1833 loss: 1.92936727e-06
Iter: 1834 loss: 1.92714e-06
Iter: 1835 loss: 1.9266472e-06
Iter: 1836 loss: 1.92920061e-06
Iter: 1837 loss: 1.92647713e-06
Iter: 1838 loss: 1.92593666e-06
Iter: 1839 loss: 1.92784455e-06
Iter: 1840 loss: 1.92570224e-06
Iter: 1841 loss: 1.92535936e-06
Iter: 1842 loss: 1.92572088e-06
Iter: 1843 loss: 1.92502625e-06
Iter: 1844 loss: 1.9246e-06
Iter: 1845 loss: 1.92438711e-06
Iter: 1846 loss: 1.92415519e-06
Iter: 1847 loss: 1.92314201e-06
Iter: 1848 loss: 1.92435e-06
Iter: 1849 loss: 1.9227391e-06
Iter: 1850 loss: 1.92201355e-06
Iter: 1851 loss: 1.92499942e-06
Iter: 1852 loss: 1.92179891e-06
Iter: 1853 loss: 1.92092739e-06
Iter: 1854 loss: 1.92152743e-06
Iter: 1855 loss: 1.92043012e-06
Iter: 1856 loss: 1.91962545e-06
Iter: 1857 loss: 1.92192465e-06
Iter: 1858 loss: 1.91937579e-06
Iter: 1859 loss: 1.91841718e-06
Iter: 1860 loss: 1.92268908e-06
Iter: 1861 loss: 1.91820118e-06
Iter: 1862 loss: 1.91778054e-06
Iter: 1863 loss: 1.91772051e-06
Iter: 1864 loss: 1.91727145e-06
Iter: 1865 loss: 1.91656295e-06
Iter: 1866 loss: 1.91663776e-06
Iter: 1867 loss: 1.91573645e-06
Iter: 1868 loss: 1.92159291e-06
Iter: 1869 loss: 1.91567847e-06
Iter: 1870 loss: 1.91535946e-06
Iter: 1871 loss: 1.92103084e-06
Iter: 1872 loss: 1.91533354e-06
Iter: 1873 loss: 1.91496952e-06
Iter: 1874 loss: 1.91423351e-06
Iter: 1875 loss: 1.91843128e-06
Iter: 1876 loss: 1.91394975e-06
Iter: 1877 loss: 1.91258391e-06
Iter: 1878 loss: 1.92318726e-06
Iter: 1879 loss: 1.91263211e-06
Iter: 1880 loss: 1.91197364e-06
Iter: 1881 loss: 1.91271215e-06
Iter: 1882 loss: 1.91174627e-06
Iter: 1883 loss: 1.91076674e-06
Iter: 1884 loss: 1.91118306e-06
Iter: 1885 loss: 1.91020717e-06
Iter: 1886 loss: 1.90939932e-06
Iter: 1887 loss: 1.91271238e-06
Iter: 1888 loss: 1.9092131e-06
Iter: 1889 loss: 1.90818969e-06
Iter: 1890 loss: 1.90890705e-06
Iter: 1891 loss: 1.90764035e-06
Iter: 1892 loss: 1.90672517e-06
Iter: 1893 loss: 1.90968558e-06
Iter: 1894 loss: 1.90638548e-06
Iter: 1895 loss: 1.90530682e-06
Iter: 1896 loss: 1.91415347e-06
Iter: 1897 loss: 1.90526919e-06
Iter: 1898 loss: 1.90464e-06
Iter: 1899 loss: 1.90945798e-06
Iter: 1900 loss: 1.90454887e-06
Iter: 1901 loss: 1.90428705e-06
Iter: 1902 loss: 1.90412243e-06
Iter: 1903 loss: 1.90380331e-06
Iter: 1904 loss: 1.90327046e-06
Iter: 1905 loss: 1.90728338e-06
Iter: 1906 loss: 1.90320179e-06
Iter: 1907 loss: 1.90254116e-06
Iter: 1908 loss: 1.90238484e-06
Iter: 1909 loss: 1.90204491e-06
Iter: 1910 loss: 1.90145124e-06
Iter: 1911 loss: 1.90164758e-06
Iter: 1912 loss: 1.90101969e-06
Iter: 1913 loss: 1.90010496e-06
Iter: 1914 loss: 1.9040499e-06
Iter: 1915 loss: 1.89987475e-06
Iter: 1916 loss: 1.89930324e-06
Iter: 1917 loss: 1.89990055e-06
Iter: 1918 loss: 1.89891125e-06
Iter: 1919 loss: 1.8979764e-06
Iter: 1920 loss: 1.89829666e-06
Iter: 1921 loss: 1.89722846e-06
Iter: 1922 loss: 1.89615105e-06
Iter: 1923 loss: 1.89958428e-06
Iter: 1924 loss: 1.89609432e-06
Iter: 1925 loss: 1.89488151e-06
Iter: 1926 loss: 1.89608795e-06
Iter: 1927 loss: 1.89432853e-06
Iter: 1928 loss: 1.89353261e-06
Iter: 1929 loss: 1.89355012e-06
Iter: 1930 loss: 1.89286527e-06
Iter: 1931 loss: 1.8925864e-06
Iter: 1932 loss: 1.89220282e-06
Iter: 1933 loss: 1.8911619e-06
Iter: 1934 loss: 1.89894411e-06
Iter: 1935 loss: 1.89120772e-06
Iter: 1936 loss: 1.89069e-06
Iter: 1937 loss: 1.89608863e-06
Iter: 1938 loss: 1.89086882e-06
Iter: 1939 loss: 1.89033392e-06
Iter: 1940 loss: 1.88959473e-06
Iter: 1941 loss: 1.88952993e-06
Iter: 1942 loss: 1.88857325e-06
Iter: 1943 loss: 1.88988679e-06
Iter: 1944 loss: 1.88805211e-06
Iter: 1945 loss: 1.8872787e-06
Iter: 1946 loss: 1.89035779e-06
Iter: 1947 loss: 1.88701836e-06
Iter: 1948 loss: 1.88610284e-06
Iter: 1949 loss: 1.88742592e-06
Iter: 1950 loss: 1.88565127e-06
Iter: 1951 loss: 1.88483125e-06
Iter: 1952 loss: 1.88695481e-06
Iter: 1953 loss: 1.88444847e-06
Iter: 1954 loss: 1.8833714e-06
Iter: 1955 loss: 1.88424917e-06
Iter: 1956 loss: 1.88270292e-06
Iter: 1957 loss: 1.88150398e-06
Iter: 1958 loss: 1.88358013e-06
Iter: 1959 loss: 1.8811088e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3
+ date
Mon Oct 26 14:22:09 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 2 --phi 3 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi2_phi3_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50d9ce0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50d9ccbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b447b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4532e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b454be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b43e6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b43e62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b43739d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4374510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b435e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b42e77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4319b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4319950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b42ac950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b426b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4246620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4246bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4261598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b421bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b41b57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b41c1488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b41b5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b41c1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4174730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4174ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b40c4488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b41008c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4030840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4044620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b4046268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50b408da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50a07ce158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50a07da1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50a07907b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50a07b8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f50a0756ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.02203805e-05
Iter: 2 loss: 3.61039565e-05
Iter: 3 loss: 3.40441402e-05
Iter: 4 loss: 3.11171243e-05
Iter: 5 loss: 3.08401723e-05
Iter: 6 loss: 2.86868035e-05
Iter: 7 loss: 2.6588863e-05
Iter: 8 loss: 2.29739962e-05
Iter: 9 loss: 2.29719e-05
Iter: 10 loss: 2.05698052e-05
Iter: 11 loss: 5.71698874e-05
Iter: 12 loss: 2.05683027e-05
Iter: 13 loss: 1.87138958e-05
Iter: 14 loss: 2.05881752e-05
Iter: 15 loss: 1.76725789e-05
Iter: 16 loss: 1.6289725e-05
Iter: 17 loss: 3.37652818e-05
Iter: 18 loss: 1.62781143e-05
Iter: 19 loss: 1.53089022e-05
Iter: 20 loss: 1.41388855e-05
Iter: 21 loss: 1.40240518e-05
Iter: 22 loss: 1.27834082e-05
Iter: 23 loss: 1.27828534e-05
Iter: 24 loss: 1.21460253e-05
Iter: 25 loss: 1.33517133e-05
Iter: 26 loss: 1.18768457e-05
Iter: 27 loss: 1.12015878e-05
Iter: 28 loss: 1.23458467e-05
Iter: 29 loss: 1.0897862e-05
Iter: 30 loss: 1.04653354e-05
Iter: 31 loss: 1.01778878e-05
Iter: 32 loss: 1.00159787e-05
Iter: 33 loss: 9.69245684e-06
Iter: 34 loss: 9.61217847e-06
Iter: 35 loss: 9.28180634e-06
Iter: 36 loss: 1.01881897e-05
Iter: 37 loss: 9.17439138e-06
Iter: 38 loss: 8.92475873e-06
Iter: 39 loss: 8.60568e-06
Iter: 40 loss: 8.58233216e-06
Iter: 41 loss: 8.16003194e-06
Iter: 42 loss: 9.51371476e-06
Iter: 43 loss: 8.03983e-06
Iter: 44 loss: 7.68690734e-06
Iter: 45 loss: 7.85144948e-06
Iter: 46 loss: 7.44911904e-06
Iter: 47 loss: 7.10737731e-06
Iter: 48 loss: 7.1069453e-06
Iter: 49 loss: 6.95229392e-06
Iter: 50 loss: 7.05724096e-06
Iter: 51 loss: 6.85509531e-06
Iter: 52 loss: 6.59948e-06
Iter: 53 loss: 6.76939771e-06
Iter: 54 loss: 6.43850308e-06
Iter: 55 loss: 6.25055554e-06
Iter: 56 loss: 8.12329927e-06
Iter: 57 loss: 6.24457834e-06
Iter: 58 loss: 6.07130278e-06
Iter: 59 loss: 6.06809135e-06
Iter: 60 loss: 5.9319882e-06
Iter: 61 loss: 5.72711269e-06
Iter: 62 loss: 6.96872939e-06
Iter: 63 loss: 5.70192606e-06
Iter: 64 loss: 5.52837673e-06
Iter: 65 loss: 5.54182043e-06
Iter: 66 loss: 5.39314215e-06
Iter: 67 loss: 5.62815148e-06
Iter: 68 loss: 5.33435923e-06
Iter: 69 loss: 5.30805528e-06
Iter: 70 loss: 5.23756444e-06
Iter: 71 loss: 5.70919e-06
Iter: 72 loss: 5.22053142e-06
Iter: 73 loss: 5.09505662e-06
Iter: 74 loss: 4.97470137e-06
Iter: 75 loss: 4.94678807e-06
Iter: 76 loss: 4.84230486e-06
Iter: 77 loss: 6.22176231e-06
Iter: 78 loss: 4.84170869e-06
Iter: 79 loss: 4.74402805e-06
Iter: 80 loss: 4.76076184e-06
Iter: 81 loss: 4.67072687e-06
Iter: 82 loss: 4.57680198e-06
Iter: 83 loss: 5.77584706e-06
Iter: 84 loss: 4.57605483e-06
Iter: 85 loss: 4.50521884e-06
Iter: 86 loss: 4.48813353e-06
Iter: 87 loss: 4.44335683e-06
Iter: 88 loss: 4.35589618e-06
Iter: 89 loss: 5.05540629e-06
Iter: 90 loss: 4.35015909e-06
Iter: 91 loss: 4.28359181e-06
Iter: 92 loss: 4.24275095e-06
Iter: 93 loss: 4.21587629e-06
Iter: 94 loss: 4.10000121e-06
Iter: 95 loss: 4.92780055e-06
Iter: 96 loss: 4.08993037e-06
Iter: 97 loss: 4.02502337e-06
Iter: 98 loss: 4.01316038e-06
Iter: 99 loss: 3.96931409e-06
Iter: 100 loss: 3.90788227e-06
Iter: 101 loss: 3.90403102e-06
Iter: 102 loss: 3.84675695e-06
Iter: 103 loss: 4.07830885e-06
Iter: 104 loss: 3.83438874e-06
Iter: 105 loss: 3.81008681e-06
Iter: 106 loss: 3.75727427e-06
Iter: 107 loss: 4.54521251e-06
Iter: 108 loss: 3.75510922e-06
Iter: 109 loss: 3.69370628e-06
Iter: 110 loss: 4.03828381e-06
Iter: 111 loss: 3.68485553e-06
Iter: 112 loss: 3.63393747e-06
Iter: 113 loss: 3.56653163e-06
Iter: 114 loss: 3.56237297e-06
Iter: 115 loss: 3.52391407e-06
Iter: 116 loss: 3.51357812e-06
Iter: 117 loss: 3.47667446e-06
Iter: 118 loss: 3.43598822e-06
Iter: 119 loss: 3.43035845e-06
Iter: 120 loss: 3.3700062e-06
Iter: 121 loss: 3.98900193e-06
Iter: 122 loss: 3.36793e-06
Iter: 123 loss: 3.33145181e-06
Iter: 124 loss: 3.28795613e-06
Iter: 125 loss: 3.28349461e-06
Iter: 126 loss: 3.21302196e-06
Iter: 127 loss: 3.86522606e-06
Iter: 128 loss: 3.21015887e-06
Iter: 129 loss: 3.17077047e-06
Iter: 130 loss: 3.24123494e-06
Iter: 131 loss: 3.1538e-06
Iter: 132 loss: 3.10713608e-06
Iter: 133 loss: 3.25102678e-06
Iter: 134 loss: 3.09324446e-06
Iter: 135 loss: 3.07186906e-06
Iter: 136 loss: 3.06655852e-06
Iter: 137 loss: 3.05467529e-06
Iter: 138 loss: 3.02824719e-06
Iter: 139 loss: 3.39248118e-06
Iter: 140 loss: 3.02681065e-06
Iter: 141 loss: 2.99094336e-06
Iter: 142 loss: 2.97601628e-06
Iter: 143 loss: 2.95752716e-06
Iter: 144 loss: 2.92111167e-06
Iter: 145 loss: 3.19681249e-06
Iter: 146 loss: 2.91836068e-06
Iter: 147 loss: 2.88116098e-06
Iter: 148 loss: 2.89843433e-06
Iter: 149 loss: 2.85599663e-06
Iter: 150 loss: 2.82828569e-06
Iter: 151 loss: 3.08014819e-06
Iter: 152 loss: 2.82701035e-06
Iter: 153 loss: 2.79869846e-06
Iter: 154 loss: 2.84456223e-06
Iter: 155 loss: 2.78531797e-06
Iter: 156 loss: 2.76593573e-06
Iter: 157 loss: 2.85304759e-06
Iter: 158 loss: 2.76214087e-06
Iter: 159 loss: 2.73861292e-06
Iter: 160 loss: 2.73087289e-06
Iter: 161 loss: 2.717401e-06
Iter: 162 loss: 2.69263296e-06
Iter: 163 loss: 2.93508833e-06
Iter: 164 loss: 2.69181965e-06
Iter: 165 loss: 2.66697339e-06
Iter: 166 loss: 2.64864912e-06
Iter: 167 loss: 2.64020582e-06
Iter: 168 loss: 2.65179801e-06
Iter: 169 loss: 2.6279597e-06
Iter: 170 loss: 2.61799e-06
Iter: 171 loss: 2.60208299e-06
Iter: 172 loss: 2.60194543e-06
Iter: 173 loss: 2.58195314e-06
Iter: 174 loss: 2.56317117e-06
Iter: 175 loss: 2.55849682e-06
Iter: 176 loss: 2.53409075e-06
Iter: 177 loss: 2.66174584e-06
Iter: 178 loss: 2.53023268e-06
Iter: 179 loss: 2.50548896e-06
Iter: 180 loss: 2.53353937e-06
Iter: 181 loss: 2.49216509e-06
Iter: 182 loss: 2.46920308e-06
Iter: 183 loss: 2.5307927e-06
Iter: 184 loss: 2.46171112e-06
Iter: 185 loss: 2.43203476e-06
Iter: 186 loss: 2.53420421e-06
Iter: 187 loss: 2.42411102e-06
Iter: 188 loss: 2.40806185e-06
Iter: 189 loss: 2.59330295e-06
Iter: 190 loss: 2.40781037e-06
Iter: 191 loss: 2.39428664e-06
Iter: 192 loss: 2.37393351e-06
Iter: 193 loss: 2.37340555e-06
Iter: 194 loss: 2.35499238e-06
Iter: 195 loss: 2.62916569e-06
Iter: 196 loss: 2.35496509e-06
Iter: 197 loss: 2.33881565e-06
Iter: 198 loss: 2.32933553e-06
Iter: 199 loss: 2.32279717e-06
Iter: 200 loss: 2.30988e-06
Iter: 201 loss: 2.30884098e-06
Iter: 202 loss: 2.30040746e-06
Iter: 203 loss: 2.40188797e-06
Iter: 204 loss: 2.30037108e-06
Iter: 205 loss: 2.29364923e-06
Iter: 206 loss: 2.27384248e-06
Iter: 207 loss: 2.320774e-06
Iter: 208 loss: 2.26240786e-06
Iter: 209 loss: 2.24461633e-06
Iter: 210 loss: 2.24457199e-06
Iter: 211 loss: 2.23027678e-06
Iter: 212 loss: 2.20627908e-06
Iter: 213 loss: 2.20630227e-06
Iter: 214 loss: 2.18891159e-06
Iter: 215 loss: 2.18856985e-06
Iter: 216 loss: 2.17514139e-06
Iter: 217 loss: 2.16771514e-06
Iter: 218 loss: 2.16195849e-06
Iter: 219 loss: 2.1473279e-06
Iter: 220 loss: 2.34885238e-06
Iter: 221 loss: 2.14725787e-06
Iter: 222 loss: 2.13408794e-06
Iter: 223 loss: 2.14512056e-06
Iter: 224 loss: 2.12629902e-06
Iter: 225 loss: 2.11538963e-06
Iter: 226 loss: 2.17863453e-06
Iter: 227 loss: 2.11376937e-06
Iter: 228 loss: 2.10190274e-06
Iter: 229 loss: 2.08958863e-06
Iter: 230 loss: 2.0873083e-06
Iter: 231 loss: 2.07368339e-06
Iter: 232 loss: 2.0733346e-06
Iter: 233 loss: 2.06740378e-06
Iter: 234 loss: 2.15912723e-06
Iter: 235 loss: 2.06737695e-06
Iter: 236 loss: 2.06118375e-06
Iter: 237 loss: 2.04899243e-06
Iter: 238 loss: 2.28883164e-06
Iter: 239 loss: 2.04893968e-06
Iter: 240 loss: 2.03982086e-06
Iter: 241 loss: 2.08623578e-06
Iter: 242 loss: 2.03842092e-06
Iter: 243 loss: 2.03120794e-06
Iter: 244 loss: 2.01644048e-06
Iter: 245 loss: 2.29641455e-06
Iter: 246 loss: 2.01606463e-06
Iter: 247 loss: 2.00377e-06
Iter: 248 loss: 2.00368459e-06
Iter: 249 loss: 1.99246665e-06
Iter: 250 loss: 1.99089e-06
Iter: 251 loss: 1.98301655e-06
Iter: 252 loss: 1.97369809e-06
Iter: 253 loss: 2.05985111e-06
Iter: 254 loss: 1.97344866e-06
Iter: 255 loss: 1.9634108e-06
Iter: 256 loss: 1.97198278e-06
Iter: 257 loss: 1.95731582e-06
Iter: 258 loss: 1.94802988e-06
Iter: 259 loss: 2.03793229e-06
Iter: 260 loss: 1.94765971e-06
Iter: 261 loss: 1.94049471e-06
Iter: 262 loss: 1.92772859e-06
Iter: 263 loss: 1.92772859e-06
Iter: 264 loss: 1.91503841e-06
Iter: 265 loss: 1.91507024e-06
Iter: 266 loss: 1.90805713e-06
Iter: 267 loss: 1.96857059e-06
Iter: 268 loss: 1.90762785e-06
Iter: 269 loss: 1.90028811e-06
Iter: 270 loss: 1.91546042e-06
Iter: 271 loss: 1.8971366e-06
Iter: 272 loss: 1.89196555e-06
Iter: 273 loss: 1.89063803e-06
Iter: 274 loss: 1.88734975e-06
Iter: 275 loss: 1.88099125e-06
Iter: 276 loss: 1.87302544e-06
Iter: 277 loss: 1.87244041e-06
Iter: 278 loss: 1.86328134e-06
Iter: 279 loss: 1.99389819e-06
Iter: 280 loss: 1.86338752e-06
Iter: 281 loss: 1.85676379e-06
Iter: 282 loss: 1.84803173e-06
Iter: 283 loss: 1.84742032e-06
Iter: 284 loss: 1.83785642e-06
Iter: 285 loss: 1.9554534e-06
Iter: 286 loss: 1.83774569e-06
Iter: 287 loss: 1.8290142e-06
Iter: 288 loss: 1.83034751e-06
Iter: 289 loss: 1.82250324e-06
Iter: 290 loss: 1.81676171e-06
Iter: 291 loss: 1.81660698e-06
Iter: 292 loss: 1.81186726e-06
Iter: 293 loss: 1.80355812e-06
Iter: 294 loss: 2.00387558e-06
Iter: 295 loss: 1.80352754e-06
Iter: 296 loss: 1.79667666e-06
Iter: 297 loss: 1.79661129e-06
Iter: 298 loss: 1.79237429e-06
Iter: 299 loss: 1.8228576e-06
Iter: 300 loss: 1.79201106e-06
Iter: 301 loss: 1.78694768e-06
Iter: 302 loss: 1.79654455e-06
Iter: 303 loss: 1.78459788e-06
Iter: 304 loss: 1.77998413e-06
Iter: 305 loss: 1.7823636e-06
Iter: 306 loss: 1.77692596e-06
Iter: 307 loss: 1.77243419e-06
Iter: 308 loss: 1.76460389e-06
Iter: 309 loss: 1.76456604e-06
Iter: 310 loss: 1.75680623e-06
Iter: 311 loss: 1.83217639e-06
Iter: 312 loss: 1.75661467e-06
Iter: 313 loss: 1.74930688e-06
Iter: 314 loss: 1.74797106e-06
Iter: 315 loss: 1.74296508e-06
Iter: 316 loss: 1.73527644e-06
Iter: 317 loss: 1.79638732e-06
Iter: 318 loss: 1.73482636e-06
Iter: 319 loss: 1.72734076e-06
Iter: 320 loss: 1.73430885e-06
Iter: 321 loss: 1.72308091e-06
Iter: 322 loss: 1.71734177e-06
Iter: 323 loss: 1.76183789e-06
Iter: 324 loss: 1.71688146e-06
Iter: 325 loss: 1.71062277e-06
Iter: 326 loss: 1.71501506e-06
Iter: 327 loss: 1.7067216e-06
Iter: 328 loss: 1.70110843e-06
Iter: 329 loss: 1.73674971e-06
Iter: 330 loss: 1.7004902e-06
Iter: 331 loss: 1.69603732e-06
Iter: 332 loss: 1.70789872e-06
Iter: 333 loss: 1.69453767e-06
Iter: 334 loss: 1.68951772e-06
Iter: 335 loss: 1.75150194e-06
Iter: 336 loss: 1.68944871e-06
Iter: 337 loss: 1.68675956e-06
Iter: 338 loss: 1.68677957e-06
Iter: 339 loss: 1.68470979e-06
Iter: 340 loss: 1.6816598e-06
Iter: 341 loss: 1.67571943e-06
Iter: 342 loss: 1.79912195e-06
Iter: 343 loss: 1.67586768e-06
Iter: 344 loss: 1.66969164e-06
Iter: 345 loss: 1.72909813e-06
Iter: 346 loss: 1.66944255e-06
Iter: 347 loss: 1.66496443e-06
Iter: 348 loss: 1.66313771e-06
Iter: 349 loss: 1.6608775e-06
Iter: 350 loss: 1.65528058e-06
Iter: 351 loss: 1.67812368e-06
Iter: 352 loss: 1.65416168e-06
Iter: 353 loss: 1.64726953e-06
Iter: 354 loss: 1.66672612e-06
Iter: 355 loss: 1.64501557e-06
Iter: 356 loss: 1.64023459e-06
Iter: 357 loss: 1.65403821e-06
Iter: 358 loss: 1.63879599e-06
Iter: 359 loss: 1.63303503e-06
Iter: 360 loss: 1.66176505e-06
Iter: 361 loss: 1.6321053e-06
Iter: 362 loss: 1.62823153e-06
Iter: 363 loss: 1.63329e-06
Iter: 364 loss: 1.62625929e-06
Iter: 365 loss: 1.62066942e-06
Iter: 366 loss: 1.62995423e-06
Iter: 367 loss: 1.61820708e-06
Iter: 368 loss: 1.61732873e-06
Iter: 369 loss: 1.61525099e-06
Iter: 370 loss: 1.61361834e-06
Iter: 371 loss: 1.6113147e-06
Iter: 372 loss: 1.61128787e-06
Iter: 373 loss: 1.60793479e-06
Iter: 374 loss: 1.60317427e-06
Iter: 375 loss: 1.60297236e-06
Iter: 376 loss: 1.59781416e-06
Iter: 377 loss: 1.64232301e-06
Iter: 378 loss: 1.59756985e-06
Iter: 379 loss: 1.59381239e-06
Iter: 380 loss: 1.58938064e-06
Iter: 381 loss: 1.58896296e-06
Iter: 382 loss: 1.58323439e-06
Iter: 383 loss: 1.60965578e-06
Iter: 384 loss: 1.58209718e-06
Iter: 385 loss: 1.57594104e-06
Iter: 386 loss: 1.60414675e-06
Iter: 387 loss: 1.57488216e-06
Iter: 388 loss: 1.57065688e-06
Iter: 389 loss: 1.57806915e-06
Iter: 390 loss: 1.56866076e-06
Iter: 391 loss: 1.5630992e-06
Iter: 392 loss: 1.58926173e-06
Iter: 393 loss: 1.56210172e-06
Iter: 394 loss: 1.55808311e-06
Iter: 395 loss: 1.56870897e-06
Iter: 396 loss: 1.55666817e-06
Iter: 397 loss: 1.55171756e-06
Iter: 398 loss: 1.55552789e-06
Iter: 399 loss: 1.54868667e-06
Iter: 400 loss: 1.54915551e-06
Iter: 401 loss: 1.54673512e-06
Iter: 402 loss: 1.54502777e-06
Iter: 403 loss: 1.54263557e-06
Iter: 404 loss: 1.54248687e-06
Iter: 405 loss: 1.5390267e-06
Iter: 406 loss: 1.53817723e-06
Iter: 407 loss: 1.53591736e-06
Iter: 408 loss: 1.5319855e-06
Iter: 409 loss: 1.54822339e-06
Iter: 410 loss: 1.53128326e-06
Iter: 411 loss: 1.52715916e-06
Iter: 412 loss: 1.52584448e-06
Iter: 413 loss: 1.52342932e-06
Iter: 414 loss: 1.51955612e-06
Iter: 415 loss: 1.53797589e-06
Iter: 416 loss: 1.51877862e-06
Iter: 417 loss: 1.51400172e-06
Iter: 418 loss: 1.52044549e-06
Iter: 419 loss: 1.51159611e-06
Iter: 420 loss: 1.50737037e-06
Iter: 421 loss: 1.51738425e-06
Iter: 422 loss: 1.50583264e-06
Iter: 423 loss: 1.50130734e-06
Iter: 424 loss: 1.54111217e-06
Iter: 425 loss: 1.50114488e-06
Iter: 426 loss: 1.49792504e-06
Iter: 427 loss: 1.50319306e-06
Iter: 428 loss: 1.49660082e-06
Iter: 429 loss: 1.49217749e-06
Iter: 430 loss: 1.49849802e-06
Iter: 431 loss: 1.49015682e-06
Iter: 432 loss: 1.48804634e-06
Iter: 433 loss: 1.48795789e-06
Iter: 434 loss: 1.48549759e-06
Iter: 435 loss: 1.48703145e-06
Iter: 436 loss: 1.48393633e-06
Iter: 437 loss: 1.48127128e-06
Iter: 438 loss: 1.47824301e-06
Iter: 439 loss: 1.47790115e-06
Iter: 440 loss: 1.47451158e-06
Iter: 441 loss: 1.49207438e-06
Iter: 442 loss: 1.4740292e-06
Iter: 443 loss: 1.47075411e-06
Iter: 444 loss: 1.46876459e-06
Iter: 445 loss: 1.46738876e-06
Iter: 446 loss: 1.46322702e-06
Iter: 447 loss: 1.48291087e-06
Iter: 448 loss: 1.46248294e-06
Iter: 449 loss: 1.45775687e-06
Iter: 450 loss: 1.46458046e-06
Iter: 451 loss: 1.45550825e-06
Iter: 452 loss: 1.4521811e-06
Iter: 453 loss: 1.45359377e-06
Iter: 454 loss: 1.44981163e-06
Iter: 455 loss: 1.44578155e-06
Iter: 456 loss: 1.50404094e-06
Iter: 457 loss: 1.44581054e-06
Iter: 458 loss: 1.44300111e-06
Iter: 459 loss: 1.44531612e-06
Iter: 460 loss: 1.44137698e-06
Iter: 461 loss: 1.43754187e-06
Iter: 462 loss: 1.45406329e-06
Iter: 463 loss: 1.43680791e-06
Iter: 464 loss: 1.43442617e-06
Iter: 465 loss: 1.44759906e-06
Iter: 466 loss: 1.43410148e-06
Iter: 467 loss: 1.43143075e-06
Iter: 468 loss: 1.44653325e-06
Iter: 469 loss: 1.43102284e-06
Iter: 470 loss: 1.42926069e-06
Iter: 471 loss: 1.428019e-06
Iter: 472 loss: 1.42741021e-06
Iter: 473 loss: 1.42529802e-06
Iter: 474 loss: 1.42779913e-06
Iter: 475 loss: 1.42419344e-06
Iter: 476 loss: 1.4214778e-06
Iter: 477 loss: 1.42328327e-06
Iter: 478 loss: 1.41970986e-06
Iter: 479 loss: 1.41632563e-06
Iter: 480 loss: 1.42522686e-06
Iter: 481 loss: 1.41534326e-06
Iter: 482 loss: 1.4116049e-06
Iter: 483 loss: 1.42185286e-06
Iter: 484 loss: 1.41044177e-06
Iter: 485 loss: 1.40753468e-06
Iter: 486 loss: 1.40432871e-06
Iter: 487 loss: 1.40382292e-06
Iter: 488 loss: 1.40214547e-06
Iter: 489 loss: 1.40146881e-06
Iter: 490 loss: 1.39960821e-06
Iter: 491 loss: 1.39907593e-06
Iter: 492 loss: 1.39795497e-06
Iter: 493 loss: 1.39532585e-06
Iter: 494 loss: 1.41922976e-06
Iter: 495 loss: 1.3950804e-06
Iter: 496 loss: 1.39317888e-06
Iter: 497 loss: 1.39227473e-06
Iter: 498 loss: 1.39125439e-06
Iter: 499 loss: 1.38868972e-06
Iter: 500 loss: 1.38866926e-06
Iter: 501 loss: 1.38722703e-06
Iter: 502 loss: 1.3858014e-06
Iter: 503 loss: 1.38552582e-06
Iter: 504 loss: 1.38324367e-06
Iter: 505 loss: 1.38263249e-06
Iter: 506 loss: 1.38114319e-06
Iter: 507 loss: 1.37845132e-06
Iter: 508 loss: 1.3891015e-06
Iter: 509 loss: 1.37781205e-06
Iter: 510 loss: 1.37539439e-06
Iter: 511 loss: 1.37703455e-06
Iter: 512 loss: 1.37395818e-06
Iter: 513 loss: 1.37069901e-06
Iter: 514 loss: 1.38718394e-06
Iter: 515 loss: 1.3701756e-06
Iter: 516 loss: 1.36776885e-06
Iter: 517 loss: 1.36702761e-06
Iter: 518 loss: 1.36567382e-06
Iter: 519 loss: 1.36347921e-06
Iter: 520 loss: 1.36348331e-06
Iter: 521 loss: 1.36150254e-06
Iter: 522 loss: 1.35874859e-06
Iter: 523 loss: 1.35873847e-06
Iter: 524 loss: 1.35716516e-06
Iter: 525 loss: 1.3569063e-06
Iter: 526 loss: 1.35514972e-06
Iter: 527 loss: 1.35185655e-06
Iter: 528 loss: 1.41826854e-06
Iter: 529 loss: 1.35178902e-06
Iter: 530 loss: 1.3529052e-06
Iter: 531 loss: 1.35029609e-06
Iter: 532 loss: 1.34918787e-06
Iter: 533 loss: 1.34899324e-06
Iter: 534 loss: 1.34822972e-06
Iter: 535 loss: 1.34658035e-06
Iter: 536 loss: 1.34544803e-06
Iter: 537 loss: 1.3448946e-06
Iter: 538 loss: 1.343039e-06
Iter: 539 loss: 1.36173276e-06
Iter: 540 loss: 1.34301763e-06
Iter: 541 loss: 1.3417141e-06
Iter: 542 loss: 1.33993467e-06
Iter: 543 loss: 1.33979029e-06
Iter: 544 loss: 1.3375743e-06
Iter: 545 loss: 1.35602841e-06
Iter: 546 loss: 1.33738843e-06
Iter: 547 loss: 1.33535832e-06
Iter: 548 loss: 1.3347701e-06
Iter: 549 loss: 1.33357548e-06
Iter: 550 loss: 1.33075241e-06
Iter: 551 loss: 1.34409379e-06
Iter: 552 loss: 1.33031847e-06
Iter: 553 loss: 1.32780883e-06
Iter: 554 loss: 1.34165907e-06
Iter: 555 loss: 1.32744094e-06
Iter: 556 loss: 1.32583477e-06
Iter: 557 loss: 1.32560365e-06
Iter: 558 loss: 1.32433786e-06
Iter: 559 loss: 1.32163109e-06
Iter: 560 loss: 1.34665743e-06
Iter: 561 loss: 1.32153161e-06
Iter: 562 loss: 1.32006517e-06
Iter: 563 loss: 1.32851528e-06
Iter: 564 loss: 1.31986599e-06
Iter: 565 loss: 1.31799527e-06
Iter: 566 loss: 1.32029868e-06
Iter: 567 loss: 1.31711249e-06
Iter: 568 loss: 1.31518277e-06
Iter: 569 loss: 1.31618651e-06
Iter: 570 loss: 1.3138939e-06
Iter: 571 loss: 1.31263528e-06
Iter: 572 loss: 1.3133432e-06
Iter: 573 loss: 1.3117583e-06
Iter: 574 loss: 1.30937701e-06
Iter: 575 loss: 1.31039155e-06
Iter: 576 loss: 1.30779745e-06
Iter: 577 loss: 1.30526223e-06
Iter: 578 loss: 1.30903629e-06
Iter: 579 loss: 1.30408807e-06
Iter: 580 loss: 1.30094429e-06
Iter: 581 loss: 1.32042669e-06
Iter: 582 loss: 1.30049352e-06
Iter: 583 loss: 1.29856357e-06
Iter: 584 loss: 1.29757973e-06
Iter: 585 loss: 1.2967397e-06
Iter: 586 loss: 1.29414434e-06
Iter: 587 loss: 1.32505261e-06
Iter: 588 loss: 1.29415093e-06
Iter: 589 loss: 1.2926098e-06
Iter: 590 loss: 1.29383898e-06
Iter: 591 loss: 1.29162913e-06
Iter: 592 loss: 1.28978104e-06
Iter: 593 loss: 1.29795899e-06
Iter: 594 loss: 1.28937882e-06
Iter: 595 loss: 1.28730517e-06
Iter: 596 loss: 1.29173441e-06
Iter: 597 loss: 1.28656575e-06
Iter: 598 loss: 1.28509657e-06
Iter: 599 loss: 1.28493275e-06
Iter: 600 loss: 1.28399324e-06
Iter: 601 loss: 1.28406646e-06
Iter: 602 loss: 1.28322404e-06
Iter: 603 loss: 1.28231306e-06
Iter: 604 loss: 1.28023657e-06
Iter: 605 loss: 1.31438605e-06
Iter: 606 loss: 1.2801504e-06
Iter: 607 loss: 1.27810949e-06
Iter: 608 loss: 1.30613091e-06
Iter: 609 loss: 1.27815724e-06
Iter: 610 loss: 1.27659223e-06
Iter: 611 loss: 1.27503574e-06
Iter: 612 loss: 1.27472799e-06
Iter: 613 loss: 1.27245016e-06
Iter: 614 loss: 1.29389878e-06
Iter: 615 loss: 1.27241049e-06
Iter: 616 loss: 1.27052817e-06
Iter: 617 loss: 1.26804196e-06
Iter: 618 loss: 1.26783289e-06
Iter: 619 loss: 1.26575173e-06
Iter: 620 loss: 1.26572809e-06
Iter: 621 loss: 1.26415102e-06
Iter: 622 loss: 1.26261887e-06
Iter: 623 loss: 1.26228178e-06
Iter: 624 loss: 1.2601929e-06
Iter: 625 loss: 1.27039766e-06
Iter: 626 loss: 1.25991153e-06
Iter: 627 loss: 1.25764745e-06
Iter: 628 loss: 1.2583979e-06
Iter: 629 loss: 1.25618271e-06
Iter: 630 loss: 1.25473196e-06
Iter: 631 loss: 1.25468887e-06
Iter: 632 loss: 1.25370127e-06
Iter: 633 loss: 1.25370207e-06
Iter: 634 loss: 1.25300107e-06
Iter: 635 loss: 1.25213978e-06
Iter: 636 loss: 1.25197812e-06
Iter: 637 loss: 1.25106158e-06
Iter: 638 loss: 1.2496414e-06
Iter: 639 loss: 1.24962503e-06
Iter: 640 loss: 1.24733219e-06
Iter: 641 loss: 1.26169436e-06
Iter: 642 loss: 1.24706276e-06
Iter: 643 loss: 1.24563132e-06
Iter: 644 loss: 1.24498615e-06
Iter: 645 loss: 1.24430187e-06
Iter: 646 loss: 1.24167468e-06
Iter: 647 loss: 1.25253268e-06
Iter: 648 loss: 1.24112353e-06
Iter: 649 loss: 1.23920427e-06
Iter: 650 loss: 1.23820746e-06
Iter: 651 loss: 1.23739483e-06
Iter: 652 loss: 1.23609038e-06
Iter: 653 loss: 1.23577922e-06
Iter: 654 loss: 1.23495192e-06
Iter: 655 loss: 1.23474e-06
Iter: 656 loss: 1.2340895e-06
Iter: 657 loss: 1.23237703e-06
Iter: 658 loss: 1.2324814e-06
Iter: 659 loss: 1.23108759e-06
Iter: 660 loss: 1.22928759e-06
Iter: 661 loss: 1.23426e-06
Iter: 662 loss: 1.22868073e-06
Iter: 663 loss: 1.2279952e-06
Iter: 664 loss: 1.22761787e-06
Iter: 665 loss: 1.22683377e-06
Iter: 666 loss: 1.22693541e-06
Iter: 667 loss: 1.22615165e-06
Iter: 668 loss: 1.22532936e-06
Iter: 669 loss: 1.22355914e-06
Iter: 670 loss: 1.25273198e-06
Iter: 671 loss: 1.22353208e-06
Iter: 672 loss: 1.22154302e-06
Iter: 673 loss: 1.24490634e-06
Iter: 674 loss: 1.22153256e-06
Iter: 675 loss: 1.2205976e-06
Iter: 676 loss: 1.21969106e-06
Iter: 677 loss: 1.21948233e-06
Iter: 678 loss: 1.21729829e-06
Iter: 679 loss: 1.22478252e-06
Iter: 680 loss: 1.21679841e-06
Iter: 681 loss: 1.2155009e-06
Iter: 682 loss: 1.21632286e-06
Iter: 683 loss: 1.21460334e-06
Iter: 684 loss: 1.21275468e-06
Iter: 685 loss: 1.22597271e-06
Iter: 686 loss: 1.2125779e-06
Iter: 687 loss: 1.21135236e-06
Iter: 688 loss: 1.21379753e-06
Iter: 689 loss: 1.21081189e-06
Iter: 690 loss: 1.20907384e-06
Iter: 691 loss: 1.21359744e-06
Iter: 692 loss: 1.20849688e-06
Iter: 693 loss: 1.20725724e-06
Iter: 694 loss: 1.20938716e-06
Iter: 695 loss: 1.20667414e-06
Iter: 696 loss: 1.20527329e-06
Iter: 697 loss: 1.21621974e-06
Iter: 698 loss: 1.20516938e-06
Iter: 699 loss: 1.2040889e-06
Iter: 700 loss: 1.21860239e-06
Iter: 701 loss: 1.20413222e-06
Iter: 702 loss: 1.20362142e-06
Iter: 703 loss: 1.20240293e-06
Iter: 704 loss: 1.20626305e-06
Iter: 705 loss: 1.20169489e-06
Iter: 706 loss: 1.19989193e-06
Iter: 707 loss: 1.21955964e-06
Iter: 708 loss: 1.19989147e-06
Iter: 709 loss: 1.1989182e-06
Iter: 710 loss: 1.19986794e-06
Iter: 711 loss: 1.19837387e-06
Iter: 712 loss: 1.19693186e-06
Iter: 713 loss: 1.19779429e-06
Iter: 714 loss: 1.19601884e-06
Iter: 715 loss: 1.19454967e-06
Iter: 716 loss: 1.19495553e-06
Iter: 717 loss: 1.19331219e-06
Iter: 718 loss: 1.1916585e-06
Iter: 719 loss: 1.21756761e-06
Iter: 720 loss: 1.1915804e-06
Iter: 721 loss: 1.19065567e-06
Iter: 722 loss: 1.18980893e-06
Iter: 723 loss: 1.18946332e-06
Iter: 724 loss: 1.18759101e-06
Iter: 725 loss: 1.19732772e-06
Iter: 726 loss: 1.18723506e-06
Iter: 727 loss: 1.18614071e-06
Iter: 728 loss: 1.18681646e-06
Iter: 729 loss: 1.18548724e-06
Iter: 730 loss: 1.18408173e-06
Iter: 731 loss: 1.19029642e-06
Iter: 732 loss: 1.18373805e-06
Iter: 733 loss: 1.18303024e-06
Iter: 734 loss: 1.18312551e-06
Iter: 735 loss: 1.18257731e-06
Iter: 736 loss: 1.18122784e-06
Iter: 737 loss: 1.19690139e-06
Iter: 738 loss: 1.1810846e-06
Iter: 739 loss: 1.17953937e-06
Iter: 740 loss: 1.18345372e-06
Iter: 741 loss: 1.1789773e-06
Iter: 742 loss: 1.17782599e-06
Iter: 743 loss: 1.18333878e-06
Iter: 744 loss: 1.17763193e-06
Iter: 745 loss: 1.17624313e-06
Iter: 746 loss: 1.17568516e-06
Iter: 747 loss: 1.17503214e-06
Iter: 748 loss: 1.17374213e-06
Iter: 749 loss: 1.18343269e-06
Iter: 750 loss: 1.17360878e-06
Iter: 751 loss: 1.17243007e-06
Iter: 752 loss: 1.17284185e-06
Iter: 753 loss: 1.17162222e-06
Iter: 754 loss: 1.17038076e-06
Iter: 755 loss: 1.17585955e-06
Iter: 756 loss: 1.17009881e-06
Iter: 757 loss: 1.16865135e-06
Iter: 758 loss: 1.174403e-06
Iter: 759 loss: 1.16834315e-06
Iter: 760 loss: 1.16740534e-06
Iter: 761 loss: 1.17119191e-06
Iter: 762 loss: 1.16721662e-06
Iter: 763 loss: 1.16604576e-06
Iter: 764 loss: 1.16430488e-06
Iter: 765 loss: 1.16421347e-06
Iter: 766 loss: 1.1658592e-06
Iter: 767 loss: 1.16358387e-06
Iter: 768 loss: 1.16316801e-06
Iter: 769 loss: 1.16237106e-06
Iter: 770 loss: 1.16232172e-06
Iter: 771 loss: 1.16115586e-06
Iter: 772 loss: 1.15985017e-06
Iter: 773 loss: 1.15965736e-06
Iter: 774 loss: 1.15850082e-06
Iter: 775 loss: 1.17140712e-06
Iter: 776 loss: 1.15851662e-06
Iter: 777 loss: 1.15719263e-06
Iter: 778 loss: 1.15643593e-06
Iter: 779 loss: 1.1559423e-06
Iter: 780 loss: 1.15463206e-06
Iter: 781 loss: 1.17333207e-06
Iter: 782 loss: 1.15464627e-06
Iter: 783 loss: 1.15370051e-06
Iter: 784 loss: 1.15260889e-06
Iter: 785 loss: 1.15251589e-06
Iter: 786 loss: 1.15116836e-06
Iter: 787 loss: 1.16100739e-06
Iter: 788 loss: 1.15110242e-06
Iter: 789 loss: 1.14971795e-06
Iter: 790 loss: 1.15085936e-06
Iter: 791 loss: 1.14887666e-06
Iter: 792 loss: 1.14750969e-06
Iter: 793 loss: 1.16316312e-06
Iter: 794 loss: 1.14752788e-06
Iter: 795 loss: 1.1465396e-06
Iter: 796 loss: 1.14522641e-06
Iter: 797 loss: 1.14518491e-06
Iter: 798 loss: 1.14364911e-06
Iter: 799 loss: 1.15956891e-06
Iter: 800 loss: 1.14356089e-06
Iter: 801 loss: 1.14302225e-06
Iter: 802 loss: 1.14300633e-06
Iter: 803 loss: 1.14232807e-06
Iter: 804 loss: 1.14090426e-06
Iter: 805 loss: 1.17031698e-06
Iter: 806 loss: 1.1409229e-06
Iter: 807 loss: 1.14005741e-06
Iter: 808 loss: 1.1408481e-06
Iter: 809 loss: 1.13953161e-06
Iter: 810 loss: 1.13813383e-06
Iter: 811 loss: 1.13784154e-06
Iter: 812 loss: 1.13691385e-06
Iter: 813 loss: 1.13607325e-06
Iter: 814 loss: 1.13593967e-06
Iter: 815 loss: 1.13537089e-06
Iter: 816 loss: 1.13424653e-06
Iter: 817 loss: 1.13426108e-06
Iter: 818 loss: 1.13302599e-06
Iter: 819 loss: 1.1485597e-06
Iter: 820 loss: 1.13306169e-06
Iter: 821 loss: 1.13242243e-06
Iter: 822 loss: 1.13112378e-06
Iter: 823 loss: 1.13113697e-06
Iter: 824 loss: 1.12980092e-06
Iter: 825 loss: 1.14571799e-06
Iter: 826 loss: 1.12984537e-06
Iter: 827 loss: 1.12900796e-06
Iter: 828 loss: 1.12852877e-06
Iter: 829 loss: 1.12812768e-06
Iter: 830 loss: 1.12726616e-06
Iter: 831 loss: 1.1272723e-06
Iter: 832 loss: 1.12642692e-06
Iter: 833 loss: 1.12633938e-06
Iter: 834 loss: 1.12577015e-06
Iter: 835 loss: 1.12531836e-06
Iter: 836 loss: 1.12509451e-06
Iter: 837 loss: 1.12471957e-06
Iter: 838 loss: 1.12443513e-06
Iter: 839 loss: 1.12422345e-06
Iter: 840 loss: 1.1236782e-06
Iter: 841 loss: 1.1221689e-06
Iter: 842 loss: 1.12843236e-06
Iter: 843 loss: 1.12156658e-06
Iter: 844 loss: 1.12015448e-06
Iter: 845 loss: 1.12005296e-06
Iter: 846 loss: 1.11904467e-06
Iter: 847 loss: 1.12037458e-06
Iter: 848 loss: 1.11850454e-06
Iter: 849 loss: 1.117328e-06
Iter: 850 loss: 1.12294344e-06
Iter: 851 loss: 1.11705936e-06
Iter: 852 loss: 1.11582335e-06
Iter: 853 loss: 1.11818508e-06
Iter: 854 loss: 1.11534632e-06
Iter: 855 loss: 1.11425311e-06
Iter: 856 loss: 1.12158909e-06
Iter: 857 loss: 1.11408758e-06
Iter: 858 loss: 1.11313739e-06
Iter: 859 loss: 1.11260692e-06
Iter: 860 loss: 1.11219663e-06
Iter: 861 loss: 1.11111319e-06
Iter: 862 loss: 1.12708028e-06
Iter: 863 loss: 1.11109011e-06
Iter: 864 loss: 1.11049917e-06
Iter: 865 loss: 1.11077452e-06
Iter: 866 loss: 1.11004761e-06
Iter: 867 loss: 1.10943347e-06
Iter: 868 loss: 1.10943688e-06
Iter: 869 loss: 1.10883479e-06
Iter: 870 loss: 1.10922394e-06
Iter: 871 loss: 1.10859401e-06
Iter: 872 loss: 1.10810765e-06
Iter: 873 loss: 1.10708493e-06
Iter: 874 loss: 1.12371163e-06
Iter: 875 loss: 1.1070714e-06
Iter: 876 loss: 1.1059293e-06
Iter: 877 loss: 1.11317661e-06
Iter: 878 loss: 1.10578844e-06
Iter: 879 loss: 1.10487065e-06
Iter: 880 loss: 1.10309395e-06
Iter: 881 loss: 1.14359955e-06
Iter: 882 loss: 1.10306007e-06
Iter: 883 loss: 1.10209271e-06
Iter: 884 loss: 1.10202552e-06
Iter: 885 loss: 1.10099086e-06
Iter: 886 loss: 1.10201904e-06
Iter: 887 loss: 1.10034989e-06
Iter: 888 loss: 1.09915379e-06
Iter: 889 loss: 1.10566793e-06
Iter: 890 loss: 1.0989661e-06
Iter: 891 loss: 1.0980641e-06
Iter: 892 loss: 1.09661619e-06
Iter: 893 loss: 1.09656526e-06
Iter: 894 loss: 1.09498649e-06
Iter: 895 loss: 1.1152149e-06
Iter: 896 loss: 1.09495056e-06
Iter: 897 loss: 1.09384405e-06
Iter: 898 loss: 1.09537871e-06
Iter: 899 loss: 1.09333428e-06
Iter: 900 loss: 1.09229131e-06
Iter: 901 loss: 1.09228426e-06
Iter: 902 loss: 1.09165262e-06
Iter: 903 loss: 1.09540451e-06
Iter: 904 loss: 1.09151119e-06
Iter: 905 loss: 1.0910959e-06
Iter: 906 loss: 1.09010341e-06
Iter: 907 loss: 1.1017014e-06
Iter: 908 loss: 1.09000666e-06
Iter: 909 loss: 1.08866197e-06
Iter: 910 loss: 1.09308894e-06
Iter: 911 loss: 1.0883349e-06
Iter: 912 loss: 1.08720019e-06
Iter: 913 loss: 1.08595918e-06
Iter: 914 loss: 1.08573067e-06
Iter: 915 loss: 1.08436416e-06
Iter: 916 loss: 1.10621613e-06
Iter: 917 loss: 1.08430913e-06
Iter: 918 loss: 1.08317772e-06
Iter: 919 loss: 1.08330642e-06
Iter: 920 loss: 1.08229119e-06
Iter: 921 loss: 1.08125209e-06
Iter: 922 loss: 1.08129518e-06
Iter: 923 loss: 1.08051699e-06
Iter: 924 loss: 1.07898393e-06
Iter: 925 loss: 1.11452164e-06
Iter: 926 loss: 1.07897472e-06
Iter: 927 loss: 1.07792471e-06
Iter: 928 loss: 1.09546602e-06
Iter: 929 loss: 1.07785604e-06
Iter: 930 loss: 1.07692233e-06
Iter: 931 loss: 1.07649498e-06
Iter: 932 loss: 1.07604933e-06
Iter: 933 loss: 1.07529593e-06
Iter: 934 loss: 1.07520464e-06
Iter: 935 loss: 1.07467213e-06
Iter: 936 loss: 1.07638789e-06
Iter: 937 loss: 1.07447215e-06
Iter: 938 loss: 1.0738288e-06
Iter: 939 loss: 1.07425069e-06
Iter: 940 loss: 1.07345738e-06
Iter: 941 loss: 1.07283745e-06
Iter: 942 loss: 1.07410597e-06
Iter: 943 loss: 1.07262713e-06
Iter: 944 loss: 1.07214305e-06
Iter: 945 loss: 1.07074197e-06
Iter: 946 loss: 1.08970573e-06
Iter: 947 loss: 1.07072947e-06
Iter: 948 loss: 1.06955099e-06
Iter: 949 loss: 1.08237498e-06
Iter: 950 loss: 1.06951893e-06
Iter: 951 loss: 1.06843595e-06
Iter: 952 loss: 1.07073834e-06
Iter: 953 loss: 1.06792095e-06
Iter: 954 loss: 1.06710866e-06
Iter: 955 loss: 1.0696408e-06
Iter: 956 loss: 1.06680204e-06
Iter: 957 loss: 1.06560503e-06
Iter: 958 loss: 1.07112919e-06
Iter: 959 loss: 1.06534685e-06
Iter: 960 loss: 1.06461903e-06
Iter: 961 loss: 1.06589482e-06
Iter: 962 loss: 1.0642907e-06
Iter: 963 loss: 1.06326911e-06
Iter: 964 loss: 1.06299876e-06
Iter: 965 loss: 1.06237621e-06
Iter: 966 loss: 1.06179732e-06
Iter: 967 loss: 1.06175719e-06
Iter: 968 loss: 1.06116875e-06
Iter: 969 loss: 1.06536572e-06
Iter: 970 loss: 1.06112043e-06
Iter: 971 loss: 1.06064124e-06
Iter: 972 loss: 1.06040102e-06
Iter: 973 loss: 1.06024845e-06
Iter: 974 loss: 1.05963613e-06
Iter: 975 loss: 1.0608951e-06
Iter: 976 loss: 1.05941945e-06
Iter: 977 loss: 1.05872209e-06
Iter: 978 loss: 1.05765764e-06
Iter: 979 loss: 1.05769209e-06
Iter: 980 loss: 1.05655738e-06
Iter: 981 loss: 1.05995991e-06
Iter: 982 loss: 1.05627214e-06
Iter: 983 loss: 1.05498907e-06
Iter: 984 loss: 1.06205414e-06
Iter: 985 loss: 1.05481706e-06
Iter: 986 loss: 1.05406275e-06
Iter: 987 loss: 1.05438221e-06
Iter: 988 loss: 1.05361335e-06
Iter: 989 loss: 1.05271715e-06
Iter: 990 loss: 1.06525454e-06
Iter: 991 loss: 1.05274967e-06
Iter: 992 loss: 1.05215349e-06
Iter: 993 loss: 1.05174934e-06
Iter: 994 loss: 1.05149547e-06
Iter: 995 loss: 1.05044967e-06
Iter: 996 loss: 1.05490528e-06
Iter: 997 loss: 1.05018171e-06
Iter: 998 loss: 1.04951732e-06
Iter: 999 loss: 1.05031882e-06
Iter: 1000 loss: 1.0492281e-06
Iter: 1001 loss: 1.04871242e-06
Iter: 1002 loss: 1.04858827e-06
Iter: 1003 loss: 1.04813762e-06
Iter: 1004 loss: 1.04856224e-06
Iter: 1005 loss: 1.04784192e-06
Iter: 1006 loss: 1.04734272e-06
Iter: 1007 loss: 1.04715889e-06
Iter: 1008 loss: 1.04703088e-06
Iter: 1009 loss: 1.04608853e-06
Iter: 1010 loss: 1.04573178e-06
Iter: 1011 loss: 1.04530022e-06
Iter: 1012 loss: 1.04450146e-06
Iter: 1013 loss: 1.04699325e-06
Iter: 1014 loss: 1.04429114e-06
Iter: 1015 loss: 1.04338983e-06
Iter: 1016 loss: 1.04658886e-06
Iter: 1017 loss: 1.04315404e-06
Iter: 1018 loss: 1.04238802e-06
Iter: 1019 loss: 1.04145477e-06
Iter: 1020 loss: 1.04132357e-06
Iter: 1021 loss: 1.04082733e-06
Iter: 1022 loss: 1.04068067e-06
Iter: 1023 loss: 1.04005642e-06
Iter: 1024 loss: 1.04026776e-06
Iter: 1025 loss: 1.03966659e-06
Iter: 1026 loss: 1.03894342e-06
Iter: 1027 loss: 1.0435183e-06
Iter: 1028 loss: 1.03887328e-06
Iter: 1029 loss: 1.03849254e-06
Iter: 1030 loss: 1.03807088e-06
Iter: 1031 loss: 1.0379415e-06
Iter: 1032 loss: 1.03756406e-06
Iter: 1033 loss: 1.03752132e-06
Iter: 1034 loss: 1.03711352e-06
Iter: 1035 loss: 1.03817581e-06
Iter: 1036 loss: 1.03700143e-06
Iter: 1037 loss: 1.03664524e-06
Iter: 1038 loss: 1.03602815e-06
Iter: 1039 loss: 1.04991e-06
Iter: 1040 loss: 1.03602724e-06
Iter: 1041 loss: 1.03533989e-06
Iter: 1042 loss: 1.03980642e-06
Iter: 1043 loss: 1.03523405e-06
Iter: 1044 loss: 1.03476077e-06
Iter: 1045 loss: 1.03403727e-06
Iter: 1046 loss: 1.03401158e-06
Iter: 1047 loss: 1.03304728e-06
Iter: 1048 loss: 1.04270634e-06
Iter: 1049 loss: 1.03299499e-06
Iter: 1050 loss: 1.03248408e-06
Iter: 1051 loss: 1.03216e-06
Iter: 1052 loss: 1.03192895e-06
Iter: 1053 loss: 1.03111608e-06
Iter: 1054 loss: 1.03782963e-06
Iter: 1055 loss: 1.03103025e-06
Iter: 1056 loss: 1.03020909e-06
Iter: 1057 loss: 1.0293852e-06
Iter: 1058 loss: 1.02925424e-06
Iter: 1059 loss: 1.0287572e-06
Iter: 1060 loss: 1.02870638e-06
Iter: 1061 loss: 1.02808349e-06
Iter: 1062 loss: 1.02715649e-06
Iter: 1063 loss: 1.02719196e-06
Iter: 1064 loss: 1.02634749e-06
Iter: 1065 loss: 1.03707043e-06
Iter: 1066 loss: 1.02627337e-06
Iter: 1067 loss: 1.02611068e-06
Iter: 1068 loss: 1.02595345e-06
Iter: 1069 loss: 1.02565025e-06
Iter: 1070 loss: 1.02498836e-06
Iter: 1071 loss: 1.02576905e-06
Iter: 1072 loss: 1.02438389e-06
Iter: 1073 loss: 1.0236754e-06
Iter: 1074 loss: 1.03515845e-06
Iter: 1075 loss: 1.02365163e-06
Iter: 1076 loss: 1.02300237e-06
Iter: 1077 loss: 1.02305557e-06
Iter: 1078 loss: 1.02255751e-06
Iter: 1079 loss: 1.02166405e-06
Iter: 1080 loss: 1.02680588e-06
Iter: 1081 loss: 1.02158344e-06
Iter: 1082 loss: 1.02108515e-06
Iter: 1083 loss: 1.02055753e-06
Iter: 1084 loss: 1.02042668e-06
Iter: 1085 loss: 1.01963815e-06
Iter: 1086 loss: 1.02695412e-06
Iter: 1087 loss: 1.01964656e-06
Iter: 1088 loss: 1.01898331e-06
Iter: 1089 loss: 1.01852856e-06
Iter: 1090 loss: 1.01842409e-06
Iter: 1091 loss: 1.01761952e-06
Iter: 1092 loss: 1.02681247e-06
Iter: 1093 loss: 1.01760088e-06
Iter: 1094 loss: 1.01699243e-06
Iter: 1095 loss: 1.0166325e-06
Iter: 1096 loss: 1.01639057e-06
Iter: 1097 loss: 1.01564092e-06
Iter: 1098 loss: 1.02388947e-06
Iter: 1099 loss: 1.01559192e-06
Iter: 1100 loss: 1.01533772e-06
Iter: 1101 loss: 1.01535409e-06
Iter: 1102 loss: 1.01492094e-06
Iter: 1103 loss: 1.01408398e-06
Iter: 1104 loss: 1.02298964e-06
Iter: 1105 loss: 1.01399814e-06
Iter: 1106 loss: 1.0133565e-06
Iter: 1107 loss: 1.01558976e-06
Iter: 1108 loss: 1.01315277e-06
Iter: 1109 loss: 1.01249839e-06
Iter: 1110 loss: 1.01185174e-06
Iter: 1111 loss: 1.01177363e-06
Iter: 1112 loss: 1.01117303e-06
Iter: 1113 loss: 1.01113824e-06
Iter: 1114 loss: 1.01057958e-06
Iter: 1115 loss: 1.00997886e-06
Iter: 1116 loss: 1.00992156e-06
Iter: 1117 loss: 1.00896341e-06
Iter: 1118 loss: 1.01625051e-06
Iter: 1119 loss: 1.00893328e-06
Iter: 1120 loss: 1.00813804e-06
Iter: 1121 loss: 1.00792761e-06
Iter: 1122 loss: 1.00757302e-06
Iter: 1123 loss: 1.006714e-06
Iter: 1124 loss: 1.01463365e-06
Iter: 1125 loss: 1.00665125e-06
Iter: 1126 loss: 1.00613408e-06
Iter: 1127 loss: 1.00565694e-06
Iter: 1128 loss: 1.00544935e-06
Iter: 1129 loss: 1.00484749e-06
Iter: 1130 loss: 1.00909278e-06
Iter: 1131 loss: 1.00477359e-06
Iter: 1132 loss: 1.0042337e-06
Iter: 1133 loss: 1.00486238e-06
Iter: 1134 loss: 1.0038957e-06
Iter: 1135 loss: 1.00362672e-06
Iter: 1136 loss: 1.00352884e-06
Iter: 1137 loss: 1.00333682e-06
Iter: 1138 loss: 1.00289731e-06
Iter: 1139 loss: 1.00288548e-06
Iter: 1140 loss: 1.00226362e-06
Iter: 1141 loss: 1.00139243e-06
Iter: 1142 loss: 1.0013764e-06
Iter: 1143 loss: 1.00076068e-06
Iter: 1144 loss: 1.00075988e-06
Iter: 1145 loss: 1.00023055e-06
Iter: 1146 loss: 9.99922349e-07
Iter: 1147 loss: 9.99691792e-07
Iter: 1148 loss: 9.9899944e-07
Iter: 1149 loss: 1.00542456e-06
Iter: 1150 loss: 9.98991e-07
Iter: 1151 loss: 9.98419182e-07
Iter: 1152 loss: 9.97341203e-07
Iter: 1153 loss: 9.9736792e-07
Iter: 1154 loss: 9.96651352e-07
Iter: 1155 loss: 9.96626113e-07
Iter: 1156 loss: 9.96153744e-07
Iter: 1157 loss: 9.95647611e-07
Iter: 1158 loss: 9.95597247e-07
Iter: 1159 loss: 9.94929792e-07
Iter: 1160 loss: 9.98789119e-07
Iter: 1161 loss: 9.9476074e-07
Iter: 1162 loss: 9.94272455e-07
Iter: 1163 loss: 9.9386375e-07
Iter: 1164 loss: 9.93801905e-07
Iter: 1165 loss: 9.9394515e-07
Iter: 1166 loss: 9.93545882e-07
Iter: 1167 loss: 9.93197887e-07
Iter: 1168 loss: 9.93305548e-07
Iter: 1169 loss: 9.92930836e-07
Iter: 1170 loss: 9.92524292e-07
Iter: 1171 loss: 9.91890943e-07
Iter: 1172 loss: 9.91816478e-07
Iter: 1173 loss: 9.91318188e-07
Iter: 1174 loss: 9.95492201e-07
Iter: 1175 loss: 9.91286e-07
Iter: 1176 loss: 9.90829e-07
Iter: 1177 loss: 9.90706781e-07
Iter: 1178 loss: 9.90358558e-07
Iter: 1179 loss: 9.8983287e-07
Iter: 1180 loss: 9.96998324e-07
Iter: 1181 loss: 9.89832415e-07
Iter: 1182 loss: 9.89275122e-07
Iter: 1183 loss: 9.88579131e-07
Iter: 1184 loss: 9.88538659e-07
Iter: 1185 loss: 9.8786586e-07
Iter: 1186 loss: 9.94343e-07
Iter: 1187 loss: 9.87832664e-07
Iter: 1188 loss: 9.87036e-07
Iter: 1189 loss: 9.87482508e-07
Iter: 1190 loss: 9.86591203e-07
Iter: 1191 loss: 9.85878614e-07
Iter: 1192 loss: 9.8853809e-07
Iter: 1193 loss: 9.85740826e-07
Iter: 1194 loss: 9.84998792e-07
Iter: 1195 loss: 9.85805286e-07
Iter: 1196 loss: 9.84586336e-07
Iter: 1197 loss: 9.84054623e-07
Iter: 1198 loss: 9.89152e-07
Iter: 1199 loss: 9.84065082e-07
Iter: 1200 loss: 9.83735731e-07
Iter: 1201 loss: 9.87405883e-07
Iter: 1202 loss: 9.83696623e-07
Iter: 1203 loss: 9.83305e-07
Iter: 1204 loss: 9.82982783e-07
Iter: 1205 loss: 9.82833e-07
Iter: 1206 loss: 9.82598749e-07
Iter: 1207 loss: 9.82216534e-07
Iter: 1208 loss: 9.82174242e-07
Iter: 1209 loss: 9.81598646e-07
Iter: 1210 loss: 9.83742552e-07
Iter: 1211 loss: 9.81458243e-07
Iter: 1212 loss: 9.80952223e-07
Iter: 1213 loss: 9.82215397e-07
Iter: 1214 loss: 9.80856385e-07
Iter: 1215 loss: 9.80340701e-07
Iter: 1216 loss: 9.81824769e-07
Iter: 1217 loss: 9.80087179e-07
Iter: 1218 loss: 9.79703714e-07
Iter: 1219 loss: 9.80487812e-07
Iter: 1220 loss: 9.79563538e-07
Iter: 1221 loss: 9.79000902e-07
Iter: 1222 loss: 9.80329901e-07
Iter: 1223 loss: 9.78900744e-07
Iter: 1224 loss: 9.78455773e-07
Iter: 1225 loss: 9.80373898e-07
Iter: 1226 loss: 9.78352205e-07
Iter: 1227 loss: 9.77913e-07
Iter: 1228 loss: 9.78075605e-07
Iter: 1229 loss: 9.77556397e-07
Iter: 1230 loss: 9.7710722e-07
Iter: 1231 loss: 9.78504e-07
Iter: 1232 loss: 9.76987849e-07
Iter: 1233 loss: 9.76640649e-07
Iter: 1234 loss: 9.81802941e-07
Iter: 1235 loss: 9.76547881e-07
Iter: 1236 loss: 9.76236834e-07
Iter: 1237 loss: 9.79025344e-07
Iter: 1238 loss: 9.76246724e-07
Iter: 1239 loss: 9.76094498e-07
Iter: 1240 loss: 9.75747071e-07
Iter: 1241 loss: 9.77690661e-07
Iter: 1242 loss: 9.75523108e-07
Iter: 1243 loss: 9.75044486e-07
Iter: 1244 loss: 9.80186769e-07
Iter: 1245 loss: 9.75009812e-07
Iter: 1246 loss: 9.74691375e-07
Iter: 1247 loss: 9.74290288e-07
Iter: 1248 loss: 9.74264367e-07
Iter: 1249 loss: 9.73842361e-07
Iter: 1250 loss: 9.8111741e-07
Iter: 1251 loss: 9.73831902e-07
Iter: 1252 loss: 9.73585657e-07
Iter: 1253 loss: 9.7354166e-07
Iter: 1254 loss: 9.73372835e-07
Iter: 1255 loss: 9.72899e-07
Iter: 1256 loss: 9.73548254e-07
Iter: 1257 loss: 9.72670705e-07
Iter: 1258 loss: 9.72215162e-07
Iter: 1259 loss: 9.74756063e-07
Iter: 1260 loss: 9.72219937e-07
Iter: 1261 loss: 9.71904456e-07
Iter: 1262 loss: 9.73780516e-07
Iter: 1263 loss: 9.71902e-07
Iter: 1264 loss: 9.71604095e-07
Iter: 1265 loss: 9.71881832e-07
Iter: 1266 loss: 9.71477903e-07
Iter: 1267 loss: 9.71162763e-07
Iter: 1268 loss: 9.72383759e-07
Iter: 1269 loss: 9.71073518e-07
Iter: 1270 loss: 9.70867632e-07
Iter: 1271 loss: 9.70867518e-07
Iter: 1272 loss: 9.70742121e-07
Iter: 1273 loss: 9.70526344e-07
Iter: 1274 loss: 9.71107738e-07
Iter: 1275 loss: 9.70303e-07
Iter: 1276 loss: 9.70001111e-07
Iter: 1277 loss: 9.72383077e-07
Iter: 1278 loss: 9.69933126e-07
Iter: 1279 loss: 9.69597522e-07
Iter: 1280 loss: 9.69447228e-07
Iter: 1281 loss: 9.69321377e-07
Iter: 1282 loss: 9.68883569e-07
Iter: 1283 loss: 9.68930408e-07
Iter: 1284 loss: 9.68665063e-07
Iter: 1285 loss: 9.69065468e-07
Iter: 1286 loss: 9.68610607e-07
Iter: 1287 loss: 9.6828e-07
Iter: 1288 loss: 9.68272275e-07
Iter: 1289 loss: 9.67992719e-07
Iter: 1290 loss: 9.67681785e-07
Iter: 1291 loss: 9.6840779e-07
Iter: 1292 loss: 9.67520805e-07
Iter: 1293 loss: 9.67142682e-07
Iter: 1294 loss: 9.67160304e-07
Iter: 1295 loss: 9.66723519e-07
Iter: 1296 loss: 9.66189e-07
Iter: 1297 loss: 9.68615723e-07
Iter: 1298 loss: 9.66118932e-07
Iter: 1299 loss: 9.65741606e-07
Iter: 1300 loss: 9.68813765e-07
Iter: 1301 loss: 9.65777645e-07
Iter: 1302 loss: 9.65536174e-07
Iter: 1303 loss: 9.65524691e-07
Iter: 1304 loss: 9.65325512e-07
Iter: 1305 loss: 9.65053e-07
Iter: 1306 loss: 9.64980472e-07
Iter: 1307 loss: 9.64727178e-07
Iter: 1308 loss: 9.65032541e-07
Iter: 1309 loss: 9.64500487e-07
Iter: 1310 loss: 9.64214451e-07
Iter: 1311 loss: 9.63944331e-07
Iter: 1312 loss: 9.63838261e-07
Iter: 1313 loss: 9.63445e-07
Iter: 1314 loss: 9.68416316e-07
Iter: 1315 loss: 9.63466846e-07
Iter: 1316 loss: 9.63163757e-07
Iter: 1317 loss: 9.63353386e-07
Iter: 1318 loss: 9.63028469e-07
Iter: 1319 loss: 9.62645117e-07
Iter: 1320 loss: 9.65575168e-07
Iter: 1321 loss: 9.62600097e-07
Iter: 1322 loss: 9.62416379e-07
Iter: 1323 loss: 9.62094191e-07
Iter: 1324 loss: 9.62114314e-07
Iter: 1325 loss: 9.61657179e-07
Iter: 1326 loss: 9.64023457e-07
Iter: 1327 loss: 9.61543265e-07
Iter: 1328 loss: 9.61202886e-07
Iter: 1329 loss: 9.61325554e-07
Iter: 1330 loss: 9.61016099e-07
Iter: 1331 loss: 9.60526791e-07
Iter: 1332 loss: 9.65654749e-07
Iter: 1333 loss: 9.60549755e-07
Iter: 1334 loss: 9.6036e-07
Iter: 1335 loss: 9.62461854e-07
Iter: 1336 loss: 9.60396392e-07
Iter: 1337 loss: 9.60123657e-07
Iter: 1338 loss: 9.59762133e-07
Iter: 1339 loss: 9.59744284e-07
Iter: 1340 loss: 9.59385488e-07
Iter: 1341 loss: 9.61055548e-07
Iter: 1342 loss: 9.59309205e-07
Iter: 1343 loss: 9.59043518e-07
Iter: 1344 loss: 9.58721785e-07
Iter: 1345 loss: 9.58593e-07
Iter: 1346 loss: 9.5823907e-07
Iter: 1347 loss: 9.63669095e-07
Iter: 1348 loss: 9.58265559e-07
Iter: 1349 loss: 9.57915518e-07
Iter: 1350 loss: 9.57588327e-07
Iter: 1351 loss: 9.57591283e-07
Iter: 1352 loss: 9.57183829e-07
Iter: 1353 loss: 9.57158363e-07
Iter: 1354 loss: 9.56934855e-07
Iter: 1355 loss: 9.56910412e-07
Iter: 1356 loss: 9.56656322e-07
Iter: 1357 loss: 9.5631151e-07
Iter: 1358 loss: 9.58807277e-07
Iter: 1359 loss: 9.56287408e-07
Iter: 1360 loss: 9.56036e-07
Iter: 1361 loss: 9.55773658e-07
Iter: 1362 loss: 9.55714199e-07
Iter: 1363 loss: 9.55449e-07
Iter: 1364 loss: 9.55427822e-07
Iter: 1365 loss: 9.55362111e-07
Iter: 1366 loss: 9.55298674e-07
Iter: 1367 loss: 9.55151449e-07
Iter: 1368 loss: 9.55266387e-07
Iter: 1369 loss: 9.55072323e-07
Iter: 1370 loss: 9.54938628e-07
Iter: 1371 loss: 9.54871e-07
Iter: 1372 loss: 9.54734332e-07
Iter: 1373 loss: 9.54562552e-07
Iter: 1374 loss: 9.54393499e-07
Iter: 1375 loss: 9.54329607e-07
Iter: 1376 loss: 9.54013103e-07
Iter: 1377 loss: 9.55803785e-07
Iter: 1378 loss: 9.53957851e-07
Iter: 1379 loss: 9.53651579e-07
Iter: 1380 loss: 9.53479798e-07
Iter: 1381 loss: 9.53295682e-07
Iter: 1382 loss: 9.53023402e-07
Iter: 1383 loss: 9.5746509e-07
Iter: 1384 loss: 9.5302164e-07
Iter: 1385 loss: 9.52666312e-07
Iter: 1386 loss: 9.52736968e-07
Iter: 1387 loss: 9.52357595e-07
Iter: 1388 loss: 9.51972197e-07
Iter: 1389 loss: 9.54896677e-07
Iter: 1390 loss: 9.51923539e-07
Iter: 1391 loss: 9.51693494e-07
Iter: 1392 loss: 9.51343452e-07
Iter: 1393 loss: 9.51284164e-07
Iter: 1394 loss: 9.5084954e-07
Iter: 1395 loss: 9.5516566e-07
Iter: 1396 loss: 9.50850051e-07
Iter: 1397 loss: 9.5058175e-07
Iter: 1398 loss: 9.51570655e-07
Iter: 1399 loss: 9.50444871e-07
Iter: 1400 loss: 9.50034632e-07
Iter: 1401 loss: 9.54011853e-07
Iter: 1402 loss: 9.50010531e-07
Iter: 1403 loss: 9.49902415e-07
Iter: 1404 loss: 9.49785317e-07
Iter: 1405 loss: 9.49766331e-07
Iter: 1406 loss: 9.49507125e-07
Iter: 1407 loss: 9.49571699e-07
Iter: 1408 loss: 9.49356263e-07
Iter: 1409 loss: 9.48831257e-07
Iter: 1410 loss: 9.49428909e-07
Iter: 1411 loss: 9.48601439e-07
Iter: 1412 loss: 9.48095362e-07
Iter: 1413 loss: 9.50200672e-07
Iter: 1414 loss: 9.48008051e-07
Iter: 1415 loss: 9.47657099e-07
Iter: 1416 loss: 9.48493664e-07
Iter: 1417 loss: 9.47597869e-07
Iter: 1418 loss: 9.47140734e-07
Iter: 1419 loss: 9.48555112e-07
Iter: 1420 loss: 9.47135618e-07
Iter: 1421 loss: 9.46825935e-07
Iter: 1422 loss: 9.48854733e-07
Iter: 1423 loss: 9.46766079e-07
Iter: 1424 loss: 9.46507896e-07
Iter: 1425 loss: 9.46145747e-07
Iter: 1426 loss: 9.46146145e-07
Iter: 1427 loss: 9.45669342e-07
Iter: 1428 loss: 9.45701231e-07
Iter: 1429 loss: 9.45484487e-07
Iter: 1430 loss: 9.45470333e-07
Iter: 1431 loss: 9.45240345e-07
Iter: 1432 loss: 9.45188617e-07
Iter: 1433 loss: 9.45070269e-07
Iter: 1434 loss: 9.44956241e-07
Iter: 1435 loss: 9.44733131e-07
Iter: 1436 loss: 9.48043e-07
Iter: 1437 loss: 9.44721876e-07
Iter: 1438 loss: 9.44481314e-07
Iter: 1439 loss: 9.44568683e-07
Iter: 1440 loss: 9.44304873e-07
Iter: 1441 loss: 9.43896794e-07
Iter: 1442 loss: 9.44873e-07
Iter: 1443 loss: 9.43746329e-07
Iter: 1444 loss: 9.43448072e-07
Iter: 1445 loss: 9.44856424e-07
Iter: 1446 loss: 9.43376e-07
Iter: 1447 loss: 9.43056705e-07
Iter: 1448 loss: 9.43442274e-07
Iter: 1449 loss: 9.4293506e-07
Iter: 1450 loss: 9.42517772e-07
Iter: 1451 loss: 9.43356781e-07
Iter: 1452 loss: 9.42408406e-07
Iter: 1453 loss: 9.42080874e-07
Iter: 1454 loss: 9.4279369e-07
Iter: 1455 loss: 9.42028805e-07
Iter: 1456 loss: 9.41486405e-07
Iter: 1457 loss: 9.41699454e-07
Iter: 1458 loss: 9.41168196e-07
Iter: 1459 loss: 9.40827817e-07
Iter: 1460 loss: 9.44790258e-07
Iter: 1461 loss: 9.40785753e-07
Iter: 1462 loss: 9.40478685e-07
Iter: 1463 loss: 9.39935092e-07
Iter: 1464 loss: 9.5184248e-07
Iter: 1465 loss: 9.39864719e-07
Iter: 1466 loss: 9.40688835e-07
Iter: 1467 loss: 9.3968913e-07
Iter: 1468 loss: 9.39579195e-07
Iter: 1469 loss: 9.39376605e-07
Iter: 1470 loss: 9.39380243e-07
Iter: 1471 loss: 9.3912206e-07
Iter: 1472 loss: 9.38837559e-07
Iter: 1473 loss: 9.38783387e-07
Iter: 1474 loss: 9.3845847e-07
Iter: 1475 loss: 9.39225231e-07
Iter: 1476 loss: 9.38316816e-07
Iter: 1477 loss: 9.37873608e-07
Iter: 1478 loss: 9.3934e-07
Iter: 1479 loss: 9.37874063e-07
Iter: 1480 loss: 9.37525328e-07
Iter: 1481 loss: 9.38366554e-07
Iter: 1482 loss: 9.37404252e-07
Iter: 1483 loss: 9.36922788e-07
Iter: 1484 loss: 9.38454377e-07
Iter: 1485 loss: 9.36838035e-07
Iter: 1486 loss: 9.36590595e-07
Iter: 1487 loss: 9.37081438e-07
Iter: 1488 loss: 9.36445474e-07
Iter: 1489 loss: 9.36110439e-07
Iter: 1490 loss: 9.3731785e-07
Iter: 1491 loss: 9.36020911e-07
Iter: 1492 loss: 9.35689627e-07
Iter: 1493 loss: 9.36125787e-07
Iter: 1494 loss: 9.35498747e-07
Iter: 1495 loss: 9.34994262e-07
Iter: 1496 loss: 9.35244486e-07
Iter: 1497 loss: 9.34622278e-07
Iter: 1498 loss: 9.34453794e-07
Iter: 1499 loss: 9.34397121e-07
Iter: 1500 loss: 9.34150478e-07
Iter: 1501 loss: 9.33967385e-07
Iter: 1502 loss: 9.3378577e-07
Iter: 1503 loss: 9.33460626e-07
Iter: 1504 loss: 9.33790602e-07
Iter: 1505 loss: 9.33186698e-07
Iter: 1506 loss: 9.3293005e-07
Iter: 1507 loss: 9.32991156e-07
Iter: 1508 loss: 9.3269432e-07
Iter: 1509 loss: 9.3220973e-07
Iter: 1510 loss: 9.33337503e-07
Iter: 1511 loss: 9.32022488e-07
Iter: 1512 loss: 9.31563363e-07
Iter: 1513 loss: 9.31265674e-07
Iter: 1514 loss: 9.31098555e-07
Iter: 1515 loss: 9.30588783e-07
Iter: 1516 loss: 9.30609303e-07
Iter: 1517 loss: 9.30316844e-07
Iter: 1518 loss: 9.30124429e-07
Iter: 1519 loss: 9.29986072e-07
Iter: 1520 loss: 9.29490625e-07
Iter: 1521 loss: 9.32087232e-07
Iter: 1522 loss: 9.29379e-07
Iter: 1523 loss: 9.28955274e-07
Iter: 1524 loss: 9.30416377e-07
Iter: 1525 loss: 9.28958684e-07
Iter: 1526 loss: 9.28497798e-07
Iter: 1527 loss: 9.28893428e-07
Iter: 1528 loss: 9.28241036e-07
Iter: 1529 loss: 9.2786081e-07
Iter: 1530 loss: 9.28482e-07
Iter: 1531 loss: 9.27717281e-07
Iter: 1532 loss: 9.27170333e-07
Iter: 1533 loss: 9.27216547e-07
Iter: 1534 loss: 9.26875941e-07
Iter: 1535 loss: 9.26616224e-07
Iter: 1536 loss: 9.26650273e-07
Iter: 1537 loss: 9.26267944e-07
Iter: 1538 loss: 9.25896529e-07
Iter: 1539 loss: 9.25848667e-07
Iter: 1540 loss: 9.25236463e-07
Iter: 1541 loss: 9.29477949e-07
Iter: 1542 loss: 9.25261475e-07
Iter: 1543 loss: 9.24875678e-07
Iter: 1544 loss: 9.24519554e-07
Iter: 1545 loss: 9.24417122e-07
Iter: 1546 loss: 9.23900757e-07
Iter: 1547 loss: 9.2790242e-07
Iter: 1548 loss: 9.23819925e-07
Iter: 1549 loss: 9.23317771e-07
Iter: 1550 loss: 9.23670314e-07
Iter: 1551 loss: 9.23062885e-07
Iter: 1552 loss: 9.22553113e-07
Iter: 1553 loss: 9.26199107e-07
Iter: 1554 loss: 9.22425215e-07
Iter: 1555 loss: 9.22114396e-07
Iter: 1556 loss: 9.21711205e-07
Iter: 1557 loss: 9.21631454e-07
Iter: 1558 loss: 9.2088942e-07
Iter: 1559 loss: 9.24368862e-07
Iter: 1560 loss: 9.20741343e-07
Iter: 1561 loss: 9.20269372e-07
Iter: 1562 loss: 9.24019446e-07
Iter: 1563 loss: 9.20239e-07
Iter: 1564 loss: 9.19848446e-07
Iter: 1565 loss: 9.22858135e-07
Iter: 1566 loss: 9.19768e-07
Iter: 1567 loss: 9.19396598e-07
Iter: 1568 loss: 9.20003345e-07
Iter: 1569 loss: 9.19214e-07
Iter: 1570 loss: 9.19012962e-07
Iter: 1571 loss: 9.18380124e-07
Iter: 1572 loss: 9.24608e-07
Iter: 1573 loss: 9.18388594e-07
Iter: 1574 loss: 9.17771558e-07
Iter: 1575 loss: 9.25024665e-07
Iter: 1576 loss: 9.17680268e-07
Iter: 1577 loss: 9.17249338e-07
Iter: 1578 loss: 9.1686411e-07
Iter: 1579 loss: 9.16736155e-07
Iter: 1580 loss: 9.16102579e-07
Iter: 1581 loss: 9.23484947e-07
Iter: 1582 loss: 9.16089903e-07
Iter: 1583 loss: 9.15675741e-07
Iter: 1584 loss: 9.15147325e-07
Iter: 1585 loss: 9.15121348e-07
Iter: 1586 loss: 9.14512952e-07
Iter: 1587 loss: 9.21270953e-07
Iter: 1588 loss: 9.14544898e-07
Iter: 1589 loss: 9.14123e-07
Iter: 1590 loss: 9.14128236e-07
Iter: 1591 loss: 9.13841745e-07
Iter: 1592 loss: 9.13433098e-07
Iter: 1593 loss: 9.14063e-07
Iter: 1594 loss: 9.13219594e-07
Iter: 1595 loss: 9.12789289e-07
Iter: 1596 loss: 9.13975555e-07
Iter: 1597 loss: 9.12646101e-07
Iter: 1598 loss: 9.12237624e-07
Iter: 1599 loss: 9.15386806e-07
Iter: 1600 loss: 9.12205905e-07
Iter: 1601 loss: 9.119737e-07
Iter: 1602 loss: 9.13171107e-07
Iter: 1603 loss: 9.11948405e-07
Iter: 1604 loss: 9.11751954e-07
Iter: 1605 loss: 9.11318239e-07
Iter: 1606 loss: 9.1609445e-07
Iter: 1607 loss: 9.1118784e-07
Iter: 1608 loss: 9.10668405e-07
Iter: 1609 loss: 9.15671308e-07
Iter: 1610 loss: 9.10631e-07
Iter: 1611 loss: 9.10276071e-07
Iter: 1612 loss: 9.09844459e-07
Iter: 1613 loss: 9.09729465e-07
Iter: 1614 loss: 9.09198207e-07
Iter: 1615 loss: 9.16970578e-07
Iter: 1616 loss: 9.09194e-07
Iter: 1617 loss: 9.08765855e-07
Iter: 1618 loss: 9.08425818e-07
Iter: 1619 loss: 9.08232892e-07
Iter: 1620 loss: 9.07923095e-07
Iter: 1621 loss: 9.0793651e-07
Iter: 1622 loss: 9.07675e-07
Iter: 1623 loss: 9.07131437e-07
Iter: 1624 loss: 9.16866e-07
Iter: 1625 loss: 9.07173671e-07
Iter: 1626 loss: 9.06543278e-07
Iter: 1627 loss: 9.10317567e-07
Iter: 1628 loss: 9.06469779e-07
Iter: 1629 loss: 9.05978311e-07
Iter: 1630 loss: 9.07006324e-07
Iter: 1631 loss: 9.0582239e-07
Iter: 1632 loss: 9.05261231e-07
Iter: 1633 loss: 9.05442278e-07
Iter: 1634 loss: 9.04926708e-07
Iter: 1635 loss: 9.0460469e-07
Iter: 1636 loss: 9.0445684e-07
Iter: 1637 loss: 9.04292392e-07
Iter: 1638 loss: 9.04301658e-07
Iter: 1639 loss: 9.04217757e-07
Iter: 1640 loss: 9.03962246e-07
Iter: 1641 loss: 9.03525574e-07
Iter: 1642 loss: 9.03518753e-07
Iter: 1643 loss: 9.03104819e-07
Iter: 1644 loss: 9.05096954e-07
Iter: 1645 loss: 9.03104194e-07
Iter: 1646 loss: 9.02629836e-07
Iter: 1647 loss: 9.02023544e-07
Iter: 1648 loss: 9.02025363e-07
Iter: 1649 loss: 9.01580336e-07
Iter: 1650 loss: 9.01596536e-07
Iter: 1651 loss: 9.01193289e-07
Iter: 1652 loss: 9.00952614e-07
Iter: 1653 loss: 9.00791861e-07
Iter: 1654 loss: 9.00305508e-07
Iter: 1655 loss: 9.05306081e-07
Iter: 1656 loss: 9.00318469e-07
Iter: 1657 loss: 8.99939209e-07
Iter: 1658 loss: 8.99717804e-07
Iter: 1659 loss: 8.99559e-07
Iter: 1660 loss: 8.98990891e-07
Iter: 1661 loss: 9.02472038e-07
Iter: 1662 loss: 8.99008057e-07
Iter: 1663 loss: 8.98668077e-07
Iter: 1664 loss: 8.98264545e-07
Iter: 1665 loss: 8.98208384e-07
Iter: 1666 loss: 8.98174562e-07
Iter: 1667 loss: 8.98013923e-07
Iter: 1668 loss: 8.9773954e-07
Iter: 1669 loss: 8.98317126e-07
Iter: 1670 loss: 8.97661323e-07
Iter: 1671 loss: 8.9743537e-07
Iter: 1672 loss: 8.96923154e-07
Iter: 1673 loss: 9.05452282e-07
Iter: 1674 loss: 8.96898769e-07
Iter: 1675 loss: 8.96579877e-07
Iter: 1676 loss: 9.00854e-07
Iter: 1677 loss: 8.96577831e-07
Iter: 1678 loss: 8.9626e-07
Iter: 1679 loss: 8.96182428e-07
Iter: 1680 loss: 8.96056463e-07
Iter: 1681 loss: 8.95754965e-07
Iter: 1682 loss: 8.97473228e-07
Iter: 1683 loss: 8.95738367e-07
Iter: 1684 loss: 8.95348194e-07
Iter: 1685 loss: 8.9537707e-07
Iter: 1686 loss: 8.95105245e-07
Iter: 1687 loss: 8.94816594e-07
Iter: 1688 loss: 8.97520238e-07
Iter: 1689 loss: 8.94815e-07
Iter: 1690 loss: 8.94485e-07
Iter: 1691 loss: 8.94990364e-07
Iter: 1692 loss: 8.94391633e-07
Iter: 1693 loss: 8.94144478e-07
Iter: 1694 loss: 8.94858204e-07
Iter: 1695 loss: 8.94019422e-07
Iter: 1696 loss: 8.93740662e-07
Iter: 1697 loss: 8.93475317e-07
Iter: 1698 loss: 8.9338937e-07
Iter: 1699 loss: 8.9289324e-07
Iter: 1700 loss: 8.95646963e-07
Iter: 1701 loss: 8.927517e-07
Iter: 1702 loss: 8.92563946e-07
Iter: 1703 loss: 8.92437129e-07
Iter: 1704 loss: 8.92228115e-07
Iter: 1705 loss: 8.91837431e-07
Iter: 1706 loss: 8.91775e-07
Iter: 1707 loss: 8.91525247e-07
Iter: 1708 loss: 8.91364095e-07
Iter: 1709 loss: 8.91229433e-07
Iter: 1710 loss: 8.90671856e-07
Iter: 1711 loss: 8.92669789e-07
Iter: 1712 loss: 8.90508431e-07
Iter: 1713 loss: 8.90239676e-07
Iter: 1714 loss: 8.93785796e-07
Iter: 1715 loss: 8.90215631e-07
Iter: 1716 loss: 8.90055617e-07
Iter: 1717 loss: 8.89598709e-07
Iter: 1718 loss: 8.89597572e-07
Iter: 1719 loss: 8.89234059e-07
Iter: 1720 loss: 8.90757178e-07
Iter: 1721 loss: 8.8907e-07
Iter: 1722 loss: 8.88779311e-07
Iter: 1723 loss: 8.91980449e-07
Iter: 1724 loss: 8.88746285e-07
Iter: 1725 loss: 8.88597469e-07
Iter: 1726 loss: 8.89049147e-07
Iter: 1727 loss: 8.88462807e-07
Iter: 1728 loss: 8.88081445e-07
Iter: 1729 loss: 8.88162617e-07
Iter: 1730 loss: 8.87879082e-07
Iter: 1731 loss: 8.8751267e-07
Iter: 1732 loss: 8.89367925e-07
Iter: 1733 loss: 8.874797e-07
Iter: 1734 loss: 8.87182182e-07
Iter: 1735 loss: 8.88864861e-07
Iter: 1736 loss: 8.87174451e-07
Iter: 1737 loss: 8.86842543e-07
Iter: 1738 loss: 8.8887e-07
Iter: 1739 loss: 8.86793146e-07
Iter: 1740 loss: 8.86698331e-07
Iter: 1741 loss: 8.86406724e-07
Iter: 1742 loss: 8.9042004e-07
Iter: 1743 loss: 8.86355e-07
Iter: 1744 loss: 8.86014675e-07
Iter: 1745 loss: 8.87536658e-07
Iter: 1746 loss: 8.85963061e-07
Iter: 1747 loss: 8.85664747e-07
Iter: 1748 loss: 8.8603872e-07
Iter: 1749 loss: 8.85581755e-07
Iter: 1750 loss: 8.85175268e-07
Iter: 1751 loss: 8.86929911e-07
Iter: 1752 loss: 8.85025e-07
Iter: 1753 loss: 8.84837959e-07
Iter: 1754 loss: 8.84890937e-07
Iter: 1755 loss: 8.8455846e-07
Iter: 1756 loss: 8.84267479e-07
Iter: 1757 loss: 8.86394105e-07
Iter: 1758 loss: 8.84288397e-07
Iter: 1759 loss: 8.84017368e-07
Iter: 1760 loss: 8.84308065e-07
Iter: 1761 loss: 8.8388208e-07
Iter: 1762 loss: 8.83554719e-07
Iter: 1763 loss: 8.84246276e-07
Iter: 1764 loss: 8.83451207e-07
Iter: 1765 loss: 8.83173129e-07
Iter: 1766 loss: 8.84336885e-07
Iter: 1767 loss: 8.83085249e-07
Iter: 1768 loss: 8.82854238e-07
Iter: 1769 loss: 8.83379926e-07
Iter: 1770 loss: 8.82733275e-07
Iter: 1771 loss: 8.82681434e-07
Iter: 1772 loss: 8.82545464e-07
Iter: 1773 loss: 8.82511358e-07
Iter: 1774 loss: 8.82360212e-07
Iter: 1775 loss: 8.83486848e-07
Iter: 1776 loss: 8.82313316e-07
Iter: 1777 loss: 8.82026939e-07
Iter: 1778 loss: 8.82557174e-07
Iter: 1779 loss: 8.81983112e-07
Iter: 1780 loss: 8.81655865e-07
Iter: 1781 loss: 8.82004656e-07
Iter: 1782 loss: 8.81543372e-07
Iter: 1783 loss: 8.81304743e-07
Iter: 1784 loss: 8.84261055e-07
Iter: 1785 loss: 8.81265919e-07
Iter: 1786 loss: 8.81005235e-07
Iter: 1787 loss: 8.80998869e-07
Iter: 1788 loss: 8.80901e-07
Iter: 1789 loss: 8.80606e-07
Iter: 1790 loss: 8.81862661e-07
Iter: 1791 loss: 8.80465109e-07
Iter: 1792 loss: 8.8026087e-07
Iter: 1793 loss: 8.80010361e-07
Iter: 1794 loss: 8.7996284e-07
Iter: 1795 loss: 8.79710683e-07
Iter: 1796 loss: 8.82499251e-07
Iter: 1797 loss: 8.7969039e-07
Iter: 1798 loss: 8.79416575e-07
Iter: 1799 loss: 8.79674189e-07
Iter: 1800 loss: 8.79325398e-07
Iter: 1801 loss: 8.79013669e-07
Iter: 1802 loss: 8.79042545e-07
Iter: 1803 loss: 8.78833e-07
Iter: 1804 loss: 8.78821879e-07
Iter: 1805 loss: 8.78717174e-07
Iter: 1806 loss: 8.78488549e-07
Iter: 1807 loss: 8.78234289e-07
Iter: 1808 loss: 8.8427e-07
Iter: 1809 loss: 8.78223e-07
Iter: 1810 loss: 8.77878449e-07
Iter: 1811 loss: 8.78715468e-07
Iter: 1812 loss: 8.77889079e-07
Iter: 1813 loss: 8.77670345e-07
Iter: 1814 loss: 8.77558762e-07
Iter: 1815 loss: 8.77469e-07
Iter: 1816 loss: 8.76970603e-07
Iter: 1817 loss: 8.78676076e-07
Iter: 1818 loss: 8.76922059e-07
Iter: 1819 loss: 8.76585204e-07
Iter: 1820 loss: 8.7621e-07
Iter: 1821 loss: 8.76126421e-07
Iter: 1822 loss: 8.75705894e-07
Iter: 1823 loss: 8.75695946e-07
Iter: 1824 loss: 8.75328624e-07
Iter: 1825 loss: 8.75380238e-07
Iter: 1826 loss: 8.75063108e-07
Iter: 1827 loss: 8.74643831e-07
Iter: 1828 loss: 8.78444098e-07
Iter: 1829 loss: 8.74673333e-07
Iter: 1830 loss: 8.7436274e-07
Iter: 1831 loss: 8.74139e-07
Iter: 1832 loss: 8.74117859e-07
Iter: 1833 loss: 8.73601607e-07
Iter: 1834 loss: 8.76067e-07
Iter: 1835 loss: 8.73389e-07
Iter: 1836 loss: 8.73126623e-07
Iter: 1837 loss: 8.74683792e-07
Iter: 1838 loss: 8.73097065e-07
Iter: 1839 loss: 8.72898795e-07
Iter: 1840 loss: 8.72898227e-07
Iter: 1841 loss: 8.72667897e-07
Iter: 1842 loss: 8.72454279e-07
Iter: 1843 loss: 8.72510611e-07
Iter: 1844 loss: 8.72259363e-07
Iter: 1845 loss: 8.71874875e-07
Iter: 1846 loss: 8.71826103e-07
Iter: 1847 loss: 8.71365955e-07
Iter: 1848 loss: 8.76483e-07
Iter: 1849 loss: 8.71420582e-07
Iter: 1850 loss: 8.7111016e-07
Iter: 1851 loss: 8.70634835e-07
Iter: 1852 loss: 8.81247502e-07
Iter: 1853 loss: 8.70643703e-07
Iter: 1854 loss: 8.69989549e-07
Iter: 1855 loss: 8.77348612e-07
Iter: 1856 loss: 8.70016493e-07
Iter: 1857 loss: 8.69596e-07
Iter: 1858 loss: 8.6968e-07
Iter: 1859 loss: 8.69380415e-07
Iter: 1860 loss: 8.68947268e-07
Iter: 1861 loss: 8.72503676e-07
Iter: 1862 loss: 8.68942152e-07
Iter: 1863 loss: 8.68699317e-07
Iter: 1864 loss: 8.69433507e-07
Iter: 1865 loss: 8.68571306e-07
Iter: 1866 loss: 8.68166921e-07
Iter: 1867 loss: 8.68282e-07
Iter: 1868 loss: 8.67866447e-07
Iter: 1869 loss: 8.67537949e-07
Iter: 1870 loss: 8.69577605e-07
Iter: 1871 loss: 8.67521294e-07
Iter: 1872 loss: 8.67368385e-07
Iter: 1873 loss: 8.67378048e-07
Iter: 1874 loss: 8.67145388e-07
Iter: 1875 loss: 8.67723543e-07
Iter: 1876 loss: 8.67112419e-07
Iter: 1877 loss: 8.66973e-07
Iter: 1878 loss: 8.66638175e-07
Iter: 1879 loss: 8.6718e-07
Iter: 1880 loss: 8.66319169e-07
Iter: 1881 loss: 8.65794618e-07
Iter: 1882 loss: 8.65776201e-07
Iter: 1883 loss: 8.65474135e-07
Iter: 1884 loss: 8.64990852e-07
Iter: 1885 loss: 8.65035759e-07
Iter: 1886 loss: 8.64553272e-07
Iter: 1887 loss: 8.70391034e-07
Iter: 1888 loss: 8.64535139e-07
Iter: 1889 loss: 8.64196863e-07
Iter: 1890 loss: 8.64543324e-07
Iter: 1891 loss: 8.64038384e-07
Iter: 1892 loss: 8.63639173e-07
Iter: 1893 loss: 8.64474259e-07
Iter: 1894 loss: 8.63499963e-07
Iter: 1895 loss: 8.63074774e-07
Iter: 1896 loss: 8.63151286e-07
Iter: 1897 loss: 8.62857917e-07
Iter: 1898 loss: 8.62353943e-07
Iter: 1899 loss: 8.63185278e-07
Iter: 1900 loss: 8.62181878e-07
Iter: 1901 loss: 8.61815238e-07
Iter: 1902 loss: 8.63697551e-07
Iter: 1903 loss: 8.61759872e-07
Iter: 1904 loss: 8.61378e-07
Iter: 1905 loss: 8.61821036e-07
Iter: 1906 loss: 8.61243109e-07
Iter: 1907 loss: 8.60978844e-07
Iter: 1908 loss: 8.63268554e-07
Iter: 1909 loss: 8.60982709e-07
Iter: 1910 loss: 8.60783757e-07
Iter: 1911 loss: 8.6085106e-07
Iter: 1912 loss: 8.60642217e-07
Iter: 1913 loss: 8.60441787e-07
Iter: 1914 loss: 8.59952479e-07
Iter: 1915 loss: 8.69198288e-07
Iter: 1916 loss: 8.59935597e-07
Iter: 1917 loss: 8.59406e-07
Iter: 1918 loss: 8.63424361e-07
Iter: 1919 loss: 8.59416332e-07
Iter: 1920 loss: 8.58874614e-07
Iter: 1921 loss: 8.58925546e-07
Iter: 1922 loss: 8.58431065e-07
Iter: 1923 loss: 8.57930729e-07
Iter: 1924 loss: 8.58925773e-07
Iter: 1925 loss: 8.57762302e-07
Iter: 1926 loss: 8.5708723e-07
Iter: 1927 loss: 8.60864134e-07
Iter: 1928 loss: 8.56958934e-07
Iter: 1929 loss: 8.56541078e-07
Iter: 1930 loss: 8.58734893e-07
Iter: 1931 loss: 8.56485201e-07
Iter: 1932 loss: 8.56037673e-07
Iter: 1933 loss: 8.55490612e-07
Iter: 1934 loss: 8.5537414e-07
Iter: 1935 loss: 8.55004714e-07
Iter: 1936 loss: 8.61400167e-07
Iter: 1937 loss: 8.55002384e-07
Iter: 1938 loss: 8.5452632e-07
Iter: 1939 loss: 8.54344933e-07
Iter: 1940 loss: 8.54110681e-07
Iter: 1941 loss: 8.5397653e-07
Iter: 1942 loss: 8.53737e-07
Iter: 1943 loss: 8.53608071e-07
Iter: 1944 loss: 8.53587153e-07
Iter: 1945 loss: 8.53393715e-07
Iter: 1946 loss: 8.53146219e-07
Iter: 1947 loss: 8.52854e-07
Iter: 1948 loss: 8.52798394e-07
Iter: 1949 loss: 8.52343931e-07
Iter: 1950 loss: 8.54466748e-07
Iter: 1951 loss: 8.52210292e-07
Iter: 1952 loss: 8.51723939e-07
Iter: 1953 loss: 8.52053404e-07
Iter: 1954 loss: 8.51423749e-07
Iter: 1955 loss: 8.5079779e-07
Iter: 1956 loss: 8.54738232e-07
Iter: 1957 loss: 8.50757033e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi2_phi3/500_500_500_500_1
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0
+ date
Mon Oct 26 14:49:54 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0c9ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0c5e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0c56158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1fca59d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0c308c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0c306a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0bf1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0c046a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0be9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0ba0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0be9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0ac8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0ad7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0a7a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0ad7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0ad7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0a8cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e09f96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0a64378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e09ecd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e09ec598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e098d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e098db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e0917950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e09178c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e091e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e091e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e089a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e08b7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e084ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e084cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e082b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e082bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e07e9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1b3b09d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1e07c40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.72552152e-06
Iter: 2 loss: 8.11844438e-06
Iter: 3 loss: 8.11841e-06
Iter: 4 loss: 7.31004729e-06
Iter: 5 loss: 1.10796464e-05
Iter: 6 loss: 7.16082195e-06
Iter: 7 loss: 6.82817699e-06
Iter: 8 loss: 7.55711199e-06
Iter: 9 loss: 6.70004738e-06
Iter: 10 loss: 6.34593516e-06
Iter: 11 loss: 7.25106611e-06
Iter: 12 loss: 6.22367952e-06
Iter: 13 loss: 5.83337714e-06
Iter: 14 loss: 6.02369346e-06
Iter: 15 loss: 5.57218027e-06
Iter: 16 loss: 5.34332776e-06
Iter: 17 loss: 5.27299153e-06
Iter: 18 loss: 5.13741361e-06
Iter: 19 loss: 4.67992049e-06
Iter: 20 loss: 8.27983604e-06
Iter: 21 loss: 4.64807181e-06
Iter: 22 loss: 4.46163858e-06
Iter: 23 loss: 4.30536602e-06
Iter: 24 loss: 4.25269e-06
Iter: 25 loss: 4.11181418e-06
Iter: 26 loss: 5.88669172e-06
Iter: 27 loss: 4.11058136e-06
Iter: 28 loss: 3.94093331e-06
Iter: 29 loss: 4.01720445e-06
Iter: 30 loss: 3.82566031e-06
Iter: 31 loss: 3.69643431e-06
Iter: 32 loss: 3.44198725e-06
Iter: 33 loss: 8.50029483e-06
Iter: 34 loss: 3.43957777e-06
Iter: 35 loss: 3.37590245e-06
Iter: 36 loss: 3.32236846e-06
Iter: 37 loss: 3.22460301e-06
Iter: 38 loss: 3.33642561e-06
Iter: 39 loss: 3.17211834e-06
Iter: 40 loss: 3.04778723e-06
Iter: 41 loss: 3.34608e-06
Iter: 42 loss: 3.00283e-06
Iter: 43 loss: 2.90221124e-06
Iter: 44 loss: 4.12942063e-06
Iter: 45 loss: 2.90109119e-06
Iter: 46 loss: 2.8435627e-06
Iter: 47 loss: 3.01529781e-06
Iter: 48 loss: 2.82612791e-06
Iter: 49 loss: 2.77501181e-06
Iter: 50 loss: 2.70739292e-06
Iter: 51 loss: 2.70336704e-06
Iter: 52 loss: 2.62442791e-06
Iter: 53 loss: 3.27259067e-06
Iter: 54 loss: 2.61949026e-06
Iter: 55 loss: 2.52939094e-06
Iter: 56 loss: 2.73183559e-06
Iter: 57 loss: 2.4953174e-06
Iter: 58 loss: 2.45520596e-06
Iter: 59 loss: 2.39976248e-06
Iter: 60 loss: 2.39732071e-06
Iter: 61 loss: 2.39390647e-06
Iter: 62 loss: 2.36726305e-06
Iter: 63 loss: 2.34133904e-06
Iter: 64 loss: 2.27913051e-06
Iter: 65 loss: 2.963219e-06
Iter: 66 loss: 2.27275359e-06
Iter: 67 loss: 2.23523e-06
Iter: 68 loss: 2.69048724e-06
Iter: 69 loss: 2.23481288e-06
Iter: 70 loss: 2.20130391e-06
Iter: 71 loss: 2.49338154e-06
Iter: 72 loss: 2.19955359e-06
Iter: 73 loss: 2.17583124e-06
Iter: 74 loss: 2.15531645e-06
Iter: 75 loss: 2.14897864e-06
Iter: 76 loss: 2.11942756e-06
Iter: 77 loss: 2.49439927e-06
Iter: 78 loss: 2.11919792e-06
Iter: 79 loss: 2.09777022e-06
Iter: 80 loss: 2.10578764e-06
Iter: 81 loss: 2.08280017e-06
Iter: 82 loss: 2.0547011e-06
Iter: 83 loss: 2.12808527e-06
Iter: 84 loss: 2.04511593e-06
Iter: 85 loss: 2.02332376e-06
Iter: 86 loss: 2.00919385e-06
Iter: 87 loss: 2.00080649e-06
Iter: 88 loss: 1.97446047e-06
Iter: 89 loss: 1.97331838e-06
Iter: 90 loss: 1.95830921e-06
Iter: 91 loss: 1.92813036e-06
Iter: 92 loss: 2.49473669e-06
Iter: 93 loss: 1.92770858e-06
Iter: 94 loss: 1.9039735e-06
Iter: 95 loss: 2.04690559e-06
Iter: 96 loss: 1.90099809e-06
Iter: 97 loss: 1.87141745e-06
Iter: 98 loss: 1.98088264e-06
Iter: 99 loss: 1.86417401e-06
Iter: 100 loss: 1.85279521e-06
Iter: 101 loss: 1.83479506e-06
Iter: 102 loss: 1.83461282e-06
Iter: 103 loss: 1.82356598e-06
Iter: 104 loss: 1.82125132e-06
Iter: 105 loss: 1.80859752e-06
Iter: 106 loss: 1.79557287e-06
Iter: 107 loss: 1.79314713e-06
Iter: 108 loss: 1.780204e-06
Iter: 109 loss: 1.9402521e-06
Iter: 110 loss: 1.78006587e-06
Iter: 111 loss: 1.76938761e-06
Iter: 112 loss: 1.77756135e-06
Iter: 113 loss: 1.7628621e-06
Iter: 114 loss: 1.74954016e-06
Iter: 115 loss: 1.7765467e-06
Iter: 116 loss: 1.74415663e-06
Iter: 117 loss: 1.73248725e-06
Iter: 118 loss: 1.72459204e-06
Iter: 119 loss: 1.72030309e-06
Iter: 120 loss: 1.70976557e-06
Iter: 121 loss: 1.70935903e-06
Iter: 122 loss: 1.69755492e-06
Iter: 123 loss: 1.68717258e-06
Iter: 124 loss: 1.68407189e-06
Iter: 125 loss: 1.67223266e-06
Iter: 126 loss: 1.66131417e-06
Iter: 127 loss: 1.6584454e-06
Iter: 128 loss: 1.6595443e-06
Iter: 129 loss: 1.64953576e-06
Iter: 130 loss: 1.6444161e-06
Iter: 131 loss: 1.63293043e-06
Iter: 132 loss: 1.79387587e-06
Iter: 133 loss: 1.63234449e-06
Iter: 134 loss: 1.62269214e-06
Iter: 135 loss: 1.65693564e-06
Iter: 136 loss: 1.62017091e-06
Iter: 137 loss: 1.60850573e-06
Iter: 138 loss: 1.70041494e-06
Iter: 139 loss: 1.60767661e-06
Iter: 140 loss: 1.60241927e-06
Iter: 141 loss: 1.60005152e-06
Iter: 142 loss: 1.59738784e-06
Iter: 143 loss: 1.58918749e-06
Iter: 144 loss: 1.65985944e-06
Iter: 145 loss: 1.58871535e-06
Iter: 146 loss: 1.58361308e-06
Iter: 147 loss: 1.59527372e-06
Iter: 148 loss: 1.58170201e-06
Iter: 149 loss: 1.57633826e-06
Iter: 150 loss: 1.57068666e-06
Iter: 151 loss: 1.56972453e-06
Iter: 152 loss: 1.56282329e-06
Iter: 153 loss: 1.60953152e-06
Iter: 154 loss: 1.56217629e-06
Iter: 155 loss: 1.55445036e-06
Iter: 156 loss: 1.58964076e-06
Iter: 157 loss: 1.5529979e-06
Iter: 158 loss: 1.54713553e-06
Iter: 159 loss: 1.53332098e-06
Iter: 160 loss: 1.6921947e-06
Iter: 161 loss: 1.53204792e-06
Iter: 162 loss: 1.53357678e-06
Iter: 163 loss: 1.52779023e-06
Iter: 164 loss: 1.52336497e-06
Iter: 165 loss: 1.51964673e-06
Iter: 166 loss: 1.51842949e-06
Iter: 167 loss: 1.5135588e-06
Iter: 168 loss: 1.51093946e-06
Iter: 169 loss: 1.50883602e-06
Iter: 170 loss: 1.50687515e-06
Iter: 171 loss: 1.50504718e-06
Iter: 172 loss: 1.50199628e-06
Iter: 173 loss: 1.49429377e-06
Iter: 174 loss: 1.56486249e-06
Iter: 175 loss: 1.49318885e-06
Iter: 176 loss: 1.48975664e-06
Iter: 177 loss: 1.48881213e-06
Iter: 178 loss: 1.48523645e-06
Iter: 179 loss: 1.48092738e-06
Iter: 180 loss: 1.480479e-06
Iter: 181 loss: 1.47394e-06
Iter: 182 loss: 1.50690892e-06
Iter: 183 loss: 1.4728621e-06
Iter: 184 loss: 1.46953835e-06
Iter: 185 loss: 1.47047876e-06
Iter: 186 loss: 1.46719617e-06
Iter: 187 loss: 1.46330797e-06
Iter: 188 loss: 1.46330615e-06
Iter: 189 loss: 1.460352e-06
Iter: 190 loss: 1.45346803e-06
Iter: 191 loss: 1.53629708e-06
Iter: 192 loss: 1.45288766e-06
Iter: 193 loss: 1.44621993e-06
Iter: 194 loss: 1.45491731e-06
Iter: 195 loss: 1.44280932e-06
Iter: 196 loss: 1.44248702e-06
Iter: 197 loss: 1.43890361e-06
Iter: 198 loss: 1.43707871e-06
Iter: 199 loss: 1.43220575e-06
Iter: 200 loss: 1.46789898e-06
Iter: 201 loss: 1.43117518e-06
Iter: 202 loss: 1.43086527e-06
Iter: 203 loss: 1.42901797e-06
Iter: 204 loss: 1.42694194e-06
Iter: 205 loss: 1.42364024e-06
Iter: 206 loss: 1.42360955e-06
Iter: 207 loss: 1.42061072e-06
Iter: 208 loss: 1.43937473e-06
Iter: 209 loss: 1.42027739e-06
Iter: 210 loss: 1.41664759e-06
Iter: 211 loss: 1.4177914e-06
Iter: 212 loss: 1.41405928e-06
Iter: 213 loss: 1.41061537e-06
Iter: 214 loss: 1.43124066e-06
Iter: 215 loss: 1.41017404e-06
Iter: 216 loss: 1.40756572e-06
Iter: 217 loss: 1.40671398e-06
Iter: 218 loss: 1.40518955e-06
Iter: 219 loss: 1.40317456e-06
Iter: 220 loss: 1.40297095e-06
Iter: 221 loss: 1.40119323e-06
Iter: 222 loss: 1.3978356e-06
Iter: 223 loss: 1.47115873e-06
Iter: 224 loss: 1.39783015e-06
Iter: 225 loss: 1.39447513e-06
Iter: 226 loss: 1.39429164e-06
Iter: 227 loss: 1.39174267e-06
Iter: 228 loss: 1.38985638e-06
Iter: 229 loss: 1.38930784e-06
Iter: 230 loss: 1.38666599e-06
Iter: 231 loss: 1.38161522e-06
Iter: 232 loss: 1.48588902e-06
Iter: 233 loss: 1.38155281e-06
Iter: 234 loss: 1.37988548e-06
Iter: 235 loss: 1.37982408e-06
Iter: 236 loss: 1.37787868e-06
Iter: 237 loss: 1.3798898e-06
Iter: 238 loss: 1.37680945e-06
Iter: 239 loss: 1.37516508e-06
Iter: 240 loss: 1.37572613e-06
Iter: 241 loss: 1.37397615e-06
Iter: 242 loss: 1.37155769e-06
Iter: 243 loss: 1.38891187e-06
Iter: 244 loss: 1.37133065e-06
Iter: 245 loss: 1.36989911e-06
Iter: 246 loss: 1.36877679e-06
Iter: 247 loss: 1.36832307e-06
Iter: 248 loss: 1.36522544e-06
Iter: 249 loss: 1.36726624e-06
Iter: 250 loss: 1.36323774e-06
Iter: 251 loss: 1.36142023e-06
Iter: 252 loss: 1.36136896e-06
Iter: 253 loss: 1.35955531e-06
Iter: 254 loss: 1.35846108e-06
Iter: 255 loss: 1.35771916e-06
Iter: 256 loss: 1.35576977e-06
Iter: 257 loss: 1.35486425e-06
Iter: 258 loss: 1.35387188e-06
Iter: 259 loss: 1.35186963e-06
Iter: 260 loss: 1.38340818e-06
Iter: 261 loss: 1.35187088e-06
Iter: 262 loss: 1.34941217e-06
Iter: 263 loss: 1.34970924e-06
Iter: 264 loss: 1.34751826e-06
Iter: 265 loss: 1.34594939e-06
Iter: 266 loss: 1.346516e-06
Iter: 267 loss: 1.34481934e-06
Iter: 268 loss: 1.3426245e-06
Iter: 269 loss: 1.37468146e-06
Iter: 270 loss: 1.34262723e-06
Iter: 271 loss: 1.34142169e-06
Iter: 272 loss: 1.33958042e-06
Iter: 273 loss: 1.33956246e-06
Iter: 274 loss: 1.33809692e-06
Iter: 275 loss: 1.33803735e-06
Iter: 276 loss: 1.33719311e-06
Iter: 277 loss: 1.33533445e-06
Iter: 278 loss: 1.3621102e-06
Iter: 279 loss: 1.33524873e-06
Iter: 280 loss: 1.33261062e-06
Iter: 281 loss: 1.34518473e-06
Iter: 282 loss: 1.33213393e-06
Iter: 283 loss: 1.33054323e-06
Iter: 284 loss: 1.340072e-06
Iter: 285 loss: 1.33033518e-06
Iter: 286 loss: 1.32854814e-06
Iter: 287 loss: 1.33353933e-06
Iter: 288 loss: 1.32798164e-06
Iter: 289 loss: 1.32677451e-06
Iter: 290 loss: 1.32487821e-06
Iter: 291 loss: 1.32485093e-06
Iter: 292 loss: 1.32322339e-06
Iter: 293 loss: 1.34516938e-06
Iter: 294 loss: 1.3231969e-06
Iter: 295 loss: 1.32158107e-06
Iter: 296 loss: 1.32946684e-06
Iter: 297 loss: 1.32133096e-06
Iter: 298 loss: 1.32051173e-06
Iter: 299 loss: 1.31862407e-06
Iter: 300 loss: 1.34237985e-06
Iter: 301 loss: 1.31851743e-06
Iter: 302 loss: 1.31814568e-06
Iter: 303 loss: 1.3173194e-06
Iter: 304 loss: 1.31653e-06
Iter: 305 loss: 1.31476497e-06
Iter: 306 loss: 1.33958667e-06
Iter: 307 loss: 1.314678e-06
Iter: 308 loss: 1.31382399e-06
Iter: 309 loss: 1.31364345e-06
Iter: 310 loss: 1.31288925e-06
Iter: 311 loss: 1.31122852e-06
Iter: 312 loss: 1.3363815e-06
Iter: 313 loss: 1.31118099e-06
Iter: 314 loss: 1.30916146e-06
Iter: 315 loss: 1.31921922e-06
Iter: 316 loss: 1.30882472e-06
Iter: 317 loss: 1.30716523e-06
Iter: 318 loss: 1.30830108e-06
Iter: 319 loss: 1.30613898e-06
Iter: 320 loss: 1.30555668e-06
Iter: 321 loss: 1.30521903e-06
Iter: 322 loss: 1.30451485e-06
Iter: 323 loss: 1.30275066e-06
Iter: 324 loss: 1.31814545e-06
Iter: 325 loss: 1.30248657e-06
Iter: 326 loss: 1.30074068e-06
Iter: 327 loss: 1.31046454e-06
Iter: 328 loss: 1.30051035e-06
Iter: 329 loss: 1.29937462e-06
Iter: 330 loss: 1.30223361e-06
Iter: 331 loss: 1.29895818e-06
Iter: 332 loss: 1.29795762e-06
Iter: 333 loss: 1.29567206e-06
Iter: 334 loss: 1.32745151e-06
Iter: 335 loss: 1.29556815e-06
Iter: 336 loss: 1.29366992e-06
Iter: 337 loss: 1.31569982e-06
Iter: 338 loss: 1.29362502e-06
Iter: 339 loss: 1.29144269e-06
Iter: 340 loss: 1.2991012e-06
Iter: 341 loss: 1.29086152e-06
Iter: 342 loss: 1.28987597e-06
Iter: 343 loss: 1.28887132e-06
Iter: 344 loss: 1.28868624e-06
Iter: 345 loss: 1.28800764e-06
Iter: 346 loss: 1.28778674e-06
Iter: 347 loss: 1.28713123e-06
Iter: 348 loss: 1.2854141e-06
Iter: 349 loss: 1.29948421e-06
Iter: 350 loss: 1.28508395e-06
Iter: 351 loss: 1.28363922e-06
Iter: 352 loss: 1.29822729e-06
Iter: 353 loss: 1.2835809e-06
Iter: 354 loss: 1.28241163e-06
Iter: 355 loss: 1.29458954e-06
Iter: 356 loss: 1.28236866e-06
Iter: 357 loss: 1.28161469e-06
Iter: 358 loss: 1.28627835e-06
Iter: 359 loss: 1.2815301e-06
Iter: 360 loss: 1.2809553e-06
Iter: 361 loss: 1.27965063e-06
Iter: 362 loss: 1.29834052e-06
Iter: 363 loss: 1.27957946e-06
Iter: 364 loss: 1.27886631e-06
Iter: 365 loss: 1.27869271e-06
Iter: 366 loss: 1.27815656e-06
Iter: 367 loss: 1.27739941e-06
Iter: 368 loss: 1.27737212e-06
Iter: 369 loss: 1.27641e-06
Iter: 370 loss: 1.27823955e-06
Iter: 371 loss: 1.27600038e-06
Iter: 372 loss: 1.2749797e-06
Iter: 373 loss: 1.28294437e-06
Iter: 374 loss: 1.27487851e-06
Iter: 375 loss: 1.2743385e-06
Iter: 376 loss: 1.27339354e-06
Iter: 377 loss: 1.27341332e-06
Iter: 378 loss: 1.2726457e-06
Iter: 379 loss: 1.28137015e-06
Iter: 380 loss: 1.27265082e-06
Iter: 381 loss: 1.27181556e-06
Iter: 382 loss: 1.27304588e-06
Iter: 383 loss: 1.27144017e-06
Iter: 384 loss: 1.27087549e-06
Iter: 385 loss: 1.26969144e-06
Iter: 386 loss: 1.28722763e-06
Iter: 387 loss: 1.26963084e-06
Iter: 388 loss: 1.26897896e-06
Iter: 389 loss: 1.26888631e-06
Iter: 390 loss: 1.26811562e-06
Iter: 391 loss: 1.2676287e-06
Iter: 392 loss: 1.2673172e-06
Iter: 393 loss: 1.26597922e-06
Iter: 394 loss: 1.27354804e-06
Iter: 395 loss: 1.26580767e-06
Iter: 396 loss: 1.26503539e-06
Iter: 397 loss: 1.2661643e-06
Iter: 398 loss: 1.26468399e-06
Iter: 399 loss: 1.2640387e-06
Iter: 400 loss: 1.27391013e-06
Iter: 401 loss: 1.26404166e-06
Iter: 402 loss: 1.2637347e-06
Iter: 403 loss: 1.26308157e-06
Iter: 404 loss: 1.27662429e-06
Iter: 405 loss: 1.26310124e-06
Iter: 406 loss: 1.26245482e-06
Iter: 407 loss: 1.26244959e-06
Iter: 408 loss: 1.26211467e-06
Iter: 409 loss: 1.2612802e-06
Iter: 410 loss: 1.27128203e-06
Iter: 411 loss: 1.26119301e-06
Iter: 412 loss: 1.26016801e-06
Iter: 413 loss: 1.25990209e-06
Iter: 414 loss: 1.25923066e-06
Iter: 415 loss: 1.25880706e-06
Iter: 416 loss: 1.25846827e-06
Iter: 417 loss: 1.25778729e-06
Iter: 418 loss: 1.25694282e-06
Iter: 419 loss: 1.25685301e-06
Iter: 420 loss: 1.25617544e-06
Iter: 421 loss: 1.25564247e-06
Iter: 422 loss: 1.25543693e-06
Iter: 423 loss: 1.2549001e-06
Iter: 424 loss: 1.25485417e-06
Iter: 425 loss: 1.25417569e-06
Iter: 426 loss: 1.25439124e-06
Iter: 427 loss: 1.25369309e-06
Iter: 428 loss: 1.25298959e-06
Iter: 429 loss: 1.25648035e-06
Iter: 430 loss: 1.25282668e-06
Iter: 431 loss: 1.2521873e-06
Iter: 432 loss: 1.25146039e-06
Iter: 433 loss: 1.25136535e-06
Iter: 434 loss: 1.25045801e-06
Iter: 435 loss: 1.25043834e-06
Iter: 436 loss: 1.24989992e-06
Iter: 437 loss: 1.24902544e-06
Iter: 438 loss: 1.24902749e-06
Iter: 439 loss: 1.24894859e-06
Iter: 440 loss: 1.24857934e-06
Iter: 441 loss: 1.24834514e-06
Iter: 442 loss: 1.24784049e-06
Iter: 443 loss: 1.25336237e-06
Iter: 444 loss: 1.24773055e-06
Iter: 445 loss: 1.24704115e-06
Iter: 446 loss: 1.25509655e-06
Iter: 447 loss: 1.24702149e-06
Iter: 448 loss: 1.24660653e-06
Iter: 449 loss: 1.24608664e-06
Iter: 450 loss: 1.2460174e-06
Iter: 451 loss: 1.24532448e-06
Iter: 452 loss: 1.24566679e-06
Iter: 453 loss: 1.2448404e-06
Iter: 454 loss: 1.24416e-06
Iter: 455 loss: 1.24616e-06
Iter: 456 loss: 1.24392602e-06
Iter: 457 loss: 1.24332314e-06
Iter: 458 loss: 1.25045165e-06
Iter: 459 loss: 1.2432879e-06
Iter: 460 loss: 1.24273447e-06
Iter: 461 loss: 1.24206656e-06
Iter: 462 loss: 1.24197618e-06
Iter: 463 loss: 1.24126313e-06
Iter: 464 loss: 1.25167139e-06
Iter: 465 loss: 1.2412487e-06
Iter: 466 loss: 1.24090298e-06
Iter: 467 loss: 1.24141161e-06
Iter: 468 loss: 1.24073063e-06
Iter: 469 loss: 1.24002884e-06
Iter: 470 loss: 1.23953919e-06
Iter: 471 loss: 1.23930431e-06
Iter: 472 loss: 1.23898076e-06
Iter: 473 loss: 1.23895074e-06
Iter: 474 loss: 1.23854647e-06
Iter: 475 loss: 1.23790699e-06
Iter: 476 loss: 1.23791028e-06
Iter: 477 loss: 1.23731627e-06
Iter: 478 loss: 1.23939117e-06
Iter: 479 loss: 1.23718746e-06
Iter: 480 loss: 1.2363987e-06
Iter: 481 loss: 1.23797554e-06
Iter: 482 loss: 1.23605332e-06
Iter: 483 loss: 1.23538939e-06
Iter: 484 loss: 1.2350522e-06
Iter: 485 loss: 1.23476684e-06
Iter: 486 loss: 1.23395444e-06
Iter: 487 loss: 1.24086637e-06
Iter: 488 loss: 1.23393033e-06
Iter: 489 loss: 1.23350412e-06
Iter: 490 loss: 1.23814516e-06
Iter: 491 loss: 1.23348968e-06
Iter: 492 loss: 1.23313271e-06
Iter: 493 loss: 1.23316966e-06
Iter: 494 loss: 1.23287407e-06
Iter: 495 loss: 1.23237248e-06
Iter: 496 loss: 1.23304051e-06
Iter: 497 loss: 1.23214636e-06
Iter: 498 loss: 1.23147993e-06
Iter: 499 loss: 1.23268069e-06
Iter: 500 loss: 1.23117979e-06
Iter: 501 loss: 1.23066911e-06
Iter: 502 loss: 1.23883365e-06
Iter: 503 loss: 1.23066582e-06
Iter: 504 loss: 1.23028235e-06
Iter: 505 loss: 1.22940696e-06
Iter: 506 loss: 1.23976588e-06
Iter: 507 loss: 1.22931806e-06
Iter: 508 loss: 1.22949416e-06
Iter: 509 loss: 1.22895347e-06
Iter: 510 loss: 1.22867255e-06
Iter: 511 loss: 1.22799224e-06
Iter: 512 loss: 1.23232007e-06
Iter: 513 loss: 1.22782899e-06
Iter: 514 loss: 1.22738254e-06
Iter: 515 loss: 1.22728704e-06
Iter: 516 loss: 1.22693177e-06
Iter: 517 loss: 1.22636993e-06
Iter: 518 loss: 1.22638164e-06
Iter: 519 loss: 1.22573647e-06
Iter: 520 loss: 1.22581082e-06
Iter: 521 loss: 1.22526876e-06
Iter: 522 loss: 1.22478968e-06
Iter: 523 loss: 1.22465906e-06
Iter: 524 loss: 1.22435972e-06
Iter: 525 loss: 1.22373513e-06
Iter: 526 loss: 1.22371659e-06
Iter: 527 loss: 1.22328925e-06
Iter: 528 loss: 1.22249389e-06
Iter: 529 loss: 1.24054441e-06
Iter: 530 loss: 1.2224948e-06
Iter: 531 loss: 1.22153972e-06
Iter: 532 loss: 1.23142411e-06
Iter: 533 loss: 1.2215346e-06
Iter: 534 loss: 1.22101756e-06
Iter: 535 loss: 1.22847666e-06
Iter: 536 loss: 1.22100982e-06
Iter: 537 loss: 1.22060828e-06
Iter: 538 loss: 1.22019617e-06
Iter: 539 loss: 1.22010601e-06
Iter: 540 loss: 1.21956771e-06
Iter: 541 loss: 1.2205503e-06
Iter: 542 loss: 1.21934886e-06
Iter: 543 loss: 1.21878725e-06
Iter: 544 loss: 1.22728648e-06
Iter: 545 loss: 1.21877827e-06
Iter: 546 loss: 1.21847211e-06
Iter: 547 loss: 1.21794289e-06
Iter: 548 loss: 1.21794687e-06
Iter: 549 loss: 1.21741641e-06
Iter: 550 loss: 1.22498284e-06
Iter: 551 loss: 1.21739731e-06
Iter: 552 loss: 1.21710639e-06
Iter: 553 loss: 1.21635571e-06
Iter: 554 loss: 1.22150834e-06
Iter: 555 loss: 1.21619678e-06
Iter: 556 loss: 1.2155399e-06
Iter: 557 loss: 1.2155424e-06
Iter: 558 loss: 1.21513528e-06
Iter: 559 loss: 1.21651021e-06
Iter: 560 loss: 1.21504445e-06
Iter: 561 loss: 1.21462324e-06
Iter: 562 loss: 1.21429048e-06
Iter: 563 loss: 1.21414769e-06
Iter: 564 loss: 1.21338007e-06
Iter: 565 loss: 1.21480161e-06
Iter: 566 loss: 1.21303731e-06
Iter: 567 loss: 1.21214748e-06
Iter: 568 loss: 1.21788867e-06
Iter: 569 loss: 1.21202891e-06
Iter: 570 loss: 1.21149242e-06
Iter: 571 loss: 1.21769176e-06
Iter: 572 loss: 1.21148105e-06
Iter: 573 loss: 1.21107212e-06
Iter: 574 loss: 1.21015296e-06
Iter: 575 loss: 1.22345273e-06
Iter: 576 loss: 1.21012852e-06
Iter: 577 loss: 1.20949358e-06
Iter: 578 loss: 1.21613618e-06
Iter: 579 loss: 1.20948039e-06
Iter: 580 loss: 1.20891161e-06
Iter: 581 loss: 1.21436653e-06
Iter: 582 loss: 1.20888967e-06
Iter: 583 loss: 1.20866389e-06
Iter: 584 loss: 1.20847051e-06
Iter: 585 loss: 1.20839377e-06
Iter: 586 loss: 1.20787024e-06
Iter: 587 loss: 1.20887535e-06
Iter: 588 loss: 1.20767163e-06
Iter: 589 loss: 1.20705954e-06
Iter: 590 loss: 1.20569189e-06
Iter: 591 loss: 1.2207372e-06
Iter: 592 loss: 1.20552727e-06
Iter: 593 loss: 1.20559969e-06
Iter: 594 loss: 1.20496463e-06
Iter: 595 loss: 1.20449647e-06
Iter: 596 loss: 1.20448203e-06
Iter: 597 loss: 1.20411801e-06
Iter: 598 loss: 1.20343907e-06
Iter: 599 loss: 1.20312211e-06
Iter: 600 loss: 1.20282652e-06
Iter: 601 loss: 1.20202037e-06
Iter: 602 loss: 1.20827508e-06
Iter: 603 loss: 1.20196728e-06
Iter: 604 loss: 1.20123082e-06
Iter: 605 loss: 1.20367008e-06
Iter: 606 loss: 1.20106642e-06
Iter: 607 loss: 1.20034224e-06
Iter: 608 loss: 1.2044394e-06
Iter: 609 loss: 1.20024788e-06
Iter: 610 loss: 1.19963124e-06
Iter: 611 loss: 1.19843855e-06
Iter: 612 loss: 1.22251117e-06
Iter: 613 loss: 1.19840934e-06
Iter: 614 loss: 1.19763195e-06
Iter: 615 loss: 1.20956884e-06
Iter: 616 loss: 1.19763195e-06
Iter: 617 loss: 1.19696608e-06
Iter: 618 loss: 1.20176821e-06
Iter: 619 loss: 1.19692913e-06
Iter: 620 loss: 1.19662786e-06
Iter: 621 loss: 1.19620722e-06
Iter: 622 loss: 1.19619494e-06
Iter: 623 loss: 1.19532069e-06
Iter: 624 loss: 1.1964712e-06
Iter: 625 loss: 1.19486401e-06
Iter: 626 loss: 1.19423e-06
Iter: 627 loss: 1.19336278e-06
Iter: 628 loss: 1.19331298e-06
Iter: 629 loss: 1.1928397e-06
Iter: 630 loss: 1.19271272e-06
Iter: 631 loss: 1.1921145e-06
Iter: 632 loss: 1.19159472e-06
Iter: 633 loss: 1.19142533e-06
Iter: 634 loss: 1.19069068e-06
Iter: 635 loss: 1.1907216e-06
Iter: 636 loss: 1.19014749e-06
Iter: 637 loss: 1.1896409e-06
Iter: 638 loss: 1.18957905e-06
Iter: 639 loss: 1.18916557e-06
Iter: 640 loss: 1.18949833e-06
Iter: 641 loss: 1.18890966e-06
Iter: 642 loss: 1.18819332e-06
Iter: 643 loss: 1.18887624e-06
Iter: 644 loss: 1.18783271e-06
Iter: 645 loss: 1.18716025e-06
Iter: 646 loss: 1.18696153e-06
Iter: 647 loss: 1.18655134e-06
Iter: 648 loss: 1.18648893e-06
Iter: 649 loss: 1.18624484e-06
Iter: 650 loss: 1.18591083e-06
Iter: 651 loss: 1.18512571e-06
Iter: 652 loss: 1.19704669e-06
Iter: 653 loss: 1.18512082e-06
Iter: 654 loss: 1.18460912e-06
Iter: 655 loss: 1.18459775e-06
Iter: 656 loss: 1.18413959e-06
Iter: 657 loss: 1.18361208e-06
Iter: 658 loss: 1.18350908e-06
Iter: 659 loss: 1.18296771e-06
Iter: 660 loss: 1.1828613e-06
Iter: 661 loss: 1.18250296e-06
Iter: 662 loss: 1.18206094e-06
Iter: 663 loss: 1.18196408e-06
Iter: 664 loss: 1.18158823e-06
Iter: 665 loss: 1.18086064e-06
Iter: 666 loss: 1.19402432e-06
Iter: 667 loss: 1.1808371e-06
Iter: 668 loss: 1.18035837e-06
Iter: 669 loss: 1.18163189e-06
Iter: 670 loss: 1.18017419e-06
Iter: 671 loss: 1.17964805e-06
Iter: 672 loss: 1.18324306e-06
Iter: 673 loss: 1.17957643e-06
Iter: 674 loss: 1.17917023e-06
Iter: 675 loss: 1.18086666e-06
Iter: 676 loss: 1.17905529e-06
Iter: 677 loss: 1.1787115e-06
Iter: 678 loss: 1.17871605e-06
Iter: 679 loss: 1.17841603e-06
Iter: 680 loss: 1.17806655e-06
Iter: 681 loss: 1.17895513e-06
Iter: 682 loss: 1.17796026e-06
Iter: 683 loss: 1.1774041e-06
Iter: 684 loss: 1.1792182e-06
Iter: 685 loss: 1.17726904e-06
Iter: 686 loss: 1.17695413e-06
Iter: 687 loss: 1.1768268e-06
Iter: 688 loss: 1.17665616e-06
Iter: 689 loss: 1.17630145e-06
Iter: 690 loss: 1.17629e-06
Iter: 691 loss: 1.17612149e-06
Iter: 692 loss: 1.17563343e-06
Iter: 693 loss: 1.17782929e-06
Iter: 694 loss: 1.17541697e-06
Iter: 695 loss: 1.17490481e-06
Iter: 696 loss: 1.17489969e-06
Iter: 697 loss: 1.17433342e-06
Iter: 698 loss: 1.17481409e-06
Iter: 699 loss: 1.17401419e-06
Iter: 700 loss: 1.17364266e-06
Iter: 701 loss: 1.17319e-06
Iter: 702 loss: 1.1731355e-06
Iter: 703 loss: 1.17276863e-06
Iter: 704 loss: 1.17273748e-06
Iter: 705 loss: 1.17233424e-06
Iter: 706 loss: 1.17241132e-06
Iter: 707 loss: 1.17204127e-06
Iter: 708 loss: 1.17154639e-06
Iter: 709 loss: 1.17527077e-06
Iter: 710 loss: 1.17148193e-06
Iter: 711 loss: 1.17107879e-06
Iter: 712 loss: 1.17089462e-06
Iter: 713 loss: 1.17069726e-06
Iter: 714 loss: 1.17047807e-06
Iter: 715 loss: 1.17042464e-06
Iter: 716 loss: 1.17013951e-06
Iter: 717 loss: 1.16937986e-06
Iter: 718 loss: 1.17548313e-06
Iter: 719 loss: 1.16923206e-06
Iter: 720 loss: 1.1691393e-06
Iter: 721 loss: 1.16895899e-06
Iter: 722 loss: 1.16873059e-06
Iter: 723 loss: 1.16861429e-06
Iter: 724 loss: 1.16850333e-06
Iter: 725 loss: 1.16814704e-06
Iter: 726 loss: 1.1678095e-06
Iter: 727 loss: 1.16774356e-06
Iter: 728 loss: 1.1674349e-06
Iter: 729 loss: 1.16733224e-06
Iter: 730 loss: 1.16709077e-06
Iter: 731 loss: 1.16677688e-06
Iter: 732 loss: 1.16677836e-06
Iter: 733 loss: 1.16634919e-06
Iter: 734 loss: 1.16570152e-06
Iter: 735 loss: 1.16566537e-06
Iter: 736 loss: 1.16552269e-06
Iter: 737 loss: 1.16525212e-06
Iter: 738 loss: 1.16504475e-06
Iter: 739 loss: 1.16497824e-06
Iter: 740 loss: 1.16485921e-06
Iter: 741 loss: 1.1644845e-06
Iter: 742 loss: 1.16397666e-06
Iter: 743 loss: 1.16396279e-06
Iter: 744 loss: 1.16339697e-06
Iter: 745 loss: 1.16508954e-06
Iter: 746 loss: 1.16325168e-06
Iter: 747 loss: 1.16279466e-06
Iter: 748 loss: 1.16279909e-06
Iter: 749 loss: 1.16257524e-06
Iter: 750 loss: 1.16203489e-06
Iter: 751 loss: 1.16552837e-06
Iter: 752 loss: 1.16189153e-06
Iter: 753 loss: 1.16127103e-06
Iter: 754 loss: 1.16731076e-06
Iter: 755 loss: 1.16125761e-06
Iter: 756 loss: 1.16052865e-06
Iter: 757 loss: 1.1617841e-06
Iter: 758 loss: 1.16018191e-06
Iter: 759 loss: 1.15983198e-06
Iter: 760 loss: 1.15971238e-06
Iter: 761 loss: 1.15950161e-06
Iter: 762 loss: 1.1590389e-06
Iter: 763 loss: 1.15904015e-06
Iter: 764 loss: 1.1587432e-06
Iter: 765 loss: 1.15809166e-06
Iter: 766 loss: 1.16955505e-06
Iter: 767 loss: 1.15806029e-06
Iter: 768 loss: 1.15774185e-06
Iter: 769 loss: 1.15772355e-06
Iter: 770 loss: 1.15734429e-06
Iter: 771 loss: 1.15702892e-06
Iter: 772 loss: 1.15688863e-06
Iter: 773 loss: 1.15637613e-06
Iter: 774 loss: 1.15929231e-06
Iter: 775 loss: 1.15629678e-06
Iter: 776 loss: 1.1556474e-06
Iter: 777 loss: 1.15493924e-06
Iter: 778 loss: 1.15484636e-06
Iter: 779 loss: 1.15455839e-06
Iter: 780 loss: 1.15452144e-06
Iter: 781 loss: 1.15418686e-06
Iter: 782 loss: 1.15368221e-06
Iter: 783 loss: 1.15369392e-06
Iter: 784 loss: 1.15318312e-06
Iter: 785 loss: 1.15455123e-06
Iter: 786 loss: 1.15301941e-06
Iter: 787 loss: 1.15261435e-06
Iter: 788 loss: 1.1579732e-06
Iter: 789 loss: 1.15261366e-06
Iter: 790 loss: 1.15233e-06
Iter: 791 loss: 1.15176033e-06
Iter: 792 loss: 1.15803164e-06
Iter: 793 loss: 1.15166142e-06
Iter: 794 loss: 1.15128671e-06
Iter: 795 loss: 1.15124749e-06
Iter: 796 loss: 1.15075318e-06
Iter: 797 loss: 1.15036232e-06
Iter: 798 loss: 1.15021271e-06
Iter: 799 loss: 1.14984095e-06
Iter: 800 loss: 1.15162857e-06
Iter: 801 loss: 1.14978968e-06
Iter: 802 loss: 1.14943487e-06
Iter: 803 loss: 1.15261048e-06
Iter: 804 loss: 1.14940008e-06
Iter: 805 loss: 1.14919123e-06
Iter: 806 loss: 1.14927752e-06
Iter: 807 loss: 1.14899581e-06
Iter: 808 loss: 1.14857812e-06
Iter: 809 loss: 1.14865691e-06
Iter: 810 loss: 1.14827321e-06
Iter: 811 loss: 1.14790441e-06
Iter: 812 loss: 1.14893032e-06
Iter: 813 loss: 1.14778902e-06
Iter: 814 loss: 1.14736713e-06
Iter: 815 loss: 1.15012722e-06
Iter: 816 loss: 1.14733e-06
Iter: 817 loss: 1.14706006e-06
Iter: 818 loss: 1.14656268e-06
Iter: 819 loss: 1.15687021e-06
Iter: 820 loss: 1.14656564e-06
Iter: 821 loss: 1.14630211e-06
Iter: 822 loss: 1.14623185e-06
Iter: 823 loss: 1.14605382e-06
Iter: 824 loss: 1.14565432e-06
Iter: 825 loss: 1.15386069e-06
Iter: 826 loss: 1.14564773e-06
Iter: 827 loss: 1.14521652e-06
Iter: 828 loss: 1.14498016e-06
Iter: 829 loss: 1.14480883e-06
Iter: 830 loss: 1.14457544e-06
Iter: 831 loss: 1.14441082e-06
Iter: 832 loss: 1.14409613e-06
Iter: 833 loss: 1.14337172e-06
Iter: 834 loss: 1.15247258e-06
Iter: 835 loss: 1.14332852e-06
Iter: 836 loss: 1.14320483e-06
Iter: 837 loss: 1.14305567e-06
Iter: 838 loss: 1.14285456e-06
Iter: 839 loss: 1.14230568e-06
Iter: 840 loss: 1.14924342e-06
Iter: 841 loss: 1.14230579e-06
Iter: 842 loss: 1.14189277e-06
Iter: 843 loss: 1.14840759e-06
Iter: 844 loss: 1.14188424e-06
Iter: 845 loss: 1.14147792e-06
Iter: 846 loss: 1.14174043e-06
Iter: 847 loss: 1.14118598e-06
Iter: 848 loss: 1.14084673e-06
Iter: 849 loss: 1.14299064e-06
Iter: 850 loss: 1.14078398e-06
Iter: 851 loss: 1.14034788e-06
Iter: 852 loss: 1.14076056e-06
Iter: 853 loss: 1.14006912e-06
Iter: 854 loss: 1.13973022e-06
Iter: 855 loss: 1.13965257e-06
Iter: 856 loss: 1.13944179e-06
Iter: 857 loss: 1.13918304e-06
Iter: 858 loss: 1.1391387e-06
Iter: 859 loss: 1.13891019e-06
Iter: 860 loss: 1.13832243e-06
Iter: 861 loss: 1.14481782e-06
Iter: 862 loss: 1.1382856e-06
Iter: 863 loss: 1.13769659e-06
Iter: 864 loss: 1.14461443e-06
Iter: 865 loss: 1.13767896e-06
Iter: 866 loss: 1.13703459e-06
Iter: 867 loss: 1.13658393e-06
Iter: 868 loss: 1.1363411e-06
Iter: 869 loss: 1.13571616e-06
Iter: 870 loss: 1.13721148e-06
Iter: 871 loss: 1.13549277e-06
Iter: 872 loss: 1.13525448e-06
Iter: 873 loss: 1.13520673e-06
Iter: 874 loss: 1.13494434e-06
Iter: 875 loss: 1.13443787e-06
Iter: 876 loss: 1.14189288e-06
Iter: 877 loss: 1.13439705e-06
Iter: 878 loss: 1.13386307e-06
Iter: 879 loss: 1.14178488e-06
Iter: 880 loss: 1.13388205e-06
Iter: 881 loss: 1.1335203e-06
Iter: 882 loss: 1.13330782e-06
Iter: 883 loss: 1.13314695e-06
Iter: 884 loss: 1.13280225e-06
Iter: 885 loss: 1.13280703e-06
Iter: 886 loss: 1.13257704e-06
Iter: 887 loss: 1.13200838e-06
Iter: 888 loss: 1.13873466e-06
Iter: 889 loss: 1.13196927e-06
Iter: 890 loss: 1.1317295e-06
Iter: 891 loss: 1.13162218e-06
Iter: 892 loss: 1.13132501e-06
Iter: 893 loss: 1.13160434e-06
Iter: 894 loss: 1.13115152e-06
Iter: 895 loss: 1.13090471e-06
Iter: 896 loss: 1.1303589e-06
Iter: 897 loss: 1.13661565e-06
Iter: 898 loss: 1.13028909e-06
Iter: 899 loss: 1.12964324e-06
Iter: 900 loss: 1.1393397e-06
Iter: 901 loss: 1.12963301e-06
Iter: 902 loss: 1.12931014e-06
Iter: 903 loss: 1.12929797e-06
Iter: 904 loss: 1.12902603e-06
Iter: 905 loss: 1.12822988e-06
Iter: 906 loss: 1.13140482e-06
Iter: 907 loss: 1.12790326e-06
Iter: 908 loss: 1.12791508e-06
Iter: 909 loss: 1.12762302e-06
Iter: 910 loss: 1.1273296e-06
Iter: 911 loss: 1.1273836e-06
Iter: 912 loss: 1.12711371e-06
Iter: 913 loss: 1.12667499e-06
Iter: 914 loss: 1.12773421e-06
Iter: 915 loss: 1.12654061e-06
Iter: 916 loss: 1.12626026e-06
Iter: 917 loss: 1.1257714e-06
Iter: 918 loss: 1.12577914e-06
Iter: 919 loss: 1.12509747e-06
Iter: 920 loss: 1.13092437e-06
Iter: 921 loss: 1.12506325e-06
Iter: 922 loss: 1.12462931e-06
Iter: 923 loss: 1.12397277e-06
Iter: 924 loss: 1.12394855e-06
Iter: 925 loss: 1.12340126e-06
Iter: 926 loss: 1.12688838e-06
Iter: 927 loss: 1.12330656e-06
Iter: 928 loss: 1.12294811e-06
Iter: 929 loss: 1.12293105e-06
Iter: 930 loss: 1.12275313e-06
Iter: 931 loss: 1.12219027e-06
Iter: 932 loss: 1.12369457e-06
Iter: 933 loss: 1.12189912e-06
Iter: 934 loss: 1.12111388e-06
Iter: 935 loss: 1.12630687e-06
Iter: 936 loss: 1.12104726e-06
Iter: 937 loss: 1.12050611e-06
Iter: 938 loss: 1.12050225e-06
Iter: 939 loss: 1.12023508e-06
Iter: 940 loss: 1.11963857e-06
Iter: 941 loss: 1.1281353e-06
Iter: 942 loss: 1.11962231e-06
Iter: 943 loss: 1.11909731e-06
Iter: 944 loss: 1.12226439e-06
Iter: 945 loss: 1.1190549e-06
Iter: 946 loss: 1.11858947e-06
Iter: 947 loss: 1.12432849e-06
Iter: 948 loss: 1.11858185e-06
Iter: 949 loss: 1.11833515e-06
Iter: 950 loss: 1.1180108e-06
Iter: 951 loss: 1.11798283e-06
Iter: 952 loss: 1.11733084e-06
Iter: 953 loss: 1.12065572e-06
Iter: 954 loss: 1.11723079e-06
Iter: 955 loss: 1.11689428e-06
Iter: 956 loss: 1.1171735e-06
Iter: 957 loss: 1.11670761e-06
Iter: 958 loss: 1.11627355e-06
Iter: 959 loss: 1.11734653e-06
Iter: 960 loss: 1.11613213e-06
Iter: 961 loss: 1.11583586e-06
Iter: 962 loss: 1.11714246e-06
Iter: 963 loss: 1.11578993e-06
Iter: 964 loss: 1.11543784e-06
Iter: 965 loss: 1.11605141e-06
Iter: 966 loss: 1.11527152e-06
Iter: 967 loss: 1.11499355e-06
Iter: 968 loss: 1.11443092e-06
Iter: 969 loss: 1.12467342e-06
Iter: 970 loss: 1.11442591e-06
Iter: 971 loss: 1.1141085e-06
Iter: 972 loss: 1.11408247e-06
Iter: 973 loss: 1.11371128e-06
Iter: 974 loss: 1.11494887e-06
Iter: 975 loss: 1.11362317e-06
Iter: 976 loss: 1.11333475e-06
Iter: 977 loss: 1.1127936e-06
Iter: 978 loss: 1.12277121e-06
Iter: 979 loss: 1.11279792e-06
Iter: 980 loss: 1.11257168e-06
Iter: 981 loss: 1.11250483e-06
Iter: 982 loss: 1.112164e-06
Iter: 983 loss: 1.11178895e-06
Iter: 984 loss: 1.11172699e-06
Iter: 985 loss: 1.11154225e-06
Iter: 986 loss: 1.11153474e-06
Iter: 987 loss: 1.11128884e-06
Iter: 988 loss: 1.11083102e-06
Iter: 989 loss: 1.11958434e-06
Iter: 990 loss: 1.11080635e-06
Iter: 991 loss: 1.11041857e-06
Iter: 992 loss: 1.11308839e-06
Iter: 993 loss: 1.11032728e-06
Iter: 994 loss: 1.11002555e-06
Iter: 995 loss: 1.11015356e-06
Iter: 996 loss: 1.10977362e-06
Iter: 997 loss: 1.10945098e-06
Iter: 998 loss: 1.11241206e-06
Iter: 999 loss: 1.10942153e-06
Iter: 1000 loss: 1.10906831e-06
Iter: 1001 loss: 1.10862834e-06
Iter: 1002 loss: 1.1085973e-06
Iter: 1003 loss: 1.10818928e-06
Iter: 1004 loss: 1.11056931e-06
Iter: 1005 loss: 1.10813687e-06
Iter: 1006 loss: 1.10777285e-06
Iter: 1007 loss: 1.10951908e-06
Iter: 1008 loss: 1.10770088e-06
Iter: 1009 loss: 1.10739825e-06
Iter: 1010 loss: 1.10698852e-06
Iter: 1011 loss: 1.10697385e-06
Iter: 1012 loss: 1.10652672e-06
Iter: 1013 loss: 1.10804729e-06
Iter: 1014 loss: 1.10640087e-06
Iter: 1015 loss: 1.10590759e-06
Iter: 1016 loss: 1.11159477e-06
Iter: 1017 loss: 1.10588371e-06
Iter: 1018 loss: 1.10559745e-06
Iter: 1019 loss: 1.10489145e-06
Iter: 1020 loss: 1.11408326e-06
Iter: 1021 loss: 1.10483074e-06
Iter: 1022 loss: 1.10444466e-06
Iter: 1023 loss: 1.10432404e-06
Iter: 1024 loss: 1.1041069e-06
Iter: 1025 loss: 1.10354222e-06
Iter: 1026 loss: 1.10695169e-06
Iter: 1027 loss: 1.10337805e-06
Iter: 1028 loss: 1.10326528e-06
Iter: 1029 loss: 1.10309554e-06
Iter: 1030 loss: 1.10285987e-06
Iter: 1031 loss: 1.10363203e-06
Iter: 1032 loss: 1.10277017e-06
Iter: 1033 loss: 1.10256383e-06
Iter: 1034 loss: 1.10272481e-06
Iter: 1035 loss: 1.10240353e-06
Iter: 1036 loss: 1.10213068e-06
Iter: 1037 loss: 1.10255382e-06
Iter: 1038 loss: 1.10199051e-06
Iter: 1039 loss: 1.10178587e-06
Iter: 1040 loss: 1.10177677e-06
Iter: 1041 loss: 1.10161443e-06
Iter: 1042 loss: 1.1012894e-06
Iter: 1043 loss: 1.10703604e-06
Iter: 1044 loss: 1.10128803e-06
Iter: 1045 loss: 1.1009713e-06
Iter: 1046 loss: 1.10334747e-06
Iter: 1047 loss: 1.10097301e-06
Iter: 1048 loss: 1.10080919e-06
Iter: 1049 loss: 1.10080009e-06
Iter: 1050 loss: 1.10068788e-06
Iter: 1051 loss: 1.10039809e-06
Iter: 1052 loss: 1.10374936e-06
Iter: 1053 loss: 1.10037627e-06
Iter: 1054 loss: 1.10037911e-06
Iter: 1055 loss: 1.10023961e-06
Iter: 1056 loss: 1.10016151e-06
Iter: 1057 loss: 1.09990128e-06
Iter: 1058 loss: 1.10061e-06
Iter: 1059 loss: 1.09978737e-06
Iter: 1060 loss: 1.09939037e-06
Iter: 1061 loss: 1.10128246e-06
Iter: 1062 loss: 1.09934228e-06
Iter: 1063 loss: 1.09901748e-06
Iter: 1064 loss: 1.1032721e-06
Iter: 1065 loss: 1.0990243e-06
Iter: 1066 loss: 1.09880034e-06
Iter: 1067 loss: 1.09883058e-06
Iter: 1068 loss: 1.09868483e-06
Iter: 1069 loss: 1.0983822e-06
Iter: 1070 loss: 1.09858615e-06
Iter: 1071 loss: 1.09817483e-06
Iter: 1072 loss: 1.09796724e-06
Iter: 1073 loss: 1.09795951e-06
Iter: 1074 loss: 1.09771622e-06
Iter: 1075 loss: 1.09718371e-06
Iter: 1076 loss: 1.10300277e-06
Iter: 1077 loss: 1.09713437e-06
Iter: 1078 loss: 1.09663665e-06
Iter: 1079 loss: 1.09819018e-06
Iter: 1080 loss: 1.09649091e-06
Iter: 1081 loss: 1.09643224e-06
Iter: 1082 loss: 1.09627297e-06
Iter: 1083 loss: 1.09605685e-06
Iter: 1084 loss: 1.09566497e-06
Iter: 1085 loss: 1.10165797e-06
Iter: 1086 loss: 1.09566315e-06
Iter: 1087 loss: 1.09543112e-06
Iter: 1088 loss: 1.0954243e-06
Iter: 1089 loss: 1.09517987e-06
Iter: 1090 loss: 1.09488121e-06
Iter: 1091 loss: 1.09485666e-06
Iter: 1092 loss: 1.09451662e-06
Iter: 1093 loss: 1.0942872e-06
Iter: 1094 loss: 1.09415464e-06
Iter: 1095 loss: 1.09396467e-06
Iter: 1096 loss: 1.09388179e-06
Iter: 1097 loss: 1.0937091e-06
Iter: 1098 loss: 1.09359735e-06
Iter: 1099 loss: 1.09353e-06
Iter: 1100 loss: 1.0932506e-06
Iter: 1101 loss: 1.0943877e-06
Iter: 1102 loss: 1.0932165e-06
Iter: 1103 loss: 1.09303028e-06
Iter: 1104 loss: 1.09328175e-06
Iter: 1105 loss: 1.09294012e-06
Iter: 1106 loss: 1.09270741e-06
Iter: 1107 loss: 1.09431994e-06
Iter: 1108 loss: 1.09271275e-06
Iter: 1109 loss: 1.09256803e-06
Iter: 1110 loss: 1.0922098e-06
Iter: 1111 loss: 1.0948105e-06
Iter: 1112 loss: 1.09212976e-06
Iter: 1113 loss: 1.0915719e-06
Iter: 1114 loss: 1.09290568e-06
Iter: 1115 loss: 1.09134839e-06
Iter: 1116 loss: 1.0915212e-06
Iter: 1117 loss: 1.09115058e-06
Iter: 1118 loss: 1.09096948e-06
Iter: 1119 loss: 1.09071823e-06
Iter: 1120 loss: 1.09071254e-06
Iter: 1121 loss: 1.09062671e-06
Iter: 1122 loss: 1.09059692e-06
Iter: 1123 loss: 1.09050825e-06
Iter: 1124 loss: 1.09032817e-06
Iter: 1125 loss: 1.09367522e-06
Iter: 1126 loss: 1.09031396e-06
Iter: 1127 loss: 1.09012922e-06
Iter: 1128 loss: 1.09024768e-06
Iter: 1129 loss: 1.08998745e-06
Iter: 1130 loss: 1.0898558e-06
Iter: 1131 loss: 1.08984705e-06
Iter: 1132 loss: 1.08976508e-06
Iter: 1133 loss: 1.0895842e-06
Iter: 1134 loss: 1.09225289e-06
Iter: 1135 loss: 1.08956851e-06
Iter: 1136 loss: 1.08927406e-06
Iter: 1137 loss: 1.09020687e-06
Iter: 1138 loss: 1.08917823e-06
Iter: 1139 loss: 1.0890119e-06
Iter: 1140 loss: 1.08900622e-06
Iter: 1141 loss: 1.08888753e-06
Iter: 1142 loss: 1.08866925e-06
Iter: 1143 loss: 1.09348571e-06
Iter: 1144 loss: 1.08867448e-06
Iter: 1145 loss: 1.08840698e-06
Iter: 1146 loss: 1.08846564e-06
Iter: 1147 loss: 1.08823588e-06
Iter: 1148 loss: 1.0880392e-06
Iter: 1149 loss: 1.09104417e-06
Iter: 1150 loss: 1.08804363e-06
Iter: 1151 loss: 1.08784707e-06
Iter: 1152 loss: 1.08871075e-06
Iter: 1153 loss: 1.08781e-06
Iter: 1154 loss: 1.08768836e-06
Iter: 1155 loss: 1.08783433e-06
Iter: 1156 loss: 1.0876322e-06
Iter: 1157 loss: 1.08744825e-06
Iter: 1158 loss: 1.08765119e-06
Iter: 1159 loss: 1.08735753e-06
Iter: 1160 loss: 1.08722054e-06
Iter: 1161 loss: 1.08695599e-06
Iter: 1162 loss: 1.08692893e-06
Iter: 1163 loss: 1.08678967e-06
Iter: 1164 loss: 1.08676932e-06
Iter: 1165 loss: 1.08658776e-06
Iter: 1166 loss: 1.08648965e-06
Iter: 1167 loss: 1.08640222e-06
Iter: 1168 loss: 1.08616769e-06
Iter: 1169 loss: 1.08695417e-06
Iter: 1170 loss: 1.08614017e-06
Iter: 1171 loss: 1.08593099e-06
Iter: 1172 loss: 1.08726647e-06
Iter: 1173 loss: 1.08591757e-06
Iter: 1174 loss: 1.08576944e-06
Iter: 1175 loss: 1.08614745e-06
Iter: 1176 loss: 1.08570703e-06
Iter: 1177 loss: 1.08556992e-06
Iter: 1178 loss: 1.08523636e-06
Iter: 1179 loss: 1.08861843e-06
Iter: 1180 loss: 1.08521749e-06
Iter: 1181 loss: 1.08485085e-06
Iter: 1182 loss: 1.08676988e-06
Iter: 1183 loss: 1.0847989e-06
Iter: 1184 loss: 1.08470647e-06
Iter: 1185 loss: 1.08459687e-06
Iter: 1186 loss: 1.08447875e-06
Iter: 1187 loss: 1.08420977e-06
Iter: 1188 loss: 1.08933409e-06
Iter: 1189 loss: 1.08421409e-06
Iter: 1190 loss: 1.08396341e-06
Iter: 1191 loss: 1.08792415e-06
Iter: 1192 loss: 1.08395534e-06
Iter: 1193 loss: 1.08379845e-06
Iter: 1194 loss: 1.08343727e-06
Iter: 1195 loss: 1.08855e-06
Iter: 1196 loss: 1.08343556e-06
Iter: 1197 loss: 1.0830945e-06
Iter: 1198 loss: 1.08405595e-06
Iter: 1199 loss: 1.08297809e-06
Iter: 1200 loss: 1.08264317e-06
Iter: 1201 loss: 1.08799873e-06
Iter: 1202 loss: 1.08265147e-06
Iter: 1203 loss: 1.08247798e-06
Iter: 1204 loss: 1.08216784e-06
Iter: 1205 loss: 1.08216864e-06
Iter: 1206 loss: 1.08182621e-06
Iter: 1207 loss: 1.08630513e-06
Iter: 1208 loss: 1.08182167e-06
Iter: 1209 loss: 1.08163908e-06
Iter: 1210 loss: 1.08309291e-06
Iter: 1211 loss: 1.08161692e-06
Iter: 1212 loss: 1.08146855e-06
Iter: 1213 loss: 1.0811973e-06
Iter: 1214 loss: 1.08616871e-06
Iter: 1215 loss: 1.08117126e-06
Iter: 1216 loss: 1.0808069e-06
Iter: 1217 loss: 1.08086351e-06
Iter: 1218 loss: 1.08052257e-06
Iter: 1219 loss: 1.08040103e-06
Iter: 1220 loss: 1.08031486e-06
Iter: 1221 loss: 1.08007043e-06
Iter: 1222 loss: 1.07975859e-06
Iter: 1223 loss: 1.07974097e-06
Iter: 1224 loss: 1.07951632e-06
Iter: 1225 loss: 1.07951587e-06
Iter: 1226 loss: 1.07931896e-06
Iter: 1227 loss: 1.0789945e-06
Iter: 1228 loss: 1.07898745e-06
Iter: 1229 loss: 1.07868414e-06
Iter: 1230 loss: 1.07865299e-06
Iter: 1231 loss: 1.07843448e-06
Iter: 1232 loss: 1.07824826e-06
Iter: 1233 loss: 1.07823621e-06
Iter: 1234 loss: 1.07797405e-06
Iter: 1235 loss: 1.07747474e-06
Iter: 1236 loss: 1.08861718e-06
Iter: 1237 loss: 1.07748292e-06
Iter: 1238 loss: 1.07707422e-06
Iter: 1239 loss: 1.08061158e-06
Iter: 1240 loss: 1.07706137e-06
Iter: 1241 loss: 1.07670371e-06
Iter: 1242 loss: 1.07836297e-06
Iter: 1243 loss: 1.07665562e-06
Iter: 1244 loss: 1.07633832e-06
Iter: 1245 loss: 1.0767501e-06
Iter: 1246 loss: 1.07619496e-06
Iter: 1247 loss: 1.07588608e-06
Iter: 1248 loss: 1.07558992e-06
Iter: 1249 loss: 1.07552319e-06
Iter: 1250 loss: 1.07515496e-06
Iter: 1251 loss: 1.07591245e-06
Iter: 1252 loss: 1.07498272e-06
Iter: 1253 loss: 1.07491826e-06
Iter: 1254 loss: 1.07480219e-06
Iter: 1255 loss: 1.07458357e-06
Iter: 1256 loss: 1.07418907e-06
Iter: 1257 loss: 1.08084282e-06
Iter: 1258 loss: 1.07416849e-06
Iter: 1259 loss: 1.07393407e-06
Iter: 1260 loss: 1.07390474e-06
Iter: 1261 loss: 1.07370329e-06
Iter: 1262 loss: 1.07327992e-06
Iter: 1263 loss: 1.07836968e-06
Iter: 1264 loss: 1.07324854e-06
Iter: 1265 loss: 1.07287622e-06
Iter: 1266 loss: 1.07373364e-06
Iter: 1267 loss: 1.07275559e-06
Iter: 1268 loss: 1.07260644e-06
Iter: 1269 loss: 1.07254709e-06
Iter: 1270 loss: 1.07240544e-06
Iter: 1271 loss: 1.07196774e-06
Iter: 1272 loss: 1.07469509e-06
Iter: 1273 loss: 1.07183735e-06
Iter: 1274 loss: 1.07139795e-06
Iter: 1275 loss: 1.07571861e-06
Iter: 1276 loss: 1.07137794e-06
Iter: 1277 loss: 1.07089772e-06
Iter: 1278 loss: 1.07264384e-06
Iter: 1279 loss: 1.07074516e-06
Iter: 1280 loss: 1.07044843e-06
Iter: 1281 loss: 1.07143183e-06
Iter: 1282 loss: 1.07037022e-06
Iter: 1283 loss: 1.0701367e-06
Iter: 1284 loss: 1.0696e-06
Iter: 1285 loss: 1.07832489e-06
Iter: 1286 loss: 1.06959294e-06
Iter: 1287 loss: 1.06897642e-06
Iter: 1288 loss: 1.07154824e-06
Iter: 1289 loss: 1.06884977e-06
Iter: 1290 loss: 1.06861376e-06
Iter: 1291 loss: 1.06861967e-06
Iter: 1292 loss: 1.06830032e-06
Iter: 1293 loss: 1.0681083e-06
Iter: 1294 loss: 1.06797813e-06
Iter: 1295 loss: 1.06770767e-06
Iter: 1296 loss: 1.06981543e-06
Iter: 1297 loss: 1.06769858e-06
Iter: 1298 loss: 1.06738378e-06
Iter: 1299 loss: 1.06689129e-06
Iter: 1300 loss: 1.06689333e-06
Iter: 1301 loss: 1.066408e-06
Iter: 1302 loss: 1.06669563e-06
Iter: 1303 loss: 1.06608536e-06
Iter: 1304 loss: 1.0659254e-06
Iter: 1305 loss: 1.06579682e-06
Iter: 1306 loss: 1.06552943e-06
Iter: 1307 loss: 1.06495622e-06
Iter: 1308 loss: 1.07094684e-06
Iter: 1309 loss: 1.06489244e-06
Iter: 1310 loss: 1.06442621e-06
Iter: 1311 loss: 1.06411642e-06
Iter: 1312 loss: 1.06393281e-06
Iter: 1313 loss: 1.06394907e-06
Iter: 1314 loss: 1.06357402e-06
Iter: 1315 loss: 1.0633089e-06
Iter: 1316 loss: 1.0628994e-06
Iter: 1317 loss: 1.06291236e-06
Iter: 1318 loss: 1.06234802e-06
Iter: 1319 loss: 1.06332254e-06
Iter: 1320 loss: 1.06212542e-06
Iter: 1321 loss: 1.06160201e-06
Iter: 1322 loss: 1.06222114e-06
Iter: 1323 loss: 1.0613104e-06
Iter: 1324 loss: 1.06079324e-06
Iter: 1325 loss: 1.06119148e-06
Iter: 1326 loss: 1.06045354e-06
Iter: 1327 loss: 1.06024754e-06
Iter: 1328 loss: 1.06005098e-06
Iter: 1329 loss: 1.05986192e-06
Iter: 1330 loss: 1.05931565e-06
Iter: 1331 loss: 1.06368111e-06
Iter: 1332 loss: 1.05921845e-06
Iter: 1333 loss: 1.05877211e-06
Iter: 1334 loss: 1.0587537e-06
Iter: 1335 loss: 1.05840309e-06
Iter: 1336 loss: 1.05781965e-06
Iter: 1337 loss: 1.05781464e-06
Iter: 1338 loss: 1.05742879e-06
Iter: 1339 loss: 1.05742913e-06
Iter: 1340 loss: 1.05717402e-06
Iter: 1341 loss: 1.05659217e-06
Iter: 1342 loss: 1.06102323e-06
Iter: 1343 loss: 1.0564861e-06
Iter: 1344 loss: 1.05600293e-06
Iter: 1345 loss: 1.05701452e-06
Iter: 1346 loss: 1.05582626e-06
Iter: 1347 loss: 1.05559752e-06
Iter: 1348 loss: 1.0580145e-06
Iter: 1349 loss: 1.05558195e-06
Iter: 1350 loss: 1.05533e-06
Iter: 1351 loss: 1.05495974e-06
Iter: 1352 loss: 1.05494428e-06
Iter: 1353 loss: 1.05467871e-06
Iter: 1354 loss: 1.05475158e-06
Iter: 1355 loss: 1.05447521e-06
Iter: 1356 loss: 1.05422498e-06
Iter: 1357 loss: 1.05395725e-06
Iter: 1358 loss: 1.05393417e-06
Iter: 1359 loss: 1.05356321e-06
Iter: 1360 loss: 1.05434958e-06
Iter: 1361 loss: 1.0534045e-06
Iter: 1362 loss: 1.05297431e-06
Iter: 1363 loss: 1.05231197e-06
Iter: 1364 loss: 1.05229742e-06
Iter: 1365 loss: 1.05155164e-06
Iter: 1366 loss: 1.05518916e-06
Iter: 1367 loss: 1.05142749e-06
Iter: 1368 loss: 1.05091829e-06
Iter: 1369 loss: 1.050935e-06
Iter: 1370 loss: 1.05054573e-06
Iter: 1371 loss: 1.05306958e-06
Iter: 1372 loss: 1.05049389e-06
Iter: 1373 loss: 1.05024492e-06
Iter: 1374 loss: 1.0503436e-06
Iter: 1375 loss: 1.05005802e-06
Iter: 1376 loss: 1.04984326e-06
Iter: 1377 loss: 1.05073082e-06
Iter: 1378 loss: 1.04978244e-06
Iter: 1379 loss: 1.04955427e-06
Iter: 1380 loss: 1.05171227e-06
Iter: 1381 loss: 1.04955029e-06
Iter: 1382 loss: 1.04940318e-06
Iter: 1383 loss: 1.04926414e-06
Iter: 1384 loss: 1.04922651e-06
Iter: 1385 loss: 1.04893229e-06
Iter: 1386 loss: 1.05041477e-06
Iter: 1387 loss: 1.0489191e-06
Iter: 1388 loss: 1.0486807e-06
Iter: 1389 loss: 1.04921151e-06
Iter: 1390 loss: 1.04859669e-06
Iter: 1391 loss: 1.04841547e-06
Iter: 1392 loss: 1.04862318e-06
Iter: 1393 loss: 1.04831156e-06
Iter: 1394 loss: 1.04812557e-06
Iter: 1395 loss: 1.0502356e-06
Iter: 1396 loss: 1.04812875e-06
Iter: 1397 loss: 1.04795777e-06
Iter: 1398 loss: 1.04786477e-06
Iter: 1399 loss: 1.04777564e-06
Iter: 1400 loss: 1.04758419e-06
Iter: 1401 loss: 1.04727781e-06
Iter: 1402 loss: 1.04725143e-06
Iter: 1403 loss: 1.04696016e-06
Iter: 1404 loss: 1.05015556e-06
Iter: 1405 loss: 1.04695187e-06
Iter: 1406 loss: 1.04670903e-06
Iter: 1407 loss: 1.0493776e-06
Iter: 1408 loss: 1.04668993e-06
Iter: 1409 loss: 1.04655408e-06
Iter: 1410 loss: 1.04623848e-06
Iter: 1411 loss: 1.05098536e-06
Iter: 1412 loss: 1.04624792e-06
Iter: 1413 loss: 1.04599246e-06
Iter: 1414 loss: 1.04848e-06
Iter: 1415 loss: 1.04596029e-06
Iter: 1416 loss: 1.04570927e-06
Iter: 1417 loss: 1.04703781e-06
Iter: 1418 loss: 1.04566959e-06
Iter: 1419 loss: 1.04544301e-06
Iter: 1420 loss: 1.04596495e-06
Iter: 1421 loss: 1.04537844e-06
Iter: 1422 loss: 1.0451995e-06
Iter: 1423 loss: 1.04568664e-06
Iter: 1424 loss: 1.04511503e-06
Iter: 1425 loss: 1.04491403e-06
Iter: 1426 loss: 1.0455783e-06
Iter: 1427 loss: 1.0448623e-06
Iter: 1428 loss: 1.04462038e-06
Iter: 1429 loss: 1.04517812e-06
Iter: 1430 loss: 1.04448372e-06
Iter: 1431 loss: 1.04426533e-06
Iter: 1432 loss: 1.04411856e-06
Iter: 1433 loss: 1.04402989e-06
Iter: 1434 loss: 1.04377807e-06
Iter: 1435 loss: 1.04691424e-06
Iter: 1436 loss: 1.04377546e-06
Iter: 1437 loss: 1.04352819e-06
Iter: 1438 loss: 1.04375272e-06
Iter: 1439 loss: 1.04337096e-06
Iter: 1440 loss: 1.04319781e-06
Iter: 1441 loss: 1.0428962e-06
Iter: 1442 loss: 1.05043875e-06
Iter: 1443 loss: 1.04289825e-06
Iter: 1444 loss: 1.04254525e-06
Iter: 1445 loss: 1.0433738e-06
Iter: 1446 loss: 1.04241144e-06
Iter: 1447 loss: 1.04223045e-06
Iter: 1448 loss: 1.04220089e-06
Iter: 1449 loss: 1.04197466e-06
Iter: 1450 loss: 1.04178196e-06
Iter: 1451 loss: 1.04169544e-06
Iter: 1452 loss: 1.04147944e-06
Iter: 1453 loss: 1.04282924e-06
Iter: 1454 loss: 1.04142703e-06
Iter: 1455 loss: 1.04120841e-06
Iter: 1456 loss: 1.04232606e-06
Iter: 1457 loss: 1.04116066e-06
Iter: 1458 loss: 1.04098956e-06
Iter: 1459 loss: 1.04119681e-06
Iter: 1460 loss: 1.04089077e-06
Iter: 1461 loss: 1.04069898e-06
Iter: 1462 loss: 1.04141077e-06
Iter: 1463 loss: 1.04064077e-06
Iter: 1464 loss: 1.04041919e-06
Iter: 1465 loss: 1.04071773e-06
Iter: 1466 loss: 1.04030767e-06
Iter: 1467 loss: 1.04008689e-06
Iter: 1468 loss: 1.03995399e-06
Iter: 1469 loss: 1.03985349e-06
Iter: 1470 loss: 1.039636e-06
Iter: 1471 loss: 1.03964419e-06
Iter: 1472 loss: 1.03940886e-06
Iter: 1473 loss: 1.03904131e-06
Iter: 1474 loss: 1.03904131e-06
Iter: 1475 loss: 1.03877596e-06
Iter: 1476 loss: 1.03912498e-06
Iter: 1477 loss: 1.03861873e-06
Iter: 1478 loss: 1.03833963e-06
Iter: 1479 loss: 1.03855746e-06
Iter: 1480 loss: 1.0381641e-06
Iter: 1481 loss: 1.03816615e-06
Iter: 1482 loss: 1.03800357e-06
Iter: 1483 loss: 1.03786419e-06
Iter: 1484 loss: 1.03753121e-06
Iter: 1485 loss: 1.04063304e-06
Iter: 1486 loss: 1.03749358e-06
Iter: 1487 loss: 1.03728757e-06
Iter: 1488 loss: 1.03725574e-06
Iter: 1489 loss: 1.03708737e-06
Iter: 1490 loss: 1.03699426e-06
Iter: 1491 loss: 1.03692446e-06
Iter: 1492 loss: 1.03672915e-06
Iter: 1493 loss: 1.0388228e-06
Iter: 1494 loss: 1.03672335e-06
Iter: 1495 loss: 1.03658738e-06
Iter: 1496 loss: 1.03652064e-06
Iter: 1497 loss: 1.03644606e-06
Iter: 1498 loss: 1.03618254e-06
Iter: 1499 loss: 1.03664968e-06
Iter: 1500 loss: 1.03607431e-06
Iter: 1501 loss: 1.03585944e-06
Iter: 1502 loss: 1.03621619e-06
Iter: 1503 loss: 1.03578441e-06
Iter: 1504 loss: 1.03548041e-06
Iter: 1505 loss: 1.03754e-06
Iter: 1506 loss: 1.03543869e-06
Iter: 1507 loss: 1.03527441e-06
Iter: 1508 loss: 1.03501031e-06
Iter: 1509 loss: 1.03498576e-06
Iter: 1510 loss: 1.03475236e-06
Iter: 1511 loss: 1.03494563e-06
Iter: 1512 loss: 1.03459286e-06
Iter: 1513 loss: 1.03441175e-06
Iter: 1514 loss: 1.03442517e-06
Iter: 1515 loss: 1.03423145e-06
Iter: 1516 loss: 1.03446951e-06
Iter: 1517 loss: 1.03411799e-06
Iter: 1518 loss: 1.03400521e-06
Iter: 1519 loss: 1.03420837e-06
Iter: 1520 loss: 1.03391608e-06
Iter: 1521 loss: 1.03369041e-06
Iter: 1522 loss: 1.03403727e-06
Iter: 1523 loss: 1.03355785e-06
Iter: 1524 loss: 1.03337595e-06
Iter: 1525 loss: 1.03437822e-06
Iter: 1526 loss: 1.03334435e-06
Iter: 1527 loss: 1.03315324e-06
Iter: 1528 loss: 1.03343302e-06
Iter: 1529 loss: 1.03307934e-06
Iter: 1530 loss: 1.03289972e-06
Iter: 1531 loss: 1.03341563e-06
Iter: 1532 loss: 1.03284924e-06
Iter: 1533 loss: 1.03267462e-06
Iter: 1534 loss: 1.03285606e-06
Iter: 1535 loss: 1.03257526e-06
Iter: 1536 loss: 1.03248522e-06
Iter: 1537 loss: 1.03247385e-06
Iter: 1538 loss: 1.03238506e-06
Iter: 1539 loss: 1.03209982e-06
Iter: 1540 loss: 1.0348997e-06
Iter: 1541 loss: 1.03208504e-06
Iter: 1542 loss: 1.03172806e-06
Iter: 1543 loss: 1.03232105e-06
Iter: 1544 loss: 1.03156856e-06
Iter: 1545 loss: 1.03133902e-06
Iter: 1546 loss: 1.03448565e-06
Iter: 1547 loss: 1.03132652e-06
Iter: 1548 loss: 1.03111961e-06
Iter: 1549 loss: 1.03209732e-06
Iter: 1550 loss: 1.03108312e-06
Iter: 1551 loss: 1.03094123e-06
Iter: 1552 loss: 1.03088769e-06
Iter: 1553 loss: 1.03081095e-06
Iter: 1554 loss: 1.0307225e-06
Iter: 1555 loss: 1.03070965e-06
Iter: 1556 loss: 1.03065133e-06
Iter: 1557 loss: 1.0305157e-06
Iter: 1558 loss: 1.03299897e-06
Iter: 1559 loss: 1.03050513e-06
Iter: 1560 loss: 1.03027446e-06
Iter: 1561 loss: 1.03160596e-06
Iter: 1562 loss: 1.03024286e-06
Iter: 1563 loss: 1.03007835e-06
Iter: 1564 loss: 1.02999024e-06
Iter: 1565 loss: 1.02991544e-06
Iter: 1566 loss: 1.02962565e-06
Iter: 1567 loss: 1.03019545e-06
Iter: 1568 loss: 1.02953186e-06
Iter: 1569 loss: 1.02934064e-06
Iter: 1570 loss: 1.03125399e-06
Iter: 1571 loss: 1.0293204e-06
Iter: 1572 loss: 1.02916067e-06
Iter: 1573 loss: 1.02953618e-06
Iter: 1574 loss: 1.02909689e-06
Iter: 1575 loss: 1.02899014e-06
Iter: 1576 loss: 1.02881677e-06
Iter: 1577 loss: 1.02882132e-06
Iter: 1578 loss: 1.02862657e-06
Iter: 1579 loss: 1.03032505e-06
Iter: 1580 loss: 1.02860645e-06
Iter: 1581 loss: 1.02847241e-06
Iter: 1582 loss: 1.03043533e-06
Iter: 1583 loss: 1.02846093e-06
Iter: 1584 loss: 1.02837521e-06
Iter: 1585 loss: 1.0281359e-06
Iter: 1586 loss: 1.03091725e-06
Iter: 1587 loss: 1.02808758e-06
Iter: 1588 loss: 1.02795616e-06
Iter: 1589 loss: 1.0279291e-06
Iter: 1590 loss: 1.02778677e-06
Iter: 1591 loss: 1.02761612e-06
Iter: 1592 loss: 1.02760771e-06
Iter: 1593 loss: 1.02750232e-06
Iter: 1594 loss: 1.0274772e-06
Iter: 1595 loss: 1.02739318e-06
Iter: 1596 loss: 1.02723152e-06
Iter: 1597 loss: 1.03069431e-06
Iter: 1598 loss: 1.02722504e-06
Iter: 1599 loss: 1.02701699e-06
Iter: 1600 loss: 1.02780905e-06
Iter: 1601 loss: 1.02696765e-06
Iter: 1602 loss: 1.0267886e-06
Iter: 1603 loss: 1.02713284e-06
Iter: 1604 loss: 1.02674539e-06
Iter: 1605 loss: 1.02650517e-06
Iter: 1606 loss: 1.02761885e-06
Iter: 1607 loss: 1.02647402e-06
Iter: 1608 loss: 1.02632782e-06
Iter: 1609 loss: 1.02611409e-06
Iter: 1610 loss: 1.02609488e-06
Iter: 1611 loss: 1.02588012e-06
Iter: 1612 loss: 1.02649983e-06
Iter: 1613 loss: 1.02581271e-06
Iter: 1614 loss: 1.02566628e-06
Iter: 1615 loss: 1.02566787e-06
Iter: 1616 loss: 1.02555e-06
Iter: 1617 loss: 1.02552099e-06
Iter: 1618 loss: 1.02544277e-06
Iter: 1619 loss: 1.02533613e-06
Iter: 1620 loss: 1.02579588e-06
Iter: 1621 loss: 1.02531294e-06
Iter: 1622 loss: 1.02511717e-06
Iter: 1623 loss: 1.02492356e-06
Iter: 1624 loss: 1.02490742e-06
Iter: 1625 loss: 1.02467504e-06
Iter: 1626 loss: 1.02741626e-06
Iter: 1627 loss: 1.02466061e-06
Iter: 1628 loss: 1.02443107e-06
Iter: 1629 loss: 1.02463378e-06
Iter: 1630 loss: 1.02431875e-06
Iter: 1631 loss: 1.02413935e-06
Iter: 1632 loss: 1.02468027e-06
Iter: 1633 loss: 1.02408512e-06
Iter: 1634 loss: 1.0239371e-06
Iter: 1635 loss: 1.02400531e-06
Iter: 1636 loss: 1.02382273e-06
Iter: 1637 loss: 1.02365607e-06
Iter: 1638 loss: 1.02366494e-06
Iter: 1639 loss: 1.02356489e-06
Iter: 1640 loss: 1.02333252e-06
Iter: 1641 loss: 1.02648096e-06
Iter: 1642 loss: 1.02332297e-06
Iter: 1643 loss: 1.02307024e-06
Iter: 1644 loss: 1.02385184e-06
Iter: 1645 loss: 1.02299521e-06
Iter: 1646 loss: 1.02283559e-06
Iter: 1647 loss: 1.02282468e-06
Iter: 1648 loss: 1.0226853e-06
Iter: 1649 loss: 1.02273782e-06
Iter: 1650 loss: 1.02258161e-06
Iter: 1651 loss: 1.02241688e-06
Iter: 1652 loss: 1.02289039e-06
Iter: 1653 loss: 1.02237027e-06
Iter: 1654 loss: 1.0221986e-06
Iter: 1655 loss: 1.02296383e-06
Iter: 1656 loss: 1.02215904e-06
Iter: 1657 loss: 1.02205854e-06
Iter: 1658 loss: 1.02218632e-06
Iter: 1659 loss: 1.02197123e-06
Iter: 1660 loss: 1.02178797e-06
Iter: 1661 loss: 1.02228546e-06
Iter: 1662 loss: 1.02174567e-06
Iter: 1663 loss: 1.02158742e-06
Iter: 1664 loss: 1.02165018e-06
Iter: 1665 loss: 1.0215166e-06
Iter: 1666 loss: 1.02130616e-06
Iter: 1667 loss: 1.02156707e-06
Iter: 1668 loss: 1.02121817e-06
Iter: 1669 loss: 1.02108697e-06
Iter: 1670 loss: 1.02109288e-06
Iter: 1671 loss: 1.0209767e-06
Iter: 1672 loss: 1.02081913e-06
Iter: 1673 loss: 1.02510273e-06
Iter: 1674 loss: 1.02082413e-06
Iter: 1675 loss: 1.02064132e-06
Iter: 1676 loss: 1.02068009e-06
Iter: 1677 loss: 1.02050217e-06
Iter: 1678 loss: 1.0203745e-06
Iter: 1679 loss: 1.0203687e-06
Iter: 1680 loss: 1.02022295e-06
Iter: 1681 loss: 1.02029185e-06
Iter: 1682 loss: 1.02014883e-06
Iter: 1683 loss: 1.01999171e-06
Iter: 1684 loss: 1.02021102e-06
Iter: 1685 loss: 1.01991702e-06
Iter: 1686 loss: 1.01974229e-06
Iter: 1687 loss: 1.0208289e-06
Iter: 1688 loss: 1.01972e-06
Iter: 1689 loss: 1.01959927e-06
Iter: 1690 loss: 1.01958744e-06
Iter: 1691 loss: 1.01948774e-06
Iter: 1692 loss: 1.01934927e-06
Iter: 1693 loss: 1.02173044e-06
Iter: 1694 loss: 1.01933824e-06
Iter: 1695 loss: 1.01927481e-06
Iter: 1696 loss: 1.0191427e-06
Iter: 1697 loss: 1.01914452e-06
Iter: 1698 loss: 1.01895591e-06
Iter: 1699 loss: 1.0193512e-06
Iter: 1700 loss: 1.01886303e-06
Iter: 1701 loss: 1.01874593e-06
Iter: 1702 loss: 1.02033414e-06
Iter: 1703 loss: 1.01875014e-06
Iter: 1704 loss: 1.01861929e-06
Iter: 1705 loss: 1.01854812e-06
Iter: 1706 loss: 1.01849662e-06
Iter: 1707 loss: 1.01833939e-06
Iter: 1708 loss: 1.01832234e-06
Iter: 1709 loss: 1.01820956e-06
Iter: 1710 loss: 1.0180637e-06
Iter: 1711 loss: 1.01987848e-06
Iter: 1712 loss: 1.01807336e-06
Iter: 1713 loss: 1.01792079e-06
Iter: 1714 loss: 1.01838737e-06
Iter: 1715 loss: 1.01787123e-06
Iter: 1716 loss: 1.01776277e-06
Iter: 1717 loss: 1.01792784e-06
Iter: 1718 loss: 1.01771388e-06
Iter: 1719 loss: 1.01760145e-06
Iter: 1720 loss: 1.01824185e-06
Iter: 1721 loss: 1.01758633e-06
Iter: 1722 loss: 1.01746627e-06
Iter: 1723 loss: 1.01738692e-06
Iter: 1724 loss: 1.01733576e-06
Iter: 1725 loss: 1.01725914e-06
Iter: 1726 loss: 1.01725766e-06
Iter: 1727 loss: 1.01718081e-06
Iter: 1728 loss: 1.01708e-06
Iter: 1729 loss: 1.01707292e-06
Iter: 1730 loss: 1.01695161e-06
Iter: 1731 loss: 1.01748219e-06
Iter: 1732 loss: 1.01692012e-06
Iter: 1733 loss: 1.01680212e-06
Iter: 1734 loss: 1.01722605e-06
Iter: 1735 loss: 1.01680871e-06
Iter: 1736 loss: 1.0166741e-06
Iter: 1737 loss: 1.01689534e-06
Iter: 1738 loss: 1.01662795e-06
Iter: 1739 loss: 1.01652108e-06
Iter: 1740 loss: 1.01640603e-06
Iter: 1741 loss: 1.01638852e-06
Iter: 1742 loss: 1.01627461e-06
Iter: 1743 loss: 1.01799469e-06
Iter: 1744 loss: 1.01626335e-06
Iter: 1745 loss: 1.01617752e-06
Iter: 1746 loss: 1.01716876e-06
Iter: 1747 loss: 1.01617889e-06
Iter: 1748 loss: 1.01612534e-06
Iter: 1749 loss: 1.01607077e-06
Iter: 1750 loss: 1.01608043e-06
Iter: 1751 loss: 1.01599232e-06
Iter: 1752 loss: 1.01676835e-06
Iter: 1753 loss: 1.01597459e-06
Iter: 1754 loss: 1.01592263e-06
Iter: 1755 loss: 1.01588569e-06
Iter: 1756 loss: 1.01587e-06
Iter: 1757 loss: 1.01577643e-06
Iter: 1758 loss: 1.0157803e-06
Iter: 1759 loss: 1.01573664e-06
Iter: 1760 loss: 1.01564865e-06
Iter: 1761 loss: 1.0156466e-06
Iter: 1762 loss: 1.01554656e-06
Iter: 1763 loss: 1.01595674e-06
Iter: 1764 loss: 1.01553985e-06
Iter: 1765 loss: 1.01546982e-06
Iter: 1766 loss: 1.0158202e-06
Iter: 1767 loss: 1.01546379e-06
Iter: 1768 loss: 1.0153708e-06
Iter: 1769 loss: 1.01583055e-06
Iter: 1770 loss: 1.01535784e-06
Iter: 1771 loss: 1.01531475e-06
Iter: 1772 loss: 1.01517344e-06
Iter: 1773 loss: 1.0167895e-06
Iter: 1774 loss: 1.01517139e-06
Iter: 1775 loss: 1.0150419e-06
Iter: 1776 loss: 1.01564615e-06
Iter: 1777 loss: 1.01500223e-06
Iter: 1778 loss: 1.01493652e-06
Iter: 1779 loss: 1.01491889e-06
Iter: 1780 loss: 1.01487058e-06
Iter: 1781 loss: 1.01481078e-06
Iter: 1782 loss: 1.01481294e-06
Iter: 1783 loss: 1.01474166e-06
Iter: 1784 loss: 1.01561614e-06
Iter: 1785 loss: 1.01473643e-06
Iter: 1786 loss: 1.01470437e-06
Iter: 1787 loss: 1.01464809e-06
Iter: 1788 loss: 1.01463809e-06
Iter: 1789 loss: 1.01455578e-06
Iter: 1790 loss: 1.01571095e-06
Iter: 1791 loss: 1.0145535e-06
Iter: 1792 loss: 1.01445062e-06
Iter: 1793 loss: 1.01440105e-06
Iter: 1794 loss: 1.01436672e-06
Iter: 1795 loss: 1.01427099e-06
Iter: 1796 loss: 1.01439582e-06
Iter: 1797 loss: 1.01421449e-06
Iter: 1798 loss: 1.01412957e-06
Iter: 1799 loss: 1.01433579e-06
Iter: 1800 loss: 1.01404544e-06
Iter: 1801 loss: 1.01394812e-06
Iter: 1802 loss: 1.0154813e-06
Iter: 1803 loss: 1.01394312e-06
Iter: 1804 loss: 1.01388434e-06
Iter: 1805 loss: 1.01371961e-06
Iter: 1806 loss: 1.0169033e-06
Iter: 1807 loss: 1.01371415e-06
Iter: 1808 loss: 1.01355272e-06
Iter: 1809 loss: 1.01356545e-06
Iter: 1810 loss: 1.01345574e-06
Iter: 1811 loss: 1.01333308e-06
Iter: 1812 loss: 1.01332307e-06
Iter: 1813 loss: 1.01320211e-06
Iter: 1814 loss: 1.01299463e-06
Iter: 1815 loss: 1.0178311e-06
Iter: 1816 loss: 1.01300861e-06
Iter: 1817 loss: 1.01280716e-06
Iter: 1818 loss: 1.01281103e-06
Iter: 1819 loss: 1.0127028e-06
Iter: 1820 loss: 1.01267131e-06
Iter: 1821 loss: 1.01261e-06
Iter: 1822 loss: 1.01247019e-06
Iter: 1823 loss: 1.01306387e-06
Iter: 1824 loss: 1.01245905e-06
Iter: 1825 loss: 1.01227954e-06
Iter: 1826 loss: 1.01281216e-06
Iter: 1827 loss: 1.01223191e-06
Iter: 1828 loss: 1.01212038e-06
Iter: 1829 loss: 1.01205387e-06
Iter: 1830 loss: 1.01198657e-06
Iter: 1831 loss: 1.01180649e-06
Iter: 1832 loss: 1.01200965e-06
Iter: 1833 loss: 1.01173259e-06
Iter: 1834 loss: 1.01150613e-06
Iter: 1835 loss: 1.01404908e-06
Iter: 1836 loss: 1.01148271e-06
Iter: 1837 loss: 1.01133082e-06
Iter: 1838 loss: 1.01111777e-06
Iter: 1839 loss: 1.01109697e-06
Iter: 1840 loss: 1.01087448e-06
Iter: 1841 loss: 1.01127011e-06
Iter: 1842 loss: 1.01077592e-06
Iter: 1843 loss: 1.01067553e-06
Iter: 1844 loss: 1.01064938e-06
Iter: 1845 loss: 1.01054263e-06
Iter: 1846 loss: 1.01049909e-06
Iter: 1847 loss: 1.01043793e-06
Iter: 1848 loss: 1.01032265e-06
Iter: 1849 loss: 1.01120349e-06
Iter: 1850 loss: 1.01031628e-06
Iter: 1851 loss: 1.01021942e-06
Iter: 1852 loss: 1.01009164e-06
Iter: 1853 loss: 1.01005594e-06
Iter: 1854 loss: 1.0098945e-06
Iter: 1855 loss: 1.01028695e-06
Iter: 1856 loss: 1.00983607e-06
Iter: 1857 loss: 1.00970533e-06
Iter: 1858 loss: 1.00971e-06
Iter: 1859 loss: 1.00960301e-06
Iter: 1860 loss: 1.0094908e-06
Iter: 1861 loss: 1.00948273e-06
Iter: 1862 loss: 1.00929651e-06
Iter: 1863 loss: 1.00974194e-06
Iter: 1864 loss: 1.00924308e-06
Iter: 1865 loss: 1.00913462e-06
Iter: 1866 loss: 1.01082423e-06
Iter: 1867 loss: 1.00912246e-06
Iter: 1868 loss: 1.00901354e-06
Iter: 1869 loss: 1.00900411e-06
Iter: 1870 loss: 1.00893567e-06
Iter: 1871 loss: 1.00880038e-06
Iter: 1872 loss: 1.00862189e-06
Iter: 1873 loss: 1.00862633e-06
Iter: 1874 loss: 1.00840543e-06
Iter: 1875 loss: 1.00967759e-06
Iter: 1876 loss: 1.00836473e-06
Iter: 1877 loss: 1.00822672e-06
Iter: 1878 loss: 1.01078513e-06
Iter: 1879 loss: 1.00821e-06
Iter: 1880 loss: 1.00812042e-06
Iter: 1881 loss: 1.00808006e-06
Iter: 1882 loss: 1.00808393e-06
Iter: 1883 loss: 1.00789725e-06
Iter: 1884 loss: 1.00835985e-06
Iter: 1885 loss: 1.00786633e-06
Iter: 1886 loss: 1.00771297e-06
Iter: 1887 loss: 1.00749639e-06
Iter: 1888 loss: 1.00751606e-06
Iter: 1889 loss: 1.00745842e-06
Iter: 1890 loss: 1.00738657e-06
Iter: 1891 loss: 1.00729881e-06
Iter: 1892 loss: 1.00719478e-06
Iter: 1893 loss: 1.00716488e-06
Iter: 1894 loss: 1.00703176e-06
Iter: 1895 loss: 1.00721616e-06
Iter: 1896 loss: 1.0069416e-06
Iter: 1897 loss: 1.00678903e-06
Iter: 1898 loss: 1.00748775e-06
Iter: 1899 loss: 1.00674947e-06
Iter: 1900 loss: 1.006611e-06
Iter: 1901 loss: 1.00757791e-06
Iter: 1902 loss: 1.00659713e-06
Iter: 1903 loss: 1.00648379e-06
Iter: 1904 loss: 1.00633031e-06
Iter: 1905 loss: 1.00630677e-06
Iter: 1906 loss: 1.00614909e-06
Iter: 1907 loss: 1.00657667e-06
Iter: 1908 loss: 1.00606394e-06
Iter: 1909 loss: 1.00604495e-06
Iter: 1910 loss: 1.00598891e-06
Iter: 1911 loss: 1.00591569e-06
Iter: 1912 loss: 1.00580064e-06
Iter: 1913 loss: 1.00581383e-06
Iter: 1914 loss: 1.00572447e-06
Iter: 1915 loss: 1.00572368e-06
Iter: 1916 loss: 1.00566558e-06
Iter: 1917 loss: 1.0055021e-06
Iter: 1918 loss: 1.00662214e-06
Iter: 1919 loss: 1.00548402e-06
Iter: 1920 loss: 1.00535362e-06
Iter: 1921 loss: 1.0053534e-06
Iter: 1922 loss: 1.00520242e-06
Iter: 1923 loss: 1.00554348e-06
Iter: 1924 loss: 1.00514808e-06
Iter: 1925 loss: 1.00505315e-06
Iter: 1926 loss: 1.00508669e-06
Iter: 1927 loss: 1.00498721e-06
Iter: 1928 loss: 1.00487114e-06
Iter: 1929 loss: 1.00538864e-06
Iter: 1930 loss: 1.00483874e-06
Iter: 1931 loss: 1.00470595e-06
Iter: 1932 loss: 1.00584498e-06
Iter: 1933 loss: 1.00470129e-06
Iter: 1934 loss: 1.00461921e-06
Iter: 1935 loss: 1.00449847e-06
Iter: 1936 loss: 1.00794239e-06
Iter: 1937 loss: 1.00449404e-06
Iter: 1938 loss: 1.00431589e-06
Iter: 1939 loss: 1.00457521e-06
Iter: 1940 loss: 1.00425495e-06
Iter: 1941 loss: 1.00415264e-06
Iter: 1942 loss: 1.00417446e-06
Iter: 1943 loss: 1.00404975e-06
Iter: 1944 loss: 1.00405987e-06
Iter: 1945 loss: 1.00397278e-06
Iter: 1946 loss: 1.00389821e-06
Iter: 1947 loss: 1.00439729e-06
Iter: 1948 loss: 1.00385864e-06
Iter: 1949 loss: 1.00374314e-06
Iter: 1950 loss: 1.00376064e-06
Iter: 1951 loss: 1.00367311e-06
Iter: 1952 loss: 1.00355351e-06
Iter: 1953 loss: 1.00347643e-06
Iter: 1954 loss: 1.00345255e-06
Iter: 1955 loss: 1.00324746e-06
Iter: 1956 loss: 1.00325212e-06
Iter: 1957 loss: 1.00313798e-06
Iter: 1958 loss: 1.00300463e-06
Iter: 1959 loss: 1.0030094e-06
Iter: 1960 loss: 1.00285354e-06
Iter: 1961 loss: 1.00370346e-06
Iter: 1962 loss: 1.00282864e-06
Iter: 1963 loss: 1.00274883e-06
Iter: 1964 loss: 1.00393663e-06
Iter: 1965 loss: 1.00275793e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4
+ date
Mon Oct 26 15:01:01 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814cce0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814c609d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814c60d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814c602f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814d35598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814c02c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814bb5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814ba2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814b59620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814b59d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814b596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814b05f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814b10840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814a9c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814a75f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814a9c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814a3e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814a3e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88149fd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814a3eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88149ce730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88149cfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814925840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814952a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88149527b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88148fc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88148b9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f881487c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8814881598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbbb6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbbc0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbba18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbba10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbba1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbb57ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87fbb01ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.22919901e-05
Iter: 2 loss: 9.64845822e-06
Iter: 3 loss: 8.82089171e-06
Iter: 4 loss: 7.95495907e-06
Iter: 5 loss: 9.41584676e-06
Iter: 6 loss: 7.56655345e-06
Iter: 7 loss: 7.14395355e-06
Iter: 8 loss: 7.28717669e-06
Iter: 9 loss: 6.84526e-06
Iter: 10 loss: 6.4582855e-06
Iter: 11 loss: 1.09067551e-05
Iter: 12 loss: 6.45198497e-06
Iter: 13 loss: 6.07527909e-06
Iter: 14 loss: 5.71065175e-06
Iter: 15 loss: 5.62831e-06
Iter: 16 loss: 5.3399217e-06
Iter: 17 loss: 5.75473678e-06
Iter: 18 loss: 5.19938112e-06
Iter: 19 loss: 4.88407341e-06
Iter: 20 loss: 4.88405749e-06
Iter: 21 loss: 4.70297073e-06
Iter: 22 loss: 4.41958764e-06
Iter: 23 loss: 4.41617613e-06
Iter: 24 loss: 4.31565695e-06
Iter: 25 loss: 4.29978172e-06
Iter: 26 loss: 4.18359832e-06
Iter: 27 loss: 4.13099133e-06
Iter: 28 loss: 4.0727532e-06
Iter: 29 loss: 3.95857433e-06
Iter: 30 loss: 3.87090222e-06
Iter: 31 loss: 3.83439965e-06
Iter: 32 loss: 3.67894199e-06
Iter: 33 loss: 3.63063464e-06
Iter: 34 loss: 3.53883843e-06
Iter: 35 loss: 3.3639285e-06
Iter: 36 loss: 3.38229802e-06
Iter: 37 loss: 3.22913047e-06
Iter: 38 loss: 3.02933086e-06
Iter: 39 loss: 4.28050953e-06
Iter: 40 loss: 3.00636339e-06
Iter: 41 loss: 2.85106171e-06
Iter: 42 loss: 3.97169515e-06
Iter: 43 loss: 2.8376985e-06
Iter: 44 loss: 2.75368029e-06
Iter: 45 loss: 4.01288253e-06
Iter: 46 loss: 2.75361117e-06
Iter: 47 loss: 2.70923351e-06
Iter: 48 loss: 2.61826222e-06
Iter: 49 loss: 4.23752681e-06
Iter: 50 loss: 2.61652781e-06
Iter: 51 loss: 2.52352811e-06
Iter: 52 loss: 2.92433197e-06
Iter: 53 loss: 2.50442781e-06
Iter: 54 loss: 2.40991699e-06
Iter: 55 loss: 3.4638133e-06
Iter: 56 loss: 2.40809e-06
Iter: 57 loss: 2.37316908e-06
Iter: 58 loss: 2.30402475e-06
Iter: 59 loss: 3.64738389e-06
Iter: 60 loss: 2.30330943e-06
Iter: 61 loss: 2.27941609e-06
Iter: 62 loss: 2.26284328e-06
Iter: 63 loss: 2.23484903e-06
Iter: 64 loss: 2.20779407e-06
Iter: 65 loss: 2.20166703e-06
Iter: 66 loss: 2.17749312e-06
Iter: 67 loss: 2.17557727e-06
Iter: 68 loss: 2.1601295e-06
Iter: 69 loss: 2.12381292e-06
Iter: 70 loss: 2.55040527e-06
Iter: 71 loss: 2.12068312e-06
Iter: 72 loss: 2.07785115e-06
Iter: 73 loss: 2.140471e-06
Iter: 74 loss: 2.05708579e-06
Iter: 75 loss: 2.00972408e-06
Iter: 76 loss: 2.27247369e-06
Iter: 77 loss: 2.00293653e-06
Iter: 78 loss: 1.97290842e-06
Iter: 79 loss: 2.35951575e-06
Iter: 80 loss: 1.97270401e-06
Iter: 81 loss: 1.94858967e-06
Iter: 82 loss: 1.98362204e-06
Iter: 83 loss: 1.93684764e-06
Iter: 84 loss: 1.91589788e-06
Iter: 85 loss: 1.89191917e-06
Iter: 86 loss: 1.88896433e-06
Iter: 87 loss: 1.87113255e-06
Iter: 88 loss: 1.86972136e-06
Iter: 89 loss: 1.84854184e-06
Iter: 90 loss: 1.83317718e-06
Iter: 91 loss: 1.82590975e-06
Iter: 92 loss: 1.80151596e-06
Iter: 93 loss: 1.80430595e-06
Iter: 94 loss: 1.78277264e-06
Iter: 95 loss: 1.74804973e-06
Iter: 96 loss: 2.2310719e-06
Iter: 97 loss: 1.74795866e-06
Iter: 98 loss: 1.73229705e-06
Iter: 99 loss: 1.7515747e-06
Iter: 100 loss: 1.72409136e-06
Iter: 101 loss: 1.70650219e-06
Iter: 102 loss: 1.86515672e-06
Iter: 103 loss: 1.70566091e-06
Iter: 104 loss: 1.69851955e-06
Iter: 105 loss: 1.67949872e-06
Iter: 106 loss: 1.81530083e-06
Iter: 107 loss: 1.67533267e-06
Iter: 108 loss: 1.65371603e-06
Iter: 109 loss: 1.84285341e-06
Iter: 110 loss: 1.65260826e-06
Iter: 111 loss: 1.63703885e-06
Iter: 112 loss: 1.74846605e-06
Iter: 113 loss: 1.63566745e-06
Iter: 114 loss: 1.62364699e-06
Iter: 115 loss: 1.70155784e-06
Iter: 116 loss: 1.62227343e-06
Iter: 117 loss: 1.61064577e-06
Iter: 118 loss: 1.59426349e-06
Iter: 119 loss: 1.59364254e-06
Iter: 120 loss: 1.57731824e-06
Iter: 121 loss: 1.64025073e-06
Iter: 122 loss: 1.57350019e-06
Iter: 123 loss: 1.56717965e-06
Iter: 124 loss: 1.56561077e-06
Iter: 125 loss: 1.55992052e-06
Iter: 126 loss: 1.5461643e-06
Iter: 127 loss: 1.69346697e-06
Iter: 128 loss: 1.54469672e-06
Iter: 129 loss: 1.534018e-06
Iter: 130 loss: 1.68730503e-06
Iter: 131 loss: 1.53400492e-06
Iter: 132 loss: 1.52146322e-06
Iter: 133 loss: 1.52205803e-06
Iter: 134 loss: 1.51161748e-06
Iter: 135 loss: 1.50626852e-06
Iter: 136 loss: 1.50584219e-06
Iter: 137 loss: 1.50052085e-06
Iter: 138 loss: 1.49126174e-06
Iter: 139 loss: 1.49123548e-06
Iter: 140 loss: 1.48122524e-06
Iter: 141 loss: 1.47332275e-06
Iter: 142 loss: 1.47019932e-06
Iter: 143 loss: 1.46124989e-06
Iter: 144 loss: 1.46102593e-06
Iter: 145 loss: 1.45346894e-06
Iter: 146 loss: 1.47765229e-06
Iter: 147 loss: 1.4513505e-06
Iter: 148 loss: 1.44303158e-06
Iter: 149 loss: 1.46796947e-06
Iter: 150 loss: 1.44050284e-06
Iter: 151 loss: 1.4335576e-06
Iter: 152 loss: 1.42895919e-06
Iter: 153 loss: 1.42634917e-06
Iter: 154 loss: 1.4200474e-06
Iter: 155 loss: 1.49969856e-06
Iter: 156 loss: 1.41997509e-06
Iter: 157 loss: 1.41361716e-06
Iter: 158 loss: 1.43122179e-06
Iter: 159 loss: 1.41158807e-06
Iter: 160 loss: 1.40687848e-06
Iter: 161 loss: 1.4003233e-06
Iter: 162 loss: 1.40009263e-06
Iter: 163 loss: 1.39715223e-06
Iter: 164 loss: 1.39561064e-06
Iter: 165 loss: 1.3922778e-06
Iter: 166 loss: 1.38644441e-06
Iter: 167 loss: 1.38643895e-06
Iter: 168 loss: 1.38296161e-06
Iter: 169 loss: 1.38239636e-06
Iter: 170 loss: 1.3796506e-06
Iter: 171 loss: 1.37172e-06
Iter: 172 loss: 1.40335931e-06
Iter: 173 loss: 1.36852168e-06
Iter: 174 loss: 1.36111964e-06
Iter: 175 loss: 1.42892793e-06
Iter: 176 loss: 1.36076665e-06
Iter: 177 loss: 1.35676362e-06
Iter: 178 loss: 1.41606074e-06
Iter: 179 loss: 1.35674395e-06
Iter: 180 loss: 1.35290838e-06
Iter: 181 loss: 1.35643415e-06
Iter: 182 loss: 1.35069513e-06
Iter: 183 loss: 1.34542597e-06
Iter: 184 loss: 1.35227867e-06
Iter: 185 loss: 1.34275831e-06
Iter: 186 loss: 1.33829326e-06
Iter: 187 loss: 1.34121615e-06
Iter: 188 loss: 1.33548042e-06
Iter: 189 loss: 1.33229e-06
Iter: 190 loss: 1.33212529e-06
Iter: 191 loss: 1.3291185e-06
Iter: 192 loss: 1.32313994e-06
Iter: 193 loss: 1.43776128e-06
Iter: 194 loss: 1.32305706e-06
Iter: 195 loss: 1.31856564e-06
Iter: 196 loss: 1.36907727e-06
Iter: 197 loss: 1.31850015e-06
Iter: 198 loss: 1.31486695e-06
Iter: 199 loss: 1.34057609e-06
Iter: 200 loss: 1.31450327e-06
Iter: 201 loss: 1.31257559e-06
Iter: 202 loss: 1.31347406e-06
Iter: 203 loss: 1.31127103e-06
Iter: 204 loss: 1.30745764e-06
Iter: 205 loss: 1.31087745e-06
Iter: 206 loss: 1.30522676e-06
Iter: 207 loss: 1.30268779e-06
Iter: 208 loss: 1.29871387e-06
Iter: 209 loss: 1.29867067e-06
Iter: 210 loss: 1.29389946e-06
Iter: 211 loss: 1.31847401e-06
Iter: 212 loss: 1.29313946e-06
Iter: 213 loss: 1.28932766e-06
Iter: 214 loss: 1.2893305e-06
Iter: 215 loss: 1.28670581e-06
Iter: 216 loss: 1.28799547e-06
Iter: 217 loss: 1.28493593e-06
Iter: 218 loss: 1.28175589e-06
Iter: 219 loss: 1.28620422e-06
Iter: 220 loss: 1.280167e-06
Iter: 221 loss: 1.27780288e-06
Iter: 222 loss: 1.29198952e-06
Iter: 223 loss: 1.27752401e-06
Iter: 224 loss: 1.27456087e-06
Iter: 225 loss: 1.27858061e-06
Iter: 226 loss: 1.27312e-06
Iter: 227 loss: 1.2703415e-06
Iter: 228 loss: 1.26843656e-06
Iter: 229 loss: 1.26744362e-06
Iter: 230 loss: 1.26589885e-06
Iter: 231 loss: 1.26528926e-06
Iter: 232 loss: 1.26376472e-06
Iter: 233 loss: 1.26135183e-06
Iter: 234 loss: 1.26133955e-06
Iter: 235 loss: 1.25914789e-06
Iter: 236 loss: 1.25910435e-06
Iter: 237 loss: 1.25764041e-06
Iter: 238 loss: 1.25442318e-06
Iter: 239 loss: 1.29988655e-06
Iter: 240 loss: 1.25422525e-06
Iter: 241 loss: 1.2517005e-06
Iter: 242 loss: 1.25148767e-06
Iter: 243 loss: 1.24960161e-06
Iter: 244 loss: 1.24631913e-06
Iter: 245 loss: 1.24632106e-06
Iter: 246 loss: 1.24304916e-06
Iter: 247 loss: 1.25080146e-06
Iter: 248 loss: 1.2418468e-06
Iter: 249 loss: 1.2393707e-06
Iter: 250 loss: 1.24593885e-06
Iter: 251 loss: 1.2385201e-06
Iter: 252 loss: 1.23626114e-06
Iter: 253 loss: 1.23722316e-06
Iter: 254 loss: 1.23470511e-06
Iter: 255 loss: 1.23282211e-06
Iter: 256 loss: 1.23276777e-06
Iter: 257 loss: 1.23146242e-06
Iter: 258 loss: 1.22931556e-06
Iter: 259 loss: 1.22933238e-06
Iter: 260 loss: 1.22781034e-06
Iter: 261 loss: 1.25128054e-06
Iter: 262 loss: 1.22779568e-06
Iter: 263 loss: 1.22623385e-06
Iter: 264 loss: 1.22651795e-06
Iter: 265 loss: 1.22504764e-06
Iter: 266 loss: 1.22325059e-06
Iter: 267 loss: 1.22977531e-06
Iter: 268 loss: 1.22281563e-06
Iter: 269 loss: 1.22020379e-06
Iter: 270 loss: 1.22045833e-06
Iter: 271 loss: 1.21818562e-06
Iter: 272 loss: 1.2164669e-06
Iter: 273 loss: 1.21513187e-06
Iter: 274 loss: 1.2146113e-06
Iter: 275 loss: 1.21206665e-06
Iter: 276 loss: 1.21671167e-06
Iter: 277 loss: 1.21097833e-06
Iter: 278 loss: 1.20999539e-06
Iter: 279 loss: 1.20943059e-06
Iter: 280 loss: 1.20826974e-06
Iter: 281 loss: 1.2069205e-06
Iter: 282 loss: 1.2067942e-06
Iter: 283 loss: 1.20474215e-06
Iter: 284 loss: 1.20949551e-06
Iter: 285 loss: 1.20395703e-06
Iter: 286 loss: 1.20185484e-06
Iter: 287 loss: 1.20986067e-06
Iter: 288 loss: 1.20136292e-06
Iter: 289 loss: 1.19907543e-06
Iter: 290 loss: 1.21086373e-06
Iter: 291 loss: 1.19866354e-06
Iter: 292 loss: 1.1976399e-06
Iter: 293 loss: 1.19677179e-06
Iter: 294 loss: 1.1964504e-06
Iter: 295 loss: 1.19532774e-06
Iter: 296 loss: 1.19527385e-06
Iter: 297 loss: 1.19445622e-06
Iter: 298 loss: 1.19310823e-06
Iter: 299 loss: 1.19309391e-06
Iter: 300 loss: 1.1919077e-06
Iter: 301 loss: 1.19185961e-06
Iter: 302 loss: 1.19099991e-06
Iter: 303 loss: 1.18871492e-06
Iter: 304 loss: 1.2078774e-06
Iter: 305 loss: 1.1883817e-06
Iter: 306 loss: 1.18628918e-06
Iter: 307 loss: 1.18909429e-06
Iter: 308 loss: 1.18519824e-06
Iter: 309 loss: 1.1830731e-06
Iter: 310 loss: 1.19965807e-06
Iter: 311 loss: 1.18295372e-06
Iter: 312 loss: 1.18176831e-06
Iter: 313 loss: 1.18168737e-06
Iter: 314 loss: 1.18114758e-06
Iter: 315 loss: 1.17998411e-06
Iter: 316 loss: 1.1996234e-06
Iter: 317 loss: 1.17993841e-06
Iter: 318 loss: 1.17816694e-06
Iter: 319 loss: 1.18231651e-06
Iter: 320 loss: 1.17751233e-06
Iter: 321 loss: 1.17586319e-06
Iter: 322 loss: 1.19106892e-06
Iter: 323 loss: 1.17581317e-06
Iter: 324 loss: 1.1743748e-06
Iter: 325 loss: 1.17458944e-06
Iter: 326 loss: 1.17330228e-06
Iter: 327 loss: 1.17205855e-06
Iter: 328 loss: 1.1745658e-06
Iter: 329 loss: 1.17158675e-06
Iter: 330 loss: 1.16981391e-06
Iter: 331 loss: 1.178925e-06
Iter: 332 loss: 1.16952958e-06
Iter: 333 loss: 1.16870433e-06
Iter: 334 loss: 1.17075433e-06
Iter: 335 loss: 1.16841989e-06
Iter: 336 loss: 1.1673834e-06
Iter: 337 loss: 1.17079207e-06
Iter: 338 loss: 1.16708338e-06
Iter: 339 loss: 1.1663858e-06
Iter: 340 loss: 1.16455794e-06
Iter: 341 loss: 1.1793918e-06
Iter: 342 loss: 1.16424462e-06
Iter: 343 loss: 1.16179797e-06
Iter: 344 loss: 1.16905539e-06
Iter: 345 loss: 1.16104877e-06
Iter: 346 loss: 1.15926832e-06
Iter: 347 loss: 1.16634897e-06
Iter: 348 loss: 1.15887019e-06
Iter: 349 loss: 1.1571484e-06
Iter: 350 loss: 1.15942635e-06
Iter: 351 loss: 1.1562812e-06
Iter: 352 loss: 1.15568037e-06
Iter: 353 loss: 1.1551831e-06
Iter: 354 loss: 1.15431146e-06
Iter: 355 loss: 1.15349644e-06
Iter: 356 loss: 1.15328385e-06
Iter: 357 loss: 1.15203818e-06
Iter: 358 loss: 1.15584498e-06
Iter: 359 loss: 1.15169e-06
Iter: 360 loss: 1.15037244e-06
Iter: 361 loss: 1.15401849e-06
Iter: 362 loss: 1.14996544e-06
Iter: 363 loss: 1.1488678e-06
Iter: 364 loss: 1.16370461e-06
Iter: 365 loss: 1.14886643e-06
Iter: 366 loss: 1.14838076e-06
Iter: 367 loss: 1.14753971e-06
Iter: 368 loss: 1.1665154e-06
Iter: 369 loss: 1.14752106e-06
Iter: 370 loss: 1.14668194e-06
Iter: 371 loss: 1.14666227e-06
Iter: 372 loss: 1.14609554e-06
Iter: 373 loss: 1.14462296e-06
Iter: 374 loss: 1.15747821e-06
Iter: 375 loss: 1.14439194e-06
Iter: 376 loss: 1.14385716e-06
Iter: 377 loss: 1.14351394e-06
Iter: 378 loss: 1.14285535e-06
Iter: 379 loss: 1.14133582e-06
Iter: 380 loss: 1.15540615e-06
Iter: 381 loss: 1.14108252e-06
Iter: 382 loss: 1.13962676e-06
Iter: 383 loss: 1.14276975e-06
Iter: 384 loss: 1.13902911e-06
Iter: 385 loss: 1.13771068e-06
Iter: 386 loss: 1.14323348e-06
Iter: 387 loss: 1.13741862e-06
Iter: 388 loss: 1.13672479e-06
Iter: 389 loss: 1.1367e-06
Iter: 390 loss: 1.13583792e-06
Iter: 391 loss: 1.13462875e-06
Iter: 392 loss: 1.13458577e-06
Iter: 393 loss: 1.13325973e-06
Iter: 394 loss: 1.13884016e-06
Iter: 395 loss: 1.13299302e-06
Iter: 396 loss: 1.13199212e-06
Iter: 397 loss: 1.13882243e-06
Iter: 398 loss: 1.13188116e-06
Iter: 399 loss: 1.13109695e-06
Iter: 400 loss: 1.13552608e-06
Iter: 401 loss: 1.13099554e-06
Iter: 402 loss: 1.13034298e-06
Iter: 403 loss: 1.12981502e-06
Iter: 404 loss: 1.12963016e-06
Iter: 405 loss: 1.12865894e-06
Iter: 406 loss: 1.14261775e-06
Iter: 407 loss: 1.12867519e-06
Iter: 408 loss: 1.12809948e-06
Iter: 409 loss: 1.12709199e-06
Iter: 410 loss: 1.14801799e-06
Iter: 411 loss: 1.12707994e-06
Iter: 412 loss: 1.12642249e-06
Iter: 413 loss: 1.126406e-06
Iter: 414 loss: 1.12565658e-06
Iter: 415 loss: 1.12396037e-06
Iter: 416 loss: 1.14766544e-06
Iter: 417 loss: 1.12385919e-06
Iter: 418 loss: 1.12256703e-06
Iter: 419 loss: 1.12408361e-06
Iter: 420 loss: 1.12189184e-06
Iter: 421 loss: 1.12053e-06
Iter: 422 loss: 1.12363864e-06
Iter: 423 loss: 1.12002624e-06
Iter: 424 loss: 1.11926602e-06
Iter: 425 loss: 1.11916404e-06
Iter: 426 loss: 1.11820941e-06
Iter: 427 loss: 1.11820077e-06
Iter: 428 loss: 1.11743975e-06
Iter: 429 loss: 1.11658346e-06
Iter: 430 loss: 1.11724682e-06
Iter: 431 loss: 1.11604697e-06
Iter: 432 loss: 1.11523991e-06
Iter: 433 loss: 1.12760847e-06
Iter: 434 loss: 1.11524685e-06
Iter: 435 loss: 1.11447889e-06
Iter: 436 loss: 1.1151958e-06
Iter: 437 loss: 1.11407257e-06
Iter: 438 loss: 1.11328654e-06
Iter: 439 loss: 1.11623842e-06
Iter: 440 loss: 1.11307418e-06
Iter: 441 loss: 1.11251393e-06
Iter: 442 loss: 1.11875465e-06
Iter: 443 loss: 1.11250688e-06
Iter: 444 loss: 1.1120685e-06
Iter: 445 loss: 1.11090458e-06
Iter: 446 loss: 1.11838676e-06
Iter: 447 loss: 1.11065049e-06
Iter: 448 loss: 1.11008171e-06
Iter: 449 loss: 1.10995347e-06
Iter: 450 loss: 1.10926521e-06
Iter: 451 loss: 1.10939777e-06
Iter: 452 loss: 1.10871383e-06
Iter: 453 loss: 1.10805843e-06
Iter: 454 loss: 1.10673125e-06
Iter: 455 loss: 1.13220699e-06
Iter: 456 loss: 1.10672261e-06
Iter: 457 loss: 1.10536757e-06
Iter: 458 loss: 1.11524093e-06
Iter: 459 loss: 1.10525923e-06
Iter: 460 loss: 1.10474957e-06
Iter: 461 loss: 1.10463748e-06
Iter: 462 loss: 1.10404835e-06
Iter: 463 loss: 1.10327039e-06
Iter: 464 loss: 1.10322162e-06
Iter: 465 loss: 1.10227506e-06
Iter: 466 loss: 1.10210647e-06
Iter: 467 loss: 1.10147016e-06
Iter: 468 loss: 1.10073438e-06
Iter: 469 loss: 1.10059216e-06
Iter: 470 loss: 1.10012434e-06
Iter: 471 loss: 1.10060762e-06
Iter: 472 loss: 1.0998267e-06
Iter: 473 loss: 1.09925907e-06
Iter: 474 loss: 1.10047654e-06
Iter: 475 loss: 1.09904863e-06
Iter: 476 loss: 1.09830103e-06
Iter: 477 loss: 1.0997237e-06
Iter: 478 loss: 1.09796565e-06
Iter: 479 loss: 1.0973431e-06
Iter: 480 loss: 1.09696657e-06
Iter: 481 loss: 1.09670736e-06
Iter: 482 loss: 1.09623545e-06
Iter: 483 loss: 1.09621e-06
Iter: 484 loss: 1.0956885e-06
Iter: 485 loss: 1.0945256e-06
Iter: 486 loss: 1.11310703e-06
Iter: 487 loss: 1.09448763e-06
Iter: 488 loss: 1.09328505e-06
Iter: 489 loss: 1.09415419e-06
Iter: 490 loss: 1.09252494e-06
Iter: 491 loss: 1.09141251e-06
Iter: 492 loss: 1.09603275e-06
Iter: 493 loss: 1.09117332e-06
Iter: 494 loss: 1.09086704e-06
Iter: 495 loss: 1.09061216e-06
Iter: 496 loss: 1.0901806e-06
Iter: 497 loss: 1.0892187e-06
Iter: 498 loss: 1.10355154e-06
Iter: 499 loss: 1.08919176e-06
Iter: 500 loss: 1.08852e-06
Iter: 501 loss: 1.09558789e-06
Iter: 502 loss: 1.08849349e-06
Iter: 503 loss: 1.08780068e-06
Iter: 504 loss: 1.09050063e-06
Iter: 505 loss: 1.08763834e-06
Iter: 506 loss: 1.08706547e-06
Iter: 507 loss: 1.08698441e-06
Iter: 508 loss: 1.08655343e-06
Iter: 509 loss: 1.08572544e-06
Iter: 510 loss: 1.09350719e-06
Iter: 511 loss: 1.08569327e-06
Iter: 512 loss: 1.08508641e-06
Iter: 513 loss: 1.08546305e-06
Iter: 514 loss: 1.08472932e-06
Iter: 515 loss: 1.08417362e-06
Iter: 516 loss: 1.08400229e-06
Iter: 517 loss: 1.08367885e-06
Iter: 518 loss: 1.08327436e-06
Iter: 519 loss: 1.08322729e-06
Iter: 520 loss: 1.08280483e-06
Iter: 521 loss: 1.08178938e-06
Iter: 522 loss: 1.09177608e-06
Iter: 523 loss: 1.08165364e-06
Iter: 524 loss: 1.08072391e-06
Iter: 525 loss: 1.08258462e-06
Iter: 526 loss: 1.08035283e-06
Iter: 527 loss: 1.07918197e-06
Iter: 528 loss: 1.08226914e-06
Iter: 529 loss: 1.07879009e-06
Iter: 530 loss: 1.07831806e-06
Iter: 531 loss: 1.07806386e-06
Iter: 532 loss: 1.07776873e-06
Iter: 533 loss: 1.07715073e-06
Iter: 534 loss: 1.08486643e-06
Iter: 535 loss: 1.07707342e-06
Iter: 536 loss: 1.07651442e-06
Iter: 537 loss: 1.07651397e-06
Iter: 538 loss: 1.07586766e-06
Iter: 539 loss: 1.07531434e-06
Iter: 540 loss: 1.07512506e-06
Iter: 541 loss: 1.07467304e-06
Iter: 542 loss: 1.07464814e-06
Iter: 543 loss: 1.07421488e-06
Iter: 544 loss: 1.07415792e-06
Iter: 545 loss: 1.07385824e-06
Iter: 546 loss: 1.07320443e-06
Iter: 547 loss: 1.07312189e-06
Iter: 548 loss: 1.07263054e-06
Iter: 549 loss: 1.07192e-06
Iter: 550 loss: 1.07589619e-06
Iter: 551 loss: 1.07180756e-06
Iter: 552 loss: 1.07130654e-06
Iter: 553 loss: 1.078271e-06
Iter: 554 loss: 1.07129404e-06
Iter: 555 loss: 1.07102642e-06
Iter: 556 loss: 1.07036658e-06
Iter: 557 loss: 1.07702726e-06
Iter: 558 loss: 1.07027779e-06
Iter: 559 loss: 1.0693559e-06
Iter: 560 loss: 1.0686731e-06
Iter: 561 loss: 1.06835023e-06
Iter: 562 loss: 1.06710672e-06
Iter: 563 loss: 1.07629342e-06
Iter: 564 loss: 1.06698303e-06
Iter: 565 loss: 1.06653806e-06
Iter: 566 loss: 1.06643699e-06
Iter: 567 loss: 1.06583923e-06
Iter: 568 loss: 1.06487641e-06
Iter: 569 loss: 1.06486937e-06
Iter: 570 loss: 1.0642608e-06
Iter: 571 loss: 1.06512925e-06
Iter: 572 loss: 1.06396419e-06
Iter: 573 loss: 1.06343168e-06
Iter: 574 loss: 1.06344748e-06
Iter: 575 loss: 1.06281027e-06
Iter: 576 loss: 1.06229368e-06
Iter: 577 loss: 1.06212087e-06
Iter: 578 loss: 1.06156153e-06
Iter: 579 loss: 1.06605557e-06
Iter: 580 loss: 1.06151697e-06
Iter: 581 loss: 1.06094615e-06
Iter: 582 loss: 1.06286961e-06
Iter: 583 loss: 1.06079835e-06
Iter: 584 loss: 1.06025516e-06
Iter: 585 loss: 1.06021275e-06
Iter: 586 loss: 1.05985976e-06
Iter: 587 loss: 1.05917161e-06
Iter: 588 loss: 1.06070195e-06
Iter: 589 loss: 1.0589016e-06
Iter: 590 loss: 1.05830054e-06
Iter: 591 loss: 1.0663241e-06
Iter: 592 loss: 1.05829986e-06
Iter: 593 loss: 1.05794606e-06
Iter: 594 loss: 1.05717686e-06
Iter: 595 loss: 1.0652218e-06
Iter: 596 loss: 1.0570709e-06
Iter: 597 loss: 1.0560675e-06
Iter: 598 loss: 1.05722461e-06
Iter: 599 loss: 1.05553727e-06
Iter: 600 loss: 1.05553897e-06
Iter: 601 loss: 1.05500726e-06
Iter: 602 loss: 1.05461174e-06
Iter: 603 loss: 1.054108e-06
Iter: 604 loss: 1.05408117e-06
Iter: 605 loss: 1.05356946e-06
Iter: 606 loss: 1.05294816e-06
Iter: 607 loss: 1.05287381e-06
Iter: 608 loss: 1.0530531e-06
Iter: 609 loss: 1.05249126e-06
Iter: 610 loss: 1.05217077e-06
Iter: 611 loss: 1.05167044e-06
Iter: 612 loss: 1.06302264e-06
Iter: 613 loss: 1.05167328e-06
Iter: 614 loss: 1.05128379e-06
Iter: 615 loss: 1.05129516e-06
Iter: 616 loss: 1.05076424e-06
Iter: 617 loss: 1.05001698e-06
Iter: 618 loss: 1.04999026e-06
Iter: 619 loss: 1.04934861e-06
Iter: 620 loss: 1.05459844e-06
Iter: 621 loss: 1.04930882e-06
Iter: 622 loss: 1.0488726e-06
Iter: 623 loss: 1.05047161e-06
Iter: 624 loss: 1.04878472e-06
Iter: 625 loss: 1.04828132e-06
Iter: 626 loss: 1.04868354e-06
Iter: 627 loss: 1.04797016e-06
Iter: 628 loss: 1.04745732e-06
Iter: 629 loss: 1.04680964e-06
Iter: 630 loss: 1.04673563e-06
Iter: 631 loss: 1.04618493e-06
Iter: 632 loss: 1.05380695e-06
Iter: 633 loss: 1.04617868e-06
Iter: 634 loss: 1.04561605e-06
Iter: 635 loss: 1.04788421e-06
Iter: 636 loss: 1.04544483e-06
Iter: 637 loss: 1.04503556e-06
Iter: 638 loss: 1.04432115e-06
Iter: 639 loss: 1.04430887e-06
Iter: 640 loss: 1.0437135e-06
Iter: 641 loss: 1.0513827e-06
Iter: 642 loss: 1.04372396e-06
Iter: 643 loss: 1.04319622e-06
Iter: 644 loss: 1.04731703e-06
Iter: 645 loss: 1.04314722e-06
Iter: 646 loss: 1.04286801e-06
Iter: 647 loss: 1.04232322e-06
Iter: 648 loss: 1.05487561e-06
Iter: 649 loss: 1.04232799e-06
Iter: 650 loss: 1.041725e-06
Iter: 651 loss: 1.04173523e-06
Iter: 652 loss: 1.04138348e-06
Iter: 653 loss: 1.04067203e-06
Iter: 654 loss: 1.05259687e-06
Iter: 655 loss: 1.04062985e-06
Iter: 656 loss: 1.0401568e-06
Iter: 657 loss: 1.04014009e-06
Iter: 658 loss: 1.03984326e-06
Iter: 659 loss: 1.04060405e-06
Iter: 660 loss: 1.03971422e-06
Iter: 661 loss: 1.03932325e-06
Iter: 662 loss: 1.03895366e-06
Iter: 663 loss: 1.03886794e-06
Iter: 664 loss: 1.03830803e-06
Iter: 665 loss: 1.03878e-06
Iter: 666 loss: 1.03795355e-06
Iter: 667 loss: 1.03763296e-06
Iter: 668 loss: 1.03754951e-06
Iter: 669 loss: 1.0372e-06
Iter: 670 loss: 1.0363708e-06
Iter: 671 loss: 1.04819628e-06
Iter: 672 loss: 1.03634352e-06
Iter: 673 loss: 1.03554225e-06
Iter: 674 loss: 1.03795674e-06
Iter: 675 loss: 1.0352735e-06
Iter: 676 loss: 1.03509115e-06
Iter: 677 loss: 1.03489742e-06
Iter: 678 loss: 1.03462662e-06
Iter: 679 loss: 1.03410491e-06
Iter: 680 loss: 1.04543778e-06
Iter: 681 loss: 1.03408388e-06
Iter: 682 loss: 1.03381285e-06
Iter: 683 loss: 1.03377738e-06
Iter: 684 loss: 1.03348577e-06
Iter: 685 loss: 1.03301318e-06
Iter: 686 loss: 1.03300533e-06
Iter: 687 loss: 1.03253615e-06
Iter: 688 loss: 1.03347065e-06
Iter: 689 loss: 1.0323505e-06
Iter: 690 loss: 1.0318e-06
Iter: 691 loss: 1.03613729e-06
Iter: 692 loss: 1.03176228e-06
Iter: 693 loss: 1.03139769e-06
Iter: 694 loss: 1.03194225e-06
Iter: 695 loss: 1.03120817e-06
Iter: 696 loss: 1.03077559e-06
Iter: 697 loss: 1.03018613e-06
Iter: 698 loss: 1.0301344e-06
Iter: 699 loss: 1.02965726e-06
Iter: 700 loss: 1.02966737e-06
Iter: 701 loss: 1.0291825e-06
Iter: 702 loss: 1.03064383e-06
Iter: 703 loss: 1.02902595e-06
Iter: 704 loss: 1.02861634e-06
Iter: 705 loss: 1.0276292e-06
Iter: 706 loss: 1.03657726e-06
Iter: 707 loss: 1.02746037e-06
Iter: 708 loss: 1.02728745e-06
Iter: 709 loss: 1.02698914e-06
Iter: 710 loss: 1.02653007e-06
Iter: 711 loss: 1.02713557e-06
Iter: 712 loss: 1.02626746e-06
Iter: 713 loss: 1.02590741e-06
Iter: 714 loss: 1.02644606e-06
Iter: 715 loss: 1.02573313e-06
Iter: 716 loss: 1.02519743e-06
Iter: 717 loss: 1.02791319e-06
Iter: 718 loss: 1.02511319e-06
Iter: 719 loss: 1.02485637e-06
Iter: 720 loss: 1.02447802e-06
Iter: 721 loss: 1.0244521e-06
Iter: 722 loss: 1.02400725e-06
Iter: 723 loss: 1.0292797e-06
Iter: 724 loss: 1.02399008e-06
Iter: 725 loss: 1.02365061e-06
Iter: 726 loss: 1.02313345e-06
Iter: 727 loss: 1.02311606e-06
Iter: 728 loss: 1.02241074e-06
Iter: 729 loss: 1.02622823e-06
Iter: 730 loss: 1.02228046e-06
Iter: 731 loss: 1.0218597e-06
Iter: 732 loss: 1.02199374e-06
Iter: 733 loss: 1.02153967e-06
Iter: 734 loss: 1.0212982e-06
Iter: 735 loss: 1.02124034e-06
Iter: 736 loss: 1.02098375e-06
Iter: 737 loss: 1.02034357e-06
Iter: 738 loss: 1.02720173e-06
Iter: 739 loss: 1.02031072e-06
Iter: 740 loss: 1.01967646e-06
Iter: 741 loss: 1.02119168e-06
Iter: 742 loss: 1.01944715e-06
Iter: 743 loss: 1.01895762e-06
Iter: 744 loss: 1.01896899e-06
Iter: 745 loss: 1.01863134e-06
Iter: 746 loss: 1.01804699e-06
Iter: 747 loss: 1.02904301e-06
Iter: 748 loss: 1.01803334e-06
Iter: 749 loss: 1.01751516e-06
Iter: 750 loss: 1.01748174e-06
Iter: 751 loss: 1.01717455e-06
Iter: 752 loss: 1.0166525e-06
Iter: 753 loss: 1.01664818e-06
Iter: 754 loss: 1.01620481e-06
Iter: 755 loss: 1.01896819e-06
Iter: 756 loss: 1.01613216e-06
Iter: 757 loss: 1.01566093e-06
Iter: 758 loss: 1.01722276e-06
Iter: 759 loss: 1.01552848e-06
Iter: 760 loss: 1.01520936e-06
Iter: 761 loss: 1.01481055e-06
Iter: 762 loss: 1.01475746e-06
Iter: 763 loss: 1.01401179e-06
Iter: 764 loss: 1.017469e-06
Iter: 765 loss: 1.01389048e-06
Iter: 766 loss: 1.01343846e-06
Iter: 767 loss: 1.01448654e-06
Iter: 768 loss: 1.0132419e-06
Iter: 769 loss: 1.01272394e-06
Iter: 770 loss: 1.01871774e-06
Iter: 771 loss: 1.01271826e-06
Iter: 772 loss: 1.01239755e-06
Iter: 773 loss: 1.01176784e-06
Iter: 774 loss: 1.02315596e-06
Iter: 775 loss: 1.01175829e-06
Iter: 776 loss: 1.01129308e-06
Iter: 777 loss: 1.01130126e-06
Iter: 778 loss: 1.01079797e-06
Iter: 779 loss: 1.01247e-06
Iter: 780 loss: 1.01066917e-06
Iter: 781 loss: 1.01039541e-06
Iter: 782 loss: 1.01106468e-06
Iter: 783 loss: 1.01031355e-06
Iter: 784 loss: 1.00982652e-06
Iter: 785 loss: 1.00939974e-06
Iter: 786 loss: 1.00930049e-06
Iter: 787 loss: 1.00884415e-06
Iter: 788 loss: 1.01070111e-06
Iter: 789 loss: 1.00872455e-06
Iter: 790 loss: 1.00833927e-06
Iter: 791 loss: 1.01226965e-06
Iter: 792 loss: 1.00832017e-06
Iter: 793 loss: 1.00799707e-06
Iter: 794 loss: 1.00734155e-06
Iter: 795 loss: 1.0204144e-06
Iter: 796 loss: 1.00733098e-06
Iter: 797 loss: 1.00675845e-06
Iter: 798 loss: 1.01287253e-06
Iter: 799 loss: 1.00673265e-06
Iter: 800 loss: 1.00623663e-06
Iter: 801 loss: 1.00633281e-06
Iter: 802 loss: 1.00587704e-06
Iter: 803 loss: 1.00547913e-06
Iter: 804 loss: 1.00547322e-06
Iter: 805 loss: 1.00508089e-06
Iter: 806 loss: 1.00453747e-06
Iter: 807 loss: 1.00449984e-06
Iter: 808 loss: 1.00400757e-06
Iter: 809 loss: 1.00394823e-06
Iter: 810 loss: 1.00361603e-06
Iter: 811 loss: 1.00341242e-06
Iter: 812 loss: 1.00330112e-06
Iter: 813 loss: 1.00295017e-06
Iter: 814 loss: 1.00245654e-06
Iter: 815 loss: 1.00244552e-06
Iter: 816 loss: 1.00203704e-06
Iter: 817 loss: 1.00734133e-06
Iter: 818 loss: 1.00203624e-06
Iter: 819 loss: 1.00160855e-06
Iter: 820 loss: 1.00141483e-06
Iter: 821 loss: 1.00120303e-06
Iter: 822 loss: 1.00079183e-06
Iter: 823 loss: 1.00018065e-06
Iter: 824 loss: 1.00017428e-06
Iter: 825 loss: 9.99430085e-07
Iter: 826 loss: 1.00231682e-06
Iter: 827 loss: 9.99265239e-07
Iter: 828 loss: 9.98735914e-07
Iter: 829 loss: 1.00419641e-06
Iter: 830 loss: 9.98738187e-07
Iter: 831 loss: 9.98152245e-07
Iter: 832 loss: 9.99014901e-07
Iter: 833 loss: 9.97860639e-07
Iter: 834 loss: 9.97401116e-07
Iter: 835 loss: 9.98807536e-07
Iter: 836 loss: 9.97264124e-07
Iter: 837 loss: 9.9687054e-07
Iter: 838 loss: 9.98623705e-07
Iter: 839 loss: 9.96803351e-07
Iter: 840 loss: 9.96411e-07
Iter: 841 loss: 9.97897132e-07
Iter: 842 loss: 9.96313247e-07
Iter: 843 loss: 9.95980372e-07
Iter: 844 loss: 9.95448545e-07
Iter: 845 loss: 9.95460368e-07
Iter: 846 loss: 9.94921493e-07
Iter: 847 loss: 9.98052656e-07
Iter: 848 loss: 9.94872153e-07
Iter: 849 loss: 9.94332368e-07
Iter: 850 loss: 9.98162818e-07
Iter: 851 loss: 9.94280299e-07
Iter: 852 loss: 9.94039738e-07
Iter: 853 loss: 9.93856133e-07
Iter: 854 loss: 9.93767344e-07
Iter: 855 loss: 9.93228e-07
Iter: 856 loss: 9.95517e-07
Iter: 857 loss: 9.93112e-07
Iter: 858 loss: 9.92827609e-07
Iter: 859 loss: 9.92150603e-07
Iter: 860 loss: 1.00314423e-06
Iter: 861 loss: 9.92134574e-07
Iter: 862 loss: 9.9153317e-07
Iter: 863 loss: 9.92394e-07
Iter: 864 loss: 9.91233e-07
Iter: 865 loss: 9.9064448e-07
Iter: 866 loss: 9.97690449e-07
Iter: 867 loss: 9.90638682e-07
Iter: 868 loss: 9.90319677e-07
Iter: 869 loss: 9.90305807e-07
Iter: 870 loss: 9.90111e-07
Iter: 871 loss: 9.89587306e-07
Iter: 872 loss: 9.93056801e-07
Iter: 873 loss: 9.89486466e-07
Iter: 874 loss: 9.89222e-07
Iter: 875 loss: 9.89126647e-07
Iter: 876 loss: 9.88810143e-07
Iter: 877 loss: 9.88978854e-07
Iter: 878 loss: 9.88609e-07
Iter: 879 loss: 9.88286274e-07
Iter: 880 loss: 9.88593115e-07
Iter: 881 loss: 9.88092438e-07
Iter: 882 loss: 9.87641442e-07
Iter: 883 loss: 9.8742612e-07
Iter: 884 loss: 9.87190788e-07
Iter: 885 loss: 9.87059479e-07
Iter: 886 loss: 9.86931582e-07
Iter: 887 loss: 9.86675e-07
Iter: 888 loss: 9.86067562e-07
Iter: 889 loss: 9.91721208e-07
Iter: 890 loss: 9.8599719e-07
Iter: 891 loss: 9.85501401e-07
Iter: 892 loss: 9.91344109e-07
Iter: 893 loss: 9.85489123e-07
Iter: 894 loss: 9.8496912e-07
Iter: 895 loss: 9.86566874e-07
Iter: 896 loss: 9.84822691e-07
Iter: 897 loss: 9.84517669e-07
Iter: 898 loss: 9.83848395e-07
Iter: 899 loss: 9.95204118e-07
Iter: 900 loss: 9.83830432e-07
Iter: 901 loss: 9.83205837e-07
Iter: 902 loss: 9.86319719e-07
Iter: 903 loss: 9.83098062e-07
Iter: 904 loss: 9.82888423e-07
Iter: 905 loss: 9.82774282e-07
Iter: 906 loss: 9.82522806e-07
Iter: 907 loss: 9.82060556e-07
Iter: 908 loss: 9.93174694e-07
Iter: 909 loss: 9.82057372e-07
Iter: 910 loss: 9.8160956e-07
Iter: 911 loss: 9.81877065e-07
Iter: 912 loss: 9.81339554e-07
Iter: 913 loss: 9.80869686e-07
Iter: 914 loss: 9.80852178e-07
Iter: 915 loss: 9.80559207e-07
Iter: 916 loss: 9.8013129e-07
Iter: 917 loss: 9.80130153e-07
Iter: 918 loss: 9.79634251e-07
Iter: 919 loss: 9.82364782e-07
Iter: 920 loss: 9.79590141e-07
Iter: 921 loss: 9.79244078e-07
Iter: 922 loss: 9.79581387e-07
Iter: 923 loss: 9.78974867e-07
Iter: 924 loss: 9.78641e-07
Iter: 925 loss: 9.78649496e-07
Iter: 926 loss: 9.78413254e-07
Iter: 927 loss: 9.77857098e-07
Iter: 928 loss: 9.85442284e-07
Iter: 929 loss: 9.77826062e-07
Iter: 930 loss: 9.77472723e-07
Iter: 931 loss: 9.77440322e-07
Iter: 932 loss: 9.7720465e-07
Iter: 933 loss: 9.76599495e-07
Iter: 934 loss: 9.81734161e-07
Iter: 935 loss: 9.76505135e-07
Iter: 936 loss: 9.76015599e-07
Iter: 937 loss: 9.76005936e-07
Iter: 938 loss: 9.75651346e-07
Iter: 939 loss: 9.75238891e-07
Iter: 940 loss: 9.75178182e-07
Iter: 941 loss: 9.74751742e-07
Iter: 942 loss: 9.74924205e-07
Iter: 943 loss: 9.74420232e-07
Iter: 944 loss: 9.7389875e-07
Iter: 945 loss: 9.78403932e-07
Iter: 946 loss: 9.73870556e-07
Iter: 947 loss: 9.7329e-07
Iter: 948 loss: 9.75066314e-07
Iter: 949 loss: 9.73110673e-07
Iter: 950 loss: 9.72800308e-07
Iter: 951 loss: 9.72326e-07
Iter: 952 loss: 9.72334874e-07
Iter: 953 loss: 9.71748818e-07
Iter: 954 loss: 9.75391913e-07
Iter: 955 loss: 9.71675604e-07
Iter: 956 loss: 9.7115867e-07
Iter: 957 loss: 9.7329621e-07
Iter: 958 loss: 9.71035547e-07
Iter: 959 loss: 9.7061934e-07
Iter: 960 loss: 9.76109618e-07
Iter: 961 loss: 9.70623091e-07
Iter: 962 loss: 9.70362407e-07
Iter: 963 loss: 9.70033852e-07
Iter: 964 loss: 9.70025e-07
Iter: 965 loss: 9.69522489e-07
Iter: 966 loss: 9.74429895e-07
Iter: 967 loss: 9.69503617e-07
Iter: 968 loss: 9.69214e-07
Iter: 969 loss: 9.68548648e-07
Iter: 970 loss: 9.77409854e-07
Iter: 971 loss: 9.68500558e-07
Iter: 972 loss: 9.68304e-07
Iter: 973 loss: 9.68131189e-07
Iter: 974 loss: 9.67823325e-07
Iter: 975 loss: 9.67222149e-07
Iter: 976 loss: 9.80225195e-07
Iter: 977 loss: 9.67212486e-07
Iter: 978 loss: 9.66715334e-07
Iter: 979 loss: 9.67118126e-07
Iter: 980 loss: 9.66372909e-07
Iter: 981 loss: 9.65749337e-07
Iter: 982 loss: 9.67846063e-07
Iter: 983 loss: 9.65562322e-07
Iter: 984 loss: 9.65171e-07
Iter: 985 loss: 9.65089384e-07
Iter: 986 loss: 9.64849505e-07
Iter: 987 loss: 9.64278797e-07
Iter: 988 loss: 9.72007228e-07
Iter: 989 loss: 9.64254e-07
Iter: 990 loss: 9.63764478e-07
Iter: 991 loss: 9.66584594e-07
Iter: 992 loss: 9.63688e-07
Iter: 993 loss: 9.63268803e-07
Iter: 994 loss: 9.65343133e-07
Iter: 995 loss: 9.63207071e-07
Iter: 996 loss: 9.62908757e-07
Iter: 997 loss: 9.65276172e-07
Iter: 998 loss: 9.62903641e-07
Iter: 999 loss: 9.62625222e-07
Iter: 1000 loss: 9.62159902e-07
Iter: 1001 loss: 9.62141712e-07
Iter: 1002 loss: 9.61764158e-07
Iter: 1003 loss: 9.61738806e-07
Iter: 1004 loss: 9.61525075e-07
Iter: 1005 loss: 9.60985858e-07
Iter: 1006 loss: 9.65198637e-07
Iter: 1007 loss: 9.60859e-07
Iter: 1008 loss: 9.60598868e-07
Iter: 1009 loss: 9.60535e-07
Iter: 1010 loss: 9.60197e-07
Iter: 1011 loss: 9.60031798e-07
Iter: 1012 loss: 9.59872068e-07
Iter: 1013 loss: 9.59517e-07
Iter: 1014 loss: 9.59077852e-07
Iter: 1015 loss: 9.59022e-07
Iter: 1016 loss: 9.58733153e-07
Iter: 1017 loss: 9.58688815e-07
Iter: 1018 loss: 9.58312398e-07
Iter: 1019 loss: 9.58205192e-07
Iter: 1020 loss: 9.58009082e-07
Iter: 1021 loss: 9.57528528e-07
Iter: 1022 loss: 9.57571388e-07
Iter: 1023 loss: 9.57168481e-07
Iter: 1024 loss: 9.56770577e-07
Iter: 1025 loss: 9.62668537e-07
Iter: 1026 loss: 9.56759322e-07
Iter: 1027 loss: 9.56456688e-07
Iter: 1028 loss: 9.5668338e-07
Iter: 1029 loss: 9.56249778e-07
Iter: 1030 loss: 9.55934638e-07
Iter: 1031 loss: 9.59029649e-07
Iter: 1032 loss: 9.55902806e-07
Iter: 1033 loss: 9.55689075e-07
Iter: 1034 loss: 9.55467499e-07
Iter: 1035 loss: 9.55422138e-07
Iter: 1036 loss: 9.54963e-07
Iter: 1037 loss: 9.58448823e-07
Iter: 1038 loss: 9.5490168e-07
Iter: 1039 loss: 9.54663392e-07
Iter: 1040 loss: 9.54040161e-07
Iter: 1041 loss: 9.59452109e-07
Iter: 1042 loss: 9.53938411e-07
Iter: 1043 loss: 9.5364561e-07
Iter: 1044 loss: 9.53500717e-07
Iter: 1045 loss: 9.53228891e-07
Iter: 1046 loss: 9.5277295e-07
Iter: 1047 loss: 9.52772893e-07
Iter: 1048 loss: 9.52310756e-07
Iter: 1049 loss: 9.53572794e-07
Iter: 1050 loss: 9.52181381e-07
Iter: 1051 loss: 9.52093217e-07
Iter: 1052 loss: 9.5193235e-07
Iter: 1053 loss: 9.51770858e-07
Iter: 1054 loss: 9.51347261e-07
Iter: 1055 loss: 9.55399855e-07
Iter: 1056 loss: 9.51284619e-07
Iter: 1057 loss: 9.50848289e-07
Iter: 1058 loss: 9.53597066e-07
Iter: 1059 loss: 9.50795425e-07
Iter: 1060 loss: 9.5033721e-07
Iter: 1061 loss: 9.52861228e-07
Iter: 1062 loss: 9.50263825e-07
Iter: 1063 loss: 9.49889852e-07
Iter: 1064 loss: 9.50567e-07
Iter: 1065 loss: 9.49725916e-07
Iter: 1066 loss: 9.49286061e-07
Iter: 1067 loss: 9.50213632e-07
Iter: 1068 loss: 9.49119965e-07
Iter: 1069 loss: 9.48871218e-07
Iter: 1070 loss: 9.52153073e-07
Iter: 1071 loss: 9.48879403e-07
Iter: 1072 loss: 9.48660102e-07
Iter: 1073 loss: 9.48279762e-07
Iter: 1074 loss: 9.48283e-07
Iter: 1075 loss: 9.47984176e-07
Iter: 1076 loss: 9.49719947e-07
Iter: 1077 loss: 9.47922786e-07
Iter: 1078 loss: 9.47499302e-07
Iter: 1079 loss: 9.47882484e-07
Iter: 1080 loss: 9.47247372e-07
Iter: 1081 loss: 9.46913588e-07
Iter: 1082 loss: 9.4626995e-07
Iter: 1083 loss: 9.46268131e-07
Iter: 1084 loss: 9.45698503e-07
Iter: 1085 loss: 9.51193215e-07
Iter: 1086 loss: 9.45670422e-07
Iter: 1087 loss: 9.45392969e-07
Iter: 1088 loss: 9.45358579e-07
Iter: 1089 loss: 9.4519379e-07
Iter: 1090 loss: 9.44809358e-07
Iter: 1091 loss: 9.49104e-07
Iter: 1092 loss: 9.44743192e-07
Iter: 1093 loss: 9.44424755e-07
Iter: 1094 loss: 9.44430667e-07
Iter: 1095 loss: 9.44138833e-07
Iter: 1096 loss: 9.44787303e-07
Iter: 1097 loss: 9.44015824e-07
Iter: 1098 loss: 9.43706141e-07
Iter: 1099 loss: 9.4441782e-07
Iter: 1100 loss: 9.43590635e-07
Iter: 1101 loss: 9.43279247e-07
Iter: 1102 loss: 9.43272426e-07
Iter: 1103 loss: 9.43011514e-07
Iter: 1104 loss: 9.4252681e-07
Iter: 1105 loss: 9.46497835e-07
Iter: 1106 loss: 9.42497422e-07
Iter: 1107 loss: 9.42248789e-07
Iter: 1108 loss: 9.41977305e-07
Iter: 1109 loss: 9.41939675e-07
Iter: 1110 loss: 9.41727194e-07
Iter: 1111 loss: 9.416936e-07
Iter: 1112 loss: 9.41508574e-07
Iter: 1113 loss: 9.41054054e-07
Iter: 1114 loss: 9.46511e-07
Iter: 1115 loss: 9.40998575e-07
Iter: 1116 loss: 9.40538939e-07
Iter: 1117 loss: 9.40953271e-07
Iter: 1118 loss: 9.40234088e-07
Iter: 1119 loss: 9.39820609e-07
Iter: 1120 loss: 9.44582041e-07
Iter: 1121 loss: 9.3979537e-07
Iter: 1122 loss: 9.39328743e-07
Iter: 1123 loss: 9.4178796e-07
Iter: 1124 loss: 9.39243876e-07
Iter: 1125 loss: 9.3902122e-07
Iter: 1126 loss: 9.3863e-07
Iter: 1127 loss: 9.38631047e-07
Iter: 1128 loss: 9.38328185e-07
Iter: 1129 loss: 9.38284757e-07
Iter: 1130 loss: 9.38010658e-07
Iter: 1131 loss: 9.37721552e-07
Iter: 1132 loss: 9.37703248e-07
Iter: 1133 loss: 9.37204447e-07
Iter: 1134 loss: 9.39860911e-07
Iter: 1135 loss: 9.37147661e-07
Iter: 1136 loss: 9.36784772e-07
Iter: 1137 loss: 9.38113089e-07
Iter: 1138 loss: 9.36682284e-07
Iter: 1139 loss: 9.36303934e-07
Iter: 1140 loss: 9.36470769e-07
Iter: 1141 loss: 9.36093215e-07
Iter: 1142 loss: 9.35745391e-07
Iter: 1143 loss: 9.36098388e-07
Iter: 1144 loss: 9.35597541e-07
Iter: 1145 loss: 9.35181049e-07
Iter: 1146 loss: 9.39415145e-07
Iter: 1147 loss: 9.35165758e-07
Iter: 1148 loss: 9.34953277e-07
Iter: 1149 loss: 9.34476589e-07
Iter: 1150 loss: 9.3981339e-07
Iter: 1151 loss: 9.34425884e-07
Iter: 1152 loss: 9.33813226e-07
Iter: 1153 loss: 9.34271043e-07
Iter: 1154 loss: 9.3343823e-07
Iter: 1155 loss: 9.32736555e-07
Iter: 1156 loss: 9.36002607e-07
Iter: 1157 loss: 9.32582054e-07
Iter: 1158 loss: 9.3242511e-07
Iter: 1159 loss: 9.32335183e-07
Iter: 1160 loss: 9.32046078e-07
Iter: 1161 loss: 9.31968e-07
Iter: 1162 loss: 9.31771751e-07
Iter: 1163 loss: 9.31531588e-07
Iter: 1164 loss: 9.31148634e-07
Iter: 1165 loss: 9.31149486e-07
Iter: 1166 loss: 9.30938654e-07
Iter: 1167 loss: 9.30840201e-07
Iter: 1168 loss: 9.30629255e-07
Iter: 1169 loss: 9.30330884e-07
Iter: 1170 loss: 9.30323608e-07
Iter: 1171 loss: 9.29987095e-07
Iter: 1172 loss: 9.34345849e-07
Iter: 1173 loss: 9.29974135e-07
Iter: 1174 loss: 9.29723285e-07
Iter: 1175 loss: 9.29505177e-07
Iter: 1176 loss: 9.29456291e-07
Iter: 1177 loss: 9.29035537e-07
Iter: 1178 loss: 9.29795306e-07
Iter: 1179 loss: 9.2883414e-07
Iter: 1180 loss: 9.28539066e-07
Iter: 1181 loss: 9.31482134e-07
Iter: 1182 loss: 9.28533041e-07
Iter: 1183 loss: 9.28246777e-07
Iter: 1184 loss: 9.28313e-07
Iter: 1185 loss: 9.28012469e-07
Iter: 1186 loss: 9.27664701e-07
Iter: 1187 loss: 9.27292376e-07
Iter: 1188 loss: 9.2724332e-07
Iter: 1189 loss: 9.26678e-07
Iter: 1190 loss: 9.26586608e-07
Iter: 1191 loss: 9.26188591e-07
Iter: 1192 loss: 9.25775112e-07
Iter: 1193 loss: 9.2571878e-07
Iter: 1194 loss: 9.25348331e-07
Iter: 1195 loss: 9.28735801e-07
Iter: 1196 loss: 9.25356687e-07
Iter: 1197 loss: 9.2514972e-07
Iter: 1198 loss: 9.24721917e-07
Iter: 1199 loss: 9.29568785e-07
Iter: 1200 loss: 9.24665528e-07
Iter: 1201 loss: 9.24449637e-07
Iter: 1202 loss: 9.24391202e-07
Iter: 1203 loss: 9.24113237e-07
Iter: 1204 loss: 9.23938046e-07
Iter: 1205 loss: 9.23817311e-07
Iter: 1206 loss: 9.23515529e-07
Iter: 1207 loss: 9.2489347e-07
Iter: 1208 loss: 9.23447374e-07
Iter: 1209 loss: 9.23079824e-07
Iter: 1210 loss: 9.23360403e-07
Iter: 1211 loss: 9.22843753e-07
Iter: 1212 loss: 9.22535833e-07
Iter: 1213 loss: 9.23118819e-07
Iter: 1214 loss: 9.2239145e-07
Iter: 1215 loss: 9.21990477e-07
Iter: 1216 loss: 9.23441121e-07
Iter: 1217 loss: 9.21894639e-07
Iter: 1218 loss: 9.21577225e-07
Iter: 1219 loss: 9.23978575e-07
Iter: 1220 loss: 9.21549201e-07
Iter: 1221 loss: 9.21353262e-07
Iter: 1222 loss: 9.20912612e-07
Iter: 1223 loss: 9.27711199e-07
Iter: 1224 loss: 9.20891921e-07
Iter: 1225 loss: 9.20480943e-07
Iter: 1226 loss: 9.21843935e-07
Iter: 1227 loss: 9.20364641e-07
Iter: 1228 loss: 9.20064167e-07
Iter: 1229 loss: 9.20074285e-07
Iter: 1230 loss: 9.19720378e-07
Iter: 1231 loss: 9.19675131e-07
Iter: 1232 loss: 9.19435e-07
Iter: 1233 loss: 9.19102831e-07
Iter: 1234 loss: 9.18882506e-07
Iter: 1235 loss: 9.18738863e-07
Iter: 1236 loss: 9.18749095e-07
Iter: 1237 loss: 9.18521323e-07
Iter: 1238 loss: 9.18368301e-07
Iter: 1239 loss: 9.1799069e-07
Iter: 1240 loss: 9.23194136e-07
Iter: 1241 loss: 9.17932596e-07
Iter: 1242 loss: 9.17767807e-07
Iter: 1243 loss: 9.1772722e-07
Iter: 1244 loss: 9.17553621e-07
Iter: 1245 loss: 9.17156626e-07
Iter: 1246 loss: 9.23673838e-07
Iter: 1247 loss: 9.17173e-07
Iter: 1248 loss: 9.16778504e-07
Iter: 1249 loss: 9.19182185e-07
Iter: 1250 loss: 9.16743204e-07
Iter: 1251 loss: 9.16342856e-07
Iter: 1252 loss: 9.1861591e-07
Iter: 1253 loss: 9.16298688e-07
Iter: 1254 loss: 9.15938585e-07
Iter: 1255 loss: 9.15889359e-07
Iter: 1256 loss: 9.15637088e-07
Iter: 1257 loss: 9.15239298e-07
Iter: 1258 loss: 9.15127828e-07
Iter: 1259 loss: 9.14904035e-07
Iter: 1260 loss: 9.14502e-07
Iter: 1261 loss: 9.1758136e-07
Iter: 1262 loss: 9.14466341e-07
Iter: 1263 loss: 9.14160296e-07
Iter: 1264 loss: 9.14142163e-07
Iter: 1265 loss: 9.13987265e-07
Iter: 1266 loss: 9.13517908e-07
Iter: 1267 loss: 9.17868249e-07
Iter: 1268 loss: 9.13468511e-07
Iter: 1269 loss: 9.13062422e-07
Iter: 1270 loss: 9.1736058e-07
Iter: 1271 loss: 9.13030703e-07
Iter: 1272 loss: 9.12558107e-07
Iter: 1273 loss: 9.14931547e-07
Iter: 1274 loss: 9.12473e-07
Iter: 1275 loss: 9.12217502e-07
Iter: 1276 loss: 9.11976372e-07
Iter: 1277 loss: 9.11933e-07
Iter: 1278 loss: 9.11555162e-07
Iter: 1279 loss: 9.17283046e-07
Iter: 1280 loss: 9.11535267e-07
Iter: 1281 loss: 9.11379857e-07
Iter: 1282 loss: 9.11017707e-07
Iter: 1283 loss: 9.16538113e-07
Iter: 1284 loss: 9.11017594e-07
Iter: 1285 loss: 9.10706376e-07
Iter: 1286 loss: 9.10707286e-07
Iter: 1287 loss: 9.10466952e-07
Iter: 1288 loss: 9.10305232e-07
Iter: 1289 loss: 9.10226618e-07
Iter: 1290 loss: 9.09826099e-07
Iter: 1291 loss: 9.10548522e-07
Iter: 1292 loss: 9.09655796e-07
Iter: 1293 loss: 9.09264486e-07
Iter: 1294 loss: 9.09098844e-07
Iter: 1295 loss: 9.08921493e-07
Iter: 1296 loss: 9.08838274e-07
Iter: 1297 loss: 9.0870094e-07
Iter: 1298 loss: 9.08511424e-07
Iter: 1299 loss: 9.08227264e-07
Iter: 1300 loss: 9.08227889e-07
Iter: 1301 loss: 9.07891376e-07
Iter: 1302 loss: 9.07556455e-07
Iter: 1303 loss: 9.07484946e-07
Iter: 1304 loss: 9.07090396e-07
Iter: 1305 loss: 9.10589733e-07
Iter: 1306 loss: 9.07075048e-07
Iter: 1307 loss: 9.06660375e-07
Iter: 1308 loss: 9.09749247e-07
Iter: 1309 loss: 9.06618823e-07
Iter: 1310 loss: 9.06428909e-07
Iter: 1311 loss: 9.0608853e-07
Iter: 1312 loss: 9.06080402e-07
Iter: 1313 loss: 9.05773845e-07
Iter: 1314 loss: 9.05764068e-07
Iter: 1315 loss: 9.05626791e-07
Iter: 1316 loss: 9.05272714e-07
Iter: 1317 loss: 9.0918752e-07
Iter: 1318 loss: 9.05246964e-07
Iter: 1319 loss: 9.04992874e-07
Iter: 1320 loss: 9.04978265e-07
Iter: 1321 loss: 9.04801652e-07
Iter: 1322 loss: 9.04573199e-07
Iter: 1323 loss: 9.04541253e-07
Iter: 1324 loss: 9.04223555e-07
Iter: 1325 loss: 9.0489641e-07
Iter: 1326 loss: 9.04084288e-07
Iter: 1327 loss: 9.03701221e-07
Iter: 1328 loss: 9.03598675e-07
Iter: 1329 loss: 9.03371415e-07
Iter: 1330 loss: 9.03132332e-07
Iter: 1331 loss: 9.03137334e-07
Iter: 1332 loss: 9.02843169e-07
Iter: 1333 loss: 9.03123e-07
Iter: 1334 loss: 9.02710099e-07
Iter: 1335 loss: 9.02465558e-07
Iter: 1336 loss: 9.02259785e-07
Iter: 1337 loss: 9.02205159e-07
Iter: 1338 loss: 9.01946919e-07
Iter: 1339 loss: 9.05597631e-07
Iter: 1340 loss: 9.01930548e-07
Iter: 1341 loss: 9.01595911e-07
Iter: 1342 loss: 9.01736144e-07
Iter: 1343 loss: 9.01375074e-07
Iter: 1344 loss: 9.01087e-07
Iter: 1345 loss: 9.00704094e-07
Iter: 1346 loss: 9.00689e-07
Iter: 1347 loss: 9.00488203e-07
Iter: 1348 loss: 9.00454154e-07
Iter: 1349 loss: 9.00195687e-07
Iter: 1350 loss: 9.00065857e-07
Iter: 1351 loss: 8.9994893e-07
Iter: 1352 loss: 8.99736108e-07
Iter: 1353 loss: 8.99572115e-07
Iter: 1354 loss: 8.99491738e-07
Iter: 1355 loss: 8.99191036e-07
Iter: 1356 loss: 9.0322726e-07
Iter: 1357 loss: 8.99191036e-07
Iter: 1358 loss: 8.9891978e-07
Iter: 1359 loss: 8.99786357e-07
Iter: 1360 loss: 8.98847418e-07
Iter: 1361 loss: 8.98614701e-07
Iter: 1362 loss: 8.99159431e-07
Iter: 1363 loss: 8.98506073e-07
Iter: 1364 loss: 8.9829507e-07
Iter: 1365 loss: 8.98710368e-07
Iter: 1366 loss: 8.98196959e-07
Iter: 1367 loss: 8.97888697e-07
Iter: 1368 loss: 8.99336897e-07
Iter: 1369 loss: 8.97825e-07
Iter: 1370 loss: 8.97655184e-07
Iter: 1371 loss: 8.97287464e-07
Iter: 1372 loss: 9.04730712e-07
Iter: 1373 loss: 8.97292693e-07
Iter: 1374 loss: 8.96860115e-07
Iter: 1375 loss: 8.9776546e-07
Iter: 1376 loss: 8.96715903e-07
Iter: 1377 loss: 8.9629782e-07
Iter: 1378 loss: 9.00077225e-07
Iter: 1379 loss: 8.963e-07
Iter: 1380 loss: 8.95859e-07
Iter: 1381 loss: 8.97641257e-07
Iter: 1382 loss: 8.95759626e-07
Iter: 1383 loss: 8.95530604e-07
Iter: 1384 loss: 8.94989853e-07
Iter: 1385 loss: 9.03587306e-07
Iter: 1386 loss: 8.94997584e-07
Iter: 1387 loss: 8.94463597e-07
Iter: 1388 loss: 8.95612402e-07
Iter: 1389 loss: 8.94276923e-07
Iter: 1390 loss: 8.93793526e-07
Iter: 1391 loss: 8.96156962e-07
Iter: 1392 loss: 8.93703941e-07
Iter: 1393 loss: 8.93460253e-07
Iter: 1394 loss: 8.93435072e-07
Iter: 1395 loss: 8.93184279e-07
Iter: 1396 loss: 8.93060928e-07
Iter: 1397 loss: 8.92959406e-07
Iter: 1398 loss: 8.92620051e-07
Iter: 1399 loss: 8.9434e-07
Iter: 1400 loss: 8.92551554e-07
Iter: 1401 loss: 8.9230366e-07
Iter: 1402 loss: 8.93429501e-07
Iter: 1403 loss: 8.92261085e-07
Iter: 1404 loss: 8.92000912e-07
Iter: 1405 loss: 8.92183493e-07
Iter: 1406 loss: 8.91847378e-07
Iter: 1407 loss: 8.91606192e-07
Iter: 1408 loss: 8.91613e-07
Iter: 1409 loss: 8.91426112e-07
Iter: 1410 loss: 8.91140587e-07
Iter: 1411 loss: 8.91120521e-07
Iter: 1412 loss: 8.90976708e-07
Iter: 1413 loss: 8.90572551e-07
Iter: 1414 loss: 8.93400511e-07
Iter: 1415 loss: 8.90468641e-07
Iter: 1416 loss: 8.90367232e-07
Iter: 1417 loss: 8.90233764e-07
Iter: 1418 loss: 8.9003936e-07
Iter: 1419 loss: 8.89606895e-07
Iter: 1420 loss: 8.98211169e-07
Iter: 1421 loss: 8.89613716e-07
Iter: 1422 loss: 8.89217858e-07
Iter: 1423 loss: 8.89166586e-07
Iter: 1424 loss: 8.88917839e-07
Iter: 1425 loss: 8.88453e-07
Iter: 1426 loss: 8.90839146e-07
Iter: 1427 loss: 8.88396357e-07
Iter: 1428 loss: 8.8808838e-07
Iter: 1429 loss: 8.88080535e-07
Iter: 1430 loss: 8.87768465e-07
Iter: 1431 loss: 8.87658e-07
Iter: 1432 loss: 8.8746458e-07
Iter: 1433 loss: 8.87185e-07
Iter: 1434 loss: 8.88747195e-07
Iter: 1435 loss: 8.87166607e-07
Iter: 1436 loss: 8.86850557e-07
Iter: 1437 loss: 8.87174963e-07
Iter: 1438 loss: 8.86663429e-07
Iter: 1439 loss: 8.86364376e-07
Iter: 1440 loss: 8.87005399e-07
Iter: 1441 loss: 8.86256316e-07
Iter: 1442 loss: 8.85988527e-07
Iter: 1443 loss: 8.87438546e-07
Iter: 1444 loss: 8.85944246e-07
Iter: 1445 loss: 8.85672648e-07
Iter: 1446 loss: 8.86796101e-07
Iter: 1447 loss: 8.85622569e-07
Iter: 1448 loss: 8.85413e-07
Iter: 1449 loss: 8.84869849e-07
Iter: 1450 loss: 8.92394269e-07
Iter: 1451 loss: 8.84837618e-07
Iter: 1452 loss: 8.84908502e-07
Iter: 1453 loss: 8.84593533e-07
Iter: 1454 loss: 8.84426925e-07
Iter: 1455 loss: 8.83981e-07
Iter: 1456 loss: 8.86311568e-07
Iter: 1457 loss: 8.83802613e-07
Iter: 1458 loss: 8.83327971e-07
Iter: 1459 loss: 8.85520592e-07
Iter: 1460 loss: 8.83222697e-07
Iter: 1461 loss: 8.82853e-07
Iter: 1462 loss: 8.83028235e-07
Iter: 1463 loss: 8.8260947e-07
Iter: 1464 loss: 8.82312236e-07
Iter: 1465 loss: 8.82286884e-07
Iter: 1466 loss: 8.8194696e-07
Iter: 1467 loss: 8.82092536e-07
Iter: 1468 loss: 8.81706569e-07
Iter: 1469 loss: 8.8136062e-07
Iter: 1470 loss: 8.81045821e-07
Iter: 1471 loss: 8.80951347e-07
Iter: 1472 loss: 8.80785e-07
Iter: 1473 loss: 8.80715163e-07
Iter: 1474 loss: 8.80458856e-07
Iter: 1475 loss: 8.80472157e-07
Iter: 1476 loss: 8.80279458e-07
Iter: 1477 loss: 8.80036339e-07
Iter: 1478 loss: 8.80575499e-07
Iter: 1479 loss: 8.79944764e-07
Iter: 1480 loss: 8.79713753e-07
Iter: 1481 loss: 8.80342157e-07
Iter: 1482 loss: 8.79632e-07
Iter: 1483 loss: 8.7936553e-07
Iter: 1484 loss: 8.81645292e-07
Iter: 1485 loss: 8.79354275e-07
Iter: 1486 loss: 8.79149809e-07
Iter: 1487 loss: 8.78710409e-07
Iter: 1488 loss: 8.85356371e-07
Iter: 1489 loss: 8.78685171e-07
Iter: 1490 loss: 8.7867e-07
Iter: 1491 loss: 8.78516175e-07
Iter: 1492 loss: 8.78330866e-07
Iter: 1493 loss: 8.77956268e-07
Iter: 1494 loss: 8.83602524e-07
Iter: 1495 loss: 8.77961099e-07
Iter: 1496 loss: 8.77618788e-07
Iter: 1497 loss: 8.78724336e-07
Iter: 1498 loss: 8.77553362e-07
Iter: 1499 loss: 8.77331786e-07
Iter: 1500 loss: 8.77318939e-07
Iter: 1501 loss: 8.77166144e-07
Iter: 1502 loss: 8.76841113e-07
Iter: 1503 loss: 8.8140871e-07
Iter: 1504 loss: 8.76826562e-07
Iter: 1505 loss: 8.76465037e-07
Iter: 1506 loss: 8.78605704e-07
Iter: 1507 loss: 8.76420131e-07
Iter: 1508 loss: 8.76087825e-07
Iter: 1509 loss: 8.79253321e-07
Iter: 1510 loss: 8.76081231e-07
Iter: 1511 loss: 8.75873127e-07
Iter: 1512 loss: 8.7550643e-07
Iter: 1513 loss: 8.75508476e-07
Iter: 1514 loss: 8.75257115e-07
Iter: 1515 loss: 8.75261321e-07
Iter: 1516 loss: 8.75087096e-07
Iter: 1517 loss: 8.75719707e-07
Iter: 1518 loss: 8.7503156e-07
Iter: 1519 loss: 8.74765874e-07
Iter: 1520 loss: 8.74704085e-07
Iter: 1521 loss: 8.74567604e-07
Iter: 1522 loss: 8.74291231e-07
Iter: 1523 loss: 8.74626153e-07
Iter: 1524 loss: 8.74144632e-07
Iter: 1525 loss: 8.73828526e-07
Iter: 1526 loss: 8.7825947e-07
Iter: 1527 loss: 8.73837791e-07
Iter: 1528 loss: 8.73697786e-07
Iter: 1529 loss: 8.73297154e-07
Iter: 1530 loss: 8.7653774e-07
Iter: 1531 loss: 8.7322519e-07
Iter: 1532 loss: 8.72919713e-07
Iter: 1533 loss: 8.77498223e-07
Iter: 1534 loss: 8.72922101e-07
Iter: 1535 loss: 8.72675457e-07
Iter: 1536 loss: 8.75356136e-07
Iter: 1537 loss: 8.72674718e-07
Iter: 1538 loss: 8.72536646e-07
Iter: 1539 loss: 8.72224064e-07
Iter: 1540 loss: 8.74641728e-07
Iter: 1541 loss: 8.72129135e-07
Iter: 1542 loss: 8.71921372e-07
Iter: 1543 loss: 8.71887096e-07
Iter: 1544 loss: 8.71635791e-07
Iter: 1545 loss: 8.71607483e-07
Iter: 1546 loss: 8.71424959e-07
Iter: 1547 loss: 8.71168254e-07
Iter: 1548 loss: 8.71014436e-07
Iter: 1549 loss: 8.70923e-07
Iter: 1550 loss: 8.70649103e-07
Iter: 1551 loss: 8.70659221e-07
Iter: 1552 loss: 8.70423378e-07
Iter: 1553 loss: 8.70897e-07
Iter: 1554 loss: 8.70340671e-07
Iter: 1555 loss: 8.70113809e-07
Iter: 1556 loss: 8.70154736e-07
Iter: 1557 loss: 8.69939527e-07
Iter: 1558 loss: 8.69703626e-07
Iter: 1559 loss: 8.71473958e-07
Iter: 1560 loss: 8.69707264e-07
Iter: 1561 loss: 8.69433961e-07
Iter: 1562 loss: 8.6947739e-07
Iter: 1563 loss: 8.69201756e-07
Iter: 1564 loss: 8.68969096e-07
Iter: 1565 loss: 8.68472398e-07
Iter: 1566 loss: 8.80249388e-07
Iter: 1567 loss: 8.68465463e-07
Iter: 1568 loss: 8.68514292e-07
Iter: 1569 loss: 8.68268785e-07
Iter: 1570 loss: 8.68083248e-07
Iter: 1571 loss: 8.67914196e-07
Iter: 1572 loss: 8.67873041e-07
Iter: 1573 loss: 8.67609742e-07
Iter: 1574 loss: 8.67393624e-07
Iter: 1575 loss: 8.67329049e-07
Iter: 1576 loss: 8.67300287e-07
Iter: 1577 loss: 8.67135896e-07
Iter: 1578 loss: 8.67021186e-07
Iter: 1579 loss: 8.66727419e-07
Iter: 1580 loss: 8.69966527e-07
Iter: 1581 loss: 8.66696439e-07
Iter: 1582 loss: 8.66468611e-07
Iter: 1583 loss: 8.69728865e-07
Iter: 1584 loss: 8.6646844e-07
Iter: 1585 loss: 8.66237656e-07
Iter: 1586 loss: 8.66395681e-07
Iter: 1587 loss: 8.66098048e-07
Iter: 1588 loss: 8.65838956e-07
Iter: 1589 loss: 8.66957691e-07
Iter: 1590 loss: 8.65791094e-07
Iter: 1591 loss: 8.65587594e-07
Iter: 1592 loss: 8.6606417e-07
Iter: 1593 loss: 8.65544735e-07
Iter: 1594 loss: 8.65299626e-07
Iter: 1595 loss: 8.66872142e-07
Iter: 1596 loss: 8.65289167e-07
Iter: 1597 loss: 8.65118068e-07
Iter: 1598 loss: 8.64745402e-07
Iter: 1599 loss: 8.69467954e-07
Iter: 1600 loss: 8.64724711e-07
Iter: 1601 loss: 8.6444544e-07
Iter: 1602 loss: 8.6898649e-07
Iter: 1603 loss: 8.64439755e-07
Iter: 1604 loss: 8.64191122e-07
Iter: 1605 loss: 8.64961521e-07
Iter: 1606 loss: 8.64102446e-07
Iter: 1607 loss: 8.63930723e-07
Iter: 1608 loss: 8.63568062e-07
Iter: 1609 loss: 8.7117968e-07
Iter: 1610 loss: 8.63576474e-07
Iter: 1611 loss: 8.63310845e-07
Iter: 1612 loss: 8.63290609e-07
Iter: 1613 loss: 8.63053174e-07
Iter: 1614 loss: 8.62975298e-07
Iter: 1615 loss: 8.62807042e-07
Iter: 1616 loss: 8.62599336e-07
Iter: 1617 loss: 8.63930495e-07
Iter: 1618 loss: 8.62570914e-07
Iter: 1619 loss: 8.62363322e-07
Iter: 1620 loss: 8.62652428e-07
Iter: 1621 loss: 8.62275e-07
Iter: 1622 loss: 8.62008051e-07
Iter: 1623 loss: 8.62497473e-07
Iter: 1624 loss: 8.61908347e-07
Iter: 1625 loss: 8.61612932e-07
Iter: 1626 loss: 8.62088712e-07
Iter: 1627 loss: 8.61531134e-07
Iter: 1628 loss: 8.61320416e-07
Iter: 1629 loss: 8.61324224e-07
Iter: 1630 loss: 8.61143235e-07
Iter: 1631 loss: 8.60714749e-07
Iter: 1632 loss: 8.65797404e-07
Iter: 1633 loss: 8.60685532e-07
Iter: 1634 loss: 8.60381078e-07
Iter: 1635 loss: 8.63110472e-07
Iter: 1636 loss: 8.60357943e-07
Iter: 1637 loss: 8.60121418e-07
Iter: 1638 loss: 8.62303807e-07
Iter: 1639 loss: 8.60102e-07
Iter: 1640 loss: 8.59952252e-07
Iter: 1641 loss: 8.596204e-07
Iter: 1642 loss: 8.65708557e-07
Iter: 1643 loss: 8.59619e-07
Iter: 1644 loss: 8.59381657e-07
Iter: 1645 loss: 8.59399393e-07
Iter: 1646 loss: 8.59160309e-07
Iter: 1647 loss: 8.59434465e-07
Iter: 1648 loss: 8.5903514e-07
Iter: 1649 loss: 8.58850058e-07
Iter: 1650 loss: 8.5906936e-07
Iter: 1651 loss: 8.5875763e-07
Iter: 1652 loss: 8.58553904e-07
Iter: 1653 loss: 8.60328669e-07
Iter: 1654 loss: 8.58522185e-07
Iter: 1655 loss: 8.58340911e-07
Iter: 1656 loss: 8.583728e-07
Iter: 1657 loss: 8.58219551e-07
Iter: 1658 loss: 8.57966143e-07
Iter: 1659 loss: 8.58295493e-07
Iter: 1660 loss: 8.57851148e-07
Iter: 1661 loss: 8.57670614e-07
Iter: 1662 loss: 8.57680391e-07
Iter: 1663 loss: 8.5751077e-07
Iter: 1664 loss: 8.57367922e-07
Iter: 1665 loss: 8.57327507e-07
Iter: 1666 loss: 8.57092687e-07
Iter: 1667 loss: 8.57093369e-07
Iter: 1668 loss: 8.56942393e-07
Iter: 1669 loss: 8.56746396e-07
Iter: 1670 loss: 8.5672923e-07
Iter: 1671 loss: 8.56582631e-07
Iter: 1672 loss: 8.56385213e-07
Iter: 1673 loss: 8.56367592e-07
Iter: 1674 loss: 8.56161932e-07
Iter: 1675 loss: 8.57006739e-07
Iter: 1676 loss: 8.56102361e-07
Iter: 1677 loss: 8.55871576e-07
Iter: 1678 loss: 8.58000135e-07
Iter: 1679 loss: 8.55865e-07
Iter: 1680 loss: 8.55735095e-07
Iter: 1681 loss: 8.55613962e-07
Iter: 1682 loss: 8.55591338e-07
Iter: 1683 loss: 8.55406938e-07
Iter: 1684 loss: 8.57495706e-07
Iter: 1685 loss: 8.55419273e-07
Iter: 1686 loss: 8.55321218e-07
Iter: 1687 loss: 8.55232088e-07
Iter: 1688 loss: 8.55168878e-07
Iter: 1689 loss: 8.5494105e-07
Iter: 1690 loss: 8.55301664e-07
Iter: 1691 loss: 8.54834184e-07
Iter: 1692 loss: 8.54627388e-07
Iter: 1693 loss: 8.56547786e-07
Iter: 1694 loss: 8.54616e-07
Iter: 1695 loss: 8.54369659e-07
Iter: 1696 loss: 8.54761e-07
Iter: 1697 loss: 8.54290533e-07
Iter: 1698 loss: 8.5414257e-07
Iter: 1699 loss: 8.54013138e-07
Iter: 1700 loss: 8.53973e-07
Iter: 1701 loss: 8.53804409e-07
Iter: 1702 loss: 8.53812935e-07
Iter: 1703 loss: 8.53641268e-07
Iter: 1704 loss: 8.53477502e-07
Iter: 1705 loss: 8.53442771e-07
Iter: 1706 loss: 8.53246206e-07
Iter: 1707 loss: 8.53543497e-07
Iter: 1708 loss: 8.53135703e-07
Iter: 1709 loss: 8.52941128e-07
Iter: 1710 loss: 8.52943856e-07
Iter: 1711 loss: 8.52797029e-07
Iter: 1712 loss: 8.52553e-07
Iter: 1713 loss: 8.58262297e-07
Iter: 1714 loss: 8.52560504e-07
Iter: 1715 loss: 8.5240913e-07
Iter: 1716 loss: 8.52395942e-07
Iter: 1717 loss: 8.52266453e-07
Iter: 1718 loss: 8.52327048e-07
Iter: 1719 loss: 8.52188236e-07
Iter: 1720 loss: 8.52018275e-07
Iter: 1721 loss: 8.52059429e-07
Iter: 1722 loss: 8.51876734e-07
Iter: 1723 loss: 8.51671075e-07
Iter: 1724 loss: 8.5235331e-07
Iter: 1725 loss: 8.51603204e-07
Iter: 1726 loss: 8.51333766e-07
Iter: 1727 loss: 8.53043389e-07
Iter: 1728 loss: 8.51306481e-07
Iter: 1729 loss: 8.51160962e-07
Iter: 1730 loss: 8.50931e-07
Iter: 1731 loss: 8.50940467e-07
Iter: 1732 loss: 8.50800916e-07
Iter: 1733 loss: 8.50788297e-07
Iter: 1734 loss: 8.50641754e-07
Iter: 1735 loss: 8.50552055e-07
Iter: 1736 loss: 8.50482479e-07
Iter: 1737 loss: 8.50296374e-07
Iter: 1738 loss: 8.50325307e-07
Iter: 1739 loss: 8.50157619e-07
Iter: 1740 loss: 8.50064794e-07
Iter: 1741 loss: 8.50007893e-07
Iter: 1742 loss: 8.49896537e-07
Iter: 1743 loss: 8.49643811e-07
Iter: 1744 loss: 8.52335575e-07
Iter: 1745 loss: 8.49604589e-07
Iter: 1746 loss: 8.49356866e-07
Iter: 1747 loss: 8.51514869e-07
Iter: 1748 loss: 8.49362436e-07
Iter: 1749 loss: 8.49113349e-07
Iter: 1750 loss: 8.50214803e-07
Iter: 1751 loss: 8.49092146e-07
Iter: 1752 loss: 8.48960553e-07
Iter: 1753 loss: 8.49052242e-07
Iter: 1754 loss: 8.48862e-07
Iter: 1755 loss: 8.48701632e-07
Iter: 1756 loss: 8.48912407e-07
Iter: 1757 loss: 8.48595391e-07
Iter: 1758 loss: 8.48396724e-07
Iter: 1759 loss: 8.51104346e-07
Iter: 1760 loss: 8.48401214e-07
Iter: 1761 loss: 8.48284458e-07
Iter: 1762 loss: 8.48072e-07
Iter: 1763 loss: 8.48070897e-07
Iter: 1764 loss: 8.47901617e-07
Iter: 1765 loss: 8.50071274e-07
Iter: 1766 loss: 8.47905312e-07
Iter: 1767 loss: 8.47739898e-07
Iter: 1768 loss: 8.47874503e-07
Iter: 1769 loss: 8.47664239e-07
Iter: 1770 loss: 8.47488195e-07
Iter: 1771 loss: 8.47365754e-07
Iter: 1772 loss: 8.47303681e-07
Iter: 1773 loss: 8.47221827e-07
Iter: 1774 loss: 8.47180218e-07
Iter: 1775 loss: 8.47054935e-07
Iter: 1776 loss: 8.4686e-07
Iter: 1777 loss: 8.4685837e-07
Iter: 1778 loss: 8.46681871e-07
Iter: 1779 loss: 8.47234332e-07
Iter: 1780 loss: 8.46622754e-07
Iter: 1781 loss: 8.46387252e-07
Iter: 1782 loss: 8.47861202e-07
Iter: 1783 loss: 8.46364514e-07
Iter: 1784 loss: 8.46237242e-07
Iter: 1785 loss: 8.46146463e-07
Iter: 1786 loss: 8.46074443e-07
Iter: 1787 loss: 8.45858722e-07
Iter: 1788 loss: 8.46875764e-07
Iter: 1789 loss: 8.45836553e-07
Iter: 1790 loss: 8.45703312e-07
Iter: 1791 loss: 8.47680496e-07
Iter: 1792 loss: 8.45707177e-07
Iter: 1793 loss: 8.45605882e-07
Iter: 1794 loss: 8.45336103e-07
Iter: 1795 loss: 8.49350101e-07
Iter: 1796 loss: 8.45316322e-07
Iter: 1797 loss: 8.45119814e-07
Iter: 1798 loss: 8.46970181e-07
Iter: 1799 loss: 8.45116062e-07
Iter: 1800 loss: 8.44921601e-07
Iter: 1801 loss: 8.45681825e-07
Iter: 1802 loss: 8.44873284e-07
Iter: 1803 loss: 8.44734814e-07
Iter: 1804 loss: 8.44424903e-07
Iter: 1805 loss: 8.5026943e-07
Iter: 1806 loss: 8.44425472e-07
Iter: 1807 loss: 8.44131648e-07
Iter: 1808 loss: 8.48148204e-07
Iter: 1809 loss: 8.4413216e-07
Iter: 1810 loss: 8.43841633e-07
Iter: 1811 loss: 8.44688316e-07
Iter: 1812 loss: 8.43755629e-07
Iter: 1813 loss: 8.43614544e-07
Iter: 1814 loss: 8.43554176e-07
Iter: 1815 loss: 8.43484145e-07
Iter: 1816 loss: 8.43256e-07
Iter: 1817 loss: 8.45718773e-07
Iter: 1818 loss: 8.43259841e-07
Iter: 1819 loss: 8.4312552e-07
Iter: 1820 loss: 8.42934753e-07
Iter: 1821 loss: 8.42915711e-07
Iter: 1822 loss: 8.42679697e-07
Iter: 1823 loss: 8.43854309e-07
Iter: 1824 loss: 8.42621375e-07
Iter: 1825 loss: 8.42447434e-07
Iter: 1826 loss: 8.44913188e-07
Iter: 1827 loss: 8.42441636e-07
Iter: 1828 loss: 8.42257577e-07
Iter: 1829 loss: 8.42190161e-07
Iter: 1830 loss: 8.42108363e-07
Iter: 1831 loss: 8.41930046e-07
Iter: 1832 loss: 8.42306406e-07
Iter: 1833 loss: 8.41830911e-07
Iter: 1834 loss: 8.41610131e-07
Iter: 1835 loss: 8.429069e-07
Iter: 1836 loss: 8.41589781e-07
Iter: 1837 loss: 8.41419137e-07
Iter: 1838 loss: 8.41216661e-07
Iter: 1839 loss: 8.4119597e-07
Iter: 1840 loss: 8.40959046e-07
Iter: 1841 loss: 8.42214945e-07
Iter: 1842 loss: 8.40909e-07
Iter: 1843 loss: 8.40640269e-07
Iter: 1844 loss: 8.42537872e-07
Iter: 1845 loss: 8.40596385e-07
Iter: 1846 loss: 8.40421194e-07
Iter: 1847 loss: 8.40263624e-07
Iter: 1848 loss: 8.40234748e-07
Iter: 1849 loss: 8.40050916e-07
Iter: 1850 loss: 8.40036876e-07
Iter: 1851 loss: 8.39914264e-07
Iter: 1852 loss: 8.39684503e-07
Iter: 1853 loss: 8.39682968e-07
Iter: 1854 loss: 8.39426434e-07
Iter: 1855 loss: 8.40229177e-07
Iter: 1856 loss: 8.39365498e-07
Iter: 1857 loss: 8.39160691e-07
Iter: 1858 loss: 8.39153756e-07
Iter: 1859 loss: 8.39019776e-07
Iter: 1860 loss: 8.39057748e-07
Iter: 1861 loss: 8.3889779e-07
Iter: 1862 loss: 8.38754886e-07
Iter: 1863 loss: 8.38830829e-07
Iter: 1864 loss: 8.38660696e-07
Iter: 1865 loss: 8.38464246e-07
Iter: 1866 loss: 8.39844404e-07
Iter: 1867 loss: 8.38438837e-07
Iter: 1868 loss: 8.38285246e-07
Iter: 1869 loss: 8.38045e-07
Iter: 1870 loss: 8.3804332e-07
Iter: 1871 loss: 8.37778e-07
Iter: 1872 loss: 8.38899496e-07
Iter: 1873 loss: 8.37746711e-07
Iter: 1874 loss: 8.37486482e-07
Iter: 1875 loss: 8.41125711e-07
Iter: 1876 loss: 8.37495918e-07
Iter: 1877 loss: 8.37352786e-07
Iter: 1878 loss: 8.37059474e-07
Iter: 1879 loss: 8.42192094e-07
Iter: 1880 loss: 8.37061e-07
Iter: 1881 loss: 8.36954143e-07
Iter: 1882 loss: 8.36898835e-07
Iter: 1883 loss: 8.36779179e-07
Iter: 1884 loss: 8.36584604e-07
Iter: 1885 loss: 8.36577e-07
Iter: 1886 loss: 8.36357401e-07
Iter: 1887 loss: 8.36562435e-07
Iter: 1888 loss: 8.3622507e-07
Iter: 1889 loss: 8.35998776e-07
Iter: 1890 loss: 8.3597979e-07
Iter: 1891 loss: 8.35811875e-07
Iter: 1892 loss: 8.3597331e-07
Iter: 1893 loss: 8.3569131e-07
Iter: 1894 loss: 8.35512822e-07
Iter: 1895 loss: 8.35523849e-07
Iter: 1896 loss: 8.35343144e-07
Iter: 1897 loss: 8.35187052e-07
Iter: 1898 loss: 8.38204073e-07
Iter: 1899 loss: 8.35187734e-07
Iter: 1900 loss: 8.35052333e-07
Iter: 1901 loss: 8.34738955e-07
Iter: 1902 loss: 8.40435519e-07
Iter: 1903 loss: 8.34738159e-07
Iter: 1904 loss: 8.34448542e-07
Iter: 1905 loss: 8.34934724e-07
Iter: 1906 loss: 8.3429e-07
Iter: 1907 loss: 8.34208777e-07
Iter: 1908 loss: 8.34109414e-07
Iter: 1909 loss: 8.33976344e-07
Iter: 1910 loss: 8.33681213e-07
Iter: 1911 loss: 8.36819254e-07
Iter: 1912 loss: 8.33661886e-07
Iter: 1913 loss: 8.33511649e-07
Iter: 1914 loss: 8.33481351e-07
Iter: 1915 loss: 8.33319405e-07
Iter: 1916 loss: 8.33210493e-07
Iter: 1917 loss: 8.33164563e-07
Iter: 1918 loss: 8.32944124e-07
Iter: 1919 loss: 8.33005856e-07
Iter: 1920 loss: 8.32770866e-07
Iter: 1921 loss: 8.32500632e-07
Iter: 1922 loss: 8.35347578e-07
Iter: 1923 loss: 8.3249148e-07
Iter: 1924 loss: 8.32214482e-07
Iter: 1925 loss: 8.33126592e-07
Iter: 1926 loss: 8.32130354e-07
Iter: 1927 loss: 8.31925377e-07
Iter: 1928 loss: 8.31845796e-07
Iter: 1929 loss: 8.31725401e-07
Iter: 1930 loss: 8.31559646e-07
Iter: 1931 loss: 8.33756417e-07
Iter: 1932 loss: 8.31575562e-07
Iter: 1933 loss: 8.31402531e-07
Iter: 1934 loss: 8.31329316e-07
Iter: 1935 loss: 8.31217e-07
Iter: 1936 loss: 8.31011505e-07
Iter: 1937 loss: 8.30690567e-07
Iter: 1938 loss: 8.30683462e-07
Iter: 1939 loss: 8.30509066e-07
Iter: 1940 loss: 8.30467684e-07
Iter: 1941 loss: 8.3026373e-07
Iter: 1942 loss: 8.30326826e-07
Iter: 1943 loss: 8.3008166e-07
Iter: 1944 loss: 8.29899875e-07
Iter: 1945 loss: 8.29899e-07
Iter: 1946 loss: 8.29755152e-07
Iter: 1947 loss: 8.29512487e-07
Iter: 1948 loss: 8.33166382e-07
Iter: 1949 loss: 8.2951982e-07
Iter: 1950 loss: 8.2941034e-07
Iter: 1951 loss: 8.29216617e-07
Iter: 1952 loss: 8.33770855e-07
Iter: 1953 loss: 8.29193425e-07
Iter: 1954 loss: 8.28962698e-07
Iter: 1955 loss: 8.29446e-07
Iter: 1956 loss: 8.28895963e-07
Iter: 1957 loss: 8.28667567e-07
Iter: 1958 loss: 8.29922215e-07
Iter: 1959 loss: 8.2861925e-07
Iter: 1960 loss: 8.28392672e-07
Iter: 1961 loss: 8.30818067e-07
Iter: 1962 loss: 8.28382611e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8
+ date
Mon Oct 26 15:12:12 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09e93158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09e34950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09e34d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09efce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09f04ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09dbb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09d809d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09d90c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09d3c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09cff0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09ccb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09ccdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09ccdea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09c6fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09c6f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09be8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09c12400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09c0ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09b9b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09c12d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09bae7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09baef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5e76730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb09bae378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5e95048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5e4fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5e1a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5dde1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5dd2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5dcd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdae5d82510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdac06666a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdac0666158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdac05fee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdac061dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdac05aeb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.05608979e-05
Iter: 2 loss: 8.70987787e-06
Iter: 3 loss: 8.70967506e-06
Iter: 4 loss: 7.93292111e-06
Iter: 5 loss: 9.67622327e-06
Iter: 6 loss: 7.63951812e-06
Iter: 7 loss: 7.21030028e-06
Iter: 8 loss: 8.28757402e-06
Iter: 9 loss: 7.05973525e-06
Iter: 10 loss: 6.71076941e-06
Iter: 11 loss: 9.12808446e-06
Iter: 12 loss: 6.6776829e-06
Iter: 13 loss: 6.32437605e-06
Iter: 14 loss: 6.16495799e-06
Iter: 15 loss: 5.98760653e-06
Iter: 16 loss: 5.75138165e-06
Iter: 17 loss: 8.15611202e-06
Iter: 18 loss: 5.7442976e-06
Iter: 19 loss: 5.50076038e-06
Iter: 20 loss: 5.58836746e-06
Iter: 21 loss: 5.32993818e-06
Iter: 22 loss: 5.02714147e-06
Iter: 23 loss: 4.78402126e-06
Iter: 24 loss: 4.69292809e-06
Iter: 25 loss: 4.74484523e-06
Iter: 26 loss: 4.52641325e-06
Iter: 27 loss: 4.43750196e-06
Iter: 28 loss: 4.23953e-06
Iter: 29 loss: 7.04054401e-06
Iter: 30 loss: 4.22940639e-06
Iter: 31 loss: 4.03451213e-06
Iter: 32 loss: 3.91202184e-06
Iter: 33 loss: 3.83463566e-06
Iter: 34 loss: 3.55569659e-06
Iter: 35 loss: 5.8738633e-06
Iter: 36 loss: 3.53899941e-06
Iter: 37 loss: 3.39834469e-06
Iter: 38 loss: 3.39820326e-06
Iter: 39 loss: 3.24768871e-06
Iter: 40 loss: 3.3165752e-06
Iter: 41 loss: 3.14565364e-06
Iter: 42 loss: 3.03251863e-06
Iter: 43 loss: 3.52092025e-06
Iter: 44 loss: 3.00931833e-06
Iter: 45 loss: 2.91027732e-06
Iter: 46 loss: 3.66465838e-06
Iter: 47 loss: 2.90278876e-06
Iter: 48 loss: 2.83502413e-06
Iter: 49 loss: 2.92517734e-06
Iter: 50 loss: 2.80081167e-06
Iter: 51 loss: 2.7413555e-06
Iter: 52 loss: 2.81428947e-06
Iter: 53 loss: 2.71029103e-06
Iter: 54 loss: 2.62809363e-06
Iter: 55 loss: 3.05038793e-06
Iter: 56 loss: 2.61481046e-06
Iter: 57 loss: 2.55745363e-06
Iter: 58 loss: 2.46918512e-06
Iter: 59 loss: 2.46784566e-06
Iter: 60 loss: 2.46076161e-06
Iter: 61 loss: 2.42676902e-06
Iter: 62 loss: 2.39454403e-06
Iter: 63 loss: 2.328557e-06
Iter: 64 loss: 3.50614187e-06
Iter: 65 loss: 2.32730235e-06
Iter: 66 loss: 2.27031e-06
Iter: 67 loss: 2.43428417e-06
Iter: 68 loss: 2.25248323e-06
Iter: 69 loss: 2.20534139e-06
Iter: 70 loss: 2.28036697e-06
Iter: 71 loss: 2.18344985e-06
Iter: 72 loss: 2.16417516e-06
Iter: 73 loss: 2.15403588e-06
Iter: 74 loss: 2.12929945e-06
Iter: 75 loss: 2.09784889e-06
Iter: 76 loss: 2.0955913e-06
Iter: 77 loss: 2.06868981e-06
Iter: 78 loss: 2.36421783e-06
Iter: 79 loss: 2.0681382e-06
Iter: 80 loss: 2.04198568e-06
Iter: 81 loss: 2.06989284e-06
Iter: 82 loss: 2.02760202e-06
Iter: 83 loss: 2.00335603e-06
Iter: 84 loss: 2.06072582e-06
Iter: 85 loss: 1.99452984e-06
Iter: 86 loss: 1.96974179e-06
Iter: 87 loss: 2.04214416e-06
Iter: 88 loss: 1.96207907e-06
Iter: 89 loss: 1.93155688e-06
Iter: 90 loss: 1.99500141e-06
Iter: 91 loss: 1.91939512e-06
Iter: 92 loss: 1.89832156e-06
Iter: 93 loss: 1.90066362e-06
Iter: 94 loss: 1.88216904e-06
Iter: 95 loss: 1.86107388e-06
Iter: 96 loss: 1.86077909e-06
Iter: 97 loss: 1.84458361e-06
Iter: 98 loss: 1.8127389e-06
Iter: 99 loss: 2.44460534e-06
Iter: 100 loss: 1.81248106e-06
Iter: 101 loss: 1.78538335e-06
Iter: 102 loss: 1.82851e-06
Iter: 103 loss: 1.77283323e-06
Iter: 104 loss: 1.74875e-06
Iter: 105 loss: 1.8590456e-06
Iter: 106 loss: 1.74420666e-06
Iter: 107 loss: 1.72814259e-06
Iter: 108 loss: 1.72694945e-06
Iter: 109 loss: 1.71734689e-06
Iter: 110 loss: 1.69949601e-06
Iter: 111 loss: 2.10662483e-06
Iter: 112 loss: 1.69947123e-06
Iter: 113 loss: 1.68812778e-06
Iter: 114 loss: 1.68722431e-06
Iter: 115 loss: 1.67672101e-06
Iter: 116 loss: 1.66313703e-06
Iter: 117 loss: 1.66221344e-06
Iter: 118 loss: 1.64702e-06
Iter: 119 loss: 1.74499814e-06
Iter: 120 loss: 1.64537039e-06
Iter: 121 loss: 1.6339734e-06
Iter: 122 loss: 1.69488374e-06
Iter: 123 loss: 1.63225491e-06
Iter: 124 loss: 1.62277433e-06
Iter: 125 loss: 1.63063328e-06
Iter: 126 loss: 1.61714604e-06
Iter: 127 loss: 1.60601962e-06
Iter: 128 loss: 1.60057402e-06
Iter: 129 loss: 1.59521835e-06
Iter: 130 loss: 1.57778527e-06
Iter: 131 loss: 1.81688119e-06
Iter: 132 loss: 1.57768136e-06
Iter: 133 loss: 1.5700731e-06
Iter: 134 loss: 1.55471389e-06
Iter: 135 loss: 1.83728025e-06
Iter: 136 loss: 1.55442217e-06
Iter: 137 loss: 1.53870349e-06
Iter: 138 loss: 1.58222906e-06
Iter: 139 loss: 1.53361361e-06
Iter: 140 loss: 1.52237112e-06
Iter: 141 loss: 1.66591474e-06
Iter: 142 loss: 1.52230507e-06
Iter: 143 loss: 1.5127e-06
Iter: 144 loss: 1.59448314e-06
Iter: 145 loss: 1.51215795e-06
Iter: 146 loss: 1.50751032e-06
Iter: 147 loss: 1.49850746e-06
Iter: 148 loss: 1.68368695e-06
Iter: 149 loss: 1.49845607e-06
Iter: 150 loss: 1.48972799e-06
Iter: 151 loss: 1.4895395e-06
Iter: 152 loss: 1.48455456e-06
Iter: 153 loss: 1.47547598e-06
Iter: 154 loss: 1.69415785e-06
Iter: 155 loss: 1.4754695e-06
Iter: 156 loss: 1.46835123e-06
Iter: 157 loss: 1.46833304e-06
Iter: 158 loss: 1.46296668e-06
Iter: 159 loss: 1.46968546e-06
Iter: 160 loss: 1.4601942e-06
Iter: 161 loss: 1.45365607e-06
Iter: 162 loss: 1.45434933e-06
Iter: 163 loss: 1.44862952e-06
Iter: 164 loss: 1.4432801e-06
Iter: 165 loss: 1.51811298e-06
Iter: 166 loss: 1.44327498e-06
Iter: 167 loss: 1.43806653e-06
Iter: 168 loss: 1.43958209e-06
Iter: 169 loss: 1.43430748e-06
Iter: 170 loss: 1.429127e-06
Iter: 171 loss: 1.41960868e-06
Iter: 172 loss: 1.64304106e-06
Iter: 173 loss: 1.41961232e-06
Iter: 174 loss: 1.4076079e-06
Iter: 175 loss: 1.461e-06
Iter: 176 loss: 1.40529369e-06
Iter: 177 loss: 1.4040603e-06
Iter: 178 loss: 1.40135478e-06
Iter: 179 loss: 1.39758708e-06
Iter: 180 loss: 1.393258e-06
Iter: 181 loss: 1.39270855e-06
Iter: 182 loss: 1.38752591e-06
Iter: 183 loss: 1.403331e-06
Iter: 184 loss: 1.38596738e-06
Iter: 185 loss: 1.37896939e-06
Iter: 186 loss: 1.40632233e-06
Iter: 187 loss: 1.37734639e-06
Iter: 188 loss: 1.37408472e-06
Iter: 189 loss: 1.37112693e-06
Iter: 190 loss: 1.37028633e-06
Iter: 191 loss: 1.36463382e-06
Iter: 192 loss: 1.42542945e-06
Iter: 193 loss: 1.36451126e-06
Iter: 194 loss: 1.36030371e-06
Iter: 195 loss: 1.35947175e-06
Iter: 196 loss: 1.35671303e-06
Iter: 197 loss: 1.35089454e-06
Iter: 198 loss: 1.36930498e-06
Iter: 199 loss: 1.34919924e-06
Iter: 200 loss: 1.34627226e-06
Iter: 201 loss: 1.34621644e-06
Iter: 202 loss: 1.34398908e-06
Iter: 203 loss: 1.33941171e-06
Iter: 204 loss: 1.41858141e-06
Iter: 205 loss: 1.33929518e-06
Iter: 206 loss: 1.33344474e-06
Iter: 207 loss: 1.33329991e-06
Iter: 208 loss: 1.32870844e-06
Iter: 209 loss: 1.3227293e-06
Iter: 210 loss: 1.36593349e-06
Iter: 211 loss: 1.32217554e-06
Iter: 212 loss: 1.31920478e-06
Iter: 213 loss: 1.31879483e-06
Iter: 214 loss: 1.31665888e-06
Iter: 215 loss: 1.31206161e-06
Iter: 216 loss: 1.38186942e-06
Iter: 217 loss: 1.31187e-06
Iter: 218 loss: 1.31110141e-06
Iter: 219 loss: 1.30980243e-06
Iter: 220 loss: 1.30819865e-06
Iter: 221 loss: 1.30425883e-06
Iter: 222 loss: 1.34885772e-06
Iter: 223 loss: 1.30391072e-06
Iter: 224 loss: 1.29984392e-06
Iter: 225 loss: 1.32637797e-06
Iter: 226 loss: 1.29944488e-06
Iter: 227 loss: 1.29561636e-06
Iter: 228 loss: 1.31845286e-06
Iter: 229 loss: 1.29511227e-06
Iter: 230 loss: 1.29249e-06
Iter: 231 loss: 1.29009766e-06
Iter: 232 loss: 1.28942497e-06
Iter: 233 loss: 1.28556042e-06
Iter: 234 loss: 1.32621108e-06
Iter: 235 loss: 1.28548629e-06
Iter: 236 loss: 1.2829762e-06
Iter: 237 loss: 1.29771661e-06
Iter: 238 loss: 1.28265924e-06
Iter: 239 loss: 1.28063539e-06
Iter: 240 loss: 1.27599117e-06
Iter: 241 loss: 1.33584854e-06
Iter: 242 loss: 1.27568774e-06
Iter: 243 loss: 1.27061071e-06
Iter: 244 loss: 1.28649617e-06
Iter: 245 loss: 1.26914779e-06
Iter: 246 loss: 1.26523673e-06
Iter: 247 loss: 1.29744558e-06
Iter: 248 loss: 1.26497298e-06
Iter: 249 loss: 1.26027339e-06
Iter: 250 loss: 1.27710427e-06
Iter: 251 loss: 1.25911254e-06
Iter: 252 loss: 1.25715781e-06
Iter: 253 loss: 1.25869133e-06
Iter: 254 loss: 1.25595682e-06
Iter: 255 loss: 1.25373083e-06
Iter: 256 loss: 1.28215527e-06
Iter: 257 loss: 1.25369695e-06
Iter: 258 loss: 1.25234556e-06
Iter: 259 loss: 1.24872577e-06
Iter: 260 loss: 1.27500846e-06
Iter: 261 loss: 1.2479527e-06
Iter: 262 loss: 1.24691428e-06
Iter: 263 loss: 1.24591008e-06
Iter: 264 loss: 1.24421331e-06
Iter: 265 loss: 1.24289943e-06
Iter: 266 loss: 1.24235089e-06
Iter: 267 loss: 1.23974314e-06
Iter: 268 loss: 1.24310577e-06
Iter: 269 loss: 1.2383822e-06
Iter: 270 loss: 1.23535381e-06
Iter: 271 loss: 1.26458553e-06
Iter: 272 loss: 1.23522841e-06
Iter: 273 loss: 1.23324196e-06
Iter: 274 loss: 1.23764949e-06
Iter: 275 loss: 1.23248458e-06
Iter: 276 loss: 1.23079315e-06
Iter: 277 loss: 1.22920176e-06
Iter: 278 loss: 1.22884853e-06
Iter: 279 loss: 1.2261952e-06
Iter: 280 loss: 1.22721121e-06
Iter: 281 loss: 1.22435222e-06
Iter: 282 loss: 1.22338713e-06
Iter: 283 loss: 1.22272854e-06
Iter: 284 loss: 1.22082872e-06
Iter: 285 loss: 1.21785547e-06
Iter: 286 loss: 1.21782944e-06
Iter: 287 loss: 1.21536868e-06
Iter: 288 loss: 1.23194695e-06
Iter: 289 loss: 1.21510436e-06
Iter: 290 loss: 1.21207518e-06
Iter: 291 loss: 1.21606786e-06
Iter: 292 loss: 1.21058872e-06
Iter: 293 loss: 1.20876916e-06
Iter: 294 loss: 1.2095802e-06
Iter: 295 loss: 1.20756454e-06
Iter: 296 loss: 1.20635013e-06
Iter: 297 loss: 1.20623258e-06
Iter: 298 loss: 1.20519167e-06
Iter: 299 loss: 1.20319862e-06
Iter: 300 loss: 1.24845201e-06
Iter: 301 loss: 1.20320976e-06
Iter: 302 loss: 1.20144887e-06
Iter: 303 loss: 1.21920561e-06
Iter: 304 loss: 1.20137656e-06
Iter: 305 loss: 1.19960214e-06
Iter: 306 loss: 1.20234176e-06
Iter: 307 loss: 1.19873346e-06
Iter: 308 loss: 1.19711353e-06
Iter: 309 loss: 1.20187599e-06
Iter: 310 loss: 1.19663503e-06
Iter: 311 loss: 1.19512833e-06
Iter: 312 loss: 1.19295942e-06
Iter: 313 loss: 1.19289894e-06
Iter: 314 loss: 1.1904865e-06
Iter: 315 loss: 1.2039286e-06
Iter: 316 loss: 1.19013976e-06
Iter: 317 loss: 1.18825108e-06
Iter: 318 loss: 1.19274205e-06
Iter: 319 loss: 1.18751245e-06
Iter: 320 loss: 1.18592652e-06
Iter: 321 loss: 1.18586615e-06
Iter: 322 loss: 1.18487549e-06
Iter: 323 loss: 1.1825789e-06
Iter: 324 loss: 1.21296102e-06
Iter: 325 loss: 1.1824178e-06
Iter: 326 loss: 1.18151286e-06
Iter: 327 loss: 1.18107232e-06
Iter: 328 loss: 1.18002799e-06
Iter: 329 loss: 1.17771333e-06
Iter: 330 loss: 1.20969116e-06
Iter: 331 loss: 1.17756804e-06
Iter: 332 loss: 1.17596e-06
Iter: 333 loss: 1.19906849e-06
Iter: 334 loss: 1.17595994e-06
Iter: 335 loss: 1.1743e-06
Iter: 336 loss: 1.17611467e-06
Iter: 337 loss: 1.17334616e-06
Iter: 338 loss: 1.17217314e-06
Iter: 339 loss: 1.17101592e-06
Iter: 340 loss: 1.17076411e-06
Iter: 341 loss: 1.16936553e-06
Iter: 342 loss: 1.16928595e-06
Iter: 343 loss: 1.16807905e-06
Iter: 344 loss: 1.16632054e-06
Iter: 345 loss: 1.16625029e-06
Iter: 346 loss: 1.16470073e-06
Iter: 347 loss: 1.17702155e-06
Iter: 348 loss: 1.16460194e-06
Iter: 349 loss: 1.16339447e-06
Iter: 350 loss: 1.16227579e-06
Iter: 351 loss: 1.1619851e-06
Iter: 352 loss: 1.16023284e-06
Iter: 353 loss: 1.1729112e-06
Iter: 354 loss: 1.16007323e-06
Iter: 355 loss: 1.15885234e-06
Iter: 356 loss: 1.15886633e-06
Iter: 357 loss: 1.15820353e-06
Iter: 358 loss: 1.15666785e-06
Iter: 359 loss: 1.17589025e-06
Iter: 360 loss: 1.15656121e-06
Iter: 361 loss: 1.15547107e-06
Iter: 362 loss: 1.15533123e-06
Iter: 363 loss: 1.15441014e-06
Iter: 364 loss: 1.15204193e-06
Iter: 365 loss: 1.17628508e-06
Iter: 366 loss: 1.15178545e-06
Iter: 367 loss: 1.1511454e-06
Iter: 368 loss: 1.15084856e-06
Iter: 369 loss: 1.14987733e-06
Iter: 370 loss: 1.14918794e-06
Iter: 371 loss: 1.14884267e-06
Iter: 372 loss: 1.14760519e-06
Iter: 373 loss: 1.14715203e-06
Iter: 374 loss: 1.14645593e-06
Iter: 375 loss: 1.14559202e-06
Iter: 376 loss: 1.14534009e-06
Iter: 377 loss: 1.14459431e-06
Iter: 378 loss: 1.14278043e-06
Iter: 379 loss: 1.16493493e-06
Iter: 380 loss: 1.14260774e-06
Iter: 381 loss: 1.14041973e-06
Iter: 382 loss: 1.14357647e-06
Iter: 383 loss: 1.13937131e-06
Iter: 384 loss: 1.13767e-06
Iter: 385 loss: 1.1376419e-06
Iter: 386 loss: 1.13668398e-06
Iter: 387 loss: 1.13953297e-06
Iter: 388 loss: 1.1363868e-06
Iter: 389 loss: 1.13531837e-06
Iter: 390 loss: 1.14429213e-06
Iter: 391 loss: 1.13524879e-06
Iter: 392 loss: 1.13461397e-06
Iter: 393 loss: 1.13359101e-06
Iter: 394 loss: 1.13356555e-06
Iter: 395 loss: 1.13229294e-06
Iter: 396 loss: 1.14899558e-06
Iter: 397 loss: 1.1323109e-06
Iter: 398 loss: 1.13156341e-06
Iter: 399 loss: 1.1299893e-06
Iter: 400 loss: 1.15190937e-06
Iter: 401 loss: 1.12990529e-06
Iter: 402 loss: 1.12816383e-06
Iter: 403 loss: 1.14093461e-06
Iter: 404 loss: 1.12801058e-06
Iter: 405 loss: 1.1260521e-06
Iter: 406 loss: 1.13301394e-06
Iter: 407 loss: 1.12555529e-06
Iter: 408 loss: 1.12471218e-06
Iter: 409 loss: 1.12416797e-06
Iter: 410 loss: 1.12386977e-06
Iter: 411 loss: 1.12312239e-06
Iter: 412 loss: 1.12306e-06
Iter: 413 loss: 1.12233397e-06
Iter: 414 loss: 1.12100747e-06
Iter: 415 loss: 1.14849922e-06
Iter: 416 loss: 1.12100849e-06
Iter: 417 loss: 1.11967142e-06
Iter: 418 loss: 1.12141026e-06
Iter: 419 loss: 1.11898657e-06
Iter: 420 loss: 1.11760107e-06
Iter: 421 loss: 1.13096269e-06
Iter: 422 loss: 1.11753945e-06
Iter: 423 loss: 1.11652366e-06
Iter: 424 loss: 1.12258033e-06
Iter: 425 loss: 1.11635791e-06
Iter: 426 loss: 1.11532154e-06
Iter: 427 loss: 1.11730651e-06
Iter: 428 loss: 1.11486816e-06
Iter: 429 loss: 1.11405177e-06
Iter: 430 loss: 1.11540271e-06
Iter: 431 loss: 1.11371469e-06
Iter: 432 loss: 1.1126258e-06
Iter: 433 loss: 1.11676536e-06
Iter: 434 loss: 1.11236398e-06
Iter: 435 loss: 1.11163695e-06
Iter: 436 loss: 1.11003339e-06
Iter: 437 loss: 1.13316207e-06
Iter: 438 loss: 1.1099537e-06
Iter: 439 loss: 1.10910105e-06
Iter: 440 loss: 1.10889448e-06
Iter: 441 loss: 1.10788983e-06
Iter: 442 loss: 1.10714564e-06
Iter: 443 loss: 1.10682322e-06
Iter: 444 loss: 1.10574729e-06
Iter: 445 loss: 1.10705423e-06
Iter: 446 loss: 1.10520386e-06
Iter: 447 loss: 1.10393307e-06
Iter: 448 loss: 1.12034331e-06
Iter: 449 loss: 1.10392318e-06
Iter: 450 loss: 1.10325414e-06
Iter: 451 loss: 1.1018135e-06
Iter: 452 loss: 1.12236296e-06
Iter: 453 loss: 1.10171436e-06
Iter: 454 loss: 1.10030192e-06
Iter: 455 loss: 1.10581595e-06
Iter: 456 loss: 1.09999371e-06
Iter: 457 loss: 1.09879295e-06
Iter: 458 loss: 1.1147099e-06
Iter: 459 loss: 1.09880023e-06
Iter: 460 loss: 1.09781649e-06
Iter: 461 loss: 1.10311271e-06
Iter: 462 loss: 1.09766268e-06
Iter: 463 loss: 1.09700431e-06
Iter: 464 loss: 1.0974918e-06
Iter: 465 loss: 1.09657321e-06
Iter: 466 loss: 1.09587415e-06
Iter: 467 loss: 1.09928089e-06
Iter: 468 loss: 1.09577627e-06
Iter: 469 loss: 1.0948396e-06
Iter: 470 loss: 1.09388327e-06
Iter: 471 loss: 1.09375344e-06
Iter: 472 loss: 1.09273628e-06
Iter: 473 loss: 1.09315056e-06
Iter: 474 loss: 1.09206781e-06
Iter: 475 loss: 1.09131554e-06
Iter: 476 loss: 1.09122709e-06
Iter: 477 loss: 1.09059533e-06
Iter: 478 loss: 1.08929521e-06
Iter: 479 loss: 1.11142697e-06
Iter: 480 loss: 1.08925929e-06
Iter: 481 loss: 1.08828704e-06
Iter: 482 loss: 1.10110852e-06
Iter: 483 loss: 1.08829977e-06
Iter: 484 loss: 1.08728682e-06
Iter: 485 loss: 1.08988274e-06
Iter: 486 loss: 1.08694542e-06
Iter: 487 loss: 1.08630206e-06
Iter: 488 loss: 1.08493236e-06
Iter: 489 loss: 1.10511792e-06
Iter: 490 loss: 1.08485347e-06
Iter: 491 loss: 1.0832772e-06
Iter: 492 loss: 1.09253119e-06
Iter: 493 loss: 1.08305903e-06
Iter: 494 loss: 1.08258814e-06
Iter: 495 loss: 1.08238487e-06
Iter: 496 loss: 1.08177892e-06
Iter: 497 loss: 1.08105064e-06
Iter: 498 loss: 1.08099061e-06
Iter: 499 loss: 1.0798658e-06
Iter: 500 loss: 1.08519987e-06
Iter: 501 loss: 1.07967708e-06
Iter: 502 loss: 1.0788882e-06
Iter: 503 loss: 1.08409085e-06
Iter: 504 loss: 1.07881169e-06
Iter: 505 loss: 1.07817482e-06
Iter: 506 loss: 1.07748019e-06
Iter: 507 loss: 1.07736173e-06
Iter: 508 loss: 1.07653796e-06
Iter: 509 loss: 1.07857363e-06
Iter: 510 loss: 1.07626113e-06
Iter: 511 loss: 1.07529797e-06
Iter: 512 loss: 1.08594099e-06
Iter: 513 loss: 1.07526671e-06
Iter: 514 loss: 1.07466326e-06
Iter: 515 loss: 1.07341964e-06
Iter: 516 loss: 1.09411553e-06
Iter: 517 loss: 1.07336746e-06
Iter: 518 loss: 1.07298092e-06
Iter: 519 loss: 1.07272251e-06
Iter: 520 loss: 1.07212372e-06
Iter: 521 loss: 1.07088158e-06
Iter: 522 loss: 1.09036114e-06
Iter: 523 loss: 1.07082315e-06
Iter: 524 loss: 1.06968707e-06
Iter: 525 loss: 1.07437108e-06
Iter: 526 loss: 1.06943526e-06
Iter: 527 loss: 1.0685884e-06
Iter: 528 loss: 1.06975301e-06
Iter: 529 loss: 1.06816469e-06
Iter: 530 loss: 1.06766925e-06
Iter: 531 loss: 1.06751429e-06
Iter: 532 loss: 1.06715652e-06
Iter: 533 loss: 1.06633263e-06
Iter: 534 loss: 1.07923961e-06
Iter: 535 loss: 1.06629625e-06
Iter: 536 loss: 1.06545133e-06
Iter: 537 loss: 1.07669348e-06
Iter: 538 loss: 1.06546281e-06
Iter: 539 loss: 1.0647741e-06
Iter: 540 loss: 1.06565881e-06
Iter: 541 loss: 1.06445736e-06
Iter: 542 loss: 1.0637724e-06
Iter: 543 loss: 1.06340667e-06
Iter: 544 loss: 1.06306788e-06
Iter: 545 loss: 1.06211337e-06
Iter: 546 loss: 1.06626908e-06
Iter: 547 loss: 1.06188713e-06
Iter: 548 loss: 1.06123446e-06
Iter: 549 loss: 1.06122775e-06
Iter: 550 loss: 1.06087759e-06
Iter: 551 loss: 1.05997151e-06
Iter: 552 loss: 1.06743471e-06
Iter: 553 loss: 1.05984907e-06
Iter: 554 loss: 1.05919889e-06
Iter: 555 loss: 1.05914023e-06
Iter: 556 loss: 1.05847425e-06
Iter: 557 loss: 1.05748973e-06
Iter: 558 loss: 1.05743845e-06
Iter: 559 loss: 1.05655397e-06
Iter: 560 loss: 1.05614299e-06
Iter: 561 loss: 1.05568438e-06
Iter: 562 loss: 1.05489516e-06
Iter: 563 loss: 1.05487425e-06
Iter: 564 loss: 1.05418462e-06
Iter: 565 loss: 1.05980632e-06
Iter: 566 loss: 1.05413915e-06
Iter: 567 loss: 1.05371191e-06
Iter: 568 loss: 1.05296476e-06
Iter: 569 loss: 1.05295567e-06
Iter: 570 loss: 1.05224467e-06
Iter: 571 loss: 1.05224331e-06
Iter: 572 loss: 1.05175059e-06
Iter: 573 loss: 1.05085269e-06
Iter: 574 loss: 1.07298115e-06
Iter: 575 loss: 1.05085758e-06
Iter: 576 loss: 1.04976584e-06
Iter: 577 loss: 1.05404047e-06
Iter: 578 loss: 1.04949299e-06
Iter: 579 loss: 1.04868673e-06
Iter: 580 loss: 1.04907281e-06
Iter: 581 loss: 1.04814649e-06
Iter: 582 loss: 1.04776461e-06
Iter: 583 loss: 1.04757214e-06
Iter: 584 loss: 1.04723154e-06
Iter: 585 loss: 1.04647779e-06
Iter: 586 loss: 1.06187986e-06
Iter: 587 loss: 1.04649746e-06
Iter: 588 loss: 1.04583967e-06
Iter: 589 loss: 1.05078084e-06
Iter: 590 loss: 1.04578658e-06
Iter: 591 loss: 1.04507785e-06
Iter: 592 loss: 1.04707283e-06
Iter: 593 loss: 1.0448307e-06
Iter: 594 loss: 1.04433093e-06
Iter: 595 loss: 1.043373e-06
Iter: 596 loss: 1.06476045e-06
Iter: 597 loss: 1.04336482e-06
Iter: 598 loss: 1.04247727e-06
Iter: 599 loss: 1.05047229e-06
Iter: 600 loss: 1.04243463e-06
Iter: 601 loss: 1.04203434e-06
Iter: 602 loss: 1.04197727e-06
Iter: 603 loss: 1.04166475e-06
Iter: 604 loss: 1.04089042e-06
Iter: 605 loss: 1.04694982e-06
Iter: 606 loss: 1.04073854e-06
Iter: 607 loss: 1.04050855e-06
Iter: 608 loss: 1.04029664e-06
Iter: 609 loss: 1.03993193e-06
Iter: 610 loss: 1.03914465e-06
Iter: 611 loss: 1.05076015e-06
Iter: 612 loss: 1.03912112e-06
Iter: 613 loss: 1.03829973e-06
Iter: 614 loss: 1.03898799e-06
Iter: 615 loss: 1.03785692e-06
Iter: 616 loss: 1.0368808e-06
Iter: 617 loss: 1.04523701e-06
Iter: 618 loss: 1.03684533e-06
Iter: 619 loss: 1.0361282e-06
Iter: 620 loss: 1.03751688e-06
Iter: 621 loss: 1.03586194e-06
Iter: 622 loss: 1.03524906e-06
Iter: 623 loss: 1.03525826e-06
Iter: 624 loss: 1.03489708e-06
Iter: 625 loss: 1.03407478e-06
Iter: 626 loss: 1.04564492e-06
Iter: 627 loss: 1.03405591e-06
Iter: 628 loss: 1.03345087e-06
Iter: 629 loss: 1.03342722e-06
Iter: 630 loss: 1.03292177e-06
Iter: 631 loss: 1.03285913e-06
Iter: 632 loss: 1.03249283e-06
Iter: 633 loss: 1.03205161e-06
Iter: 634 loss: 1.03597608e-06
Iter: 635 loss: 1.03201501e-06
Iter: 636 loss: 1.03148477e-06
Iter: 637 loss: 1.03065895e-06
Iter: 638 loss: 1.03062473e-06
Iter: 639 loss: 1.0300887e-06
Iter: 640 loss: 1.03137336e-06
Iter: 641 loss: 1.02985928e-06
Iter: 642 loss: 1.02919091e-06
Iter: 643 loss: 1.03622415e-06
Iter: 644 loss: 1.02915419e-06
Iter: 645 loss: 1.02877868e-06
Iter: 646 loss: 1.02794411e-06
Iter: 647 loss: 1.0426952e-06
Iter: 648 loss: 1.02791262e-06
Iter: 649 loss: 1.02690433e-06
Iter: 650 loss: 1.02942408e-06
Iter: 651 loss: 1.02657521e-06
Iter: 652 loss: 1.02582e-06
Iter: 653 loss: 1.03208686e-06
Iter: 654 loss: 1.02577656e-06
Iter: 655 loss: 1.025031e-06
Iter: 656 loss: 1.02760237e-06
Iter: 657 loss: 1.02486115e-06
Iter: 658 loss: 1.02409979e-06
Iter: 659 loss: 1.02832121e-06
Iter: 660 loss: 1.02396234e-06
Iter: 661 loss: 1.02352431e-06
Iter: 662 loss: 1.0231679e-06
Iter: 663 loss: 1.02301874e-06
Iter: 664 loss: 1.02254444e-06
Iter: 665 loss: 1.02251295e-06
Iter: 666 loss: 1.0221604e-06
Iter: 667 loss: 1.02128274e-06
Iter: 668 loss: 1.03222419e-06
Iter: 669 loss: 1.02124795e-06
Iter: 670 loss: 1.02086665e-06
Iter: 671 loss: 1.0207516e-06
Iter: 672 loss: 1.02028275e-06
Iter: 673 loss: 1.01962064e-06
Iter: 674 loss: 1.01960188e-06
Iter: 675 loss: 1.0190231e-06
Iter: 676 loss: 1.02163517e-06
Iter: 677 loss: 1.01892101e-06
Iter: 678 loss: 1.01817363e-06
Iter: 679 loss: 1.02032232e-06
Iter: 680 loss: 1.0179275e-06
Iter: 681 loss: 1.0174341e-06
Iter: 682 loss: 1.01640694e-06
Iter: 683 loss: 1.03703667e-06
Iter: 684 loss: 1.01641058e-06
Iter: 685 loss: 1.01555122e-06
Iter: 686 loss: 1.01964861e-06
Iter: 687 loss: 1.01539558e-06
Iter: 688 loss: 1.01453361e-06
Iter: 689 loss: 1.0220399e-06
Iter: 690 loss: 1.01449598e-06
Iter: 691 loss: 1.01381795e-06
Iter: 692 loss: 1.01797798e-06
Iter: 693 loss: 1.01371393e-06
Iter: 694 loss: 1.01323701e-06
Iter: 695 loss: 1.01359797e-06
Iter: 696 loss: 1.01292551e-06
Iter: 697 loss: 1.01235378e-06
Iter: 698 loss: 1.01346598e-06
Iter: 699 loss: 1.01211788e-06
Iter: 700 loss: 1.01145247e-06
Iter: 701 loss: 1.01564206e-06
Iter: 702 loss: 1.01134879e-06
Iter: 703 loss: 1.0108829e-06
Iter: 704 loss: 1.01023352e-06
Iter: 705 loss: 1.01018668e-06
Iter: 706 loss: 1.00956504e-06
Iter: 707 loss: 1.00954969e-06
Iter: 708 loss: 1.00921284e-06
Iter: 709 loss: 1.00841555e-06
Iter: 710 loss: 1.01528246e-06
Iter: 711 loss: 1.00830016e-06
Iter: 712 loss: 1.00774469e-06
Iter: 713 loss: 1.00766806e-06
Iter: 714 loss: 1.00712225e-06
Iter: 715 loss: 1.00657849e-06
Iter: 716 loss: 1.00649947e-06
Iter: 717 loss: 1.00589773e-06
Iter: 718 loss: 1.00553825e-06
Iter: 719 loss: 1.00528609e-06
Iter: 720 loss: 1.0042736e-06
Iter: 721 loss: 1.00537136e-06
Iter: 722 loss: 1.00368584e-06
Iter: 723 loss: 1.00326679e-06
Iter: 724 loss: 1.00313605e-06
Iter: 725 loss: 1.00256193e-06
Iter: 726 loss: 1.00270063e-06
Iter: 727 loss: 1.00216243e-06
Iter: 728 loss: 1.00152761e-06
Iter: 729 loss: 1.00266709e-06
Iter: 730 loss: 1.00124362e-06
Iter: 731 loss: 1.0005956e-06
Iter: 732 loss: 1.00458965e-06
Iter: 733 loss: 1.00051557e-06
Iter: 734 loss: 9.99970212e-07
Iter: 735 loss: 1.00191744e-06
Iter: 736 loss: 9.99818e-07
Iter: 737 loss: 9.99358463e-07
Iter: 738 loss: 9.99152235e-07
Iter: 739 loss: 9.98918154e-07
Iter: 740 loss: 9.98362339e-07
Iter: 741 loss: 9.98382234e-07
Iter: 742 loss: 9.97995926e-07
Iter: 743 loss: 9.97015832e-07
Iter: 744 loss: 1.00380771e-06
Iter: 745 loss: 9.9676447e-07
Iter: 746 loss: 9.96421136e-07
Iter: 747 loss: 9.96268795e-07
Iter: 748 loss: 9.95773348e-07
Iter: 749 loss: 9.96001745e-07
Iter: 750 loss: 9.95454911e-07
Iter: 751 loss: 9.95000732e-07
Iter: 752 loss: 9.94265292e-07
Iter: 753 loss: 9.94255061e-07
Iter: 754 loss: 9.93557705e-07
Iter: 755 loss: 9.96477866e-07
Iter: 756 loss: 9.93393314e-07
Iter: 757 loss: 9.93008598e-07
Iter: 758 loss: 9.92946298e-07
Iter: 759 loss: 9.92630362e-07
Iter: 760 loss: 9.91962111e-07
Iter: 761 loss: 1.00417947e-06
Iter: 762 loss: 9.919587e-07
Iter: 763 loss: 9.91275556e-07
Iter: 764 loss: 9.9815793e-07
Iter: 765 loss: 9.91270213e-07
Iter: 766 loss: 9.90733497e-07
Iter: 767 loss: 9.92635364e-07
Iter: 768 loss: 9.90603667e-07
Iter: 769 loss: 9.90087528e-07
Iter: 770 loss: 9.9039471e-07
Iter: 771 loss: 9.89754767e-07
Iter: 772 loss: 9.89269893e-07
Iter: 773 loss: 9.92295668e-07
Iter: 774 loss: 9.89187356e-07
Iter: 775 loss: 9.8862165e-07
Iter: 776 loss: 9.8949215e-07
Iter: 777 loss: 9.88329361e-07
Iter: 778 loss: 9.87873e-07
Iter: 779 loss: 9.87346539e-07
Iter: 780 loss: 9.87294129e-07
Iter: 781 loss: 9.86941473e-07
Iter: 782 loss: 9.86842224e-07
Iter: 783 loss: 9.86467057e-07
Iter: 784 loss: 9.85514362e-07
Iter: 785 loss: 9.95046094e-07
Iter: 786 loss: 9.85396923e-07
Iter: 787 loss: 9.84553e-07
Iter: 788 loss: 9.86546e-07
Iter: 789 loss: 9.84268695e-07
Iter: 790 loss: 9.8377177e-07
Iter: 791 loss: 9.83773703e-07
Iter: 792 loss: 9.83282689e-07
Iter: 793 loss: 9.84336339e-07
Iter: 794 loss: 9.83121822e-07
Iter: 795 loss: 9.82651841e-07
Iter: 796 loss: 9.81941412e-07
Iter: 797 loss: 9.81930725e-07
Iter: 798 loss: 9.81540325e-07
Iter: 799 loss: 9.81442327e-07
Iter: 800 loss: 9.81116273e-07
Iter: 801 loss: 9.80889808e-07
Iter: 802 loss: 9.80792379e-07
Iter: 803 loss: 9.80179607e-07
Iter: 804 loss: 9.80795335e-07
Iter: 805 loss: 9.79866172e-07
Iter: 806 loss: 9.79441893e-07
Iter: 807 loss: 9.79418814e-07
Iter: 808 loss: 9.79149e-07
Iter: 809 loss: 9.78695425e-07
Iter: 810 loss: 9.78676326e-07
Iter: 811 loss: 9.78222602e-07
Iter: 812 loss: 9.79459e-07
Iter: 813 loss: 9.78054231e-07
Iter: 814 loss: 9.77423838e-07
Iter: 815 loss: 9.80460754e-07
Iter: 816 loss: 9.77312766e-07
Iter: 817 loss: 9.76887804e-07
Iter: 818 loss: 9.76085289e-07
Iter: 819 loss: 9.91808292e-07
Iter: 820 loss: 9.76055162e-07
Iter: 821 loss: 9.75206603e-07
Iter: 822 loss: 9.78719413e-07
Iter: 823 loss: 9.75049375e-07
Iter: 824 loss: 9.74607246e-07
Iter: 825 loss: 9.74534942e-07
Iter: 826 loss: 9.74085197e-07
Iter: 827 loss: 9.73378e-07
Iter: 828 loss: 9.73371e-07
Iter: 829 loss: 9.72850785e-07
Iter: 830 loss: 9.77383706e-07
Iter: 831 loss: 9.7285033e-07
Iter: 832 loss: 9.72287125e-07
Iter: 833 loss: 9.73205374e-07
Iter: 834 loss: 9.72002908e-07
Iter: 835 loss: 9.71517466e-07
Iter: 836 loss: 9.72428211e-07
Iter: 837 loss: 9.712885e-07
Iter: 838 loss: 9.70816131e-07
Iter: 839 loss: 9.74194108e-07
Iter: 840 loss: 9.70762699e-07
Iter: 841 loss: 9.70318069e-07
Iter: 842 loss: 9.7142447e-07
Iter: 843 loss: 9.70139695e-07
Iter: 844 loss: 9.69791586e-07
Iter: 845 loss: 9.69137e-07
Iter: 846 loss: 9.84907842e-07
Iter: 847 loss: 9.69123e-07
Iter: 848 loss: 9.68778181e-07
Iter: 849 loss: 9.68693e-07
Iter: 850 loss: 9.68277163e-07
Iter: 851 loss: 9.67869e-07
Iter: 852 loss: 9.67778419e-07
Iter: 853 loss: 9.67265805e-07
Iter: 854 loss: 9.67145297e-07
Iter: 855 loss: 9.66806738e-07
Iter: 856 loss: 9.66076755e-07
Iter: 857 loss: 9.68245e-07
Iter: 858 loss: 9.65860522e-07
Iter: 859 loss: 9.65310392e-07
Iter: 860 loss: 9.65292088e-07
Iter: 861 loss: 9.65023219e-07
Iter: 862 loss: 9.64403625e-07
Iter: 863 loss: 9.71025429e-07
Iter: 864 loss: 9.64307219e-07
Iter: 865 loss: 9.63932735e-07
Iter: 866 loss: 9.63860884e-07
Iter: 867 loss: 9.63506e-07
Iter: 868 loss: 9.63161938e-07
Iter: 869 loss: 9.63081447e-07
Iter: 870 loss: 9.625129e-07
Iter: 871 loss: 9.62404783e-07
Iter: 872 loss: 9.62017793e-07
Iter: 873 loss: 9.61742e-07
Iter: 874 loss: 9.615934e-07
Iter: 875 loss: 9.6125018e-07
Iter: 876 loss: 9.60879902e-07
Iter: 877 loss: 9.60828174e-07
Iter: 878 loss: 9.60248713e-07
Iter: 879 loss: 9.60197781e-07
Iter: 880 loss: 9.59765885e-07
Iter: 881 loss: 9.59548061e-07
Iter: 882 loss: 9.59418912e-07
Iter: 883 loss: 9.59131285e-07
Iter: 884 loss: 9.58616511e-07
Iter: 885 loss: 9.58613896e-07
Iter: 886 loss: 9.58105602e-07
Iter: 887 loss: 9.57876e-07
Iter: 888 loss: 9.57617203e-07
Iter: 889 loss: 9.56871872e-07
Iter: 890 loss: 9.62087256e-07
Iter: 891 loss: 9.56790927e-07
Iter: 892 loss: 9.56391887e-07
Iter: 893 loss: 9.56377221e-07
Iter: 894 loss: 9.56129611e-07
Iter: 895 loss: 9.55501605e-07
Iter: 896 loss: 9.6234487e-07
Iter: 897 loss: 9.55443738e-07
Iter: 898 loss: 9.55007863e-07
Iter: 899 loss: 9.54990696e-07
Iter: 900 loss: 9.54522875e-07
Iter: 901 loss: 9.54530606e-07
Iter: 902 loss: 9.54147595e-07
Iter: 903 loss: 9.53749804e-07
Iter: 904 loss: 9.53593e-07
Iter: 905 loss: 9.53341555e-07
Iter: 906 loss: 9.52889081e-07
Iter: 907 loss: 9.52897267e-07
Iter: 908 loss: 9.52459743e-07
Iter: 909 loss: 9.52644086e-07
Iter: 910 loss: 9.52179334e-07
Iter: 911 loss: 9.51727884e-07
Iter: 912 loss: 9.5197862e-07
Iter: 913 loss: 9.51436448e-07
Iter: 914 loss: 9.50968683e-07
Iter: 915 loss: 9.5375276e-07
Iter: 916 loss: 9.50937761e-07
Iter: 917 loss: 9.50467324e-07
Iter: 918 loss: 9.5349543e-07
Iter: 919 loss: 9.50428102e-07
Iter: 920 loss: 9.50099889e-07
Iter: 921 loss: 9.4923405e-07
Iter: 922 loss: 9.55636665e-07
Iter: 923 loss: 9.49047319e-07
Iter: 924 loss: 9.48292268e-07
Iter: 925 loss: 9.56382337e-07
Iter: 926 loss: 9.48271463e-07
Iter: 927 loss: 9.47837179e-07
Iter: 928 loss: 9.47829e-07
Iter: 929 loss: 9.47437e-07
Iter: 930 loss: 9.46698606e-07
Iter: 931 loss: 9.4668809e-07
Iter: 932 loss: 9.46275293e-07
Iter: 933 loss: 9.51078164e-07
Iter: 934 loss: 9.46269552e-07
Iter: 935 loss: 9.45912916e-07
Iter: 936 loss: 9.47991111e-07
Iter: 937 loss: 9.45842487e-07
Iter: 938 loss: 9.45564068e-07
Iter: 939 loss: 9.4489377e-07
Iter: 940 loss: 9.51987261e-07
Iter: 941 loss: 9.44783096e-07
Iter: 942 loss: 9.44259e-07
Iter: 943 loss: 9.44282647e-07
Iter: 944 loss: 9.43706709e-07
Iter: 945 loss: 9.44830504e-07
Iter: 946 loss: 9.4349241e-07
Iter: 947 loss: 9.43081886e-07
Iter: 948 loss: 9.4284303e-07
Iter: 949 loss: 9.42647148e-07
Iter: 950 loss: 9.42002828e-07
Iter: 951 loss: 9.44942485e-07
Iter: 952 loss: 9.41864528e-07
Iter: 953 loss: 9.41501071e-07
Iter: 954 loss: 9.41500105e-07
Iter: 955 loss: 9.41218957e-07
Iter: 956 loss: 9.40750169e-07
Iter: 957 loss: 9.40759435e-07
Iter: 958 loss: 9.40201176e-07
Iter: 959 loss: 9.40066229e-07
Iter: 960 loss: 9.39698396e-07
Iter: 961 loss: 9.39431629e-07
Iter: 962 loss: 9.39270194e-07
Iter: 963 loss: 9.38927428e-07
Iter: 964 loss: 9.38402422e-07
Iter: 965 loss: 9.38388609e-07
Iter: 966 loss: 9.37856498e-07
Iter: 967 loss: 9.38380083e-07
Iter: 968 loss: 9.3759877e-07
Iter: 969 loss: 9.37030734e-07
Iter: 970 loss: 9.37020843e-07
Iter: 971 loss: 9.3672827e-07
Iter: 972 loss: 9.36148467e-07
Iter: 973 loss: 9.49594664e-07
Iter: 974 loss: 9.36151082e-07
Iter: 975 loss: 9.35566447e-07
Iter: 976 loss: 9.39241147e-07
Iter: 977 loss: 9.35515516e-07
Iter: 978 loss: 9.34919512e-07
Iter: 979 loss: 9.38661799e-07
Iter: 980 loss: 9.34805541e-07
Iter: 981 loss: 9.34424122e-07
Iter: 982 loss: 9.33689932e-07
Iter: 983 loss: 9.47553872e-07
Iter: 984 loss: 9.33671629e-07
Iter: 985 loss: 9.33218928e-07
Iter: 986 loss: 9.33179365e-07
Iter: 987 loss: 9.32823355e-07
Iter: 988 loss: 9.34349544e-07
Iter: 989 loss: 9.32757928e-07
Iter: 990 loss: 9.32370199e-07
Iter: 991 loss: 9.32226044e-07
Iter: 992 loss: 9.31989121e-07
Iter: 993 loss: 9.31557111e-07
Iter: 994 loss: 9.32093485e-07
Iter: 995 loss: 9.31305067e-07
Iter: 996 loss: 9.30947124e-07
Iter: 997 loss: 9.30933425e-07
Iter: 998 loss: 9.30578608e-07
Iter: 999 loss: 9.2996811e-07
Iter: 1000 loss: 9.29973965e-07
Iter: 1001 loss: 9.29377563e-07
Iter: 1002 loss: 9.30517672e-07
Iter: 1003 loss: 9.29128419e-07
Iter: 1004 loss: 9.28640247e-07
Iter: 1005 loss: 9.28630698e-07
Iter: 1006 loss: 9.28345457e-07
Iter: 1007 loss: 9.27751216e-07
Iter: 1008 loss: 9.38565108e-07
Iter: 1009 loss: 9.27733822e-07
Iter: 1010 loss: 9.27265319e-07
Iter: 1011 loss: 9.33228932e-07
Iter: 1012 loss: 9.27261965e-07
Iter: 1013 loss: 9.26733719e-07
Iter: 1014 loss: 9.27702445e-07
Iter: 1015 loss: 9.26513337e-07
Iter: 1016 loss: 9.26130781e-07
Iter: 1017 loss: 9.25930294e-07
Iter: 1018 loss: 9.25757263e-07
Iter: 1019 loss: 9.253759e-07
Iter: 1020 loss: 9.29265639e-07
Iter: 1021 loss: 9.25351742e-07
Iter: 1022 loss: 9.24954691e-07
Iter: 1023 loss: 9.25618394e-07
Iter: 1024 loss: 9.24758126e-07
Iter: 1025 loss: 9.24329129e-07
Iter: 1026 loss: 9.25042514e-07
Iter: 1027 loss: 9.24126084e-07
Iter: 1028 loss: 9.23714822e-07
Iter: 1029 loss: 9.23540028e-07
Iter: 1030 loss: 9.2331e-07
Iter: 1031 loss: 9.22910772e-07
Iter: 1032 loss: 9.2291225e-07
Iter: 1033 loss: 9.22459947e-07
Iter: 1034 loss: 9.21964443e-07
Iter: 1035 loss: 9.21908622e-07
Iter: 1036 loss: 9.21307731e-07
Iter: 1037 loss: 9.21767082e-07
Iter: 1038 loss: 9.20944672e-07
Iter: 1039 loss: 9.20679213e-07
Iter: 1040 loss: 9.20568255e-07
Iter: 1041 loss: 9.20288e-07
Iter: 1042 loss: 9.19702757e-07
Iter: 1043 loss: 9.29144562e-07
Iter: 1044 loss: 9.19684226e-07
Iter: 1045 loss: 9.19253e-07
Iter: 1046 loss: 9.19252329e-07
Iter: 1047 loss: 9.18836747e-07
Iter: 1048 loss: 9.19509546e-07
Iter: 1049 loss: 9.18606e-07
Iter: 1050 loss: 9.18346757e-07
Iter: 1051 loss: 9.17968464e-07
Iter: 1052 loss: 9.17940156e-07
Iter: 1053 loss: 9.17561579e-07
Iter: 1054 loss: 9.23635525e-07
Iter: 1055 loss: 9.17550892e-07
Iter: 1056 loss: 9.1714594e-07
Iter: 1057 loss: 9.17421175e-07
Iter: 1058 loss: 9.16885881e-07
Iter: 1059 loss: 9.16482293e-07
Iter: 1060 loss: 9.1727776e-07
Iter: 1061 loss: 9.16341833e-07
Iter: 1062 loss: 9.15923692e-07
Iter: 1063 loss: 9.16181534e-07
Iter: 1064 loss: 9.15624696e-07
Iter: 1065 loss: 9.15182e-07
Iter: 1066 loss: 9.18367448e-07
Iter: 1067 loss: 9.15144255e-07
Iter: 1068 loss: 9.14633574e-07
Iter: 1069 loss: 9.160334e-07
Iter: 1070 loss: 9.14466682e-07
Iter: 1071 loss: 9.14186444e-07
Iter: 1072 loss: 9.13756935e-07
Iter: 1073 loss: 9.1377e-07
Iter: 1074 loss: 9.1320976e-07
Iter: 1075 loss: 9.16517422e-07
Iter: 1076 loss: 9.13163831e-07
Iter: 1077 loss: 9.12578344e-07
Iter: 1078 loss: 9.16449665e-07
Iter: 1079 loss: 9.1256112e-07
Iter: 1080 loss: 9.12313226e-07
Iter: 1081 loss: 9.12128712e-07
Iter: 1082 loss: 9.12049927e-07
Iter: 1083 loss: 9.11737857e-07
Iter: 1084 loss: 9.11711e-07
Iter: 1085 loss: 9.1155556e-07
Iter: 1086 loss: 9.11058919e-07
Iter: 1087 loss: 9.15886631e-07
Iter: 1088 loss: 9.10986842e-07
Iter: 1089 loss: 9.10435062e-07
Iter: 1090 loss: 9.12347218e-07
Iter: 1091 loss: 9.10285621e-07
Iter: 1092 loss: 9.09831158e-07
Iter: 1093 loss: 9.09829623e-07
Iter: 1094 loss: 9.09623736e-07
Iter: 1095 loss: 9.09215942e-07
Iter: 1096 loss: 9.16708814e-07
Iter: 1097 loss: 9.0921543e-07
Iter: 1098 loss: 9.08642505e-07
Iter: 1099 loss: 9.10832227e-07
Iter: 1100 loss: 9.08521884e-07
Iter: 1101 loss: 9.08119432e-07
Iter: 1102 loss: 9.10656922e-07
Iter: 1103 loss: 9.08060031e-07
Iter: 1104 loss: 9.07650815e-07
Iter: 1105 loss: 9.09184337e-07
Iter: 1106 loss: 9.07538379e-07
Iter: 1107 loss: 9.07199706e-07
Iter: 1108 loss: 9.06663558e-07
Iter: 1109 loss: 9.06650087e-07
Iter: 1110 loss: 9.0598752e-07
Iter: 1111 loss: 9.06770651e-07
Iter: 1112 loss: 9.05667e-07
Iter: 1113 loss: 9.05047841e-07
Iter: 1114 loss: 9.07020308e-07
Iter: 1115 loss: 9.0485554e-07
Iter: 1116 loss: 9.04505725e-07
Iter: 1117 loss: 9.04478782e-07
Iter: 1118 loss: 9.04071555e-07
Iter: 1119 loss: 9.04759872e-07
Iter: 1120 loss: 9.03920352e-07
Iter: 1121 loss: 9.03654325e-07
Iter: 1122 loss: 9.0331946e-07
Iter: 1123 loss: 9.03284e-07
Iter: 1124 loss: 9.02866645e-07
Iter: 1125 loss: 9.0288e-07
Iter: 1126 loss: 9.02596e-07
Iter: 1127 loss: 9.02171962e-07
Iter: 1128 loss: 9.02170541e-07
Iter: 1129 loss: 9.01919748e-07
Iter: 1130 loss: 9.01912813e-07
Iter: 1131 loss: 9.01637122e-07
Iter: 1132 loss: 9.01214662e-07
Iter: 1133 loss: 9.01218186e-07
Iter: 1134 loss: 9.0078521e-07
Iter: 1135 loss: 9.02199758e-07
Iter: 1136 loss: 9.00652367e-07
Iter: 1137 loss: 9.00167095e-07
Iter: 1138 loss: 9.00993371e-07
Iter: 1139 loss: 8.99935742e-07
Iter: 1140 loss: 8.99647489e-07
Iter: 1141 loss: 8.99627707e-07
Iter: 1142 loss: 8.99394763e-07
Iter: 1143 loss: 8.99147835e-07
Iter: 1144 loss: 8.99100257e-07
Iter: 1145 loss: 8.98708777e-07
Iter: 1146 loss: 8.98408871e-07
Iter: 1147 loss: 8.98295639e-07
Iter: 1148 loss: 8.97861185e-07
Iter: 1149 loss: 9.04802732e-07
Iter: 1150 loss: 8.97855e-07
Iter: 1151 loss: 8.97479254e-07
Iter: 1152 loss: 9.01193744e-07
Iter: 1153 loss: 8.97485961e-07
Iter: 1154 loss: 8.97222435e-07
Iter: 1155 loss: 8.96663778e-07
Iter: 1156 loss: 9.02694637e-07
Iter: 1157 loss: 8.9659e-07
Iter: 1158 loss: 8.9635887e-07
Iter: 1159 loss: 8.96250413e-07
Iter: 1160 loss: 8.95950734e-07
Iter: 1161 loss: 8.95574544e-07
Iter: 1162 loss: 8.95540779e-07
Iter: 1163 loss: 8.95208245e-07
Iter: 1164 loss: 8.98568942e-07
Iter: 1165 loss: 8.95191533e-07
Iter: 1166 loss: 8.94812786e-07
Iter: 1167 loss: 8.94725417e-07
Iter: 1168 loss: 8.94500317e-07
Iter: 1169 loss: 8.94127822e-07
Iter: 1170 loss: 8.94144137e-07
Iter: 1171 loss: 8.93800575e-07
Iter: 1172 loss: 8.93457525e-07
Iter: 1173 loss: 8.97619543e-07
Iter: 1174 loss: 8.9345076e-07
Iter: 1175 loss: 8.93036713e-07
Iter: 1176 loss: 8.93642209e-07
Iter: 1177 loss: 8.92876926e-07
Iter: 1178 loss: 8.92516e-07
Iter: 1179 loss: 8.92823039e-07
Iter: 1180 loss: 8.92300648e-07
Iter: 1181 loss: 8.91817763e-07
Iter: 1182 loss: 8.92271828e-07
Iter: 1183 loss: 8.91551508e-07
Iter: 1184 loss: 8.91076297e-07
Iter: 1185 loss: 8.9310754e-07
Iter: 1186 loss: 8.909592e-07
Iter: 1187 loss: 8.9052412e-07
Iter: 1188 loss: 8.96094036e-07
Iter: 1189 loss: 8.90495301e-07
Iter: 1190 loss: 8.90239335e-07
Iter: 1191 loss: 8.89666751e-07
Iter: 1192 loss: 8.97964355e-07
Iter: 1193 loss: 8.89625426e-07
Iter: 1194 loss: 8.8921945e-07
Iter: 1195 loss: 8.9471007e-07
Iter: 1196 loss: 8.89230591e-07
Iter: 1197 loss: 8.88809836e-07
Iter: 1198 loss: 8.90761441e-07
Iter: 1199 loss: 8.88731506e-07
Iter: 1200 loss: 8.88455531e-07
Iter: 1201 loss: 8.87948204e-07
Iter: 1202 loss: 8.99079112e-07
Iter: 1203 loss: 8.87960766e-07
Iter: 1204 loss: 8.8744838e-07
Iter: 1205 loss: 8.87451165e-07
Iter: 1206 loss: 8.87240958e-07
Iter: 1207 loss: 8.86710609e-07
Iter: 1208 loss: 8.92511366e-07
Iter: 1209 loss: 8.86674798e-07
Iter: 1210 loss: 8.86183045e-07
Iter: 1211 loss: 8.92791093e-07
Iter: 1212 loss: 8.86182363e-07
Iter: 1213 loss: 8.857171e-07
Iter: 1214 loss: 8.87512442e-07
Iter: 1215 loss: 8.85592726e-07
Iter: 1216 loss: 8.85307259e-07
Iter: 1217 loss: 8.84805843e-07
Iter: 1218 loss: 8.8480067e-07
Iter: 1219 loss: 8.84303404e-07
Iter: 1220 loss: 8.89055968e-07
Iter: 1221 loss: 8.84276801e-07
Iter: 1222 loss: 8.83874463e-07
Iter: 1223 loss: 8.84830968e-07
Iter: 1224 loss: 8.83677103e-07
Iter: 1225 loss: 8.83265557e-07
Iter: 1226 loss: 8.8869308e-07
Iter: 1227 loss: 8.8326334e-07
Iter: 1228 loss: 8.83008852e-07
Iter: 1229 loss: 8.82467759e-07
Iter: 1230 loss: 8.90557146e-07
Iter: 1231 loss: 8.82428e-07
Iter: 1232 loss: 8.8211857e-07
Iter: 1233 loss: 8.82096856e-07
Iter: 1234 loss: 8.81760457e-07
Iter: 1235 loss: 8.81294454e-07
Iter: 1236 loss: 8.81260803e-07
Iter: 1237 loss: 8.80793e-07
Iter: 1238 loss: 8.81935591e-07
Iter: 1239 loss: 8.80644848e-07
Iter: 1240 loss: 8.80330958e-07
Iter: 1241 loss: 8.80312e-07
Iter: 1242 loss: 8.80087327e-07
Iter: 1243 loss: 8.79493712e-07
Iter: 1244 loss: 8.83670452e-07
Iter: 1245 loss: 8.79395657e-07
Iter: 1246 loss: 8.78986555e-07
Iter: 1247 loss: 8.78967739e-07
Iter: 1248 loss: 8.78597575e-07
Iter: 1249 loss: 8.79917707e-07
Iter: 1250 loss: 8.78490425e-07
Iter: 1251 loss: 8.78251285e-07
Iter: 1252 loss: 8.77724119e-07
Iter: 1253 loss: 8.85770874e-07
Iter: 1254 loss: 8.77701154e-07
Iter: 1255 loss: 8.77053481e-07
Iter: 1256 loss: 8.80185326e-07
Iter: 1257 loss: 8.76918477e-07
Iter: 1258 loss: 8.76661886e-07
Iter: 1259 loss: 8.76586682e-07
Iter: 1260 loss: 8.76373065e-07
Iter: 1261 loss: 8.7635658e-07
Iter: 1262 loss: 8.76219133e-07
Iter: 1263 loss: 8.75857722e-07
Iter: 1264 loss: 8.75182252e-07
Iter: 1265 loss: 8.88404884e-07
Iter: 1266 loss: 8.75181797e-07
Iter: 1267 loss: 8.75194416e-07
Iter: 1268 loss: 8.7489741e-07
Iter: 1269 loss: 8.74673049e-07
Iter: 1270 loss: 8.74348643e-07
Iter: 1271 loss: 8.7434006e-07
Iter: 1272 loss: 8.739039e-07
Iter: 1273 loss: 8.74765419e-07
Iter: 1274 loss: 8.73779925e-07
Iter: 1275 loss: 8.73362e-07
Iter: 1276 loss: 8.78561764e-07
Iter: 1277 loss: 8.73355134e-07
Iter: 1278 loss: 8.73169768e-07
Iter: 1279 loss: 8.72723092e-07
Iter: 1280 loss: 8.78962908e-07
Iter: 1281 loss: 8.72710189e-07
Iter: 1282 loss: 8.72564e-07
Iter: 1283 loss: 8.72482929e-07
Iter: 1284 loss: 8.72238104e-07
Iter: 1285 loss: 8.71731231e-07
Iter: 1286 loss: 8.79764457e-07
Iter: 1287 loss: 8.71721113e-07
Iter: 1288 loss: 8.71175757e-07
Iter: 1289 loss: 8.7172441e-07
Iter: 1290 loss: 8.70851295e-07
Iter: 1291 loss: 8.70374151e-07
Iter: 1292 loss: 8.7508829e-07
Iter: 1293 loss: 8.70352324e-07
Iter: 1294 loss: 8.69861765e-07
Iter: 1295 loss: 8.73205522e-07
Iter: 1296 loss: 8.69804e-07
Iter: 1297 loss: 8.69487224e-07
Iter: 1298 loss: 8.69329085e-07
Iter: 1299 loss: 8.69204484e-07
Iter: 1300 loss: 8.68800328e-07
Iter: 1301 loss: 8.70906206e-07
Iter: 1302 loss: 8.68754057e-07
Iter: 1303 loss: 8.68501331e-07
Iter: 1304 loss: 8.71078214e-07
Iter: 1305 loss: 8.68490304e-07
Iter: 1306 loss: 8.68266227e-07
Iter: 1307 loss: 8.67745143e-07
Iter: 1308 loss: 8.75377509e-07
Iter: 1309 loss: 8.67728829e-07
Iter: 1310 loss: 8.67422045e-07
Iter: 1311 loss: 8.67430629e-07
Iter: 1312 loss: 8.67070753e-07
Iter: 1313 loss: 8.66946948e-07
Iter: 1314 loss: 8.66752373e-07
Iter: 1315 loss: 8.66426149e-07
Iter: 1316 loss: 8.66590085e-07
Iter: 1317 loss: 8.6619491e-07
Iter: 1318 loss: 8.65846403e-07
Iter: 1319 loss: 8.65840718e-07
Iter: 1320 loss: 8.65611412e-07
Iter: 1321 loss: 8.65121137e-07
Iter: 1322 loss: 8.73371846e-07
Iter: 1323 loss: 8.65098968e-07
Iter: 1324 loss: 8.646374e-07
Iter: 1325 loss: 8.65213337e-07
Iter: 1326 loss: 8.64419349e-07
Iter: 1327 loss: 8.64088179e-07
Iter: 1328 loss: 8.64076e-07
Iter: 1329 loss: 8.63667e-07
Iter: 1330 loss: 8.63829825e-07
Iter: 1331 loss: 8.63397872e-07
Iter: 1332 loss: 8.63095067e-07
Iter: 1333 loss: 8.63530545e-07
Iter: 1334 loss: 8.62971319e-07
Iter: 1335 loss: 8.62588536e-07
Iter: 1336 loss: 8.64191e-07
Iter: 1337 loss: 8.62518505e-07
Iter: 1338 loss: 8.62154593e-07
Iter: 1339 loss: 8.63833577e-07
Iter: 1340 loss: 8.62089848e-07
Iter: 1341 loss: 8.61839908e-07
Iter: 1342 loss: 8.61492936e-07
Iter: 1343 loss: 8.61493049e-07
Iter: 1344 loss: 8.61255899e-07
Iter: 1345 loss: 8.61246576e-07
Iter: 1346 loss: 8.60995385e-07
Iter: 1347 loss: 8.60516934e-07
Iter: 1348 loss: 8.67460699e-07
Iter: 1349 loss: 8.60501e-07
Iter: 1350 loss: 8.60070372e-07
Iter: 1351 loss: 8.64090907e-07
Iter: 1352 loss: 8.60051784e-07
Iter: 1353 loss: 8.5962489e-07
Iter: 1354 loss: 8.61098385e-07
Iter: 1355 loss: 8.59490342e-07
Iter: 1356 loss: 8.5925808e-07
Iter: 1357 loss: 8.58900648e-07
Iter: 1358 loss: 8.58886665e-07
Iter: 1359 loss: 8.5835029e-07
Iter: 1360 loss: 8.58837438e-07
Iter: 1361 loss: 8.58039471e-07
Iter: 1362 loss: 8.57925897e-07
Iter: 1363 loss: 8.578088e-07
Iter: 1364 loss: 8.57493e-07
Iter: 1365 loss: 8.57063e-07
Iter: 1366 loss: 8.57062446e-07
Iter: 1367 loss: 8.56669089e-07
Iter: 1368 loss: 8.57337341e-07
Iter: 1369 loss: 8.56482e-07
Iter: 1370 loss: 8.56054612e-07
Iter: 1371 loss: 8.61480828e-07
Iter: 1372 loss: 8.5606473e-07
Iter: 1373 loss: 8.55792791e-07
Iter: 1374 loss: 8.55875442e-07
Iter: 1375 loss: 8.55551491e-07
Iter: 1376 loss: 8.55226062e-07
Iter: 1377 loss: 8.5563164e-07
Iter: 1378 loss: 8.55012104e-07
Iter: 1379 loss: 8.54658254e-07
Iter: 1380 loss: 8.58365468e-07
Iter: 1381 loss: 8.54654786e-07
Iter: 1382 loss: 8.54334075e-07
Iter: 1383 loss: 8.54023e-07
Iter: 1384 loss: 8.53937536e-07
Iter: 1385 loss: 8.53592951e-07
Iter: 1386 loss: 8.55483222e-07
Iter: 1387 loss: 8.53551228e-07
Iter: 1388 loss: 8.53146162e-07
Iter: 1389 loss: 8.54598e-07
Iter: 1390 loss: 8.53024858e-07
Iter: 1391 loss: 8.52729386e-07
Iter: 1392 loss: 8.52131166e-07
Iter: 1393 loss: 8.6237776e-07
Iter: 1394 loss: 8.52096946e-07
Iter: 1395 loss: 8.51502477e-07
Iter: 1396 loss: 8.54481584e-07
Iter: 1397 loss: 8.51418861e-07
Iter: 1398 loss: 8.5114533e-07
Iter: 1399 loss: 8.51075754e-07
Iter: 1400 loss: 8.50841843e-07
Iter: 1401 loss: 8.50420633e-07
Iter: 1402 loss: 8.60690079e-07
Iter: 1403 loss: 8.50405854e-07
Iter: 1404 loss: 8.50033643e-07
Iter: 1405 loss: 8.5143796e-07
Iter: 1406 loss: 8.49911316e-07
Iter: 1407 loss: 8.49522792e-07
Iter: 1408 loss: 8.53320557e-07
Iter: 1409 loss: 8.49508751e-07
Iter: 1410 loss: 8.49297749e-07
Iter: 1411 loss: 8.4896044e-07
Iter: 1412 loss: 8.48973514e-07
Iter: 1413 loss: 8.48469426e-07
Iter: 1414 loss: 8.51619859e-07
Iter: 1415 loss: 8.48419575e-07
Iter: 1416 loss: 8.48063451e-07
Iter: 1417 loss: 8.50036145e-07
Iter: 1418 loss: 8.47996034e-07
Iter: 1419 loss: 8.4770943e-07
Iter: 1420 loss: 8.47466254e-07
Iter: 1421 loss: 8.47378715e-07
Iter: 1422 loss: 8.47138836e-07
Iter: 1423 loss: 8.47115075e-07
Iter: 1424 loss: 8.4684666e-07
Iter: 1425 loss: 8.46497244e-07
Iter: 1426 loss: 8.46481157e-07
Iter: 1427 loss: 8.46077e-07
Iter: 1428 loss: 8.46250089e-07
Iter: 1429 loss: 8.45814952e-07
Iter: 1430 loss: 8.45348438e-07
Iter: 1431 loss: 8.47026342e-07
Iter: 1432 loss: 8.45257887e-07
Iter: 1433 loss: 8.4472731e-07
Iter: 1434 loss: 8.50011361e-07
Iter: 1435 loss: 8.44719466e-07
Iter: 1436 loss: 8.44428655e-07
Iter: 1437 loss: 8.43813837e-07
Iter: 1438 loss: 8.53134168e-07
Iter: 1439 loss: 8.43779503e-07
Iter: 1440 loss: 8.43699695e-07
Iter: 1441 loss: 8.43557928e-07
Iter: 1442 loss: 8.43303098e-07
Iter: 1443 loss: 8.42782356e-07
Iter: 1444 loss: 8.50950073e-07
Iter: 1445 loss: 8.42778661e-07
Iter: 1446 loss: 8.4243834e-07
Iter: 1447 loss: 8.47276965e-07
Iter: 1448 loss: 8.42422082e-07
Iter: 1449 loss: 8.42129509e-07
Iter: 1450 loss: 8.43069188e-07
Iter: 1451 loss: 8.4202776e-07
Iter: 1452 loss: 8.41734845e-07
Iter: 1453 loss: 8.41902704e-07
Iter: 1454 loss: 8.41512133e-07
Iter: 1455 loss: 8.41135659e-07
Iter: 1456 loss: 8.42049189e-07
Iter: 1457 loss: 8.40997473e-07
Iter: 1458 loss: 8.40577286e-07
Iter: 1459 loss: 8.43189753e-07
Iter: 1460 loss: 8.40532095e-07
Iter: 1461 loss: 8.40206894e-07
Iter: 1462 loss: 8.39698146e-07
Iter: 1463 loss: 8.39686777e-07
Iter: 1464 loss: 8.39189852e-07
Iter: 1465 loss: 8.41355927e-07
Iter: 1466 loss: 8.39099471e-07
Iter: 1467 loss: 8.38872211e-07
Iter: 1468 loss: 8.38808603e-07
Iter: 1469 loss: 8.38624146e-07
Iter: 1470 loss: 8.38157916e-07
Iter: 1471 loss: 8.45249e-07
Iter: 1472 loss: 8.38134213e-07
Iter: 1473 loss: 8.3783118e-07
Iter: 1474 loss: 8.40026644e-07
Iter: 1475 loss: 8.37778316e-07
Iter: 1476 loss: 8.37400648e-07
Iter: 1477 loss: 8.39254767e-07
Iter: 1478 loss: 8.37340622e-07
Iter: 1479 loss: 8.37095399e-07
Iter: 1480 loss: 8.36759341e-07
Iter: 1481 loss: 8.36737399e-07
Iter: 1482 loss: 8.36466e-07
Iter: 1483 loss: 8.36457218e-07
Iter: 1484 loss: 8.36211484e-07
Iter: 1485 loss: 8.36028505e-07
Iter: 1486 loss: 8.35947048e-07
Iter: 1487 loss: 8.35580408e-07
Iter: 1488 loss: 8.36734102e-07
Iter: 1489 loss: 8.35453591e-07
Iter: 1490 loss: 8.3513288e-07
Iter: 1491 loss: 8.36529466e-07
Iter: 1492 loss: 8.35059097e-07
Iter: 1493 loss: 8.34687739e-07
Iter: 1494 loss: 8.35161927e-07
Iter: 1495 loss: 8.34463776e-07
Iter: 1496 loss: 8.34152104e-07
Iter: 1497 loss: 8.33819513e-07
Iter: 1498 loss: 8.33784895e-07
Iter: 1499 loss: 8.3346481e-07
Iter: 1500 loss: 8.33451168e-07
Iter: 1501 loss: 8.33125853e-07
Iter: 1502 loss: 8.33539502e-07
Iter: 1503 loss: 8.32899559e-07
Iter: 1504 loss: 8.32674402e-07
Iter: 1505 loss: 8.32261776e-07
Iter: 1506 loss: 8.32274225e-07
Iter: 1507 loss: 8.32085334e-07
Iter: 1508 loss: 8.31972841e-07
Iter: 1509 loss: 8.31751663e-07
Iter: 1510 loss: 8.3131431e-07
Iter: 1511 loss: 8.39725431e-07
Iter: 1512 loss: 8.3130567e-07
Iter: 1513 loss: 8.30986494e-07
Iter: 1514 loss: 8.34606283e-07
Iter: 1515 loss: 8.30982174e-07
Iter: 1516 loss: 8.30626334e-07
Iter: 1517 loss: 8.31741e-07
Iter: 1518 loss: 8.30518388e-07
Iter: 1519 loss: 8.30277656e-07
Iter: 1520 loss: 8.30330748e-07
Iter: 1521 loss: 8.3009661e-07
Iter: 1522 loss: 8.2971394e-07
Iter: 1523 loss: 8.31009345e-07
Iter: 1524 loss: 8.29629414e-07
Iter: 1525 loss: 8.29306771e-07
Iter: 1526 loss: 8.32016667e-07
Iter: 1527 loss: 8.29312455e-07
Iter: 1528 loss: 8.29115152e-07
Iter: 1529 loss: 8.28709233e-07
Iter: 1530 loss: 8.35008734e-07
Iter: 1531 loss: 8.28696e-07
Iter: 1532 loss: 8.28253917e-07
Iter: 1533 loss: 8.31126215e-07
Iter: 1534 loss: 8.28193265e-07
Iter: 1535 loss: 8.27884719e-07
Iter: 1536 loss: 8.27887e-07
Iter: 1537 loss: 8.27726467e-07
Iter: 1538 loss: 8.27280815e-07
Iter: 1539 loss: 8.29495e-07
Iter: 1540 loss: 8.2713035e-07
Iter: 1541 loss: 8.26792871e-07
Iter: 1542 loss: 8.2677974e-07
Iter: 1543 loss: 8.26421228e-07
Iter: 1544 loss: 8.26450616e-07
Iter: 1545 loss: 8.26138148e-07
Iter: 1546 loss: 8.25856603e-07
Iter: 1547 loss: 8.2595335e-07
Iter: 1548 loss: 8.25621044e-07
Iter: 1549 loss: 8.25340294e-07
Iter: 1550 loss: 8.25326197e-07
Iter: 1551 loss: 8.25113432e-07
Iter: 1552 loss: 8.24812787e-07
Iter: 1553 loss: 8.24824838e-07
Iter: 1554 loss: 8.24474e-07
Iter: 1555 loss: 8.27571057e-07
Iter: 1556 loss: 8.24461495e-07
Iter: 1557 loss: 8.24207632e-07
Iter: 1558 loss: 8.25307325e-07
Iter: 1559 loss: 8.24162441e-07
Iter: 1560 loss: 8.2388749e-07
Iter: 1561 loss: 8.23516416e-07
Iter: 1562 loss: 8.23491177e-07
Iter: 1563 loss: 8.23076334e-07
Iter: 1564 loss: 8.24313929e-07
Iter: 1565 loss: 8.22930815e-07
Iter: 1566 loss: 8.22853679e-07
Iter: 1567 loss: 8.22756874e-07
Iter: 1568 loss: 8.22597e-07
Iter: 1569 loss: 8.22124321e-07
Iter: 1570 loss: 8.2509348e-07
Iter: 1571 loss: 8.21992899e-07
Iter: 1572 loss: 8.21551339e-07
Iter: 1573 loss: 8.24468316e-07
Iter: 1574 loss: 8.21512401e-07
Iter: 1575 loss: 8.21127969e-07
Iter: 1576 loss: 8.26223641e-07
Iter: 1577 loss: 8.21127799e-07
Iter: 1578 loss: 8.20928108e-07
Iter: 1579 loss: 8.20497462e-07
Iter: 1580 loss: 8.25952e-07
Iter: 1581 loss: 8.20476487e-07
Iter: 1582 loss: 8.20293053e-07
Iter: 1583 loss: 8.20233538e-07
Iter: 1584 loss: 8.19997354e-07
Iter: 1585 loss: 8.19657942e-07
Iter: 1586 loss: 8.1963617e-07
Iter: 1587 loss: 8.19305114e-07
Iter: 1588 loss: 8.20655373e-07
Iter: 1589 loss: 8.19226e-07
Iter: 1590 loss: 8.18855597e-07
Iter: 1591 loss: 8.20808623e-07
Iter: 1592 loss: 8.18788237e-07
Iter: 1593 loss: 8.18474348e-07
Iter: 1594 loss: 8.18680178e-07
Iter: 1595 loss: 8.18244e-07
Iter: 1596 loss: 8.17922341e-07
Iter: 1597 loss: 8.18181661e-07
Iter: 1598 loss: 8.17733564e-07
Iter: 1599 loss: 8.17405123e-07
Iter: 1600 loss: 8.18596391e-07
Iter: 1601 loss: 8.17309456e-07
Iter: 1602 loss: 8.16902912e-07
Iter: 1603 loss: 8.19113779e-07
Iter: 1604 loss: 8.16831061e-07
Iter: 1605 loss: 8.16637566e-07
Iter: 1606 loss: 8.16246029e-07
Iter: 1607 loss: 8.24352242e-07
Iter: 1608 loss: 8.16243812e-07
Iter: 1609 loss: 8.16067086e-07
Iter: 1610 loss: 8.16001943e-07
Iter: 1611 loss: 8.15781732e-07
Iter: 1612 loss: 8.15347335e-07
Iter: 1613 loss: 8.24200924e-07
Iter: 1614 loss: 8.15344038e-07
Iter: 1615 loss: 8.15011333e-07
Iter: 1616 loss: 8.17094133e-07
Iter: 1617 loss: 8.14967393e-07
Iter: 1618 loss: 8.14661291e-07
Iter: 1619 loss: 8.17577302e-07
Iter: 1620 loss: 8.14636905e-07
Iter: 1621 loss: 8.14465466e-07
Iter: 1622 loss: 8.14190287e-07
Iter: 1623 loss: 8.14185739e-07
Iter: 1624 loss: 8.13870543e-07
Iter: 1625 loss: 8.17157456e-07
Iter: 1626 loss: 8.13890324e-07
Iter: 1627 loss: 8.13583483e-07
Iter: 1628 loss: 8.13838824e-07
Iter: 1629 loss: 8.1342e-07
Iter: 1630 loss: 8.13099916e-07
Iter: 1631 loss: 8.13435463e-07
Iter: 1632 loss: 8.12912901e-07
Iter: 1633 loss: 8.12633061e-07
Iter: 1634 loss: 8.12492e-07
Iter: 1635 loss: 8.12339863e-07
Iter: 1636 loss: 8.12271651e-07
Iter: 1637 loss: 8.12144094e-07
Iter: 1638 loss: 8.11978e-07
Iter: 1639 loss: 8.11582538e-07
Iter: 1640 loss: 8.15312887e-07
Iter: 1641 loss: 8.11507675e-07
Iter: 1642 loss: 8.11172242e-07
Iter: 1643 loss: 8.14210239e-07
Iter: 1644 loss: 8.11141035e-07
Iter: 1645 loss: 8.10787355e-07
Iter: 1646 loss: 8.12604299e-07
Iter: 1647 loss: 8.10733809e-07
Iter: 1648 loss: 8.10505e-07
Iter: 1649 loss: 8.10115694e-07
Iter: 1650 loss: 8.10114216e-07
Iter: 1651 loss: 8.09843868e-07
Iter: 1652 loss: 8.09820847e-07
Iter: 1653 loss: 8.09605751e-07
Iter: 1654 loss: 8.09247865e-07
Iter: 1655 loss: 8.09232233e-07
Iter: 1656 loss: 8.08863206e-07
Iter: 1657 loss: 8.09172093e-07
Iter: 1658 loss: 8.08619347e-07
Iter: 1659 loss: 8.08434436e-07
Iter: 1660 loss: 8.08332743e-07
Iter: 1661 loss: 8.08179266e-07
Iter: 1662 loss: 8.08061486e-07
Iter: 1663 loss: 8.08011805e-07
Iter: 1664 loss: 8.07738161e-07
Iter: 1665 loss: 8.07802792e-07
Iter: 1666 loss: 8.0751829e-07
Iter: 1667 loss: 8.0726204e-07
Iter: 1668 loss: 8.10736367e-07
Iter: 1669 loss: 8.07279321e-07
Iter: 1670 loss: 8.0700579e-07
Iter: 1671 loss: 8.07254253e-07
Iter: 1672 loss: 8.06859191e-07
Iter: 1673 loss: 8.06613e-07
Iter: 1674 loss: 8.06484422e-07
Iter: 1675 loss: 8.06394041e-07
Iter: 1676 loss: 8.06193498e-07
Iter: 1677 loss: 8.06195203e-07
Iter: 1678 loss: 8.05988293e-07
Iter: 1679 loss: 8.05617674e-07
Iter: 1680 loss: 8.14666e-07
Iter: 1681 loss: 8.05607044e-07
Iter: 1682 loss: 8.05390243e-07
Iter: 1683 loss: 8.08713764e-07
Iter: 1684 loss: 8.0539138e-07
Iter: 1685 loss: 8.05144623e-07
Iter: 1686 loss: 8.05103582e-07
Iter: 1687 loss: 8.04946e-07
Iter: 1688 loss: 8.04660317e-07
Iter: 1689 loss: 8.043761e-07
Iter: 1690 loss: 8.04293506e-07
Iter: 1691 loss: 8.03887644e-07
Iter: 1692 loss: 8.08886739e-07
Iter: 1693 loss: 8.03889748e-07
Iter: 1694 loss: 8.03572277e-07
Iter: 1695 loss: 8.06077196e-07
Iter: 1696 loss: 8.03527371e-07
Iter: 1697 loss: 8.03339219e-07
Iter: 1698 loss: 8.03154421e-07
Iter: 1699 loss: 8.03110936e-07
Iter: 1700 loss: 8.02796649e-07
Iter: 1701 loss: 8.04732281e-07
Iter: 1702 loss: 8.02762372e-07
Iter: 1703 loss: 8.02568536e-07
Iter: 1704 loss: 8.04660885e-07
Iter: 1705 loss: 8.02557508e-07
Iter: 1706 loss: 8.02403861e-07
Iter: 1707 loss: 8.02099123e-07
Iter: 1708 loss: 8.08636969e-07
Iter: 1709 loss: 8.02099635e-07
Iter: 1710 loss: 8.01788e-07
Iter: 1711 loss: 8.02783916e-07
Iter: 1712 loss: 8.0170571e-07
Iter: 1713 loss: 8.01312922e-07
Iter: 1714 loss: 8.03937837e-07
Iter: 1715 loss: 8.01264264e-07
Iter: 1716 loss: 8.01071963e-07
Iter: 1717 loss: 8.00897681e-07
Iter: 1718 loss: 8.00852263e-07
Iter: 1719 loss: 8.00603743e-07
Iter: 1720 loss: 8.00602606e-07
Iter: 1721 loss: 8.00413e-07
Iter: 1722 loss: 7.99985287e-07
Iter: 1723 loss: 8.07631e-07
Iter: 1724 loss: 8.0001e-07
Iter: 1725 loss: 7.99636609e-07
Iter: 1726 loss: 8.00543887e-07
Iter: 1727 loss: 7.99485179e-07
Iter: 1728 loss: 7.99254167e-07
Iter: 1729 loss: 7.9922745e-07
Iter: 1730 loss: 7.99042141e-07
Iter: 1731 loss: 7.98918279e-07
Iter: 1732 loss: 7.98846258e-07
Iter: 1733 loss: 7.98575115e-07
Iter: 1734 loss: 7.98898782e-07
Iter: 1735 loss: 7.98421297e-07
Iter: 1736 loss: 7.98097403e-07
Iter: 1737 loss: 8.01377155e-07
Iter: 1738 loss: 7.98085125e-07
Iter: 1739 loss: 7.97841949e-07
Iter: 1740 loss: 7.98014071e-07
Iter: 1741 loss: 7.97698249e-07
Iter: 1742 loss: 7.97486109e-07
Iter: 1743 loss: 7.97372081e-07
Iter: 1744 loss: 7.97283064e-07
Iter: 1745 loss: 7.97059e-07
Iter: 1746 loss: 7.97041366e-07
Iter: 1747 loss: 7.96851964e-07
Iter: 1748 loss: 7.96512097e-07
Iter: 1749 loss: 7.96513461e-07
Iter: 1750 loss: 7.9628677e-07
Iter: 1751 loss: 7.9887684e-07
Iter: 1752 loss: 7.96281e-07
Iter: 1753 loss: 7.96019776e-07
Iter: 1754 loss: 7.96152221e-07
Iter: 1755 loss: 7.95839696e-07
Iter: 1756 loss: 7.95594929e-07
Iter: 1757 loss: 7.95253072e-07
Iter: 1758 loss: 7.95221524e-07
Iter: 1759 loss: 7.94944299e-07
Iter: 1760 loss: 7.94937591e-07
Iter: 1761 loss: 7.94680261e-07
Iter: 1762 loss: 7.95651545e-07
Iter: 1763 loss: 7.94626317e-07
Iter: 1764 loss: 7.94404173e-07
Iter: 1765 loss: 7.94281505e-07
Iter: 1766 loss: 7.94170774e-07
Iter: 1767 loss: 7.93915035e-07
Iter: 1768 loss: 7.97280563e-07
Iter: 1769 loss: 7.93912477e-07
Iter: 1770 loss: 7.93717959e-07
Iter: 1771 loss: 7.94249331e-07
Iter: 1772 loss: 7.93612685e-07
Iter: 1773 loss: 7.93417769e-07
Iter: 1774 loss: 7.93069091e-07
Iter: 1775 loss: 8.0215932e-07
Iter: 1776 loss: 7.93068807e-07
Iter: 1777 loss: 7.92745254e-07
Iter: 1778 loss: 7.97257655e-07
Iter: 1779 loss: 7.92749574e-07
Iter: 1780 loss: 7.92442108e-07
Iter: 1781 loss: 7.93564141e-07
Iter: 1782 loss: 7.92345759e-07
Iter: 1783 loss: 7.92195692e-07
Iter: 1784 loss: 7.92031642e-07
Iter: 1785 loss: 7.91993443e-07
Iter: 1786 loss: 7.91740945e-07
Iter: 1787 loss: 7.95714584e-07
Iter: 1788 loss: 7.9173941e-07
Iter: 1789 loss: 7.91561945e-07
Iter: 1790 loss: 7.91211e-07
Iter: 1791 loss: 7.97794883e-07
Iter: 1792 loss: 7.91197e-07
Iter: 1793 loss: 7.90856404e-07
Iter: 1794 loss: 7.92048183e-07
Iter: 1795 loss: 7.90778529e-07
Iter: 1796 loss: 7.90560421e-07
Iter: 1797 loss: 7.90537911e-07
Iter: 1798 loss: 7.90383297e-07
Iter: 1799 loss: 7.90055765e-07
Iter: 1800 loss: 7.97147436e-07
Iter: 1801 loss: 7.90055594e-07
Iter: 1802 loss: 7.89775186e-07
Iter: 1803 loss: 7.89777687e-07
Iter: 1804 loss: 7.89605906e-07
Iter: 1805 loss: 7.90326965e-07
Iter: 1806 loss: 7.89541787e-07
Iter: 1807 loss: 7.89342778e-07
Iter: 1808 loss: 7.89162755e-07
Iter: 1809 loss: 7.89142632e-07
Iter: 1810 loss: 7.88849775e-07
Iter: 1811 loss: 7.89437649e-07
Iter: 1812 loss: 7.88721081e-07
Iter: 1813 loss: 7.88451416e-07
Iter: 1814 loss: 7.88453519e-07
Iter: 1815 loss: 7.88271791e-07
Iter: 1816 loss: 7.87912256e-07
Iter: 1817 loss: 7.95186565e-07
Iter: 1818 loss: 7.87914871e-07
Iter: 1819 loss: 7.87694717e-07
Iter: 1820 loss: 7.876788e-07
Iter: 1821 loss: 7.87431873e-07
Iter: 1822 loss: 7.87110253e-07
Iter: 1823 loss: 7.87112526e-07
Iter: 1824 loss: 7.86808e-07
Iter: 1825 loss: 7.87155727e-07
Iter: 1826 loss: 7.86641067e-07
Iter: 1827 loss: 7.86480825e-07
Iter: 1828 loss: 7.86451835e-07
Iter: 1829 loss: 7.86266924e-07
Iter: 1830 loss: 7.86076839e-07
Iter: 1831 loss: 7.86067346e-07
Iter: 1832 loss: 7.85737257e-07
Iter: 1833 loss: 7.86735882e-07
Iter: 1834 loss: 7.85672341e-07
Iter: 1835 loss: 7.8536641e-07
Iter: 1836 loss: 7.8868328e-07
Iter: 1837 loss: 7.85358111e-07
Iter: 1838 loss: 7.85181783e-07
Iter: 1839 loss: 7.85211569e-07
Iter: 1840 loss: 7.85037457e-07
Iter: 1841 loss: 7.84811789e-07
Iter: 1842 loss: 7.84557415e-07
Iter: 1843 loss: 7.845141e-07
Iter: 1844 loss: 7.84388362e-07
Iter: 1845 loss: 7.8433834e-07
Iter: 1846 loss: 7.84167867e-07
Iter: 1847 loss: 7.83891096e-07
Iter: 1848 loss: 7.83902124e-07
Iter: 1849 loss: 7.83639621e-07
Iter: 1850 loss: 7.85167458e-07
Iter: 1851 loss: 7.83625069e-07
Iter: 1852 loss: 7.8333278e-07
Iter: 1853 loss: 7.84282406e-07
Iter: 1854 loss: 7.83253881e-07
Iter: 1855 loss: 7.83023097e-07
Iter: 1856 loss: 7.82622237e-07
Iter: 1857 loss: 7.92655555e-07
Iter: 1858 loss: 7.826103e-07
Iter: 1859 loss: 7.8231534e-07
Iter: 1860 loss: 7.8553353e-07
Iter: 1861 loss: 7.82307666e-07
Iter: 1862 loss: 7.82010716e-07
Iter: 1863 loss: 7.84107954e-07
Iter: 1864 loss: 7.81998665e-07
Iter: 1865 loss: 7.81802214e-07
Iter: 1866 loss: 7.81637254e-07
Iter: 1867 loss: 7.81614403e-07
Iter: 1868 loss: 7.81398796e-07
Iter: 1869 loss: 7.81398285e-07
Iter: 1870 loss: 7.81235656e-07
Iter: 1871 loss: 7.8120479e-07
Iter: 1872 loss: 7.81096e-07
Iter: 1873 loss: 7.80879191e-07
Iter: 1874 loss: 7.80734581e-07
Iter: 1875 loss: 7.80633172e-07
Iter: 1876 loss: 7.80352138e-07
Iter: 1877 loss: 7.82563461e-07
Iter: 1878 loss: 7.80328833e-07
Iter: 1879 loss: 7.80042569e-07
Iter: 1880 loss: 7.81145218e-07
Iter: 1881 loss: 7.79969184e-07
Iter: 1882 loss: 7.79752e-07
Iter: 1883 loss: 7.79509264e-07
Iter: 1884 loss: 7.79458446e-07
Iter: 1885 loss: 7.79333732e-07
Iter: 1886 loss: 7.79283141e-07
Iter: 1887 loss: 7.79140407e-07
Iter: 1888 loss: 7.78795652e-07
Iter: 1889 loss: 7.8307869e-07
Iter: 1890 loss: 7.78772915e-07
Iter: 1891 loss: 7.78472327e-07
Iter: 1892 loss: 7.79751133e-07
Iter: 1893 loss: 7.78403944e-07
Iter: 1894 loss: 7.7818e-07
Iter: 1895 loss: 7.81223434e-07
Iter: 1896 loss: 7.7817981e-07
Iter: 1897 loss: 7.77970854e-07
Iter: 1898 loss: 7.77566356e-07
Iter: 1899 loss: 7.77564878e-07
Iter: 1900 loss: 7.77286573e-07
Iter: 1901 loss: 7.80985374e-07
Iter: 1902 loss: 7.77279411e-07
Iter: 1903 loss: 7.76980755e-07
Iter: 1904 loss: 7.77632295e-07
Iter: 1905 loss: 7.76880483e-07
Iter: 1906 loss: 7.76659704e-07
Iter: 1907 loss: 7.7692323e-07
Iter: 1908 loss: 7.76534478e-07
Iter: 1909 loss: 7.76298748e-07
Iter: 1910 loss: 7.76572165e-07
Iter: 1911 loss: 7.76187676e-07
Iter: 1912 loss: 7.76034881e-07
Iter: 1913 loss: 7.76024933e-07
Iter: 1914 loss: 7.75905164e-07
Iter: 1915 loss: 7.75672561e-07
Iter: 1916 loss: 7.79892105e-07
Iter: 1917 loss: 7.75671367e-07
Iter: 1918 loss: 7.75476906e-07
Iter: 1919 loss: 7.77920036e-07
Iter: 1920 loss: 7.75459739e-07
Iter: 1921 loss: 7.75211845e-07
Iter: 1922 loss: 7.74982595e-07
Iter: 1923 loss: 7.74945534e-07
Iter: 1924 loss: 7.74653699e-07
Iter: 1925 loss: 7.74861576e-07
Iter: 1926 loss: 7.74491e-07
Iter: 1927 loss: 7.74188436e-07
Iter: 1928 loss: 7.76803176e-07
Iter: 1929 loss: 7.74167802e-07
Iter: 1930 loss: 7.73830152e-07
Iter: 1931 loss: 7.75072863e-07
Iter: 1932 loss: 7.73748411e-07
Iter: 1933 loss: 7.73585157e-07
Iter: 1934 loss: 7.73382567e-07
Iter: 1935 loss: 7.73359602e-07
Iter: 1936 loss: 7.73187821e-07
Iter: 1937 loss: 7.73136719e-07
Iter: 1938 loss: 7.73024112e-07
Iter: 1939 loss: 7.72736598e-07
Iter: 1940 loss: 7.77231548e-07
Iter: 1941 loss: 7.72757403e-07
Iter: 1942 loss: 7.72425665e-07
Iter: 1943 loss: 7.73829e-07
Iter: 1944 loss: 7.72384055e-07
Iter: 1945 loss: 7.72179476e-07
Iter: 1946 loss: 7.74043144e-07
Iter: 1947 loss: 7.72155488e-07
Iter: 1948 loss: 7.71965631e-07
Iter: 1949 loss: 7.72253884e-07
Iter: 1950 loss: 7.71857856e-07
Iter: 1951 loss: 7.71684824e-07
Iter: 1952 loss: 7.71525436e-07
Iter: 1953 loss: 7.71485475e-07
Iter: 1954 loss: 7.71149303e-07
Iter: 1955 loss: 7.75221224e-07
Iter: 1956 loss: 7.71142766e-07
Iter: 1957 loss: 7.71012935e-07
Iter: 1958 loss: 7.70780957e-07
Iter: 1959 loss: 7.70788688e-07
Iter: 1960 loss: 7.70511122e-07
Iter: 1961 loss: 7.72009685e-07
Iter: 1962 loss: 7.70479e-07
Iter: 1963 loss: 7.70234351e-07
Iter: 1964 loss: 7.72841759e-07
Iter: 1965 loss: 7.70232e-07
Iter: 1966 loss: 7.70073541e-07
Iter: 1967 loss: 7.69794042e-07
Iter: 1968 loss: 7.75797048e-07
Iter: 1969 loss: 7.697966e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2
+ date
Mon Oct 26 15:24:07 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 1.2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025aff2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025b04bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025b04be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025b128e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025afe8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025afe8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025af940d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025af3b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025af94400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025af44d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025af449d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025aeda9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025aeda6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025aeda400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025ae3b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025adeed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025ae22378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025adf7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025addc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025addc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025ad6e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025ad6e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f025ad1bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257fb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257fbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0225831378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257fb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257f7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257e3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02257b6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0225762488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f022576a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01e00a49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01e00c3a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01e006e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.8951723e-06
Iter: 2 loss: 8.45809427e-06
Iter: 3 loss: 2.1268781e-05
Iter: 4 loss: 8.38663527e-06
Iter: 5 loss: 7.71410669e-06
Iter: 6 loss: 1.07699725e-05
Iter: 7 loss: 7.58482247e-06
Iter: 8 loss: 7.11433813e-06
Iter: 9 loss: 7.4481668e-06
Iter: 10 loss: 6.82265909e-06
Iter: 11 loss: 6.47269326e-06
Iter: 12 loss: 1.13694041e-05
Iter: 13 loss: 6.4717824e-06
Iter: 14 loss: 6.19444e-06
Iter: 15 loss: 6.1684741e-06
Iter: 16 loss: 5.96433665e-06
Iter: 17 loss: 5.69444865e-06
Iter: 18 loss: 6.54799e-06
Iter: 19 loss: 5.61690285e-06
Iter: 20 loss: 5.31026035e-06
Iter: 21 loss: 6.46207536e-06
Iter: 22 loss: 5.23634208e-06
Iter: 23 loss: 4.98875852e-06
Iter: 24 loss: 4.71681096e-06
Iter: 25 loss: 4.67688142e-06
Iter: 26 loss: 4.61001218e-06
Iter: 27 loss: 4.52956829e-06
Iter: 28 loss: 4.39661835e-06
Iter: 29 loss: 4.20600918e-06
Iter: 30 loss: 4.19985327e-06
Iter: 31 loss: 4.0233831e-06
Iter: 32 loss: 3.97545182e-06
Iter: 33 loss: 3.8666094e-06
Iter: 34 loss: 3.60474473e-06
Iter: 35 loss: 5.02901e-06
Iter: 36 loss: 3.56611e-06
Iter: 37 loss: 3.3910012e-06
Iter: 38 loss: 3.67649682e-06
Iter: 39 loss: 3.31067781e-06
Iter: 40 loss: 3.203907e-06
Iter: 41 loss: 3.17890158e-06
Iter: 42 loss: 3.10091355e-06
Iter: 43 loss: 3.03677416e-06
Iter: 44 loss: 3.01420869e-06
Iter: 45 loss: 2.95110704e-06
Iter: 46 loss: 2.95005475e-06
Iter: 47 loss: 2.89613e-06
Iter: 48 loss: 2.86043382e-06
Iter: 49 loss: 2.84001635e-06
Iter: 50 loss: 2.75304183e-06
Iter: 51 loss: 2.98547047e-06
Iter: 52 loss: 2.72416719e-06
Iter: 53 loss: 2.66357483e-06
Iter: 54 loss: 3.21172706e-06
Iter: 55 loss: 2.66083703e-06
Iter: 56 loss: 2.61193759e-06
Iter: 57 loss: 2.53599137e-06
Iter: 58 loss: 2.53494545e-06
Iter: 59 loss: 2.46193144e-06
Iter: 60 loss: 3.29697104e-06
Iter: 61 loss: 2.46074796e-06
Iter: 62 loss: 2.40020768e-06
Iter: 63 loss: 2.72596412e-06
Iter: 64 loss: 2.39105611e-06
Iter: 65 loss: 2.35296443e-06
Iter: 66 loss: 2.30584556e-06
Iter: 67 loss: 2.30170667e-06
Iter: 68 loss: 2.25269469e-06
Iter: 69 loss: 2.28753947e-06
Iter: 70 loss: 2.22236e-06
Iter: 71 loss: 2.16454032e-06
Iter: 72 loss: 2.57191186e-06
Iter: 73 loss: 2.15931959e-06
Iter: 74 loss: 2.13781891e-06
Iter: 75 loss: 2.13452176e-06
Iter: 76 loss: 2.11140718e-06
Iter: 77 loss: 2.09626569e-06
Iter: 78 loss: 2.08739357e-06
Iter: 79 loss: 2.06082404e-06
Iter: 80 loss: 2.17046272e-06
Iter: 81 loss: 2.05508422e-06
Iter: 82 loss: 2.01746161e-06
Iter: 83 loss: 2.03661079e-06
Iter: 84 loss: 1.99241799e-06
Iter: 85 loss: 1.97001e-06
Iter: 86 loss: 2.06933669e-06
Iter: 87 loss: 1.96565566e-06
Iter: 88 loss: 1.93973528e-06
Iter: 89 loss: 1.97650661e-06
Iter: 90 loss: 1.92708626e-06
Iter: 91 loss: 1.90497099e-06
Iter: 92 loss: 2.00605382e-06
Iter: 93 loss: 1.90073592e-06
Iter: 94 loss: 1.88224055e-06
Iter: 95 loss: 1.88634499e-06
Iter: 96 loss: 1.86856028e-06
Iter: 97 loss: 1.84540602e-06
Iter: 98 loss: 2.15857062e-06
Iter: 99 loss: 1.8453087e-06
Iter: 100 loss: 1.8336807e-06
Iter: 101 loss: 1.81324447e-06
Iter: 102 loss: 1.81325015e-06
Iter: 103 loss: 1.7882187e-06
Iter: 104 loss: 1.82162546e-06
Iter: 105 loss: 1.77560696e-06
Iter: 106 loss: 1.74994261e-06
Iter: 107 loss: 1.83249961e-06
Iter: 108 loss: 1.74274328e-06
Iter: 109 loss: 1.73433227e-06
Iter: 110 loss: 1.73169451e-06
Iter: 111 loss: 1.71900319e-06
Iter: 112 loss: 1.69979626e-06
Iter: 113 loss: 1.6994552e-06
Iter: 114 loss: 1.68684915e-06
Iter: 115 loss: 1.68684028e-06
Iter: 116 loss: 1.67489134e-06
Iter: 117 loss: 1.68453971e-06
Iter: 118 loss: 1.66776454e-06
Iter: 119 loss: 1.65686583e-06
Iter: 120 loss: 1.65498057e-06
Iter: 121 loss: 1.6475135e-06
Iter: 122 loss: 1.63532843e-06
Iter: 123 loss: 1.82552367e-06
Iter: 124 loss: 1.63533105e-06
Iter: 125 loss: 1.62630863e-06
Iter: 126 loss: 1.62265451e-06
Iter: 127 loss: 1.61786966e-06
Iter: 128 loss: 1.608611e-06
Iter: 129 loss: 1.66965765e-06
Iter: 130 loss: 1.60767843e-06
Iter: 131 loss: 1.59742069e-06
Iter: 132 loss: 1.61332764e-06
Iter: 133 loss: 1.59258957e-06
Iter: 134 loss: 1.58154944e-06
Iter: 135 loss: 1.60458399e-06
Iter: 136 loss: 1.57712384e-06
Iter: 137 loss: 1.56809051e-06
Iter: 138 loss: 1.55984844e-06
Iter: 139 loss: 1.55766134e-06
Iter: 140 loss: 1.54318877e-06
Iter: 141 loss: 1.56866406e-06
Iter: 142 loss: 1.53681458e-06
Iter: 143 loss: 1.53213648e-06
Iter: 144 loss: 1.52967266e-06
Iter: 145 loss: 1.52248867e-06
Iter: 146 loss: 1.5277069e-06
Iter: 147 loss: 1.51802692e-06
Iter: 148 loss: 1.51186487e-06
Iter: 149 loss: 1.52310645e-06
Iter: 150 loss: 1.5092146e-06
Iter: 151 loss: 1.50092524e-06
Iter: 152 loss: 1.53999451e-06
Iter: 153 loss: 1.49936011e-06
Iter: 154 loss: 1.49335176e-06
Iter: 155 loss: 1.48222193e-06
Iter: 156 loss: 1.73760486e-06
Iter: 157 loss: 1.48222705e-06
Iter: 158 loss: 1.47778076e-06
Iter: 159 loss: 1.4763591e-06
Iter: 160 loss: 1.47101264e-06
Iter: 161 loss: 1.46348498e-06
Iter: 162 loss: 1.46317166e-06
Iter: 163 loss: 1.45558715e-06
Iter: 164 loss: 1.50944118e-06
Iter: 165 loss: 1.45488502e-06
Iter: 166 loss: 1.44751459e-06
Iter: 167 loss: 1.48415825e-06
Iter: 168 loss: 1.4462928e-06
Iter: 169 loss: 1.44158025e-06
Iter: 170 loss: 1.44363639e-06
Iter: 171 loss: 1.43831949e-06
Iter: 172 loss: 1.43223451e-06
Iter: 173 loss: 1.43285047e-06
Iter: 174 loss: 1.42752242e-06
Iter: 175 loss: 1.41850524e-06
Iter: 176 loss: 1.43906129e-06
Iter: 177 loss: 1.41513783e-06
Iter: 178 loss: 1.40806958e-06
Iter: 179 loss: 1.4286918e-06
Iter: 180 loss: 1.40586599e-06
Iter: 181 loss: 1.40140173e-06
Iter: 182 loss: 1.40076486e-06
Iter: 183 loss: 1.39862948e-06
Iter: 184 loss: 1.39363169e-06
Iter: 185 loss: 1.45175443e-06
Iter: 186 loss: 1.3931508e-06
Iter: 187 loss: 1.3875881e-06
Iter: 188 loss: 1.38756718e-06
Iter: 189 loss: 1.38435951e-06
Iter: 190 loss: 1.38046198e-06
Iter: 191 loss: 1.38009386e-06
Iter: 192 loss: 1.37447046e-06
Iter: 193 loss: 1.37450024e-06
Iter: 194 loss: 1.37001189e-06
Iter: 195 loss: 1.36345113e-06
Iter: 196 loss: 1.36339713e-06
Iter: 197 loss: 1.36035328e-06
Iter: 198 loss: 1.35596372e-06
Iter: 199 loss: 1.35580399e-06
Iter: 200 loss: 1.35244204e-06
Iter: 201 loss: 1.35230744e-06
Iter: 202 loss: 1.34880588e-06
Iter: 203 loss: 1.34222864e-06
Iter: 204 loss: 1.48894503e-06
Iter: 205 loss: 1.34221204e-06
Iter: 206 loss: 1.33636263e-06
Iter: 207 loss: 1.35929702e-06
Iter: 208 loss: 1.33509684e-06
Iter: 209 loss: 1.3296924e-06
Iter: 210 loss: 1.34490153e-06
Iter: 211 loss: 1.32794253e-06
Iter: 212 loss: 1.32241826e-06
Iter: 213 loss: 1.3394216e-06
Iter: 214 loss: 1.32078094e-06
Iter: 215 loss: 1.31791603e-06
Iter: 216 loss: 1.31775391e-06
Iter: 217 loss: 1.31487661e-06
Iter: 218 loss: 1.31098273e-06
Iter: 219 loss: 1.3107699e-06
Iter: 220 loss: 1.3077597e-06
Iter: 221 loss: 1.33901938e-06
Iter: 222 loss: 1.30766966e-06
Iter: 223 loss: 1.30442061e-06
Iter: 224 loss: 1.30551098e-06
Iter: 225 loss: 1.30211606e-06
Iter: 226 loss: 1.29900695e-06
Iter: 227 loss: 1.29341379e-06
Iter: 228 loss: 1.42881458e-06
Iter: 229 loss: 1.29340265e-06
Iter: 230 loss: 1.29409705e-06
Iter: 231 loss: 1.29122509e-06
Iter: 232 loss: 1.28909812e-06
Iter: 233 loss: 1.28438023e-06
Iter: 234 loss: 1.3491848e-06
Iter: 235 loss: 1.28408851e-06
Iter: 236 loss: 1.28079228e-06
Iter: 237 loss: 1.28078e-06
Iter: 238 loss: 1.27796602e-06
Iter: 239 loss: 1.28609031e-06
Iter: 240 loss: 1.27707494e-06
Iter: 241 loss: 1.27469707e-06
Iter: 242 loss: 1.27035582e-06
Iter: 243 loss: 1.37486495e-06
Iter: 244 loss: 1.27035173e-06
Iter: 245 loss: 1.26592624e-06
Iter: 246 loss: 1.27789644e-06
Iter: 247 loss: 1.26444661e-06
Iter: 248 loss: 1.26070347e-06
Iter: 249 loss: 1.30712419e-06
Iter: 250 loss: 1.26064856e-06
Iter: 251 loss: 1.2579842e-06
Iter: 252 loss: 1.27282942e-06
Iter: 253 loss: 1.25762688e-06
Iter: 254 loss: 1.25480847e-06
Iter: 255 loss: 1.26280452e-06
Iter: 256 loss: 1.25392012e-06
Iter: 257 loss: 1.2521059e-06
Iter: 258 loss: 1.25054407e-06
Iter: 259 loss: 1.25008e-06
Iter: 260 loss: 1.24673829e-06
Iter: 261 loss: 1.28009287e-06
Iter: 262 loss: 1.24660619e-06
Iter: 263 loss: 1.24505334e-06
Iter: 264 loss: 1.24335475e-06
Iter: 265 loss: 1.24307439e-06
Iter: 266 loss: 1.2403226e-06
Iter: 267 loss: 1.24104622e-06
Iter: 268 loss: 1.23836026e-06
Iter: 269 loss: 1.23605139e-06
Iter: 270 loss: 1.23581458e-06
Iter: 271 loss: 1.2342324e-06
Iter: 272 loss: 1.23114637e-06
Iter: 273 loss: 1.29500586e-06
Iter: 274 loss: 1.23112568e-06
Iter: 275 loss: 1.2290202e-06
Iter: 276 loss: 1.22891788e-06
Iter: 277 loss: 1.22703523e-06
Iter: 278 loss: 1.22465462e-06
Iter: 279 loss: 1.22444203e-06
Iter: 280 loss: 1.22166864e-06
Iter: 281 loss: 1.22256779e-06
Iter: 282 loss: 1.21969265e-06
Iter: 283 loss: 1.21634173e-06
Iter: 284 loss: 1.22483152e-06
Iter: 285 loss: 1.21514552e-06
Iter: 286 loss: 1.21120047e-06
Iter: 287 loss: 1.2141254e-06
Iter: 288 loss: 1.20876734e-06
Iter: 289 loss: 1.20864024e-06
Iter: 290 loss: 1.20739855e-06
Iter: 291 loss: 1.20580808e-06
Iter: 292 loss: 1.20560503e-06
Iter: 293 loss: 1.20448294e-06
Iter: 294 loss: 1.20273762e-06
Iter: 295 loss: 1.20489676e-06
Iter: 296 loss: 1.20184927e-06
Iter: 297 loss: 1.19999299e-06
Iter: 298 loss: 1.21972903e-06
Iter: 299 loss: 1.1999573e-06
Iter: 300 loss: 1.19864944e-06
Iter: 301 loss: 1.1989091e-06
Iter: 302 loss: 1.19765627e-06
Iter: 303 loss: 1.1959778e-06
Iter: 304 loss: 1.19498759e-06
Iter: 305 loss: 1.19426466e-06
Iter: 306 loss: 1.19140248e-06
Iter: 307 loss: 1.20272671e-06
Iter: 308 loss: 1.19073366e-06
Iter: 309 loss: 1.18900812e-06
Iter: 310 loss: 1.18895582e-06
Iter: 311 loss: 1.1880561e-06
Iter: 312 loss: 1.18587616e-06
Iter: 313 loss: 1.20837751e-06
Iter: 314 loss: 1.18563253e-06
Iter: 315 loss: 1.18344281e-06
Iter: 316 loss: 1.18340654e-06
Iter: 317 loss: 1.1822849e-06
Iter: 318 loss: 1.1798204e-06
Iter: 319 loss: 1.21509117e-06
Iter: 320 loss: 1.17969614e-06
Iter: 321 loss: 1.1772413e-06
Iter: 322 loss: 1.18042203e-06
Iter: 323 loss: 1.17594959e-06
Iter: 324 loss: 1.17312311e-06
Iter: 325 loss: 1.20384789e-06
Iter: 326 loss: 1.17305581e-06
Iter: 327 loss: 1.17107697e-06
Iter: 328 loss: 1.19925539e-06
Iter: 329 loss: 1.17108857e-06
Iter: 330 loss: 1.17017066e-06
Iter: 331 loss: 1.16809815e-06
Iter: 332 loss: 1.19535866e-06
Iter: 333 loss: 1.167969e-06
Iter: 334 loss: 1.16718059e-06
Iter: 335 loss: 1.16672879e-06
Iter: 336 loss: 1.16588103e-06
Iter: 337 loss: 1.16419426e-06
Iter: 338 loss: 1.1946363e-06
Iter: 339 loss: 1.16416186e-06
Iter: 340 loss: 1.16222645e-06
Iter: 341 loss: 1.17451646e-06
Iter: 342 loss: 1.16197293e-06
Iter: 343 loss: 1.16079457e-06
Iter: 344 loss: 1.16357216e-06
Iter: 345 loss: 1.16036267e-06
Iter: 346 loss: 1.15864145e-06
Iter: 347 loss: 1.16343188e-06
Iter: 348 loss: 1.15808768e-06
Iter: 349 loss: 1.15665955e-06
Iter: 350 loss: 1.15787566e-06
Iter: 351 loss: 1.1558318e-06
Iter: 352 loss: 1.15437535e-06
Iter: 353 loss: 1.17133311e-06
Iter: 354 loss: 1.15432783e-06
Iter: 355 loss: 1.15331864e-06
Iter: 356 loss: 1.15147384e-06
Iter: 357 loss: 1.19149809e-06
Iter: 358 loss: 1.15146076e-06
Iter: 359 loss: 1.14916065e-06
Iter: 360 loss: 1.15283308e-06
Iter: 361 loss: 1.14808654e-06
Iter: 362 loss: 1.14609156e-06
Iter: 363 loss: 1.1517659e-06
Iter: 364 loss: 1.14546515e-06
Iter: 365 loss: 1.14361035e-06
Iter: 366 loss: 1.15893295e-06
Iter: 367 loss: 1.1435e-06
Iter: 368 loss: 1.1417435e-06
Iter: 369 loss: 1.15828163e-06
Iter: 370 loss: 1.14167938e-06
Iter: 371 loss: 1.14070122e-06
Iter: 372 loss: 1.13868555e-06
Iter: 373 loss: 1.17500224e-06
Iter: 374 loss: 1.13865042e-06
Iter: 375 loss: 1.13750525e-06
Iter: 376 loss: 1.13741794e-06
Iter: 377 loss: 1.1362464e-06
Iter: 378 loss: 1.1362597e-06
Iter: 379 loss: 1.13530905e-06
Iter: 380 loss: 1.13430519e-06
Iter: 381 loss: 1.1326988e-06
Iter: 382 loss: 1.13269232e-06
Iter: 383 loss: 1.13114595e-06
Iter: 384 loss: 1.1311032e-06
Iter: 385 loss: 1.12993007e-06
Iter: 386 loss: 1.13315605e-06
Iter: 387 loss: 1.12954092e-06
Iter: 388 loss: 1.1283131e-06
Iter: 389 loss: 1.1272582e-06
Iter: 390 loss: 1.12691691e-06
Iter: 391 loss: 1.12517023e-06
Iter: 392 loss: 1.14396244e-06
Iter: 393 loss: 1.12514499e-06
Iter: 394 loss: 1.12392354e-06
Iter: 395 loss: 1.12640316e-06
Iter: 396 loss: 1.12341718e-06
Iter: 397 loss: 1.12236376e-06
Iter: 398 loss: 1.12153475e-06
Iter: 399 loss: 1.12120188e-06
Iter: 400 loss: 1.11954944e-06
Iter: 401 loss: 1.11986901e-06
Iter: 402 loss: 1.11835789e-06
Iter: 403 loss: 1.11656482e-06
Iter: 404 loss: 1.14060663e-06
Iter: 405 loss: 1.11655299e-06
Iter: 406 loss: 1.11482268e-06
Iter: 407 loss: 1.12656676e-06
Iter: 408 loss: 1.11465533e-06
Iter: 409 loss: 1.11358599e-06
Iter: 410 loss: 1.11218139e-06
Iter: 411 loss: 1.11209874e-06
Iter: 412 loss: 1.11083523e-06
Iter: 413 loss: 1.12652651e-06
Iter: 414 loss: 1.1108292e-06
Iter: 415 loss: 1.10961457e-06
Iter: 416 loss: 1.11307986e-06
Iter: 417 loss: 1.10924123e-06
Iter: 418 loss: 1.10855012e-06
Iter: 419 loss: 1.10684186e-06
Iter: 420 loss: 1.12400755e-06
Iter: 421 loss: 1.10662052e-06
Iter: 422 loss: 1.10475298e-06
Iter: 423 loss: 1.12800217e-06
Iter: 424 loss: 1.10472786e-06
Iter: 425 loss: 1.10350811e-06
Iter: 426 loss: 1.11545478e-06
Iter: 427 loss: 1.10348378e-06
Iter: 428 loss: 1.1024282e-06
Iter: 429 loss: 1.10391227e-06
Iter: 430 loss: 1.10197118e-06
Iter: 431 loss: 1.10080236e-06
Iter: 432 loss: 1.10186102e-06
Iter: 433 loss: 1.10012411e-06
Iter: 434 loss: 1.09893165e-06
Iter: 435 loss: 1.11116356e-06
Iter: 436 loss: 1.09888083e-06
Iter: 437 loss: 1.09805853e-06
Iter: 438 loss: 1.09823793e-06
Iter: 439 loss: 1.09746759e-06
Iter: 440 loss: 1.09657447e-06
Iter: 441 loss: 1.09523933e-06
Iter: 442 loss: 1.09520738e-06
Iter: 443 loss: 1.09423206e-06
Iter: 444 loss: 1.09416862e-06
Iter: 445 loss: 1.09289635e-06
Iter: 446 loss: 1.09347e-06
Iter: 447 loss: 1.09202892e-06
Iter: 448 loss: 1.09112875e-06
Iter: 449 loss: 1.09031464e-06
Iter: 450 loss: 1.09007965e-06
Iter: 451 loss: 1.08919699e-06
Iter: 452 loss: 1.08914696e-06
Iter: 453 loss: 1.08827976e-06
Iter: 454 loss: 1.08785434e-06
Iter: 455 loss: 1.08743041e-06
Iter: 456 loss: 1.08639551e-06
Iter: 457 loss: 1.08562142e-06
Iter: 458 loss: 1.08528434e-06
Iter: 459 loss: 1.08384381e-06
Iter: 460 loss: 1.09239954e-06
Iter: 461 loss: 1.0836593e-06
Iter: 462 loss: 1.08225129e-06
Iter: 463 loss: 1.09434984e-06
Iter: 464 loss: 1.08218535e-06
Iter: 465 loss: 1.08122163e-06
Iter: 466 loss: 1.08226084e-06
Iter: 467 loss: 1.08069628e-06
Iter: 468 loss: 1.07962626e-06
Iter: 469 loss: 1.08390418e-06
Iter: 470 loss: 1.07942742e-06
Iter: 471 loss: 1.07848678e-06
Iter: 472 loss: 1.08272934e-06
Iter: 473 loss: 1.07834114e-06
Iter: 474 loss: 1.07754465e-06
Iter: 475 loss: 1.07618439e-06
Iter: 476 loss: 1.07618587e-06
Iter: 477 loss: 1.07495168e-06
Iter: 478 loss: 1.08501695e-06
Iter: 479 loss: 1.07487858e-06
Iter: 480 loss: 1.07420431e-06
Iter: 481 loss: 1.08361473e-06
Iter: 482 loss: 1.07420601e-06
Iter: 483 loss: 1.07343294e-06
Iter: 484 loss: 1.07217625e-06
Iter: 485 loss: 1.07216408e-06
Iter: 486 loss: 1.07111555e-06
Iter: 487 loss: 1.07066967e-06
Iter: 488 loss: 1.07013977e-06
Iter: 489 loss: 1.06940286e-06
Iter: 490 loss: 1.06913046e-06
Iter: 491 loss: 1.0685427e-06
Iter: 492 loss: 1.06742198e-06
Iter: 493 loss: 1.09201744e-06
Iter: 494 loss: 1.06742527e-06
Iter: 495 loss: 1.06609798e-06
Iter: 496 loss: 1.06714231e-06
Iter: 497 loss: 1.06535322e-06
Iter: 498 loss: 1.06442928e-06
Iter: 499 loss: 1.06442951e-06
Iter: 500 loss: 1.06353059e-06
Iter: 501 loss: 1.06674611e-06
Iter: 502 loss: 1.06331299e-06
Iter: 503 loss: 1.06264167e-06
Iter: 504 loss: 1.06255334e-06
Iter: 505 loss: 1.06205562e-06
Iter: 506 loss: 1.0608054e-06
Iter: 507 loss: 1.06535617e-06
Iter: 508 loss: 1.06048901e-06
Iter: 509 loss: 1.05952131e-06
Iter: 510 loss: 1.06386574e-06
Iter: 511 loss: 1.05929576e-06
Iter: 512 loss: 1.05853519e-06
Iter: 513 loss: 1.05725098e-06
Iter: 514 loss: 1.05725962e-06
Iter: 515 loss: 1.05622189e-06
Iter: 516 loss: 1.05621712e-06
Iter: 517 loss: 1.05568211e-06
Iter: 518 loss: 1.05568347e-06
Iter: 519 loss: 1.05526442e-06
Iter: 520 loss: 1.0541446e-06
Iter: 521 loss: 1.06174048e-06
Iter: 522 loss: 1.05388585e-06
Iter: 523 loss: 1.05283948e-06
Iter: 524 loss: 1.05942559e-06
Iter: 525 loss: 1.05270874e-06
Iter: 526 loss: 1.05158608e-06
Iter: 527 loss: 1.06022196e-06
Iter: 528 loss: 1.05149843e-06
Iter: 529 loss: 1.05087236e-06
Iter: 530 loss: 1.04972059e-06
Iter: 531 loss: 1.07701317e-06
Iter: 532 loss: 1.0497298e-06
Iter: 533 loss: 1.04831111e-06
Iter: 534 loss: 1.05177685e-06
Iter: 535 loss: 1.04782418e-06
Iter: 536 loss: 1.04715718e-06
Iter: 537 loss: 1.04710352e-06
Iter: 538 loss: 1.04644391e-06
Iter: 539 loss: 1.04711955e-06
Iter: 540 loss: 1.04606568e-06
Iter: 541 loss: 1.04542369e-06
Iter: 542 loss: 1.04571973e-06
Iter: 543 loss: 1.04500157e-06
Iter: 544 loss: 1.04378137e-06
Iter: 545 loss: 1.04643937e-06
Iter: 546 loss: 1.04334254e-06
Iter: 547 loss: 1.04234982e-06
Iter: 548 loss: 1.04494586e-06
Iter: 549 loss: 1.04204059e-06
Iter: 550 loss: 1.04112621e-06
Iter: 551 loss: 1.04175274e-06
Iter: 552 loss: 1.04056517e-06
Iter: 553 loss: 1.03975162e-06
Iter: 554 loss: 1.04858043e-06
Iter: 555 loss: 1.03973252e-06
Iter: 556 loss: 1.03884361e-06
Iter: 557 loss: 1.04015089e-06
Iter: 558 loss: 1.03841069e-06
Iter: 559 loss: 1.03781736e-06
Iter: 560 loss: 1.03748357e-06
Iter: 561 loss: 1.03725392e-06
Iter: 562 loss: 1.03649325e-06
Iter: 563 loss: 1.0425631e-06
Iter: 564 loss: 1.03644209e-06
Iter: 565 loss: 1.03563593e-06
Iter: 566 loss: 1.03714137e-06
Iter: 567 loss: 1.0352735e-06
Iter: 568 loss: 1.03464504e-06
Iter: 569 loss: 1.03323418e-06
Iter: 570 loss: 1.05089782e-06
Iter: 571 loss: 1.03310435e-06
Iter: 572 loss: 1.03175103e-06
Iter: 573 loss: 1.04405535e-06
Iter: 574 loss: 1.03166735e-06
Iter: 575 loss: 1.0307856e-06
Iter: 576 loss: 1.03076536e-06
Iter: 577 loss: 1.03016714e-06
Iter: 578 loss: 1.03003686e-06
Iter: 579 loss: 1.02964782e-06
Iter: 580 loss: 1.02903743e-06
Iter: 581 loss: 1.0334503e-06
Iter: 582 loss: 1.02896547e-06
Iter: 583 loss: 1.02832962e-06
Iter: 584 loss: 1.02867102e-06
Iter: 585 loss: 1.0278826e-06
Iter: 586 loss: 1.02717559e-06
Iter: 587 loss: 1.02735146e-06
Iter: 588 loss: 1.02665012e-06
Iter: 589 loss: 1.02555646e-06
Iter: 590 loss: 1.02904039e-06
Iter: 591 loss: 1.02524018e-06
Iter: 592 loss: 1.02486854e-06
Iter: 593 loss: 1.02478771e-06
Iter: 594 loss: 1.02434365e-06
Iter: 595 loss: 1.02340448e-06
Iter: 596 loss: 1.03569e-06
Iter: 597 loss: 1.02333513e-06
Iter: 598 loss: 1.02233832e-06
Iter: 599 loss: 1.02505453e-06
Iter: 600 loss: 1.02194588e-06
Iter: 601 loss: 1.02139597e-06
Iter: 602 loss: 1.02137437e-06
Iter: 603 loss: 1.02080799e-06
Iter: 604 loss: 1.02045033e-06
Iter: 605 loss: 1.02019703e-06
Iter: 606 loss: 1.01953049e-06
Iter: 607 loss: 1.01836747e-06
Iter: 608 loss: 1.01837963e-06
Iter: 609 loss: 1.01740841e-06
Iter: 610 loss: 1.01738306e-06
Iter: 611 loss: 1.01643104e-06
Iter: 612 loss: 1.02002832e-06
Iter: 613 loss: 1.01614842e-06
Iter: 614 loss: 1.0155e-06
Iter: 615 loss: 1.01594173e-06
Iter: 616 loss: 1.01508613e-06
Iter: 617 loss: 1.01433773e-06
Iter: 618 loss: 1.02131776e-06
Iter: 619 loss: 1.01430555e-06
Iter: 620 loss: 1.0137245e-06
Iter: 621 loss: 1.01318017e-06
Iter: 622 loss: 1.01304181e-06
Iter: 623 loss: 1.0123274e-06
Iter: 624 loss: 1.01467731e-06
Iter: 625 loss: 1.01211481e-06
Iter: 626 loss: 1.01117553e-06
Iter: 627 loss: 1.01420392e-06
Iter: 628 loss: 1.01094031e-06
Iter: 629 loss: 1.0099227e-06
Iter: 630 loss: 1.01557271e-06
Iter: 631 loss: 1.00976229e-06
Iter: 632 loss: 1.00926241e-06
Iter: 633 loss: 1.00839293e-06
Iter: 634 loss: 1.02844251e-06
Iter: 635 loss: 1.00838929e-06
Iter: 636 loss: 1.00757575e-06
Iter: 637 loss: 1.01803175e-06
Iter: 638 loss: 1.00756949e-06
Iter: 639 loss: 1.00677141e-06
Iter: 640 loss: 1.00928423e-06
Iter: 641 loss: 1.00650607e-06
Iter: 642 loss: 1.00599539e-06
Iter: 643 loss: 1.00531963e-06
Iter: 644 loss: 1.00529371e-06
Iter: 645 loss: 1.00434e-06
Iter: 646 loss: 1.00685975e-06
Iter: 647 loss: 1.00401815e-06
Iter: 648 loss: 1.00347233e-06
Iter: 649 loss: 1.00339253e-06
Iter: 650 loss: 1.00298246e-06
Iter: 651 loss: 1.00200396e-06
Iter: 652 loss: 1.01288697e-06
Iter: 653 loss: 1.001908e-06
Iter: 654 loss: 1.00131956e-06
Iter: 655 loss: 1.00122395e-06
Iter: 656 loss: 1.00075465e-06
Iter: 657 loss: 1.00062857e-06
Iter: 658 loss: 1.00034049e-06
Iter: 659 loss: 9.99685199e-07
Iter: 660 loss: 9.9980241e-07
Iter: 661 loss: 9.99208396e-07
Iter: 662 loss: 9.9854185e-07
Iter: 663 loss: 9.98533892e-07
Iter: 664 loss: 9.9797262e-07
Iter: 665 loss: 9.98180212e-07
Iter: 666 loss: 9.97594498e-07
Iter: 667 loss: 9.96958761e-07
Iter: 668 loss: 9.96792778e-07
Iter: 669 loss: 9.96394533e-07
Iter: 670 loss: 9.95490836e-07
Iter: 671 loss: 9.97120765e-07
Iter: 672 loss: 9.95140454e-07
Iter: 673 loss: 9.9468366e-07
Iter: 674 loss: 9.94562811e-07
Iter: 675 loss: 9.94240509e-07
Iter: 676 loss: 9.93176627e-07
Iter: 677 loss: 9.98261726e-07
Iter: 678 loss: 9.92817149e-07
Iter: 679 loss: 9.91830802e-07
Iter: 680 loss: 1.0007609e-06
Iter: 681 loss: 9.91771458e-07
Iter: 682 loss: 9.9108513e-07
Iter: 683 loss: 9.91072284e-07
Iter: 684 loss: 9.90603439e-07
Iter: 685 loss: 9.90008857e-07
Iter: 686 loss: 9.89937462e-07
Iter: 687 loss: 9.8928183e-07
Iter: 688 loss: 9.9413171e-07
Iter: 689 loss: 9.892359e-07
Iter: 690 loss: 9.88425427e-07
Iter: 691 loss: 9.88555e-07
Iter: 692 loss: 9.87864269e-07
Iter: 693 loss: 9.87115413e-07
Iter: 694 loss: 9.88236e-07
Iter: 695 loss: 9.86732857e-07
Iter: 696 loss: 9.86321197e-07
Iter: 697 loss: 9.86263103e-07
Iter: 698 loss: 9.85943757e-07
Iter: 699 loss: 9.85434781e-07
Iter: 700 loss: 9.85431825e-07
Iter: 701 loss: 9.84614417e-07
Iter: 702 loss: 9.84361236e-07
Iter: 703 loss: 9.83870336e-07
Iter: 704 loss: 9.83135806e-07
Iter: 705 loss: 9.91754519e-07
Iter: 706 loss: 9.8314581e-07
Iter: 707 loss: 9.82591587e-07
Iter: 708 loss: 9.87242402e-07
Iter: 709 loss: 9.82548e-07
Iter: 710 loss: 9.82099e-07
Iter: 711 loss: 9.81417e-07
Iter: 712 loss: 9.81410153e-07
Iter: 713 loss: 9.80615482e-07
Iter: 714 loss: 9.80623213e-07
Iter: 715 loss: 9.79960532e-07
Iter: 716 loss: 9.79810466e-07
Iter: 717 loss: 9.7943132e-07
Iter: 718 loss: 9.79051151e-07
Iter: 719 loss: 9.78179742e-07
Iter: 720 loss: 9.90090712e-07
Iter: 721 loss: 9.7815041e-07
Iter: 722 loss: 9.77436343e-07
Iter: 723 loss: 9.87883823e-07
Iter: 724 loss: 9.77439754e-07
Iter: 725 loss: 9.76776391e-07
Iter: 726 loss: 9.77625632e-07
Iter: 727 loss: 9.76458523e-07
Iter: 728 loss: 9.75915e-07
Iter: 729 loss: 9.76205e-07
Iter: 730 loss: 9.75506509e-07
Iter: 731 loss: 9.75096327e-07
Iter: 732 loss: 9.75077e-07
Iter: 733 loss: 9.74715704e-07
Iter: 734 loss: 9.73897613e-07
Iter: 735 loss: 9.82944584e-07
Iter: 736 loss: 9.73826673e-07
Iter: 737 loss: 9.73066221e-07
Iter: 738 loss: 9.79506126e-07
Iter: 739 loss: 9.73021542e-07
Iter: 740 loss: 9.72447651e-07
Iter: 741 loss: 9.73343276e-07
Iter: 742 loss: 9.72105909e-07
Iter: 743 loss: 9.71248e-07
Iter: 744 loss: 9.77013542e-07
Iter: 745 loss: 9.71173677e-07
Iter: 746 loss: 9.70635824e-07
Iter: 747 loss: 9.69793405e-07
Iter: 748 loss: 9.69776465e-07
Iter: 749 loss: 9.68956215e-07
Iter: 750 loss: 9.73266083e-07
Iter: 751 loss: 9.6884537e-07
Iter: 752 loss: 9.6838653e-07
Iter: 753 loss: 9.68380277e-07
Iter: 754 loss: 9.68017389e-07
Iter: 755 loss: 9.67276719e-07
Iter: 756 loss: 9.80987579e-07
Iter: 757 loss: 9.67256256e-07
Iter: 758 loss: 9.66555376e-07
Iter: 759 loss: 9.72504267e-07
Iter: 760 loss: 9.66514904e-07
Iter: 761 loss: 9.65795607e-07
Iter: 762 loss: 9.67446567e-07
Iter: 763 loss: 9.65558e-07
Iter: 764 loss: 9.65058462e-07
Iter: 765 loss: 9.65073923e-07
Iter: 766 loss: 9.64661353e-07
Iter: 767 loss: 9.63853267e-07
Iter: 768 loss: 9.69746111e-07
Iter: 769 loss: 9.63806201e-07
Iter: 770 loss: 9.63335765e-07
Iter: 771 loss: 9.62595436e-07
Iter: 772 loss: 9.62593617e-07
Iter: 773 loss: 9.61780074e-07
Iter: 774 loss: 9.6613644e-07
Iter: 775 loss: 9.61628302e-07
Iter: 776 loss: 9.61040541e-07
Iter: 777 loss: 9.65564368e-07
Iter: 778 loss: 9.60970169e-07
Iter: 779 loss: 9.6031431e-07
Iter: 780 loss: 9.61214369e-07
Iter: 781 loss: 9.599961e-07
Iter: 782 loss: 9.59298745e-07
Iter: 783 loss: 9.59778163e-07
Iter: 784 loss: 9.58903456e-07
Iter: 785 loss: 9.58301e-07
Iter: 786 loss: 9.58046371e-07
Iter: 787 loss: 9.57782731e-07
Iter: 788 loss: 9.57127668e-07
Iter: 789 loss: 9.57091288e-07
Iter: 790 loss: 9.56790359e-07
Iter: 791 loss: 9.56297526e-07
Iter: 792 loss: 9.56307076e-07
Iter: 793 loss: 9.5577434e-07
Iter: 794 loss: 9.60020316e-07
Iter: 795 loss: 9.55755695e-07
Iter: 796 loss: 9.55185442e-07
Iter: 797 loss: 9.54895654e-07
Iter: 798 loss: 9.54646453e-07
Iter: 799 loss: 9.53941253e-07
Iter: 800 loss: 9.56994313e-07
Iter: 801 loss: 9.53796302e-07
Iter: 802 loss: 9.53159372e-07
Iter: 803 loss: 9.60384227e-07
Iter: 804 loss: 9.53171082e-07
Iter: 805 loss: 9.52867822e-07
Iter: 806 loss: 9.52050925e-07
Iter: 807 loss: 9.556544e-07
Iter: 808 loss: 9.51732204e-07
Iter: 809 loss: 9.50977665e-07
Iter: 810 loss: 9.50963056e-07
Iter: 811 loss: 9.50448168e-07
Iter: 812 loss: 9.54566303e-07
Iter: 813 loss: 9.504069e-07
Iter: 814 loss: 9.4992788e-07
Iter: 815 loss: 9.50958565e-07
Iter: 816 loss: 9.49725404e-07
Iter: 817 loss: 9.49282594e-07
Iter: 818 loss: 9.48866045e-07
Iter: 819 loss: 9.48735249e-07
Iter: 820 loss: 9.47939895e-07
Iter: 821 loss: 9.49869786e-07
Iter: 822 loss: 9.47597641e-07
Iter: 823 loss: 9.47078092e-07
Iter: 824 loss: 9.47064677e-07
Iter: 825 loss: 9.46678824e-07
Iter: 826 loss: 9.45965326e-07
Iter: 827 loss: 9.60895363e-07
Iter: 828 loss: 9.45940428e-07
Iter: 829 loss: 9.45444071e-07
Iter: 830 loss: 9.45438046e-07
Iter: 831 loss: 9.44943224e-07
Iter: 832 loss: 9.45416673e-07
Iter: 833 loss: 9.44659234e-07
Iter: 834 loss: 9.44296175e-07
Iter: 835 loss: 9.45994202e-07
Iter: 836 loss: 9.44236263e-07
Iter: 837 loss: 9.43706709e-07
Iter: 838 loss: 9.44082785e-07
Iter: 839 loss: 9.43439659e-07
Iter: 840 loss: 9.4291039e-07
Iter: 841 loss: 9.42544602e-07
Iter: 842 loss: 9.42365887e-07
Iter: 843 loss: 9.41740893e-07
Iter: 844 loss: 9.41647954e-07
Iter: 845 loss: 9.41202302e-07
Iter: 846 loss: 9.40532971e-07
Iter: 847 loss: 9.40536268e-07
Iter: 848 loss: 9.39966867e-07
Iter: 849 loss: 9.4199379e-07
Iter: 850 loss: 9.39795598e-07
Iter: 851 loss: 9.39411734e-07
Iter: 852 loss: 9.39768711e-07
Iter: 853 loss: 9.39228698e-07
Iter: 854 loss: 9.38749452e-07
Iter: 855 loss: 9.38749793e-07
Iter: 856 loss: 9.38361325e-07
Iter: 857 loss: 9.37868435e-07
Iter: 858 loss: 9.37864286e-07
Iter: 859 loss: 9.37351672e-07
Iter: 860 loss: 9.3690835e-07
Iter: 861 loss: 9.36812739e-07
Iter: 862 loss: 9.36182289e-07
Iter: 863 loss: 9.38023504e-07
Iter: 864 loss: 9.36036031e-07
Iter: 865 loss: 9.35642902e-07
Iter: 866 loss: 9.35638695e-07
Iter: 867 loss: 9.35275693e-07
Iter: 868 loss: 9.34608522e-07
Iter: 869 loss: 9.47687909e-07
Iter: 870 loss: 9.34603577e-07
Iter: 871 loss: 9.34438674e-07
Iter: 872 loss: 9.34225852e-07
Iter: 873 loss: 9.339808e-07
Iter: 874 loss: 9.33433853e-07
Iter: 875 loss: 9.38642529e-07
Iter: 876 loss: 9.33334263e-07
Iter: 877 loss: 9.32643047e-07
Iter: 878 loss: 9.33475e-07
Iter: 879 loss: 9.32261287e-07
Iter: 880 loss: 9.31436659e-07
Iter: 881 loss: 9.33309536e-07
Iter: 882 loss: 9.31077466e-07
Iter: 883 loss: 9.30976398e-07
Iter: 884 loss: 9.30713668e-07
Iter: 885 loss: 9.30380793e-07
Iter: 886 loss: 9.29582143e-07
Iter: 887 loss: 9.37675964e-07
Iter: 888 loss: 9.29458906e-07
Iter: 889 loss: 9.28895929e-07
Iter: 890 loss: 9.36865149e-07
Iter: 891 loss: 9.28928785e-07
Iter: 892 loss: 9.28299755e-07
Iter: 893 loss: 9.29483292e-07
Iter: 894 loss: 9.28056238e-07
Iter: 895 loss: 9.27630481e-07
Iter: 896 loss: 9.28956752e-07
Iter: 897 loss: 9.27533506e-07
Iter: 898 loss: 9.27121334e-07
Iter: 899 loss: 9.26681821e-07
Iter: 900 loss: 9.26604912e-07
Iter: 901 loss: 9.26071095e-07
Iter: 902 loss: 9.26067514e-07
Iter: 903 loss: 9.25636186e-07
Iter: 904 loss: 9.25744189e-07
Iter: 905 loss: 9.25302686e-07
Iter: 906 loss: 9.24797632e-07
Iter: 907 loss: 9.29951568e-07
Iter: 908 loss: 9.24767164e-07
Iter: 909 loss: 9.24458732e-07
Iter: 910 loss: 9.23903599e-07
Iter: 911 loss: 9.23878588e-07
Iter: 912 loss: 9.23202151e-07
Iter: 913 loss: 9.23132916e-07
Iter: 914 loss: 9.22588526e-07
Iter: 915 loss: 9.21866899e-07
Iter: 916 loss: 9.25596339e-07
Iter: 917 loss: 9.21734511e-07
Iter: 918 loss: 9.2124543e-07
Iter: 919 loss: 9.21241394e-07
Iter: 920 loss: 9.20768514e-07
Iter: 921 loss: 9.20525281e-07
Iter: 922 loss: 9.20264768e-07
Iter: 923 loss: 9.19745901e-07
Iter: 924 loss: 9.20344235e-07
Iter: 925 loss: 9.1944753e-07
Iter: 926 loss: 9.19128183e-07
Iter: 927 loss: 9.19086119e-07
Iter: 928 loss: 9.18779449e-07
Iter: 929 loss: 9.18002456e-07
Iter: 930 loss: 9.25886638e-07
Iter: 931 loss: 9.17901389e-07
Iter: 932 loss: 9.17251612e-07
Iter: 933 loss: 9.2310529e-07
Iter: 934 loss: 9.17234e-07
Iter: 935 loss: 9.16557156e-07
Iter: 936 loss: 9.19076115e-07
Iter: 937 loss: 9.16410443e-07
Iter: 938 loss: 9.15993894e-07
Iter: 939 loss: 9.18203e-07
Iter: 940 loss: 9.15927046e-07
Iter: 941 loss: 9.15483724e-07
Iter: 942 loss: 9.16004751e-07
Iter: 943 loss: 9.1524106e-07
Iter: 944 loss: 9.14642442e-07
Iter: 945 loss: 9.14939392e-07
Iter: 946 loss: 9.14253064e-07
Iter: 947 loss: 9.13773192e-07
Iter: 948 loss: 9.14031659e-07
Iter: 949 loss: 9.13443159e-07
Iter: 950 loss: 9.12788323e-07
Iter: 951 loss: 9.13567192e-07
Iter: 952 loss: 9.12499161e-07
Iter: 953 loss: 9.11970687e-07
Iter: 954 loss: 9.19456852e-07
Iter: 955 loss: 9.11952611e-07
Iter: 956 loss: 9.11492236e-07
Iter: 957 loss: 9.13752046e-07
Iter: 958 loss: 9.11397251e-07
Iter: 959 loss: 9.11014695e-07
Iter: 960 loss: 9.10107929e-07
Iter: 961 loss: 9.18609601e-07
Iter: 962 loss: 9.09990433e-07
Iter: 963 loss: 9.09750611e-07
Iter: 964 loss: 9.09473727e-07
Iter: 965 loss: 9.08993741e-07
Iter: 966 loss: 9.08601919e-07
Iter: 967 loss: 9.08464131e-07
Iter: 968 loss: 9.07947879e-07
Iter: 969 loss: 9.08348341e-07
Iter: 970 loss: 9.07596871e-07
Iter: 971 loss: 9.07194362e-07
Iter: 972 loss: 9.0720016e-07
Iter: 973 loss: 9.06813227e-07
Iter: 974 loss: 9.06957553e-07
Iter: 975 loss: 9.06509626e-07
Iter: 976 loss: 9.06081937e-07
Iter: 977 loss: 9.08526772e-07
Iter: 978 loss: 9.06007e-07
Iter: 979 loss: 9.05520324e-07
Iter: 980 loss: 9.05178354e-07
Iter: 981 loss: 9.05016805e-07
Iter: 982 loss: 9.04472699e-07
Iter: 983 loss: 9.03834803e-07
Iter: 984 loss: 9.03780915e-07
Iter: 985 loss: 9.03127955e-07
Iter: 986 loss: 9.11832672e-07
Iter: 987 loss: 9.03119485e-07
Iter: 988 loss: 9.02559577e-07
Iter: 989 loss: 9.03303317e-07
Iter: 990 loss: 9.02276781e-07
Iter: 991 loss: 9.01676458e-07
Iter: 992 loss: 9.10211895e-07
Iter: 993 loss: 9.0166094e-07
Iter: 994 loss: 9.01321187e-07
Iter: 995 loss: 9.01609383e-07
Iter: 996 loss: 9.01113708e-07
Iter: 997 loss: 9.00672944e-07
Iter: 998 loss: 9.00075293e-07
Iter: 999 loss: 9.00058581e-07
Iter: 1000 loss: 8.99450924e-07
Iter: 1001 loss: 9.03573e-07
Iter: 1002 loss: 8.99391466e-07
Iter: 1003 loss: 8.98777785e-07
Iter: 1004 loss: 9.0409435e-07
Iter: 1005 loss: 8.98754308e-07
Iter: 1006 loss: 8.98391249e-07
Iter: 1007 loss: 8.97977657e-07
Iter: 1008 loss: 8.97928032e-07
Iter: 1009 loss: 8.97428663e-07
Iter: 1010 loss: 9.01134172e-07
Iter: 1011 loss: 8.97368466e-07
Iter: 1012 loss: 8.96805545e-07
Iter: 1013 loss: 8.98403471e-07
Iter: 1014 loss: 8.96610118e-07
Iter: 1015 loss: 8.96207496e-07
Iter: 1016 loss: 8.9605237e-07
Iter: 1017 loss: 8.958325e-07
Iter: 1018 loss: 8.95309e-07
Iter: 1019 loss: 9.01732733e-07
Iter: 1020 loss: 8.95296921e-07
Iter: 1021 loss: 8.95018957e-07
Iter: 1022 loss: 8.94301479e-07
Iter: 1023 loss: 9.01016392e-07
Iter: 1024 loss: 8.94215418e-07
Iter: 1025 loss: 8.93409833e-07
Iter: 1026 loss: 8.99256861e-07
Iter: 1027 loss: 8.93369e-07
Iter: 1028 loss: 8.93029664e-07
Iter: 1029 loss: 8.93028471e-07
Iter: 1030 loss: 8.9269696e-07
Iter: 1031 loss: 8.92587309e-07
Iter: 1032 loss: 8.92408593e-07
Iter: 1033 loss: 8.91934405e-07
Iter: 1034 loss: 8.91590162e-07
Iter: 1035 loss: 8.9148449e-07
Iter: 1036 loss: 8.90842159e-07
Iter: 1037 loss: 8.94645893e-07
Iter: 1038 loss: 8.90765193e-07
Iter: 1039 loss: 8.90196361e-07
Iter: 1040 loss: 8.94042728e-07
Iter: 1041 loss: 8.90153444e-07
Iter: 1042 loss: 8.89794251e-07
Iter: 1043 loss: 8.93176207e-07
Iter: 1044 loss: 8.89792204e-07
Iter: 1045 loss: 8.89503553e-07
Iter: 1046 loss: 8.8883445e-07
Iter: 1047 loss: 8.96307e-07
Iter: 1048 loss: 8.88722866e-07
Iter: 1049 loss: 8.88321438e-07
Iter: 1050 loss: 8.88276759e-07
Iter: 1051 loss: 8.87845488e-07
Iter: 1052 loss: 8.88607e-07
Iter: 1053 loss: 8.87642102e-07
Iter: 1054 loss: 8.87304054e-07
Iter: 1055 loss: 8.86902285e-07
Iter: 1056 loss: 8.86850216e-07
Iter: 1057 loss: 8.86404052e-07
Iter: 1058 loss: 8.86383532e-07
Iter: 1059 loss: 8.8612336e-07
Iter: 1060 loss: 8.85518148e-07
Iter: 1061 loss: 8.93817457e-07
Iter: 1062 loss: 8.85472105e-07
Iter: 1063 loss: 8.84880421e-07
Iter: 1064 loss: 8.87331453e-07
Iter: 1065 loss: 8.84762528e-07
Iter: 1066 loss: 8.84219787e-07
Iter: 1067 loss: 8.92807179e-07
Iter: 1068 loss: 8.84224619e-07
Iter: 1069 loss: 8.83914652e-07
Iter: 1070 loss: 8.83363612e-07
Iter: 1071 loss: 8.83356279e-07
Iter: 1072 loss: 8.82746e-07
Iter: 1073 loss: 8.83189159e-07
Iter: 1074 loss: 8.82341283e-07
Iter: 1075 loss: 8.81739425e-07
Iter: 1076 loss: 8.86118869e-07
Iter: 1077 loss: 8.81716915e-07
Iter: 1078 loss: 8.81158428e-07
Iter: 1079 loss: 8.86273313e-07
Iter: 1080 loss: 8.81133644e-07
Iter: 1081 loss: 8.8082453e-07
Iter: 1082 loss: 8.81511596e-07
Iter: 1083 loss: 8.80711184e-07
Iter: 1084 loss: 8.80446066e-07
Iter: 1085 loss: 8.80456923e-07
Iter: 1086 loss: 8.8023728e-07
Iter: 1087 loss: 8.79798e-07
Iter: 1088 loss: 8.83682844e-07
Iter: 1089 loss: 8.79770596e-07
Iter: 1090 loss: 8.79479899e-07
Iter: 1091 loss: 8.78959781e-07
Iter: 1092 loss: 8.90832382e-07
Iter: 1093 loss: 8.78969615e-07
Iter: 1094 loss: 8.78472463e-07
Iter: 1095 loss: 8.85191412e-07
Iter: 1096 loss: 8.78457513e-07
Iter: 1097 loss: 8.78120773e-07
Iter: 1098 loss: 8.78883384e-07
Iter: 1099 loss: 8.77964226e-07
Iter: 1100 loss: 8.7764073e-07
Iter: 1101 loss: 8.77085824e-07
Iter: 1102 loss: 8.77074228e-07
Iter: 1103 loss: 8.7700073e-07
Iter: 1104 loss: 8.76831621e-07
Iter: 1105 loss: 8.76571676e-07
Iter: 1106 loss: 8.7613671e-07
Iter: 1107 loss: 8.76139325e-07
Iter: 1108 loss: 8.75663773e-07
Iter: 1109 loss: 8.75642058e-07
Iter: 1110 loss: 8.75233e-07
Iter: 1111 loss: 8.74639227e-07
Iter: 1112 loss: 8.76939907e-07
Iter: 1113 loss: 8.74483362e-07
Iter: 1114 loss: 8.73949261e-07
Iter: 1115 loss: 8.77301773e-07
Iter: 1116 loss: 8.73883891e-07
Iter: 1117 loss: 8.73271915e-07
Iter: 1118 loss: 8.77087643e-07
Iter: 1119 loss: 8.73214049e-07
Iter: 1120 loss: 8.72947226e-07
Iter: 1121 loss: 8.7257007e-07
Iter: 1122 loss: 8.72547446e-07
Iter: 1123 loss: 8.7237953e-07
Iter: 1124 loss: 8.72285568e-07
Iter: 1125 loss: 8.72098099e-07
Iter: 1126 loss: 8.71749535e-07
Iter: 1127 loss: 8.71766929e-07
Iter: 1128 loss: 8.71312636e-07
Iter: 1129 loss: 8.71962584e-07
Iter: 1130 loss: 8.71103e-07
Iter: 1131 loss: 8.70676217e-07
Iter: 1132 loss: 8.74181865e-07
Iter: 1133 loss: 8.70630799e-07
Iter: 1134 loss: 8.70252904e-07
Iter: 1135 loss: 8.70235056e-07
Iter: 1136 loss: 8.69937821e-07
Iter: 1137 loss: 8.69498649e-07
Iter: 1138 loss: 8.69527355e-07
Iter: 1139 loss: 8.6915793e-07
Iter: 1140 loss: 8.68854613e-07
Iter: 1141 loss: 8.68801408e-07
Iter: 1142 loss: 8.68532311e-07
Iter: 1143 loss: 8.68286747e-07
Iter: 1144 loss: 8.68243887e-07
Iter: 1145 loss: 8.67884921e-07
Iter: 1146 loss: 8.67353378e-07
Iter: 1147 loss: 8.67324502e-07
Iter: 1148 loss: 8.67020503e-07
Iter: 1149 loss: 8.66965e-07
Iter: 1150 loss: 8.66573146e-07
Iter: 1151 loss: 8.67044832e-07
Iter: 1152 loss: 8.663431e-07
Iter: 1153 loss: 8.66046776e-07
Iter: 1154 loss: 8.65903928e-07
Iter: 1155 loss: 8.65778247e-07
Iter: 1156 loss: 8.65454751e-07
Iter: 1157 loss: 8.65442075e-07
Iter: 1158 loss: 8.65192419e-07
Iter: 1159 loss: 8.64746596e-07
Iter: 1160 loss: 8.75263424e-07
Iter: 1161 loss: 8.64731817e-07
Iter: 1162 loss: 8.64273147e-07
Iter: 1163 loss: 8.65790696e-07
Iter: 1164 loss: 8.64169238e-07
Iter: 1165 loss: 8.6374348e-07
Iter: 1166 loss: 8.68076086e-07
Iter: 1167 loss: 8.63748483e-07
Iter: 1168 loss: 8.63455739e-07
Iter: 1169 loss: 8.63411401e-07
Iter: 1170 loss: 8.63214382e-07
Iter: 1171 loss: 8.6271649e-07
Iter: 1172 loss: 8.62631339e-07
Iter: 1173 loss: 8.62268e-07
Iter: 1174 loss: 8.62029367e-07
Iter: 1175 loss: 8.61986678e-07
Iter: 1176 loss: 8.61726562e-07
Iter: 1177 loss: 8.61459228e-07
Iter: 1178 loss: 8.61387946e-07
Iter: 1179 loss: 8.60944454e-07
Iter: 1180 loss: 8.60891589e-07
Iter: 1181 loss: 8.60558373e-07
Iter: 1182 loss: 8.60066336e-07
Iter: 1183 loss: 8.61481908e-07
Iter: 1184 loss: 8.59913143e-07
Iter: 1185 loss: 8.59471356e-07
Iter: 1186 loss: 8.63029641e-07
Iter: 1187 loss: 8.59443674e-07
Iter: 1188 loss: 8.58990802e-07
Iter: 1189 loss: 8.60920295e-07
Iter: 1190 loss: 8.58878366e-07
Iter: 1191 loss: 8.58658609e-07
Iter: 1192 loss: 8.5840793e-07
Iter: 1193 loss: 8.58353701e-07
Iter: 1194 loss: 8.58042597e-07
Iter: 1195 loss: 8.58029e-07
Iter: 1196 loss: 8.57826137e-07
Iter: 1197 loss: 8.57339671e-07
Iter: 1198 loss: 8.64200445e-07
Iter: 1199 loss: 8.57318128e-07
Iter: 1200 loss: 8.56854513e-07
Iter: 1201 loss: 8.58068915e-07
Iter: 1202 loss: 8.56700524e-07
Iter: 1203 loss: 8.56383849e-07
Iter: 1204 loss: 8.61411195e-07
Iter: 1205 loss: 8.56366853e-07
Iter: 1206 loss: 8.56017948e-07
Iter: 1207 loss: 8.56012662e-07
Iter: 1208 loss: 8.55767325e-07
Iter: 1209 loss: 8.5536135e-07
Iter: 1210 loss: 8.56174211e-07
Iter: 1211 loss: 8.55183259e-07
Iter: 1212 loss: 8.54778e-07
Iter: 1213 loss: 8.56439897e-07
Iter: 1214 loss: 8.54665359e-07
Iter: 1215 loss: 8.54398877e-07
Iter: 1216 loss: 8.54395807e-07
Iter: 1217 loss: 8.54173209e-07
Iter: 1218 loss: 8.53603865e-07
Iter: 1219 loss: 8.5814861e-07
Iter: 1220 loss: 8.53503934e-07
Iter: 1221 loss: 8.52963e-07
Iter: 1222 loss: 8.55338612e-07
Iter: 1223 loss: 8.52852224e-07
Iter: 1224 loss: 8.52580911e-07
Iter: 1225 loss: 8.52570679e-07
Iter: 1226 loss: 8.52281232e-07
Iter: 1227 loss: 8.52193807e-07
Iter: 1228 loss: 8.52004746e-07
Iter: 1229 loss: 8.51661298e-07
Iter: 1230 loss: 8.52305e-07
Iter: 1231 loss: 8.51506172e-07
Iter: 1232 loss: 8.51051e-07
Iter: 1233 loss: 8.55109079e-07
Iter: 1234 loss: 8.51040909e-07
Iter: 1235 loss: 8.50852814e-07
Iter: 1236 loss: 8.5031462e-07
Iter: 1237 loss: 8.52436642e-07
Iter: 1238 loss: 8.50058e-07
Iter: 1239 loss: 8.49438038e-07
Iter: 1240 loss: 8.55839744e-07
Iter: 1241 loss: 8.49421838e-07
Iter: 1242 loss: 8.49059802e-07
Iter: 1243 loss: 8.54456118e-07
Iter: 1244 loss: 8.49037804e-07
Iter: 1245 loss: 8.48666446e-07
Iter: 1246 loss: 8.48946e-07
Iter: 1247 loss: 8.48480624e-07
Iter: 1248 loss: 8.48082664e-07
Iter: 1249 loss: 8.48111142e-07
Iter: 1250 loss: 8.47788328e-07
Iter: 1251 loss: 8.47384968e-07
Iter: 1252 loss: 8.50700303e-07
Iter: 1253 loss: 8.47353306e-07
Iter: 1254 loss: 8.47075171e-07
Iter: 1255 loss: 8.48004333e-07
Iter: 1256 loss: 8.46979674e-07
Iter: 1257 loss: 8.4669e-07
Iter: 1258 loss: 8.49242e-07
Iter: 1259 loss: 8.46677608e-07
Iter: 1260 loss: 8.46439207e-07
Iter: 1261 loss: 8.45875775e-07
Iter: 1262 loss: 8.50157903e-07
Iter: 1263 loss: 8.45735713e-07
Iter: 1264 loss: 8.45130103e-07
Iter: 1265 loss: 8.49934281e-07
Iter: 1266 loss: 8.45092472e-07
Iter: 1267 loss: 8.4475613e-07
Iter: 1268 loss: 8.44779e-07
Iter: 1269 loss: 8.4443883e-07
Iter: 1270 loss: 8.4466518e-07
Iter: 1271 loss: 8.44212082e-07
Iter: 1272 loss: 8.43961686e-07
Iter: 1273 loss: 8.44223052e-07
Iter: 1274 loss: 8.43799739e-07
Iter: 1275 loss: 8.43420651e-07
Iter: 1276 loss: 8.45421368e-07
Iter: 1277 loss: 8.43353178e-07
Iter: 1278 loss: 8.43087548e-07
Iter: 1279 loss: 8.42593465e-07
Iter: 1280 loss: 8.53370068e-07
Iter: 1281 loss: 8.42596535e-07
Iter: 1282 loss: 8.42088753e-07
Iter: 1283 loss: 8.42780651e-07
Iter: 1284 loss: 8.41834094e-07
Iter: 1285 loss: 8.41525662e-07
Iter: 1286 loss: 8.41469614e-07
Iter: 1287 loss: 8.41183464e-07
Iter: 1288 loss: 8.41675217e-07
Iter: 1289 loss: 8.41047267e-07
Iter: 1290 loss: 8.4079187e-07
Iter: 1291 loss: 8.40545454e-07
Iter: 1292 loss: 8.40470875e-07
Iter: 1293 loss: 8.40138114e-07
Iter: 1294 loss: 8.40134589e-07
Iter: 1295 loss: 8.39873849e-07
Iter: 1296 loss: 8.40549376e-07
Iter: 1297 loss: 8.39766756e-07
Iter: 1298 loss: 8.39530799e-07
Iter: 1299 loss: 8.39210202e-07
Iter: 1300 loss: 8.39200311e-07
Iter: 1301 loss: 8.38707479e-07
Iter: 1302 loss: 8.38820142e-07
Iter: 1303 loss: 8.38367612e-07
Iter: 1304 loss: 8.37866e-07
Iter: 1305 loss: 8.40369069e-07
Iter: 1306 loss: 8.37776781e-07
Iter: 1307 loss: 8.37483356e-07
Iter: 1308 loss: 8.37454536e-07
Iter: 1309 loss: 8.37173843e-07
Iter: 1310 loss: 8.37187031e-07
Iter: 1311 loss: 8.36947152e-07
Iter: 1312 loss: 8.36634797e-07
Iter: 1313 loss: 8.37590164e-07
Iter: 1314 loss: 8.36579488e-07
Iter: 1315 loss: 8.36167487e-07
Iter: 1316 loss: 8.36682489e-07
Iter: 1317 loss: 8.35958417e-07
Iter: 1318 loss: 8.3570103e-07
Iter: 1319 loss: 8.35256685e-07
Iter: 1320 loss: 8.46265493e-07
Iter: 1321 loss: 8.35256742e-07
Iter: 1322 loss: 8.34840307e-07
Iter: 1323 loss: 8.34840193e-07
Iter: 1324 loss: 8.34529828e-07
Iter: 1325 loss: 8.36533047e-07
Iter: 1326 loss: 8.34504135e-07
Iter: 1327 loss: 8.34281764e-07
Iter: 1328 loss: 8.33906313e-07
Iter: 1329 loss: 8.33908643e-07
Iter: 1330 loss: 8.33551e-07
Iter: 1331 loss: 8.33548881e-07
Iter: 1332 loss: 8.33234e-07
Iter: 1333 loss: 8.33616696e-07
Iter: 1334 loss: 8.33060881e-07
Iter: 1335 loss: 8.32728119e-07
Iter: 1336 loss: 8.33432182e-07
Iter: 1337 loss: 8.32593742e-07
Iter: 1338 loss: 8.3228025e-07
Iter: 1339 loss: 8.31875809e-07
Iter: 1340 loss: 8.3184807e-07
Iter: 1341 loss: 8.31327782e-07
Iter: 1342 loss: 8.33610102e-07
Iter: 1343 loss: 8.31209604e-07
Iter: 1344 loss: 8.30980127e-07
Iter: 1345 loss: 8.30942e-07
Iter: 1346 loss: 8.3067755e-07
Iter: 1347 loss: 8.30711883e-07
Iter: 1348 loss: 8.304537e-07
Iter: 1349 loss: 8.30165675e-07
Iter: 1350 loss: 8.30202339e-07
Iter: 1351 loss: 8.29966211e-07
Iter: 1352 loss: 8.29601959e-07
Iter: 1353 loss: 8.34663183e-07
Iter: 1354 loss: 8.29593432e-07
Iter: 1355 loss: 8.29423925e-07
Iter: 1356 loss: 8.28981513e-07
Iter: 1357 loss: 8.34200137e-07
Iter: 1358 loss: 8.28958e-07
Iter: 1359 loss: 8.28520967e-07
Iter: 1360 loss: 8.29448311e-07
Iter: 1361 loss: 8.28347481e-07
Iter: 1362 loss: 8.28115731e-07
Iter: 1363 loss: 8.28078896e-07
Iter: 1364 loss: 8.27811618e-07
Iter: 1365 loss: 8.27644726e-07
Iter: 1366 loss: 8.27560712e-07
Iter: 1367 loss: 8.27227893e-07
Iter: 1368 loss: 8.27921497e-07
Iter: 1369 loss: 8.27133817e-07
Iter: 1370 loss: 8.26753137e-07
Iter: 1371 loss: 8.29111173e-07
Iter: 1372 loss: 8.26697203e-07
Iter: 1373 loss: 8.26369615e-07
Iter: 1374 loss: 8.27274505e-07
Iter: 1375 loss: 8.26281052e-07
Iter: 1376 loss: 8.26022188e-07
Iter: 1377 loss: 8.25984557e-07
Iter: 1378 loss: 8.25795382e-07
Iter: 1379 loss: 8.25409302e-07
Iter: 1380 loss: 8.25224333e-07
Iter: 1381 loss: 8.25027541e-07
Iter: 1382 loss: 8.24700464e-07
Iter: 1383 loss: 8.24723088e-07
Iter: 1384 loss: 8.24398228e-07
Iter: 1385 loss: 8.25470863e-07
Iter: 1386 loss: 8.24311769e-07
Iter: 1387 loss: 8.24124754e-07
Iter: 1388 loss: 8.2386606e-07
Iter: 1389 loss: 8.2383724e-07
Iter: 1390 loss: 8.23452808e-07
Iter: 1391 loss: 8.28664497e-07
Iter: 1392 loss: 8.23469122e-07
Iter: 1393 loss: 8.23227197e-07
Iter: 1394 loss: 8.22908476e-07
Iter: 1395 loss: 8.22901654e-07
Iter: 1396 loss: 8.22501704e-07
Iter: 1397 loss: 8.22914956e-07
Iter: 1398 loss: 8.22303946e-07
Iter: 1399 loss: 8.21976187e-07
Iter: 1400 loss: 8.21970559e-07
Iter: 1401 loss: 8.21683898e-07
Iter: 1402 loss: 8.21272408e-07
Iter: 1403 loss: 8.21258823e-07
Iter: 1404 loss: 8.2097182e-07
Iter: 1405 loss: 8.23450421e-07
Iter: 1406 loss: 8.20978642e-07
Iter: 1407 loss: 8.2075519e-07
Iter: 1408 loss: 8.22052925e-07
Iter: 1409 loss: 8.20708749e-07
Iter: 1410 loss: 8.20442381e-07
Iter: 1411 loss: 8.20157368e-07
Iter: 1412 loss: 8.20106436e-07
Iter: 1413 loss: 8.19701313e-07
Iter: 1414 loss: 8.20995069e-07
Iter: 1415 loss: 8.19604338e-07
Iter: 1416 loss: 8.19200636e-07
Iter: 1417 loss: 8.19483375e-07
Iter: 1418 loss: 8.18951662e-07
Iter: 1419 loss: 8.18815579e-07
Iter: 1420 loss: 8.18716785e-07
Iter: 1421 loss: 8.1853193e-07
Iter: 1422 loss: 8.18159e-07
Iter: 1423 loss: 8.24218318e-07
Iter: 1424 loss: 8.1816836e-07
Iter: 1425 loss: 8.17952241e-07
Iter: 1426 loss: 8.17959403e-07
Iter: 1427 loss: 8.1769349e-07
Iter: 1428 loss: 8.17351236e-07
Iter: 1429 loss: 8.17353566e-07
Iter: 1430 loss: 8.17016257e-07
Iter: 1431 loss: 8.16923034e-07
Iter: 1432 loss: 8.16673776e-07
Iter: 1433 loss: 8.16312422e-07
Iter: 1434 loss: 8.16319e-07
Iter: 1435 loss: 8.15976477e-07
Iter: 1436 loss: 8.17075716e-07
Iter: 1437 loss: 8.15911505e-07
Iter: 1438 loss: 8.15674753e-07
Iter: 1439 loss: 8.15271505e-07
Iter: 1440 loss: 8.15265821e-07
Iter: 1441 loss: 8.14969e-07
Iter: 1442 loss: 8.14941586e-07
Iter: 1443 loss: 8.14665896e-07
Iter: 1444 loss: 8.15271505e-07
Iter: 1445 loss: 8.14570683e-07
Iter: 1446 loss: 8.14394468e-07
Iter: 1447 loss: 8.13929e-07
Iter: 1448 loss: 8.18529145e-07
Iter: 1449 loss: 8.13845702e-07
Iter: 1450 loss: 8.13453e-07
Iter: 1451 loss: 8.13427675e-07
Iter: 1452 loss: 8.1314306e-07
Iter: 1453 loss: 8.15682e-07
Iter: 1454 loss: 8.13115776e-07
Iter: 1455 loss: 8.12856513e-07
Iter: 1456 loss: 8.1311623e-07
Iter: 1457 loss: 8.12719406e-07
Iter: 1458 loss: 8.12446331e-07
Iter: 1459 loss: 8.12415237e-07
Iter: 1460 loss: 8.1225e-07
Iter: 1461 loss: 8.11905579e-07
Iter: 1462 loss: 8.15833118e-07
Iter: 1463 loss: 8.11910695e-07
Iter: 1464 loss: 8.11659561e-07
Iter: 1465 loss: 8.11440657e-07
Iter: 1466 loss: 8.11389953e-07
Iter: 1467 loss: 8.11051223e-07
Iter: 1468 loss: 8.106623e-07
Iter: 1469 loss: 8.10614722e-07
Iter: 1470 loss: 8.10156905e-07
Iter: 1471 loss: 8.10159577e-07
Iter: 1472 loss: 8.09767e-07
Iter: 1473 loss: 8.11535074e-07
Iter: 1474 loss: 8.09672883e-07
Iter: 1475 loss: 8.09475296e-07
Iter: 1476 loss: 8.09185963e-07
Iter: 1477 loss: 8.09171638e-07
Iter: 1478 loss: 8.08870936e-07
Iter: 1479 loss: 8.08869459e-07
Iter: 1480 loss: 8.08614232e-07
Iter: 1481 loss: 8.08651407e-07
Iter: 1482 loss: 8.08423067e-07
Iter: 1483 loss: 8.08152947e-07
Iter: 1484 loss: 8.07571951e-07
Iter: 1485 loss: 8.16222723e-07
Iter: 1486 loss: 8.07577521e-07
Iter: 1487 loss: 8.06973617e-07
Iter: 1488 loss: 8.12105895e-07
Iter: 1489 loss: 8.06942694e-07
Iter: 1490 loss: 8.06525804e-07
Iter: 1491 loss: 8.10475171e-07
Iter: 1492 loss: 8.06490164e-07
Iter: 1493 loss: 8.06192361e-07
Iter: 1494 loss: 8.10157758e-07
Iter: 1495 loss: 8.06188041e-07
Iter: 1496 loss: 8.06017681e-07
Iter: 1497 loss: 8.05759782e-07
Iter: 1498 loss: 8.05746311e-07
Iter: 1499 loss: 8.05388254e-07
Iter: 1500 loss: 8.06354251e-07
Iter: 1501 loss: 8.05271384e-07
Iter: 1502 loss: 8.04964429e-07
Iter: 1503 loss: 8.08272887e-07
Iter: 1504 loss: 8.04949195e-07
Iter: 1505 loss: 8.04709543e-07
Iter: 1506 loss: 8.04352339e-07
Iter: 1507 loss: 8.04341198e-07
Iter: 1508 loss: 8.03995363e-07
Iter: 1509 loss: 8.03626335e-07
Iter: 1510 loss: 8.03549085e-07
Iter: 1511 loss: 8.03282546e-07
Iter: 1512 loss: 8.03215528e-07
Iter: 1513 loss: 8.02892032e-07
Iter: 1514 loss: 8.0346183e-07
Iter: 1515 loss: 8.02749355e-07
Iter: 1516 loss: 8.02484863e-07
Iter: 1517 loss: 8.02903742e-07
Iter: 1518 loss: 8.02358443e-07
Iter: 1519 loss: 8.02045406e-07
Iter: 1520 loss: 8.04834826e-07
Iter: 1521 loss: 8.02027785e-07
Iter: 1522 loss: 8.01813769e-07
Iter: 1523 loss: 8.01340548e-07
Iter: 1524 loss: 8.09091091e-07
Iter: 1525 loss: 8.0132412e-07
Iter: 1526 loss: 8.00874204e-07
Iter: 1527 loss: 8.01611463e-07
Iter: 1528 loss: 8.00679231e-07
Iter: 1529 loss: 8.00350335e-07
Iter: 1530 loss: 8.00341468e-07
Iter: 1531 loss: 8.00020075e-07
Iter: 1532 loss: 8.01800127e-07
Iter: 1533 loss: 7.99994837e-07
Iter: 1534 loss: 7.99774455e-07
Iter: 1535 loss: 7.99590453e-07
Iter: 1536 loss: 7.9951019e-07
Iter: 1537 loss: 7.99198688e-07
Iter: 1538 loss: 7.99921963e-07
Iter: 1539 loss: 7.99064196e-07
Iter: 1540 loss: 7.98729275e-07
Iter: 1541 loss: 8.01422402e-07
Iter: 1542 loss: 7.98698125e-07
Iter: 1543 loss: 7.98352e-07
Iter: 1544 loss: 7.985916e-07
Iter: 1545 loss: 7.98141e-07
Iter: 1546 loss: 7.97852522e-07
Iter: 1547 loss: 7.97502821e-07
Iter: 1548 loss: 7.97481448e-07
Iter: 1549 loss: 7.96954851e-07
Iter: 1550 loss: 7.98075348e-07
Iter: 1551 loss: 7.96758968e-07
Iter: 1552 loss: 7.96476627e-07
Iter: 1553 loss: 7.96448603e-07
Iter: 1554 loss: 7.9620736e-07
Iter: 1555 loss: 7.97490088e-07
Iter: 1556 loss: 7.96169616e-07
Iter: 1557 loss: 7.95987e-07
Iter: 1558 loss: 7.95477717e-07
Iter: 1559 loss: 7.98316876e-07
Iter: 1560 loss: 7.95315714e-07
Iter: 1561 loss: 7.95182132e-07
Iter: 1562 loss: 7.95031781e-07
Iter: 1563 loss: 7.94733864e-07
Iter: 1564 loss: 7.94449306e-07
Iter: 1565 loss: 7.9441e-07
Iter: 1566 loss: 7.93991717e-07
Iter: 1567 loss: 7.94438279e-07
Iter: 1568 loss: 7.93803395e-07
Iter: 1569 loss: 7.93535264e-07
Iter: 1570 loss: 7.93509116e-07
Iter: 1571 loss: 7.93247182e-07
Iter: 1572 loss: 7.93245249e-07
Iter: 1573 loss: 7.93016511e-07
Iter: 1574 loss: 7.92796641e-07
Iter: 1575 loss: 7.9270967e-07
Iter: 1576 loss: 7.92581432e-07
Iter: 1577 loss: 7.92188587e-07
Iter: 1578 loss: 7.93873483e-07
Iter: 1579 loss: 7.9210497e-07
Iter: 1580 loss: 7.91811033e-07
Iter: 1581 loss: 7.9451047e-07
Iter: 1582 loss: 7.91794605e-07
Iter: 1583 loss: 7.91496518e-07
Iter: 1584 loss: 7.91692401e-07
Iter: 1585 loss: 7.91297452e-07
Iter: 1586 loss: 7.910063e-07
Iter: 1587 loss: 7.90488457e-07
Iter: 1588 loss: 7.9047004e-07
Iter: 1589 loss: 7.9022891e-07
Iter: 1590 loss: 7.90168087e-07
Iter: 1591 loss: 7.89841295e-07
Iter: 1592 loss: 7.90234935e-07
Iter: 1593 loss: 7.89687476e-07
Iter: 1594 loss: 7.8941946e-07
Iter: 1595 loss: 7.89174635e-07
Iter: 1596 loss: 7.89124101e-07
Iter: 1597 loss: 7.88709031e-07
Iter: 1598 loss: 7.90259833e-07
Iter: 1599 loss: 7.88594e-07
Iter: 1600 loss: 7.88217392e-07
Iter: 1601 loss: 7.93215463e-07
Iter: 1602 loss: 7.88221428e-07
Iter: 1603 loss: 7.87999625e-07
Iter: 1604 loss: 7.87469617e-07
Iter: 1605 loss: 7.94969878e-07
Iter: 1606 loss: 7.87445742e-07
Iter: 1607 loss: 7.87602744e-07
Iter: 1608 loss: 7.87259921e-07
Iter: 1609 loss: 7.87098486e-07
Iter: 1610 loss: 7.86645273e-07
Iter: 1611 loss: 7.88719262e-07
Iter: 1612 loss: 7.86473322e-07
Iter: 1613 loss: 7.86039323e-07
Iter: 1614 loss: 7.89160197e-07
Iter: 1615 loss: 7.86000101e-07
Iter: 1616 loss: 7.85733278e-07
Iter: 1617 loss: 7.89911041e-07
Iter: 1618 loss: 7.85720601e-07
Iter: 1619 loss: 7.85455086e-07
Iter: 1620 loss: 7.85466739e-07
Iter: 1621 loss: 7.85246e-07
Iter: 1622 loss: 7.84965778e-07
Iter: 1623 loss: 7.84756e-07
Iter: 1624 loss: 7.84643134e-07
Iter: 1625 loss: 7.84277e-07
Iter: 1626 loss: 7.87165845e-07
Iter: 1627 loss: 7.84211579e-07
Iter: 1628 loss: 7.83871428e-07
Iter: 1629 loss: 7.85190537e-07
Iter: 1630 loss: 7.83776557e-07
Iter: 1631 loss: 7.83495125e-07
Iter: 1632 loss: 7.86307851e-07
Iter: 1633 loss: 7.8347432e-07
Iter: 1634 loss: 7.8329731e-07
Iter: 1635 loss: 7.82936468e-07
Iter: 1636 loss: 7.88020543e-07
Iter: 1637 loss: 7.82928964e-07
Iter: 1638 loss: 7.82620873e-07
Iter: 1639 loss: 7.8261121e-07
Iter: 1640 loss: 7.82353311e-07
Iter: 1641 loss: 7.82203131e-07
Iter: 1642 loss: 7.82081e-07
Iter: 1643 loss: 7.81818528e-07
Iter: 1644 loss: 7.81832114e-07
Iter: 1645 loss: 7.81581321e-07
Iter: 1646 loss: 7.81411586e-07
Iter: 1647 loss: 7.81330186e-07
Iter: 1648 loss: 7.81062568e-07
Iter: 1649 loss: 7.8071821e-07
Iter: 1650 loss: 7.80708831e-07
Iter: 1651 loss: 7.80245273e-07
Iter: 1652 loss: 7.82864959e-07
Iter: 1653 loss: 7.80180073e-07
Iter: 1654 loss: 7.80072412e-07
Iter: 1655 loss: 7.80012215e-07
Iter: 1656 loss: 7.79849415e-07
Iter: 1657 loss: 7.79514039e-07
Iter: 1658 loss: 7.84244946e-07
Iter: 1659 loss: 7.79493632e-07
Iter: 1660 loss: 7.79042e-07
Iter: 1661 loss: 7.79785296e-07
Iter: 1662 loss: 7.7882828e-07
Iter: 1663 loss: 7.7857203e-07
Iter: 1664 loss: 7.82286747e-07
Iter: 1665 loss: 7.78551509e-07
Iter: 1666 loss: 7.78300944e-07
Iter: 1667 loss: 7.79157858e-07
Iter: 1668 loss: 7.78249387e-07
Iter: 1669 loss: 7.77990238e-07
Iter: 1670 loss: 7.78080789e-07
Iter: 1671 loss: 7.77779462e-07
Iter: 1672 loss: 7.77437663e-07
Iter: 1673 loss: 7.77694083e-07
Iter: 1674 loss: 7.77247e-07
Iter: 1675 loss: 7.76958927e-07
Iter: 1676 loss: 7.78435094e-07
Iter: 1677 loss: 7.76898048e-07
Iter: 1678 loss: 7.76543061e-07
Iter: 1679 loss: 7.77540663e-07
Iter: 1680 loss: 7.76397883e-07
Iter: 1681 loss: 7.76142144e-07
Iter: 1682 loss: 7.75821491e-07
Iter: 1683 loss: 7.75786702e-07
Iter: 1684 loss: 7.75497256e-07
Iter: 1685 loss: 7.75507715e-07
Iter: 1686 loss: 7.75219462e-07
Iter: 1687 loss: 7.76680281e-07
Iter: 1688 loss: 7.75197122e-07
Iter: 1689 loss: 7.7501295e-07
Iter: 1690 loss: 7.74603905e-07
Iter: 1691 loss: 7.77767809e-07
Iter: 1692 loss: 7.74530236e-07
Iter: 1693 loss: 7.74183491e-07
Iter: 1694 loss: 7.79109882e-07
Iter: 1695 loss: 7.74188265e-07
Iter: 1696 loss: 7.73897966e-07
Iter: 1697 loss: 7.76554089e-07
Iter: 1698 loss: 7.73897455e-07
Iter: 1699 loss: 7.73734087e-07
Iter: 1700 loss: 7.734061e-07
Iter: 1701 loss: 7.80673531e-07
Iter: 1702 loss: 7.73405532e-07
Iter: 1703 loss: 7.73012971e-07
Iter: 1704 loss: 7.74163595e-07
Iter: 1705 loss: 7.72878593e-07
Iter: 1706 loss: 7.72567205e-07
Iter: 1707 loss: 7.75148e-07
Iter: 1708 loss: 7.72542251e-07
Iter: 1709 loss: 7.72244903e-07
Iter: 1710 loss: 7.73454701e-07
Iter: 1711 loss: 7.7218e-07
Iter: 1712 loss: 7.71863483e-07
Iter: 1713 loss: 7.72208409e-07
Iter: 1714 loss: 7.71677605e-07
Iter: 1715 loss: 7.71414136e-07
Iter: 1716 loss: 7.71241162e-07
Iter: 1717 loss: 7.71147768e-07
Iter: 1718 loss: 7.70998327e-07
Iter: 1719 loss: 7.70927272e-07
Iter: 1720 loss: 7.70795054e-07
Iter: 1721 loss: 7.70505665e-07
Iter: 1722 loss: 7.7657586e-07
Iter: 1723 loss: 7.70514475e-07
Iter: 1724 loss: 7.70140218e-07
Iter: 1725 loss: 7.71405041e-07
Iter: 1726 loss: 7.70066038e-07
Iter: 1727 loss: 7.69839119e-07
Iter: 1728 loss: 7.69836788e-07
Iter: 1729 loss: 7.69708549e-07
Iter: 1730 loss: 7.69373571e-07
Iter: 1731 loss: 7.71231043e-07
Iter: 1732 loss: 7.69247e-07
Iter: 1733 loss: 7.68792574e-07
Iter: 1734 loss: 7.69788926e-07
Iter: 1735 loss: 7.68588734e-07
Iter: 1736 loss: 7.68585153e-07
Iter: 1737 loss: 7.68403083e-07
Iter: 1738 loss: 7.68243922e-07
Iter: 1739 loss: 7.67916276e-07
Iter: 1740 loss: 7.72117517e-07
Iter: 1741 loss: 7.67878703e-07
Iter: 1742 loss: 7.67554582e-07
Iter: 1743 loss: 7.68342886e-07
Iter: 1744 loss: 7.67415827e-07
Iter: 1745 loss: 7.67027e-07
Iter: 1746 loss: 7.68403311e-07
Iter: 1747 loss: 7.66919129e-07
Iter: 1748 loss: 7.66622634e-07
Iter: 1749 loss: 7.71076429e-07
Iter: 1750 loss: 7.66627068e-07
Iter: 1751 loss: 7.66376047e-07
Iter: 1752 loss: 7.66594155e-07
Iter: 1753 loss: 7.66238e-07
Iter: 1754 loss: 7.65888444e-07
Iter: 1755 loss: 7.65971322e-07
Iter: 1756 loss: 7.6563731e-07
Iter: 1757 loss: 7.65335756e-07
Iter: 1758 loss: 7.66176868e-07
Iter: 1759 loss: 7.65231107e-07
Iter: 1760 loss: 7.64966103e-07
Iter: 1761 loss: 7.68900748e-07
Iter: 1762 loss: 7.64967695e-07
Iter: 1763 loss: 7.64761808e-07
Iter: 1764 loss: 7.6437459e-07
Iter: 1765 loss: 7.6957167e-07
Iter: 1766 loss: 7.64359527e-07
Iter: 1767 loss: 7.64271874e-07
Iter: 1768 loss: 7.64141305e-07
Iter: 1769 loss: 7.63959804e-07
Iter: 1770 loss: 7.63671665e-07
Iter: 1771 loss: 7.63656089e-07
Iter: 1772 loss: 7.63346634e-07
Iter: 1773 loss: 7.63012622e-07
Iter: 1774 loss: 7.62953619e-07
Iter: 1775 loss: 7.6274091e-07
Iter: 1776 loss: 7.62674119e-07
Iter: 1777 loss: 7.62410536e-07
Iter: 1778 loss: 7.62304694e-07
Iter: 1779 loss: 7.62174636e-07
Iter: 1780 loss: 7.61904744e-07
Iter: 1781 loss: 7.61942033e-07
Iter: 1782 loss: 7.61727847e-07
Iter: 1783 loss: 7.61503827e-07
Iter: 1784 loss: 7.61510819e-07
Iter: 1785 loss: 7.61284e-07
Iter: 1786 loss: 7.61280376e-07
Iter: 1787 loss: 7.61112119e-07
Iter: 1788 loss: 7.60878606e-07
Iter: 1789 loss: 7.60642251e-07
Iter: 1790 loss: 7.60588307e-07
Iter: 1791 loss: 7.60244461e-07
Iter: 1792 loss: 7.65195864e-07
Iter: 1793 loss: 7.60223486e-07
Iter: 1794 loss: 7.59948307e-07
Iter: 1795 loss: 7.60699152e-07
Iter: 1796 loss: 7.59883505e-07
Iter: 1797 loss: 7.59575528e-07
Iter: 1798 loss: 7.59411e-07
Iter: 1799 loss: 7.59285513e-07
Iter: 1800 loss: 7.59094746e-07
Iter: 1801 loss: 7.59071781e-07
Iter: 1802 loss: 7.58900228e-07
Iter: 1803 loss: 7.5877756e-07
Iter: 1804 loss: 7.58680812e-07
Iter: 1805 loss: 7.58478279e-07
Iter: 1806 loss: 7.58171609e-07
Iter: 1807 loss: 7.58148587e-07
Iter: 1808 loss: 7.57917803e-07
Iter: 1809 loss: 7.57874886e-07
Iter: 1810 loss: 7.57690032e-07
Iter: 1811 loss: 7.5738194e-07
Iter: 1812 loss: 7.57376313e-07
Iter: 1813 loss: 7.57028147e-07
Iter: 1814 loss: 7.57148428e-07
Iter: 1815 loss: 7.56722898e-07
Iter: 1816 loss: 7.56634847e-07
Iter: 1817 loss: 7.56489953e-07
Iter: 1818 loss: 7.56340228e-07
Iter: 1819 loss: 7.559388e-07
Iter: 1820 loss: 7.61039246e-07
Iter: 1821 loss: 7.5594005e-07
Iter: 1822 loss: 7.55589838e-07
Iter: 1823 loss: 7.57489886e-07
Iter: 1824 loss: 7.55534529e-07
Iter: 1825 loss: 7.5524747e-07
Iter: 1826 loss: 7.56773488e-07
Iter: 1827 loss: 7.55194264e-07
Iter: 1828 loss: 7.54925622e-07
Iter: 1829 loss: 7.55508097e-07
Iter: 1830 loss: 7.5480375e-07
Iter: 1831 loss: 7.54506743e-07
Iter: 1832 loss: 7.54748044e-07
Iter: 1833 loss: 7.54365146e-07
Iter: 1834 loss: 7.54094344e-07
Iter: 1835 loss: 7.58028364e-07
Iter: 1836 loss: 7.54105258e-07
Iter: 1837 loss: 7.53893573e-07
Iter: 1838 loss: 7.53581389e-07
Iter: 1839 loss: 7.53583208e-07
Iter: 1840 loss: 7.53217e-07
Iter: 1841 loss: 7.53973779e-07
Iter: 1842 loss: 7.53100608e-07
Iter: 1843 loss: 7.52906431e-07
Iter: 1844 loss: 7.5286863e-07
Iter: 1845 loss: 7.52742949e-07
Iter: 1846 loss: 7.52349592e-07
Iter: 1847 loss: 7.5494188e-07
Iter: 1848 loss: 7.5224267e-07
Iter: 1849 loss: 7.51784341e-07
Iter: 1850 loss: 7.53992822e-07
Iter: 1851 loss: 7.5173125e-07
Iter: 1852 loss: 7.51360915e-07
Iter: 1853 loss: 7.51368702e-07
Iter: 1854 loss: 7.51117284e-07
Iter: 1855 loss: 7.50846141e-07
Iter: 1856 loss: 7.50813342e-07
Iter: 1857 loss: 7.50457502e-07
Iter: 1858 loss: 7.50814593e-07
Iter: 1859 loss: 7.50285267e-07
Iter: 1860 loss: 7.50091317e-07
Iter: 1861 loss: 7.50045615e-07
Iter: 1862 loss: 7.49894411e-07
Iter: 1863 loss: 7.49587855e-07
Iter: 1864 loss: 7.49594449e-07
Iter: 1865 loss: 7.49347e-07
Iter: 1866 loss: 7.49346952e-07
Iter: 1867 loss: 7.49118897e-07
Iter: 1868 loss: 7.49342405e-07
Iter: 1869 loss: 7.4902141e-07
Iter: 1870 loss: 7.48724233e-07
Iter: 1871 loss: 7.48435298e-07
Iter: 1872 loss: 7.48361629e-07
Iter: 1873 loss: 7.48047796e-07
Iter: 1874 loss: 7.50850631e-07
Iter: 1875 loss: 7.48036882e-07
Iter: 1876 loss: 7.47711908e-07
Iter: 1877 loss: 7.49306e-07
Iter: 1878 loss: 7.47625563e-07
Iter: 1879 loss: 7.47466e-07
Iter: 1880 loss: 7.47216291e-07
Iter: 1881 loss: 7.47183606e-07
Iter: 1882 loss: 7.4686676e-07
Iter: 1883 loss: 7.4786243e-07
Iter: 1884 loss: 7.46777175e-07
Iter: 1885 loss: 7.46569697e-07
Iter: 1886 loss: 7.46531214e-07
Iter: 1887 loss: 7.46423893e-07
Iter: 1888 loss: 7.46010073e-07
Iter: 1889 loss: 7.47171896e-07
Iter: 1890 loss: 7.45776e-07
Iter: 1891 loss: 7.45407817e-07
Iter: 1892 loss: 7.45397813e-07
Iter: 1893 loss: 7.45122634e-07
Iter: 1894 loss: 7.47653e-07
Iter: 1895 loss: 7.45096713e-07
Iter: 1896 loss: 7.44893725e-07
Iter: 1897 loss: 7.44712906e-07
Iter: 1898 loss: 7.4464208e-07
Iter: 1899 loss: 7.44382078e-07
Iter: 1900 loss: 7.443806e-07
Iter: 1901 loss: 7.44202907e-07
Iter: 1902 loss: 7.44030615e-07
Iter: 1903 loss: 7.43999635e-07
Iter: 1904 loss: 7.4373304e-07
Iter: 1905 loss: 7.44166186e-07
Iter: 1906 loss: 7.43601959e-07
Iter: 1907 loss: 7.43326552e-07
Iter: 1908 loss: 7.45173111e-07
Iter: 1909 loss: 7.43310579e-07
Iter: 1910 loss: 7.4303216e-07
Iter: 1911 loss: 7.43571718e-07
Iter: 1912 loss: 7.42894485e-07
Iter: 1913 loss: 7.42638122e-07
Iter: 1914 loss: 7.42223847e-07
Iter: 1915 loss: 7.42242548e-07
Iter: 1916 loss: 7.41946e-07
Iter: 1917 loss: 7.41944064e-07
Iter: 1918 loss: 7.41604936e-07
Iter: 1919 loss: 7.42255168e-07
Iter: 1920 loss: 7.41461861e-07
Iter: 1921 loss: 7.41221584e-07
Iter: 1922 loss: 7.41085557e-07
Iter: 1923 loss: 7.40998416e-07
Iter: 1924 loss: 7.40689643e-07
Iter: 1925 loss: 7.41918825e-07
Iter: 1926 loss: 7.40615576e-07
Iter: 1927 loss: 7.40282701e-07
Iter: 1928 loss: 7.42963493e-07
Iter: 1929 loss: 7.40249163e-07
Iter: 1930 loss: 7.39995244e-07
Iter: 1931 loss: 7.40027588e-07
Iter: 1932 loss: 7.39815391e-07
Iter: 1933 loss: 7.39619963e-07
Iter: 1934 loss: 7.39619281e-07
Iter: 1935 loss: 7.39500649e-07
Iter: 1936 loss: 7.39179484e-07
Iter: 1937 loss: 7.4064792e-07
Iter: 1938 loss: 7.39085067e-07
Iter: 1939 loss: 7.38803578e-07
Iter: 1940 loss: 7.38788401e-07
Iter: 1941 loss: 7.38579672e-07
Iter: 1942 loss: 7.3941527e-07
Iter: 1943 loss: 7.38530048e-07
Iter: 1944 loss: 7.38322512e-07
Iter: 1945 loss: 7.38375093e-07
Iter: 1946 loss: 7.38152607e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6
+ date
Mon Oct 26 15:35:00 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 1.6 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12374e00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f123751db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f123751dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f123751d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f125f9e2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f125f9e26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12103cf8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121035e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121035e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210364ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12102fb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12103096a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210309730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12102a3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12102a3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121028bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121023c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121023c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12101f1048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12101f1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12101b4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12101b4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210120950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121014f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210106ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12100d27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12100b1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f121007e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210075510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210075598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1210045ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f0139268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f01552f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f00e37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f01058c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f00a46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.18279668e-05
Iter: 2 loss: 1.05002373e-05
Iter: 3 loss: 1.85316458e-05
Iter: 4 loss: 1.03371e-05
Iter: 5 loss: 9.62327795e-06
Iter: 6 loss: 1.48548625e-05
Iter: 7 loss: 9.56443546e-06
Iter: 8 loss: 9.08043785e-06
Iter: 9 loss: 9.70977453e-06
Iter: 10 loss: 8.83370467e-06
Iter: 11 loss: 8.20969217e-06
Iter: 12 loss: 9.35235e-06
Iter: 13 loss: 7.94123662e-06
Iter: 14 loss: 7.4802947e-06
Iter: 15 loss: 7.78968206e-06
Iter: 16 loss: 7.19078707e-06
Iter: 17 loss: 6.61262402e-06
Iter: 18 loss: 1.14689155e-05
Iter: 19 loss: 6.5791246e-06
Iter: 20 loss: 6.32272213e-06
Iter: 21 loss: 5.92460265e-06
Iter: 22 loss: 5.91918433e-06
Iter: 23 loss: 5.66964445e-06
Iter: 24 loss: 5.62557943e-06
Iter: 25 loss: 5.41775535e-06
Iter: 26 loss: 5.6388526e-06
Iter: 27 loss: 5.30320449e-06
Iter: 28 loss: 5.09737765e-06
Iter: 29 loss: 4.73535601e-06
Iter: 30 loss: 4.73534783e-06
Iter: 31 loss: 4.43838735e-06
Iter: 32 loss: 5.95473193e-06
Iter: 33 loss: 4.39004361e-06
Iter: 34 loss: 4.15820341e-06
Iter: 35 loss: 6.43953172e-06
Iter: 36 loss: 4.15007253e-06
Iter: 37 loss: 3.9954075e-06
Iter: 38 loss: 4.42745932e-06
Iter: 39 loss: 3.94590734e-06
Iter: 40 loss: 3.79347557e-06
Iter: 41 loss: 4.44698662e-06
Iter: 42 loss: 3.76188109e-06
Iter: 43 loss: 3.59670412e-06
Iter: 44 loss: 4.90767161e-06
Iter: 45 loss: 3.5853559e-06
Iter: 46 loss: 3.5055109e-06
Iter: 47 loss: 3.66644372e-06
Iter: 48 loss: 3.47315222e-06
Iter: 49 loss: 3.40343809e-06
Iter: 50 loss: 3.73080343e-06
Iter: 51 loss: 3.3906681e-06
Iter: 52 loss: 3.33099956e-06
Iter: 53 loss: 3.22703841e-06
Iter: 54 loss: 3.22701226e-06
Iter: 55 loss: 3.15650823e-06
Iter: 56 loss: 3.15037278e-06
Iter: 57 loss: 3.09756433e-06
Iter: 58 loss: 3.02211629e-06
Iter: 59 loss: 3.01962086e-06
Iter: 60 loss: 2.95000746e-06
Iter: 61 loss: 3.93909431e-06
Iter: 62 loss: 2.94989309e-06
Iter: 63 loss: 2.88512183e-06
Iter: 64 loss: 2.95966402e-06
Iter: 65 loss: 2.85050533e-06
Iter: 66 loss: 2.78810853e-06
Iter: 67 loss: 2.79687356e-06
Iter: 68 loss: 2.74076092e-06
Iter: 69 loss: 2.67417272e-06
Iter: 70 loss: 2.70372402e-06
Iter: 71 loss: 2.62889671e-06
Iter: 72 loss: 2.56431485e-06
Iter: 73 loss: 2.85070973e-06
Iter: 74 loss: 2.55150098e-06
Iter: 75 loss: 2.49807272e-06
Iter: 76 loss: 2.96540475e-06
Iter: 77 loss: 2.49529694e-06
Iter: 78 loss: 2.45583783e-06
Iter: 79 loss: 2.45582783e-06
Iter: 80 loss: 2.43149975e-06
Iter: 81 loss: 2.39997985e-06
Iter: 82 loss: 2.39782867e-06
Iter: 83 loss: 2.36653477e-06
Iter: 84 loss: 2.76815604e-06
Iter: 85 loss: 2.36624464e-06
Iter: 86 loss: 2.33946457e-06
Iter: 87 loss: 2.29112129e-06
Iter: 88 loss: 3.46190859e-06
Iter: 89 loss: 2.29111856e-06
Iter: 90 loss: 2.26651446e-06
Iter: 91 loss: 2.26448219e-06
Iter: 92 loss: 2.24224345e-06
Iter: 93 loss: 2.22460358e-06
Iter: 94 loss: 2.21770074e-06
Iter: 95 loss: 2.1839503e-06
Iter: 96 loss: 2.42423812e-06
Iter: 97 loss: 2.18100377e-06
Iter: 98 loss: 2.1635542e-06
Iter: 99 loss: 2.31450804e-06
Iter: 100 loss: 2.16266812e-06
Iter: 101 loss: 2.14604029e-06
Iter: 102 loss: 2.11640258e-06
Iter: 103 loss: 2.85608758e-06
Iter: 104 loss: 2.11638303e-06
Iter: 105 loss: 2.09099153e-06
Iter: 106 loss: 2.20439597e-06
Iter: 107 loss: 2.08599067e-06
Iter: 108 loss: 2.05907622e-06
Iter: 109 loss: 2.04962635e-06
Iter: 110 loss: 2.03449167e-06
Iter: 111 loss: 2.00193062e-06
Iter: 112 loss: 2.20195443e-06
Iter: 113 loss: 1.99804253e-06
Iter: 114 loss: 1.99504507e-06
Iter: 115 loss: 1.98507905e-06
Iter: 116 loss: 1.97625877e-06
Iter: 117 loss: 1.95305256e-06
Iter: 118 loss: 2.12311897e-06
Iter: 119 loss: 1.94813219e-06
Iter: 120 loss: 1.93376582e-06
Iter: 121 loss: 1.93256233e-06
Iter: 122 loss: 1.9195229e-06
Iter: 123 loss: 1.90922674e-06
Iter: 124 loss: 1.90519256e-06
Iter: 125 loss: 1.88931244e-06
Iter: 126 loss: 1.96067822e-06
Iter: 127 loss: 1.88624813e-06
Iter: 128 loss: 1.87252954e-06
Iter: 129 loss: 1.96798146e-06
Iter: 130 loss: 1.87124374e-06
Iter: 131 loss: 1.86073351e-06
Iter: 132 loss: 1.85823467e-06
Iter: 133 loss: 1.85151782e-06
Iter: 134 loss: 1.83974248e-06
Iter: 135 loss: 1.99901569e-06
Iter: 136 loss: 1.83970769e-06
Iter: 137 loss: 1.82958706e-06
Iter: 138 loss: 1.81392329e-06
Iter: 139 loss: 1.81374514e-06
Iter: 140 loss: 1.7992304e-06
Iter: 141 loss: 1.9280933e-06
Iter: 142 loss: 1.79855783e-06
Iter: 143 loss: 1.78821938e-06
Iter: 144 loss: 1.77467018e-06
Iter: 145 loss: 1.77384572e-06
Iter: 146 loss: 1.75856724e-06
Iter: 147 loss: 1.92237576e-06
Iter: 148 loss: 1.75817513e-06
Iter: 149 loss: 1.74722993e-06
Iter: 150 loss: 1.82607141e-06
Iter: 151 loss: 1.74630009e-06
Iter: 152 loss: 1.73274225e-06
Iter: 153 loss: 1.75248658e-06
Iter: 154 loss: 1.72617092e-06
Iter: 155 loss: 1.7197782e-06
Iter: 156 loss: 1.71006195e-06
Iter: 157 loss: 1.70988687e-06
Iter: 158 loss: 1.70039334e-06
Iter: 159 loss: 1.70000158e-06
Iter: 160 loss: 1.69442592e-06
Iter: 161 loss: 1.6833892e-06
Iter: 162 loss: 1.89861271e-06
Iter: 163 loss: 1.68329041e-06
Iter: 164 loss: 1.67410167e-06
Iter: 165 loss: 1.75319951e-06
Iter: 166 loss: 1.67356256e-06
Iter: 167 loss: 1.66507334e-06
Iter: 168 loss: 1.7084509e-06
Iter: 169 loss: 1.66370569e-06
Iter: 170 loss: 1.6563165e-06
Iter: 171 loss: 1.6591332e-06
Iter: 172 loss: 1.65115102e-06
Iter: 173 loss: 1.64490962e-06
Iter: 174 loss: 1.7324362e-06
Iter: 175 loss: 1.64494008e-06
Iter: 176 loss: 1.639282e-06
Iter: 177 loss: 1.63094649e-06
Iter: 178 loss: 1.63076072e-06
Iter: 179 loss: 1.62274705e-06
Iter: 180 loss: 1.62547371e-06
Iter: 181 loss: 1.61710568e-06
Iter: 182 loss: 1.60714103e-06
Iter: 183 loss: 1.66458699e-06
Iter: 184 loss: 1.60579657e-06
Iter: 185 loss: 1.59715796e-06
Iter: 186 loss: 1.64959806e-06
Iter: 187 loss: 1.59617639e-06
Iter: 188 loss: 1.59074261e-06
Iter: 189 loss: 1.59068168e-06
Iter: 190 loss: 1.58703449e-06
Iter: 191 loss: 1.57912837e-06
Iter: 192 loss: 1.70321846e-06
Iter: 193 loss: 1.57889872e-06
Iter: 194 loss: 1.57048441e-06
Iter: 195 loss: 1.60548097e-06
Iter: 196 loss: 1.56871772e-06
Iter: 197 loss: 1.56325973e-06
Iter: 198 loss: 1.63484219e-06
Iter: 199 loss: 1.56323176e-06
Iter: 200 loss: 1.55819885e-06
Iter: 201 loss: 1.5505716e-06
Iter: 202 loss: 1.55039959e-06
Iter: 203 loss: 1.54349868e-06
Iter: 204 loss: 1.57601517e-06
Iter: 205 loss: 1.54226723e-06
Iter: 206 loss: 1.5376711e-06
Iter: 207 loss: 1.53763506e-06
Iter: 208 loss: 1.53478811e-06
Iter: 209 loss: 1.5292693e-06
Iter: 210 loss: 1.63992331e-06
Iter: 211 loss: 1.52922144e-06
Iter: 212 loss: 1.52264545e-06
Iter: 213 loss: 1.60944137e-06
Iter: 214 loss: 1.5226251e-06
Iter: 215 loss: 1.51965287e-06
Iter: 216 loss: 1.5164245e-06
Iter: 217 loss: 1.51592076e-06
Iter: 218 loss: 1.50931396e-06
Iter: 219 loss: 1.50692858e-06
Iter: 220 loss: 1.50324445e-06
Iter: 221 loss: 1.4964827e-06
Iter: 222 loss: 1.51546635e-06
Iter: 223 loss: 1.49433663e-06
Iter: 224 loss: 1.48911272e-06
Iter: 225 loss: 1.48854815e-06
Iter: 226 loss: 1.48592517e-06
Iter: 227 loss: 1.48161462e-06
Iter: 228 loss: 1.48156948e-06
Iter: 229 loss: 1.47667629e-06
Iter: 230 loss: 1.48056461e-06
Iter: 231 loss: 1.47376522e-06
Iter: 232 loss: 1.46890648e-06
Iter: 233 loss: 1.54498639e-06
Iter: 234 loss: 1.46890193e-06
Iter: 235 loss: 1.46504647e-06
Iter: 236 loss: 1.46714706e-06
Iter: 237 loss: 1.4624336e-06
Iter: 238 loss: 1.45789977e-06
Iter: 239 loss: 1.46486195e-06
Iter: 240 loss: 1.4557711e-06
Iter: 241 loss: 1.45186482e-06
Iter: 242 loss: 1.47503965e-06
Iter: 243 loss: 1.4514103e-06
Iter: 244 loss: 1.44686828e-06
Iter: 245 loss: 1.454418e-06
Iter: 246 loss: 1.44486501e-06
Iter: 247 loss: 1.44174624e-06
Iter: 248 loss: 1.45039803e-06
Iter: 249 loss: 1.44076159e-06
Iter: 250 loss: 1.4366251e-06
Iter: 251 loss: 1.44157741e-06
Iter: 252 loss: 1.43438979e-06
Iter: 253 loss: 1.43076772e-06
Iter: 254 loss: 1.43108605e-06
Iter: 255 loss: 1.42793965e-06
Iter: 256 loss: 1.42404906e-06
Iter: 257 loss: 1.44107173e-06
Iter: 258 loss: 1.4232802e-06
Iter: 259 loss: 1.42034594e-06
Iter: 260 loss: 1.46643686e-06
Iter: 261 loss: 1.42034037e-06
Iter: 262 loss: 1.4170696e-06
Iter: 263 loss: 1.41485111e-06
Iter: 264 loss: 1.41366468e-06
Iter: 265 loss: 1.41084104e-06
Iter: 266 loss: 1.40469137e-06
Iter: 267 loss: 1.49943685e-06
Iter: 268 loss: 1.40447764e-06
Iter: 269 loss: 1.40029533e-06
Iter: 270 loss: 1.39975043e-06
Iter: 271 loss: 1.39642702e-06
Iter: 272 loss: 1.41403666e-06
Iter: 273 loss: 1.39591339e-06
Iter: 274 loss: 1.3933934e-06
Iter: 275 loss: 1.38996518e-06
Iter: 276 loss: 1.38985138e-06
Iter: 277 loss: 1.38533778e-06
Iter: 278 loss: 1.41427768e-06
Iter: 279 loss: 1.38481926e-06
Iter: 280 loss: 1.38054179e-06
Iter: 281 loss: 1.40593011e-06
Iter: 282 loss: 1.37999461e-06
Iter: 283 loss: 1.378055e-06
Iter: 284 loss: 1.38246878e-06
Iter: 285 loss: 1.37731661e-06
Iter: 286 loss: 1.37487677e-06
Iter: 287 loss: 1.37559584e-06
Iter: 288 loss: 1.3731576e-06
Iter: 289 loss: 1.36950734e-06
Iter: 290 loss: 1.38216888e-06
Iter: 291 loss: 1.3685592e-06
Iter: 292 loss: 1.36601909e-06
Iter: 293 loss: 1.36367589e-06
Iter: 294 loss: 1.36313258e-06
Iter: 295 loss: 1.36039318e-06
Iter: 296 loss: 1.36040376e-06
Iter: 297 loss: 1.35741266e-06
Iter: 298 loss: 1.36390736e-06
Iter: 299 loss: 1.35631012e-06
Iter: 300 loss: 1.3539036e-06
Iter: 301 loss: 1.35096298e-06
Iter: 302 loss: 1.35069695e-06
Iter: 303 loss: 1.34716811e-06
Iter: 304 loss: 1.34841093e-06
Iter: 305 loss: 1.34469e-06
Iter: 306 loss: 1.34391348e-06
Iter: 307 loss: 1.34254594e-06
Iter: 308 loss: 1.3408e-06
Iter: 309 loss: 1.33684216e-06
Iter: 310 loss: 1.39121869e-06
Iter: 311 loss: 1.33661513e-06
Iter: 312 loss: 1.33323545e-06
Iter: 313 loss: 1.36803226e-06
Iter: 314 loss: 1.3331703e-06
Iter: 315 loss: 1.33114963e-06
Iter: 316 loss: 1.35930929e-06
Iter: 317 loss: 1.33114452e-06
Iter: 318 loss: 1.32975129e-06
Iter: 319 loss: 1.32724983e-06
Iter: 320 loss: 1.3852333e-06
Iter: 321 loss: 1.32724949e-06
Iter: 322 loss: 1.32404557e-06
Iter: 323 loss: 1.34604056e-06
Iter: 324 loss: 1.32375624e-06
Iter: 325 loss: 1.32103708e-06
Iter: 326 loss: 1.32813227e-06
Iter: 327 loss: 1.32009745e-06
Iter: 328 loss: 1.31825516e-06
Iter: 329 loss: 1.31640547e-06
Iter: 330 loss: 1.31605816e-06
Iter: 331 loss: 1.31305387e-06
Iter: 332 loss: 1.35128403e-06
Iter: 333 loss: 1.31304864e-06
Iter: 334 loss: 1.31079639e-06
Iter: 335 loss: 1.33040294e-06
Iter: 336 loss: 1.31066463e-06
Iter: 337 loss: 1.30933086e-06
Iter: 338 loss: 1.3062072e-06
Iter: 339 loss: 1.3458158e-06
Iter: 340 loss: 1.30597459e-06
Iter: 341 loss: 1.30313128e-06
Iter: 342 loss: 1.32184982e-06
Iter: 343 loss: 1.30281978e-06
Iter: 344 loss: 1.30030719e-06
Iter: 345 loss: 1.30168178e-06
Iter: 346 loss: 1.29868397e-06
Iter: 347 loss: 1.29615057e-06
Iter: 348 loss: 1.296086e-06
Iter: 349 loss: 1.29478019e-06
Iter: 350 loss: 1.29163368e-06
Iter: 351 loss: 1.32806849e-06
Iter: 352 loss: 1.29135219e-06
Iter: 353 loss: 1.28993906e-06
Iter: 354 loss: 1.28963211e-06
Iter: 355 loss: 1.28777833e-06
Iter: 356 loss: 1.28569377e-06
Iter: 357 loss: 1.28542092e-06
Iter: 358 loss: 1.28313184e-06
Iter: 359 loss: 1.29582963e-06
Iter: 360 loss: 1.28283727e-06
Iter: 361 loss: 1.28110082e-06
Iter: 362 loss: 1.29169382e-06
Iter: 363 loss: 1.28089539e-06
Iter: 364 loss: 1.27911414e-06
Iter: 365 loss: 1.27667704e-06
Iter: 366 loss: 1.27657381e-06
Iter: 367 loss: 1.27507212e-06
Iter: 368 loss: 1.27502358e-06
Iter: 369 loss: 1.27335659e-06
Iter: 370 loss: 1.27585736e-06
Iter: 371 loss: 1.27253554e-06
Iter: 372 loss: 1.2712178e-06
Iter: 373 loss: 1.26845293e-06
Iter: 374 loss: 1.31550632e-06
Iter: 375 loss: 1.26836221e-06
Iter: 376 loss: 1.2658578e-06
Iter: 377 loss: 1.29661657e-06
Iter: 378 loss: 1.26581062e-06
Iter: 379 loss: 1.26410941e-06
Iter: 380 loss: 1.26681255e-06
Iter: 381 loss: 1.26326813e-06
Iter: 382 loss: 1.26157715e-06
Iter: 383 loss: 1.2855387e-06
Iter: 384 loss: 1.26156465e-06
Iter: 385 loss: 1.26039788e-06
Iter: 386 loss: 1.25908502e-06
Iter: 387 loss: 1.2588705e-06
Iter: 388 loss: 1.25668214e-06
Iter: 389 loss: 1.26082136e-06
Iter: 390 loss: 1.25574729e-06
Iter: 391 loss: 1.25423594e-06
Iter: 392 loss: 1.25416534e-06
Iter: 393 loss: 1.25310794e-06
Iter: 394 loss: 1.25098904e-06
Iter: 395 loss: 1.28909869e-06
Iter: 396 loss: 1.25095403e-06
Iter: 397 loss: 1.2486164e-06
Iter: 398 loss: 1.25868462e-06
Iter: 399 loss: 1.24811879e-06
Iter: 400 loss: 1.24538064e-06
Iter: 401 loss: 1.25695601e-06
Iter: 402 loss: 1.24477026e-06
Iter: 403 loss: 1.24333087e-06
Iter: 404 loss: 1.24855933e-06
Iter: 405 loss: 1.24299868e-06
Iter: 406 loss: 1.24186556e-06
Iter: 407 loss: 1.25784891e-06
Iter: 408 loss: 1.24188568e-06
Iter: 409 loss: 1.24104736e-06
Iter: 410 loss: 1.23922518e-06
Iter: 411 loss: 1.26277723e-06
Iter: 412 loss: 1.23907739e-06
Iter: 413 loss: 1.23724089e-06
Iter: 414 loss: 1.23856807e-06
Iter: 415 loss: 1.23614529e-06
Iter: 416 loss: 1.23400253e-06
Iter: 417 loss: 1.24084909e-06
Iter: 418 loss: 1.23343966e-06
Iter: 419 loss: 1.23143627e-06
Iter: 420 loss: 1.258525e-06
Iter: 421 loss: 1.23144741e-06
Iter: 422 loss: 1.22972256e-06
Iter: 423 loss: 1.23230393e-06
Iter: 424 loss: 1.228869e-06
Iter: 425 loss: 1.22727852e-06
Iter: 426 loss: 1.22605184e-06
Iter: 427 loss: 1.22557742e-06
Iter: 428 loss: 1.22480765e-06
Iter: 429 loss: 1.22432334e-06
Iter: 430 loss: 1.2235447e-06
Iter: 431 loss: 1.22187862e-06
Iter: 432 loss: 1.24684595e-06
Iter: 433 loss: 1.22181859e-06
Iter: 434 loss: 1.21968378e-06
Iter: 435 loss: 1.23122447e-06
Iter: 436 loss: 1.2193675e-06
Iter: 437 loss: 1.21804624e-06
Iter: 438 loss: 1.22272786e-06
Iter: 439 loss: 1.21767607e-06
Iter: 440 loss: 1.21581866e-06
Iter: 441 loss: 1.21660219e-06
Iter: 442 loss: 1.21449045e-06
Iter: 443 loss: 1.21351e-06
Iter: 444 loss: 1.21335904e-06
Iter: 445 loss: 1.21251833e-06
Iter: 446 loss: 1.2111592e-06
Iter: 447 loss: 1.21118865e-06
Iter: 448 loss: 1.2095079e-06
Iter: 449 loss: 1.20860318e-06
Iter: 450 loss: 1.20791242e-06
Iter: 451 loss: 1.20567779e-06
Iter: 452 loss: 1.21590801e-06
Iter: 453 loss: 1.20525351e-06
Iter: 454 loss: 1.20355844e-06
Iter: 455 loss: 1.20790753e-06
Iter: 456 loss: 1.20297011e-06
Iter: 457 loss: 1.20128266e-06
Iter: 458 loss: 1.22839106e-06
Iter: 459 loss: 1.20127356e-06
Iter: 460 loss: 1.20046718e-06
Iter: 461 loss: 1.19905917e-06
Iter: 462 loss: 1.23399525e-06
Iter: 463 loss: 1.19903848e-06
Iter: 464 loss: 1.19727588e-06
Iter: 465 loss: 1.21278958e-06
Iter: 466 loss: 1.19721108e-06
Iter: 467 loss: 1.19561173e-06
Iter: 468 loss: 1.20007815e-06
Iter: 469 loss: 1.19503989e-06
Iter: 470 loss: 1.19391598e-06
Iter: 471 loss: 1.19281572e-06
Iter: 472 loss: 1.19255697e-06
Iter: 473 loss: 1.19128299e-06
Iter: 474 loss: 1.2082719e-06
Iter: 475 loss: 1.19126037e-06
Iter: 476 loss: 1.18992284e-06
Iter: 477 loss: 1.19061087e-06
Iter: 478 loss: 1.18905041e-06
Iter: 479 loss: 1.18793491e-06
Iter: 480 loss: 1.18791456e-06
Iter: 481 loss: 1.18733374e-06
Iter: 482 loss: 1.18679338e-06
Iter: 483 loss: 1.18667845e-06
Iter: 484 loss: 1.18549553e-06
Iter: 485 loss: 1.18329399e-06
Iter: 486 loss: 1.23494237e-06
Iter: 487 loss: 1.1833074e-06
Iter: 488 loss: 1.18135858e-06
Iter: 489 loss: 1.1963084e-06
Iter: 490 loss: 1.18122489e-06
Iter: 491 loss: 1.17947957e-06
Iter: 492 loss: 1.18266826e-06
Iter: 493 loss: 1.17871878e-06
Iter: 494 loss: 1.17807713e-06
Iter: 495 loss: 1.17785407e-06
Iter: 496 loss: 1.17713785e-06
Iter: 497 loss: 1.17567879e-06
Iter: 498 loss: 1.20194159e-06
Iter: 499 loss: 1.17566856e-06
Iter: 500 loss: 1.17422474e-06
Iter: 501 loss: 1.18045659e-06
Iter: 502 loss: 1.17390016e-06
Iter: 503 loss: 1.17237801e-06
Iter: 504 loss: 1.1846796e-06
Iter: 505 loss: 1.17227751e-06
Iter: 506 loss: 1.17146021e-06
Iter: 507 loss: 1.16994784e-06
Iter: 508 loss: 1.20393418e-06
Iter: 509 loss: 1.16995182e-06
Iter: 510 loss: 1.16855381e-06
Iter: 511 loss: 1.18934759e-06
Iter: 512 loss: 1.1685388e-06
Iter: 513 loss: 1.16752938e-06
Iter: 514 loss: 1.17480272e-06
Iter: 515 loss: 1.16743695e-06
Iter: 516 loss: 1.1667405e-06
Iter: 517 loss: 1.16853062e-06
Iter: 518 loss: 1.16649937e-06
Iter: 519 loss: 1.16552178e-06
Iter: 520 loss: 1.16379442e-06
Iter: 521 loss: 1.20625475e-06
Iter: 522 loss: 1.16380477e-06
Iter: 523 loss: 1.16228989e-06
Iter: 524 loss: 1.16782303e-06
Iter: 525 loss: 1.16194292e-06
Iter: 526 loss: 1.16039007e-06
Iter: 527 loss: 1.16342937e-06
Iter: 528 loss: 1.15968987e-06
Iter: 529 loss: 1.15816101e-06
Iter: 530 loss: 1.1607051e-06
Iter: 531 loss: 1.15738976e-06
Iter: 532 loss: 1.15638818e-06
Iter: 533 loss: 1.1563958e-06
Iter: 534 loss: 1.15532112e-06
Iter: 535 loss: 1.15600631e-06
Iter: 536 loss: 1.15459352e-06
Iter: 537 loss: 1.15344972e-06
Iter: 538 loss: 1.15420596e-06
Iter: 539 loss: 1.15272485e-06
Iter: 540 loss: 1.15158809e-06
Iter: 541 loss: 1.16446211e-06
Iter: 542 loss: 1.15159196e-06
Iter: 543 loss: 1.15049761e-06
Iter: 544 loss: 1.15032185e-06
Iter: 545 loss: 1.14953968e-06
Iter: 546 loss: 1.14848831e-06
Iter: 547 loss: 1.14851809e-06
Iter: 548 loss: 1.14766851e-06
Iter: 549 loss: 1.14690852e-06
Iter: 550 loss: 1.14675845e-06
Iter: 551 loss: 1.14605859e-06
Iter: 552 loss: 1.14554109e-06
Iter: 553 loss: 1.14529144e-06
Iter: 554 loss: 1.14397517e-06
Iter: 555 loss: 1.14643944e-06
Iter: 556 loss: 1.14342515e-06
Iter: 557 loss: 1.14210957e-06
Iter: 558 loss: 1.14384181e-06
Iter: 559 loss: 1.1414237e-06
Iter: 560 loss: 1.14040552e-06
Iter: 561 loss: 1.1389717e-06
Iter: 562 loss: 1.13891406e-06
Iter: 563 loss: 1.13765498e-06
Iter: 564 loss: 1.13760052e-06
Iter: 565 loss: 1.13648298e-06
Iter: 566 loss: 1.13674616e-06
Iter: 567 loss: 1.13559884e-06
Iter: 568 loss: 1.1343177e-06
Iter: 569 loss: 1.13432736e-06
Iter: 570 loss: 1.13369936e-06
Iter: 571 loss: 1.13240196e-06
Iter: 572 loss: 1.15064e-06
Iter: 573 loss: 1.13230726e-06
Iter: 574 loss: 1.13127112e-06
Iter: 575 loss: 1.13126407e-06
Iter: 576 loss: 1.13028329e-06
Iter: 577 loss: 1.13140993e-06
Iter: 578 loss: 1.12981047e-06
Iter: 579 loss: 1.12883731e-06
Iter: 580 loss: 1.12839325e-06
Iter: 581 loss: 1.12792452e-06
Iter: 582 loss: 1.12728981e-06
Iter: 583 loss: 1.12723524e-06
Iter: 584 loss: 1.12641806e-06
Iter: 585 loss: 1.12476721e-06
Iter: 586 loss: 1.15431988e-06
Iter: 587 loss: 1.12471571e-06
Iter: 588 loss: 1.12390671e-06
Iter: 589 loss: 1.12386283e-06
Iter: 590 loss: 1.12317423e-06
Iter: 591 loss: 1.12188491e-06
Iter: 592 loss: 1.1511612e-06
Iter: 593 loss: 1.12189127e-06
Iter: 594 loss: 1.12050338e-06
Iter: 595 loss: 1.12703856e-06
Iter: 596 loss: 1.12025384e-06
Iter: 597 loss: 1.11911345e-06
Iter: 598 loss: 1.11932059e-06
Iter: 599 loss: 1.11825705e-06
Iter: 600 loss: 1.11713155e-06
Iter: 601 loss: 1.13348074e-06
Iter: 602 loss: 1.11713803e-06
Iter: 603 loss: 1.11616441e-06
Iter: 604 loss: 1.12062366e-06
Iter: 605 loss: 1.11595955e-06
Iter: 606 loss: 1.11508598e-06
Iter: 607 loss: 1.11499617e-06
Iter: 608 loss: 1.11441182e-06
Iter: 609 loss: 1.11324186e-06
Iter: 610 loss: 1.11575253e-06
Iter: 611 loss: 1.11273221e-06
Iter: 612 loss: 1.11181339e-06
Iter: 613 loss: 1.1118218e-06
Iter: 614 loss: 1.11107761e-06
Iter: 615 loss: 1.10973929e-06
Iter: 616 loss: 1.13915928e-06
Iter: 617 loss: 1.10974622e-06
Iter: 618 loss: 1.1085956e-06
Iter: 619 loss: 1.1232969e-06
Iter: 620 loss: 1.10857275e-06
Iter: 621 loss: 1.10767223e-06
Iter: 622 loss: 1.11610052e-06
Iter: 623 loss: 1.10763449e-06
Iter: 624 loss: 1.10712324e-06
Iter: 625 loss: 1.10579629e-06
Iter: 626 loss: 1.11607358e-06
Iter: 627 loss: 1.10554663e-06
Iter: 628 loss: 1.10462247e-06
Iter: 629 loss: 1.10450458e-06
Iter: 630 loss: 1.103758e-06
Iter: 631 loss: 1.10249755e-06
Iter: 632 loss: 1.10248175e-06
Iter: 633 loss: 1.10118708e-06
Iter: 634 loss: 1.10317694e-06
Iter: 635 loss: 1.10057613e-06
Iter: 636 loss: 1.09938469e-06
Iter: 637 loss: 1.11072302e-06
Iter: 638 loss: 1.09931e-06
Iter: 639 loss: 1.0983531e-06
Iter: 640 loss: 1.10652741e-06
Iter: 641 loss: 1.09833809e-06
Iter: 642 loss: 1.09746168e-06
Iter: 643 loss: 1.09668213e-06
Iter: 644 loss: 1.096495e-06
Iter: 645 loss: 1.09562291e-06
Iter: 646 loss: 1.10014798e-06
Iter: 647 loss: 1.09551388e-06
Iter: 648 loss: 1.09459836e-06
Iter: 649 loss: 1.09904181e-06
Iter: 650 loss: 1.09447342e-06
Iter: 651 loss: 1.09366874e-06
Iter: 652 loss: 1.09365942e-06
Iter: 653 loss: 1.0930637e-06
Iter: 654 loss: 1.09200732e-06
Iter: 655 loss: 1.09599534e-06
Iter: 656 loss: 1.09177813e-06
Iter: 657 loss: 1.09084e-06
Iter: 658 loss: 1.10255746e-06
Iter: 659 loss: 1.0908343e-06
Iter: 660 loss: 1.09042787e-06
Iter: 661 loss: 1.08941799e-06
Iter: 662 loss: 1.09930272e-06
Iter: 663 loss: 1.08931658e-06
Iter: 664 loss: 1.08801612e-06
Iter: 665 loss: 1.09720702e-06
Iter: 666 loss: 1.08792437e-06
Iter: 667 loss: 1.08714414e-06
Iter: 668 loss: 1.09370467e-06
Iter: 669 loss: 1.08710094e-06
Iter: 670 loss: 1.08643553e-06
Iter: 671 loss: 1.08475388e-06
Iter: 672 loss: 1.09888083e-06
Iter: 673 loss: 1.08444385e-06
Iter: 674 loss: 1.0829707e-06
Iter: 675 loss: 1.09493726e-06
Iter: 676 loss: 1.08287179e-06
Iter: 677 loss: 1.08211498e-06
Iter: 678 loss: 1.08206882e-06
Iter: 679 loss: 1.08126346e-06
Iter: 680 loss: 1.07996402e-06
Iter: 681 loss: 1.07996061e-06
Iter: 682 loss: 1.07879578e-06
Iter: 683 loss: 1.08101699e-06
Iter: 684 loss: 1.0782876e-06
Iter: 685 loss: 1.07703829e-06
Iter: 686 loss: 1.07703613e-06
Iter: 687 loss: 1.07640608e-06
Iter: 688 loss: 1.07651556e-06
Iter: 689 loss: 1.07594462e-06
Iter: 690 loss: 1.07528876e-06
Iter: 691 loss: 1.08007521e-06
Iter: 692 loss: 1.07523738e-06
Iter: 693 loss: 1.07443725e-06
Iter: 694 loss: 1.07463609e-06
Iter: 695 loss: 1.07384062e-06
Iter: 696 loss: 1.07311541e-06
Iter: 697 loss: 1.07318897e-06
Iter: 698 loss: 1.07252743e-06
Iter: 699 loss: 1.07147662e-06
Iter: 700 loss: 1.0748995e-06
Iter: 701 loss: 1.07120138e-06
Iter: 702 loss: 1.070238e-06
Iter: 703 loss: 1.07527126e-06
Iter: 704 loss: 1.07005064e-06
Iter: 705 loss: 1.0689555e-06
Iter: 706 loss: 1.0674537e-06
Iter: 707 loss: 1.0674114e-06
Iter: 708 loss: 1.06617313e-06
Iter: 709 loss: 1.07329151e-06
Iter: 710 loss: 1.06602101e-06
Iter: 711 loss: 1.06493439e-06
Iter: 712 loss: 1.07110623e-06
Iter: 713 loss: 1.06479365e-06
Iter: 714 loss: 1.06368816e-06
Iter: 715 loss: 1.06958498e-06
Iter: 716 loss: 1.06350717e-06
Iter: 717 loss: 1.06289519e-06
Iter: 718 loss: 1.06219386e-06
Iter: 719 loss: 1.06208756e-06
Iter: 720 loss: 1.06132711e-06
Iter: 721 loss: 1.06947437e-06
Iter: 722 loss: 1.0613478e-06
Iter: 723 loss: 1.06036396e-06
Iter: 724 loss: 1.06015057e-06
Iter: 725 loss: 1.05951472e-06
Iter: 726 loss: 1.05880645e-06
Iter: 727 loss: 1.06409129e-06
Iter: 728 loss: 1.05877473e-06
Iter: 729 loss: 1.0578558e-06
Iter: 730 loss: 1.05900983e-06
Iter: 731 loss: 1.05736081e-06
Iter: 732 loss: 1.05663298e-06
Iter: 733 loss: 1.05634354e-06
Iter: 734 loss: 1.05590652e-06
Iter: 735 loss: 1.05505126e-06
Iter: 736 loss: 1.0560575e-06
Iter: 737 loss: 1.0545491e-06
Iter: 738 loss: 1.05350557e-06
Iter: 739 loss: 1.06481707e-06
Iter: 740 loss: 1.05346965e-06
Iter: 741 loss: 1.05263348e-06
Iter: 742 loss: 1.05209119e-06
Iter: 743 loss: 1.05180357e-06
Iter: 744 loss: 1.05081085e-06
Iter: 745 loss: 1.05360573e-06
Iter: 746 loss: 1.05048321e-06
Iter: 747 loss: 1.04944854e-06
Iter: 748 loss: 1.05540244e-06
Iter: 749 loss: 1.04935543e-06
Iter: 750 loss: 1.0484772e-06
Iter: 751 loss: 1.05544007e-06
Iter: 752 loss: 1.04842752e-06
Iter: 753 loss: 1.04784237e-06
Iter: 754 loss: 1.04725814e-06
Iter: 755 loss: 1.04714627e-06
Iter: 756 loss: 1.04617493e-06
Iter: 757 loss: 1.0501451e-06
Iter: 758 loss: 1.04594972e-06
Iter: 759 loss: 1.04518529e-06
Iter: 760 loss: 1.0536437e-06
Iter: 761 loss: 1.04517085e-06
Iter: 762 loss: 1.04449919e-06
Iter: 763 loss: 1.04417359e-06
Iter: 764 loss: 1.04384503e-06
Iter: 765 loss: 1.04340563e-06
Iter: 766 loss: 1.04333435e-06
Iter: 767 loss: 1.04297089e-06
Iter: 768 loss: 1.04192327e-06
Iter: 769 loss: 1.04646051e-06
Iter: 770 loss: 1.04153094e-06
Iter: 771 loss: 1.04045284e-06
Iter: 772 loss: 1.04841627e-06
Iter: 773 loss: 1.04039395e-06
Iter: 774 loss: 1.0394524e-06
Iter: 775 loss: 1.04120147e-06
Iter: 776 loss: 1.03903858e-06
Iter: 777 loss: 1.03832679e-06
Iter: 778 loss: 1.03833031e-06
Iter: 779 loss: 1.03785828e-06
Iter: 780 loss: 1.03673915e-06
Iter: 781 loss: 1.0505662e-06
Iter: 782 loss: 1.03666935e-06
Iter: 783 loss: 1.03592765e-06
Iter: 784 loss: 1.04697665e-06
Iter: 785 loss: 1.0359247e-06
Iter: 786 loss: 1.03513025e-06
Iter: 787 loss: 1.03781917e-06
Iter: 788 loss: 1.03495199e-06
Iter: 789 loss: 1.03421303e-06
Iter: 790 loss: 1.03311254e-06
Iter: 791 loss: 1.03307866e-06
Iter: 792 loss: 1.03177661e-06
Iter: 793 loss: 1.03886657e-06
Iter: 794 loss: 1.03159437e-06
Iter: 795 loss: 1.03099978e-06
Iter: 796 loss: 1.03095886e-06
Iter: 797 loss: 1.03044204e-06
Iter: 798 loss: 1.02987599e-06
Iter: 799 loss: 1.02978561e-06
Iter: 800 loss: 1.02897184e-06
Iter: 801 loss: 1.04015521e-06
Iter: 802 loss: 1.0289682e-06
Iter: 803 loss: 1.02848651e-06
Iter: 804 loss: 1.02807223e-06
Iter: 805 loss: 1.02798822e-06
Iter: 806 loss: 1.02719991e-06
Iter: 807 loss: 1.0273551e-06
Iter: 808 loss: 1.02662648e-06
Iter: 809 loss: 1.02556919e-06
Iter: 810 loss: 1.02618355e-06
Iter: 811 loss: 1.02488048e-06
Iter: 812 loss: 1.02414663e-06
Iter: 813 loss: 1.0241265e-06
Iter: 814 loss: 1.02347644e-06
Iter: 815 loss: 1.02401293e-06
Iter: 816 loss: 1.02307865e-06
Iter: 817 loss: 1.02216836e-06
Iter: 818 loss: 1.02238448e-06
Iter: 819 loss: 1.02155559e-06
Iter: 820 loss: 1.02080526e-06
Iter: 821 loss: 1.02719719e-06
Iter: 822 loss: 1.02076172e-06
Iter: 823 loss: 1.01997125e-06
Iter: 824 loss: 1.02281854e-06
Iter: 825 loss: 1.01979026e-06
Iter: 826 loss: 1.01926571e-06
Iter: 827 loss: 1.0184441e-06
Iter: 828 loss: 1.01844728e-06
Iter: 829 loss: 1.01798526e-06
Iter: 830 loss: 1.01786713e-06
Iter: 831 loss: 1.01736896e-06
Iter: 832 loss: 1.01682906e-06
Iter: 833 loss: 1.01673209e-06
Iter: 834 loss: 1.01598766e-06
Iter: 835 loss: 1.02569584e-06
Iter: 836 loss: 1.0160004e-06
Iter: 837 loss: 1.01551609e-06
Iter: 838 loss: 1.01494084e-06
Iter: 839 loss: 1.01487865e-06
Iter: 840 loss: 1.0140775e-06
Iter: 841 loss: 1.01329647e-06
Iter: 842 loss: 1.01311957e-06
Iter: 843 loss: 1.01210776e-06
Iter: 844 loss: 1.02746071e-06
Iter: 845 loss: 1.01209889e-06
Iter: 846 loss: 1.0113697e-06
Iter: 847 loss: 1.01277317e-06
Iter: 848 loss: 1.01109413e-06
Iter: 849 loss: 1.01030639e-06
Iter: 850 loss: 1.0165312e-06
Iter: 851 loss: 1.01025228e-06
Iter: 852 loss: 1.00972102e-06
Iter: 853 loss: 1.00930595e-06
Iter: 854 loss: 1.00914895e-06
Iter: 855 loss: 1.0082955e-06
Iter: 856 loss: 1.01088744e-06
Iter: 857 loss: 1.00804482e-06
Iter: 858 loss: 1.00739169e-06
Iter: 859 loss: 1.00738202e-06
Iter: 860 loss: 1.0069856e-06
Iter: 861 loss: 1.00649413e-06
Iter: 862 loss: 1.00642274e-06
Iter: 863 loss: 1.00571594e-06
Iter: 864 loss: 1.00747684e-06
Iter: 865 loss: 1.00546868e-06
Iter: 866 loss: 1.00449176e-06
Iter: 867 loss: 1.01010687e-06
Iter: 868 loss: 1.00433931e-06
Iter: 869 loss: 1.00387024e-06
Iter: 870 loss: 1.006091e-06
Iter: 871 loss: 1.00380623e-06
Iter: 872 loss: 1.00327111e-06
Iter: 873 loss: 1.00268448e-06
Iter: 874 loss: 1.00259479e-06
Iter: 875 loss: 1.00196871e-06
Iter: 876 loss: 1.00240482e-06
Iter: 877 loss: 1.00155376e-06
Iter: 878 loss: 1.00061925e-06
Iter: 879 loss: 1.00147327e-06
Iter: 880 loss: 1.00008219e-06
Iter: 881 loss: 9.99139274e-07
Iter: 882 loss: 1.00296074e-06
Iter: 883 loss: 9.98940664e-07
Iter: 884 loss: 9.98161113e-07
Iter: 885 loss: 9.98175437e-07
Iter: 886 loss: 9.97798224e-07
Iter: 887 loss: 9.97038342e-07
Iter: 888 loss: 1.00869386e-06
Iter: 889 loss: 9.96999233e-07
Iter: 890 loss: 9.96004815e-07
Iter: 891 loss: 1.00471073e-06
Iter: 892 loss: 9.95994355e-07
Iter: 893 loss: 9.95386e-07
Iter: 894 loss: 1.00174066e-06
Iter: 895 loss: 9.95381e-07
Iter: 896 loss: 9.94906713e-07
Iter: 897 loss: 9.94425136e-07
Iter: 898 loss: 9.94313723e-07
Iter: 899 loss: 9.93533604e-07
Iter: 900 loss: 9.95494702e-07
Iter: 901 loss: 9.93232561e-07
Iter: 902 loss: 9.92400601e-07
Iter: 903 loss: 1.00270609e-06
Iter: 904 loss: 9.92383775e-07
Iter: 905 loss: 9.91958927e-07
Iter: 906 loss: 9.91977231e-07
Iter: 907 loss: 9.91609454e-07
Iter: 908 loss: 9.90902e-07
Iter: 909 loss: 9.93113645e-07
Iter: 910 loss: 9.90713829e-07
Iter: 911 loss: 9.90101171e-07
Iter: 912 loss: 9.89168257e-07
Iter: 913 loss: 9.89137334e-07
Iter: 914 loss: 9.88355396e-07
Iter: 915 loss: 9.9061549e-07
Iter: 916 loss: 9.88119154e-07
Iter: 917 loss: 9.87265935e-07
Iter: 918 loss: 9.90063654e-07
Iter: 919 loss: 9.8704e-07
Iter: 920 loss: 9.8630926e-07
Iter: 921 loss: 9.94123297e-07
Iter: 922 loss: 9.86294481e-07
Iter: 923 loss: 9.8576561e-07
Iter: 924 loss: 9.87224e-07
Iter: 925 loss: 9.85547558e-07
Iter: 926 loss: 9.85051656e-07
Iter: 927 loss: 9.844224e-07
Iter: 928 loss: 9.84370217e-07
Iter: 929 loss: 9.83918881e-07
Iter: 930 loss: 9.83864538e-07
Iter: 931 loss: 9.8338478e-07
Iter: 932 loss: 9.82410256e-07
Iter: 933 loss: 9.98130531e-07
Iter: 934 loss: 9.82365577e-07
Iter: 935 loss: 9.81799758e-07
Iter: 936 loss: 9.81776225e-07
Iter: 937 loss: 9.81216544e-07
Iter: 938 loss: 9.82436404e-07
Iter: 939 loss: 9.80988e-07
Iter: 940 loss: 9.80574214e-07
Iter: 941 loss: 9.81333e-07
Iter: 942 loss: 9.80375489e-07
Iter: 943 loss: 9.79817059e-07
Iter: 944 loss: 9.810542e-07
Iter: 945 loss: 9.79587071e-07
Iter: 946 loss: 9.79042284e-07
Iter: 947 loss: 9.78408934e-07
Iter: 948 loss: 9.78362436e-07
Iter: 949 loss: 9.77478e-07
Iter: 950 loss: 9.83602376e-07
Iter: 951 loss: 9.77384161e-07
Iter: 952 loss: 9.76809474e-07
Iter: 953 loss: 9.7617351e-07
Iter: 954 loss: 9.76069714e-07
Iter: 955 loss: 9.7526322e-07
Iter: 956 loss: 9.83375458e-07
Iter: 957 loss: 9.75270495e-07
Iter: 958 loss: 9.74610202e-07
Iter: 959 loss: 9.79787e-07
Iter: 960 loss: 9.74593377e-07
Iter: 961 loss: 9.74017098e-07
Iter: 962 loss: 9.73830083e-07
Iter: 963 loss: 9.73521423e-07
Iter: 964 loss: 9.72815656e-07
Iter: 965 loss: 9.76936e-07
Iter: 966 loss: 9.72709586e-07
Iter: 967 loss: 9.71957206e-07
Iter: 968 loss: 9.7415159e-07
Iter: 969 loss: 9.71758482e-07
Iter: 970 loss: 9.71130248e-07
Iter: 971 loss: 9.7105e-07
Iter: 972 loss: 9.70600922e-07
Iter: 973 loss: 9.7024315e-07
Iter: 974 loss: 9.7012412e-07
Iter: 975 loss: 9.69867642e-07
Iter: 976 loss: 9.69169378e-07
Iter: 977 loss: 9.73941155e-07
Iter: 978 loss: 9.69028406e-07
Iter: 979 loss: 9.68331733e-07
Iter: 980 loss: 9.68333552e-07
Iter: 981 loss: 9.67900178e-07
Iter: 982 loss: 9.6715678e-07
Iter: 983 loss: 9.8399e-07
Iter: 984 loss: 9.6715587e-07
Iter: 985 loss: 9.66240691e-07
Iter: 986 loss: 9.68469294e-07
Iter: 987 loss: 9.65885874e-07
Iter: 988 loss: 9.64953415e-07
Iter: 989 loss: 9.65612116e-07
Iter: 990 loss: 9.64363e-07
Iter: 991 loss: 9.63506e-07
Iter: 992 loss: 9.70400265e-07
Iter: 993 loss: 9.63476396e-07
Iter: 994 loss: 9.62743e-07
Iter: 995 loss: 9.68537393e-07
Iter: 996 loss: 9.62715262e-07
Iter: 997 loss: 9.62219247e-07
Iter: 998 loss: 9.62203103e-07
Iter: 999 loss: 9.61800538e-07
Iter: 1000 loss: 9.61232672e-07
Iter: 1001 loss: 9.64063929e-07
Iter: 1002 loss: 9.61132059e-07
Iter: 1003 loss: 9.60530087e-07
Iter: 1004 loss: 9.63887373e-07
Iter: 1005 loss: 9.60457669e-07
Iter: 1006 loss: 9.60045099e-07
Iter: 1007 loss: 9.60116267e-07
Iter: 1008 loss: 9.59755653e-07
Iter: 1009 loss: 9.59326485e-07
Iter: 1010 loss: 9.59322279e-07
Iter: 1011 loss: 9.59031127e-07
Iter: 1012 loss: 9.5842006e-07
Iter: 1013 loss: 9.67631877e-07
Iter: 1014 loss: 9.58388114e-07
Iter: 1015 loss: 9.57804559e-07
Iter: 1016 loss: 9.66060497e-07
Iter: 1017 loss: 9.57790462e-07
Iter: 1018 loss: 9.57417456e-07
Iter: 1019 loss: 9.58120836e-07
Iter: 1020 loss: 9.57253e-07
Iter: 1021 loss: 9.56770464e-07
Iter: 1022 loss: 9.56039457e-07
Iter: 1023 loss: 9.56037184e-07
Iter: 1024 loss: 9.55271616e-07
Iter: 1025 loss: 9.59204726e-07
Iter: 1026 loss: 9.55125188e-07
Iter: 1027 loss: 9.54375309e-07
Iter: 1028 loss: 9.55939186e-07
Iter: 1029 loss: 9.54088e-07
Iter: 1030 loss: 9.53381686e-07
Iter: 1031 loss: 9.58686542e-07
Iter: 1032 loss: 9.53329845e-07
Iter: 1033 loss: 9.52582582e-07
Iter: 1034 loss: 9.53903168e-07
Iter: 1035 loss: 9.52271648e-07
Iter: 1036 loss: 9.51784273e-07
Iter: 1037 loss: 9.52671257e-07
Iter: 1038 loss: 9.51602317e-07
Iter: 1039 loss: 9.50958793e-07
Iter: 1040 loss: 9.5570806e-07
Iter: 1041 loss: 9.50919173e-07
Iter: 1042 loss: 9.505805e-07
Iter: 1043 loss: 9.50585331e-07
Iter: 1044 loss: 9.50326921e-07
Iter: 1045 loss: 9.49754735e-07
Iter: 1046 loss: 9.5347383e-07
Iter: 1047 loss: 9.4967254e-07
Iter: 1048 loss: 9.4928123e-07
Iter: 1049 loss: 9.48914419e-07
Iter: 1050 loss: 9.48826823e-07
Iter: 1051 loss: 9.48366448e-07
Iter: 1052 loss: 9.53248e-07
Iter: 1053 loss: 9.48368552e-07
Iter: 1054 loss: 9.47891294e-07
Iter: 1055 loss: 9.481098e-07
Iter: 1056 loss: 9.47612193e-07
Iter: 1057 loss: 9.47165631e-07
Iter: 1058 loss: 9.47536819e-07
Iter: 1059 loss: 9.46913133e-07
Iter: 1060 loss: 9.4630343e-07
Iter: 1061 loss: 9.47180467e-07
Iter: 1062 loss: 9.46049738e-07
Iter: 1063 loss: 9.45382453e-07
Iter: 1064 loss: 9.4541474e-07
Iter: 1065 loss: 9.44888825e-07
Iter: 1066 loss: 9.44296175e-07
Iter: 1067 loss: 9.44292708e-07
Iter: 1068 loss: 9.4383239e-07
Iter: 1069 loss: 9.45828162e-07
Iter: 1070 loss: 9.43741952e-07
Iter: 1071 loss: 9.43319833e-07
Iter: 1072 loss: 9.43115822e-07
Iter: 1073 loss: 9.42894133e-07
Iter: 1074 loss: 9.42459e-07
Iter: 1075 loss: 9.42449e-07
Iter: 1076 loss: 9.42135159e-07
Iter: 1077 loss: 9.41907899e-07
Iter: 1078 loss: 9.41773578e-07
Iter: 1079 loss: 9.41416374e-07
Iter: 1080 loss: 9.41424275e-07
Iter: 1081 loss: 9.41149665e-07
Iter: 1082 loss: 9.40552582e-07
Iter: 1083 loss: 9.48553122e-07
Iter: 1084 loss: 9.40508642e-07
Iter: 1085 loss: 9.40055088e-07
Iter: 1086 loss: 9.46072e-07
Iter: 1087 loss: 9.40055486e-07
Iter: 1088 loss: 9.39604888e-07
Iter: 1089 loss: 9.39668837e-07
Iter: 1090 loss: 9.39285542e-07
Iter: 1091 loss: 9.38682547e-07
Iter: 1092 loss: 9.39044298e-07
Iter: 1093 loss: 9.38261564e-07
Iter: 1094 loss: 9.37663117e-07
Iter: 1095 loss: 9.38187441e-07
Iter: 1096 loss: 9.37317282e-07
Iter: 1097 loss: 9.3640358e-07
Iter: 1098 loss: 9.40455834e-07
Iter: 1099 loss: 9.36222818e-07
Iter: 1100 loss: 9.35640855e-07
Iter: 1101 loss: 9.36606966e-07
Iter: 1102 loss: 9.35384e-07
Iter: 1103 loss: 9.34905188e-07
Iter: 1104 loss: 9.34900584e-07
Iter: 1105 loss: 9.34538036e-07
Iter: 1106 loss: 9.3397e-07
Iter: 1107 loss: 9.33982562e-07
Iter: 1108 loss: 9.3332028e-07
Iter: 1109 loss: 9.33316301e-07
Iter: 1110 loss: 9.3292374e-07
Iter: 1111 loss: 9.33516844e-07
Iter: 1112 loss: 9.32739965e-07
Iter: 1113 loss: 9.32405e-07
Iter: 1114 loss: 9.35195e-07
Iter: 1115 loss: 9.32385149e-07
Iter: 1116 loss: 9.32043122e-07
Iter: 1117 loss: 9.31414547e-07
Iter: 1118 loss: 9.44663839e-07
Iter: 1119 loss: 9.31411364e-07
Iter: 1120 loss: 9.30957754e-07
Iter: 1121 loss: 9.35818093e-07
Iter: 1122 loss: 9.30948204e-07
Iter: 1123 loss: 9.30446106e-07
Iter: 1124 loss: 9.30580768e-07
Iter: 1125 loss: 9.30098508e-07
Iter: 1126 loss: 9.29535247e-07
Iter: 1127 loss: 9.3037329e-07
Iter: 1128 loss: 9.29293378e-07
Iter: 1129 loss: 9.28780082e-07
Iter: 1130 loss: 9.29109092e-07
Iter: 1131 loss: 9.28454824e-07
Iter: 1132 loss: 9.27753433e-07
Iter: 1133 loss: 9.3024e-07
Iter: 1134 loss: 9.27606607e-07
Iter: 1135 loss: 9.26935456e-07
Iter: 1136 loss: 9.29816565e-07
Iter: 1137 loss: 9.26804319e-07
Iter: 1138 loss: 9.26231905e-07
Iter: 1139 loss: 9.30344697e-07
Iter: 1140 loss: 9.26205587e-07
Iter: 1141 loss: 9.25661539e-07
Iter: 1142 loss: 9.26227926e-07
Iter: 1143 loss: 9.25377208e-07
Iter: 1144 loss: 9.250316e-07
Iter: 1145 loss: 9.30300871e-07
Iter: 1146 loss: 9.25030463e-07
Iter: 1147 loss: 9.24707592e-07
Iter: 1148 loss: 9.24301958e-07
Iter: 1149 loss: 9.24283086e-07
Iter: 1150 loss: 9.23830953e-07
Iter: 1151 loss: 9.23824587e-07
Iter: 1152 loss: 9.23588573e-07
Iter: 1153 loss: 9.23074481e-07
Iter: 1154 loss: 9.29959072e-07
Iter: 1155 loss: 9.2302696e-07
Iter: 1156 loss: 9.22374113e-07
Iter: 1157 loss: 9.25959512e-07
Iter: 1158 loss: 9.22266224e-07
Iter: 1159 loss: 9.21601952e-07
Iter: 1160 loss: 9.25423819e-07
Iter: 1161 loss: 9.21512594e-07
Iter: 1162 loss: 9.21162837e-07
Iter: 1163 loss: 9.20578373e-07
Iter: 1164 loss: 9.20580646e-07
Iter: 1165 loss: 9.19954857e-07
Iter: 1166 loss: 9.21596e-07
Iter: 1167 loss: 9.19743e-07
Iter: 1168 loss: 9.19062416e-07
Iter: 1169 loss: 9.23652806e-07
Iter: 1170 loss: 9.18965952e-07
Iter: 1171 loss: 9.18496653e-07
Iter: 1172 loss: 9.19814738e-07
Iter: 1173 loss: 9.18353066e-07
Iter: 1174 loss: 9.17796228e-07
Iter: 1175 loss: 9.20305297e-07
Iter: 1176 loss: 9.17712e-07
Iter: 1177 loss: 9.17256955e-07
Iter: 1178 loss: 9.19100671e-07
Iter: 1179 loss: 9.17182888e-07
Iter: 1180 loss: 9.16832732e-07
Iter: 1181 loss: 9.18713056e-07
Iter: 1182 loss: 9.16803117e-07
Iter: 1183 loss: 9.1645461e-07
Iter: 1184 loss: 9.16319664e-07
Iter: 1185 loss: 9.16115e-07
Iter: 1186 loss: 9.15684836e-07
Iter: 1187 loss: 9.2006178e-07
Iter: 1188 loss: 9.15663691e-07
Iter: 1189 loss: 9.15374699e-07
Iter: 1190 loss: 9.14799159e-07
Iter: 1191 loss: 9.25354584e-07
Iter: 1192 loss: 9.14800808e-07
Iter: 1193 loss: 9.14381076e-07
Iter: 1194 loss: 9.14365842e-07
Iter: 1195 loss: 9.13981125e-07
Iter: 1196 loss: 9.13883582e-07
Iter: 1197 loss: 9.13652343e-07
Iter: 1198 loss: 9.13193617e-07
Iter: 1199 loss: 9.13467602e-07
Iter: 1200 loss: 9.12902863e-07
Iter: 1201 loss: 9.12318853e-07
Iter: 1202 loss: 9.12644964e-07
Iter: 1203 loss: 9.11916e-07
Iter: 1204 loss: 9.11303e-07
Iter: 1205 loss: 9.14678e-07
Iter: 1206 loss: 9.11204097e-07
Iter: 1207 loss: 9.1067983e-07
Iter: 1208 loss: 9.1423874e-07
Iter: 1209 loss: 9.1061861e-07
Iter: 1210 loss: 9.10210701e-07
Iter: 1211 loss: 9.1335869e-07
Iter: 1212 loss: 9.10173924e-07
Iter: 1213 loss: 9.09825872e-07
Iter: 1214 loss: 9.0973316e-07
Iter: 1215 loss: 9.09523806e-07
Iter: 1216 loss: 9.09014432e-07
Iter: 1217 loss: 9.13728627e-07
Iter: 1218 loss: 9.08992774e-07
Iter: 1219 loss: 9.08656716e-07
Iter: 1220 loss: 9.0914159e-07
Iter: 1221 loss: 9.08489085e-07
Iter: 1222 loss: 9.08113861e-07
Iter: 1223 loss: 9.09446044e-07
Iter: 1224 loss: 9.08011e-07
Iter: 1225 loss: 9.07671279e-07
Iter: 1226 loss: 9.0736421e-07
Iter: 1227 loss: 9.07290541e-07
Iter: 1228 loss: 9.06703235e-07
Iter: 1229 loss: 9.0879422e-07
Iter: 1230 loss: 9.06540379e-07
Iter: 1231 loss: 9.06029584e-07
Iter: 1232 loss: 9.11738653e-07
Iter: 1233 loss: 9.06034586e-07
Iter: 1234 loss: 9.0580329e-07
Iter: 1235 loss: 9.05208822e-07
Iter: 1236 loss: 9.10900837e-07
Iter: 1237 loss: 9.05137085e-07
Iter: 1238 loss: 9.04433364e-07
Iter: 1239 loss: 9.08354764e-07
Iter: 1240 loss: 9.04331046e-07
Iter: 1241 loss: 9.03688431e-07
Iter: 1242 loss: 9.05464447e-07
Iter: 1243 loss: 9.03501643e-07
Iter: 1244 loss: 9.0299e-07
Iter: 1245 loss: 9.06212676e-07
Iter: 1246 loss: 9.02947e-07
Iter: 1247 loss: 9.02369152e-07
Iter: 1248 loss: 9.05194e-07
Iter: 1249 loss: 9.02275588e-07
Iter: 1250 loss: 9.02029797e-07
Iter: 1251 loss: 9.04026422e-07
Iter: 1252 loss: 9.02002171e-07
Iter: 1253 loss: 9.01755811e-07
Iter: 1254 loss: 9.01913722e-07
Iter: 1255 loss: 9.01580734e-07
Iter: 1256 loss: 9.01183398e-07
Iter: 1257 loss: 9.0124604e-07
Iter: 1258 loss: 9.00886846e-07
Iter: 1259 loss: 9.00423856e-07
Iter: 1260 loss: 9.03897899e-07
Iter: 1261 loss: 9.00392081e-07
Iter: 1262 loss: 9.00132704e-07
Iter: 1263 loss: 8.99779707e-07
Iter: 1264 loss: 8.99749239e-07
Iter: 1265 loss: 8.99284601e-07
Iter: 1266 loss: 9.04806427e-07
Iter: 1267 loss: 8.99289148e-07
Iter: 1268 loss: 8.98943881e-07
Iter: 1269 loss: 8.99526412e-07
Iter: 1270 loss: 8.98759e-07
Iter: 1271 loss: 8.98386304e-07
Iter: 1272 loss: 8.97679399e-07
Iter: 1273 loss: 9.13641429e-07
Iter: 1274 loss: 8.97674227e-07
Iter: 1275 loss: 8.96987501e-07
Iter: 1276 loss: 9.00406576e-07
Iter: 1277 loss: 8.9688e-07
Iter: 1278 loss: 8.96195843e-07
Iter: 1279 loss: 8.98263409e-07
Iter: 1280 loss: 8.95995584e-07
Iter: 1281 loss: 8.95516962e-07
Iter: 1282 loss: 9.01737906e-07
Iter: 1283 loss: 8.95525034e-07
Iter: 1284 loss: 8.95063636e-07
Iter: 1285 loss: 8.96420261e-07
Iter: 1286 loss: 8.94928689e-07
Iter: 1287 loss: 8.94620655e-07
Iter: 1288 loss: 8.9660125e-07
Iter: 1289 loss: 8.94591153e-07
Iter: 1290 loss: 8.94265384e-07
Iter: 1291 loss: 8.94144e-07
Iter: 1292 loss: 8.93978154e-07
Iter: 1293 loss: 8.93557171e-07
Iter: 1294 loss: 8.95762184e-07
Iter: 1295 loss: 8.93504762e-07
Iter: 1296 loss: 8.93122433e-07
Iter: 1297 loss: 8.92898697e-07
Iter: 1298 loss: 8.92724699e-07
Iter: 1299 loss: 8.92222829e-07
Iter: 1300 loss: 8.94537038e-07
Iter: 1301 loss: 8.92119772e-07
Iter: 1302 loss: 8.91742616e-07
Iter: 1303 loss: 8.94025732e-07
Iter: 1304 loss: 8.91682362e-07
Iter: 1305 loss: 8.91287186e-07
Iter: 1306 loss: 8.9163035e-07
Iter: 1307 loss: 8.91057596e-07
Iter: 1308 loss: 8.90707099e-07
Iter: 1309 loss: 8.90633601e-07
Iter: 1310 loss: 8.90402e-07
Iter: 1311 loss: 8.89823241e-07
Iter: 1312 loss: 8.90994784e-07
Iter: 1313 loss: 8.89590638e-07
Iter: 1314 loss: 8.89001853e-07
Iter: 1315 loss: 8.89027092e-07
Iter: 1316 loss: 8.88532213e-07
Iter: 1317 loss: 8.8865221e-07
Iter: 1318 loss: 8.88256864e-07
Iter: 1319 loss: 8.8802426e-07
Iter: 1320 loss: 8.87803139e-07
Iter: 1321 loss: 8.87756812e-07
Iter: 1322 loss: 8.87285637e-07
Iter: 1323 loss: 8.90049705e-07
Iter: 1324 loss: 8.87249143e-07
Iter: 1325 loss: 8.86833959e-07
Iter: 1326 loss: 8.87027625e-07
Iter: 1327 loss: 8.86563498e-07
Iter: 1328 loss: 8.86206294e-07
Iter: 1329 loss: 8.88882141e-07
Iter: 1330 loss: 8.86188786e-07
Iter: 1331 loss: 8.85908662e-07
Iter: 1332 loss: 8.85464829e-07
Iter: 1333 loss: 8.8546733e-07
Iter: 1334 loss: 8.84932547e-07
Iter: 1335 loss: 8.86498469e-07
Iter: 1336 loss: 8.84793451e-07
Iter: 1337 loss: 8.84239967e-07
Iter: 1338 loss: 8.88864861e-07
Iter: 1339 loss: 8.84200801e-07
Iter: 1340 loss: 8.8376089e-07
Iter: 1341 loss: 8.8420768e-07
Iter: 1342 loss: 8.83507767e-07
Iter: 1343 loss: 8.83040059e-07
Iter: 1344 loss: 8.82863901e-07
Iter: 1345 loss: 8.82590143e-07
Iter: 1346 loss: 8.82040467e-07
Iter: 1347 loss: 8.84555902e-07
Iter: 1348 loss: 8.81920698e-07
Iter: 1349 loss: 8.81434971e-07
Iter: 1350 loss: 8.82282336e-07
Iter: 1351 loss: 8.81194921e-07
Iter: 1352 loss: 8.80798609e-07
Iter: 1353 loss: 8.86009161e-07
Iter: 1354 loss: 8.80782636e-07
Iter: 1355 loss: 8.80357618e-07
Iter: 1356 loss: 8.81683832e-07
Iter: 1357 loss: 8.80238531e-07
Iter: 1358 loss: 8.79961931e-07
Iter: 1359 loss: 8.8156628e-07
Iter: 1360 loss: 8.79942888e-07
Iter: 1361 loss: 8.7958324e-07
Iter: 1362 loss: 8.79152822e-07
Iter: 1363 loss: 8.79127413e-07
Iter: 1364 loss: 8.78674427e-07
Iter: 1365 loss: 8.83038524e-07
Iter: 1366 loss: 8.78681931e-07
Iter: 1367 loss: 8.78366e-07
Iter: 1368 loss: 8.78598769e-07
Iter: 1369 loss: 8.7815647e-07
Iter: 1370 loss: 8.77751745e-07
Iter: 1371 loss: 8.77561661e-07
Iter: 1372 loss: 8.77404e-07
Iter: 1373 loss: 8.76944398e-07
Iter: 1374 loss: 8.76931495e-07
Iter: 1375 loss: 8.76593617e-07
Iter: 1376 loss: 8.76682748e-07
Iter: 1377 loss: 8.76321053e-07
Iter: 1378 loss: 8.7593105e-07
Iter: 1379 loss: 8.76417971e-07
Iter: 1380 loss: 8.7572829e-07
Iter: 1381 loss: 8.75261094e-07
Iter: 1382 loss: 8.7580878e-07
Iter: 1383 loss: 8.75007686e-07
Iter: 1384 loss: 8.74474267e-07
Iter: 1385 loss: 8.75431056e-07
Iter: 1386 loss: 8.74247519e-07
Iter: 1387 loss: 8.73844e-07
Iter: 1388 loss: 8.80109042e-07
Iter: 1389 loss: 8.73842282e-07
Iter: 1390 loss: 8.73490194e-07
Iter: 1391 loss: 8.75296621e-07
Iter: 1392 loss: 8.73413455e-07
Iter: 1393 loss: 8.73079955e-07
Iter: 1394 loss: 8.73282261e-07
Iter: 1395 loss: 8.72881913e-07
Iter: 1396 loss: 8.72373107e-07
Iter: 1397 loss: 8.73311e-07
Iter: 1398 loss: 8.72163469e-07
Iter: 1399 loss: 8.71906536e-07
Iter: 1400 loss: 8.72622479e-07
Iter: 1401 loss: 8.71790917e-07
Iter: 1402 loss: 8.71365842e-07
Iter: 1403 loss: 8.71266707e-07
Iter: 1404 loss: 8.71025691e-07
Iter: 1405 loss: 8.70499832e-07
Iter: 1406 loss: 8.71648695e-07
Iter: 1407 loss: 8.70295253e-07
Iter: 1408 loss: 8.69838345e-07
Iter: 1409 loss: 8.73694717e-07
Iter: 1410 loss: 8.69823566e-07
Iter: 1411 loss: 8.69386099e-07
Iter: 1412 loss: 8.70234885e-07
Iter: 1413 loss: 8.69207611e-07
Iter: 1414 loss: 8.68876896e-07
Iter: 1415 loss: 8.68609391e-07
Iter: 1416 loss: 8.68513212e-07
Iter: 1417 loss: 8.6793932e-07
Iter: 1418 loss: 8.70351073e-07
Iter: 1419 loss: 8.6779994e-07
Iter: 1420 loss: 8.6729159e-07
Iter: 1421 loss: 8.67805852e-07
Iter: 1422 loss: 8.67003564e-07
Iter: 1423 loss: 8.6656803e-07
Iter: 1424 loss: 8.73275781e-07
Iter: 1425 loss: 8.66566097e-07
Iter: 1426 loss: 8.66176322e-07
Iter: 1427 loss: 8.68190114e-07
Iter: 1428 loss: 8.66114249e-07
Iter: 1429 loss: 8.65864195e-07
Iter: 1430 loss: 8.66303196e-07
Iter: 1431 loss: 8.65771369e-07
Iter: 1432 loss: 8.65404843e-07
Iter: 1433 loss: 8.65381253e-07
Iter: 1434 loss: 8.65129152e-07
Iter: 1435 loss: 8.64710273e-07
Iter: 1436 loss: 8.65682466e-07
Iter: 1437 loss: 8.64599031e-07
Iter: 1438 loss: 8.64194135e-07
Iter: 1439 loss: 8.66731739e-07
Iter: 1440 loss: 8.64139338e-07
Iter: 1441 loss: 8.63805383e-07
Iter: 1442 loss: 8.63196817e-07
Iter: 1443 loss: 8.75814294e-07
Iter: 1444 loss: 8.63203752e-07
Iter: 1445 loss: 8.62917886e-07
Iter: 1446 loss: 8.6282671e-07
Iter: 1447 loss: 8.62541e-07
Iter: 1448 loss: 8.6241721e-07
Iter: 1449 loss: 8.62277375e-07
Iter: 1450 loss: 8.61830472e-07
Iter: 1451 loss: 8.61777949e-07
Iter: 1452 loss: 8.61476224e-07
Iter: 1453 loss: 8.60930186e-07
Iter: 1454 loss: 8.62230308e-07
Iter: 1455 loss: 8.60714692e-07
Iter: 1456 loss: 8.60198554e-07
Iter: 1457 loss: 8.63467903e-07
Iter: 1458 loss: 8.60104876e-07
Iter: 1459 loss: 8.59731131e-07
Iter: 1460 loss: 8.60417572e-07
Iter: 1461 loss: 8.59544912e-07
Iter: 1462 loss: 8.59061231e-07
Iter: 1463 loss: 8.65467655e-07
Iter: 1464 loss: 8.59030877e-07
Iter: 1465 loss: 8.58829708e-07
Iter: 1466 loss: 8.5882516e-07
Iter: 1467 loss: 8.58659632e-07
Iter: 1468 loss: 8.58261217e-07
Iter: 1469 loss: 8.58907e-07
Iter: 1470 loss: 8.5810052e-07
Iter: 1471 loss: 8.57714099e-07
Iter: 1472 loss: 8.57602458e-07
Iter: 1473 loss: 8.57363716e-07
Iter: 1474 loss: 8.56991619e-07
Iter: 1475 loss: 8.62567902e-07
Iter: 1476 loss: 8.56975817e-07
Iter: 1477 loss: 8.56643112e-07
Iter: 1478 loss: 8.56721613e-07
Iter: 1479 loss: 8.56392376e-07
Iter: 1480 loss: 8.56101224e-07
Iter: 1481 loss: 8.57273e-07
Iter: 1482 loss: 8.56025167e-07
Iter: 1483 loss: 8.556338e-07
Iter: 1484 loss: 8.5673264e-07
Iter: 1485 loss: 8.55494932e-07
Iter: 1486 loss: 8.55166945e-07
Iter: 1487 loss: 8.54810366e-07
Iter: 1488 loss: 8.54790073e-07
Iter: 1489 loss: 8.54255859e-07
Iter: 1490 loss: 8.56985196e-07
Iter: 1491 loss: 8.54178779e-07
Iter: 1492 loss: 8.53749839e-07
Iter: 1493 loss: 8.53983352e-07
Iter: 1494 loss: 8.53498648e-07
Iter: 1495 loss: 8.52895596e-07
Iter: 1496 loss: 8.5644308e-07
Iter: 1497 loss: 8.52815219e-07
Iter: 1498 loss: 8.5253572e-07
Iter: 1499 loss: 8.52556639e-07
Iter: 1500 loss: 8.52254402e-07
Iter: 1501 loss: 8.51887819e-07
Iter: 1502 loss: 8.5186656e-07
Iter: 1503 loss: 8.51561595e-07
Iter: 1504 loss: 8.55524775e-07
Iter: 1505 loss: 8.51550794e-07
Iter: 1506 loss: 8.51277662e-07
Iter: 1507 loss: 8.51062168e-07
Iter: 1508 loss: 8.5096417e-07
Iter: 1509 loss: 8.50612707e-07
Iter: 1510 loss: 8.5116892e-07
Iter: 1511 loss: 8.50415461e-07
Iter: 1512 loss: 8.49914613e-07
Iter: 1513 loss: 8.52545156e-07
Iter: 1514 loss: 8.49853848e-07
Iter: 1515 loss: 8.49483058e-07
Iter: 1516 loss: 8.49887215e-07
Iter: 1517 loss: 8.49250739e-07
Iter: 1518 loss: 8.48901436e-07
Iter: 1519 loss: 8.50838717e-07
Iter: 1520 loss: 8.48867444e-07
Iter: 1521 loss: 8.48402578e-07
Iter: 1522 loss: 8.48183959e-07
Iter: 1523 loss: 8.47985291e-07
Iter: 1524 loss: 8.47474325e-07
Iter: 1525 loss: 8.4744363e-07
Iter: 1526 loss: 8.47074773e-07
Iter: 1527 loss: 8.46555622e-07
Iter: 1528 loss: 8.52831704e-07
Iter: 1529 loss: 8.46543173e-07
Iter: 1530 loss: 8.46212345e-07
Iter: 1531 loss: 8.46894295e-07
Iter: 1532 loss: 8.46065632e-07
Iter: 1533 loss: 8.45844738e-07
Iter: 1534 loss: 8.45828822e-07
Iter: 1535 loss: 8.45670684e-07
Iter: 1536 loss: 8.45463092e-07
Iter: 1537 loss: 8.45445e-07
Iter: 1538 loss: 8.45113959e-07
Iter: 1539 loss: 8.45674833e-07
Iter: 1540 loss: 8.44970828e-07
Iter: 1541 loss: 8.4448277e-07
Iter: 1542 loss: 8.45275963e-07
Iter: 1543 loss: 8.44262445e-07
Iter: 1544 loss: 8.43956741e-07
Iter: 1545 loss: 8.4381594e-07
Iter: 1546 loss: 8.43655528e-07
Iter: 1547 loss: 8.43102839e-07
Iter: 1548 loss: 8.47730121e-07
Iter: 1549 loss: 8.430722e-07
Iter: 1550 loss: 8.42772238e-07
Iter: 1551 loss: 8.4279327e-07
Iter: 1552 loss: 8.42509053e-07
Iter: 1553 loss: 8.42144573e-07
Iter: 1554 loss: 8.43415762e-07
Iter: 1555 loss: 8.42028498e-07
Iter: 1556 loss: 8.41581368e-07
Iter: 1557 loss: 8.44296494e-07
Iter: 1558 loss: 8.41522251e-07
Iter: 1559 loss: 8.41263841e-07
Iter: 1560 loss: 8.40767e-07
Iter: 1561 loss: 8.40750772e-07
Iter: 1562 loss: 8.40219286e-07
Iter: 1563 loss: 8.41978078e-07
Iter: 1564 loss: 8.40073767e-07
Iter: 1565 loss: 8.39662107e-07
Iter: 1566 loss: 8.44129772e-07
Iter: 1567 loss: 8.39657673e-07
Iter: 1568 loss: 8.39368e-07
Iter: 1569 loss: 8.43314183e-07
Iter: 1570 loss: 8.39350378e-07
Iter: 1571 loss: 8.39124368e-07
Iter: 1572 loss: 8.38761366e-07
Iter: 1573 loss: 8.38745336e-07
Iter: 1574 loss: 8.3837773e-07
Iter: 1575 loss: 8.41641452e-07
Iter: 1576 loss: 8.38343908e-07
Iter: 1577 loss: 8.38019901e-07
Iter: 1578 loss: 8.38308551e-07
Iter: 1579 loss: 8.3781083e-07
Iter: 1580 loss: 8.37482901e-07
Iter: 1581 loss: 8.38000688e-07
Iter: 1582 loss: 8.37351422e-07
Iter: 1583 loss: 8.37054131e-07
Iter: 1584 loss: 8.39025802e-07
Iter: 1585 loss: 8.37035827e-07
Iter: 1586 loss: 8.36686e-07
Iter: 1587 loss: 8.36426238e-07
Iter: 1588 loss: 8.36354e-07
Iter: 1589 loss: 8.35895435e-07
Iter: 1590 loss: 8.3721568e-07
Iter: 1591 loss: 8.35801188e-07
Iter: 1592 loss: 8.35302671e-07
Iter: 1593 loss: 8.38609253e-07
Iter: 1594 loss: 8.35283231e-07
Iter: 1595 loss: 8.35009e-07
Iter: 1596 loss: 8.35224569e-07
Iter: 1597 loss: 8.3483485e-07
Iter: 1598 loss: 8.34509478e-07
Iter: 1599 loss: 8.33959803e-07
Iter: 1600 loss: 8.33972308e-07
Iter: 1601 loss: 8.33796662e-07
Iter: 1602 loss: 8.33705144e-07
Iter: 1603 loss: 8.33410695e-07
Iter: 1604 loss: 8.34168418e-07
Iter: 1605 loss: 8.33356353e-07
Iter: 1606 loss: 8.3307043e-07
Iter: 1607 loss: 8.32866249e-07
Iter: 1608 loss: 8.32754381e-07
Iter: 1609 loss: 8.32433329e-07
Iter: 1610 loss: 8.35952392e-07
Iter: 1611 loss: 8.32413e-07
Iter: 1612 loss: 8.32142e-07
Iter: 1613 loss: 8.32085902e-07
Iter: 1614 loss: 8.31871034e-07
Iter: 1615 loss: 8.31553564e-07
Iter: 1616 loss: 8.32383762e-07
Iter: 1617 loss: 8.31461e-07
Iter: 1618 loss: 8.31116608e-07
Iter: 1619 loss: 8.3269822e-07
Iter: 1620 loss: 8.31058685e-07
Iter: 1621 loss: 8.30750082e-07
Iter: 1622 loss: 8.31118768e-07
Iter: 1623 loss: 8.305405e-07
Iter: 1624 loss: 8.30235649e-07
Iter: 1625 loss: 8.30525039e-07
Iter: 1626 loss: 8.30059321e-07
Iter: 1627 loss: 8.29628561e-07
Iter: 1628 loss: 8.32857211e-07
Iter: 1629 loss: 8.29599344e-07
Iter: 1630 loss: 8.29344913e-07
Iter: 1631 loss: 8.29103442e-07
Iter: 1632 loss: 8.29053874e-07
Iter: 1633 loss: 8.28606801e-07
Iter: 1634 loss: 8.29040232e-07
Iter: 1635 loss: 8.28361749e-07
Iter: 1636 loss: 8.27973963e-07
Iter: 1637 loss: 8.339739e-07
Iter: 1638 loss: 8.27971633e-07
Iter: 1639 loss: 8.27560712e-07
Iter: 1640 loss: 8.29041596e-07
Iter: 1641 loss: 8.27455779e-07
Iter: 1642 loss: 8.27240569e-07
Iter: 1643 loss: 8.26938958e-07
Iter: 1644 loss: 8.26925145e-07
Iter: 1645 loss: 8.26472956e-07
Iter: 1646 loss: 8.29608723e-07
Iter: 1647 loss: 8.26398775e-07
Iter: 1648 loss: 8.26092901e-07
Iter: 1649 loss: 8.26743417e-07
Iter: 1650 loss: 8.25962161e-07
Iter: 1651 loss: 8.25698521e-07
Iter: 1652 loss: 8.25721656e-07
Iter: 1653 loss: 8.25492805e-07
Iter: 1654 loss: 8.25123834e-07
Iter: 1655 loss: 8.28696557e-07
Iter: 1656 loss: 8.25122243e-07
Iter: 1657 loss: 8.24869119e-07
Iter: 1658 loss: 8.24912263e-07
Iter: 1659 loss: 8.24669712e-07
Iter: 1660 loss: 8.24351503e-07
Iter: 1661 loss: 8.25122584e-07
Iter: 1662 loss: 8.24236224e-07
Iter: 1663 loss: 8.23952064e-07
Iter: 1664 loss: 8.26371e-07
Iter: 1665 loss: 8.23926086e-07
Iter: 1666 loss: 8.2367751e-07
Iter: 1667 loss: 8.23184564e-07
Iter: 1668 loss: 8.33028594e-07
Iter: 1669 loss: 8.23194682e-07
Iter: 1670 loss: 8.22688435e-07
Iter: 1671 loss: 8.24516121e-07
Iter: 1672 loss: 8.22578e-07
Iter: 1673 loss: 8.22327934e-07
Iter: 1674 loss: 8.2227848e-07
Iter: 1675 loss: 8.2202456e-07
Iter: 1676 loss: 8.21844253e-07
Iter: 1677 loss: 8.21748131e-07
Iter: 1678 loss: 8.21418325e-07
Iter: 1679 loss: 8.21316348e-07
Iter: 1680 loss: 8.2110796e-07
Iter: 1681 loss: 8.20623598e-07
Iter: 1682 loss: 8.27715212e-07
Iter: 1683 loss: 8.20633204e-07
Iter: 1684 loss: 8.20431865e-07
Iter: 1685 loss: 8.20095579e-07
Iter: 1686 loss: 8.20104447e-07
Iter: 1687 loss: 8.196198e-07
Iter: 1688 loss: 8.21956519e-07
Iter: 1689 loss: 8.19543743e-07
Iter: 1690 loss: 8.19187335e-07
Iter: 1691 loss: 8.21633478e-07
Iter: 1692 loss: 8.19170396e-07
Iter: 1693 loss: 8.18870603e-07
Iter: 1694 loss: 8.18773628e-07
Iter: 1695 loss: 8.1862089e-07
Iter: 1696 loss: 8.18296883e-07
Iter: 1697 loss: 8.21292474e-07
Iter: 1698 loss: 8.18292847e-07
Iter: 1699 loss: 8.18004423e-07
Iter: 1700 loss: 8.18485546e-07
Iter: 1701 loss: 8.17899604e-07
Iter: 1702 loss: 8.17610328e-07
Iter: 1703 loss: 8.17409614e-07
Iter: 1704 loss: 8.17286434e-07
Iter: 1705 loss: 8.1685414e-07
Iter: 1706 loss: 8.17033424e-07
Iter: 1707 loss: 8.16578222e-07
Iter: 1708 loss: 8.16447937e-07
Iter: 1709 loss: 8.16257739e-07
Iter: 1710 loss: 8.16084366e-07
Iter: 1711 loss: 8.15785256e-07
Iter: 1712 loss: 8.22539903e-07
Iter: 1713 loss: 8.15768203e-07
Iter: 1714 loss: 8.15450903e-07
Iter: 1715 loss: 8.17068155e-07
Iter: 1716 loss: 8.15391957e-07
Iter: 1717 loss: 8.15038959e-07
Iter: 1718 loss: 8.16294175e-07
Iter: 1719 loss: 8.14957559e-07
Iter: 1720 loss: 8.14685109e-07
Iter: 1721 loss: 8.14581199e-07
Iter: 1722 loss: 8.14446594e-07
Iter: 1723 loss: 8.14109285e-07
Iter: 1724 loss: 8.16191459e-07
Iter: 1725 loss: 8.14077e-07
Iter: 1726 loss: 8.13737131e-07
Iter: 1727 loss: 8.14161467e-07
Iter: 1728 loss: 8.13520671e-07
Iter: 1729 loss: 8.13162501e-07
Iter: 1730 loss: 8.14303803e-07
Iter: 1731 loss: 8.1306672e-07
Iter: 1732 loss: 8.12732083e-07
Iter: 1733 loss: 8.13506176e-07
Iter: 1734 loss: 8.12612257e-07
Iter: 1735 loss: 8.121512e-07
Iter: 1736 loss: 8.13042675e-07
Iter: 1737 loss: 8.11973e-07
Iter: 1738 loss: 8.11563552e-07
Iter: 1739 loss: 8.11683776e-07
Iter: 1740 loss: 8.1130429e-07
Iter: 1741 loss: 8.10846473e-07
Iter: 1742 loss: 8.12862e-07
Iter: 1743 loss: 8.10779738e-07
Iter: 1744 loss: 8.10683957e-07
Iter: 1745 loss: 8.10604547e-07
Iter: 1746 loss: 8.10455902e-07
Iter: 1747 loss: 8.10123083e-07
Iter: 1748 loss: 8.12048711e-07
Iter: 1749 loss: 8.09990695e-07
Iter: 1750 loss: 8.09682149e-07
Iter: 1751 loss: 8.12800522e-07
Iter: 1752 loss: 8.09682604e-07
Iter: 1753 loss: 8.09302719e-07
Iter: 1754 loss: 8.09421294e-07
Iter: 1755 loss: 8.09018559e-07
Iter: 1756 loss: 8.0868142e-07
Iter: 1757 loss: 8.09395715e-07
Iter: 1758 loss: 8.08542836e-07
Iter: 1759 loss: 8.08160394e-07
Iter: 1760 loss: 8.08903906e-07
Iter: 1761 loss: 8.07996173e-07
Iter: 1762 loss: 8.07522269e-07
Iter: 1763 loss: 8.10194877e-07
Iter: 1764 loss: 8.0746554e-07
Iter: 1765 loss: 8.07214e-07
Iter: 1766 loss: 8.07626236e-07
Iter: 1767 loss: 8.07116066e-07
Iter: 1768 loss: 8.06823437e-07
Iter: 1769 loss: 8.07350318e-07
Iter: 1770 loss: 8.06659273e-07
Iter: 1771 loss: 8.06300761e-07
Iter: 1772 loss: 8.0756422e-07
Iter: 1773 loss: 8.06207936e-07
Iter: 1774 loss: 8.05922582e-07
Iter: 1775 loss: 8.05622449e-07
Iter: 1776 loss: 8.05578e-07
Iter: 1777 loss: 8.05137063e-07
Iter: 1778 loss: 8.09717562e-07
Iter: 1779 loss: 8.05129844e-07
Iter: 1780 loss: 8.04844831e-07
Iter: 1781 loss: 8.08989284e-07
Iter: 1782 loss: 8.04844035e-07
Iter: 1783 loss: 8.04671572e-07
Iter: 1784 loss: 8.04236834e-07
Iter: 1785 loss: 8.09024755e-07
Iter: 1786 loss: 8.04196247e-07
Iter: 1787 loss: 8.03826481e-07
Iter: 1788 loss: 8.06962419e-07
Iter: 1789 loss: 8.03784246e-07
Iter: 1790 loss: 8.03423234e-07
Iter: 1791 loss: 8.05674517e-07
Iter: 1792 loss: 8.03355874e-07
Iter: 1793 loss: 8.03156922e-07
Iter: 1794 loss: 8.02737247e-07
Iter: 1795 loss: 8.08846153e-07
Iter: 1796 loss: 8.02719e-07
Iter: 1797 loss: 8.02407953e-07
Iter: 1798 loss: 8.02399541e-07
Iter: 1799 loss: 8.02094405e-07
Iter: 1800 loss: 8.02257773e-07
Iter: 1801 loss: 8.01921487e-07
Iter: 1802 loss: 8.01593615e-07
Iter: 1803 loss: 8.01746467e-07
Iter: 1804 loss: 8.01351689e-07
Iter: 1805 loss: 8.0096703e-07
Iter: 1806 loss: 8.05714308e-07
Iter: 1807 loss: 8.00968166e-07
Iter: 1808 loss: 8.00693897e-07
Iter: 1809 loss: 8.00575663e-07
Iter: 1810 loss: 8.00445264e-07
Iter: 1811 loss: 8.00079761e-07
Iter: 1812 loss: 8.0120094e-07
Iter: 1813 loss: 7.9997551e-07
Iter: 1814 loss: 7.99665e-07
Iter: 1815 loss: 8.00825433e-07
Iter: 1816 loss: 7.99572945e-07
Iter: 1817 loss: 7.99241548e-07
Iter: 1818 loss: 8.02341106e-07
Iter: 1819 loss: 7.99220345e-07
Iter: 1820 loss: 7.99098075e-07
Iter: 1821 loss: 7.98787369e-07
Iter: 1822 loss: 8.04205968e-07
Iter: 1823 loss: 7.98798624e-07
Iter: 1824 loss: 7.98457506e-07
Iter: 1825 loss: 7.9948876e-07
Iter: 1826 loss: 7.98376846e-07
Iter: 1827 loss: 7.98056476e-07
Iter: 1828 loss: 8.02163072e-07
Iter: 1829 loss: 7.98034648e-07
Iter: 1830 loss: 7.97830239e-07
Iter: 1831 loss: 7.97566656e-07
Iter: 1832 loss: 7.97549035e-07
Iter: 1833 loss: 7.97181e-07
Iter: 1834 loss: 7.97319103e-07
Iter: 1835 loss: 7.96917675e-07
Iter: 1836 loss: 7.96537847e-07
Iter: 1837 loss: 7.96536369e-07
Iter: 1838 loss: 7.96308939e-07
Iter: 1839 loss: 7.95915867e-07
Iter: 1840 loss: 8.05077e-07
Iter: 1841 loss: 7.95914275e-07
Iter: 1842 loss: 7.95527399e-07
Iter: 1843 loss: 8.01292344e-07
Iter: 1844 loss: 7.95546612e-07
Iter: 1845 loss: 7.95254721e-07
Iter: 1846 loss: 7.95802066e-07
Iter: 1847 loss: 7.95144842e-07
Iter: 1848 loss: 7.94903769e-07
Iter: 1849 loss: 7.94788093e-07
Iter: 1850 loss: 7.94675543e-07
Iter: 1851 loss: 7.94455445e-07
Iter: 1852 loss: 7.94437824e-07
Iter: 1853 loss: 7.94243874e-07
Iter: 1854 loss: 7.94240748e-07
Iter: 1855 loss: 7.94059588e-07
Iter: 1856 loss: 7.93806066e-07
Iter: 1857 loss: 7.93373488e-07
Iter: 1858 loss: 7.9336138e-07
Iter: 1859 loss: 7.92949947e-07
Iter: 1860 loss: 7.94831294e-07
Iter: 1861 loss: 7.928694e-07
Iter: 1862 loss: 7.92502192e-07
Iter: 1863 loss: 7.98272254e-07
Iter: 1864 loss: 7.92510036e-07
Iter: 1865 loss: 7.92326261e-07
Iter: 1866 loss: 7.92176081e-07
Iter: 1867 loss: 7.92118669e-07
Iter: 1868 loss: 7.91814841e-07
Iter: 1869 loss: 7.9180586e-07
Iter: 1870 loss: 7.91545176e-07
Iter: 1871 loss: 7.91324169e-07
Iter: 1872 loss: 7.91304046e-07
Iter: 1873 loss: 7.91084801e-07
Iter: 1874 loss: 7.9054837e-07
Iter: 1875 loss: 7.97056714e-07
Iter: 1876 loss: 7.9051722e-07
Iter: 1877 loss: 7.90263869e-07
Iter: 1878 loss: 7.9023647e-07
Iter: 1879 loss: 7.89979e-07
Iter: 1880 loss: 7.89819069e-07
Iter: 1881 loss: 7.89727665e-07
Iter: 1882 loss: 7.89376e-07
Iter: 1883 loss: 7.91206844e-07
Iter: 1884 loss: 7.89317141e-07
Iter: 1885 loss: 7.89084197e-07
Iter: 1886 loss: 7.89087608e-07
Iter: 1887 loss: 7.88935608e-07
Iter: 1888 loss: 7.88560897e-07
Iter: 1889 loss: 7.92009359e-07
Iter: 1890 loss: 7.88512e-07
Iter: 1891 loss: 7.88039529e-07
Iter: 1892 loss: 7.90327135e-07
Iter: 1893 loss: 7.87959664e-07
Iter: 1894 loss: 7.87643387e-07
Iter: 1895 loss: 7.88236491e-07
Iter: 1896 loss: 7.8752754e-07
Iter: 1897 loss: 7.87270665e-07
Iter: 1898 loss: 7.87246222e-07
Iter: 1899 loss: 7.8708814e-07
Iter: 1900 loss: 7.86722808e-07
Iter: 1901 loss: 7.91138518e-07
Iter: 1902 loss: 7.86660507e-07
Iter: 1903 loss: 7.86217697e-07
Iter: 1904 loss: 7.88491889e-07
Iter: 1905 loss: 7.86137605e-07
Iter: 1906 loss: 7.85877546e-07
Iter: 1907 loss: 7.8587891e-07
Iter: 1908 loss: 7.8562681e-07
Iter: 1909 loss: 7.85484303e-07
Iter: 1910 loss: 7.85395628e-07
Iter: 1911 loss: 7.85109194e-07
Iter: 1912 loss: 7.86023065e-07
Iter: 1913 loss: 7.85056159e-07
Iter: 1914 loss: 7.84705492e-07
Iter: 1915 loss: 7.85775114e-07
Iter: 1916 loss: 7.84597432e-07
Iter: 1917 loss: 7.84333793e-07
Iter: 1918 loss: 7.84508075e-07
Iter: 1919 loss: 7.84136773e-07
Iter: 1920 loss: 7.8374137e-07
Iter: 1921 loss: 7.88277362e-07
Iter: 1922 loss: 7.8374535e-07
Iter: 1923 loss: 7.83592782e-07
Iter: 1924 loss: 7.83327664e-07
Iter: 1925 loss: 7.83327323e-07
Iter: 1926 loss: 7.82945449e-07
Iter: 1927 loss: 7.82850179e-07
Iter: 1928 loss: 7.8258995e-07
Iter: 1929 loss: 7.82284928e-07
Iter: 1930 loss: 7.82268216e-07
Iter: 1931 loss: 7.82005884e-07
Iter: 1932 loss: 7.83204825e-07
Iter: 1933 loss: 7.81955407e-07
Iter: 1934 loss: 7.81632e-07
Iter: 1935 loss: 7.81625886e-07
Iter: 1936 loss: 7.81409256e-07
Iter: 1937 loss: 7.81077e-07
Iter: 1938 loss: 7.80723838e-07
Iter: 1939 loss: 7.80669438e-07
Iter: 1940 loss: 7.80477421e-07
Iter: 1941 loss: 7.80385506e-07
Iter: 1942 loss: 7.80153869e-07
Iter: 1943 loss: 7.80198491e-07
Iter: 1944 loss: 7.79970946e-07
Iter: 1945 loss: 7.79713901e-07
Iter: 1946 loss: 7.80097594e-07
Iter: 1947 loss: 7.7959703e-07
Iter: 1948 loss: 7.7931395e-07
Iter: 1949 loss: 7.81698873e-07
Iter: 1950 loss: 7.79289167e-07
Iter: 1951 loss: 7.79054119e-07
Iter: 1952 loss: 7.79106472e-07
Iter: 1953 loss: 7.7888717e-07
Iter: 1954 loss: 7.78631e-07
Iter: 1955 loss: 7.78626486e-07
Iter: 1956 loss: 7.78479944e-07
Iter: 1957 loss: 7.78118647e-07
Iter: 1958 loss: 7.80195592e-07
Iter: 1959 loss: 7.77987111e-07
Iter: 1960 loss: 7.77608932e-07
Iter: 1961 loss: 7.80199855e-07
Iter: 1962 loss: 7.77574e-07
Iter: 1963 loss: 7.77239848e-07
Iter: 1964 loss: 7.78718288e-07
Iter: 1965 loss: 7.77165e-07
Iter: 1966 loss: 7.7688378e-07
Iter: 1967 loss: 7.79248751e-07
Iter: 1968 loss: 7.76869115e-07
Iter: 1969 loss: 7.76590241e-07
Iter: 1970 loss: 7.76259867e-07
Iter: 1971 loss: 7.76220531e-07
Iter: 1972 loss: 7.75842523e-07
Iter: 1973 loss: 7.77760761e-07
Iter: 1974 loss: 7.7579e-07
Iter: 1975 loss: 7.75533181e-07
Iter: 1976 loss: 7.76483148e-07
Iter: 1977 loss: 7.75478497e-07
Iter: 1978 loss: 7.75102876e-07
Iter: 1979 loss: 7.7611287e-07
Iter: 1980 loss: 7.74977138e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2
+ date
Mon Oct 26 15:46:23 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac4640d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac4642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac3777b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac377598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac2c79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac2cd0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac26f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac252ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac2527b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac26f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac1b6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac1e1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac18ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac19db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac13d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac123e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac0e4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac105b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac0db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac088158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac0889d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e9078a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac02bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac05a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3eac05a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e9075f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e9073a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e906c6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e906c0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e906c6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e906a4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e9066a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e9066a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e905fd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e9060a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e905bfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.74262022e-05
Iter: 2 loss: 1.4167792e-05
Iter: 3 loss: 1.40845441e-05
Iter: 4 loss: 1.29039163e-05
Iter: 5 loss: 2.12819414e-05
Iter: 6 loss: 1.27996827e-05
Iter: 7 loss: 1.22221099e-05
Iter: 8 loss: 1.36381532e-05
Iter: 9 loss: 1.20162931e-05
Iter: 10 loss: 1.14404866e-05
Iter: 11 loss: 1.07084488e-05
Iter: 12 loss: 1.06536445e-05
Iter: 13 loss: 1.0122104e-05
Iter: 14 loss: 1.56267852e-05
Iter: 15 loss: 1.01073801e-05
Iter: 16 loss: 9.55763517e-06
Iter: 17 loss: 9.51432685e-06
Iter: 18 loss: 9.10490417e-06
Iter: 19 loss: 8.53530855e-06
Iter: 20 loss: 9.81958146e-06
Iter: 21 loss: 8.32022124e-06
Iter: 22 loss: 7.77613e-06
Iter: 23 loss: 1.24003273e-05
Iter: 24 loss: 7.74530326e-06
Iter: 25 loss: 7.415038e-06
Iter: 26 loss: 8.19478828e-06
Iter: 27 loss: 7.29440671e-06
Iter: 28 loss: 6.96128518e-06
Iter: 29 loss: 7.02742545e-06
Iter: 30 loss: 6.71377e-06
Iter: 31 loss: 6.27696318e-06
Iter: 32 loss: 6.85591795e-06
Iter: 33 loss: 6.05618425e-06
Iter: 34 loss: 5.7297957e-06
Iter: 35 loss: 7.86853e-06
Iter: 36 loss: 5.69521353e-06
Iter: 37 loss: 5.38662e-06
Iter: 38 loss: 6.42336454e-06
Iter: 39 loss: 5.30304533e-06
Iter: 40 loss: 5.14709336e-06
Iter: 41 loss: 7.14555e-06
Iter: 42 loss: 5.14589919e-06
Iter: 43 loss: 4.99477574e-06
Iter: 44 loss: 6.04233082e-06
Iter: 45 loss: 4.98049212e-06
Iter: 46 loss: 4.89934791e-06
Iter: 47 loss: 4.77699405e-06
Iter: 48 loss: 4.77458798e-06
Iter: 49 loss: 4.58815384e-06
Iter: 50 loss: 5.59649834e-06
Iter: 51 loss: 4.5603374e-06
Iter: 52 loss: 4.44608895e-06
Iter: 53 loss: 4.55457712e-06
Iter: 54 loss: 4.38070674e-06
Iter: 55 loss: 4.26034831e-06
Iter: 56 loss: 4.42257306e-06
Iter: 57 loss: 4.20006381e-06
Iter: 58 loss: 4.09345193e-06
Iter: 59 loss: 5.76977754e-06
Iter: 60 loss: 4.09343193e-06
Iter: 61 loss: 4.02877686e-06
Iter: 62 loss: 3.91773938e-06
Iter: 63 loss: 3.91758931e-06
Iter: 64 loss: 3.79826361e-06
Iter: 65 loss: 4.73157e-06
Iter: 66 loss: 3.78983304e-06
Iter: 67 loss: 3.69536519e-06
Iter: 68 loss: 3.83332599e-06
Iter: 69 loss: 3.64956077e-06
Iter: 70 loss: 3.54216445e-06
Iter: 71 loss: 4.38142342e-06
Iter: 72 loss: 3.53445739e-06
Iter: 73 loss: 3.47776358e-06
Iter: 74 loss: 3.38838663e-06
Iter: 75 loss: 3.38732798e-06
Iter: 76 loss: 3.30773037e-06
Iter: 77 loss: 3.30770581e-06
Iter: 78 loss: 3.25180736e-06
Iter: 79 loss: 3.45929493e-06
Iter: 80 loss: 3.23810309e-06
Iter: 81 loss: 3.15737225e-06
Iter: 82 loss: 3.40927863e-06
Iter: 83 loss: 3.13376563e-06
Iter: 84 loss: 3.10915789e-06
Iter: 85 loss: 3.05015692e-06
Iter: 86 loss: 3.70923181e-06
Iter: 87 loss: 3.04438208e-06
Iter: 88 loss: 3.00280431e-06
Iter: 89 loss: 2.99547901e-06
Iter: 90 loss: 2.97442898e-06
Iter: 91 loss: 2.9213129e-06
Iter: 92 loss: 3.39831354e-06
Iter: 93 loss: 2.91314836e-06
Iter: 94 loss: 2.88328238e-06
Iter: 95 loss: 2.87630132e-06
Iter: 96 loss: 2.85228498e-06
Iter: 97 loss: 2.84515409e-06
Iter: 98 loss: 2.83086433e-06
Iter: 99 loss: 2.7901574e-06
Iter: 100 loss: 2.82037718e-06
Iter: 101 loss: 2.76522678e-06
Iter: 102 loss: 2.73066803e-06
Iter: 103 loss: 2.82375072e-06
Iter: 104 loss: 2.71926638e-06
Iter: 105 loss: 2.68245776e-06
Iter: 106 loss: 2.93396351e-06
Iter: 107 loss: 2.6788382e-06
Iter: 108 loss: 2.64855953e-06
Iter: 109 loss: 2.68049871e-06
Iter: 110 loss: 2.63176503e-06
Iter: 111 loss: 2.60160959e-06
Iter: 112 loss: 2.64935397e-06
Iter: 113 loss: 2.58764612e-06
Iter: 114 loss: 2.5587683e-06
Iter: 115 loss: 2.94557867e-06
Iter: 116 loss: 2.55863415e-06
Iter: 117 loss: 2.52784412e-06
Iter: 118 loss: 2.59229228e-06
Iter: 119 loss: 2.51564666e-06
Iter: 120 loss: 2.50124435e-06
Iter: 121 loss: 2.47823618e-06
Iter: 122 loss: 2.47804655e-06
Iter: 123 loss: 2.45257797e-06
Iter: 124 loss: 2.73735918e-06
Iter: 125 loss: 2.45210958e-06
Iter: 126 loss: 2.43281829e-06
Iter: 127 loss: 2.51610982e-06
Iter: 128 loss: 2.42887108e-06
Iter: 129 loss: 2.41277257e-06
Iter: 130 loss: 2.38609755e-06
Iter: 131 loss: 2.38599705e-06
Iter: 132 loss: 2.36123105e-06
Iter: 133 loss: 2.53055941e-06
Iter: 134 loss: 2.35885432e-06
Iter: 135 loss: 2.33424043e-06
Iter: 136 loss: 2.48659308e-06
Iter: 137 loss: 2.33138917e-06
Iter: 138 loss: 2.31660533e-06
Iter: 139 loss: 2.3271009e-06
Iter: 140 loss: 2.30736987e-06
Iter: 141 loss: 2.28984982e-06
Iter: 142 loss: 2.30358364e-06
Iter: 143 loss: 2.27927103e-06
Iter: 144 loss: 2.25668782e-06
Iter: 145 loss: 2.30466321e-06
Iter: 146 loss: 2.24776932e-06
Iter: 147 loss: 2.23093616e-06
Iter: 148 loss: 2.23073403e-06
Iter: 149 loss: 2.22193944e-06
Iter: 150 loss: 2.20961419e-06
Iter: 151 loss: 2.20920288e-06
Iter: 152 loss: 2.18880109e-06
Iter: 153 loss: 2.4293588e-06
Iter: 154 loss: 2.18851437e-06
Iter: 155 loss: 2.17881552e-06
Iter: 156 loss: 2.17176307e-06
Iter: 157 loss: 2.16838271e-06
Iter: 158 loss: 2.15677801e-06
Iter: 159 loss: 2.14314923e-06
Iter: 160 loss: 2.14161901e-06
Iter: 161 loss: 2.13434578e-06
Iter: 162 loss: 2.13102567e-06
Iter: 163 loss: 2.12182658e-06
Iter: 164 loss: 2.10931285e-06
Iter: 165 loss: 2.10869257e-06
Iter: 166 loss: 2.09441805e-06
Iter: 167 loss: 2.16535432e-06
Iter: 168 loss: 2.09213863e-06
Iter: 169 loss: 2.08090523e-06
Iter: 170 loss: 2.07250014e-06
Iter: 171 loss: 2.06879668e-06
Iter: 172 loss: 2.05846254e-06
Iter: 173 loss: 2.0569787e-06
Iter: 174 loss: 2.050381e-06
Iter: 175 loss: 2.04122716e-06
Iter: 176 loss: 2.04082517e-06
Iter: 177 loss: 2.0279781e-06
Iter: 178 loss: 2.06684376e-06
Iter: 179 loss: 2.0241132e-06
Iter: 180 loss: 2.01247485e-06
Iter: 181 loss: 2.05512151e-06
Iter: 182 loss: 2.00954605e-06
Iter: 183 loss: 2.00237719e-06
Iter: 184 loss: 2.00232739e-06
Iter: 185 loss: 1.99644046e-06
Iter: 186 loss: 2.0188545e-06
Iter: 187 loss: 1.99504348e-06
Iter: 188 loss: 1.98829412e-06
Iter: 189 loss: 1.97962163e-06
Iter: 190 loss: 1.97899203e-06
Iter: 191 loss: 1.96993278e-06
Iter: 192 loss: 1.96163e-06
Iter: 193 loss: 1.95949224e-06
Iter: 194 loss: 1.95014445e-06
Iter: 195 loss: 2.06667437e-06
Iter: 196 loss: 1.95009511e-06
Iter: 197 loss: 1.94095833e-06
Iter: 198 loss: 1.97790177e-06
Iter: 199 loss: 1.93893266e-06
Iter: 200 loss: 1.93010351e-06
Iter: 201 loss: 1.95505618e-06
Iter: 202 loss: 1.92733046e-06
Iter: 203 loss: 1.92129846e-06
Iter: 204 loss: 1.90682965e-06
Iter: 205 loss: 2.06408345e-06
Iter: 206 loss: 1.90525952e-06
Iter: 207 loss: 1.90184733e-06
Iter: 208 loss: 1.89759442e-06
Iter: 209 loss: 1.89191314e-06
Iter: 210 loss: 1.9017757e-06
Iter: 211 loss: 1.88935599e-06
Iter: 212 loss: 1.88221532e-06
Iter: 213 loss: 1.88636955e-06
Iter: 214 loss: 1.87744536e-06
Iter: 215 loss: 1.86980333e-06
Iter: 216 loss: 1.87179864e-06
Iter: 217 loss: 1.86423267e-06
Iter: 218 loss: 1.85550925e-06
Iter: 219 loss: 1.92605876e-06
Iter: 220 loss: 1.85489159e-06
Iter: 221 loss: 1.85015813e-06
Iter: 222 loss: 1.84997089e-06
Iter: 223 loss: 1.84560224e-06
Iter: 224 loss: 1.84466103e-06
Iter: 225 loss: 1.84179976e-06
Iter: 226 loss: 1.83691179e-06
Iter: 227 loss: 1.84345618e-06
Iter: 228 loss: 1.83445741e-06
Iter: 229 loss: 1.82839165e-06
Iter: 230 loss: 1.82553447e-06
Iter: 231 loss: 1.82253621e-06
Iter: 232 loss: 1.81527116e-06
Iter: 233 loss: 1.8207827e-06
Iter: 234 loss: 1.81079668e-06
Iter: 235 loss: 1.80124198e-06
Iter: 236 loss: 1.87819739e-06
Iter: 237 loss: 1.80058714e-06
Iter: 238 loss: 1.79652511e-06
Iter: 239 loss: 1.79647509e-06
Iter: 240 loss: 1.7928113e-06
Iter: 241 loss: 1.78542086e-06
Iter: 242 loss: 1.92064363e-06
Iter: 243 loss: 1.78531513e-06
Iter: 244 loss: 1.77872607e-06
Iter: 245 loss: 1.79354333e-06
Iter: 246 loss: 1.77627635e-06
Iter: 247 loss: 1.77047366e-06
Iter: 248 loss: 1.83907059e-06
Iter: 249 loss: 1.77036213e-06
Iter: 250 loss: 1.76519438e-06
Iter: 251 loss: 1.77567586e-06
Iter: 252 loss: 1.76312028e-06
Iter: 253 loss: 1.75789501e-06
Iter: 254 loss: 1.76560116e-06
Iter: 255 loss: 1.75542402e-06
Iter: 256 loss: 1.74997808e-06
Iter: 257 loss: 1.75237392e-06
Iter: 258 loss: 1.74621084e-06
Iter: 259 loss: 1.74844286e-06
Iter: 260 loss: 1.74413299e-06
Iter: 261 loss: 1.74217166e-06
Iter: 262 loss: 1.73740045e-06
Iter: 263 loss: 1.78310324e-06
Iter: 264 loss: 1.73674266e-06
Iter: 265 loss: 1.7314369e-06
Iter: 266 loss: 1.76010462e-06
Iter: 267 loss: 1.73065769e-06
Iter: 268 loss: 1.72649993e-06
Iter: 269 loss: 1.73252954e-06
Iter: 270 loss: 1.72451598e-06
Iter: 271 loss: 1.71929548e-06
Iter: 272 loss: 1.72871705e-06
Iter: 273 loss: 1.71715783e-06
Iter: 274 loss: 1.71268437e-06
Iter: 275 loss: 1.70662679e-06
Iter: 276 loss: 1.70639123e-06
Iter: 277 loss: 1.70118369e-06
Iter: 278 loss: 1.70086901e-06
Iter: 279 loss: 1.69743544e-06
Iter: 280 loss: 1.69999089e-06
Iter: 281 loss: 1.69532052e-06
Iter: 282 loss: 1.68918677e-06
Iter: 283 loss: 1.71098372e-06
Iter: 284 loss: 1.68757674e-06
Iter: 285 loss: 1.68445797e-06
Iter: 286 loss: 1.6796605e-06
Iter: 287 loss: 1.6795866e-06
Iter: 288 loss: 1.6751867e-06
Iter: 289 loss: 1.72828879e-06
Iter: 290 loss: 1.67514111e-06
Iter: 291 loss: 1.6711756e-06
Iter: 292 loss: 1.67411758e-06
Iter: 293 loss: 1.66869199e-06
Iter: 294 loss: 1.66504446e-06
Iter: 295 loss: 1.6650215e-06
Iter: 296 loss: 1.66339191e-06
Iter: 297 loss: 1.67467761e-06
Iter: 298 loss: 1.66321797e-06
Iter: 299 loss: 1.6611325e-06
Iter: 300 loss: 1.65692245e-06
Iter: 301 loss: 1.73395e-06
Iter: 302 loss: 1.65684651e-06
Iter: 303 loss: 1.65242363e-06
Iter: 304 loss: 1.65261611e-06
Iter: 305 loss: 1.64892867e-06
Iter: 306 loss: 1.64476182e-06
Iter: 307 loss: 1.68492795e-06
Iter: 308 loss: 1.64462585e-06
Iter: 309 loss: 1.64118455e-06
Iter: 310 loss: 1.63666459e-06
Iter: 311 loss: 1.63636969e-06
Iter: 312 loss: 1.63317213e-06
Iter: 313 loss: 1.63295272e-06
Iter: 314 loss: 1.62995e-06
Iter: 315 loss: 1.63150719e-06
Iter: 316 loss: 1.62798415e-06
Iter: 317 loss: 1.62408924e-06
Iter: 318 loss: 1.63860273e-06
Iter: 319 loss: 1.623142e-06
Iter: 320 loss: 1.62019171e-06
Iter: 321 loss: 1.63418281e-06
Iter: 322 loss: 1.61963476e-06
Iter: 323 loss: 1.61658113e-06
Iter: 324 loss: 1.6288601e-06
Iter: 325 loss: 1.61590083e-06
Iter: 326 loss: 1.61387231e-06
Iter: 327 loss: 1.61045887e-06
Iter: 328 loss: 1.61042476e-06
Iter: 329 loss: 1.60624518e-06
Iter: 330 loss: 1.6331627e-06
Iter: 331 loss: 1.60581703e-06
Iter: 332 loss: 1.60279365e-06
Iter: 333 loss: 1.60957e-06
Iter: 334 loss: 1.6016628e-06
Iter: 335 loss: 1.60000866e-06
Iter: 336 loss: 1.59968465e-06
Iter: 337 loss: 1.59810975e-06
Iter: 338 loss: 1.59731644e-06
Iter: 339 loss: 1.59661386e-06
Iter: 340 loss: 1.59343278e-06
Iter: 341 loss: 1.59135561e-06
Iter: 342 loss: 1.59012848e-06
Iter: 343 loss: 1.58740704e-06
Iter: 344 loss: 1.58784792e-06
Iter: 345 loss: 1.58535659e-06
Iter: 346 loss: 1.58112266e-06
Iter: 347 loss: 1.59987792e-06
Iter: 348 loss: 1.58030298e-06
Iter: 349 loss: 1.5774973e-06
Iter: 350 loss: 1.57664897e-06
Iter: 351 loss: 1.57498221e-06
Iter: 352 loss: 1.57154932e-06
Iter: 353 loss: 1.60157083e-06
Iter: 354 loss: 1.57135037e-06
Iter: 355 loss: 1.56813803e-06
Iter: 356 loss: 1.58627e-06
Iter: 357 loss: 1.56774331e-06
Iter: 358 loss: 1.56544388e-06
Iter: 359 loss: 1.58139483e-06
Iter: 360 loss: 1.56524197e-06
Iter: 361 loss: 1.56356168e-06
Iter: 362 loss: 1.5625883e-06
Iter: 363 loss: 1.56189822e-06
Iter: 364 loss: 1.5587334e-06
Iter: 365 loss: 1.56751184e-06
Iter: 366 loss: 1.55775729e-06
Iter: 367 loss: 1.55542023e-06
Iter: 368 loss: 1.55614214e-06
Iter: 369 loss: 1.55368389e-06
Iter: 370 loss: 1.55068847e-06
Iter: 371 loss: 1.5618624e-06
Iter: 372 loss: 1.55000885e-06
Iter: 373 loss: 1.54683357e-06
Iter: 374 loss: 1.59004969e-06
Iter: 375 loss: 1.5468014e-06
Iter: 376 loss: 1.54525151e-06
Iter: 377 loss: 1.54323391e-06
Iter: 378 loss: 1.54307918e-06
Iter: 379 loss: 1.54091458e-06
Iter: 380 loss: 1.54519284e-06
Iter: 381 loss: 1.53999554e-06
Iter: 382 loss: 1.53680503e-06
Iter: 383 loss: 1.54422492e-06
Iter: 384 loss: 1.53559733e-06
Iter: 385 loss: 1.53364238e-06
Iter: 386 loss: 1.53157771e-06
Iter: 387 loss: 1.53118401e-06
Iter: 388 loss: 1.52848122e-06
Iter: 389 loss: 1.55673388e-06
Iter: 390 loss: 1.5284113e-06
Iter: 391 loss: 1.5259277e-06
Iter: 392 loss: 1.52385815e-06
Iter: 393 loss: 1.52307666e-06
Iter: 394 loss: 1.52064422e-06
Iter: 395 loss: 1.53807264e-06
Iter: 396 loss: 1.52043617e-06
Iter: 397 loss: 1.5179312e-06
Iter: 398 loss: 1.53210567e-06
Iter: 399 loss: 1.51756922e-06
Iter: 400 loss: 1.51543782e-06
Iter: 401 loss: 1.52838834e-06
Iter: 402 loss: 1.51517941e-06
Iter: 403 loss: 1.51369477e-06
Iter: 404 loss: 1.51135578e-06
Iter: 405 loss: 1.51132269e-06
Iter: 406 loss: 1.50895994e-06
Iter: 407 loss: 1.54183851e-06
Iter: 408 loss: 1.5089588e-06
Iter: 409 loss: 1.50714686e-06
Iter: 410 loss: 1.51613165e-06
Iter: 411 loss: 1.50686299e-06
Iter: 412 loss: 1.50508072e-06
Iter: 413 loss: 1.51284905e-06
Iter: 414 loss: 1.50466462e-06
Iter: 415 loss: 1.50372784e-06
Iter: 416 loss: 1.50193023e-06
Iter: 417 loss: 1.53884719e-06
Iter: 418 loss: 1.50191352e-06
Iter: 419 loss: 1.4994373e-06
Iter: 420 loss: 1.50391634e-06
Iter: 421 loss: 1.49834636e-06
Iter: 422 loss: 1.49575476e-06
Iter: 423 loss: 1.49979269e-06
Iter: 424 loss: 1.49453331e-06
Iter: 425 loss: 1.4927441e-06
Iter: 426 loss: 1.49264793e-06
Iter: 427 loss: 1.49159234e-06
Iter: 428 loss: 1.48899994e-06
Iter: 429 loss: 1.50837832e-06
Iter: 430 loss: 1.48845129e-06
Iter: 431 loss: 1.48568336e-06
Iter: 432 loss: 1.51394261e-06
Iter: 433 loss: 1.48562106e-06
Iter: 434 loss: 1.48342656e-06
Iter: 435 loss: 1.48718118e-06
Iter: 436 loss: 1.48250638e-06
Iter: 437 loss: 1.48041488e-06
Iter: 438 loss: 1.51066695e-06
Iter: 439 loss: 1.48042386e-06
Iter: 440 loss: 1.47881076e-06
Iter: 441 loss: 1.47791684e-06
Iter: 442 loss: 1.47722335e-06
Iter: 443 loss: 1.47538253e-06
Iter: 444 loss: 1.48006825e-06
Iter: 445 loss: 1.47475316e-06
Iter: 446 loss: 1.47282321e-06
Iter: 447 loss: 1.49437494e-06
Iter: 448 loss: 1.47281366e-06
Iter: 449 loss: 1.47133312e-06
Iter: 450 loss: 1.47352887e-06
Iter: 451 loss: 1.47063054e-06
Iter: 452 loss: 1.46928937e-06
Iter: 453 loss: 1.469469e-06
Iter: 454 loss: 1.46829473e-06
Iter: 455 loss: 1.4665244e-06
Iter: 456 loss: 1.46634454e-06
Iter: 457 loss: 1.46506113e-06
Iter: 458 loss: 1.4627791e-06
Iter: 459 loss: 1.46476191e-06
Iter: 460 loss: 1.46150364e-06
Iter: 461 loss: 1.4595114e-06
Iter: 462 loss: 1.45945819e-06
Iter: 463 loss: 1.45813556e-06
Iter: 464 loss: 1.46000548e-06
Iter: 465 loss: 1.45748049e-06
Iter: 466 loss: 1.45568606e-06
Iter: 467 loss: 1.45430135e-06
Iter: 468 loss: 1.45370473e-06
Iter: 469 loss: 1.45155923e-06
Iter: 470 loss: 1.45154797e-06
Iter: 471 loss: 1.44981391e-06
Iter: 472 loss: 1.44865555e-06
Iter: 473 loss: 1.44816499e-06
Iter: 474 loss: 1.44706507e-06
Iter: 475 loss: 1.45114348e-06
Iter: 476 loss: 1.4468651e-06
Iter: 477 loss: 1.44555725e-06
Iter: 478 loss: 1.44276305e-06
Iter: 479 loss: 1.48841968e-06
Iter: 480 loss: 1.44267187e-06
Iter: 481 loss: 1.44467708e-06
Iter: 482 loss: 1.44195144e-06
Iter: 483 loss: 1.44133844e-06
Iter: 484 loss: 1.43962143e-06
Iter: 485 loss: 1.45277045e-06
Iter: 486 loss: 1.43934187e-06
Iter: 487 loss: 1.43755051e-06
Iter: 488 loss: 1.45099068e-06
Iter: 489 loss: 1.43742682e-06
Iter: 490 loss: 1.43608986e-06
Iter: 491 loss: 1.4364e-06
Iter: 492 loss: 1.4351499e-06
Iter: 493 loss: 1.43319949e-06
Iter: 494 loss: 1.43538875e-06
Iter: 495 loss: 1.43217846e-06
Iter: 496 loss: 1.43003126e-06
Iter: 497 loss: 1.43340799e-06
Iter: 498 loss: 1.42905969e-06
Iter: 499 loss: 1.42668591e-06
Iter: 500 loss: 1.45350623e-06
Iter: 501 loss: 1.42662986e-06
Iter: 502 loss: 1.42498834e-06
Iter: 503 loss: 1.42406975e-06
Iter: 504 loss: 1.42330794e-06
Iter: 505 loss: 1.42149884e-06
Iter: 506 loss: 1.42673389e-06
Iter: 507 loss: 1.42088493e-06
Iter: 508 loss: 1.41887017e-06
Iter: 509 loss: 1.42856868e-06
Iter: 510 loss: 1.41848636e-06
Iter: 511 loss: 1.41731084e-06
Iter: 512 loss: 1.41730879e-06
Iter: 513 loss: 1.41639202e-06
Iter: 514 loss: 1.4139564e-06
Iter: 515 loss: 1.43283035e-06
Iter: 516 loss: 1.41351506e-06
Iter: 517 loss: 1.4146375e-06
Iter: 518 loss: 1.4124065e-06
Iter: 519 loss: 1.41164537e-06
Iter: 520 loss: 1.4107909e-06
Iter: 521 loss: 1.41064947e-06
Iter: 522 loss: 1.40956195e-06
Iter: 523 loss: 1.40856832e-06
Iter: 524 loss: 1.40831696e-06
Iter: 525 loss: 1.40689417e-06
Iter: 526 loss: 1.42313502e-06
Iter: 527 loss: 1.40684585e-06
Iter: 528 loss: 1.40550719e-06
Iter: 529 loss: 1.40373584e-06
Iter: 530 loss: 1.40360567e-06
Iter: 531 loss: 1.4019538e-06
Iter: 532 loss: 1.41997e-06
Iter: 533 loss: 1.40194186e-06
Iter: 534 loss: 1.40045768e-06
Iter: 535 loss: 1.39805081e-06
Iter: 536 loss: 1.39805547e-06
Iter: 537 loss: 1.3956153e-06
Iter: 538 loss: 1.41873375e-06
Iter: 539 loss: 1.39553185e-06
Iter: 540 loss: 1.39381541e-06
Iter: 541 loss: 1.40840689e-06
Iter: 542 loss: 1.39367603e-06
Iter: 543 loss: 1.39224119e-06
Iter: 544 loss: 1.39704707e-06
Iter: 545 loss: 1.39186875e-06
Iter: 546 loss: 1.39032772e-06
Iter: 547 loss: 1.38858309e-06
Iter: 548 loss: 1.38832729e-06
Iter: 549 loss: 1.38663938e-06
Iter: 550 loss: 1.39502981e-06
Iter: 551 loss: 1.38633595e-06
Iter: 552 loss: 1.38577479e-06
Iter: 553 loss: 1.38546625e-06
Iter: 554 loss: 1.38490668e-06
Iter: 555 loss: 1.38406676e-06
Iter: 556 loss: 1.38407199e-06
Iter: 557 loss: 1.38274595e-06
Iter: 558 loss: 1.38618782e-06
Iter: 559 loss: 1.38233509e-06
Iter: 560 loss: 1.38129371e-06
Iter: 561 loss: 1.3813376e-06
Iter: 562 loss: 1.38046016e-06
Iter: 563 loss: 1.37876123e-06
Iter: 564 loss: 1.3782942e-06
Iter: 565 loss: 1.37726602e-06
Iter: 566 loss: 1.37591542e-06
Iter: 567 loss: 1.37582799e-06
Iter: 568 loss: 1.37493601e-06
Iter: 569 loss: 1.37348366e-06
Iter: 570 loss: 1.37342295e-06
Iter: 571 loss: 1.37168593e-06
Iter: 572 loss: 1.38422683e-06
Iter: 573 loss: 1.37149516e-06
Iter: 574 loss: 1.370267e-06
Iter: 575 loss: 1.36972471e-06
Iter: 576 loss: 1.36907897e-06
Iter: 577 loss: 1.36717108e-06
Iter: 578 loss: 1.37737356e-06
Iter: 579 loss: 1.36691244e-06
Iter: 580 loss: 1.36544452e-06
Iter: 581 loss: 1.38281143e-06
Iter: 582 loss: 1.36539393e-06
Iter: 583 loss: 1.36435051e-06
Iter: 584 loss: 1.36439314e-06
Iter: 585 loss: 1.36351377e-06
Iter: 586 loss: 1.3622041e-06
Iter: 587 loss: 1.36667393e-06
Iter: 588 loss: 1.36184929e-06
Iter: 589 loss: 1.36097651e-06
Iter: 590 loss: 1.36093036e-06
Iter: 591 loss: 1.36031917e-06
Iter: 592 loss: 1.35845846e-06
Iter: 593 loss: 1.36335927e-06
Iter: 594 loss: 1.35748792e-06
Iter: 595 loss: 1.35590767e-06
Iter: 596 loss: 1.35592404e-06
Iter: 597 loss: 1.35443054e-06
Iter: 598 loss: 1.35943037e-06
Iter: 599 loss: 1.35395635e-06
Iter: 600 loss: 1.3525239e-06
Iter: 601 loss: 1.35497487e-06
Iter: 602 loss: 1.35185326e-06
Iter: 603 loss: 1.35097321e-06
Iter: 604 loss: 1.34981485e-06
Iter: 605 loss: 1.34974073e-06
Iter: 606 loss: 1.34767743e-06
Iter: 607 loss: 1.36399331e-06
Iter: 608 loss: 1.34752133e-06
Iter: 609 loss: 1.34621087e-06
Iter: 610 loss: 1.34886557e-06
Iter: 611 loss: 1.34571542e-06
Iter: 612 loss: 1.34418258e-06
Iter: 613 loss: 1.34593961e-06
Iter: 614 loss: 1.34338347e-06
Iter: 615 loss: 1.34214133e-06
Iter: 616 loss: 1.34412471e-06
Iter: 617 loss: 1.34147467e-06
Iter: 618 loss: 1.33997855e-06
Iter: 619 loss: 1.34741049e-06
Iter: 620 loss: 1.33974322e-06
Iter: 621 loss: 1.339042e-06
Iter: 622 loss: 1.33896083e-06
Iter: 623 loss: 1.33810045e-06
Iter: 624 loss: 1.33653475e-06
Iter: 625 loss: 1.33654089e-06
Iter: 626 loss: 1.33528624e-06
Iter: 627 loss: 1.33642766e-06
Iter: 628 loss: 1.33458252e-06
Iter: 629 loss: 1.33363665e-06
Iter: 630 loss: 1.33359708e-06
Iter: 631 loss: 1.33289859e-06
Iter: 632 loss: 1.33190952e-06
Iter: 633 loss: 1.33185267e-06
Iter: 634 loss: 1.33032086e-06
Iter: 635 loss: 1.33786477e-06
Iter: 636 loss: 1.33002209e-06
Iter: 637 loss: 1.32886498e-06
Iter: 638 loss: 1.33616072e-06
Iter: 639 loss: 1.32874118e-06
Iter: 640 loss: 1.32795185e-06
Iter: 641 loss: 1.32660625e-06
Iter: 642 loss: 1.32661626e-06
Iter: 643 loss: 1.32522e-06
Iter: 644 loss: 1.33507979e-06
Iter: 645 loss: 1.32511673e-06
Iter: 646 loss: 1.32379478e-06
Iter: 647 loss: 1.3277911e-06
Iter: 648 loss: 1.32340074e-06
Iter: 649 loss: 1.32204309e-06
Iter: 650 loss: 1.32449679e-06
Iter: 651 loss: 1.32143828e-06
Iter: 652 loss: 1.31995557e-06
Iter: 653 loss: 1.32090599e-06
Iter: 654 loss: 1.31900083e-06
Iter: 655 loss: 1.31773345e-06
Iter: 656 loss: 1.33599065e-06
Iter: 657 loss: 1.31772811e-06
Iter: 658 loss: 1.31635477e-06
Iter: 659 loss: 1.3205331e-06
Iter: 660 loss: 1.31596244e-06
Iter: 661 loss: 1.31524655e-06
Iter: 662 loss: 1.31474303e-06
Iter: 663 loss: 1.31448473e-06
Iter: 664 loss: 1.31334093e-06
Iter: 665 loss: 1.31295076e-06
Iter: 666 loss: 1.3123265e-06
Iter: 667 loss: 1.31163165e-06
Iter: 668 loss: 1.31141201e-06
Iter: 669 loss: 1.31073284e-06
Iter: 670 loss: 1.30916692e-06
Iter: 671 loss: 1.33192384e-06
Iter: 672 loss: 1.30911167e-06
Iter: 673 loss: 1.30829358e-06
Iter: 674 loss: 1.30811372e-06
Iter: 675 loss: 1.30741842e-06
Iter: 676 loss: 1.3058758e-06
Iter: 677 loss: 1.33097751e-06
Iter: 678 loss: 1.30578474e-06
Iter: 679 loss: 1.30421176e-06
Iter: 680 loss: 1.31814238e-06
Iter: 681 loss: 1.30408853e-06
Iter: 682 loss: 1.30314049e-06
Iter: 683 loss: 1.30268654e-06
Iter: 684 loss: 1.30221633e-06
Iter: 685 loss: 1.30092678e-06
Iter: 686 loss: 1.30093895e-06
Iter: 687 loss: 1.30005117e-06
Iter: 688 loss: 1.2993529e-06
Iter: 689 loss: 1.29908176e-06
Iter: 690 loss: 1.29841055e-06
Iter: 691 loss: 1.29823138e-06
Iter: 692 loss: 1.29765647e-06
Iter: 693 loss: 1.29703517e-06
Iter: 694 loss: 1.29699151e-06
Iter: 695 loss: 1.29614841e-06
Iter: 696 loss: 1.29473938e-06
Iter: 697 loss: 1.29472278e-06
Iter: 698 loss: 1.29341515e-06
Iter: 699 loss: 1.29966986e-06
Iter: 700 loss: 1.29317868e-06
Iter: 701 loss: 1.29187424e-06
Iter: 702 loss: 1.30490173e-06
Iter: 703 loss: 1.29180637e-06
Iter: 704 loss: 1.29082866e-06
Iter: 705 loss: 1.28976808e-06
Iter: 706 loss: 1.28963063e-06
Iter: 707 loss: 1.28870647e-06
Iter: 708 loss: 1.28869237e-06
Iter: 709 loss: 1.28788429e-06
Iter: 710 loss: 1.28790452e-06
Iter: 711 loss: 1.28729948e-06
Iter: 712 loss: 1.28611578e-06
Iter: 713 loss: 1.28623128e-06
Iter: 714 loss: 1.28517945e-06
Iter: 715 loss: 1.28401211e-06
Iter: 716 loss: 1.28538591e-06
Iter: 717 loss: 1.28340389e-06
Iter: 718 loss: 1.28202385e-06
Iter: 719 loss: 1.30041542e-06
Iter: 720 loss: 1.28202225e-06
Iter: 721 loss: 1.2812252e-06
Iter: 722 loss: 1.28228521e-06
Iter: 723 loss: 1.28081888e-06
Iter: 724 loss: 1.27990563e-06
Iter: 725 loss: 1.29278158e-06
Iter: 726 loss: 1.27991393e-06
Iter: 727 loss: 1.27929479e-06
Iter: 728 loss: 1.27850569e-06
Iter: 729 loss: 1.27843896e-06
Iter: 730 loss: 1.27749433e-06
Iter: 731 loss: 1.2764333e-06
Iter: 732 loss: 1.27621502e-06
Iter: 733 loss: 1.27508793e-06
Iter: 734 loss: 1.27504791e-06
Iter: 735 loss: 1.27419264e-06
Iter: 736 loss: 1.27578619e-06
Iter: 737 loss: 1.27385488e-06
Iter: 738 loss: 1.27295868e-06
Iter: 739 loss: 1.27270573e-06
Iter: 740 loss: 1.27220301e-06
Iter: 741 loss: 1.27101566e-06
Iter: 742 loss: 1.28051329e-06
Iter: 743 loss: 1.2709329e-06
Iter: 744 loss: 1.26980967e-06
Iter: 745 loss: 1.27175838e-06
Iter: 746 loss: 1.26928819e-06
Iter: 747 loss: 1.26839325e-06
Iter: 748 loss: 1.26699672e-06
Iter: 749 loss: 1.2669293e-06
Iter: 750 loss: 1.26553073e-06
Iter: 751 loss: 1.28500869e-06
Iter: 752 loss: 1.26552266e-06
Iter: 753 loss: 1.26460964e-06
Iter: 754 loss: 1.26890097e-06
Iter: 755 loss: 1.26441114e-06
Iter: 756 loss: 1.26364739e-06
Iter: 757 loss: 1.2688422e-06
Iter: 758 loss: 1.2635544e-06
Iter: 759 loss: 1.26267753e-06
Iter: 760 loss: 1.26569489e-06
Iter: 761 loss: 1.26246414e-06
Iter: 762 loss: 1.26178861e-06
Iter: 763 loss: 1.26069619e-06
Iter: 764 loss: 1.26066698e-06
Iter: 765 loss: 1.25962219e-06
Iter: 766 loss: 1.26066163e-06
Iter: 767 loss: 1.25904501e-06
Iter: 768 loss: 1.25812244e-06
Iter: 769 loss: 1.25813494e-06
Iter: 770 loss: 1.2574626e-06
Iter: 771 loss: 1.2573023e-06
Iter: 772 loss: 1.2569169e-06
Iter: 773 loss: 1.25584131e-06
Iter: 774 loss: 1.25600207e-06
Iter: 775 loss: 1.25505562e-06
Iter: 776 loss: 1.25429847e-06
Iter: 777 loss: 1.25425299e-06
Iter: 778 loss: 1.25350016e-06
Iter: 779 loss: 1.25195083e-06
Iter: 780 loss: 1.27879412e-06
Iter: 781 loss: 1.25190058e-06
Iter: 782 loss: 1.25065367e-06
Iter: 783 loss: 1.2613948e-06
Iter: 784 loss: 1.25059898e-06
Iter: 785 loss: 1.24957455e-06
Iter: 786 loss: 1.25084023e-06
Iter: 787 loss: 1.24905637e-06
Iter: 788 loss: 1.24817211e-06
Iter: 789 loss: 1.25953534e-06
Iter: 790 loss: 1.24813369e-06
Iter: 791 loss: 1.24740927e-06
Iter: 792 loss: 1.2527446e-06
Iter: 793 loss: 1.24735016e-06
Iter: 794 loss: 1.24679013e-06
Iter: 795 loss: 1.24730059e-06
Iter: 796 loss: 1.24647568e-06
Iter: 797 loss: 1.24592179e-06
Iter: 798 loss: 1.24474536e-06
Iter: 799 loss: 1.2655571e-06
Iter: 800 loss: 1.24471865e-06
Iter: 801 loss: 1.2436044e-06
Iter: 802 loss: 1.25432769e-06
Iter: 803 loss: 1.24356029e-06
Iter: 804 loss: 1.24254143e-06
Iter: 805 loss: 1.2473771e-06
Iter: 806 loss: 1.24232338e-06
Iter: 807 loss: 1.24155304e-06
Iter: 808 loss: 1.24231644e-06
Iter: 809 loss: 1.24113171e-06
Iter: 810 loss: 1.24027747e-06
Iter: 811 loss: 1.24070095e-06
Iter: 812 loss: 1.23970449e-06
Iter: 813 loss: 1.23879818e-06
Iter: 814 loss: 1.23880682e-06
Iter: 815 loss: 1.23822952e-06
Iter: 816 loss: 1.23725e-06
Iter: 817 loss: 1.23724612e-06
Iter: 818 loss: 1.23619952e-06
Iter: 819 loss: 1.24263966e-06
Iter: 820 loss: 1.23608652e-06
Iter: 821 loss: 1.23518657e-06
Iter: 822 loss: 1.23593884e-06
Iter: 823 loss: 1.23463383e-06
Iter: 824 loss: 1.23418965e-06
Iter: 825 loss: 1.2340904e-06
Iter: 826 loss: 1.23350628e-06
Iter: 827 loss: 1.23347945e-06
Iter: 828 loss: 1.23299799e-06
Iter: 829 loss: 1.23216341e-06
Iter: 830 loss: 1.23333393e-06
Iter: 831 loss: 1.23169889e-06
Iter: 832 loss: 1.23103155e-06
Iter: 833 loss: 1.23011318e-06
Iter: 834 loss: 1.23007578e-06
Iter: 835 loss: 1.22896472e-06
Iter: 836 loss: 1.24532721e-06
Iter: 837 loss: 1.22894141e-06
Iter: 838 loss: 1.22818847e-06
Iter: 839 loss: 1.23207246e-06
Iter: 840 loss: 1.22802146e-06
Iter: 841 loss: 1.22740425e-06
Iter: 842 loss: 1.22664551e-06
Iter: 843 loss: 1.22656684e-06
Iter: 844 loss: 1.22556889e-06
Iter: 845 loss: 1.2317139e-06
Iter: 846 loss: 1.22547135e-06
Iter: 847 loss: 1.22462893e-06
Iter: 848 loss: 1.2296066e-06
Iter: 849 loss: 1.22449046e-06
Iter: 850 loss: 1.22386689e-06
Iter: 851 loss: 1.22293545e-06
Iter: 852 loss: 1.222945e-06
Iter: 853 loss: 1.22180109e-06
Iter: 854 loss: 1.22826577e-06
Iter: 855 loss: 1.22161032e-06
Iter: 856 loss: 1.22065239e-06
Iter: 857 loss: 1.22240408e-06
Iter: 858 loss: 1.22022766e-06
Iter: 859 loss: 1.21955259e-06
Iter: 860 loss: 1.21946186e-06
Iter: 861 loss: 1.21904498e-06
Iter: 862 loss: 1.21866356e-06
Iter: 863 loss: 1.21859057e-06
Iter: 864 loss: 1.21777236e-06
Iter: 865 loss: 1.21700759e-06
Iter: 866 loss: 1.21680944e-06
Iter: 867 loss: 1.21594258e-06
Iter: 868 loss: 1.22113488e-06
Iter: 869 loss: 1.21586277e-06
Iter: 870 loss: 1.21506787e-06
Iter: 871 loss: 1.2177095e-06
Iter: 872 loss: 1.21481025e-06
Iter: 873 loss: 1.21388894e-06
Iter: 874 loss: 1.21739947e-06
Iter: 875 loss: 1.21370158e-06
Iter: 876 loss: 1.21306562e-06
Iter: 877 loss: 1.21227401e-06
Iter: 878 loss: 1.21223388e-06
Iter: 879 loss: 1.21127243e-06
Iter: 880 loss: 1.22469851e-06
Iter: 881 loss: 1.21128096e-06
Iter: 882 loss: 1.21037147e-06
Iter: 883 loss: 1.21022219e-06
Iter: 884 loss: 1.20958634e-06
Iter: 885 loss: 1.20874915e-06
Iter: 886 loss: 1.20991444e-06
Iter: 887 loss: 1.20830668e-06
Iter: 888 loss: 1.20715185e-06
Iter: 889 loss: 1.20994696e-06
Iter: 890 loss: 1.20674576e-06
Iter: 891 loss: 1.20641289e-06
Iter: 892 loss: 1.20621382e-06
Iter: 893 loss: 1.20571644e-06
Iter: 894 loss: 1.20521167e-06
Iter: 895 loss: 1.2051164e-06
Iter: 896 loss: 1.20443633e-06
Iter: 897 loss: 1.2067793e-06
Iter: 898 loss: 1.20427922e-06
Iter: 899 loss: 1.20360244e-06
Iter: 900 loss: 1.20303594e-06
Iter: 901 loss: 1.20288769e-06
Iter: 902 loss: 1.20205345e-06
Iter: 903 loss: 1.20900802e-06
Iter: 904 loss: 1.20201241e-06
Iter: 905 loss: 1.20131767e-06
Iter: 906 loss: 1.20498828e-06
Iter: 907 loss: 1.20119523e-06
Iter: 908 loss: 1.20052619e-06
Iter: 909 loss: 1.20059667e-06
Iter: 910 loss: 1.20002267e-06
Iter: 911 loss: 1.19920992e-06
Iter: 912 loss: 1.19894662e-06
Iter: 913 loss: 1.19850188e-06
Iter: 914 loss: 1.19761899e-06
Iter: 915 loss: 1.19757851e-06
Iter: 916 loss: 1.19706169e-06
Iter: 917 loss: 1.19595484e-06
Iter: 918 loss: 1.21039568e-06
Iter: 919 loss: 1.19584115e-06
Iter: 920 loss: 1.1946197e-06
Iter: 921 loss: 1.20938512e-06
Iter: 922 loss: 1.19462743e-06
Iter: 923 loss: 1.19408548e-06
Iter: 924 loss: 1.1968034e-06
Iter: 925 loss: 1.19400806e-06
Iter: 926 loss: 1.19333959e-06
Iter: 927 loss: 1.19782783e-06
Iter: 928 loss: 1.19325625e-06
Iter: 929 loss: 1.19284186e-06
Iter: 930 loss: 1.19222079e-06
Iter: 931 loss: 1.19218771e-06
Iter: 932 loss: 1.19132949e-06
Iter: 933 loss: 1.19425158e-06
Iter: 934 loss: 1.19107381e-06
Iter: 935 loss: 1.19035383e-06
Iter: 936 loss: 1.1902049e-06
Iter: 937 loss: 1.18974287e-06
Iter: 938 loss: 1.18879018e-06
Iter: 939 loss: 1.1946164e-06
Iter: 940 loss: 1.18866e-06
Iter: 941 loss: 1.18809169e-06
Iter: 942 loss: 1.19720937e-06
Iter: 943 loss: 1.18806474e-06
Iter: 944 loss: 1.18759249e-06
Iter: 945 loss: 1.18664855e-06
Iter: 946 loss: 1.20813024e-06
Iter: 947 loss: 1.18664775e-06
Iter: 948 loss: 1.18582727e-06
Iter: 949 loss: 1.19055358e-06
Iter: 950 loss: 1.1857237e-06
Iter: 951 loss: 1.18477294e-06
Iter: 952 loss: 1.18723062e-06
Iter: 953 loss: 1.18448338e-06
Iter: 954 loss: 1.18381195e-06
Iter: 955 loss: 1.18613821e-06
Iter: 956 loss: 1.18362232e-06
Iter: 957 loss: 1.18301023e-06
Iter: 958 loss: 1.18198852e-06
Iter: 959 loss: 1.18195044e-06
Iter: 960 loss: 1.18243702e-06
Iter: 961 loss: 1.18155708e-06
Iter: 962 loss: 1.18112848e-06
Iter: 963 loss: 1.18053e-06
Iter: 964 loss: 1.18050241e-06
Iter: 965 loss: 1.17984155e-06
Iter: 966 loss: 1.18049604e-06
Iter: 967 loss: 1.17953368e-06
Iter: 968 loss: 1.17870968e-06
Iter: 969 loss: 1.18218009e-06
Iter: 970 loss: 1.17852073e-06
Iter: 971 loss: 1.17774255e-06
Iter: 972 loss: 1.17808418e-06
Iter: 973 loss: 1.17726063e-06
Iter: 974 loss: 1.17650211e-06
Iter: 975 loss: 1.18115781e-06
Iter: 976 loss: 1.17643981e-06
Iter: 977 loss: 1.17575144e-06
Iter: 978 loss: 1.17943e-06
Iter: 979 loss: 1.17565787e-06
Iter: 980 loss: 1.17512832e-06
Iter: 981 loss: 1.17429454e-06
Iter: 982 loss: 1.17431648e-06
Iter: 983 loss: 1.17355762e-06
Iter: 984 loss: 1.18551895e-06
Iter: 985 loss: 1.1735674e-06
Iter: 986 loss: 1.17299055e-06
Iter: 987 loss: 1.17412424e-06
Iter: 988 loss: 1.17276682e-06
Iter: 989 loss: 1.17203479e-06
Iter: 990 loss: 1.17164348e-06
Iter: 991 loss: 1.17132709e-06
Iter: 992 loss: 1.17049217e-06
Iter: 993 loss: 1.17444711e-06
Iter: 994 loss: 1.17035017e-06
Iter: 995 loss: 1.16999809e-06
Iter: 996 loss: 1.16987701e-06
Iter: 997 loss: 1.16962406e-06
Iter: 998 loss: 1.16880096e-06
Iter: 999 loss: 1.16940555e-06
Iter: 1000 loss: 1.1681085e-06
Iter: 1001 loss: 1.16718388e-06
Iter: 1002 loss: 1.16716274e-06
Iter: 1003 loss: 1.16656702e-06
Iter: 1004 loss: 1.16770161e-06
Iter: 1005 loss: 1.16634124e-06
Iter: 1006 loss: 1.16567503e-06
Iter: 1007 loss: 1.16586648e-06
Iter: 1008 loss: 1.16519971e-06
Iter: 1009 loss: 1.16454908e-06
Iter: 1010 loss: 1.17327659e-06
Iter: 1011 loss: 1.16454237e-06
Iter: 1012 loss: 1.16389765e-06
Iter: 1013 loss: 1.16347701e-06
Iter: 1014 loss: 1.16322099e-06
Iter: 1015 loss: 1.16255478e-06
Iter: 1016 loss: 1.1652827e-06
Iter: 1017 loss: 1.16238766e-06
Iter: 1018 loss: 1.16171725e-06
Iter: 1019 loss: 1.16410263e-06
Iter: 1020 loss: 1.16155e-06
Iter: 1021 loss: 1.16084743e-06
Iter: 1022 loss: 1.16295064e-06
Iter: 1023 loss: 1.1605872e-06
Iter: 1024 loss: 1.16009392e-06
Iter: 1025 loss: 1.15976286e-06
Iter: 1026 loss: 1.15955595e-06
Iter: 1027 loss: 1.15907642e-06
Iter: 1028 loss: 1.15904413e-06
Iter: 1029 loss: 1.15843818e-06
Iter: 1030 loss: 1.15761259e-06
Iter: 1031 loss: 1.15757473e-06
Iter: 1032 loss: 1.15697958e-06
Iter: 1033 loss: 1.15764715e-06
Iter: 1034 loss: 1.15668831e-06
Iter: 1035 loss: 1.15591297e-06
Iter: 1036 loss: 1.15821263e-06
Iter: 1037 loss: 1.15568423e-06
Iter: 1038 loss: 1.15497801e-06
Iter: 1039 loss: 1.15869943e-06
Iter: 1040 loss: 1.15489638e-06
Iter: 1041 loss: 1.15428463e-06
Iter: 1042 loss: 1.15405805e-06
Iter: 1043 loss: 1.15375622e-06
Iter: 1044 loss: 1.15307137e-06
Iter: 1045 loss: 1.15305488e-06
Iter: 1046 loss: 1.15253749e-06
Iter: 1047 loss: 1.15185753e-06
Iter: 1048 loss: 1.15185276e-06
Iter: 1049 loss: 1.15097464e-06
Iter: 1050 loss: 1.1557097e-06
Iter: 1051 loss: 1.15085652e-06
Iter: 1052 loss: 1.15037619e-06
Iter: 1053 loss: 1.15452747e-06
Iter: 1054 loss: 1.15034061e-06
Iter: 1055 loss: 1.14983163e-06
Iter: 1056 loss: 1.14925683e-06
Iter: 1057 loss: 1.14921897e-06
Iter: 1058 loss: 1.14857244e-06
Iter: 1059 loss: 1.15449677e-06
Iter: 1060 loss: 1.14854788e-06
Iter: 1061 loss: 1.14799627e-06
Iter: 1062 loss: 1.15319165e-06
Iter: 1063 loss: 1.14800537e-06
Iter: 1064 loss: 1.14772649e-06
Iter: 1065 loss: 1.1469117e-06
Iter: 1066 loss: 1.15287889e-06
Iter: 1067 loss: 1.14677937e-06
Iter: 1068 loss: 1.14588011e-06
Iter: 1069 loss: 1.15115904e-06
Iter: 1070 loss: 1.14575118e-06
Iter: 1071 loss: 1.14518127e-06
Iter: 1072 loss: 1.1497666e-06
Iter: 1073 loss: 1.14512898e-06
Iter: 1074 loss: 1.14458271e-06
Iter: 1075 loss: 1.14466411e-06
Iter: 1076 loss: 1.14414604e-06
Iter: 1077 loss: 1.14353e-06
Iter: 1078 loss: 1.14778823e-06
Iter: 1079 loss: 1.1435211e-06
Iter: 1080 loss: 1.14293562e-06
Iter: 1081 loss: 1.14422562e-06
Iter: 1082 loss: 1.14272598e-06
Iter: 1083 loss: 1.1422112e-06
Iter: 1084 loss: 1.14243585e-06
Iter: 1085 loss: 1.1418507e-06
Iter: 1086 loss: 1.14124623e-06
Iter: 1087 loss: 1.14246916e-06
Iter: 1088 loss: 1.14097145e-06
Iter: 1089 loss: 1.14036993e-06
Iter: 1090 loss: 1.14784609e-06
Iter: 1091 loss: 1.14032991e-06
Iter: 1092 loss: 1.13989404e-06
Iter: 1093 loss: 1.13945225e-06
Iter: 1094 loss: 1.13939495e-06
Iter: 1095 loss: 1.1391669e-06
Iter: 1096 loss: 1.13901808e-06
Iter: 1097 loss: 1.13871613e-06
Iter: 1098 loss: 1.13805118e-06
Iter: 1099 loss: 1.14878321e-06
Iter: 1100 loss: 1.13803048e-06
Iter: 1101 loss: 1.13729254e-06
Iter: 1102 loss: 1.13782949e-06
Iter: 1103 loss: 1.13685712e-06
Iter: 1104 loss: 1.1362597e-06
Iter: 1105 loss: 1.13848932e-06
Iter: 1106 loss: 1.13613942e-06
Iter: 1107 loss: 1.13538204e-06
Iter: 1108 loss: 1.13845658e-06
Iter: 1109 loss: 1.13529268e-06
Iter: 1110 loss: 1.13469014e-06
Iter: 1111 loss: 1.13566125e-06
Iter: 1112 loss: 1.13441047e-06
Iter: 1113 loss: 1.13381248e-06
Iter: 1114 loss: 1.13804572e-06
Iter: 1115 loss: 1.13373039e-06
Iter: 1116 loss: 1.1331598e-06
Iter: 1117 loss: 1.13359056e-06
Iter: 1118 loss: 1.13282135e-06
Iter: 1119 loss: 1.13227884e-06
Iter: 1120 loss: 1.1328865e-06
Iter: 1121 loss: 1.13196427e-06
Iter: 1122 loss: 1.13135206e-06
Iter: 1123 loss: 1.13405508e-06
Iter: 1124 loss: 1.13124111e-06
Iter: 1125 loss: 1.13051738e-06
Iter: 1126 loss: 1.13278315e-06
Iter: 1127 loss: 1.130339e-06
Iter: 1128 loss: 1.12991279e-06
Iter: 1129 loss: 1.13195347e-06
Iter: 1130 loss: 1.12984594e-06
Iter: 1131 loss: 1.1292409e-06
Iter: 1132 loss: 1.1301172e-06
Iter: 1133 loss: 1.12896214e-06
Iter: 1134 loss: 1.12850739e-06
Iter: 1135 loss: 1.12798205e-06
Iter: 1136 loss: 1.12783835e-06
Iter: 1137 loss: 1.12716509e-06
Iter: 1138 loss: 1.12765144e-06
Iter: 1139 loss: 1.12672205e-06
Iter: 1140 loss: 1.1260704e-06
Iter: 1141 loss: 1.13540978e-06
Iter: 1142 loss: 1.12608097e-06
Iter: 1143 loss: 1.12557973e-06
Iter: 1144 loss: 1.1258262e-06
Iter: 1145 loss: 1.12518683e-06
Iter: 1146 loss: 1.12448902e-06
Iter: 1147 loss: 1.12783425e-06
Iter: 1148 loss: 1.12439398e-06
Iter: 1149 loss: 1.12385942e-06
Iter: 1150 loss: 1.12774205e-06
Iter: 1151 loss: 1.12383395e-06
Iter: 1152 loss: 1.12345447e-06
Iter: 1153 loss: 1.12281646e-06
Iter: 1154 loss: 1.1228243e-06
Iter: 1155 loss: 1.12213979e-06
Iter: 1156 loss: 1.12534178e-06
Iter: 1157 loss: 1.12194925e-06
Iter: 1158 loss: 1.12151793e-06
Iter: 1159 loss: 1.12889131e-06
Iter: 1160 loss: 1.12152259e-06
Iter: 1161 loss: 1.12118084e-06
Iter: 1162 loss: 1.12067448e-06
Iter: 1163 loss: 1.12068085e-06
Iter: 1164 loss: 1.12018256e-06
Iter: 1165 loss: 1.12015709e-06
Iter: 1166 loss: 1.11982899e-06
Iter: 1167 loss: 1.11919894e-06
Iter: 1168 loss: 1.13143483e-06
Iter: 1169 loss: 1.11919792e-06
Iter: 1170 loss: 1.11857958e-06
Iter: 1171 loss: 1.11919508e-06
Iter: 1172 loss: 1.11819497e-06
Iter: 1173 loss: 1.11755298e-06
Iter: 1174 loss: 1.12038128e-06
Iter: 1175 loss: 1.11740803e-06
Iter: 1176 loss: 1.11666384e-06
Iter: 1177 loss: 1.11973543e-06
Iter: 1178 loss: 1.11650888e-06
Iter: 1179 loss: 1.11591987e-06
Iter: 1180 loss: 1.11832105e-06
Iter: 1181 loss: 1.11580312e-06
Iter: 1182 loss: 1.11533075e-06
Iter: 1183 loss: 1.11705867e-06
Iter: 1184 loss: 1.1151983e-06
Iter: 1185 loss: 1.1146675e-06
Iter: 1186 loss: 1.11519739e-06
Iter: 1187 loss: 1.11438601e-06
Iter: 1188 loss: 1.1137862e-06
Iter: 1189 loss: 1.11363636e-06
Iter: 1190 loss: 1.11325335e-06
Iter: 1191 loss: 1.11285385e-06
Iter: 1192 loss: 1.11282247e-06
Iter: 1193 loss: 1.11239706e-06
Iter: 1194 loss: 1.11191571e-06
Iter: 1195 loss: 1.11184613e-06
Iter: 1196 loss: 1.11146301e-06
Iter: 1197 loss: 1.11140389e-06
Iter: 1198 loss: 1.11107192e-06
Iter: 1199 loss: 1.11082136e-06
Iter: 1200 loss: 1.11068312e-06
Iter: 1201 loss: 1.11028169e-06
Iter: 1202 loss: 1.10974e-06
Iter: 1203 loss: 1.10967892e-06
Iter: 1204 loss: 1.10887481e-06
Iter: 1205 loss: 1.11126587e-06
Iter: 1206 loss: 1.10862106e-06
Iter: 1207 loss: 1.10798874e-06
Iter: 1208 loss: 1.113189e-06
Iter: 1209 loss: 1.10790768e-06
Iter: 1210 loss: 1.10735039e-06
Iter: 1211 loss: 1.10927476e-06
Iter: 1212 loss: 1.10718906e-06
Iter: 1213 loss: 1.10661892e-06
Iter: 1214 loss: 1.1077932e-06
Iter: 1215 loss: 1.10639667e-06
Iter: 1216 loss: 1.10581857e-06
Iter: 1217 loss: 1.10924282e-06
Iter: 1218 loss: 1.10574206e-06
Iter: 1219 loss: 1.10529936e-06
Iter: 1220 loss: 1.1048428e-06
Iter: 1221 loss: 1.10475889e-06
Iter: 1222 loss: 1.10426072e-06
Iter: 1223 loss: 1.10706924e-06
Iter: 1224 loss: 1.10414123e-06
Iter: 1225 loss: 1.10351425e-06
Iter: 1226 loss: 1.10536439e-06
Iter: 1227 loss: 1.10329461e-06
Iter: 1228 loss: 1.10289523e-06
Iter: 1229 loss: 1.10672772e-06
Iter: 1230 loss: 1.1028701e-06
Iter: 1231 loss: 1.10247936e-06
Iter: 1232 loss: 1.10354176e-06
Iter: 1233 loss: 1.10234168e-06
Iter: 1234 loss: 1.1019813e-06
Iter: 1235 loss: 1.10121869e-06
Iter: 1236 loss: 1.11308441e-06
Iter: 1237 loss: 1.10119299e-06
Iter: 1238 loss: 1.10047222e-06
Iter: 1239 loss: 1.10321912e-06
Iter: 1240 loss: 1.1002569e-06
Iter: 1241 loss: 1.09963798e-06
Iter: 1242 loss: 1.10121471e-06
Iter: 1243 loss: 1.09936764e-06
Iter: 1244 loss: 1.09873463e-06
Iter: 1245 loss: 1.10452504e-06
Iter: 1246 loss: 1.09866539e-06
Iter: 1247 loss: 1.09818552e-06
Iter: 1248 loss: 1.09973644e-06
Iter: 1249 loss: 1.09801738e-06
Iter: 1250 loss: 1.09752011e-06
Iter: 1251 loss: 1.09835446e-06
Iter: 1252 loss: 1.09727068e-06
Iter: 1253 loss: 1.09659481e-06
Iter: 1254 loss: 1.09771804e-06
Iter: 1255 loss: 1.09627626e-06
Iter: 1256 loss: 1.09575649e-06
Iter: 1257 loss: 1.09638245e-06
Iter: 1258 loss: 1.09549535e-06
Iter: 1259 loss: 1.09504697e-06
Iter: 1260 loss: 1.10134295e-06
Iter: 1261 loss: 1.09504185e-06
Iter: 1262 loss: 1.09470488e-06
Iter: 1263 loss: 1.09468328e-06
Iter: 1264 loss: 1.09443351e-06
Iter: 1265 loss: 1.09396285e-06
Iter: 1266 loss: 1.1005252e-06
Iter: 1267 loss: 1.09397024e-06
Iter: 1268 loss: 1.09365124e-06
Iter: 1269 loss: 1.09298367e-06
Iter: 1270 loss: 1.10821441e-06
Iter: 1271 loss: 1.09298287e-06
Iter: 1272 loss: 1.09237737e-06
Iter: 1273 loss: 1.09284247e-06
Iter: 1274 loss: 1.09200278e-06
Iter: 1275 loss: 1.09140831e-06
Iter: 1276 loss: 1.09296752e-06
Iter: 1277 loss: 1.09119446e-06
Iter: 1278 loss: 1.09052212e-06
Iter: 1279 loss: 1.09375367e-06
Iter: 1280 loss: 1.09039797e-06
Iter: 1281 loss: 1.08990923e-06
Iter: 1282 loss: 1.09521352e-06
Iter: 1283 loss: 1.08991435e-06
Iter: 1284 loss: 1.08950519e-06
Iter: 1285 loss: 1.08946574e-06
Iter: 1286 loss: 1.08917925e-06
Iter: 1287 loss: 1.08862866e-06
Iter: 1288 loss: 1.09165171e-06
Iter: 1289 loss: 1.08853476e-06
Iter: 1290 loss: 1.08805375e-06
Iter: 1291 loss: 1.08783252e-06
Iter: 1292 loss: 1.08759752e-06
Iter: 1293 loss: 1.08698828e-06
Iter: 1294 loss: 1.09047824e-06
Iter: 1295 loss: 1.08690415e-06
Iter: 1296 loss: 1.08633162e-06
Iter: 1297 loss: 1.08967311e-06
Iter: 1298 loss: 1.08627296e-06
Iter: 1299 loss: 1.08593269e-06
Iter: 1300 loss: 1.08957215e-06
Iter: 1301 loss: 1.08593235e-06
Iter: 1302 loss: 1.08560096e-06
Iter: 1303 loss: 1.08541258e-06
Iter: 1304 loss: 1.08524489e-06
Iter: 1305 loss: 1.08480049e-06
Iter: 1306 loss: 1.0843271e-06
Iter: 1307 loss: 1.08424194e-06
Iter: 1308 loss: 1.08362929e-06
Iter: 1309 loss: 1.08473353e-06
Iter: 1310 loss: 1.08339043e-06
Iter: 1311 loss: 1.08274276e-06
Iter: 1312 loss: 1.08652375e-06
Iter: 1313 loss: 1.08261429e-06
Iter: 1314 loss: 1.08214545e-06
Iter: 1315 loss: 1.0849069e-06
Iter: 1316 loss: 1.08206063e-06
Iter: 1317 loss: 1.08157894e-06
Iter: 1318 loss: 1.08316317e-06
Iter: 1319 loss: 1.08142535e-06
Iter: 1320 loss: 1.08104564e-06
Iter: 1321 loss: 1.08239635e-06
Iter: 1322 loss: 1.08098038e-06
Iter: 1323 loss: 1.08056338e-06
Iter: 1324 loss: 1.08043832e-06
Iter: 1325 loss: 1.08021891e-06
Iter: 1326 loss: 1.07962956e-06
Iter: 1327 loss: 1.08101472e-06
Iter: 1328 loss: 1.079443e-06
Iter: 1329 loss: 1.07898484e-06
Iter: 1330 loss: 1.08391714e-06
Iter: 1331 loss: 1.07893788e-06
Iter: 1332 loss: 1.07858762e-06
Iter: 1333 loss: 1.0797562e-06
Iter: 1334 loss: 1.07848984e-06
Iter: 1335 loss: 1.07803953e-06
Iter: 1336 loss: 1.07949359e-06
Iter: 1337 loss: 1.07793085e-06
Iter: 1338 loss: 1.07752783e-06
Iter: 1339 loss: 1.07709639e-06
Iter: 1340 loss: 1.0770259e-06
Iter: 1341 loss: 1.07650249e-06
Iter: 1342 loss: 1.07639482e-06
Iter: 1343 loss: 1.07607036e-06
Iter: 1344 loss: 1.0753065e-06
Iter: 1345 loss: 1.0795809e-06
Iter: 1346 loss: 1.07521623e-06
Iter: 1347 loss: 1.07463075e-06
Iter: 1348 loss: 1.07688629e-06
Iter: 1349 loss: 1.074485e-06
Iter: 1350 loss: 1.07400388e-06
Iter: 1351 loss: 1.07904293e-06
Iter: 1352 loss: 1.07395897e-06
Iter: 1353 loss: 1.07354526e-06
Iter: 1354 loss: 1.07338769e-06
Iter: 1355 loss: 1.07316737e-06
Iter: 1356 loss: 1.0725521e-06
Iter: 1357 loss: 1.07651556e-06
Iter: 1358 loss: 1.07252777e-06
Iter: 1359 loss: 1.07207984e-06
Iter: 1360 loss: 1.07216465e-06
Iter: 1361 loss: 1.07178107e-06
Iter: 1362 loss: 1.0712472e-06
Iter: 1363 loss: 1.07448e-06
Iter: 1364 loss: 1.07116762e-06
Iter: 1365 loss: 1.0707447e-06
Iter: 1366 loss: 1.07371545e-06
Iter: 1367 loss: 1.07069286e-06
Iter: 1368 loss: 1.07033577e-06
Iter: 1369 loss: 1.07191295e-06
Iter: 1370 loss: 1.07028495e-06
Iter: 1371 loss: 1.06988978e-06
Iter: 1372 loss: 1.0695876e-06
Iter: 1373 loss: 1.06950301e-06
Iter: 1374 loss: 1.06908419e-06
Iter: 1375 loss: 1.06858488e-06
Iter: 1376 loss: 1.06852985e-06
Iter: 1377 loss: 1.06771233e-06
Iter: 1378 loss: 1.07120059e-06
Iter: 1379 loss: 1.06755203e-06
Iter: 1380 loss: 1.06700918e-06
Iter: 1381 loss: 1.07059907e-06
Iter: 1382 loss: 1.06692937e-06
Iter: 1383 loss: 1.06644075e-06
Iter: 1384 loss: 1.06844823e-06
Iter: 1385 loss: 1.06632706e-06
Iter: 1386 loss: 1.06582274e-06
Iter: 1387 loss: 1.06705602e-06
Iter: 1388 loss: 1.06557286e-06
Iter: 1389 loss: 1.06513301e-06
Iter: 1390 loss: 1.06670234e-06
Iter: 1391 loss: 1.06502114e-06
Iter: 1392 loss: 1.06450955e-06
Iter: 1393 loss: 1.06450705e-06
Iter: 1394 loss: 1.06409675e-06
Iter: 1395 loss: 1.06351831e-06
Iter: 1396 loss: 1.06714856e-06
Iter: 1397 loss: 1.0634617e-06
Iter: 1398 loss: 1.0630788e-06
Iter: 1399 loss: 1.06544553e-06
Iter: 1400 loss: 1.06307436e-06
Iter: 1401 loss: 1.0626884e-06
Iter: 1402 loss: 1.06405844e-06
Iter: 1403 loss: 1.06264702e-06
Iter: 1404 loss: 1.06223467e-06
Iter: 1405 loss: 1.06290645e-06
Iter: 1406 loss: 1.06201514e-06
Iter: 1407 loss: 1.06172774e-06
Iter: 1408 loss: 1.06111133e-06
Iter: 1409 loss: 1.071317e-06
Iter: 1410 loss: 1.06109439e-06
Iter: 1411 loss: 1.06038874e-06
Iter: 1412 loss: 1.06457423e-06
Iter: 1413 loss: 1.06029074e-06
Iter: 1414 loss: 1.05971208e-06
Iter: 1415 loss: 1.06087396e-06
Iter: 1416 loss: 1.0594498e-06
Iter: 1417 loss: 1.05882577e-06
Iter: 1418 loss: 1.06169716e-06
Iter: 1419 loss: 1.05871607e-06
Iter: 1420 loss: 1.05826257e-06
Iter: 1421 loss: 1.065064e-06
Iter: 1422 loss: 1.05826757e-06
Iter: 1423 loss: 1.05797176e-06
Iter: 1424 loss: 1.05760842e-06
Iter: 1425 loss: 1.05758795e-06
Iter: 1426 loss: 1.05692527e-06
Iter: 1427 loss: 1.05931542e-06
Iter: 1428 loss: 1.0567569e-06
Iter: 1429 loss: 1.0562303e-06
Iter: 1430 loss: 1.05752497e-06
Iter: 1431 loss: 1.05604124e-06
Iter: 1432 loss: 1.0556339e-06
Iter: 1433 loss: 1.05811591e-06
Iter: 1434 loss: 1.05561321e-06
Iter: 1435 loss: 1.05524714e-06
Iter: 1436 loss: 1.05863876e-06
Iter: 1437 loss: 1.05524714e-06
Iter: 1438 loss: 1.05499839e-06
Iter: 1439 loss: 1.05555284e-06
Iter: 1440 loss: 1.05491654e-06
Iter: 1441 loss: 1.05463073e-06
Iter: 1442 loss: 1.05405888e-06
Iter: 1443 loss: 1.06379025e-06
Iter: 1444 loss: 1.05405275e-06
Iter: 1445 loss: 1.05340064e-06
Iter: 1446 loss: 1.05492677e-06
Iter: 1447 loss: 1.05320589e-06
Iter: 1448 loss: 1.05256174e-06
Iter: 1449 loss: 1.05551283e-06
Iter: 1450 loss: 1.05242066e-06
Iter: 1451 loss: 1.05191793e-06
Iter: 1452 loss: 1.0522092e-06
Iter: 1453 loss: 1.05155618e-06
Iter: 1454 loss: 1.05110655e-06
Iter: 1455 loss: 1.05109109e-06
Iter: 1456 loss: 1.05071911e-06
Iter: 1457 loss: 1.05087236e-06
Iter: 1458 loss: 1.05050106e-06
Iter: 1459 loss: 1.0500537e-06
Iter: 1460 loss: 1.05129493e-06
Iter: 1461 loss: 1.04989681e-06
Iter: 1462 loss: 1.04943297e-06
Iter: 1463 loss: 1.0501883e-06
Iter: 1464 loss: 1.04926312e-06
Iter: 1465 loss: 1.04880235e-06
Iter: 1466 loss: 1.04981757e-06
Iter: 1467 loss: 1.04860976e-06
Iter: 1468 loss: 1.04819992e-06
Iter: 1469 loss: 1.04819912e-06
Iter: 1470 loss: 1.04788955e-06
Iter: 1471 loss: 1.0483991e-06
Iter: 1472 loss: 1.04771948e-06
Iter: 1473 loss: 1.04740604e-06
Iter: 1474 loss: 1.04762034e-06
Iter: 1475 loss: 1.04721357e-06
Iter: 1476 loss: 1.04688036e-06
Iter: 1477 loss: 1.04644187e-06
Iter: 1478 loss: 1.04640867e-06
Iter: 1479 loss: 1.04583273e-06
Iter: 1480 loss: 1.04929313e-06
Iter: 1481 loss: 1.04575111e-06
Iter: 1482 loss: 1.04519893e-06
Iter: 1483 loss: 1.04492597e-06
Iter: 1484 loss: 1.04461503e-06
Iter: 1485 loss: 1.04433218e-06
Iter: 1486 loss: 1.0442576e-06
Iter: 1487 loss: 1.04387834e-06
Iter: 1488 loss: 1.04427113e-06
Iter: 1489 loss: 1.04369428e-06
Iter: 1490 loss: 1.04327842e-06
Iter: 1491 loss: 1.04323237e-06
Iter: 1492 loss: 1.04291712e-06
Iter: 1493 loss: 1.04223773e-06
Iter: 1494 loss: 1.0454e-06
Iter: 1495 loss: 1.04210744e-06
Iter: 1496 loss: 1.04158539e-06
Iter: 1497 loss: 1.04305445e-06
Iter: 1498 loss: 1.04143089e-06
Iter: 1499 loss: 1.04102082e-06
Iter: 1500 loss: 1.045104e-06
Iter: 1501 loss: 1.0410173e-06
Iter: 1502 loss: 1.04071546e-06
Iter: 1503 loss: 1.04180708e-06
Iter: 1504 loss: 1.040602e-06
Iter: 1505 loss: 1.04033393e-06
Iter: 1506 loss: 1.0406801e-06
Iter: 1507 loss: 1.04019273e-06
Iter: 1508 loss: 1.03986463e-06
Iter: 1509 loss: 1.03944524e-06
Iter: 1510 loss: 1.03945649e-06
Iter: 1511 loss: 1.03893944e-06
Iter: 1512 loss: 1.04101377e-06
Iter: 1513 loss: 1.03879518e-06
Iter: 1514 loss: 1.0382546e-06
Iter: 1515 loss: 1.03854393e-06
Iter: 1516 loss: 1.0379581e-06
Iter: 1517 loss: 1.03743241e-06
Iter: 1518 loss: 1.04145693e-06
Iter: 1519 loss: 1.03740445e-06
Iter: 1520 loss: 1.03694606e-06
Iter: 1521 loss: 1.03991169e-06
Iter: 1522 loss: 1.03689229e-06
Iter: 1523 loss: 1.0364829e-06
Iter: 1524 loss: 1.03649177e-06
Iter: 1525 loss: 1.03614718e-06
Iter: 1526 loss: 1.03562979e-06
Iter: 1527 loss: 1.03788295e-06
Iter: 1528 loss: 1.03551656e-06
Iter: 1529 loss: 1.03510934e-06
Iter: 1530 loss: 1.03703337e-06
Iter: 1531 loss: 1.03506727e-06
Iter: 1532 loss: 1.03469074e-06
Iter: 1533 loss: 1.03494085e-06
Iter: 1534 loss: 1.03444745e-06
Iter: 1535 loss: 1.03400578e-06
Iter: 1536 loss: 1.0391982e-06
Iter: 1537 loss: 1.03398031e-06
Iter: 1538 loss: 1.03370246e-06
Iter: 1539 loss: 1.03388027e-06
Iter: 1540 loss: 1.03350953e-06
Iter: 1541 loss: 1.03310549e-06
Iter: 1542 loss: 1.03296816e-06
Iter: 1543 loss: 1.03278342e-06
Iter: 1544 loss: 1.03225307e-06
Iter: 1545 loss: 1.03286175e-06
Iter: 1546 loss: 1.03204036e-06
Iter: 1547 loss: 1.03148466e-06
Iter: 1548 loss: 1.03276761e-06
Iter: 1549 loss: 1.03128787e-06
Iter: 1550 loss: 1.03072909e-06
Iter: 1551 loss: 1.03194168e-06
Iter: 1552 loss: 1.03048603e-06
Iter: 1553 loss: 1.0300854e-06
Iter: 1554 loss: 1.03688797e-06
Iter: 1555 loss: 1.03008142e-06
Iter: 1556 loss: 1.02971558e-06
Iter: 1557 loss: 1.03017965e-06
Iter: 1558 loss: 1.02947888e-06
Iter: 1559 loss: 1.02903221e-06
Iter: 1560 loss: 1.02947729e-06
Iter: 1561 loss: 1.02879119e-06
Iter: 1562 loss: 1.02835202e-06
Iter: 1563 loss: 1.03112643e-06
Iter: 1564 loss: 1.02834565e-06
Iter: 1565 loss: 1.02791898e-06
Iter: 1566 loss: 1.02784475e-06
Iter: 1567 loss: 1.02756303e-06
Iter: 1568 loss: 1.0274091e-06
Iter: 1569 loss: 1.02728438e-06
Iter: 1570 loss: 1.0271026e-06
Iter: 1571 loss: 1.02682088e-06
Iter: 1572 loss: 1.02684066e-06
Iter: 1573 loss: 1.02639319e-06
Iter: 1574 loss: 1.02668139e-06
Iter: 1575 loss: 1.02611534e-06
Iter: 1576 loss: 1.02568129e-06
Iter: 1577 loss: 1.02591434e-06
Iter: 1578 loss: 1.02536342e-06
Iter: 1579 loss: 1.02481977e-06
Iter: 1580 loss: 1.0259007e-06
Iter: 1581 loss: 1.02461479e-06
Iter: 1582 loss: 1.02399326e-06
Iter: 1583 loss: 1.0255294e-06
Iter: 1584 loss: 1.02375282e-06
Iter: 1585 loss: 1.02328067e-06
Iter: 1586 loss: 1.02717991e-06
Iter: 1587 loss: 1.02327772e-06
Iter: 1588 loss: 1.02286538e-06
Iter: 1589 loss: 1.02434046e-06
Iter: 1590 loss: 1.02272884e-06
Iter: 1591 loss: 1.02231161e-06
Iter: 1592 loss: 1.02277636e-06
Iter: 1593 loss: 1.02208605e-06
Iter: 1594 loss: 1.02168701e-06
Iter: 1595 loss: 1.02276567e-06
Iter: 1596 loss: 1.02155684e-06
Iter: 1597 loss: 1.02102354e-06
Iter: 1598 loss: 1.02254455e-06
Iter: 1599 loss: 1.02085892e-06
Iter: 1600 loss: 1.02054594e-06
Iter: 1601 loss: 1.02476235e-06
Iter: 1602 loss: 1.02053514e-06
Iter: 1603 loss: 1.02020567e-06
Iter: 1604 loss: 1.020318e-06
Iter: 1605 loss: 1.01999876e-06
Iter: 1606 loss: 1.01965213e-06
Iter: 1607 loss: 1.0206054e-06
Iter: 1608 loss: 1.01952946e-06
Iter: 1609 loss: 1.01917431e-06
Iter: 1610 loss: 1.01906153e-06
Iter: 1611 loss: 1.01888338e-06
Iter: 1612 loss: 1.01837759e-06
Iter: 1613 loss: 1.019205e-06
Iter: 1614 loss: 1.01814669e-06
Iter: 1615 loss: 1.01761054e-06
Iter: 1616 loss: 1.01789067e-06
Iter: 1617 loss: 1.01722844e-06
Iter: 1618 loss: 1.01660112e-06
Iter: 1619 loss: 1.02106492e-06
Iter: 1620 loss: 1.01656246e-06
Iter: 1621 loss: 1.01609578e-06
Iter: 1622 loss: 1.0206868e-06
Iter: 1623 loss: 1.01607611e-06
Iter: 1624 loss: 1.01569844e-06
Iter: 1625 loss: 1.01622777e-06
Iter: 1626 loss: 1.015517e-06
Iter: 1627 loss: 1.01516912e-06
Iter: 1628 loss: 1.01542514e-06
Iter: 1629 loss: 1.0149306e-06
Iter: 1630 loss: 1.01446267e-06
Iter: 1631 loss: 1.01634828e-06
Iter: 1632 loss: 1.01438377e-06
Iter: 1633 loss: 1.01396608e-06
Iter: 1634 loss: 1.01569572e-06
Iter: 1635 loss: 1.01389901e-06
Iter: 1636 loss: 1.01348405e-06
Iter: 1637 loss: 1.01669707e-06
Iter: 1638 loss: 1.01348451e-06
Iter: 1639 loss: 1.01324576e-06
Iter: 1640 loss: 1.0131198e-06
Iter: 1641 loss: 1.0130168e-06
Iter: 1642 loss: 1.01262458e-06
Iter: 1643 loss: 1.01279079e-06
Iter: 1644 loss: 1.0123199e-06
Iter: 1645 loss: 1.01194826e-06
Iter: 1646 loss: 1.01355204e-06
Iter: 1647 loss: 1.01185628e-06
Iter: 1648 loss: 1.01148942e-06
Iter: 1649 loss: 1.01091393e-06
Iter: 1650 loss: 1.01089438e-06
Iter: 1651 loss: 1.01021078e-06
Iter: 1652 loss: 1.01626017e-06
Iter: 1653 loss: 1.01021806e-06
Iter: 1654 loss: 1.00971101e-06
Iter: 1655 loss: 1.01407682e-06
Iter: 1656 loss: 1.00967884e-06
Iter: 1657 loss: 1.00928287e-06
Iter: 1658 loss: 1.01074011e-06
Iter: 1659 loss: 1.0091602e-06
Iter: 1660 loss: 1.00886473e-06
Iter: 1661 loss: 1.00844068e-06
Iter: 1662 loss: 1.00842317e-06
Iter: 1663 loss: 1.00781835e-06
Iter: 1664 loss: 1.0134313e-06
Iter: 1665 loss: 1.00780403e-06
Iter: 1666 loss: 1.00740169e-06
Iter: 1667 loss: 1.00953298e-06
Iter: 1668 loss: 1.00732905e-06
Iter: 1669 loss: 1.00710145e-06
Iter: 1670 loss: 1.0071135e-06
Iter: 1671 loss: 1.00694911e-06
Iter: 1672 loss: 1.00666568e-06
Iter: 1673 loss: 1.01303306e-06
Iter: 1674 loss: 1.00667944e-06
Iter: 1675 loss: 1.00622174e-06
Iter: 1676 loss: 1.00691364e-06
Iter: 1677 loss: 1.00604007e-06
Iter: 1678 loss: 1.005596e-06
Iter: 1679 loss: 1.00641432e-06
Iter: 1680 loss: 1.00541138e-06
Iter: 1681 loss: 1.00493844e-06
Iter: 1682 loss: 1.0049697e-06
Iter: 1683 loss: 1.00455713e-06
Iter: 1684 loss: 1.0039787e-06
Iter: 1685 loss: 1.00628381e-06
Iter: 1686 loss: 1.00384477e-06
Iter: 1687 loss: 1.00333e-06
Iter: 1688 loss: 1.00692591e-06
Iter: 1689 loss: 1.00327873e-06
Iter: 1690 loss: 1.00285183e-06
Iter: 1691 loss: 1.00561965e-06
Iter: 1692 loss: 1.0028175e-06
Iter: 1693 loss: 1.00244597e-06
Iter: 1694 loss: 1.00213356e-06
Iter: 1695 loss: 1.00202692e-06
Iter: 1696 loss: 1.00157342e-06
Iter: 1697 loss: 1.00375109e-06
Iter: 1698 loss: 1.00150623e-06
Iter: 1699 loss: 1.00108787e-06
Iter: 1700 loss: 1.00311695e-06
Iter: 1701 loss: 1.00100215e-06
Iter: 1702 loss: 1.00075e-06
Iter: 1703 loss: 1.00415502e-06
Iter: 1704 loss: 1.00075499e-06
Iter: 1705 loss: 1.00046509e-06
Iter: 1706 loss: 1.00020407e-06
Iter: 1707 loss: 1.00017542e-06
Iter: 1708 loss: 9.99796725e-07
Iter: 1709 loss: 1.00111788e-06
Iter: 1710 loss: 9.99676558e-07
Iter: 1711 loss: 9.99331e-07
Iter: 1712 loss: 9.99911663e-07
Iter: 1713 loss: 9.99190092e-07
Iter: 1714 loss: 9.98812197e-07
Iter: 1715 loss: 9.98802761e-07
Iter: 1716 loss: 9.9851809e-07
Iter: 1717 loss: 9.97943062e-07
Iter: 1718 loss: 9.9818e-07
Iter: 1719 loss: 9.97544248e-07
Iter: 1720 loss: 9.96965355e-07
Iter: 1721 loss: 1.00343345e-06
Iter: 1722 loss: 9.9696706e-07
Iter: 1723 loss: 9.96596327e-07
Iter: 1724 loss: 9.99569579e-07
Iter: 1725 loss: 9.9657359e-07
Iter: 1726 loss: 9.9622514e-07
Iter: 1727 loss: 9.9685542e-07
Iter: 1728 loss: 9.96085191e-07
Iter: 1729 loss: 9.95800633e-07
Iter: 1730 loss: 9.95627e-07
Iter: 1731 loss: 9.95518462e-07
Iter: 1732 loss: 9.95063829e-07
Iter: 1733 loss: 9.9920976e-07
Iter: 1734 loss: 9.95037908e-07
Iter: 1735 loss: 9.94735e-07
Iter: 1736 loss: 9.9765316e-07
Iter: 1737 loss: 9.94707534e-07
Iter: 1738 loss: 9.94374886e-07
Iter: 1739 loss: 9.94566335e-07
Iter: 1740 loss: 9.94191396e-07
Iter: 1741 loss: 9.93832145e-07
Iter: 1742 loss: 9.93867161e-07
Iter: 1743 loss: 9.93578396e-07
Iter: 1744 loss: 9.9317208e-07
Iter: 1745 loss: 9.95145228e-07
Iter: 1746 loss: 9.93117e-07
Iter: 1747 loss: 9.92745527e-07
Iter: 1748 loss: 9.93024855e-07
Iter: 1749 loss: 9.92558284e-07
Iter: 1750 loss: 9.9211843e-07
Iter: 1751 loss: 9.91799e-07
Iter: 1752 loss: 9.91654815e-07
Iter: 1753 loss: 9.91008e-07
Iter: 1754 loss: 9.94746756e-07
Iter: 1755 loss: 9.90924491e-07
Iter: 1756 loss: 9.9043541e-07
Iter: 1757 loss: 9.94944685e-07
Iter: 1758 loss: 9.90406306e-07
Iter: 1759 loss: 9.90016815e-07
Iter: 1760 loss: 9.92367632e-07
Iter: 1761 loss: 9.89944738e-07
Iter: 1762 loss: 9.89676096e-07
Iter: 1763 loss: 9.89337195e-07
Iter: 1764 loss: 9.89307e-07
Iter: 1765 loss: 9.88886086e-07
Iter: 1766 loss: 9.92212449e-07
Iter: 1767 loss: 9.88858801e-07
Iter: 1768 loss: 9.88446573e-07
Iter: 1769 loss: 9.9061e-07
Iter: 1770 loss: 9.88400188e-07
Iter: 1771 loss: 9.88022521e-07
Iter: 1772 loss: 9.89787509e-07
Iter: 1773 loss: 9.87978e-07
Iter: 1774 loss: 9.87710337e-07
Iter: 1775 loss: 9.87497629e-07
Iter: 1776 loss: 9.8744249e-07
Iter: 1777 loss: 9.87035e-07
Iter: 1778 loss: 9.88169404e-07
Iter: 1779 loss: 9.86898385e-07
Iter: 1780 loss: 9.8652265e-07
Iter: 1781 loss: 9.87680096e-07
Iter: 1782 loss: 9.86412942e-07
Iter: 1783 loss: 9.86045848e-07
Iter: 1784 loss: 9.85794145e-07
Iter: 1785 loss: 9.85681254e-07
Iter: 1786 loss: 9.85172619e-07
Iter: 1787 loss: 9.87553676e-07
Iter: 1788 loss: 9.85107249e-07
Iter: 1789 loss: 9.84576445e-07
Iter: 1790 loss: 9.85760494e-07
Iter: 1791 loss: 9.84373514e-07
Iter: 1792 loss: 9.83857262e-07
Iter: 1793 loss: 9.89653245e-07
Iter: 1794 loss: 9.83871587e-07
Iter: 1795 loss: 9.83497785e-07
Iter: 1796 loss: 9.83704922e-07
Iter: 1797 loss: 9.83232212e-07
Iter: 1798 loss: 9.82876372e-07
Iter: 1799 loss: 9.83120572e-07
Iter: 1800 loss: 9.82652e-07
Iter: 1801 loss: 9.82230176e-07
Iter: 1802 loss: 9.86871896e-07
Iter: 1803 loss: 9.82209713e-07
Iter: 1804 loss: 9.81878316e-07
Iter: 1805 loss: 9.84352e-07
Iter: 1806 loss: 9.81859444e-07
Iter: 1807 loss: 9.81623543e-07
Iter: 1808 loss: 9.81407879e-07
Iter: 1809 loss: 9.81353196e-07
Iter: 1810 loss: 9.81014637e-07
Iter: 1811 loss: 9.81832159e-07
Iter: 1812 loss: 9.80897084e-07
Iter: 1813 loss: 9.80517825e-07
Iter: 1814 loss: 9.81948233e-07
Iter: 1815 loss: 9.80453478e-07
Iter: 1816 loss: 9.8015812e-07
Iter: 1817 loss: 9.79929382e-07
Iter: 1818 loss: 9.79803303e-07
Iter: 1819 loss: 9.79358219e-07
Iter: 1820 loss: 9.80749633e-07
Iter: 1821 loss: 9.79221568e-07
Iter: 1822 loss: 9.7871316e-07
Iter: 1823 loss: 9.79530796e-07
Iter: 1824 loss: 9.78456569e-07
Iter: 1825 loss: 9.7797124e-07
Iter: 1826 loss: 9.84465e-07
Iter: 1827 loss: 9.77967375e-07
Iter: 1828 loss: 9.77615855e-07
Iter: 1829 loss: 9.79097763e-07
Iter: 1830 loss: 9.77523e-07
Iter: 1831 loss: 9.77313221e-07
Iter: 1832 loss: 9.77011723e-07
Iter: 1833 loss: 9.76974775e-07
Iter: 1834 loss: 9.76606088e-07
Iter: 1835 loss: 9.82105234e-07
Iter: 1836 loss: 9.76622118e-07
Iter: 1837 loss: 9.76362571e-07
Iter: 1838 loss: 9.78298658e-07
Iter: 1839 loss: 9.76329147e-07
Iter: 1840 loss: 9.76132e-07
Iter: 1841 loss: 9.76036745e-07
Iter: 1842 loss: 9.7589168e-07
Iter: 1843 loss: 9.75600415e-07
Iter: 1844 loss: 9.75566081e-07
Iter: 1845 loss: 9.75352691e-07
Iter: 1846 loss: 9.74934323e-07
Iter: 1847 loss: 9.76757065e-07
Iter: 1848 loss: 9.74839736e-07
Iter: 1849 loss: 9.744208e-07
Iter: 1850 loss: 9.75218882e-07
Iter: 1851 loss: 9.74276418e-07
Iter: 1852 loss: 9.73924443e-07
Iter: 1853 loss: 9.73680926e-07
Iter: 1854 loss: 9.73575879e-07
Iter: 1855 loss: 9.72962425e-07
Iter: 1856 loss: 9.76301635e-07
Iter: 1857 loss: 9.72867383e-07
Iter: 1858 loss: 9.72430826e-07
Iter: 1859 loss: 9.74360773e-07
Iter: 1860 loss: 9.72315661e-07
Iter: 1861 loss: 9.71910822e-07
Iter: 1862 loss: 9.76212e-07
Iter: 1863 loss: 9.71900135e-07
Iter: 1864 loss: 9.71666509e-07
Iter: 1865 loss: 9.71311692e-07
Iter: 1866 loss: 9.71286795e-07
Iter: 1867 loss: 9.70854558e-07
Iter: 1868 loss: 9.74293698e-07
Iter: 1869 loss: 9.70854103e-07
Iter: 1870 loss: 9.70532483e-07
Iter: 1871 loss: 9.7490738e-07
Iter: 1872 loss: 9.70539759e-07
Iter: 1873 loss: 9.70325686e-07
Iter: 1874 loss: 9.70475639e-07
Iter: 1875 loss: 9.70175279e-07
Iter: 1876 loss: 9.69838538e-07
Iter: 1877 loss: 9.69734e-07
Iter: 1878 loss: 9.69623102e-07
Iter: 1879 loss: 9.69182565e-07
Iter: 1880 loss: 9.70407314e-07
Iter: 1881 loss: 9.69045914e-07
Iter: 1882 loss: 9.68652216e-07
Iter: 1883 loss: 9.70537712e-07
Iter: 1884 loss: 9.68631e-07
Iter: 1885 loss: 9.68295126e-07
Iter: 1886 loss: 9.67857432e-07
Iter: 1887 loss: 9.67845381e-07
Iter: 1888 loss: 9.6732856e-07
Iter: 1889 loss: 9.70370593e-07
Iter: 1890 loss: 9.67273763e-07
Iter: 1891 loss: 9.66817197e-07
Iter: 1892 loss: 9.67739084e-07
Iter: 1893 loss: 9.66661787e-07
Iter: 1894 loss: 9.66289917e-07
Iter: 1895 loss: 9.66284688e-07
Iter: 1896 loss: 9.66001153e-07
Iter: 1897 loss: 9.65653498e-07
Iter: 1898 loss: 9.65639515e-07
Iter: 1899 loss: 9.65196364e-07
Iter: 1900 loss: 9.67163146e-07
Iter: 1901 loss: 9.6508461e-07
Iter: 1902 loss: 9.64835294e-07
Iter: 1903 loss: 9.6482438e-07
Iter: 1904 loss: 9.64587343e-07
Iter: 1905 loss: 9.64962737e-07
Iter: 1906 loss: 9.64479796e-07
Iter: 1907 loss: 9.64225364e-07
Iter: 1908 loss: 9.64166929e-07
Iter: 1909 loss: 9.6402232e-07
Iter: 1910 loss: 9.63674779e-07
Iter: 1911 loss: 9.63912271e-07
Iter: 1912 loss: 9.63422e-07
Iter: 1913 loss: 9.62996751e-07
Iter: 1914 loss: 9.6516294e-07
Iter: 1915 loss: 9.62948434e-07
Iter: 1916 loss: 9.62550871e-07
Iter: 1917 loss: 9.62730155e-07
Iter: 1918 loss: 9.62289846e-07
Iter: 1919 loss: 9.61855903e-07
Iter: 1920 loss: 9.62587706e-07
Iter: 1921 loss: 9.61654223e-07
Iter: 1922 loss: 9.612761e-07
Iter: 1923 loss: 9.63008688e-07
Iter: 1924 loss: 9.61172304e-07
Iter: 1925 loss: 9.60783154e-07
Iter: 1926 loss: 9.63235152e-07
Iter: 1927 loss: 9.6075928e-07
Iter: 1928 loss: 9.60361604e-07
Iter: 1929 loss: 9.61250862e-07
Iter: 1930 loss: 9.60221541e-07
Iter: 1931 loss: 9.59876e-07
Iter: 1932 loss: 9.59797489e-07
Iter: 1933 loss: 9.59608201e-07
Iter: 1934 loss: 9.59305339e-07
Iter: 1935 loss: 9.5929488e-07
Iter: 1936 loss: 9.5905159e-07
Iter: 1937 loss: 9.60130478e-07
Iter: 1938 loss: 9.59002e-07
Iter: 1939 loss: 9.58826149e-07
Iter: 1940 loss: 9.58735882e-07
Iter: 1941 loss: 9.58630153e-07
Iter: 1942 loss: 9.58299552e-07
Iter: 1943 loss: 9.58188707e-07
Iter: 1944 loss: 9.57977477e-07
Iter: 1945 loss: 9.57605e-07
Iter: 1946 loss: 9.61126489e-07
Iter: 1947 loss: 9.57578663e-07
Iter: 1948 loss: 9.57224529e-07
Iter: 1949 loss: 9.57527163e-07
Iter: 1950 loss: 9.57025804e-07
Iter: 1951 loss: 9.56660188e-07
Iter: 1952 loss: 9.56809572e-07
Iter: 1953 loss: 9.56386543e-07
Iter: 1954 loss: 9.55999e-07
Iter: 1955 loss: 9.58219744e-07
Iter: 1956 loss: 9.55963401e-07
Iter: 1957 loss: 9.55588689e-07
Iter: 1958 loss: 9.56270128e-07
Iter: 1959 loss: 9.55429641e-07
Iter: 1960 loss: 9.55078576e-07
Iter: 1961 loss: 9.59999e-07
Iter: 1962 loss: 9.550713e-07
Iter: 1963 loss: 9.54821189e-07
Iter: 1964 loss: 9.5451071e-07
Iter: 1965 loss: 9.54493771e-07
Iter: 1966 loss: 9.54159759e-07
Iter: 1967 loss: 9.58570354e-07
Iter: 1968 loss: 9.54166808e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4
+ date
Mon Oct 26 15:57:38 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55caf73158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cafa68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cafa60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55caf18bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cb043268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55caee58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cb043c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cae58ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cae59268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cae59d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cadfe730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cadcbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cadcb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cad92ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cad5d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cad40950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cad5d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cad48510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cac8e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cac8eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55caca8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55caca8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55cac54ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a1798620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a1798510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a1770840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a17288c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a17086a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a1708400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a16e8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55a16e80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557c7596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557c781400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557c72a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557c749a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557c6e8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.83194633e-05
Iter: 2 loss: 9.83113e-05
Iter: 3 loss: 4.98986774e-05
Iter: 4 loss: 4.65206358e-05
Iter: 5 loss: 4.15154318e-05
Iter: 6 loss: 4.13956914e-05
Iter: 7 loss: 3.70121525e-05
Iter: 8 loss: 5.59835062e-05
Iter: 9 loss: 3.61144412e-05
Iter: 10 loss: 3.10873511e-05
Iter: 11 loss: 3.1045347e-05
Iter: 12 loss: 2.70537694e-05
Iter: 13 loss: 2.47478565e-05
Iter: 14 loss: 3.56419332e-05
Iter: 15 loss: 2.43252289e-05
Iter: 16 loss: 2.33562623e-05
Iter: 17 loss: 2.07728717e-05
Iter: 18 loss: 3.91648246e-05
Iter: 19 loss: 2.01970652e-05
Iter: 20 loss: 1.87007445e-05
Iter: 21 loss: 3.08737472e-05
Iter: 22 loss: 1.86049365e-05
Iter: 23 loss: 1.76688409e-05
Iter: 24 loss: 1.65667807e-05
Iter: 25 loss: 1.64461308e-05
Iter: 26 loss: 1.54827558e-05
Iter: 27 loss: 1.54779809e-05
Iter: 28 loss: 1.49956741e-05
Iter: 29 loss: 1.42059907e-05
Iter: 30 loss: 1.42021227e-05
Iter: 31 loss: 1.3314766e-05
Iter: 32 loss: 1.90843348e-05
Iter: 33 loss: 1.32208334e-05
Iter: 34 loss: 1.28084503e-05
Iter: 35 loss: 1.41902683e-05
Iter: 36 loss: 1.26954765e-05
Iter: 37 loss: 1.21635021e-05
Iter: 38 loss: 1.28689771e-05
Iter: 39 loss: 1.1895876e-05
Iter: 40 loss: 1.1663572e-05
Iter: 41 loss: 1.20753921e-05
Iter: 42 loss: 1.15614394e-05
Iter: 43 loss: 1.12018342e-05
Iter: 44 loss: 1.18479529e-05
Iter: 45 loss: 1.10452229e-05
Iter: 46 loss: 1.06134894e-05
Iter: 47 loss: 1.07455971e-05
Iter: 48 loss: 1.03043731e-05
Iter: 49 loss: 1.00710349e-05
Iter: 50 loss: 1.32609111e-05
Iter: 51 loss: 1.00700654e-05
Iter: 52 loss: 9.80534514e-06
Iter: 53 loss: 9.84873623e-06
Iter: 54 loss: 9.60580837e-06
Iter: 55 loss: 9.40174e-06
Iter: 56 loss: 9.70677684e-06
Iter: 57 loss: 9.3039489e-06
Iter: 58 loss: 9.07885078e-06
Iter: 59 loss: 8.99920087e-06
Iter: 60 loss: 8.87235092e-06
Iter: 61 loss: 8.62399e-06
Iter: 62 loss: 8.62360685e-06
Iter: 63 loss: 8.47605588e-06
Iter: 64 loss: 8.24825838e-06
Iter: 65 loss: 8.24498602e-06
Iter: 66 loss: 8.00874477e-06
Iter: 67 loss: 1.13084225e-05
Iter: 68 loss: 8.00796442e-06
Iter: 69 loss: 7.93055096e-06
Iter: 70 loss: 7.90915692e-06
Iter: 71 loss: 7.83812175e-06
Iter: 72 loss: 7.66455923e-06
Iter: 73 loss: 9.47938497e-06
Iter: 74 loss: 7.64457218e-06
Iter: 75 loss: 7.4691643e-06
Iter: 76 loss: 7.69378312e-06
Iter: 77 loss: 7.37926894e-06
Iter: 78 loss: 7.17534567e-06
Iter: 79 loss: 8.3277364e-06
Iter: 80 loss: 7.14703856e-06
Iter: 81 loss: 7.03360502e-06
Iter: 82 loss: 7.02767466e-06
Iter: 83 loss: 6.97802625e-06
Iter: 84 loss: 6.86722e-06
Iter: 85 loss: 8.42458849e-06
Iter: 86 loss: 6.86156545e-06
Iter: 87 loss: 6.74744251e-06
Iter: 88 loss: 6.74705188e-06
Iter: 89 loss: 6.67822314e-06
Iter: 90 loss: 6.69577639e-06
Iter: 91 loss: 6.62822e-06
Iter: 92 loss: 6.55850272e-06
Iter: 93 loss: 6.46503577e-06
Iter: 94 loss: 6.45991304e-06
Iter: 95 loss: 6.3408097e-06
Iter: 96 loss: 6.33751279e-06
Iter: 97 loss: 6.2513659e-06
Iter: 98 loss: 6.46756416e-06
Iter: 99 loss: 6.2213312e-06
Iter: 100 loss: 6.15184626e-06
Iter: 101 loss: 6.99253724e-06
Iter: 102 loss: 6.15075351e-06
Iter: 103 loss: 6.09029757e-06
Iter: 104 loss: 6.3886e-06
Iter: 105 loss: 6.08006712e-06
Iter: 106 loss: 6.04415618e-06
Iter: 107 loss: 5.94487847e-06
Iter: 108 loss: 6.48957484e-06
Iter: 109 loss: 5.91476692e-06
Iter: 110 loss: 5.82616713e-06
Iter: 111 loss: 7.16754448e-06
Iter: 112 loss: 5.82613893e-06
Iter: 113 loss: 5.77788796e-06
Iter: 114 loss: 6.44200645e-06
Iter: 115 loss: 5.77769515e-06
Iter: 116 loss: 5.73150101e-06
Iter: 117 loss: 5.75217746e-06
Iter: 118 loss: 5.69977146e-06
Iter: 119 loss: 5.65212849e-06
Iter: 120 loss: 5.72931776e-06
Iter: 121 loss: 5.63015874e-06
Iter: 122 loss: 5.5682458e-06
Iter: 123 loss: 6.03899e-06
Iter: 124 loss: 5.56345e-06
Iter: 125 loss: 5.52983147e-06
Iter: 126 loss: 5.49371089e-06
Iter: 127 loss: 5.48818207e-06
Iter: 128 loss: 5.43335545e-06
Iter: 129 loss: 5.380743e-06
Iter: 130 loss: 5.36849302e-06
Iter: 131 loss: 5.30820762e-06
Iter: 132 loss: 5.96403197e-06
Iter: 133 loss: 5.30697525e-06
Iter: 134 loss: 5.2505552e-06
Iter: 135 loss: 5.51966377e-06
Iter: 136 loss: 5.24040843e-06
Iter: 137 loss: 5.20413096e-06
Iter: 138 loss: 5.20319e-06
Iter: 139 loss: 5.18510296e-06
Iter: 140 loss: 5.15422926e-06
Iter: 141 loss: 5.15417878e-06
Iter: 142 loss: 5.1122588e-06
Iter: 143 loss: 5.03760839e-06
Iter: 144 loss: 6.90067463e-06
Iter: 145 loss: 5.03762385e-06
Iter: 146 loss: 4.98733925e-06
Iter: 147 loss: 4.98699228e-06
Iter: 148 loss: 4.95216864e-06
Iter: 149 loss: 5.23256267e-06
Iter: 150 loss: 4.94974665e-06
Iter: 151 loss: 4.90884349e-06
Iter: 152 loss: 4.88498881e-06
Iter: 153 loss: 4.86752151e-06
Iter: 154 loss: 4.84467364e-06
Iter: 155 loss: 4.84425163e-06
Iter: 156 loss: 4.82044425e-06
Iter: 157 loss: 4.80176823e-06
Iter: 158 loss: 4.79444452e-06
Iter: 159 loss: 4.76556716e-06
Iter: 160 loss: 4.8203774e-06
Iter: 161 loss: 4.75321485e-06
Iter: 162 loss: 4.72725969e-06
Iter: 163 loss: 4.69904353e-06
Iter: 164 loss: 4.69440693e-06
Iter: 165 loss: 4.65656467e-06
Iter: 166 loss: 4.65657e-06
Iter: 167 loss: 4.6437217e-06
Iter: 168 loss: 4.64358618e-06
Iter: 169 loss: 4.62709613e-06
Iter: 170 loss: 4.5995057e-06
Iter: 171 loss: 4.59941475e-06
Iter: 172 loss: 4.57171836e-06
Iter: 173 loss: 4.61544914e-06
Iter: 174 loss: 4.55889858e-06
Iter: 175 loss: 4.53290068e-06
Iter: 176 loss: 4.52917357e-06
Iter: 177 loss: 4.51117648e-06
Iter: 178 loss: 4.48257242e-06
Iter: 179 loss: 4.75741308e-06
Iter: 180 loss: 4.48165429e-06
Iter: 181 loss: 4.46236299e-06
Iter: 182 loss: 4.72490956e-06
Iter: 183 loss: 4.46225113e-06
Iter: 184 loss: 4.44714624e-06
Iter: 185 loss: 4.4348626e-06
Iter: 186 loss: 4.43047884e-06
Iter: 187 loss: 4.41875181e-06
Iter: 188 loss: 4.41854081e-06
Iter: 189 loss: 4.40595613e-06
Iter: 190 loss: 4.37516337e-06
Iter: 191 loss: 4.6836808e-06
Iter: 192 loss: 4.37134804e-06
Iter: 193 loss: 4.34228832e-06
Iter: 194 loss: 4.53124085e-06
Iter: 195 loss: 4.33930472e-06
Iter: 196 loss: 4.321284e-06
Iter: 197 loss: 4.30175e-06
Iter: 198 loss: 4.2986876e-06
Iter: 199 loss: 4.28447311e-06
Iter: 200 loss: 4.28116e-06
Iter: 201 loss: 4.27176292e-06
Iter: 202 loss: 4.27166378e-06
Iter: 203 loss: 4.26375e-06
Iter: 204 loss: 4.24000518e-06
Iter: 205 loss: 4.31989247e-06
Iter: 206 loss: 4.2290153e-06
Iter: 207 loss: 4.20736251e-06
Iter: 208 loss: 4.50058542e-06
Iter: 209 loss: 4.20720062e-06
Iter: 210 loss: 4.19226944e-06
Iter: 211 loss: 4.17036199e-06
Iter: 212 loss: 4.16981175e-06
Iter: 213 loss: 4.16882813e-06
Iter: 214 loss: 4.16007879e-06
Iter: 215 loss: 4.15110571e-06
Iter: 216 loss: 4.14111673e-06
Iter: 217 loss: 4.13982207e-06
Iter: 218 loss: 4.12238e-06
Iter: 219 loss: 4.11572955e-06
Iter: 220 loss: 4.10616758e-06
Iter: 221 loss: 4.10456323e-06
Iter: 222 loss: 4.09861968e-06
Iter: 223 loss: 4.09025142e-06
Iter: 224 loss: 4.07103744e-06
Iter: 225 loss: 4.32311936e-06
Iter: 226 loss: 4.06966547e-06
Iter: 227 loss: 4.05100764e-06
Iter: 228 loss: 4.12143709e-06
Iter: 229 loss: 4.04645471e-06
Iter: 230 loss: 4.03240529e-06
Iter: 231 loss: 4.02316437e-06
Iter: 232 loss: 4.01783655e-06
Iter: 233 loss: 3.99859709e-06
Iter: 234 loss: 4.23545589e-06
Iter: 235 loss: 3.99833607e-06
Iter: 236 loss: 3.99461e-06
Iter: 237 loss: 3.99136661e-06
Iter: 238 loss: 3.98635166e-06
Iter: 239 loss: 3.97167514e-06
Iter: 240 loss: 4.03210106e-06
Iter: 241 loss: 3.96601899e-06
Iter: 242 loss: 3.9497645e-06
Iter: 243 loss: 3.98507655e-06
Iter: 244 loss: 3.943499e-06
Iter: 245 loss: 3.9261e-06
Iter: 246 loss: 4.02287151e-06
Iter: 247 loss: 3.92365791e-06
Iter: 248 loss: 3.91280719e-06
Iter: 249 loss: 4.00025056e-06
Iter: 250 loss: 3.91203912e-06
Iter: 251 loss: 3.89850811e-06
Iter: 252 loss: 3.90624155e-06
Iter: 253 loss: 3.88954868e-06
Iter: 254 loss: 3.87834189e-06
Iter: 255 loss: 3.90542482e-06
Iter: 256 loss: 3.8745643e-06
Iter: 257 loss: 3.86594365e-06
Iter: 258 loss: 3.9373e-06
Iter: 259 loss: 3.86547435e-06
Iter: 260 loss: 3.85510248e-06
Iter: 261 loss: 3.85428575e-06
Iter: 262 loss: 3.84673467e-06
Iter: 263 loss: 3.83748e-06
Iter: 264 loss: 3.86524289e-06
Iter: 265 loss: 3.83476345e-06
Iter: 266 loss: 3.82602775e-06
Iter: 267 loss: 3.80867914e-06
Iter: 268 loss: 4.12957e-06
Iter: 269 loss: 3.80842698e-06
Iter: 270 loss: 3.79635321e-06
Iter: 271 loss: 3.79596986e-06
Iter: 272 loss: 3.78740015e-06
Iter: 273 loss: 3.81760765e-06
Iter: 274 loss: 3.7851521e-06
Iter: 275 loss: 3.77231186e-06
Iter: 276 loss: 3.81298787e-06
Iter: 277 loss: 3.76877915e-06
Iter: 278 loss: 3.76430307e-06
Iter: 279 loss: 3.75719605e-06
Iter: 280 loss: 3.75706804e-06
Iter: 281 loss: 3.74550245e-06
Iter: 282 loss: 3.73119542e-06
Iter: 283 loss: 3.72989507e-06
Iter: 284 loss: 3.72343561e-06
Iter: 285 loss: 3.7209843e-06
Iter: 286 loss: 3.71228521e-06
Iter: 287 loss: 3.74019896e-06
Iter: 288 loss: 3.70956514e-06
Iter: 289 loss: 3.70151656e-06
Iter: 290 loss: 3.6968454e-06
Iter: 291 loss: 3.69340569e-06
Iter: 292 loss: 3.68933252e-06
Iter: 293 loss: 3.68875226e-06
Iter: 294 loss: 3.68368478e-06
Iter: 295 loss: 3.67331882e-06
Iter: 296 loss: 3.86796819e-06
Iter: 297 loss: 3.67320877e-06
Iter: 298 loss: 3.66459949e-06
Iter: 299 loss: 3.70636553e-06
Iter: 300 loss: 3.66296399e-06
Iter: 301 loss: 3.65570941e-06
Iter: 302 loss: 3.64374159e-06
Iter: 303 loss: 3.64369089e-06
Iter: 304 loss: 3.63501158e-06
Iter: 305 loss: 3.63441768e-06
Iter: 306 loss: 3.63055142e-06
Iter: 307 loss: 3.63039862e-06
Iter: 308 loss: 3.62584183e-06
Iter: 309 loss: 3.61537104e-06
Iter: 310 loss: 3.74393858e-06
Iter: 311 loss: 3.61455341e-06
Iter: 312 loss: 3.60606737e-06
Iter: 313 loss: 3.65739334e-06
Iter: 314 loss: 3.60492277e-06
Iter: 315 loss: 3.59880141e-06
Iter: 316 loss: 3.59002888e-06
Iter: 317 loss: 3.58966236e-06
Iter: 318 loss: 3.57922158e-06
Iter: 319 loss: 3.68530846e-06
Iter: 320 loss: 3.57886574e-06
Iter: 321 loss: 3.57261183e-06
Iter: 322 loss: 3.64521111e-06
Iter: 323 loss: 3.57244244e-06
Iter: 324 loss: 3.56563851e-06
Iter: 325 loss: 3.5653793e-06
Iter: 326 loss: 3.55999691e-06
Iter: 327 loss: 3.55389e-06
Iter: 328 loss: 3.58089619e-06
Iter: 329 loss: 3.55267639e-06
Iter: 330 loss: 3.545666e-06
Iter: 331 loss: 3.57333329e-06
Iter: 332 loss: 3.5440064e-06
Iter: 333 loss: 3.53913924e-06
Iter: 334 loss: 3.53268206e-06
Iter: 335 loss: 3.53230917e-06
Iter: 336 loss: 3.52433358e-06
Iter: 337 loss: 3.52633106e-06
Iter: 338 loss: 3.51850917e-06
Iter: 339 loss: 3.50982464e-06
Iter: 340 loss: 3.61864e-06
Iter: 341 loss: 3.50978e-06
Iter: 342 loss: 3.50789742e-06
Iter: 343 loss: 3.50699293e-06
Iter: 344 loss: 3.50395248e-06
Iter: 345 loss: 3.49581933e-06
Iter: 346 loss: 3.55324642e-06
Iter: 347 loss: 3.49410766e-06
Iter: 348 loss: 3.48757794e-06
Iter: 349 loss: 3.50849041e-06
Iter: 350 loss: 3.48580215e-06
Iter: 351 loss: 3.47845366e-06
Iter: 352 loss: 3.48219373e-06
Iter: 353 loss: 3.4736936e-06
Iter: 354 loss: 3.46764091e-06
Iter: 355 loss: 3.51602375e-06
Iter: 356 loss: 3.46714251e-06
Iter: 357 loss: 3.46129377e-06
Iter: 358 loss: 3.50821779e-06
Iter: 359 loss: 3.46097613e-06
Iter: 360 loss: 3.45510057e-06
Iter: 361 loss: 3.45399485e-06
Iter: 362 loss: 3.45006424e-06
Iter: 363 loss: 3.44704586e-06
Iter: 364 loss: 3.44695263e-06
Iter: 365 loss: 3.44391083e-06
Iter: 366 loss: 3.43758757e-06
Iter: 367 loss: 3.54387157e-06
Iter: 368 loss: 3.43737202e-06
Iter: 369 loss: 3.43043803e-06
Iter: 370 loss: 3.45915782e-06
Iter: 371 loss: 3.42881185e-06
Iter: 372 loss: 3.42426802e-06
Iter: 373 loss: 3.43022771e-06
Iter: 374 loss: 3.42180283e-06
Iter: 375 loss: 3.41515897e-06
Iter: 376 loss: 3.4201712e-06
Iter: 377 loss: 3.41088958e-06
Iter: 378 loss: 3.41393979e-06
Iter: 379 loss: 3.40792872e-06
Iter: 380 loss: 3.40630027e-06
Iter: 381 loss: 3.4018733e-06
Iter: 382 loss: 3.42327212e-06
Iter: 383 loss: 3.4002519e-06
Iter: 384 loss: 3.39324333e-06
Iter: 385 loss: 3.401909e-06
Iter: 386 loss: 3.38972291e-06
Iter: 387 loss: 3.38304562e-06
Iter: 388 loss: 3.38839345e-06
Iter: 389 loss: 3.3791448e-06
Iter: 390 loss: 3.37152142e-06
Iter: 391 loss: 3.43827378e-06
Iter: 392 loss: 3.37113647e-06
Iter: 393 loss: 3.36677977e-06
Iter: 394 loss: 3.41172267e-06
Iter: 395 loss: 3.36670246e-06
Iter: 396 loss: 3.36159269e-06
Iter: 397 loss: 3.36438666e-06
Iter: 398 loss: 3.35819686e-06
Iter: 399 loss: 3.35413097e-06
Iter: 400 loss: 3.36382618e-06
Iter: 401 loss: 3.35279401e-06
Iter: 402 loss: 3.34791321e-06
Iter: 403 loss: 3.37474376e-06
Iter: 404 loss: 3.34721653e-06
Iter: 405 loss: 3.34358788e-06
Iter: 406 loss: 3.33964363e-06
Iter: 407 loss: 3.33911908e-06
Iter: 408 loss: 3.333927e-06
Iter: 409 loss: 3.3349736e-06
Iter: 410 loss: 3.3301535e-06
Iter: 411 loss: 3.32462059e-06
Iter: 412 loss: 3.40561155e-06
Iter: 413 loss: 3.32463287e-06
Iter: 414 loss: 3.32273657e-06
Iter: 415 loss: 3.32246464e-06
Iter: 416 loss: 3.32048558e-06
Iter: 417 loss: 3.31528145e-06
Iter: 418 loss: 3.35448544e-06
Iter: 419 loss: 3.31422757e-06
Iter: 420 loss: 3.30783678e-06
Iter: 421 loss: 3.32751279e-06
Iter: 422 loss: 3.30602688e-06
Iter: 423 loss: 3.30170087e-06
Iter: 424 loss: 3.3011188e-06
Iter: 425 loss: 3.29795421e-06
Iter: 426 loss: 3.29068052e-06
Iter: 427 loss: 3.32582817e-06
Iter: 428 loss: 3.28947158e-06
Iter: 429 loss: 3.28449119e-06
Iter: 430 loss: 3.28806823e-06
Iter: 431 loss: 3.28147826e-06
Iter: 432 loss: 3.27849716e-06
Iter: 433 loss: 3.27789394e-06
Iter: 434 loss: 3.27503176e-06
Iter: 435 loss: 3.28287251e-06
Iter: 436 loss: 3.27414909e-06
Iter: 437 loss: 3.27177167e-06
Iter: 438 loss: 3.27139151e-06
Iter: 439 loss: 3.26975987e-06
Iter: 440 loss: 3.26466511e-06
Iter: 441 loss: 3.27948646e-06
Iter: 442 loss: 3.26313966e-06
Iter: 443 loss: 3.26067857e-06
Iter: 444 loss: 3.25940687e-06
Iter: 445 loss: 3.25819042e-06
Iter: 446 loss: 3.25419296e-06
Iter: 447 loss: 3.2664334e-06
Iter: 448 loss: 3.25303381e-06
Iter: 449 loss: 3.24840266e-06
Iter: 450 loss: 3.29821273e-06
Iter: 451 loss: 3.24827124e-06
Iter: 452 loss: 3.24692905e-06
Iter: 453 loss: 3.24338771e-06
Iter: 454 loss: 3.27249791e-06
Iter: 455 loss: 3.24279517e-06
Iter: 456 loss: 3.23715972e-06
Iter: 457 loss: 3.2442772e-06
Iter: 458 loss: 3.23426912e-06
Iter: 459 loss: 3.22925121e-06
Iter: 460 loss: 3.26554482e-06
Iter: 461 loss: 3.22863775e-06
Iter: 462 loss: 3.22464e-06
Iter: 463 loss: 3.22618416e-06
Iter: 464 loss: 3.22173219e-06
Iter: 465 loss: 3.21679636e-06
Iter: 466 loss: 3.22785377e-06
Iter: 467 loss: 3.21474909e-06
Iter: 468 loss: 3.21122911e-06
Iter: 469 loss: 3.21113112e-06
Iter: 470 loss: 3.20798108e-06
Iter: 471 loss: 3.2125015e-06
Iter: 472 loss: 3.206467e-06
Iter: 473 loss: 3.20425147e-06
Iter: 474 loss: 3.20751e-06
Iter: 475 loss: 3.20321669e-06
Iter: 476 loss: 3.1994864e-06
Iter: 477 loss: 3.20783442e-06
Iter: 478 loss: 3.19808123e-06
Iter: 479 loss: 3.19575656e-06
Iter: 480 loss: 3.19664809e-06
Iter: 481 loss: 3.19411674e-06
Iter: 482 loss: 3.19229503e-06
Iter: 483 loss: 3.19210858e-06
Iter: 484 loss: 3.19031483e-06
Iter: 485 loss: 3.18553748e-06
Iter: 486 loss: 3.22293454e-06
Iter: 487 loss: 3.18464026e-06
Iter: 488 loss: 3.18108459e-06
Iter: 489 loss: 3.18788352e-06
Iter: 490 loss: 3.17957506e-06
Iter: 491 loss: 3.17448985e-06
Iter: 492 loss: 3.18329512e-06
Iter: 493 loss: 3.17229205e-06
Iter: 494 loss: 3.16884052e-06
Iter: 495 loss: 3.19223091e-06
Iter: 496 loss: 3.16840669e-06
Iter: 497 loss: 3.1648558e-06
Iter: 498 loss: 3.15927628e-06
Iter: 499 loss: 3.15921079e-06
Iter: 500 loss: 3.15764714e-06
Iter: 501 loss: 3.15647685e-06
Iter: 502 loss: 3.15425632e-06
Iter: 503 loss: 3.15677016e-06
Iter: 504 loss: 3.15310035e-06
Iter: 505 loss: 3.15023772e-06
Iter: 506 loss: 3.14879298e-06
Iter: 507 loss: 3.14750264e-06
Iter: 508 loss: 3.14638828e-06
Iter: 509 loss: 3.1457148e-06
Iter: 510 loss: 3.14450517e-06
Iter: 511 loss: 3.1418258e-06
Iter: 512 loss: 3.18396587e-06
Iter: 513 loss: 3.14168483e-06
Iter: 514 loss: 3.13894316e-06
Iter: 515 loss: 3.17579179e-06
Iter: 516 loss: 3.13892178e-06
Iter: 517 loss: 3.13621194e-06
Iter: 518 loss: 3.14041381e-06
Iter: 519 loss: 3.13483861e-06
Iter: 520 loss: 3.13333157e-06
Iter: 521 loss: 3.12937e-06
Iter: 522 loss: 3.15593343e-06
Iter: 523 loss: 3.12836755e-06
Iter: 524 loss: 3.12462043e-06
Iter: 525 loss: 3.12456632e-06
Iter: 526 loss: 3.12209227e-06
Iter: 527 loss: 3.12096017e-06
Iter: 528 loss: 3.11966414e-06
Iter: 529 loss: 3.11569397e-06
Iter: 530 loss: 3.13566466e-06
Iter: 531 loss: 3.11492613e-06
Iter: 532 loss: 3.11212807e-06
Iter: 533 loss: 3.11879126e-06
Iter: 534 loss: 3.11106396e-06
Iter: 535 loss: 3.10833639e-06
Iter: 536 loss: 3.10828773e-06
Iter: 537 loss: 3.10601081e-06
Iter: 538 loss: 3.10555924e-06
Iter: 539 loss: 3.10400378e-06
Iter: 540 loss: 3.10228779e-06
Iter: 541 loss: 3.12062548e-06
Iter: 542 loss: 3.10233918e-06
Iter: 543 loss: 3.10045152e-06
Iter: 544 loss: 3.09824691e-06
Iter: 545 loss: 3.09796064e-06
Iter: 546 loss: 3.09599091e-06
Iter: 547 loss: 3.09593884e-06
Iter: 548 loss: 3.09430061e-06
Iter: 549 loss: 3.10324822e-06
Iter: 550 loss: 3.09398115e-06
Iter: 551 loss: 3.09299844e-06
Iter: 552 loss: 3.09025427e-06
Iter: 553 loss: 3.10260521e-06
Iter: 554 loss: 3.0893143e-06
Iter: 555 loss: 3.08560766e-06
Iter: 556 loss: 3.10723635e-06
Iter: 557 loss: 3.08522931e-06
Iter: 558 loss: 3.08169137e-06
Iter: 559 loss: 3.08798235e-06
Iter: 560 loss: 3.08012977e-06
Iter: 561 loss: 3.07686901e-06
Iter: 562 loss: 3.09694042e-06
Iter: 563 loss: 3.07642813e-06
Iter: 564 loss: 3.07342088e-06
Iter: 565 loss: 3.07127243e-06
Iter: 566 loss: 3.0702256e-06
Iter: 567 loss: 3.06941047e-06
Iter: 568 loss: 3.06838547e-06
Iter: 569 loss: 3.06662332e-06
Iter: 570 loss: 3.06647689e-06
Iter: 571 loss: 3.06513243e-06
Iter: 572 loss: 3.06286438e-06
Iter: 573 loss: 3.06819106e-06
Iter: 574 loss: 3.06206084e-06
Iter: 575 loss: 3.06012203e-06
Iter: 576 loss: 3.08235803e-06
Iter: 577 loss: 3.06002812e-06
Iter: 578 loss: 3.05895469e-06
Iter: 579 loss: 3.05770391e-06
Iter: 580 loss: 3.05751314e-06
Iter: 581 loss: 3.05530239e-06
Iter: 582 loss: 3.07019036e-06
Iter: 583 loss: 3.05501453e-06
Iter: 584 loss: 3.05363574e-06
Iter: 585 loss: 3.05134859e-06
Iter: 586 loss: 3.05131425e-06
Iter: 587 loss: 3.04883315e-06
Iter: 588 loss: 3.04676382e-06
Iter: 589 loss: 3.04612058e-06
Iter: 590 loss: 3.04250443e-06
Iter: 591 loss: 3.07959954e-06
Iter: 592 loss: 3.04247169e-06
Iter: 593 loss: 3.04009927e-06
Iter: 594 loss: 3.04009177e-06
Iter: 595 loss: 3.03823299e-06
Iter: 596 loss: 3.03469142e-06
Iter: 597 loss: 3.06183756e-06
Iter: 598 loss: 3.03439651e-06
Iter: 599 loss: 3.03214529e-06
Iter: 600 loss: 3.0328863e-06
Iter: 601 loss: 3.03053139e-06
Iter: 602 loss: 3.0269498e-06
Iter: 603 loss: 3.06456468e-06
Iter: 604 loss: 3.02684907e-06
Iter: 605 loss: 3.02521e-06
Iter: 606 loss: 3.02425974e-06
Iter: 607 loss: 3.02365106e-06
Iter: 608 loss: 3.02169519e-06
Iter: 609 loss: 3.05016215e-06
Iter: 610 loss: 3.02169474e-06
Iter: 611 loss: 3.02004355e-06
Iter: 612 loss: 3.01946966e-06
Iter: 613 loss: 3.01845125e-06
Iter: 614 loss: 3.01662294e-06
Iter: 615 loss: 3.0438855e-06
Iter: 616 loss: 3.01657337e-06
Iter: 617 loss: 3.01557816e-06
Iter: 618 loss: 3.01317232e-06
Iter: 619 loss: 3.0500878e-06
Iter: 620 loss: 3.01311502e-06
Iter: 621 loss: 3.01005343e-06
Iter: 622 loss: 3.00834381e-06
Iter: 623 loss: 3.00701458e-06
Iter: 624 loss: 3.00355305e-06
Iter: 625 loss: 3.01833552e-06
Iter: 626 loss: 3.00288593e-06
Iter: 627 loss: 2.99923977e-06
Iter: 628 loss: 3.00266811e-06
Iter: 629 loss: 2.99709222e-06
Iter: 630 loss: 2.99420458e-06
Iter: 631 loss: 3.02596368e-06
Iter: 632 loss: 2.99420708e-06
Iter: 633 loss: 2.9918e-06
Iter: 634 loss: 2.99247381e-06
Iter: 635 loss: 2.98998611e-06
Iter: 636 loss: 2.98839e-06
Iter: 637 loss: 2.98801706e-06
Iter: 638 loss: 2.98676878e-06
Iter: 639 loss: 2.98566601e-06
Iter: 640 loss: 2.98505529e-06
Iter: 641 loss: 2.98336317e-06
Iter: 642 loss: 2.98816212e-06
Iter: 643 loss: 2.98258828e-06
Iter: 644 loss: 2.98071404e-06
Iter: 645 loss: 3.00717738e-06
Iter: 646 loss: 2.98067926e-06
Iter: 647 loss: 2.97974407e-06
Iter: 648 loss: 2.98219447e-06
Iter: 649 loss: 2.97946735e-06
Iter: 650 loss: 2.97820065e-06
Iter: 651 loss: 2.97603333e-06
Iter: 652 loss: 3.0297706e-06
Iter: 653 loss: 2.97601764e-06
Iter: 654 loss: 2.97369934e-06
Iter: 655 loss: 2.97966471e-06
Iter: 656 loss: 2.97296151e-06
Iter: 657 loss: 2.97095221e-06
Iter: 658 loss: 2.96991152e-06
Iter: 659 loss: 2.96883559e-06
Iter: 660 loss: 2.96526309e-06
Iter: 661 loss: 2.98101304e-06
Iter: 662 loss: 2.96444227e-06
Iter: 663 loss: 2.9615976e-06
Iter: 664 loss: 2.96669896e-06
Iter: 665 loss: 2.96024837e-06
Iter: 666 loss: 2.95690825e-06
Iter: 667 loss: 2.97226256e-06
Iter: 668 loss: 2.95616746e-06
Iter: 669 loss: 2.95437803e-06
Iter: 670 loss: 2.954401e-06
Iter: 671 loss: 2.95262726e-06
Iter: 672 loss: 2.95224754e-06
Iter: 673 loss: 2.95113023e-06
Iter: 674 loss: 2.94926031e-06
Iter: 675 loss: 2.95443829e-06
Iter: 676 loss: 2.94867277e-06
Iter: 677 loss: 2.94735901e-06
Iter: 678 loss: 2.94730171e-06
Iter: 679 loss: 2.94619804e-06
Iter: 680 loss: 2.94619576e-06
Iter: 681 loss: 2.94550091e-06
Iter: 682 loss: 2.94358642e-06
Iter: 683 loss: 2.94415577e-06
Iter: 684 loss: 2.942229e-06
Iter: 685 loss: 2.94045481e-06
Iter: 686 loss: 2.94009851e-06
Iter: 687 loss: 2.93894368e-06
Iter: 688 loss: 2.93623589e-06
Iter: 689 loss: 2.93637459e-06
Iter: 690 loss: 2.93419339e-06
Iter: 691 loss: 2.93128232e-06
Iter: 692 loss: 2.96139456e-06
Iter: 693 loss: 2.93122639e-06
Iter: 694 loss: 2.92916229e-06
Iter: 695 loss: 2.92841582e-06
Iter: 696 loss: 2.92715026e-06
Iter: 697 loss: 2.92451e-06
Iter: 698 loss: 2.94606298e-06
Iter: 699 loss: 2.92428763e-06
Iter: 700 loss: 2.9222806e-06
Iter: 701 loss: 2.93247558e-06
Iter: 702 loss: 2.92197728e-06
Iter: 703 loss: 2.91945116e-06
Iter: 704 loss: 2.9304374e-06
Iter: 705 loss: 2.91907031e-06
Iter: 706 loss: 2.91763308e-06
Iter: 707 loss: 2.91715241e-06
Iter: 708 loss: 2.91637843e-06
Iter: 709 loss: 2.91493734e-06
Iter: 710 loss: 2.91490119e-06
Iter: 711 loss: 2.91369747e-06
Iter: 712 loss: 2.91410538e-06
Iter: 713 loss: 2.91263905e-06
Iter: 714 loss: 2.91097467e-06
Iter: 715 loss: 2.91792549e-06
Iter: 716 loss: 2.91055585e-06
Iter: 717 loss: 2.90932894e-06
Iter: 718 loss: 2.90715957e-06
Iter: 719 loss: 2.95155132e-06
Iter: 720 loss: 2.90720982e-06
Iter: 721 loss: 2.90436947e-06
Iter: 722 loss: 2.90829598e-06
Iter: 723 loss: 2.90298158e-06
Iter: 724 loss: 2.90022012e-06
Iter: 725 loss: 2.91378183e-06
Iter: 726 loss: 2.89970535e-06
Iter: 727 loss: 2.89690342e-06
Iter: 728 loss: 2.89998616e-06
Iter: 729 loss: 2.89536092e-06
Iter: 730 loss: 2.89275613e-06
Iter: 731 loss: 2.90570142e-06
Iter: 732 loss: 2.89239142e-06
Iter: 733 loss: 2.88982028e-06
Iter: 734 loss: 2.89726631e-06
Iter: 735 loss: 2.88898013e-06
Iter: 736 loss: 2.88708407e-06
Iter: 737 loss: 2.88707179e-06
Iter: 738 loss: 2.88620481e-06
Iter: 739 loss: 2.88456431e-06
Iter: 740 loss: 2.92234108e-06
Iter: 741 loss: 2.88461729e-06
Iter: 742 loss: 2.88300612e-06
Iter: 743 loss: 2.90245725e-06
Iter: 744 loss: 2.8828922e-06
Iter: 745 loss: 2.88130445e-06
Iter: 746 loss: 2.8839595e-06
Iter: 747 loss: 2.88061324e-06
Iter: 748 loss: 2.87920807e-06
Iter: 749 loss: 2.88570118e-06
Iter: 750 loss: 2.8790007e-06
Iter: 751 loss: 2.87789885e-06
Iter: 752 loss: 2.87590296e-06
Iter: 753 loss: 2.8759e-06
Iter: 754 loss: 2.87369721e-06
Iter: 755 loss: 2.87805824e-06
Iter: 756 loss: 2.87271519e-06
Iter: 757 loss: 2.8706113e-06
Iter: 758 loss: 2.8751756e-06
Iter: 759 loss: 2.86982913e-06
Iter: 760 loss: 2.86744807e-06
Iter: 761 loss: 2.87523312e-06
Iter: 762 loss: 2.86675481e-06
Iter: 763 loss: 2.86455816e-06
Iter: 764 loss: 2.86908198e-06
Iter: 765 loss: 2.86366139e-06
Iter: 766 loss: 2.86087356e-06
Iter: 767 loss: 2.86915088e-06
Iter: 768 loss: 2.86001659e-06
Iter: 769 loss: 2.85921783e-06
Iter: 770 loss: 2.85872056e-06
Iter: 771 loss: 2.85795818e-06
Iter: 772 loss: 2.85616215e-06
Iter: 773 loss: 2.88051206e-06
Iter: 774 loss: 2.85614351e-06
Iter: 775 loss: 2.85483316e-06
Iter: 776 loss: 2.85479859e-06
Iter: 777 loss: 2.85349324e-06
Iter: 778 loss: 2.85829765e-06
Iter: 779 loss: 2.85324381e-06
Iter: 780 loss: 2.85247688e-06
Iter: 781 loss: 2.85399597e-06
Iter: 782 loss: 2.85207352e-06
Iter: 783 loss: 2.85114265e-06
Iter: 784 loss: 2.84964153e-06
Iter: 785 loss: 2.84956855e-06
Iter: 786 loss: 2.84774273e-06
Iter: 787 loss: 2.85101896e-06
Iter: 788 loss: 2.84690304e-06
Iter: 789 loss: 2.84465159e-06
Iter: 790 loss: 2.84643693e-06
Iter: 791 loss: 2.84347539e-06
Iter: 792 loss: 2.8410177e-06
Iter: 793 loss: 2.85598435e-06
Iter: 794 loss: 2.84066573e-06
Iter: 795 loss: 2.83844747e-06
Iter: 796 loss: 2.84096586e-06
Iter: 797 loss: 2.83733152e-06
Iter: 798 loss: 2.83502413e-06
Iter: 799 loss: 2.85183455e-06
Iter: 800 loss: 2.83482495e-06
Iter: 801 loss: 2.83383019e-06
Iter: 802 loss: 2.83384134e-06
Iter: 803 loss: 2.83283543e-06
Iter: 804 loss: 2.83096961e-06
Iter: 805 loss: 2.87175317e-06
Iter: 806 loss: 2.83102054e-06
Iter: 807 loss: 2.82960059e-06
Iter: 808 loss: 2.82959e-06
Iter: 809 loss: 2.82843439e-06
Iter: 810 loss: 2.83538725e-06
Iter: 811 loss: 2.82828546e-06
Iter: 812 loss: 2.82756037e-06
Iter: 813 loss: 2.8275615e-06
Iter: 814 loss: 2.82688666e-06
Iter: 815 loss: 2.82554925e-06
Iter: 816 loss: 2.82546739e-06
Iter: 817 loss: 2.82446126e-06
Iter: 818 loss: 2.82306564e-06
Iter: 819 loss: 2.82390033e-06
Iter: 820 loss: 2.82229371e-06
Iter: 821 loss: 2.82055362e-06
Iter: 822 loss: 2.82151541e-06
Iter: 823 loss: 2.81943539e-06
Iter: 824 loss: 2.81741745e-06
Iter: 825 loss: 2.82646306e-06
Iter: 826 loss: 2.81708117e-06
Iter: 827 loss: 2.81489656e-06
Iter: 828 loss: 2.81708981e-06
Iter: 829 loss: 2.8136983e-06
Iter: 830 loss: 2.81142638e-06
Iter: 831 loss: 2.83191298e-06
Iter: 832 loss: 2.81142911e-06
Iter: 833 loss: 2.81012422e-06
Iter: 834 loss: 2.82128485e-06
Iter: 835 loss: 2.81008806e-06
Iter: 836 loss: 2.80859376e-06
Iter: 837 loss: 2.80787458e-06
Iter: 838 loss: 2.80714903e-06
Iter: 839 loss: 2.80593622e-06
Iter: 840 loss: 2.81523148e-06
Iter: 841 loss: 2.80585346e-06
Iter: 842 loss: 2.8046943e-06
Iter: 843 loss: 2.81318398e-06
Iter: 844 loss: 2.80460813e-06
Iter: 845 loss: 2.80387462e-06
Iter: 846 loss: 2.8036452e-06
Iter: 847 loss: 2.80314362e-06
Iter: 848 loss: 2.80195604e-06
Iter: 849 loss: 2.80436302e-06
Iter: 850 loss: 2.80145e-06
Iter: 851 loss: 2.80046879e-06
Iter: 852 loss: 2.79894311e-06
Iter: 853 loss: 2.79895312e-06
Iter: 854 loss: 2.79665232e-06
Iter: 855 loss: 2.8030147e-06
Iter: 856 loss: 2.79589585e-06
Iter: 857 loss: 2.79407777e-06
Iter: 858 loss: 2.80026529e-06
Iter: 859 loss: 2.79349024e-06
Iter: 860 loss: 2.79130586e-06
Iter: 861 loss: 2.79501296e-06
Iter: 862 loss: 2.7903402e-06
Iter: 863 loss: 2.78845187e-06
Iter: 864 loss: 2.80527729e-06
Iter: 865 loss: 2.78837365e-06
Iter: 866 loss: 2.7870035e-06
Iter: 867 loss: 2.79265851e-06
Iter: 868 loss: 2.78668495e-06
Iter: 869 loss: 2.78483822e-06
Iter: 870 loss: 2.78884545e-06
Iter: 871 loss: 2.78412199e-06
Iter: 872 loss: 2.78309562e-06
Iter: 873 loss: 2.78479843e-06
Iter: 874 loss: 2.78258085e-06
Iter: 875 loss: 2.78147218e-06
Iter: 876 loss: 2.78149309e-06
Iter: 877 loss: 2.78077187e-06
Iter: 878 loss: 2.78023526e-06
Iter: 879 loss: 2.7800213e-06
Iter: 880 loss: 2.77888466e-06
Iter: 881 loss: 2.78303264e-06
Iter: 882 loss: 2.77866116e-06
Iter: 883 loss: 2.77775416e-06
Iter: 884 loss: 2.77595586e-06
Iter: 885 loss: 2.8088964e-06
Iter: 886 loss: 2.77593563e-06
Iter: 887 loss: 2.7737965e-06
Iter: 888 loss: 2.78651441e-06
Iter: 889 loss: 2.77348681e-06
Iter: 890 loss: 2.77195045e-06
Iter: 891 loss: 2.77260688e-06
Iter: 892 loss: 2.77087111e-06
Iter: 893 loss: 2.76858873e-06
Iter: 894 loss: 2.779434e-06
Iter: 895 loss: 2.76824244e-06
Iter: 896 loss: 2.76661831e-06
Iter: 897 loss: 2.77903655e-06
Iter: 898 loss: 2.76655601e-06
Iter: 899 loss: 2.76524634e-06
Iter: 900 loss: 2.76930086e-06
Iter: 901 loss: 2.76493483e-06
Iter: 902 loss: 2.76346555e-06
Iter: 903 loss: 2.77163781e-06
Iter: 904 loss: 2.76321589e-06
Iter: 905 loss: 2.76246442e-06
Iter: 906 loss: 2.76176024e-06
Iter: 907 loss: 2.76158698e-06
Iter: 908 loss: 2.76068386e-06
Iter: 909 loss: 2.76063224e-06
Iter: 910 loss: 2.75997922e-06
Iter: 911 loss: 2.75946513e-06
Iter: 912 loss: 2.75922e-06
Iter: 913 loss: 2.75812909e-06
Iter: 914 loss: 2.76117544e-06
Iter: 915 loss: 2.75780303e-06
Iter: 916 loss: 2.75679304e-06
Iter: 917 loss: 2.75481443e-06
Iter: 918 loss: 2.79250662e-06
Iter: 919 loss: 2.75470029e-06
Iter: 920 loss: 2.7526205e-06
Iter: 921 loss: 2.77010759e-06
Iter: 922 loss: 2.75246157e-06
Iter: 923 loss: 2.75104412e-06
Iter: 924 loss: 2.7521387e-06
Iter: 925 loss: 2.7502067e-06
Iter: 926 loss: 2.74847662e-06
Iter: 927 loss: 2.75588627e-06
Iter: 928 loss: 2.74803051e-06
Iter: 929 loss: 2.74663353e-06
Iter: 930 loss: 2.75363436e-06
Iter: 931 loss: 2.74636204e-06
Iter: 932 loss: 2.74481636e-06
Iter: 933 loss: 2.75033085e-06
Iter: 934 loss: 2.74439299e-06
Iter: 935 loss: 2.74300737e-06
Iter: 936 loss: 2.75739808e-06
Iter: 937 loss: 2.74300191e-06
Iter: 938 loss: 2.74224112e-06
Iter: 939 loss: 2.74077229e-06
Iter: 940 loss: 2.76926176e-06
Iter: 941 loss: 2.74073136e-06
Iter: 942 loss: 2.74038462e-06
Iter: 943 loss: 2.73970159e-06
Iter: 944 loss: 2.73912838e-06
Iter: 945 loss: 2.73884484e-06
Iter: 946 loss: 2.73837054e-06
Iter: 947 loss: 2.73762771e-06
Iter: 948 loss: 2.73945193e-06
Iter: 949 loss: 2.73734759e-06
Iter: 950 loss: 2.73642399e-06
Iter: 951 loss: 2.73456794e-06
Iter: 952 loss: 2.76457513e-06
Iter: 953 loss: 2.73451e-06
Iter: 954 loss: 2.7327842e-06
Iter: 955 loss: 2.74862919e-06
Iter: 956 loss: 2.73267392e-06
Iter: 957 loss: 2.73117212e-06
Iter: 958 loss: 2.73265914e-06
Iter: 959 loss: 2.73037267e-06
Iter: 960 loss: 2.72867965e-06
Iter: 961 loss: 2.73248133e-06
Iter: 962 loss: 2.72797934e-06
Iter: 963 loss: 2.72600187e-06
Iter: 964 loss: 2.72955026e-06
Iter: 965 loss: 2.72511829e-06
Iter: 966 loss: 2.72310808e-06
Iter: 967 loss: 2.7368651e-06
Iter: 968 loss: 2.72293892e-06
Iter: 969 loss: 2.72157899e-06
Iter: 970 loss: 2.7215774e-06
Iter: 971 loss: 2.72065745e-06
Iter: 972 loss: 2.71829958e-06
Iter: 973 loss: 2.74288027e-06
Iter: 974 loss: 2.71801832e-06
Iter: 975 loss: 2.71848148e-06
Iter: 976 loss: 2.71695262e-06
Iter: 977 loss: 2.71623662e-06
Iter: 978 loss: 2.71621298e-06
Iter: 979 loss: 2.71570525e-06
Iter: 980 loss: 2.71461977e-06
Iter: 981 loss: 2.7159092e-06
Iter: 982 loss: 2.71416729e-06
Iter: 983 loss: 2.71286217e-06
Iter: 984 loss: 2.71073918e-06
Iter: 985 loss: 2.71070348e-06
Iter: 986 loss: 2.70885198e-06
Iter: 987 loss: 2.71269073e-06
Iter: 988 loss: 2.70815553e-06
Iter: 989 loss: 2.70592136e-06
Iter: 990 loss: 2.71684712e-06
Iter: 991 loss: 2.70565897e-06
Iter: 992 loss: 2.70402074e-06
Iter: 993 loss: 2.70582063e-06
Iter: 994 loss: 2.70308647e-06
Iter: 995 loss: 2.70115743e-06
Iter: 996 loss: 2.71120348e-06
Iter: 997 loss: 2.70074543e-06
Iter: 998 loss: 2.69915722e-06
Iter: 999 loss: 2.70351484e-06
Iter: 1000 loss: 2.6985781e-06
Iter: 1001 loss: 2.69719976e-06
Iter: 1002 loss: 2.71681438e-06
Iter: 1003 loss: 2.69723137e-06
Iter: 1004 loss: 2.69595012e-06
Iter: 1005 loss: 2.69523525e-06
Iter: 1006 loss: 2.69484099e-06
Iter: 1007 loss: 2.69387056e-06
Iter: 1008 loss: 2.69389284e-06
Iter: 1009 loss: 2.69288785e-06
Iter: 1010 loss: 2.69384964e-06
Iter: 1011 loss: 2.69239922e-06
Iter: 1012 loss: 2.69126031e-06
Iter: 1013 loss: 2.69214934e-06
Iter: 1014 loss: 2.69067755e-06
Iter: 1015 loss: 2.68942631e-06
Iter: 1016 loss: 2.69024099e-06
Iter: 1017 loss: 2.68859708e-06
Iter: 1018 loss: 2.68732197e-06
Iter: 1019 loss: 2.68598842e-06
Iter: 1020 loss: 2.6857947e-06
Iter: 1021 loss: 2.68406711e-06
Iter: 1022 loss: 2.70074725e-06
Iter: 1023 loss: 2.68406802e-06
Iter: 1024 loss: 2.6825328e-06
Iter: 1025 loss: 2.6837879e-06
Iter: 1026 loss: 2.68167651e-06
Iter: 1027 loss: 2.68020631e-06
Iter: 1028 loss: 2.68853501e-06
Iter: 1029 loss: 2.67991436e-06
Iter: 1030 loss: 2.678491e-06
Iter: 1031 loss: 2.67947735e-06
Iter: 1032 loss: 2.67756423e-06
Iter: 1033 loss: 2.67663518e-06
Iter: 1034 loss: 2.67652104e-06
Iter: 1035 loss: 2.67556743e-06
Iter: 1036 loss: 2.67635278e-06
Iter: 1037 loss: 2.67494215e-06
Iter: 1038 loss: 2.67407654e-06
Iter: 1039 loss: 2.67506448e-06
Iter: 1040 loss: 2.67363521e-06
Iter: 1041 loss: 2.67231258e-06
Iter: 1042 loss: 2.68334907e-06
Iter: 1043 loss: 2.67223277e-06
Iter: 1044 loss: 2.67154155e-06
Iter: 1045 loss: 2.67153018e-06
Iter: 1046 loss: 2.67103133e-06
Iter: 1047 loss: 2.67005498e-06
Iter: 1048 loss: 2.670085e-06
Iter: 1049 loss: 2.66922393e-06
Iter: 1050 loss: 2.66785446e-06
Iter: 1051 loss: 2.66721122e-06
Iter: 1052 loss: 2.66654888e-06
Iter: 1053 loss: 2.66473e-06
Iter: 1054 loss: 2.66740903e-06
Iter: 1055 loss: 2.66367215e-06
Iter: 1056 loss: 2.66134634e-06
Iter: 1057 loss: 2.67369251e-06
Iter: 1058 loss: 2.66090319e-06
Iter: 1059 loss: 2.6593616e-06
Iter: 1060 loss: 2.66199663e-06
Iter: 1061 loss: 2.65867334e-06
Iter: 1062 loss: 2.65654717e-06
Iter: 1063 loss: 2.66402822e-06
Iter: 1064 loss: 2.655966e-06
Iter: 1065 loss: 2.65470703e-06
Iter: 1066 loss: 2.66993106e-06
Iter: 1067 loss: 2.65466679e-06
Iter: 1068 loss: 2.65330254e-06
Iter: 1069 loss: 2.6576356e-06
Iter: 1070 loss: 2.65304766e-06
Iter: 1071 loss: 2.65198332e-06
Iter: 1072 loss: 2.65146173e-06
Iter: 1073 loss: 2.65085941e-06
Iter: 1074 loss: 2.64978598e-06
Iter: 1075 loss: 2.64971095e-06
Iter: 1076 loss: 2.64907248e-06
Iter: 1077 loss: 2.64805726e-06
Iter: 1078 loss: 2.64807795e-06
Iter: 1079 loss: 2.64665437e-06
Iter: 1080 loss: 2.64790356e-06
Iter: 1081 loss: 2.64587061e-06
Iter: 1082 loss: 2.64442633e-06
Iter: 1083 loss: 2.64581854e-06
Iter: 1084 loss: 2.64376058e-06
Iter: 1085 loss: 2.64220671e-06
Iter: 1086 loss: 2.64185246e-06
Iter: 1087 loss: 2.64086884e-06
Iter: 1088 loss: 2.63888023e-06
Iter: 1089 loss: 2.6557916e-06
Iter: 1090 loss: 2.63876541e-06
Iter: 1091 loss: 2.6373641e-06
Iter: 1092 loss: 2.63572747e-06
Iter: 1093 loss: 2.6354985e-06
Iter: 1094 loss: 2.63314087e-06
Iter: 1095 loss: 2.66420921e-06
Iter: 1096 loss: 2.63318771e-06
Iter: 1097 loss: 2.63183e-06
Iter: 1098 loss: 2.63354855e-06
Iter: 1099 loss: 2.63121046e-06
Iter: 1100 loss: 2.62967978e-06
Iter: 1101 loss: 2.65207882e-06
Iter: 1102 loss: 2.62970252e-06
Iter: 1103 loss: 2.62856361e-06
Iter: 1104 loss: 2.62833328e-06
Iter: 1105 loss: 2.62759795e-06
Iter: 1106 loss: 2.6269e-06
Iter: 1107 loss: 2.62682556e-06
Iter: 1108 loss: 2.62628737e-06
Iter: 1109 loss: 2.62518415e-06
Iter: 1110 loss: 2.64073287e-06
Iter: 1111 loss: 2.62511958e-06
Iter: 1112 loss: 2.62366825e-06
Iter: 1113 loss: 2.63183392e-06
Iter: 1114 loss: 2.62349863e-06
Iter: 1115 loss: 2.62236381e-06
Iter: 1116 loss: 2.62139156e-06
Iter: 1117 loss: 2.62111871e-06
Iter: 1118 loss: 2.61937112e-06
Iter: 1119 loss: 2.61973037e-06
Iter: 1120 loss: 2.61801097e-06
Iter: 1121 loss: 2.61629748e-06
Iter: 1122 loss: 2.62610138e-06
Iter: 1123 loss: 2.61606328e-06
Iter: 1124 loss: 2.61428704e-06
Iter: 1125 loss: 2.61500782e-06
Iter: 1126 loss: 2.61308423e-06
Iter: 1127 loss: 2.61142122e-06
Iter: 1128 loss: 2.63123206e-06
Iter: 1129 loss: 2.61134028e-06
Iter: 1130 loss: 2.60994784e-06
Iter: 1131 loss: 2.61040213e-06
Iter: 1132 loss: 2.60894876e-06
Iter: 1133 loss: 2.60774323e-06
Iter: 1134 loss: 2.60770867e-06
Iter: 1135 loss: 2.60687671e-06
Iter: 1136 loss: 2.60790807e-06
Iter: 1137 loss: 2.60645083e-06
Iter: 1138 loss: 2.60576735e-06
Iter: 1139 loss: 2.61339483e-06
Iter: 1140 loss: 2.60578622e-06
Iter: 1141 loss: 2.60490651e-06
Iter: 1142 loss: 2.60386605e-06
Iter: 1143 loss: 2.60375282e-06
Iter: 1144 loss: 2.60267893e-06
Iter: 1145 loss: 2.60682282e-06
Iter: 1146 loss: 2.60254228e-06
Iter: 1147 loss: 2.60139177e-06
Iter: 1148 loss: 2.60120055e-06
Iter: 1149 loss: 2.60036768e-06
Iter: 1150 loss: 2.59883609e-06
Iter: 1151 loss: 2.59930766e-06
Iter: 1152 loss: 2.59785293e-06
Iter: 1153 loss: 2.59591343e-06
Iter: 1154 loss: 2.59760645e-06
Iter: 1155 loss: 2.59484204e-06
Iter: 1156 loss: 2.59237959e-06
Iter: 1157 loss: 2.60288721e-06
Iter: 1158 loss: 2.59195758e-06
Iter: 1159 loss: 2.59006e-06
Iter: 1160 loss: 2.59516378e-06
Iter: 1161 loss: 2.58944465e-06
Iter: 1162 loss: 2.58762475e-06
Iter: 1163 loss: 2.59811304e-06
Iter: 1164 loss: 2.58729074e-06
Iter: 1165 loss: 2.58619798e-06
Iter: 1166 loss: 2.60168e-06
Iter: 1167 loss: 2.58623186e-06
Iter: 1168 loss: 2.58518639e-06
Iter: 1169 loss: 2.58568048e-06
Iter: 1170 loss: 2.58450245e-06
Iter: 1171 loss: 2.5833333e-06
Iter: 1172 loss: 2.59127182e-06
Iter: 1173 loss: 2.58316823e-06
Iter: 1174 loss: 2.58193131e-06
Iter: 1175 loss: 2.58656428e-06
Iter: 1176 loss: 2.58152977e-06
Iter: 1177 loss: 2.58085402e-06
Iter: 1178 loss: 2.5796644e-06
Iter: 1179 loss: 2.57962029e-06
Iter: 1180 loss: 2.57789884e-06
Iter: 1181 loss: 2.58522414e-06
Iter: 1182 loss: 2.57765487e-06
Iter: 1183 loss: 2.57651254e-06
Iter: 1184 loss: 2.57693341e-06
Iter: 1185 loss: 2.57563761e-06
Iter: 1186 loss: 2.57414172e-06
Iter: 1187 loss: 2.5738525e-06
Iter: 1188 loss: 2.57299553e-06
Iter: 1189 loss: 2.57107968e-06
Iter: 1190 loss: 2.58356363e-06
Iter: 1191 loss: 2.57086299e-06
Iter: 1192 loss: 2.56911471e-06
Iter: 1193 loss: 2.57046e-06
Iter: 1194 loss: 2.56800513e-06
Iter: 1195 loss: 2.56638168e-06
Iter: 1196 loss: 2.58042814e-06
Iter: 1197 loss: 2.56626186e-06
Iter: 1198 loss: 2.56508292e-06
Iter: 1199 loss: 2.57084434e-06
Iter: 1200 loss: 2.56493422e-06
Iter: 1201 loss: 2.56348039e-06
Iter: 1202 loss: 2.57052852e-06
Iter: 1203 loss: 2.5631989e-06
Iter: 1204 loss: 2.56248109e-06
Iter: 1205 loss: 2.56710337e-06
Iter: 1206 loss: 2.5623408e-06
Iter: 1207 loss: 2.56164913e-06
Iter: 1208 loss: 2.5662373e-06
Iter: 1209 loss: 2.56158796e-06
Iter: 1210 loss: 2.56114549e-06
Iter: 1211 loss: 2.56e-06
Iter: 1212 loss: 2.56898647e-06
Iter: 1213 loss: 2.55968052e-06
Iter: 1214 loss: 2.5582849e-06
Iter: 1215 loss: 2.57576585e-06
Iter: 1216 loss: 2.55827263e-06
Iter: 1217 loss: 2.55739224e-06
Iter: 1218 loss: 2.55667919e-06
Iter: 1219 loss: 2.5564334e-06
Iter: 1220 loss: 2.55499026e-06
Iter: 1221 loss: 2.55585951e-06
Iter: 1222 loss: 2.55401073e-06
Iter: 1223 loss: 2.55239547e-06
Iter: 1224 loss: 2.55927307e-06
Iter: 1225 loss: 2.5521374e-06
Iter: 1226 loss: 2.55043278e-06
Iter: 1227 loss: 2.55506211e-06
Iter: 1228 loss: 2.54999441e-06
Iter: 1229 loss: 2.54868337e-06
Iter: 1230 loss: 2.55113173e-06
Iter: 1231 loss: 2.54816905e-06
Iter: 1232 loss: 2.54657266e-06
Iter: 1233 loss: 2.55453324e-06
Iter: 1234 loss: 2.54623683e-06
Iter: 1235 loss: 2.54516181e-06
Iter: 1236 loss: 2.54517909e-06
Iter: 1237 loss: 2.5446e-06
Iter: 1238 loss: 2.54466113e-06
Iter: 1239 loss: 2.54419069e-06
Iter: 1240 loss: 2.54326073e-06
Iter: 1241 loss: 2.55234409e-06
Iter: 1242 loss: 2.54328506e-06
Iter: 1243 loss: 2.5426225e-06
Iter: 1244 loss: 2.54115184e-06
Iter: 1245 loss: 2.56226303e-06
Iter: 1246 loss: 2.54107727e-06
Iter: 1247 loss: 2.53999542e-06
Iter: 1248 loss: 2.55691702e-06
Iter: 1249 loss: 2.5399645e-06
Iter: 1250 loss: 2.53918461e-06
Iter: 1251 loss: 2.53798953e-06
Iter: 1252 loss: 2.53794656e-06
Iter: 1253 loss: 2.53639064e-06
Iter: 1254 loss: 2.54008501e-06
Iter: 1255 loss: 2.53592475e-06
Iter: 1256 loss: 2.53456278e-06
Iter: 1257 loss: 2.53486633e-06
Iter: 1258 loss: 2.53356279e-06
Iter: 1259 loss: 2.53169082e-06
Iter: 1260 loss: 2.54344718e-06
Iter: 1261 loss: 2.53158441e-06
Iter: 1262 loss: 2.53031567e-06
Iter: 1263 loss: 2.53046846e-06
Iter: 1264 loss: 2.52932432e-06
Iter: 1265 loss: 2.52795462e-06
Iter: 1266 loss: 2.54482302e-06
Iter: 1267 loss: 2.52797963e-06
Iter: 1268 loss: 2.52724158e-06
Iter: 1269 loss: 2.5272509e-06
Iter: 1270 loss: 2.52661084e-06
Iter: 1271 loss: 2.52630048e-06
Iter: 1272 loss: 2.52608811e-06
Iter: 1273 loss: 2.52531936e-06
Iter: 1274 loss: 2.53705707e-06
Iter: 1275 loss: 2.52529344e-06
Iter: 1276 loss: 2.52465475e-06
Iter: 1277 loss: 2.52366453e-06
Iter: 1278 loss: 2.52362383e-06
Iter: 1279 loss: 2.52281e-06
Iter: 1280 loss: 2.52706741e-06
Iter: 1281 loss: 2.52270547e-06
Iter: 1282 loss: 2.52177847e-06
Iter: 1283 loss: 2.52217069e-06
Iter: 1284 loss: 2.52109294e-06
Iter: 1285 loss: 2.52011046e-06
Iter: 1286 loss: 2.52139e-06
Iter: 1287 loss: 2.51966139e-06
Iter: 1288 loss: 2.51847132e-06
Iter: 1289 loss: 2.51861252e-06
Iter: 1290 loss: 2.5175907e-06
Iter: 1291 loss: 2.51627762e-06
Iter: 1292 loss: 2.52550535e-06
Iter: 1293 loss: 2.51608049e-06
Iter: 1294 loss: 2.51500865e-06
Iter: 1295 loss: 2.51454594e-06
Iter: 1296 loss: 2.51390884e-06
Iter: 1297 loss: 2.51266147e-06
Iter: 1298 loss: 2.52866539e-06
Iter: 1299 loss: 2.51267534e-06
Iter: 1300 loss: 2.51178335e-06
Iter: 1301 loss: 2.51759207e-06
Iter: 1302 loss: 2.51173219e-06
Iter: 1303 loss: 2.51075562e-06
Iter: 1304 loss: 2.51164965e-06
Iter: 1305 loss: 2.5102936e-06
Iter: 1306 loss: 2.50963194e-06
Iter: 1307 loss: 2.50955418e-06
Iter: 1308 loss: 2.50907306e-06
Iter: 1309 loss: 2.50821e-06
Iter: 1310 loss: 2.50818402e-06
Iter: 1311 loss: 2.50728704e-06
Iter: 1312 loss: 2.507923e-06
Iter: 1313 loss: 2.50672656e-06
Iter: 1314 loss: 2.50544326e-06
Iter: 1315 loss: 2.51450047e-06
Iter: 1316 loss: 2.50536868e-06
Iter: 1317 loss: 2.50459379e-06
Iter: 1318 loss: 2.5037225e-06
Iter: 1319 loss: 2.50367748e-06
Iter: 1320 loss: 2.50232915e-06
Iter: 1321 loss: 2.50615199e-06
Iter: 1322 loss: 2.50201856e-06
Iter: 1323 loss: 2.50094263e-06
Iter: 1324 loss: 2.5016991e-06
Iter: 1325 loss: 2.50034191e-06
Iter: 1326 loss: 2.49894651e-06
Iter: 1327 loss: 2.50470544e-06
Iter: 1328 loss: 2.49869527e-06
Iter: 1329 loss: 2.49769323e-06
Iter: 1330 loss: 2.50065023e-06
Iter: 1331 loss: 2.49738764e-06
Iter: 1332 loss: 2.49642972e-06
Iter: 1333 loss: 2.50483663e-06
Iter: 1334 loss: 2.49646337e-06
Iter: 1335 loss: 2.49569757e-06
Iter: 1336 loss: 2.49805157e-06
Iter: 1337 loss: 2.49546815e-06
Iter: 1338 loss: 2.49502432e-06
Iter: 1339 loss: 2.50139556e-06
Iter: 1340 loss: 2.49500954e-06
Iter: 1341 loss: 2.49450818e-06
Iter: 1342 loss: 2.49391564e-06
Iter: 1343 loss: 2.49385403e-06
Iter: 1344 loss: 2.49311188e-06
Iter: 1345 loss: 2.49371124e-06
Iter: 1346 loss: 2.49277127e-06
Iter: 1347 loss: 2.49209415e-06
Iter: 1348 loss: 2.49863092e-06
Iter: 1349 loss: 2.49210507e-06
Iter: 1350 loss: 2.49149525e-06
Iter: 1351 loss: 2.49050072e-06
Iter: 1352 loss: 2.49049253e-06
Iter: 1353 loss: 2.48941501e-06
Iter: 1354 loss: 2.49464802e-06
Iter: 1355 loss: 2.48931019e-06
Iter: 1356 loss: 2.4883816e-06
Iter: 1357 loss: 2.48733681e-06
Iter: 1358 loss: 2.48711376e-06
Iter: 1359 loss: 2.48591346e-06
Iter: 1360 loss: 2.49988079e-06
Iter: 1361 loss: 2.48587639e-06
Iter: 1362 loss: 2.48484776e-06
Iter: 1363 loss: 2.48599213e-06
Iter: 1364 loss: 2.48432252e-06
Iter: 1365 loss: 2.48343372e-06
Iter: 1366 loss: 2.4834726e-06
Iter: 1367 loss: 2.48283914e-06
Iter: 1368 loss: 2.48476954e-06
Iter: 1369 loss: 2.48258675e-06
Iter: 1370 loss: 2.4820456e-06
Iter: 1371 loss: 2.48264519e-06
Iter: 1372 loss: 2.48174752e-06
Iter: 1373 loss: 2.48075821e-06
Iter: 1374 loss: 2.48339848e-06
Iter: 1375 loss: 2.48035781e-06
Iter: 1376 loss: 2.47972457e-06
Iter: 1377 loss: 2.47937578e-06
Iter: 1378 loss: 2.47917114e-06
Iter: 1379 loss: 2.47838307e-06
Iter: 1380 loss: 2.48340257e-06
Iter: 1381 loss: 2.47831463e-06
Iter: 1382 loss: 2.47754861e-06
Iter: 1383 loss: 2.47807247e-06
Iter: 1384 loss: 2.47702928e-06
Iter: 1385 loss: 2.47639582e-06
Iter: 1386 loss: 2.47690423e-06
Iter: 1387 loss: 2.47590106e-06
Iter: 1388 loss: 2.47497314e-06
Iter: 1389 loss: 2.47514186e-06
Iter: 1390 loss: 2.47422304e-06
Iter: 1391 loss: 2.47305161e-06
Iter: 1392 loss: 2.47736762e-06
Iter: 1393 loss: 2.47279308e-06
Iter: 1394 loss: 2.47156959e-06
Iter: 1395 loss: 2.47354387e-06
Iter: 1396 loss: 2.47094954e-06
Iter: 1397 loss: 2.47017715e-06
Iter: 1398 loss: 2.47016533e-06
Iter: 1399 loss: 2.46942886e-06
Iter: 1400 loss: 2.47130356e-06
Iter: 1401 loss: 2.46923673e-06
Iter: 1402 loss: 2.46848185e-06
Iter: 1403 loss: 2.46767e-06
Iter: 1404 loss: 2.46745958e-06
Iter: 1405 loss: 2.46802279e-06
Iter: 1406 loss: 2.46708714e-06
Iter: 1407 loss: 2.46682976e-06
Iter: 1408 loss: 2.46601417e-06
Iter: 1409 loss: 2.46967829e-06
Iter: 1410 loss: 2.46571881e-06
Iter: 1411 loss: 2.46481932e-06
Iter: 1412 loss: 2.47055027e-06
Iter: 1413 loss: 2.46477248e-06
Iter: 1414 loss: 2.46413583e-06
Iter: 1415 loss: 2.46811942e-06
Iter: 1416 loss: 2.46412355e-06
Iter: 1417 loss: 2.46335867e-06
Iter: 1418 loss: 2.4622e-06
Iter: 1419 loss: 2.46215177e-06
Iter: 1420 loss: 2.46104742e-06
Iter: 1421 loss: 2.46770514e-06
Iter: 1422 loss: 2.46088803e-06
Iter: 1423 loss: 2.45988463e-06
Iter: 1424 loss: 2.45970864e-06
Iter: 1425 loss: 2.4589317e-06
Iter: 1426 loss: 2.45786646e-06
Iter: 1427 loss: 2.46354512e-06
Iter: 1428 loss: 2.45766705e-06
Iter: 1429 loss: 2.45632646e-06
Iter: 1430 loss: 2.45569731e-06
Iter: 1431 loss: 2.45504839e-06
Iter: 1432 loss: 2.45498063e-06
Iter: 1433 loss: 2.45443675e-06
Iter: 1434 loss: 2.45382307e-06
Iter: 1435 loss: 2.45392289e-06
Iter: 1436 loss: 2.45329693e-06
Iter: 1437 loss: 2.45236879e-06
Iter: 1438 loss: 2.45336014e-06
Iter: 1439 loss: 2.45191382e-06
Iter: 1440 loss: 2.45060119e-06
Iter: 1441 loss: 2.46083346e-06
Iter: 1442 loss: 2.45049932e-06
Iter: 1443 loss: 2.4500232e-06
Iter: 1444 loss: 2.44883449e-06
Iter: 1445 loss: 2.45949968e-06
Iter: 1446 loss: 2.4487083e-06
Iter: 1447 loss: 2.44739658e-06
Iter: 1448 loss: 2.46293e-06
Iter: 1449 loss: 2.44740295e-06
Iter: 1450 loss: 2.4466e-06
Iter: 1451 loss: 2.45227693e-06
Iter: 1452 loss: 2.44649573e-06
Iter: 1453 loss: 2.4459323e-06
Iter: 1454 loss: 2.44435819e-06
Iter: 1455 loss: 2.45502042e-06
Iter: 1456 loss: 2.44400098e-06
Iter: 1457 loss: 2.44268222e-06
Iter: 1458 loss: 2.44263515e-06
Iter: 1459 loss: 2.44177636e-06
Iter: 1460 loss: 2.44099283e-06
Iter: 1461 loss: 2.44074863e-06
Iter: 1462 loss: 2.4393571e-06
Iter: 1463 loss: 2.44821354e-06
Iter: 1464 loss: 2.43922295e-06
Iter: 1465 loss: 2.437994e-06
Iter: 1466 loss: 2.43993918e-06
Iter: 1467 loss: 2.43738828e-06
Iter: 1468 loss: 2.43691852e-06
Iter: 1469 loss: 2.43677118e-06
Iter: 1470 loss: 2.43613795e-06
Iter: 1471 loss: 2.43562636e-06
Iter: 1472 loss: 2.43550517e-06
Iter: 1473 loss: 2.43480099e-06
Iter: 1474 loss: 2.43474665e-06
Iter: 1475 loss: 2.43428372e-06
Iter: 1476 loss: 2.4334995e-06
Iter: 1477 loss: 2.43349541e-06
Iter: 1478 loss: 2.43267527e-06
Iter: 1479 loss: 2.43350223e-06
Iter: 1480 loss: 2.43218e-06
Iter: 1481 loss: 2.43107161e-06
Iter: 1482 loss: 2.43902514e-06
Iter: 1483 loss: 2.43098611e-06
Iter: 1484 loss: 2.43002614e-06
Iter: 1485 loss: 2.43198883e-06
Iter: 1486 loss: 2.42970145e-06
Iter: 1487 loss: 2.42888973e-06
Iter: 1488 loss: 2.42744727e-06
Iter: 1489 loss: 2.42740794e-06
Iter: 1490 loss: 2.42586066e-06
Iter: 1491 loss: 2.44338e-06
Iter: 1492 loss: 2.42581928e-06
Iter: 1493 loss: 2.42455417e-06
Iter: 1494 loss: 2.42365832e-06
Iter: 1495 loss: 2.4233068e-06
Iter: 1496 loss: 2.4220717e-06
Iter: 1497 loss: 2.44085732e-06
Iter: 1498 loss: 2.42206033e-06
Iter: 1499 loss: 2.42115652e-06
Iter: 1500 loss: 2.42421788e-06
Iter: 1501 loss: 2.42087162e-06
Iter: 1502 loss: 2.42005103e-06
Iter: 1503 loss: 2.43211957e-06
Iter: 1504 loss: 2.41998464e-06
Iter: 1505 loss: 2.41967314e-06
Iter: 1506 loss: 2.42226588e-06
Iter: 1507 loss: 2.4196363e-06
Iter: 1508 loss: 2.41926932e-06
Iter: 1509 loss: 2.41883345e-06
Iter: 1510 loss: 2.41874e-06
Iter: 1511 loss: 2.41815178e-06
Iter: 1512 loss: 2.41700309e-06
Iter: 1513 loss: 2.41698763e-06
Iter: 1514 loss: 2.41643988e-06
Iter: 1515 loss: 2.4163005e-06
Iter: 1516 loss: 2.41573207e-06
Iter: 1517 loss: 2.4163021e-06
Iter: 1518 loss: 2.41550015e-06
Iter: 1519 loss: 2.41484736e-06
Iter: 1520 loss: 2.41399357e-06
Iter: 1521 loss: 2.41393013e-06
Iter: 1522 loss: 2.413017e-06
Iter: 1523 loss: 2.41832731e-06
Iter: 1524 loss: 2.41288535e-06
Iter: 1525 loss: 2.41198632e-06
Iter: 1526 loss: 2.412703e-06
Iter: 1527 loss: 2.41143925e-06
Iter: 1528 loss: 2.41047746e-06
Iter: 1529 loss: 2.41305315e-06
Iter: 1530 loss: 2.41019552e-06
Iter: 1531 loss: 2.40920053e-06
Iter: 1532 loss: 2.41501289e-06
Iter: 1533 loss: 2.40908867e-06
Iter: 1534 loss: 2.40855638e-06
Iter: 1535 loss: 2.40849567e-06
Iter: 1536 loss: 2.40819782e-06
Iter: 1537 loss: 2.40810641e-06
Iter: 1538 loss: 2.40780378e-06
Iter: 1539 loss: 2.40709824e-06
Iter: 1540 loss: 2.40800182e-06
Iter: 1541 loss: 2.40664554e-06
Iter: 1542 loss: 2.40606096e-06
Iter: 1543 loss: 2.40592817e-06
Iter: 1544 loss: 2.40551572e-06
Iter: 1545 loss: 2.40485861e-06
Iter: 1546 loss: 2.40698705e-06
Iter: 1547 loss: 2.40463805e-06
Iter: 1548 loss: 2.40380768e-06
Iter: 1549 loss: 2.4086512e-06
Iter: 1550 loss: 2.40369468e-06
Iter: 1551 loss: 2.40323448e-06
Iter: 1552 loss: 2.40323334e-06
Iter: 1553 loss: 2.40285385e-06
Iter: 1554 loss: 2.40195823e-06
Iter: 1555 loss: 2.40155532e-06
Iter: 1556 loss: 2.40121562e-06
Iter: 1557 loss: 2.40035911e-06
Iter: 1558 loss: 2.4070082e-06
Iter: 1559 loss: 2.40031045e-06
Iter: 1560 loss: 2.39945552e-06
Iter: 1561 loss: 2.39940891e-06
Iter: 1562 loss: 2.39873566e-06
Iter: 1563 loss: 2.39798601e-06
Iter: 1564 loss: 2.40448981e-06
Iter: 1565 loss: 2.39788278e-06
Iter: 1566 loss: 2.39735164e-06
Iter: 1567 loss: 2.40461577e-06
Iter: 1568 loss: 2.39736232e-06
Iter: 1569 loss: 2.39679e-06
Iter: 1570 loss: 2.39794235e-06
Iter: 1571 loss: 2.39657174e-06
Iter: 1572 loss: 2.39623182e-06
Iter: 1573 loss: 2.39981341e-06
Iter: 1574 loss: 2.39618316e-06
Iter: 1575 loss: 2.39594374e-06
Iter: 1576 loss: 2.39536712e-06
Iter: 1577 loss: 2.40024428e-06
Iter: 1578 loss: 2.39521955e-06
Iter: 1579 loss: 2.39438918e-06
Iter: 1580 loss: 2.39639758e-06
Iter: 1581 loss: 2.39403107e-06
Iter: 1582 loss: 2.39347582e-06
Iter: 1583 loss: 2.39346809e-06
Iter: 1584 loss: 2.39308542e-06
Iter: 1585 loss: 2.39257679e-06
Iter: 1586 loss: 2.39263613e-06
Iter: 1587 loss: 2.39182964e-06
Iter: 1588 loss: 2.39458313e-06
Iter: 1589 loss: 2.39157544e-06
Iter: 1590 loss: 2.39108567e-06
Iter: 1591 loss: 2.39119504e-06
Iter: 1592 loss: 2.39064025e-06
Iter: 1593 loss: 2.38980238e-06
Iter: 1594 loss: 2.3931384e-06
Iter: 1595 loss: 2.38954408e-06
Iter: 1596 loss: 2.38893108e-06
Iter: 1597 loss: 2.39013798e-06
Iter: 1598 loss: 2.38858456e-06
Iter: 1599 loss: 2.38798521e-06
Iter: 1600 loss: 2.3879893e-06
Iter: 1601 loss: 2.38743064e-06
Iter: 1602 loss: 2.39091969e-06
Iter: 1603 loss: 2.38733787e-06
Iter: 1604 loss: 2.38706684e-06
Iter: 1605 loss: 2.38865482e-06
Iter: 1606 loss: 2.38699022e-06
Iter: 1607 loss: 2.38671191e-06
Iter: 1608 loss: 2.38588473e-06
Iter: 1609 loss: 2.39143037e-06
Iter: 1610 loss: 2.38565735e-06
Iter: 1611 loss: 2.38489793e-06
Iter: 1612 loss: 2.39240126e-06
Iter: 1613 loss: 2.38486268e-06
Iter: 1614 loss: 2.38437678e-06
Iter: 1615 loss: 2.38767734e-06
Iter: 1616 loss: 2.38434427e-06
Iter: 1617 loss: 2.38374878e-06
Iter: 1618 loss: 2.38297412e-06
Iter: 1619 loss: 2.38299049e-06
Iter: 1620 loss: 2.38229154e-06
Iter: 1621 loss: 2.38640359e-06
Iter: 1622 loss: 2.38221719e-06
Iter: 1623 loss: 2.3816051e-06
Iter: 1624 loss: 2.38104894e-06
Iter: 1625 loss: 2.38087659e-06
Iter: 1626 loss: 2.38006487e-06
Iter: 1627 loss: 2.38803864e-06
Iter: 1628 loss: 2.38005077e-06
Iter: 1629 loss: 2.37944687e-06
Iter: 1630 loss: 2.37975382e-06
Iter: 1631 loss: 2.37901031e-06
Iter: 1632 loss: 2.37841414e-06
Iter: 1633 loss: 2.38482357e-06
Iter: 1634 loss: 2.37838822e-06
Iter: 1635 loss: 2.37798713e-06
Iter: 1636 loss: 2.38478401e-06
Iter: 1637 loss: 2.3779653e-06
Iter: 1638 loss: 2.37774566e-06
Iter: 1639 loss: 2.37794666e-06
Iter: 1640 loss: 2.37752101e-06
Iter: 1641 loss: 2.37707377e-06
Iter: 1642 loss: 2.37702693e-06
Iter: 1643 loss: 2.37677841e-06
Iter: 1644 loss: 2.37633094e-06
Iter: 1645 loss: 2.37573477e-06
Iter: 1646 loss: 2.37572067e-06
Iter: 1647 loss: 2.37501536e-06
Iter: 1648 loss: 2.38424923e-06
Iter: 1649 loss: 2.37500353e-06
Iter: 1650 loss: 2.3744567e-06
Iter: 1651 loss: 2.37635322e-06
Iter: 1652 loss: 2.37432869e-06
Iter: 1653 loss: 2.37387712e-06
Iter: 1654 loss: 2.37310473e-06
Iter: 1655 loss: 2.39141286e-06
Iter: 1656 loss: 2.37306676e-06
Iter: 1657 loss: 2.37220092e-06
Iter: 1658 loss: 2.3801158e-06
Iter: 1659 loss: 2.3721891e-06
Iter: 1660 loss: 2.37154973e-06
Iter: 1661 loss: 2.37142967e-06
Iter: 1662 loss: 2.37107952e-06
Iter: 1663 loss: 2.37023687e-06
Iter: 1664 loss: 2.37629865e-06
Iter: 1665 loss: 2.37015684e-06
Iter: 1666 loss: 2.36953701e-06
Iter: 1667 loss: 2.36950268e-06
Iter: 1668 loss: 2.36902042e-06
Iter: 1669 loss: 2.36924734e-06
Iter: 1670 loss: 2.36867845e-06
Iter: 1671 loss: 2.36849655e-06
Iter: 1672 loss: 2.36861388e-06
Iter: 1673 loss: 2.36833557e-06
Iter: 1674 loss: 2.36803044e-06
Iter: 1675 loss: 2.3684313e-06
Iter: 1676 loss: 2.36795086e-06
Iter: 1677 loss: 2.36760229e-06
Iter: 1678 loss: 2.36684195e-06
Iter: 1679 loss: 2.37771724e-06
Iter: 1680 loss: 2.36681444e-06
Iter: 1681 loss: 2.36629103e-06
Iter: 1682 loss: 2.36624169e-06
Iter: 1683 loss: 2.36592518e-06
Iter: 1684 loss: 2.3655839e-06
Iter: 1685 loss: 2.36553956e-06
Iter: 1686 loss: 2.36485153e-06
Iter: 1687 loss: 2.36611845e-06
Iter: 1688 loss: 2.3644634e-06
Iter: 1689 loss: 2.36388814e-06
Iter: 1690 loss: 2.36381766e-06
Iter: 1691 loss: 2.36342908e-06
Iter: 1692 loss: 2.36257983e-06
Iter: 1693 loss: 2.36539063e-06
Iter: 1694 loss: 2.36226833e-06
Iter: 1695 loss: 2.36150709e-06
Iter: 1696 loss: 2.36149799e-06
Iter: 1697 loss: 2.36095593e-06
Iter: 1698 loss: 2.36016831e-06
Iter: 1699 loss: 2.36337974e-06
Iter: 1700 loss: 2.36000869e-06
Iter: 1701 loss: 2.35946254e-06
Iter: 1702 loss: 2.35914467e-06
Iter: 1703 loss: 2.35891957e-06
Iter: 1704 loss: 2.36003552e-06
Iter: 1705 loss: 2.35862171e-06
Iter: 1706 loss: 2.3585153e-06
Iter: 1707 loss: 2.35821835e-06
Iter: 1708 loss: 2.36449864e-06
Iter: 1709 loss: 2.35823791e-06
Iter: 1710 loss: 2.35780635e-06
Iter: 1711 loss: 2.35847915e-06
Iter: 1712 loss: 2.35774951e-06
Iter: 1713 loss: 2.35726611e-06
Iter: 1714 loss: 2.35750394e-06
Iter: 1715 loss: 2.35692278e-06
Iter: 1716 loss: 2.35660627e-06
Iter: 1717 loss: 2.35954235e-06
Iter: 1718 loss: 2.35656216e-06
Iter: 1719 loss: 2.35600669e-06
Iter: 1720 loss: 2.35572e-06
Iter: 1721 loss: 2.35548123e-06
Iter: 1722 loss: 2.35475795e-06
Iter: 1723 loss: 2.35613697e-06
Iter: 1724 loss: 2.3544244e-06
Iter: 1725 loss: 2.35379866e-06
Iter: 1726 loss: 2.35448192e-06
Iter: 1727 loss: 2.35338962e-06
Iter: 1728 loss: 2.3524758e-06
Iter: 1729 loss: 2.35535981e-06
Iter: 1730 loss: 2.35219682e-06
Iter: 1731 loss: 2.35147922e-06
Iter: 1732 loss: 2.35126095e-06
Iter: 1733 loss: 2.35086941e-06
Iter: 1734 loss: 2.34996878e-06
Iter: 1735 loss: 2.36119376e-06
Iter: 1736 loss: 2.35004086e-06
Iter: 1737 loss: 2.34954382e-06
Iter: 1738 loss: 2.35078119e-06
Iter: 1739 loss: 2.34940399e-06
Iter: 1740 loss: 2.34890467e-06
Iter: 1741 loss: 2.35691482e-06
Iter: 1742 loss: 2.3488974e-06
Iter: 1743 loss: 2.34868116e-06
Iter: 1744 loss: 2.34824506e-06
Iter: 1745 loss: 2.35459856e-06
Iter: 1746 loss: 2.3482271e-06
Iter: 1747 loss: 2.34765503e-06
Iter: 1748 loss: 2.34965546e-06
Iter: 1749 loss: 2.34743629e-06
Iter: 1750 loss: 2.34682443e-06
Iter: 1751 loss: 2.3474804e-06
Iter: 1752 loss: 2.34651498e-06
Iter: 1753 loss: 2.34593767e-06
Iter: 1754 loss: 2.35205016e-06
Iter: 1755 loss: 2.3458997e-06
Iter: 1756 loss: 2.34545291e-06
Iter: 1757 loss: 2.34448294e-06
Iter: 1758 loss: 2.36363303e-06
Iter: 1759 loss: 2.34451e-06
Iter: 1760 loss: 2.34385129e-06
Iter: 1761 loss: 2.35146422e-06
Iter: 1762 loss: 2.34382469e-06
Iter: 1763 loss: 2.34335766e-06
Iter: 1764 loss: 2.34368167e-06
Iter: 1765 loss: 2.34307458e-06
Iter: 1766 loss: 2.34230083e-06
Iter: 1767 loss: 2.34376739e-06
Iter: 1768 loss: 2.34198546e-06
Iter: 1769 loss: 2.34145432e-06
Iter: 1770 loss: 2.34191521e-06
Iter: 1771 loss: 2.34115441e-06
Iter: 1772 loss: 2.34016852e-06
Iter: 1773 loss: 2.34241861e-06
Iter: 1774 loss: 2.33989817e-06
Iter: 1775 loss: 2.34089407e-06
Iter: 1776 loss: 2.33958963e-06
Iter: 1777 loss: 2.33943342e-06
Iter: 1778 loss: 2.33897117e-06
Iter: 1779 loss: 2.33909896e-06
Iter: 1780 loss: 2.33848232e-06
Iter: 1781 loss: 2.33758715e-06
Iter: 1782 loss: 2.34265394e-06
Iter: 1783 loss: 2.33744049e-06
Iter: 1784 loss: 2.3368757e-06
Iter: 1785 loss: 2.34230674e-06
Iter: 1786 loss: 2.33686478e-06
Iter: 1787 loss: 2.33657761e-06
Iter: 1788 loss: 2.3365892e-06
Iter: 1789 loss: 2.3362943e-06
Iter: 1790 loss: 2.33573655e-06
Iter: 1791 loss: 2.33512128e-06
Iter: 1792 loss: 2.335094e-06
Iter: 1793 loss: 2.33439732e-06
Iter: 1794 loss: 2.3405978e-06
Iter: 1795 loss: 2.33438277e-06
Iter: 1796 loss: 2.33390938e-06
Iter: 1797 loss: 2.33342553e-06
Iter: 1798 loss: 2.33319952e-06
Iter: 1799 loss: 2.33254468e-06
Iter: 1800 loss: 2.34056211e-06
Iter: 1801 loss: 2.33250967e-06
Iter: 1802 loss: 2.33195942e-06
Iter: 1803 loss: 2.33154287e-06
Iter: 1804 loss: 2.33137234e-06
Iter: 1805 loss: 2.33053265e-06
Iter: 1806 loss: 2.33243782e-06
Iter: 1807 loss: 2.33022388e-06
Iter: 1808 loss: 2.33019318e-06
Iter: 1809 loss: 2.32994125e-06
Iter: 1810 loss: 2.32952425e-06
Iter: 1811 loss: 2.3289972e-06
Iter: 1812 loss: 2.32889e-06
Iter: 1813 loss: 2.32840625e-06
Iter: 1814 loss: 2.32917273e-06
Iter: 1815 loss: 2.32813318e-06
Iter: 1816 loss: 2.32765137e-06
Iter: 1817 loss: 2.33040555e-06
Iter: 1818 loss: 2.32759385e-06
Iter: 1819 loss: 2.32702382e-06
Iter: 1820 loss: 2.3284997e-06
Iter: 1821 loss: 2.32690263e-06
Iter: 1822 loss: 2.32642378e-06
Iter: 1823 loss: 2.32645289e-06
Iter: 1824 loss: 2.32604611e-06
Iter: 1825 loss: 2.3254081e-06
Iter: 1826 loss: 2.32502316e-06
Iter: 1827 loss: 2.32472075e-06
Iter: 1828 loss: 2.32381626e-06
Iter: 1829 loss: 2.3300056e-06
Iter: 1830 loss: 2.32370962e-06
Iter: 1831 loss: 2.3230059e-06
Iter: 1832 loss: 2.32314869e-06
Iter: 1833 loss: 2.32256252e-06
Iter: 1834 loss: 2.32159505e-06
Iter: 1835 loss: 2.32788398e-06
Iter: 1836 loss: 2.3215357e-06
Iter: 1837 loss: 2.32097227e-06
Iter: 1838 loss: 2.32052662e-06
Iter: 1839 loss: 2.32036882e-06
Iter: 1840 loss: 2.31931153e-06
Iter: 1841 loss: 2.3242651e-06
Iter: 1842 loss: 2.31912554e-06
Iter: 1843 loss: 2.31862941e-06
Iter: 1844 loss: 2.31860668e-06
Iter: 1845 loss: 2.31795639e-06
Iter: 1846 loss: 2.31742297e-06
Iter: 1847 loss: 2.31719082e-06
Iter: 1848 loss: 2.31675e-06
Iter: 1849 loss: 2.31786339e-06
Iter: 1850 loss: 2.31653303e-06
Iter: 1851 loss: 2.31624563e-06
Iter: 1852 loss: 2.31974104e-06
Iter: 1853 loss: 2.31621243e-06
Iter: 1854 loss: 2.31584931e-06
Iter: 1855 loss: 2.31516037e-06
Iter: 1856 loss: 2.31517288e-06
Iter: 1857 loss: 2.31447893e-06
Iter: 1858 loss: 2.31810532e-06
Iter: 1859 loss: 2.31440731e-06
Iter: 1860 loss: 2.31396643e-06
Iter: 1861 loss: 2.31318495e-06
Iter: 1862 loss: 2.31318336e-06
Iter: 1863 loss: 2.31220838e-06
Iter: 1864 loss: 2.31813851e-06
Iter: 1865 loss: 2.31204513e-06
Iter: 1866 loss: 2.31132299e-06
Iter: 1867 loss: 2.31254012e-06
Iter: 1868 loss: 2.3110108e-06
Iter: 1869 loss: 2.31023796e-06
Iter: 1870 loss: 2.31307718e-06
Iter: 1871 loss: 2.31008744e-06
Iter: 1872 loss: 2.30924752e-06
Iter: 1873 loss: 2.31099716e-06
Iter: 1874 loss: 2.30886826e-06
Iter: 1875 loss: 2.3082448e-06
Iter: 1876 loss: 2.3100215e-06
Iter: 1877 loss: 2.30807473e-06
Iter: 1878 loss: 2.30804017e-06
Iter: 1879 loss: 2.30774776e-06
Iter: 1880 loss: 2.30751243e-06
Iter: 1881 loss: 2.30691421e-06
Iter: 1882 loss: 2.31277704e-06
Iter: 1883 loss: 2.30681144e-06
Iter: 1884 loss: 2.30631076e-06
Iter: 1885 loss: 2.30681189e-06
Iter: 1886 loss: 2.30606929e-06
Iter: 1887 loss: 2.30536875e-06
Iter: 1888 loss: 2.31236299e-06
Iter: 1889 loss: 2.3053e-06
Iter: 1890 loss: 2.30490036e-06
Iter: 1891 loss: 2.30507703e-06
Iter: 1892 loss: 2.30457567e-06
Iter: 1893 loss: 2.30409569e-06
Iter: 1894 loss: 2.30339219e-06
Iter: 1895 loss: 2.30338628e-06
Iter: 1896 loss: 2.30241153e-06
Iter: 1897 loss: 2.30680325e-06
Iter: 1898 loss: 2.30223327e-06
Iter: 1899 loss: 2.30154865e-06
Iter: 1900 loss: 2.30278556e-06
Iter: 1901 loss: 2.30126625e-06
Iter: 1902 loss: 2.30035857e-06
Iter: 1903 loss: 2.30100204e-06
Iter: 1904 loss: 2.29978741e-06
Iter: 1905 loss: 2.29906823e-06
Iter: 1906 loss: 2.30515798e-06
Iter: 1907 loss: 2.29900206e-06
Iter: 1908 loss: 2.29817078e-06
Iter: 1909 loss: 2.29688226e-06
Iter: 1910 loss: 2.29691386e-06
Iter: 1911 loss: 2.29727721e-06
Iter: 1912 loss: 2.29646434e-06
Iter: 1913 loss: 2.29600664e-06
Iter: 1914 loss: 2.29760099e-06
Iter: 1915 loss: 2.29588704e-06
Iter: 1916 loss: 2.2955287e-06
Iter: 1917 loss: 2.29454372e-06
Iter: 1918 loss: 2.30222122e-06
Iter: 1919 loss: 2.29439547e-06
Iter: 1920 loss: 2.29397756e-06
Iter: 1921 loss: 2.29394118e-06
Iter: 1922 loss: 2.29340185e-06
Iter: 1923 loss: 2.29380703e-06
Iter: 1924 loss: 2.29308307e-06
Iter: 1925 loss: 2.29251327e-06
Iter: 1926 loss: 2.29302395e-06
Iter: 1927 loss: 2.29224565e-06
Iter: 1928 loss: 2.29185503e-06
Iter: 1929 loss: 2.2932295e-06
Iter: 1930 loss: 2.29167699e-06
Iter: 1931 loss: 2.29127409e-06
Iter: 1932 loss: 2.29026136e-06
Iter: 1933 loss: 2.30937349e-06
Iter: 1934 loss: 2.29022771e-06
Iter: 1935 loss: 2.28954013e-06
Iter: 1936 loss: 2.2968934e-06
Iter: 1937 loss: 2.28953445e-06
Iter: 1938 loss: 2.28876343e-06
Iter: 1939 loss: 2.28875251e-06
Iter: 1940 loss: 2.28814201e-06
Iter: 1941 loss: 2.28753424e-06
Iter: 1942 loss: 2.29043803e-06
Iter: 1943 loss: 2.28743625e-06
Iter: 1944 loss: 2.28704857e-06
Iter: 1945 loss: 2.28671297e-06
Iter: 1946 loss: 2.28662384e-06
Iter: 1947 loss: 2.28643103e-06
Iter: 1948 loss: 2.28628573e-06
Iter: 1949 loss: 2.28616545e-06
Iter: 1950 loss: 2.28579347e-06
Iter: 1951 loss: 2.29362922e-06
Iter: 1952 loss: 2.28581325e-06
Iter: 1953 loss: 2.28541785e-06
Iter: 1954 loss: 2.28600584e-06
Iter: 1955 loss: 2.28520616e-06
Iter: 1956 loss: 2.28476256e-06
Iter: 1957 loss: 2.2850104e-06
Iter: 1958 loss: 2.28451154e-06
Iter: 1959 loss: 2.28410704e-06
Iter: 1960 loss: 2.28583576e-06
Iter: 1961 loss: 2.28406179e-06
Iter: 1962 loss: 2.28381464e-06
Iter: 1963 loss: 2.28426666e-06
Iter: 1964 loss: 2.28364752e-06
Iter: 1965 loss: 2.28324e-06
Iter: 1966 loss: 2.28334147e-06
Iter: 1967 loss: 2.28297017e-06
Iter: 1968 loss: 2.2824745e-06
Iter: 1969 loss: 2.28255749e-06
Iter: 1970 loss: 2.28214708e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8
+ date
Mon Oct 26 16:08:51 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf192b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf18f7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf18f7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf18d9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf18682f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf1899d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf185ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf182d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf17eb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf17ebc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf17ebe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf179ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf179ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf1760378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf16f38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf16ad488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf16ad378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf16db2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf16f3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf16878c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf163f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf162cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce6442840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce647fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce647f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce63f6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce640d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce63a6598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce639d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce639d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce637f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce631f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce631f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce62f7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce6287840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcce62a4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.58172947e-05
Iter: 2 loss: 2.93063404e-05
Iter: 3 loss: 7.43952696e-05
Iter: 4 loss: 2.86948271e-05
Iter: 5 loss: 2.71921199e-05
Iter: 6 loss: 2.70651472e-05
Iter: 7 loss: 2.57257161e-05
Iter: 8 loss: 2.27230885e-05
Iter: 9 loss: 6.43625317e-05
Iter: 10 loss: 2.25574677e-05
Iter: 11 loss: 2.04360986e-05
Iter: 12 loss: 4.17502088e-05
Iter: 13 loss: 2.03686341e-05
Iter: 14 loss: 1.9275516e-05
Iter: 15 loss: 1.78466908e-05
Iter: 16 loss: 1.77555776e-05
Iter: 17 loss: 1.63086406e-05
Iter: 18 loss: 1.63084696e-05
Iter: 19 loss: 1.54786903e-05
Iter: 20 loss: 1.46949596e-05
Iter: 21 loss: 1.45040231e-05
Iter: 22 loss: 1.35214814e-05
Iter: 23 loss: 1.35149476e-05
Iter: 24 loss: 1.30846511e-05
Iter: 25 loss: 1.25180768e-05
Iter: 26 loss: 1.24835387e-05
Iter: 27 loss: 1.16142746e-05
Iter: 28 loss: 1.60884701e-05
Iter: 29 loss: 1.14742288e-05
Iter: 30 loss: 1.09884268e-05
Iter: 31 loss: 1.19902561e-05
Iter: 32 loss: 1.07940368e-05
Iter: 33 loss: 1.03820839e-05
Iter: 34 loss: 1.20280201e-05
Iter: 35 loss: 1.0289602e-05
Iter: 36 loss: 9.98041833e-06
Iter: 37 loss: 9.9063036e-06
Iter: 38 loss: 9.70967085e-06
Iter: 39 loss: 9.6315016e-06
Iter: 40 loss: 9.47934859e-06
Iter: 41 loss: 9.32911826e-06
Iter: 42 loss: 9.14445627e-06
Iter: 43 loss: 9.12789073e-06
Iter: 44 loss: 8.89154489e-06
Iter: 45 loss: 8.75899332e-06
Iter: 46 loss: 8.65612856e-06
Iter: 47 loss: 8.42089503e-06
Iter: 48 loss: 1.00669786e-05
Iter: 49 loss: 8.39929271e-06
Iter: 50 loss: 8.16487e-06
Iter: 51 loss: 8.59238571e-06
Iter: 52 loss: 8.06350545e-06
Iter: 53 loss: 7.91193634e-06
Iter: 54 loss: 9.3457611e-06
Iter: 55 loss: 7.90603099e-06
Iter: 56 loss: 7.76087472e-06
Iter: 57 loss: 7.53867153e-06
Iter: 58 loss: 7.53501172e-06
Iter: 59 loss: 7.35771619e-06
Iter: 60 loss: 8.87920123e-06
Iter: 61 loss: 7.34784135e-06
Iter: 62 loss: 7.1503664e-06
Iter: 63 loss: 7.34824425e-06
Iter: 64 loss: 7.03935302e-06
Iter: 65 loss: 6.90508205e-06
Iter: 66 loss: 7.54624398e-06
Iter: 67 loss: 6.88102182e-06
Iter: 68 loss: 6.72968508e-06
Iter: 69 loss: 6.98470603e-06
Iter: 70 loss: 6.66155847e-06
Iter: 71 loss: 6.59725e-06
Iter: 72 loss: 6.59709849e-06
Iter: 73 loss: 6.52074095e-06
Iter: 74 loss: 6.72065835e-06
Iter: 75 loss: 6.49503636e-06
Iter: 76 loss: 6.43292469e-06
Iter: 77 loss: 6.34055868e-06
Iter: 78 loss: 6.33834088e-06
Iter: 79 loss: 6.26267865e-06
Iter: 80 loss: 6.38548408e-06
Iter: 81 loss: 6.22786592e-06
Iter: 82 loss: 6.13005795e-06
Iter: 83 loss: 6.64924937e-06
Iter: 84 loss: 6.11499672e-06
Iter: 85 loss: 6.0559928e-06
Iter: 86 loss: 6.0583734e-06
Iter: 87 loss: 6.009343e-06
Iter: 88 loss: 5.91447861e-06
Iter: 89 loss: 6.49422691e-06
Iter: 90 loss: 5.90300715e-06
Iter: 91 loss: 5.85380531e-06
Iter: 92 loss: 6.06917183e-06
Iter: 93 loss: 5.8438327e-06
Iter: 94 loss: 5.78316394e-06
Iter: 95 loss: 5.72770887e-06
Iter: 96 loss: 5.71260307e-06
Iter: 97 loss: 5.64918264e-06
Iter: 98 loss: 5.78898107e-06
Iter: 99 loss: 5.62489913e-06
Iter: 100 loss: 5.54844064e-06
Iter: 101 loss: 6.02974796e-06
Iter: 102 loss: 5.53983546e-06
Iter: 103 loss: 5.49072411e-06
Iter: 104 loss: 5.49761899e-06
Iter: 105 loss: 5.4533366e-06
Iter: 106 loss: 5.47843047e-06
Iter: 107 loss: 5.42540874e-06
Iter: 108 loss: 5.40806468e-06
Iter: 109 loss: 5.37325559e-06
Iter: 110 loss: 6.03431272e-06
Iter: 111 loss: 5.37283631e-06
Iter: 112 loss: 5.3377039e-06
Iter: 113 loss: 5.31119485e-06
Iter: 114 loss: 5.29966155e-06
Iter: 115 loss: 5.25758423e-06
Iter: 116 loss: 5.61978641e-06
Iter: 117 loss: 5.25550695e-06
Iter: 118 loss: 5.21668289e-06
Iter: 119 loss: 5.2637829e-06
Iter: 120 loss: 5.19646483e-06
Iter: 121 loss: 5.16074851e-06
Iter: 122 loss: 5.31401383e-06
Iter: 123 loss: 5.15349029e-06
Iter: 124 loss: 5.11407234e-06
Iter: 125 loss: 5.16565069e-06
Iter: 126 loss: 5.09392339e-06
Iter: 127 loss: 5.06093966e-06
Iter: 128 loss: 5.34884066e-06
Iter: 129 loss: 5.05919888e-06
Iter: 130 loss: 5.02846888e-06
Iter: 131 loss: 4.99057569e-06
Iter: 132 loss: 4.98723239e-06
Iter: 133 loss: 4.95157519e-06
Iter: 134 loss: 5.34082301e-06
Iter: 135 loss: 4.95073755e-06
Iter: 136 loss: 4.91673245e-06
Iter: 137 loss: 4.90407547e-06
Iter: 138 loss: 4.88525257e-06
Iter: 139 loss: 4.861864e-06
Iter: 140 loss: 4.86066e-06
Iter: 141 loss: 4.84799966e-06
Iter: 142 loss: 4.84809516e-06
Iter: 143 loss: 4.83436179e-06
Iter: 144 loss: 4.79819028e-06
Iter: 145 loss: 5.07192954e-06
Iter: 146 loss: 4.79120536e-06
Iter: 147 loss: 4.76409878e-06
Iter: 148 loss: 4.87452e-06
Iter: 149 loss: 4.75809884e-06
Iter: 150 loss: 4.72757711e-06
Iter: 151 loss: 4.73460841e-06
Iter: 152 loss: 4.70523719e-06
Iter: 153 loss: 4.68235885e-06
Iter: 154 loss: 4.73371711e-06
Iter: 155 loss: 4.67368227e-06
Iter: 156 loss: 4.64137884e-06
Iter: 157 loss: 4.77853337e-06
Iter: 158 loss: 4.63466267e-06
Iter: 159 loss: 4.61264563e-06
Iter: 160 loss: 4.63231481e-06
Iter: 161 loss: 4.59995135e-06
Iter: 162 loss: 4.57029182e-06
Iter: 163 loss: 4.74963963e-06
Iter: 164 loss: 4.5665679e-06
Iter: 165 loss: 4.54974e-06
Iter: 166 loss: 4.58383374e-06
Iter: 167 loss: 4.5429324e-06
Iter: 168 loss: 4.51961068e-06
Iter: 169 loss: 4.58115665e-06
Iter: 170 loss: 4.51182859e-06
Iter: 171 loss: 4.49649315e-06
Iter: 172 loss: 4.56213274e-06
Iter: 173 loss: 4.49322397e-06
Iter: 174 loss: 4.47497496e-06
Iter: 175 loss: 4.48753462e-06
Iter: 176 loss: 4.46359354e-06
Iter: 177 loss: 4.4522435e-06
Iter: 178 loss: 4.44886382e-06
Iter: 179 loss: 4.44288253e-06
Iter: 180 loss: 4.43222234e-06
Iter: 181 loss: 4.69556e-06
Iter: 182 loss: 4.43220506e-06
Iter: 183 loss: 4.41936254e-06
Iter: 184 loss: 4.40497797e-06
Iter: 185 loss: 4.40295662e-06
Iter: 186 loss: 4.3848172e-06
Iter: 187 loss: 4.45217756e-06
Iter: 188 loss: 4.38032748e-06
Iter: 189 loss: 4.35989386e-06
Iter: 190 loss: 4.46452304e-06
Iter: 191 loss: 4.35657921e-06
Iter: 192 loss: 4.34209414e-06
Iter: 193 loss: 4.35753827e-06
Iter: 194 loss: 4.33417972e-06
Iter: 195 loss: 4.31580565e-06
Iter: 196 loss: 4.38695406e-06
Iter: 197 loss: 4.31160151e-06
Iter: 198 loss: 4.29487864e-06
Iter: 199 loss: 4.28703061e-06
Iter: 200 loss: 4.27883424e-06
Iter: 201 loss: 4.2649508e-06
Iter: 202 loss: 4.26485303e-06
Iter: 203 loss: 4.2521242e-06
Iter: 204 loss: 4.23313077e-06
Iter: 205 loss: 4.23268466e-06
Iter: 206 loss: 4.22202584e-06
Iter: 207 loss: 4.22105677e-06
Iter: 208 loss: 4.21229834e-06
Iter: 209 loss: 4.30931414e-06
Iter: 210 loss: 4.21212189e-06
Iter: 211 loss: 4.20284141e-06
Iter: 212 loss: 4.19916e-06
Iter: 213 loss: 4.19413482e-06
Iter: 214 loss: 4.18620584e-06
Iter: 215 loss: 4.19292155e-06
Iter: 216 loss: 4.18158561e-06
Iter: 217 loss: 4.1708895e-06
Iter: 218 loss: 4.1662106e-06
Iter: 219 loss: 4.16067087e-06
Iter: 220 loss: 4.15042177e-06
Iter: 221 loss: 4.31545732e-06
Iter: 222 loss: 4.15040176e-06
Iter: 223 loss: 4.14280339e-06
Iter: 224 loss: 4.12778536e-06
Iter: 225 loss: 4.41808061e-06
Iter: 226 loss: 4.12774034e-06
Iter: 227 loss: 4.1138569e-06
Iter: 228 loss: 4.33116884e-06
Iter: 229 loss: 4.11389647e-06
Iter: 230 loss: 4.10300208e-06
Iter: 231 loss: 4.08889e-06
Iter: 232 loss: 4.0880891e-06
Iter: 233 loss: 4.08116466e-06
Iter: 234 loss: 4.07912e-06
Iter: 235 loss: 4.07214611e-06
Iter: 236 loss: 4.0586765e-06
Iter: 237 loss: 4.3375403e-06
Iter: 238 loss: 4.05864284e-06
Iter: 239 loss: 4.04774573e-06
Iter: 240 loss: 4.21989262e-06
Iter: 241 loss: 4.04782895e-06
Iter: 242 loss: 4.03752802e-06
Iter: 243 loss: 4.03519425e-06
Iter: 244 loss: 4.02873e-06
Iter: 245 loss: 4.02817568e-06
Iter: 246 loss: 4.02109572e-06
Iter: 247 loss: 4.01881334e-06
Iter: 248 loss: 4.01257512e-06
Iter: 249 loss: 4.05239507e-06
Iter: 250 loss: 4.01104444e-06
Iter: 251 loss: 4.00143836e-06
Iter: 252 loss: 4.01216039e-06
Iter: 253 loss: 3.9962e-06
Iter: 254 loss: 3.98859584e-06
Iter: 255 loss: 4.07907737e-06
Iter: 256 loss: 3.98847487e-06
Iter: 257 loss: 3.9821789e-06
Iter: 258 loss: 3.97189524e-06
Iter: 259 loss: 3.97180884e-06
Iter: 260 loss: 3.9634615e-06
Iter: 261 loss: 3.96354108e-06
Iter: 262 loss: 3.95634561e-06
Iter: 263 loss: 3.94686685e-06
Iter: 264 loss: 3.94637118e-06
Iter: 265 loss: 3.93827122e-06
Iter: 266 loss: 3.93809205e-06
Iter: 267 loss: 3.93173377e-06
Iter: 268 loss: 3.92283073e-06
Iter: 269 loss: 3.92250695e-06
Iter: 270 loss: 3.91244885e-06
Iter: 271 loss: 4.03713784e-06
Iter: 272 loss: 3.91234e-06
Iter: 273 loss: 3.90466857e-06
Iter: 274 loss: 3.89989418e-06
Iter: 275 loss: 3.89691286e-06
Iter: 276 loss: 3.88878107e-06
Iter: 277 loss: 3.99247529e-06
Iter: 278 loss: 3.88865828e-06
Iter: 279 loss: 3.88289754e-06
Iter: 280 loss: 3.88285753e-06
Iter: 281 loss: 3.87919226e-06
Iter: 282 loss: 3.87055843e-06
Iter: 283 loss: 3.97813528e-06
Iter: 284 loss: 3.8699568e-06
Iter: 285 loss: 3.86221473e-06
Iter: 286 loss: 3.86597821e-06
Iter: 287 loss: 3.85679778e-06
Iter: 288 loss: 3.84765463e-06
Iter: 289 loss: 3.93176197e-06
Iter: 290 loss: 3.84715531e-06
Iter: 291 loss: 3.84117584e-06
Iter: 292 loss: 3.84245914e-06
Iter: 293 loss: 3.83667111e-06
Iter: 294 loss: 3.82830649e-06
Iter: 295 loss: 3.89823572e-06
Iter: 296 loss: 3.82783628e-06
Iter: 297 loss: 3.82331518e-06
Iter: 298 loss: 3.82601138e-06
Iter: 299 loss: 3.82027611e-06
Iter: 300 loss: 3.81247196e-06
Iter: 301 loss: 3.82039525e-06
Iter: 302 loss: 3.80799884e-06
Iter: 303 loss: 3.80103484e-06
Iter: 304 loss: 3.81832206e-06
Iter: 305 loss: 3.79846415e-06
Iter: 306 loss: 3.78879258e-06
Iter: 307 loss: 3.80030519e-06
Iter: 308 loss: 3.78370078e-06
Iter: 309 loss: 3.7762843e-06
Iter: 310 loss: 3.82095322e-06
Iter: 311 loss: 3.77544188e-06
Iter: 312 loss: 3.76768503e-06
Iter: 313 loss: 3.77545985e-06
Iter: 314 loss: 3.7633115e-06
Iter: 315 loss: 3.76258208e-06
Iter: 316 loss: 3.7607565e-06
Iter: 317 loss: 3.75764535e-06
Iter: 318 loss: 3.75444188e-06
Iter: 319 loss: 3.75396166e-06
Iter: 320 loss: 3.74855767e-06
Iter: 321 loss: 3.74381239e-06
Iter: 322 loss: 3.74242768e-06
Iter: 323 loss: 3.73692774e-06
Iter: 324 loss: 3.75456352e-06
Iter: 325 loss: 3.7352811e-06
Iter: 326 loss: 3.72805653e-06
Iter: 327 loss: 3.73583816e-06
Iter: 328 loss: 3.72418845e-06
Iter: 329 loss: 3.71859096e-06
Iter: 330 loss: 3.73997887e-06
Iter: 331 loss: 3.71728538e-06
Iter: 332 loss: 3.71068381e-06
Iter: 333 loss: 3.72667751e-06
Iter: 334 loss: 3.70840348e-06
Iter: 335 loss: 3.70278553e-06
Iter: 336 loss: 3.73211469e-06
Iter: 337 loss: 3.70196949e-06
Iter: 338 loss: 3.69599e-06
Iter: 339 loss: 3.69612803e-06
Iter: 340 loss: 3.69124223e-06
Iter: 341 loss: 3.68531391e-06
Iter: 342 loss: 3.70594898e-06
Iter: 343 loss: 3.68370888e-06
Iter: 344 loss: 3.67738176e-06
Iter: 345 loss: 3.69699046e-06
Iter: 346 loss: 3.67558778e-06
Iter: 347 loss: 3.67044731e-06
Iter: 348 loss: 3.67506277e-06
Iter: 349 loss: 3.66742643e-06
Iter: 350 loss: 3.66013774e-06
Iter: 351 loss: 3.7000832e-06
Iter: 352 loss: 3.65908181e-06
Iter: 353 loss: 3.65642882e-06
Iter: 354 loss: 3.6560441e-06
Iter: 355 loss: 3.65252527e-06
Iter: 356 loss: 3.64579842e-06
Iter: 357 loss: 3.80508186e-06
Iter: 358 loss: 3.64573634e-06
Iter: 359 loss: 3.6407655e-06
Iter: 360 loss: 3.66033146e-06
Iter: 361 loss: 3.63954905e-06
Iter: 362 loss: 3.63568597e-06
Iter: 363 loss: 3.63145773e-06
Iter: 364 loss: 3.63079653e-06
Iter: 365 loss: 3.62535638e-06
Iter: 366 loss: 3.70230737e-06
Iter: 367 loss: 3.62530045e-06
Iter: 368 loss: 3.62184119e-06
Iter: 369 loss: 3.61524985e-06
Iter: 370 loss: 3.76997218e-06
Iter: 371 loss: 3.61528464e-06
Iter: 372 loss: 3.60968397e-06
Iter: 373 loss: 3.60948297e-06
Iter: 374 loss: 3.60581771e-06
Iter: 375 loss: 3.6061117e-06
Iter: 376 loss: 3.60306763e-06
Iter: 377 loss: 3.59677824e-06
Iter: 378 loss: 3.61226967e-06
Iter: 379 loss: 3.59458045e-06
Iter: 380 loss: 3.59059072e-06
Iter: 381 loss: 3.58781426e-06
Iter: 382 loss: 3.58637499e-06
Iter: 383 loss: 3.5799992e-06
Iter: 384 loss: 3.64679e-06
Iter: 385 loss: 3.57990552e-06
Iter: 386 loss: 3.5757007e-06
Iter: 387 loss: 3.57528415e-06
Iter: 388 loss: 3.57229692e-06
Iter: 389 loss: 3.56886267e-06
Iter: 390 loss: 3.56864984e-06
Iter: 391 loss: 3.5652979e-06
Iter: 392 loss: 3.58181251e-06
Iter: 393 loss: 3.56483247e-06
Iter: 394 loss: 3.56270857e-06
Iter: 395 loss: 3.55740644e-06
Iter: 396 loss: 3.59187334e-06
Iter: 397 loss: 3.55608154e-06
Iter: 398 loss: 3.5510061e-06
Iter: 399 loss: 3.61151115e-06
Iter: 400 loss: 3.55090197e-06
Iter: 401 loss: 3.54714098e-06
Iter: 402 loss: 3.54703025e-06
Iter: 403 loss: 3.54403551e-06
Iter: 404 loss: 3.5394437e-06
Iter: 405 loss: 3.56798841e-06
Iter: 406 loss: 3.53886935e-06
Iter: 407 loss: 3.53428914e-06
Iter: 408 loss: 3.53425366e-06
Iter: 409 loss: 3.53059386e-06
Iter: 410 loss: 3.52627376e-06
Iter: 411 loss: 3.5701562e-06
Iter: 412 loss: 3.52613529e-06
Iter: 413 loss: 3.52192819e-06
Iter: 414 loss: 3.52507413e-06
Iter: 415 loss: 3.51934295e-06
Iter: 416 loss: 3.5157118e-06
Iter: 417 loss: 3.5486064e-06
Iter: 418 loss: 3.51558424e-06
Iter: 419 loss: 3.51252061e-06
Iter: 420 loss: 3.50831147e-06
Iter: 421 loss: 3.5081523e-06
Iter: 422 loss: 3.50456639e-06
Iter: 423 loss: 3.5044518e-06
Iter: 424 loss: 3.50152459e-06
Iter: 425 loss: 3.49652601e-06
Iter: 426 loss: 3.49647598e-06
Iter: 427 loss: 3.49909e-06
Iter: 428 loss: 3.49379616e-06
Iter: 429 loss: 3.49255765e-06
Iter: 430 loss: 3.48969297e-06
Iter: 431 loss: 3.52680286e-06
Iter: 432 loss: 3.48959475e-06
Iter: 433 loss: 3.48586e-06
Iter: 434 loss: 3.48083e-06
Iter: 435 loss: 3.48052549e-06
Iter: 436 loss: 3.47540572e-06
Iter: 437 loss: 3.53239511e-06
Iter: 438 loss: 3.47526e-06
Iter: 439 loss: 3.47058017e-06
Iter: 440 loss: 3.46838988e-06
Iter: 441 loss: 3.46600973e-06
Iter: 442 loss: 3.46133038e-06
Iter: 443 loss: 3.51909375e-06
Iter: 444 loss: 3.461294e-06
Iter: 445 loss: 3.4571533e-06
Iter: 446 loss: 3.45679223e-06
Iter: 447 loss: 3.4537486e-06
Iter: 448 loss: 3.45014678e-06
Iter: 449 loss: 3.49831362e-06
Iter: 450 loss: 3.4500631e-06
Iter: 451 loss: 3.447e-06
Iter: 452 loss: 3.44510954e-06
Iter: 453 loss: 3.44380737e-06
Iter: 454 loss: 3.43961983e-06
Iter: 455 loss: 3.48438084e-06
Iter: 456 loss: 3.43952843e-06
Iter: 457 loss: 3.43671627e-06
Iter: 458 loss: 3.43352508e-06
Iter: 459 loss: 3.43315241e-06
Iter: 460 loss: 3.43217857e-06
Iter: 461 loss: 3.4308282e-06
Iter: 462 loss: 3.42908197e-06
Iter: 463 loss: 3.43645911e-06
Iter: 464 loss: 3.42873727e-06
Iter: 465 loss: 3.42751582e-06
Iter: 466 loss: 3.42365047e-06
Iter: 467 loss: 3.43588795e-06
Iter: 468 loss: 3.42173962e-06
Iter: 469 loss: 3.4181603e-06
Iter: 470 loss: 3.41815485e-06
Iter: 471 loss: 3.41521013e-06
Iter: 472 loss: 3.41102259e-06
Iter: 473 loss: 3.41089867e-06
Iter: 474 loss: 3.40566476e-06
Iter: 475 loss: 3.45651324e-06
Iter: 476 loss: 3.40551014e-06
Iter: 477 loss: 3.40185397e-06
Iter: 478 loss: 3.40540942e-06
Iter: 479 loss: 3.39982353e-06
Iter: 480 loss: 3.39609028e-06
Iter: 481 loss: 3.40960264e-06
Iter: 482 loss: 3.39529834e-06
Iter: 483 loss: 3.39137159e-06
Iter: 484 loss: 3.39885128e-06
Iter: 485 loss: 3.38975519e-06
Iter: 486 loss: 3.38625864e-06
Iter: 487 loss: 3.39480675e-06
Iter: 488 loss: 3.38497102e-06
Iter: 489 loss: 3.38075256e-06
Iter: 490 loss: 3.40179713e-06
Iter: 491 loss: 3.38008522e-06
Iter: 492 loss: 3.37736265e-06
Iter: 493 loss: 3.38751215e-06
Iter: 494 loss: 3.37669871e-06
Iter: 495 loss: 3.37432903e-06
Iter: 496 loss: 3.39969893e-06
Iter: 497 loss: 3.37415304e-06
Iter: 498 loss: 3.37154847e-06
Iter: 499 loss: 3.37079427e-06
Iter: 500 loss: 3.36924609e-06
Iter: 501 loss: 3.36746189e-06
Iter: 502 loss: 3.36485027e-06
Iter: 503 loss: 3.36477433e-06
Iter: 504 loss: 3.35994719e-06
Iter: 505 loss: 3.36985318e-06
Iter: 506 loss: 3.35805498e-06
Iter: 507 loss: 3.3549868e-06
Iter: 508 loss: 3.36881794e-06
Iter: 509 loss: 3.35444611e-06
Iter: 510 loss: 3.35089408e-06
Iter: 511 loss: 3.35329105e-06
Iter: 512 loss: 3.34853576e-06
Iter: 513 loss: 3.34516858e-06
Iter: 514 loss: 3.35248774e-06
Iter: 515 loss: 3.34385732e-06
Iter: 516 loss: 3.33919797e-06
Iter: 517 loss: 3.35349296e-06
Iter: 518 loss: 3.33770959e-06
Iter: 519 loss: 3.3350168e-06
Iter: 520 loss: 3.34123251e-06
Iter: 521 loss: 3.33389607e-06
Iter: 522 loss: 3.33007665e-06
Iter: 523 loss: 3.33685261e-06
Iter: 524 loss: 3.32840682e-06
Iter: 525 loss: 3.32543686e-06
Iter: 526 loss: 3.34208175e-06
Iter: 527 loss: 3.32519835e-06
Iter: 528 loss: 3.3222982e-06
Iter: 529 loss: 3.32848253e-06
Iter: 530 loss: 3.32115405e-06
Iter: 531 loss: 3.32044692e-06
Iter: 532 loss: 3.31964088e-06
Iter: 533 loss: 3.31902879e-06
Iter: 534 loss: 3.31716137e-06
Iter: 535 loss: 3.32539526e-06
Iter: 536 loss: 3.31647107e-06
Iter: 537 loss: 3.31295132e-06
Iter: 538 loss: 3.31622641e-06
Iter: 539 loss: 3.31084379e-06
Iter: 540 loss: 3.30790454e-06
Iter: 541 loss: 3.31888077e-06
Iter: 542 loss: 3.30720013e-06
Iter: 543 loss: 3.30356534e-06
Iter: 544 loss: 3.30335479e-06
Iter: 545 loss: 3.30061926e-06
Iter: 546 loss: 3.29766544e-06
Iter: 547 loss: 3.3195488e-06
Iter: 548 loss: 3.29749741e-06
Iter: 549 loss: 3.29423801e-06
Iter: 550 loss: 3.29751674e-06
Iter: 551 loss: 3.29246268e-06
Iter: 552 loss: 3.28977103e-06
Iter: 553 loss: 3.30431271e-06
Iter: 554 loss: 3.28927626e-06
Iter: 555 loss: 3.28607143e-06
Iter: 556 loss: 3.28255419e-06
Iter: 557 loss: 3.28203532e-06
Iter: 558 loss: 3.27855878e-06
Iter: 559 loss: 3.30159128e-06
Iter: 560 loss: 3.27817725e-06
Iter: 561 loss: 3.27498492e-06
Iter: 562 loss: 3.29008571e-06
Iter: 563 loss: 3.27433554e-06
Iter: 564 loss: 3.27345742e-06
Iter: 565 loss: 3.27310158e-06
Iter: 566 loss: 3.27168482e-06
Iter: 567 loss: 3.2697e-06
Iter: 568 loss: 3.26977215e-06
Iter: 569 loss: 3.26728536e-06
Iter: 570 loss: 3.26743179e-06
Iter: 571 loss: 3.26535246e-06
Iter: 572 loss: 3.26286909e-06
Iter: 573 loss: 3.27218913e-06
Iter: 574 loss: 3.26233408e-06
Iter: 575 loss: 3.25943961e-06
Iter: 576 loss: 3.26205918e-06
Iter: 577 loss: 3.25769861e-06
Iter: 578 loss: 3.25515384e-06
Iter: 579 loss: 3.26390864e-06
Iter: 580 loss: 3.25434121e-06
Iter: 581 loss: 3.25143401e-06
Iter: 582 loss: 3.25726523e-06
Iter: 583 loss: 3.25020392e-06
Iter: 584 loss: 3.2475059e-06
Iter: 585 loss: 3.24755206e-06
Iter: 586 loss: 3.24542589e-06
Iter: 587 loss: 3.24192456e-06
Iter: 588 loss: 3.2831349e-06
Iter: 589 loss: 3.24192683e-06
Iter: 590 loss: 3.23950553e-06
Iter: 591 loss: 3.23865243e-06
Iter: 592 loss: 3.23743666e-06
Iter: 593 loss: 3.23452105e-06
Iter: 594 loss: 3.26722648e-06
Iter: 595 loss: 3.23436325e-06
Iter: 596 loss: 3.23229324e-06
Iter: 597 loss: 3.22908613e-06
Iter: 598 loss: 3.22894607e-06
Iter: 599 loss: 3.23019594e-06
Iter: 600 loss: 3.22720052e-06
Iter: 601 loss: 3.22592678e-06
Iter: 602 loss: 3.22536812e-06
Iter: 603 loss: 3.22475171e-06
Iter: 604 loss: 3.22336336e-06
Iter: 605 loss: 3.21991683e-06
Iter: 606 loss: 3.2492494e-06
Iter: 607 loss: 3.21936955e-06
Iter: 608 loss: 3.21671723e-06
Iter: 609 loss: 3.21665516e-06
Iter: 610 loss: 3.21432594e-06
Iter: 611 loss: 3.21325888e-06
Iter: 612 loss: 3.21220523e-06
Iter: 613 loss: 3.20883055e-06
Iter: 614 loss: 3.2347059e-06
Iter: 615 loss: 3.20860227e-06
Iter: 616 loss: 3.20655431e-06
Iter: 617 loss: 3.20537424e-06
Iter: 618 loss: 3.20464369e-06
Iter: 619 loss: 3.2011385e-06
Iter: 620 loss: 3.22056712e-06
Iter: 621 loss: 3.20076902e-06
Iter: 622 loss: 3.19854735e-06
Iter: 623 loss: 3.19985975e-06
Iter: 624 loss: 3.19734454e-06
Iter: 625 loss: 3.19395144e-06
Iter: 626 loss: 3.20571189e-06
Iter: 627 loss: 3.19296691e-06
Iter: 628 loss: 3.19074547e-06
Iter: 629 loss: 3.19055152e-06
Iter: 630 loss: 3.18890648e-06
Iter: 631 loss: 3.18664661e-06
Iter: 632 loss: 3.18659659e-06
Iter: 633 loss: 3.18469665e-06
Iter: 634 loss: 3.2034e-06
Iter: 635 loss: 3.18463117e-06
Iter: 636 loss: 3.18339016e-06
Iter: 637 loss: 3.18052321e-06
Iter: 638 loss: 3.21202879e-06
Iter: 639 loss: 3.18016782e-06
Iter: 640 loss: 3.17802869e-06
Iter: 641 loss: 3.18598177e-06
Iter: 642 loss: 3.17752801e-06
Iter: 643 loss: 3.17490117e-06
Iter: 644 loss: 3.18374214e-06
Iter: 645 loss: 3.17410741e-06
Iter: 646 loss: 3.17220156e-06
Iter: 647 loss: 3.17413e-06
Iter: 648 loss: 3.17095487e-06
Iter: 649 loss: 3.16783257e-06
Iter: 650 loss: 3.17641297e-06
Iter: 651 loss: 3.16684554e-06
Iter: 652 loss: 3.1647055e-06
Iter: 653 loss: 3.17838703e-06
Iter: 654 loss: 3.16439582e-06
Iter: 655 loss: 3.16236e-06
Iter: 656 loss: 3.15896432e-06
Iter: 657 loss: 3.15899752e-06
Iter: 658 loss: 3.15683201e-06
Iter: 659 loss: 3.15674811e-06
Iter: 660 loss: 3.15481839e-06
Iter: 661 loss: 3.15197758e-06
Iter: 662 loss: 3.15191483e-06
Iter: 663 loss: 3.14897989e-06
Iter: 664 loss: 3.18070488e-06
Iter: 665 loss: 3.14896079e-06
Iter: 666 loss: 3.14751151e-06
Iter: 667 loss: 3.14748695e-06
Iter: 668 loss: 3.1458103e-06
Iter: 669 loss: 3.14539284e-06
Iter: 670 loss: 3.14434578e-06
Iter: 671 loss: 3.14331e-06
Iter: 672 loss: 3.14193176e-06
Iter: 673 loss: 3.14182603e-06
Iter: 674 loss: 3.13925943e-06
Iter: 675 loss: 3.14402723e-06
Iter: 676 loss: 3.1381494e-06
Iter: 677 loss: 3.13615101e-06
Iter: 678 loss: 3.14136491e-06
Iter: 679 loss: 3.13552619e-06
Iter: 680 loss: 3.13311284e-06
Iter: 681 loss: 3.14222e-06
Iter: 682 loss: 3.13256896e-06
Iter: 683 loss: 3.13050487e-06
Iter: 684 loss: 3.13347618e-06
Iter: 685 loss: 3.12947805e-06
Iter: 686 loss: 3.12707698e-06
Iter: 687 loss: 3.14366434e-06
Iter: 688 loss: 3.12698489e-06
Iter: 689 loss: 3.12546968e-06
Iter: 690 loss: 3.12472025e-06
Iter: 691 loss: 3.12399288e-06
Iter: 692 loss: 3.12101133e-06
Iter: 693 loss: 3.12844395e-06
Iter: 694 loss: 3.11998247e-06
Iter: 695 loss: 3.11793838e-06
Iter: 696 loss: 3.12328712e-06
Iter: 697 loss: 3.11710141e-06
Iter: 698 loss: 3.11463373e-06
Iter: 699 loss: 3.12321185e-06
Iter: 700 loss: 3.11388931e-06
Iter: 701 loss: 3.11396707e-06
Iter: 702 loss: 3.11294298e-06
Iter: 703 loss: 3.11215422e-06
Iter: 704 loss: 3.11018835e-06
Iter: 705 loss: 3.12459e-06
Iter: 706 loss: 3.10971814e-06
Iter: 707 loss: 3.10708242e-06
Iter: 708 loss: 3.11375584e-06
Iter: 709 loss: 3.10612586e-06
Iter: 710 loss: 3.10454243e-06
Iter: 711 loss: 3.10293262e-06
Iter: 712 loss: 3.10257906e-06
Iter: 713 loss: 3.09942698e-06
Iter: 714 loss: 3.12449447e-06
Iter: 715 loss: 3.0993333e-06
Iter: 716 loss: 3.09728694e-06
Iter: 717 loss: 3.09450934e-06
Iter: 718 loss: 3.09446705e-06
Iter: 719 loss: 3.09222105e-06
Iter: 720 loss: 3.09200595e-06
Iter: 721 loss: 3.09024017e-06
Iter: 722 loss: 3.08962126e-06
Iter: 723 loss: 3.08857739e-06
Iter: 724 loss: 3.08638255e-06
Iter: 725 loss: 3.10618157e-06
Iter: 726 loss: 3.08622066e-06
Iter: 727 loss: 3.08444464e-06
Iter: 728 loss: 3.08442668e-06
Iter: 729 loss: 3.08302901e-06
Iter: 730 loss: 3.08052768e-06
Iter: 731 loss: 3.09476468e-06
Iter: 732 loss: 3.08017889e-06
Iter: 733 loss: 3.07869095e-06
Iter: 734 loss: 3.07869504e-06
Iter: 735 loss: 3.0772369e-06
Iter: 736 loss: 3.08179369e-06
Iter: 737 loss: 3.07667415e-06
Iter: 738 loss: 3.07576875e-06
Iter: 739 loss: 3.07525602e-06
Iter: 740 loss: 3.07483651e-06
Iter: 741 loss: 3.07343726e-06
Iter: 742 loss: 3.07083428e-06
Iter: 743 loss: 3.12625616e-06
Iter: 744 loss: 3.07083155e-06
Iter: 745 loss: 3.06813467e-06
Iter: 746 loss: 3.10966971e-06
Iter: 747 loss: 3.06818447e-06
Iter: 748 loss: 3.06609536e-06
Iter: 749 loss: 3.06383549e-06
Iter: 750 loss: 3.06340507e-06
Iter: 751 loss: 3.06146467e-06
Iter: 752 loss: 3.0614774e-06
Iter: 753 loss: 3.05997878e-06
Iter: 754 loss: 3.05733647e-06
Iter: 755 loss: 3.05737626e-06
Iter: 756 loss: 3.05499498e-06
Iter: 757 loss: 3.05498e-06
Iter: 758 loss: 3.05305434e-06
Iter: 759 loss: 3.05009826e-06
Iter: 760 loss: 3.05012372e-06
Iter: 761 loss: 3.04753121e-06
Iter: 762 loss: 3.08549215e-06
Iter: 763 loss: 3.04749074e-06
Iter: 764 loss: 3.04541163e-06
Iter: 765 loss: 3.0453723e-06
Iter: 766 loss: 3.04379591e-06
Iter: 767 loss: 3.04356104e-06
Iter: 768 loss: 3.04246646e-06
Iter: 769 loss: 3.04197465e-06
Iter: 770 loss: 3.04065611e-06
Iter: 771 loss: 3.04948185e-06
Iter: 772 loss: 3.04033392e-06
Iter: 773 loss: 3.03781985e-06
Iter: 774 loss: 3.03689853e-06
Iter: 775 loss: 3.03555498e-06
Iter: 776 loss: 3.03347633e-06
Iter: 777 loss: 3.05328649e-06
Iter: 778 loss: 3.0334179e-06
Iter: 779 loss: 3.03126626e-06
Iter: 780 loss: 3.03087882e-06
Iter: 781 loss: 3.02949979e-06
Iter: 782 loss: 3.02722265e-06
Iter: 783 loss: 3.047257e-06
Iter: 784 loss: 3.02705394e-06
Iter: 785 loss: 3.02516173e-06
Iter: 786 loss: 3.02837475e-06
Iter: 787 loss: 3.0242868e-06
Iter: 788 loss: 3.022491e-06
Iter: 789 loss: 3.02406897e-06
Iter: 790 loss: 3.02146373e-06
Iter: 791 loss: 3.01893988e-06
Iter: 792 loss: 3.02658373e-06
Iter: 793 loss: 3.01811315e-06
Iter: 794 loss: 3.01605496e-06
Iter: 795 loss: 3.01541718e-06
Iter: 796 loss: 3.01417731e-06
Iter: 797 loss: 3.01242812e-06
Iter: 798 loss: 3.01235514e-06
Iter: 799 loss: 3.01081582e-06
Iter: 800 loss: 3.00894453e-06
Iter: 801 loss: 3.0087815e-06
Iter: 802 loss: 3.00914257e-06
Iter: 803 loss: 3.00746456e-06
Iter: 804 loss: 3.00680199e-06
Iter: 805 loss: 3.00559327e-06
Iter: 806 loss: 3.02849162e-06
Iter: 807 loss: 3.00560168e-06
Iter: 808 loss: 3.00410102e-06
Iter: 809 loss: 3.00152283e-06
Iter: 810 loss: 3.00153374e-06
Iter: 811 loss: 2.99953717e-06
Iter: 812 loss: 3.02530952e-06
Iter: 813 loss: 2.99952308e-06
Iter: 814 loss: 2.99759472e-06
Iter: 815 loss: 2.9982134e-06
Iter: 816 loss: 2.99612384e-06
Iter: 817 loss: 2.9946159e-06
Iter: 818 loss: 3.00748297e-06
Iter: 819 loss: 2.99444378e-06
Iter: 820 loss: 2.99286171e-06
Iter: 821 loss: 2.99024123e-06
Iter: 822 loss: 2.99022508e-06
Iter: 823 loss: 2.98801115e-06
Iter: 824 loss: 3.01956629e-06
Iter: 825 loss: 2.98799387e-06
Iter: 826 loss: 2.98586474e-06
Iter: 827 loss: 2.98442546e-06
Iter: 828 loss: 2.98362238e-06
Iter: 829 loss: 2.98192094e-06
Iter: 830 loss: 2.98190685e-06
Iter: 831 loss: 2.98064197e-06
Iter: 832 loss: 2.98011037e-06
Iter: 833 loss: 2.97929228e-06
Iter: 834 loss: 2.97793349e-06
Iter: 835 loss: 2.97793122e-06
Iter: 836 loss: 2.97682891e-06
Iter: 837 loss: 2.98606574e-06
Iter: 838 loss: 2.9767366e-06
Iter: 839 loss: 2.97564634e-06
Iter: 840 loss: 2.97373231e-06
Iter: 841 loss: 3.01727823e-06
Iter: 842 loss: 2.97372571e-06
Iter: 843 loss: 2.97225642e-06
Iter: 844 loss: 2.97412907e-06
Iter: 845 loss: 2.97133556e-06
Iter: 846 loss: 2.969452e-06
Iter: 847 loss: 2.97389261e-06
Iter: 848 loss: 2.96870894e-06
Iter: 849 loss: 2.96676717e-06
Iter: 850 loss: 2.96640337e-06
Iter: 851 loss: 2.96510939e-06
Iter: 852 loss: 2.9631251e-06
Iter: 853 loss: 2.96310782e-06
Iter: 854 loss: 2.96200346e-06
Iter: 855 loss: 2.96063899e-06
Iter: 856 loss: 2.96052531e-06
Iter: 857 loss: 2.9579337e-06
Iter: 858 loss: 2.96990402e-06
Iter: 859 loss: 2.95752625e-06
Iter: 860 loss: 2.95603968e-06
Iter: 861 loss: 2.95712334e-06
Iter: 862 loss: 2.95506743e-06
Iter: 863 loss: 2.9527796e-06
Iter: 864 loss: 2.96198959e-06
Iter: 865 loss: 2.95218706e-06
Iter: 866 loss: 2.95088648e-06
Iter: 867 loss: 2.95162272e-06
Iter: 868 loss: 2.95006089e-06
Iter: 869 loss: 2.94789515e-06
Iter: 870 loss: 2.95811105e-06
Iter: 871 loss: 2.94751271e-06
Iter: 872 loss: 2.94662368e-06
Iter: 873 loss: 2.94640449e-06
Iter: 874 loss: 2.94590882e-06
Iter: 875 loss: 2.94460096e-06
Iter: 876 loss: 2.95943505e-06
Iter: 877 loss: 2.94450228e-06
Iter: 878 loss: 2.94257529e-06
Iter: 879 loss: 2.94230449e-06
Iter: 880 loss: 2.94100732e-06
Iter: 881 loss: 2.93931043e-06
Iter: 882 loss: 2.95278e-06
Iter: 883 loss: 2.93916037e-06
Iter: 884 loss: 2.93764106e-06
Iter: 885 loss: 2.93690982e-06
Iter: 886 loss: 2.93611856e-06
Iter: 887 loss: 2.93419657e-06
Iter: 888 loss: 2.94390429e-06
Iter: 889 loss: 2.93382277e-06
Iter: 890 loss: 2.93167159e-06
Iter: 891 loss: 2.93563971e-06
Iter: 892 loss: 2.93070229e-06
Iter: 893 loss: 2.92874893e-06
Iter: 894 loss: 2.93391304e-06
Iter: 895 loss: 2.92818186e-06
Iter: 896 loss: 2.92615368e-06
Iter: 897 loss: 2.93714447e-06
Iter: 898 loss: 2.92576169e-06
Iter: 899 loss: 2.92428103e-06
Iter: 900 loss: 2.9237151e-06
Iter: 901 loss: 2.92290224e-06
Iter: 902 loss: 2.92083632e-06
Iter: 903 loss: 2.94556298e-06
Iter: 904 loss: 2.92076197e-06
Iter: 905 loss: 2.9196608e-06
Iter: 906 loss: 2.92003506e-06
Iter: 907 loss: 2.91884908e-06
Iter: 908 loss: 2.9168159e-06
Iter: 909 loss: 2.93725225e-06
Iter: 910 loss: 2.91676452e-06
Iter: 911 loss: 2.91577544e-06
Iter: 912 loss: 2.91559e-06
Iter: 913 loss: 2.91487663e-06
Iter: 914 loss: 2.91403421e-06
Iter: 915 loss: 2.91341189e-06
Iter: 916 loss: 2.91306969e-06
Iter: 917 loss: 2.911102e-06
Iter: 918 loss: 2.91424794e-06
Iter: 919 loss: 2.91022843e-06
Iter: 920 loss: 2.90861203e-06
Iter: 921 loss: 2.91183323e-06
Iter: 922 loss: 2.9080154e-06
Iter: 923 loss: 2.90573735e-06
Iter: 924 loss: 2.91028391e-06
Iter: 925 loss: 2.90490243e-06
Iter: 926 loss: 2.90350317e-06
Iter: 927 loss: 2.90488833e-06
Iter: 928 loss: 2.90274238e-06
Iter: 929 loss: 2.90025855e-06
Iter: 930 loss: 2.90401886e-06
Iter: 931 loss: 2.89908758e-06
Iter: 932 loss: 2.89745185e-06
Iter: 933 loss: 2.90475145e-06
Iter: 934 loss: 2.8971026e-06
Iter: 935 loss: 2.89517493e-06
Iter: 936 loss: 2.89838204e-06
Iter: 937 loss: 2.8942377e-06
Iter: 938 loss: 2.89236459e-06
Iter: 939 loss: 2.89474019e-06
Iter: 940 loss: 2.89129639e-06
Iter: 941 loss: 2.89012223e-06
Iter: 942 loss: 2.88997671e-06
Iter: 943 loss: 2.88885303e-06
Iter: 944 loss: 2.89466652e-06
Iter: 945 loss: 2.8886061e-06
Iter: 946 loss: 2.88788806e-06
Iter: 947 loss: 2.88624e-06
Iter: 948 loss: 2.90063167e-06
Iter: 949 loss: 2.88592082e-06
Iter: 950 loss: 2.88396041e-06
Iter: 951 loss: 2.90041339e-06
Iter: 952 loss: 2.88378237e-06
Iter: 953 loss: 2.88239448e-06
Iter: 954 loss: 2.88195724e-06
Iter: 955 loss: 2.8810523e-06
Iter: 956 loss: 2.87885769e-06
Iter: 957 loss: 2.89663012e-06
Iter: 958 loss: 2.87868761e-06
Iter: 959 loss: 2.8775e-06
Iter: 960 loss: 2.87586909e-06
Iter: 961 loss: 2.87580679e-06
Iter: 962 loss: 2.87360695e-06
Iter: 963 loss: 2.90014941e-06
Iter: 964 loss: 2.87357921e-06
Iter: 965 loss: 2.87249486e-06
Iter: 966 loss: 2.87123612e-06
Iter: 967 loss: 2.87101966e-06
Iter: 968 loss: 2.86854674e-06
Iter: 969 loss: 2.87897751e-06
Iter: 970 loss: 2.8679051e-06
Iter: 971 loss: 2.86665545e-06
Iter: 972 loss: 2.87000353e-06
Iter: 973 loss: 2.86613158e-06
Iter: 974 loss: 2.86449449e-06
Iter: 975 loss: 2.86523073e-06
Iter: 976 loss: 2.86336626e-06
Iter: 977 loss: 2.86169734e-06
Iter: 978 loss: 2.86549152e-06
Iter: 979 loss: 2.86095883e-06
Iter: 980 loss: 2.85904343e-06
Iter: 981 loss: 2.87042758e-06
Iter: 982 loss: 2.8587649e-06
Iter: 983 loss: 2.8583072e-06
Iter: 984 loss: 2.85788769e-06
Iter: 985 loss: 2.85744409e-06
Iter: 986 loss: 2.85600822e-06
Iter: 987 loss: 2.85890974e-06
Iter: 988 loss: 2.85512897e-06
Iter: 989 loss: 2.85325768e-06
Iter: 990 loss: 2.87479452e-06
Iter: 991 loss: 2.8532429e-06
Iter: 992 loss: 2.85204078e-06
Iter: 993 loss: 2.85241822e-06
Iter: 994 loss: 2.85111e-06
Iter: 995 loss: 2.84926205e-06
Iter: 996 loss: 2.85450869e-06
Iter: 997 loss: 2.84863063e-06
Iter: 998 loss: 2.84685802e-06
Iter: 999 loss: 2.84821567e-06
Iter: 1000 loss: 2.845783e-06
Iter: 1001 loss: 2.84412044e-06
Iter: 1002 loss: 2.86497379e-06
Iter: 1003 loss: 2.84416501e-06
Iter: 1004 loss: 2.84304861e-06
Iter: 1005 loss: 2.84082853e-06
Iter: 1006 loss: 2.88418187e-06
Iter: 1007 loss: 2.84083262e-06
Iter: 1008 loss: 2.83958639e-06
Iter: 1009 loss: 2.83939471e-06
Iter: 1010 loss: 2.83822646e-06
Iter: 1011 loss: 2.83633108e-06
Iter: 1012 loss: 2.83625354e-06
Iter: 1013 loss: 2.83521445e-06
Iter: 1014 loss: 2.83516465e-06
Iter: 1015 loss: 2.83424833e-06
Iter: 1016 loss: 2.83732788e-06
Iter: 1017 loss: 2.83396253e-06
Iter: 1018 loss: 2.83249119e-06
Iter: 1019 loss: 2.8347747e-06
Iter: 1020 loss: 2.83189434e-06
Iter: 1021 loss: 2.83117924e-06
Iter: 1022 loss: 2.83137297e-06
Iter: 1023 loss: 2.83056852e-06
Iter: 1024 loss: 2.82939118e-06
Iter: 1025 loss: 2.82749556e-06
Iter: 1026 loss: 2.82749943e-06
Iter: 1027 loss: 2.82603787e-06
Iter: 1028 loss: 2.82602559e-06
Iter: 1029 loss: 2.8245e-06
Iter: 1030 loss: 2.82379847e-06
Iter: 1031 loss: 2.82297833e-06
Iter: 1032 loss: 2.82156725e-06
Iter: 1033 loss: 2.83905683e-06
Iter: 1034 loss: 2.82147835e-06
Iter: 1035 loss: 2.82043447e-06
Iter: 1036 loss: 2.81793518e-06
Iter: 1037 loss: 2.84937209e-06
Iter: 1038 loss: 2.81775283e-06
Iter: 1039 loss: 2.8167583e-06
Iter: 1040 loss: 2.81619077e-06
Iter: 1041 loss: 2.81523398e-06
Iter: 1042 loss: 2.8138893e-06
Iter: 1043 loss: 2.81377697e-06
Iter: 1044 loss: 2.81203347e-06
Iter: 1045 loss: 2.83062104e-06
Iter: 1046 loss: 2.8120055e-06
Iter: 1047 loss: 2.81084499e-06
Iter: 1048 loss: 2.80962945e-06
Iter: 1049 loss: 2.80939912e-06
Iter: 1050 loss: 2.81014854e-06
Iter: 1051 loss: 2.80861059e-06
Iter: 1052 loss: 2.8079121e-06
Iter: 1053 loss: 2.80774202e-06
Iter: 1054 loss: 2.8073423e-06
Iter: 1055 loss: 2.80635686e-06
Iter: 1056 loss: 2.80512609e-06
Iter: 1057 loss: 2.80510199e-06
Iter: 1058 loss: 2.80359518e-06
Iter: 1059 loss: 2.80850441e-06
Iter: 1060 loss: 2.80317408e-06
Iter: 1061 loss: 2.80142331e-06
Iter: 1062 loss: 2.80971949e-06
Iter: 1063 loss: 2.80114091e-06
Iter: 1064 loss: 2.7999e-06
Iter: 1065 loss: 2.80333279e-06
Iter: 1066 loss: 2.79941014e-06
Iter: 1067 loss: 2.79786559e-06
Iter: 1068 loss: 2.79614687e-06
Iter: 1069 loss: 2.79590176e-06
Iter: 1070 loss: 2.79434585e-06
Iter: 1071 loss: 2.81830899e-06
Iter: 1072 loss: 2.79434244e-06
Iter: 1073 loss: 2.7929218e-06
Iter: 1074 loss: 2.79141204e-06
Iter: 1075 loss: 2.79107667e-06
Iter: 1076 loss: 2.78929519e-06
Iter: 1077 loss: 2.79934034e-06
Iter: 1078 loss: 2.78913126e-06
Iter: 1079 loss: 2.78738116e-06
Iter: 1080 loss: 2.7896308e-06
Iter: 1081 loss: 2.78635525e-06
Iter: 1082 loss: 2.78601783e-06
Iter: 1083 loss: 2.78562675e-06
Iter: 1084 loss: 2.78486073e-06
Iter: 1085 loss: 2.78476296e-06
Iter: 1086 loss: 2.78425614e-06
Iter: 1087 loss: 2.78318885e-06
Iter: 1088 loss: 2.78312359e-06
Iter: 1089 loss: 2.78242533e-06
Iter: 1090 loss: 2.7812589e-06
Iter: 1091 loss: 2.780258e-06
Iter: 1092 loss: 2.77998652e-06
Iter: 1093 loss: 2.77784147e-06
Iter: 1094 loss: 2.79315691e-06
Iter: 1095 loss: 2.77771483e-06
Iter: 1096 loss: 2.77640856e-06
Iter: 1097 loss: 2.77875552e-06
Iter: 1098 loss: 2.77584832e-06
Iter: 1099 loss: 2.77401773e-06
Iter: 1100 loss: 2.7786125e-06
Iter: 1101 loss: 2.773387e-06
Iter: 1102 loss: 2.77212121e-06
Iter: 1103 loss: 2.77676668e-06
Iter: 1104 loss: 2.77185154e-06
Iter: 1105 loss: 2.77035451e-06
Iter: 1106 loss: 2.7695346e-06
Iter: 1107 loss: 2.76884089e-06
Iter: 1108 loss: 2.76723904e-06
Iter: 1109 loss: 2.78085895e-06
Iter: 1110 loss: 2.76708488e-06
Iter: 1111 loss: 2.76556693e-06
Iter: 1112 loss: 2.76704236e-06
Iter: 1113 loss: 2.76452192e-06
Iter: 1114 loss: 2.76307719e-06
Iter: 1115 loss: 2.76754508e-06
Iter: 1116 loss: 2.76268838e-06
Iter: 1117 loss: 2.76171431e-06
Iter: 1118 loss: 2.76166656e-06
Iter: 1119 loss: 2.76062883e-06
Iter: 1120 loss: 2.76058654e-06
Iter: 1121 loss: 2.75978573e-06
Iter: 1122 loss: 2.75901425e-06
Iter: 1123 loss: 2.7570668e-06
Iter: 1124 loss: 2.77754134e-06
Iter: 1125 loss: 2.75698631e-06
Iter: 1126 loss: 2.75567459e-06
Iter: 1127 loss: 2.75558386e-06
Iter: 1128 loss: 2.75442926e-06
Iter: 1129 loss: 2.75317871e-06
Iter: 1130 loss: 2.75295429e-06
Iter: 1131 loss: 2.7518372e-06
Iter: 1132 loss: 2.75182401e-06
Iter: 1133 loss: 2.75079265e-06
Iter: 1134 loss: 2.74982176e-06
Iter: 1135 loss: 2.74961144e-06
Iter: 1136 loss: 2.74789318e-06
Iter: 1137 loss: 2.76402761e-06
Iter: 1138 loss: 2.74783497e-06
Iter: 1139 loss: 2.74656077e-06
Iter: 1140 loss: 2.7455385e-06
Iter: 1141 loss: 2.74518243e-06
Iter: 1142 loss: 2.74374406e-06
Iter: 1143 loss: 2.76345236e-06
Iter: 1144 loss: 2.74377703e-06
Iter: 1145 loss: 2.74251306e-06
Iter: 1146 loss: 2.74046351e-06
Iter: 1147 loss: 2.7404576e-06
Iter: 1148 loss: 2.74088052e-06
Iter: 1149 loss: 2.73962587e-06
Iter: 1150 loss: 2.73898263e-06
Iter: 1151 loss: 2.74016907e-06
Iter: 1152 loss: 2.73867886e-06
Iter: 1153 loss: 2.73797264e-06
Iter: 1154 loss: 2.73663272e-06
Iter: 1155 loss: 2.76327637e-06
Iter: 1156 loss: 2.73663454e-06
Iter: 1157 loss: 2.7349588e-06
Iter: 1158 loss: 2.74279137e-06
Iter: 1159 loss: 2.73473415e-06
Iter: 1160 loss: 2.73346768e-06
Iter: 1161 loss: 2.7328897e-06
Iter: 1162 loss: 2.7322053e-06
Iter: 1163 loss: 2.73074147e-06
Iter: 1164 loss: 2.75226103e-06
Iter: 1165 loss: 2.73072601e-06
Iter: 1166 loss: 2.72971238e-06
Iter: 1167 loss: 2.72910438e-06
Iter: 1168 loss: 2.72874922e-06
Iter: 1169 loss: 2.72719308e-06
Iter: 1170 loss: 2.74342256e-06
Iter: 1171 loss: 2.72724037e-06
Iter: 1172 loss: 2.72632678e-06
Iter: 1173 loss: 2.72634793e-06
Iter: 1174 loss: 2.72556736e-06
Iter: 1175 loss: 2.72404577e-06
Iter: 1176 loss: 2.72950365e-06
Iter: 1177 loss: 2.72370562e-06
Iter: 1178 loss: 2.72263787e-06
Iter: 1179 loss: 2.72422881e-06
Iter: 1180 loss: 2.72212856e-06
Iter: 1181 loss: 2.72096895e-06
Iter: 1182 loss: 2.72844818e-06
Iter: 1183 loss: 2.72085936e-06
Iter: 1184 loss: 2.72054604e-06
Iter: 1185 loss: 2.72038824e-06
Iter: 1186 loss: 2.71992394e-06
Iter: 1187 loss: 2.7185929e-06
Iter: 1188 loss: 2.72511306e-06
Iter: 1189 loss: 2.71822114e-06
Iter: 1190 loss: 2.71690396e-06
Iter: 1191 loss: 2.72612306e-06
Iter: 1192 loss: 2.71679619e-06
Iter: 1193 loss: 2.71569297e-06
Iter: 1194 loss: 2.71454292e-06
Iter: 1195 loss: 2.71435374e-06
Iter: 1196 loss: 2.7129804e-06
Iter: 1197 loss: 2.71297495e-06
Iter: 1198 loss: 2.71205226e-06
Iter: 1199 loss: 2.71076465e-06
Iter: 1200 loss: 2.71071576e-06
Iter: 1201 loss: 2.70948294e-06
Iter: 1202 loss: 2.70939927e-06
Iter: 1203 loss: 2.70850592e-06
Iter: 1204 loss: 2.70852047e-06
Iter: 1205 loss: 2.70780765e-06
Iter: 1206 loss: 2.70617602e-06
Iter: 1207 loss: 2.70819055e-06
Iter: 1208 loss: 2.70541568e-06
Iter: 1209 loss: 2.70415899e-06
Iter: 1210 loss: 2.70464216e-06
Iter: 1211 loss: 2.70330293e-06
Iter: 1212 loss: 2.70173086e-06
Iter: 1213 loss: 2.71238787e-06
Iter: 1214 loss: 2.70156943e-06
Iter: 1215 loss: 2.7003025e-06
Iter: 1216 loss: 2.70272858e-06
Iter: 1217 loss: 2.69987368e-06
Iter: 1218 loss: 2.69836937e-06
Iter: 1219 loss: 2.69841053e-06
Iter: 1220 loss: 2.69787506e-06
Iter: 1221 loss: 2.6967698e-06
Iter: 1222 loss: 2.71509703e-06
Iter: 1223 loss: 2.69670227e-06
Iter: 1224 loss: 2.6952639e-06
Iter: 1225 loss: 2.69708335e-06
Iter: 1226 loss: 2.69460088e-06
Iter: 1227 loss: 2.69333668e-06
Iter: 1228 loss: 2.69779616e-06
Iter: 1229 loss: 2.69301358e-06
Iter: 1230 loss: 2.69143061e-06
Iter: 1231 loss: 2.69395446e-06
Iter: 1232 loss: 2.69078691e-06
Iter: 1233 loss: 2.68942381e-06
Iter: 1234 loss: 2.6936259e-06
Iter: 1235 loss: 2.68902318e-06
Iter: 1236 loss: 2.68754434e-06
Iter: 1237 loss: 2.69323755e-06
Iter: 1238 loss: 2.68720464e-06
Iter: 1239 loss: 2.68630083e-06
Iter: 1240 loss: 2.69377392e-06
Iter: 1241 loss: 2.68627855e-06
Iter: 1242 loss: 2.68550298e-06
Iter: 1243 loss: 2.68407734e-06
Iter: 1244 loss: 2.68405029e-06
Iter: 1245 loss: 2.68293525e-06
Iter: 1246 loss: 2.69519387e-06
Iter: 1247 loss: 2.68287363e-06
Iter: 1248 loss: 2.6819107e-06
Iter: 1249 loss: 2.68183294e-06
Iter: 1250 loss: 2.68113e-06
Iter: 1251 loss: 2.68120084e-06
Iter: 1252 loss: 2.68055828e-06
Iter: 1253 loss: 2.68006e-06
Iter: 1254 loss: 2.67950099e-06
Iter: 1255 loss: 2.67947735e-06
Iter: 1256 loss: 2.67851647e-06
Iter: 1257 loss: 2.67796531e-06
Iter: 1258 loss: 2.67757878e-06
Iter: 1259 loss: 2.67663063e-06
Iter: 1260 loss: 2.67681571e-06
Iter: 1261 loss: 2.67576729e-06
Iter: 1262 loss: 2.67399741e-06
Iter: 1263 loss: 2.68087183e-06
Iter: 1264 loss: 2.67360451e-06
Iter: 1265 loss: 2.67236214e-06
Iter: 1266 loss: 2.6735147e-06
Iter: 1267 loss: 2.67161067e-06
Iter: 1268 loss: 2.67020641e-06
Iter: 1269 loss: 2.68113718e-06
Iter: 1270 loss: 2.67002747e-06
Iter: 1271 loss: 2.66881761e-06
Iter: 1272 loss: 2.66860343e-06
Iter: 1273 loss: 2.66778852e-06
Iter: 1274 loss: 2.66652387e-06
Iter: 1275 loss: 2.68640633e-06
Iter: 1276 loss: 2.6665648e-06
Iter: 1277 loss: 2.66562301e-06
Iter: 1278 loss: 2.66526354e-06
Iter: 1279 loss: 2.66478037e-06
Iter: 1280 loss: 2.66325287e-06
Iter: 1281 loss: 2.67282394e-06
Iter: 1282 loss: 2.66306688e-06
Iter: 1283 loss: 2.66216284e-06
Iter: 1284 loss: 2.66383586e-06
Iter: 1285 loss: 2.66175675e-06
Iter: 1286 loss: 2.66082225e-06
Iter: 1287 loss: 2.66084226e-06
Iter: 1288 loss: 2.66031566e-06
Iter: 1289 loss: 2.65982885e-06
Iter: 1290 loss: 2.65978815e-06
Iter: 1291 loss: 2.65896415e-06
Iter: 1292 loss: 2.65721496e-06
Iter: 1293 loss: 2.67769769e-06
Iter: 1294 loss: 2.65715266e-06
Iter: 1295 loss: 2.65575522e-06
Iter: 1296 loss: 2.65569724e-06
Iter: 1297 loss: 2.65473341e-06
Iter: 1298 loss: 2.6538919e-06
Iter: 1299 loss: 2.65361291e-06
Iter: 1300 loss: 2.65233712e-06
Iter: 1301 loss: 2.66636562e-06
Iter: 1302 loss: 2.6523328e-06
Iter: 1303 loss: 2.65116887e-06
Iter: 1304 loss: 2.65120025e-06
Iter: 1305 loss: 2.65030485e-06
Iter: 1306 loss: 2.64918526e-06
Iter: 1307 loss: 2.65845802e-06
Iter: 1308 loss: 2.6491175e-06
Iter: 1309 loss: 2.64812775e-06
Iter: 1310 loss: 2.64853747e-06
Iter: 1311 loss: 2.64743949e-06
Iter: 1312 loss: 2.6465159e-06
Iter: 1313 loss: 2.65841868e-06
Iter: 1314 loss: 2.6465068e-06
Iter: 1315 loss: 2.64573782e-06
Iter: 1316 loss: 2.64723963e-06
Iter: 1317 loss: 2.64538198e-06
Iter: 1318 loss: 2.6449602e-06
Iter: 1319 loss: 2.64492633e-06
Iter: 1320 loss: 2.64455662e-06
Iter: 1321 loss: 2.64421828e-06
Iter: 1322 loss: 2.64405344e-06
Iter: 1323 loss: 2.64345272e-06
Iter: 1324 loss: 2.64192522e-06
Iter: 1325 loss: 2.65757944e-06
Iter: 1326 loss: 2.64175401e-06
Iter: 1327 loss: 2.64064965e-06
Iter: 1328 loss: 2.64053392e-06
Iter: 1329 loss: 2.63971287e-06
Iter: 1330 loss: 2.63839888e-06
Iter: 1331 loss: 2.63839343e-06
Iter: 1332 loss: 2.63706806e-06
Iter: 1333 loss: 2.65377594e-06
Iter: 1334 loss: 2.63709398e-06
Iter: 1335 loss: 2.63613038e-06
Iter: 1336 loss: 2.63597167e-06
Iter: 1337 loss: 2.6351513e-06
Iter: 1338 loss: 2.63406105e-06
Iter: 1339 loss: 2.64631853e-06
Iter: 1340 loss: 2.63411084e-06
Iter: 1341 loss: 2.63323091e-06
Iter: 1342 loss: 2.63218226e-06
Iter: 1343 loss: 2.63212814e-06
Iter: 1344 loss: 2.63082325e-06
Iter: 1345 loss: 2.64208688e-06
Iter: 1346 loss: 2.630773e-06
Iter: 1347 loss: 2.6298178e-06
Iter: 1348 loss: 2.63295533e-06
Iter: 1349 loss: 2.62936192e-06
Iter: 1350 loss: 2.62866934e-06
Iter: 1351 loss: 2.6393775e-06
Iter: 1352 loss: 2.62864341e-06
Iter: 1353 loss: 2.62807339e-06
Iter: 1354 loss: 2.62860704e-06
Iter: 1355 loss: 2.62769368e-06
Iter: 1356 loss: 2.62705089e-06
Iter: 1357 loss: 2.62589356e-06
Iter: 1358 loss: 2.65504468e-06
Iter: 1359 loss: 2.6258549e-06
Iter: 1360 loss: 2.62453682e-06
Iter: 1361 loss: 2.62972662e-06
Iter: 1362 loss: 2.62428784e-06
Iter: 1363 loss: 2.62288404e-06
Iter: 1364 loss: 2.62286267e-06
Iter: 1365 loss: 2.62168487e-06
Iter: 1366 loss: 2.6204475e-06
Iter: 1367 loss: 2.63639026e-06
Iter: 1368 loss: 2.62038861e-06
Iter: 1369 loss: 2.61920695e-06
Iter: 1370 loss: 2.61789341e-06
Iter: 1371 loss: 2.61767468e-06
Iter: 1372 loss: 2.61644209e-06
Iter: 1373 loss: 2.63625793e-06
Iter: 1374 loss: 2.61641162e-06
Iter: 1375 loss: 2.61530886e-06
Iter: 1376 loss: 2.61427431e-06
Iter: 1377 loss: 2.61394553e-06
Iter: 1378 loss: 2.6127102e-06
Iter: 1379 loss: 2.62707067e-06
Iter: 1380 loss: 2.61271111e-06
Iter: 1381 loss: 2.61159471e-06
Iter: 1382 loss: 2.61157788e-06
Iter: 1383 loss: 2.61068681e-06
Iter: 1384 loss: 2.61004698e-06
Iter: 1385 loss: 2.60989646e-06
Iter: 1386 loss: 2.6093644e-06
Iter: 1387 loss: 2.60957177e-06
Iter: 1388 loss: 2.60903107e-06
Iter: 1389 loss: 2.60836805e-06
Iter: 1390 loss: 2.60774914e-06
Iter: 1391 loss: 2.60753791e-06
Iter: 1392 loss: 2.60654087e-06
Iter: 1393 loss: 2.60831371e-06
Iter: 1394 loss: 2.60604952e-06
Iter: 1395 loss: 2.60487468e-06
Iter: 1396 loss: 2.6049363e-06
Iter: 1397 loss: 2.60384445e-06
Iter: 1398 loss: 2.60253864e-06
Iter: 1399 loss: 2.60898764e-06
Iter: 1400 loss: 2.60228944e-06
Iter: 1401 loss: 2.60082743e-06
Iter: 1402 loss: 2.60350771e-06
Iter: 1403 loss: 2.60015577e-06
Iter: 1404 loss: 2.59897047e-06
Iter: 1405 loss: 2.60405204e-06
Iter: 1406 loss: 2.59869967e-06
Iter: 1407 loss: 2.59740318e-06
Iter: 1408 loss: 2.59999206e-06
Iter: 1409 loss: 2.5967e-06
Iter: 1410 loss: 2.59566241e-06
Iter: 1411 loss: 2.59741751e-06
Iter: 1412 loss: 2.5952404e-06
Iter: 1413 loss: 2.59347712e-06
Iter: 1414 loss: 2.59641138e-06
Iter: 1415 loss: 2.59276067e-06
Iter: 1416 loss: 2.59270587e-06
Iter: 1417 loss: 2.59225e-06
Iter: 1418 loss: 2.59171748e-06
Iter: 1419 loss: 2.59143189e-06
Iter: 1420 loss: 2.59125954e-06
Iter: 1421 loss: 2.5903264e-06
Iter: 1422 loss: 2.58964837e-06
Iter: 1423 loss: 2.58933164e-06
Iter: 1424 loss: 2.58823411e-06
Iter: 1425 loss: 2.59221088e-06
Iter: 1426 loss: 2.58796308e-06
Iter: 1427 loss: 2.58672344e-06
Iter: 1428 loss: 2.58641853e-06
Iter: 1429 loss: 2.58579644e-06
Iter: 1430 loss: 2.58444902e-06
Iter: 1431 loss: 2.59048102e-06
Iter: 1432 loss: 2.58418049e-06
Iter: 1433 loss: 2.58275395e-06
Iter: 1434 loss: 2.58563318e-06
Iter: 1435 loss: 2.58217779e-06
Iter: 1436 loss: 2.58078444e-06
Iter: 1437 loss: 2.58226123e-06
Iter: 1438 loss: 2.57998818e-06
Iter: 1439 loss: 2.57832971e-06
Iter: 1440 loss: 2.58986802e-06
Iter: 1441 loss: 2.57817283e-06
Iter: 1442 loss: 2.57683314e-06
Iter: 1443 loss: 2.57554893e-06
Iter: 1444 loss: 2.5752945e-06
Iter: 1445 loss: 2.57420515e-06
Iter: 1446 loss: 2.57407942e-06
Iter: 1447 loss: 2.57330225e-06
Iter: 1448 loss: 2.57445618e-06
Iter: 1449 loss: 2.57297256e-06
Iter: 1450 loss: 2.57194142e-06
Iter: 1451 loss: 2.57758666e-06
Iter: 1452 loss: 2.57176293e-06
Iter: 1453 loss: 2.57116199e-06
Iter: 1454 loss: 2.57180545e-06
Iter: 1455 loss: 2.57080342e-06
Iter: 1456 loss: 2.57029e-06
Iter: 1457 loss: 2.56970225e-06
Iter: 1458 loss: 2.56957e-06
Iter: 1459 loss: 2.56840372e-06
Iter: 1460 loss: 2.57000488e-06
Iter: 1461 loss: 2.56784051e-06
Iter: 1462 loss: 2.56682119e-06
Iter: 1463 loss: 2.56879457e-06
Iter: 1464 loss: 2.56638396e-06
Iter: 1465 loss: 2.56529188e-06
Iter: 1466 loss: 2.57171405e-06
Iter: 1467 loss: 2.56515955e-06
Iter: 1468 loss: 2.56429303e-06
Iter: 1469 loss: 2.56398926e-06
Iter: 1470 loss: 2.56347766e-06
Iter: 1471 loss: 2.56217913e-06
Iter: 1472 loss: 2.57194347e-06
Iter: 1473 loss: 2.56205294e-06
Iter: 1474 loss: 2.56094199e-06
Iter: 1475 loss: 2.56079147e-06
Iter: 1476 loss: 2.56002204e-06
Iter: 1477 loss: 2.55903797e-06
Iter: 1478 loss: 2.57201464e-06
Iter: 1479 loss: 2.55899431e-06
Iter: 1480 loss: 2.55801206e-06
Iter: 1481 loss: 2.55929081e-06
Iter: 1482 loss: 2.55755413e-06
Iter: 1483 loss: 2.55676696e-06
Iter: 1484 loss: 2.55669784e-06
Iter: 1485 loss: 2.55634268e-06
Iter: 1486 loss: 2.55614168e-06
Iter: 1487 loss: 2.5559923e-06
Iter: 1488 loss: 2.5553511e-06
Iter: 1489 loss: 2.5543327e-06
Iter: 1490 loss: 2.55431542e-06
Iter: 1491 loss: 2.55318946e-06
Iter: 1492 loss: 2.56590374e-06
Iter: 1493 loss: 2.55315217e-06
Iter: 1494 loss: 2.55231066e-06
Iter: 1495 loss: 2.55170767e-06
Iter: 1496 loss: 2.55136297e-06
Iter: 1497 loss: 2.55023429e-06
Iter: 1498 loss: 2.56277417e-06
Iter: 1499 loss: 2.55016334e-06
Iter: 1500 loss: 2.5494071e-06
Iter: 1501 loss: 2.54874976e-06
Iter: 1502 loss: 2.54842871e-06
Iter: 1503 loss: 2.54699739e-06
Iter: 1504 loss: 2.55658119e-06
Iter: 1505 loss: 2.54691804e-06
Iter: 1506 loss: 2.54567863e-06
Iter: 1507 loss: 2.54571546e-06
Iter: 1508 loss: 2.54478164e-06
Iter: 1509 loss: 2.54357246e-06
Iter: 1510 loss: 2.55318582e-06
Iter: 1511 loss: 2.54351789e-06
Iter: 1512 loss: 2.54243446e-06
Iter: 1513 loss: 2.5445911e-06
Iter: 1514 loss: 2.54199767e-06
Iter: 1515 loss: 2.54199335e-06
Iter: 1516 loss: 2.54158272e-06
Iter: 1517 loss: 2.54124325e-06
Iter: 1518 loss: 2.54060933e-06
Iter: 1519 loss: 2.55243094e-06
Iter: 1520 loss: 2.54063434e-06
Iter: 1521 loss: 2.53969665e-06
Iter: 1522 loss: 2.53926669e-06
Iter: 1523 loss: 2.53882627e-06
Iter: 1524 loss: 2.53792746e-06
Iter: 1525 loss: 2.54456836e-06
Iter: 1526 loss: 2.53782196e-06
Iter: 1527 loss: 2.53688495e-06
Iter: 1528 loss: 2.53607368e-06
Iter: 1529 loss: 2.53574626e-06
Iter: 1530 loss: 2.53467306e-06
Iter: 1531 loss: 2.54385668e-06
Iter: 1532 loss: 2.53461803e-06
Iter: 1533 loss: 2.5334507e-06
Iter: 1534 loss: 2.53333769e-06
Iter: 1535 loss: 2.53245435e-06
Iter: 1536 loss: 2.53136386e-06
Iter: 1537 loss: 2.54358065e-06
Iter: 1538 loss: 2.53129338e-06
Iter: 1539 loss: 2.53046164e-06
Iter: 1540 loss: 2.53025883e-06
Iter: 1541 loss: 2.52959126e-06
Iter: 1542 loss: 2.52853624e-06
Iter: 1543 loss: 2.53580765e-06
Iter: 1544 loss: 2.52844984e-06
Iter: 1545 loss: 2.52764153e-06
Iter: 1546 loss: 2.53142707e-06
Iter: 1547 loss: 2.52749169e-06
Iter: 1548 loss: 2.52706241e-06
Iter: 1549 loss: 2.52704012e-06
Iter: 1550 loss: 2.52667837e-06
Iter: 1551 loss: 2.52597602e-06
Iter: 1552 loss: 2.52597192e-06
Iter: 1553 loss: 2.52508676e-06
Iter: 1554 loss: 2.52652e-06
Iter: 1555 loss: 2.52470181e-06
Iter: 1556 loss: 2.5240422e-06
Iter: 1557 loss: 2.5245613e-06
Iter: 1558 loss: 2.52353038e-06
Iter: 1559 loss: 2.52245195e-06
Iter: 1560 loss: 2.52353038e-06
Iter: 1561 loss: 2.52179598e-06
Iter: 1562 loss: 2.5208119e-06
Iter: 1563 loss: 2.52421364e-06
Iter: 1564 loss: 2.52054497e-06
Iter: 1565 loss: 2.51945585e-06
Iter: 1566 loss: 2.52178143e-06
Iter: 1567 loss: 2.51900042e-06
Iter: 1568 loss: 2.5179088e-06
Iter: 1569 loss: 2.51985352e-06
Iter: 1570 loss: 2.51748634e-06
Iter: 1571 loss: 2.51588699e-06
Iter: 1572 loss: 2.51768347e-06
Iter: 1573 loss: 2.51502706e-06
Iter: 1574 loss: 2.51397023e-06
Iter: 1575 loss: 2.51998677e-06
Iter: 1576 loss: 2.51376719e-06
Iter: 1577 loss: 2.51276879e-06
Iter: 1578 loss: 2.51531651e-06
Iter: 1579 loss: 2.51234451e-06
Iter: 1580 loss: 2.51192e-06
Iter: 1581 loss: 2.51181609e-06
Iter: 1582 loss: 2.51125425e-06
Iter: 1583 loss: 2.51070219e-06
Iter: 1584 loss: 2.51065921e-06
Iter: 1585 loss: 2.50981361e-06
Iter: 1586 loss: 2.51127358e-06
Iter: 1587 loss: 2.50949165e-06
Iter: 1588 loss: 2.50874359e-06
Iter: 1589 loss: 2.50827406e-06
Iter: 1590 loss: 2.50790185e-06
Iter: 1591 loss: 2.50646121e-06
Iter: 1592 loss: 2.51412348e-06
Iter: 1593 loss: 2.50627477e-06
Iter: 1594 loss: 2.50547146e-06
Iter: 1595 loss: 2.50574158e-06
Iter: 1596 loss: 2.50491621e-06
Iter: 1597 loss: 2.50380162e-06
Iter: 1598 loss: 2.50853554e-06
Iter: 1599 loss: 2.50345329e-06
Iter: 1600 loss: 2.50241101e-06
Iter: 1601 loss: 2.50225867e-06
Iter: 1602 loss: 2.5015388e-06
Iter: 1603 loss: 2.50001631e-06
Iter: 1604 loss: 2.51263918e-06
Iter: 1605 loss: 2.49987306e-06
Iter: 1606 loss: 2.49910522e-06
Iter: 1607 loss: 2.49856453e-06
Iter: 1608 loss: 2.49828645e-06
Iter: 1609 loss: 2.49692584e-06
Iter: 1610 loss: 2.50898529e-06
Iter: 1611 loss: 2.49682262e-06
Iter: 1612 loss: 2.49636469e-06
Iter: 1613 loss: 2.49630057e-06
Iter: 1614 loss: 2.49578125e-06
Iter: 1615 loss: 2.49554751e-06
Iter: 1616 loss: 2.49523941e-06
Iter: 1617 loss: 2.49454479e-06
Iter: 1618 loss: 2.49482332e-06
Iter: 1619 loss: 2.49399136e-06
Iter: 1620 loss: 2.493078e-06
Iter: 1621 loss: 2.4927765e-06
Iter: 1622 loss: 2.49228356e-06
Iter: 1623 loss: 2.49111099e-06
Iter: 1624 loss: 2.50230869e-06
Iter: 1625 loss: 2.49108643e-06
Iter: 1626 loss: 2.49025379e-06
Iter: 1627 loss: 2.48923925e-06
Iter: 1628 loss: 2.48918423e-06
Iter: 1629 loss: 2.48795368e-06
Iter: 1630 loss: 2.50308e-06
Iter: 1631 loss: 2.48790502e-06
Iter: 1632 loss: 2.48700371e-06
Iter: 1633 loss: 2.48592983e-06
Iter: 1634 loss: 2.48579659e-06
Iter: 1635 loss: 2.48450692e-06
Iter: 1636 loss: 2.50408175e-06
Iter: 1637 loss: 2.48449487e-06
Iter: 1638 loss: 2.48367087e-06
Iter: 1639 loss: 2.48238371e-06
Iter: 1640 loss: 2.4823089e-06
Iter: 1641 loss: 2.48136848e-06
Iter: 1642 loss: 2.48131073e-06
Iter: 1643 loss: 2.48072e-06
Iter: 1644 loss: 2.48860124e-06
Iter: 1645 loss: 2.48064885e-06
Iter: 1646 loss: 2.4799192e-06
Iter: 1647 loss: 2.48025935e-06
Iter: 1648 loss: 2.47949401e-06
Iter: 1649 loss: 2.47889648e-06
Iter: 1650 loss: 2.47929438e-06
Iter: 1651 loss: 2.47850949e-06
Iter: 1652 loss: 2.4776773e-06
Iter: 1653 loss: 2.4771648e-06
Iter: 1654 loss: 2.47681987e-06
Iter: 1655 loss: 2.4756896e-06
Iter: 1656 loss: 2.4855276e-06
Iter: 1657 loss: 2.47561547e-06
Iter: 1658 loss: 2.47470962e-06
Iter: 1659 loss: 2.4734436e-06
Iter: 1660 loss: 2.47338789e-06
Iter: 1661 loss: 2.47213552e-06
Iter: 1662 loss: 2.48723904e-06
Iter: 1663 loss: 2.47205662e-06
Iter: 1664 loss: 2.47091884e-06
Iter: 1665 loss: 2.47075786e-06
Iter: 1666 loss: 2.46994477e-06
Iter: 1667 loss: 2.46896366e-06
Iter: 1668 loss: 2.48216338e-06
Iter: 1669 loss: 2.46889908e-06
Iter: 1670 loss: 2.46813147e-06
Iter: 1671 loss: 2.46665559e-06
Iter: 1672 loss: 2.46661239e-06
Iter: 1673 loss: 2.46545233e-06
Iter: 1674 loss: 2.47716594e-06
Iter: 1675 loss: 2.46548097e-06
Iter: 1676 loss: 2.46469517e-06
Iter: 1677 loss: 2.46470404e-06
Iter: 1678 loss: 2.46397758e-06
Iter: 1679 loss: 2.46684522e-06
Iter: 1680 loss: 2.46380296e-06
Iter: 1681 loss: 2.46341e-06
Iter: 1682 loss: 2.46267132e-06
Iter: 1683 loss: 2.47770095e-06
Iter: 1684 loss: 2.46269315e-06
Iter: 1685 loss: 2.46147897e-06
Iter: 1686 loss: 2.46261197e-06
Iter: 1687 loss: 2.46075501e-06
Iter: 1688 loss: 2.45977481e-06
Iter: 1689 loss: 2.46939499e-06
Iter: 1690 loss: 2.45976298e-06
Iter: 1691 loss: 2.45888123e-06
Iter: 1692 loss: 2.45814363e-06
Iter: 1693 loss: 2.45789079e-06
Iter: 1694 loss: 2.45681326e-06
Iter: 1695 loss: 2.46345735e-06
Iter: 1696 loss: 2.45665046e-06
Iter: 1697 loss: 2.45563933e-06
Iter: 1698 loss: 2.45688898e-06
Iter: 1699 loss: 2.45505043e-06
Iter: 1700 loss: 2.45400406e-06
Iter: 1701 loss: 2.458371e-06
Iter: 1702 loss: 2.4538349e-06
Iter: 1703 loss: 2.45272395e-06
Iter: 1704 loss: 2.4543649e-06
Iter: 1705 loss: 2.45213278e-06
Iter: 1706 loss: 2.45111482e-06
Iter: 1707 loss: 2.45077808e-06
Iter: 1708 loss: 2.45016736e-06
Iter: 1709 loss: 2.44867715e-06
Iter: 1710 loss: 2.46623313e-06
Iter: 1711 loss: 2.44866305e-06
Iter: 1712 loss: 2.44843523e-06
Iter: 1713 loss: 2.44813646e-06
Iter: 1714 loss: 2.44787179e-06
Iter: 1715 loss: 2.44696184e-06
Iter: 1716 loss: 2.44884404e-06
Iter: 1717 loss: 2.4463759e-06
Iter: 1718 loss: 2.44516923e-06
Iter: 1719 loss: 2.45833348e-06
Iter: 1720 loss: 2.44513558e-06
Iter: 1721 loss: 2.4444289e-06
Iter: 1722 loss: 2.44460307e-06
Iter: 1723 loss: 2.44389685e-06
Iter: 1724 loss: 2.44298303e-06
Iter: 1725 loss: 2.44926218e-06
Iter: 1726 loss: 2.44287094e-06
Iter: 1727 loss: 2.44219382e-06
Iter: 1728 loss: 2.44126204e-06
Iter: 1729 loss: 2.44115927e-06
Iter: 1730 loss: 2.44023772e-06
Iter: 1731 loss: 2.45413889e-06
Iter: 1732 loss: 2.44026796e-06
Iter: 1733 loss: 2.4395722e-06
Iter: 1734 loss: 2.43915747e-06
Iter: 1735 loss: 2.43887143e-06
Iter: 1736 loss: 2.43795057e-06
Iter: 1737 loss: 2.4397616e-06
Iter: 1738 loss: 2.43764453e-06
Iter: 1739 loss: 2.43656086e-06
Iter: 1740 loss: 2.44425496e-06
Iter: 1741 loss: 2.43643785e-06
Iter: 1742 loss: 2.43591967e-06
Iter: 1743 loss: 2.43642444e-06
Iter: 1744 loss: 2.43549607e-06
Iter: 1745 loss: 2.43492582e-06
Iter: 1746 loss: 2.43495333e-06
Iter: 1747 loss: 2.43436671e-06
Iter: 1748 loss: 2.43739919e-06
Iter: 1749 loss: 2.43427939e-06
Iter: 1750 loss: 2.43398335e-06
Iter: 1751 loss: 2.43318937e-06
Iter: 1752 loss: 2.44153193e-06
Iter: 1753 loss: 2.4331157e-06
Iter: 1754 loss: 2.43201339e-06
Iter: 1755 loss: 2.43760951e-06
Iter: 1756 loss: 2.43183922e-06
Iter: 1757 loss: 2.43119894e-06
Iter: 1758 loss: 2.43247496e-06
Iter: 1759 loss: 2.43088698e-06
Iter: 1760 loss: 2.42993906e-06
Iter: 1761 loss: 2.42934811e-06
Iter: 1762 loss: 2.42888564e-06
Iter: 1763 loss: 2.42794067e-06
Iter: 1764 loss: 2.43655541e-06
Iter: 1765 loss: 2.42791157e-06
Iter: 1766 loss: 2.42693295e-06
Iter: 1767 loss: 2.42672286e-06
Iter: 1768 loss: 2.42611168e-06
Iter: 1769 loss: 2.42507986e-06
Iter: 1770 loss: 2.427455e-06
Iter: 1771 loss: 2.42465148e-06
Iter: 1772 loss: 2.42298665e-06
Iter: 1773 loss: 2.42485248e-06
Iter: 1774 loss: 2.42215219e-06
Iter: 1775 loss: 2.42095848e-06
Iter: 1776 loss: 2.42789383e-06
Iter: 1777 loss: 2.42083684e-06
Iter: 1778 loss: 2.41968746e-06
Iter: 1779 loss: 2.42723581e-06
Iter: 1780 loss: 2.41964835e-06
Iter: 1781 loss: 2.41880207e-06
Iter: 1782 loss: 2.41884754e-06
Iter: 1783 loss: 2.41846465e-06
Iter: 1784 loss: 2.41743237e-06
Iter: 1785 loss: 2.43236173e-06
Iter: 1786 loss: 2.41738235e-06
Iter: 1787 loss: 2.41626594e-06
Iter: 1788 loss: 2.42047963e-06
Iter: 1789 loss: 2.41605221e-06
Iter: 1790 loss: 2.41517864e-06
Iter: 1791 loss: 2.41705e-06
Iter: 1792 loss: 2.41483895e-06
Iter: 1793 loss: 2.41386715e-06
Iter: 1794 loss: 2.41559451e-06
Iter: 1795 loss: 2.413424e-06
Iter: 1796 loss: 2.41242833e-06
Iter: 1797 loss: 2.41456451e-06
Iter: 1798 loss: 2.41204361e-06
Iter: 1799 loss: 2.41094767e-06
Iter: 1800 loss: 2.41456655e-06
Iter: 1801 loss: 2.41052953e-06
Iter: 1802 loss: 2.40968166e-06
Iter: 1803 loss: 2.41027328e-06
Iter: 1804 loss: 2.40919667e-06
Iter: 1805 loss: 2.40794384e-06
Iter: 1806 loss: 2.41349653e-06
Iter: 1807 loss: 2.40765507e-06
Iter: 1808 loss: 2.40692771e-06
Iter: 1809 loss: 2.40675445e-06
Iter: 1810 loss: 2.40627105e-06
Iter: 1811 loss: 2.4046642e-06
Iter: 1812 loss: 2.40916143e-06
Iter: 1813 loss: 2.40418967e-06
Iter: 1814 loss: 2.40422537e-06
Iter: 1815 loss: 2.40370582e-06
Iter: 1816 loss: 2.40325e-06
Iter: 1817 loss: 2.40211693e-06
Iter: 1818 loss: 2.41372618e-06
Iter: 1819 loss: 2.40194618e-06
Iter: 1820 loss: 2.40099507e-06
Iter: 1821 loss: 2.40867348e-06
Iter: 1822 loss: 2.40090526e-06
Iter: 1823 loss: 2.40022655e-06
Iter: 1824 loss: 2.39948213e-06
Iter: 1825 loss: 2.39936799e-06
Iter: 1826 loss: 2.39792826e-06
Iter: 1827 loss: 2.4058686e-06
Iter: 1828 loss: 2.39770316e-06
Iter: 1829 loss: 2.39683595e-06
Iter: 1830 loss: 2.39871e-06
Iter: 1831 loss: 2.39658129e-06
Iter: 1832 loss: 2.39552151e-06
Iter: 1833 loss: 2.39698716e-06
Iter: 1834 loss: 2.39494966e-06
Iter: 1835 loss: 2.3938519e-06
Iter: 1836 loss: 2.39418114e-06
Iter: 1837 loss: 2.39296151e-06
Iter: 1838 loss: 2.3917446e-06
Iter: 1839 loss: 2.40458621e-06
Iter: 1840 loss: 2.39175506e-06
Iter: 1841 loss: 2.39075098e-06
Iter: 1842 loss: 2.38968278e-06
Iter: 1843 loss: 2.38962275e-06
Iter: 1844 loss: 2.38805569e-06
Iter: 1845 loss: 2.40761892e-06
Iter: 1846 loss: 2.38810026e-06
Iter: 1847 loss: 2.3872924e-06
Iter: 1848 loss: 2.38667621e-06
Iter: 1849 loss: 2.38641314e-06
Iter: 1850 loss: 2.38622511e-06
Iter: 1851 loss: 2.3857865e-06
Iter: 1852 loss: 2.3853504e-06
Iter: 1853 loss: 2.38482403e-06
Iter: 1854 loss: 2.3847565e-06
Iter: 1855 loss: 2.38402845e-06
Iter: 1856 loss: 2.38256075e-06
Iter: 1857 loss: 2.40884447e-06
Iter: 1858 loss: 2.3825171e-06
Iter: 1859 loss: 2.38195707e-06
Iter: 1860 loss: 2.38171e-06
Iter: 1861 loss: 2.3810303e-06
Iter: 1862 loss: 2.38035045e-06
Iter: 1863 loss: 2.38022449e-06
Iter: 1864 loss: 2.37932863e-06
Iter: 1865 loss: 2.39025144e-06
Iter: 1866 loss: 2.37933773e-06
Iter: 1867 loss: 2.37866971e-06
Iter: 1868 loss: 2.37814379e-06
Iter: 1869 loss: 2.37795462e-06
Iter: 1870 loss: 2.37687345e-06
Iter: 1871 loss: 2.38397297e-06
Iter: 1872 loss: 2.37674908e-06
Iter: 1873 loss: 2.37605627e-06
Iter: 1874 loss: 2.3755747e-06
Iter: 1875 loss: 2.37536983e-06
Iter: 1876 loss: 2.37400582e-06
Iter: 1877 loss: 2.3780608e-06
Iter: 1878 loss: 2.3735688e-06
Iter: 1879 loss: 2.37285167e-06
Iter: 1880 loss: 2.37406175e-06
Iter: 1881 loss: 2.3724956e-06
Iter: 1882 loss: 2.37174891e-06
Iter: 1883 loss: 2.38043572e-06
Iter: 1884 loss: 2.37175e-06
Iter: 1885 loss: 2.37114455e-06
Iter: 1886 loss: 2.37506697e-06
Iter: 1887 loss: 2.37111681e-06
Iter: 1888 loss: 2.37067934e-06
Iter: 1889 loss: 2.36974529e-06
Iter: 1890 loss: 2.37979862e-06
Iter: 1891 loss: 2.36965684e-06
Iter: 1892 loss: 2.36873257e-06
Iter: 1893 loss: 2.37586505e-06
Iter: 1894 loss: 2.36864253e-06
Iter: 1895 loss: 2.36788833e-06
Iter: 1896 loss: 2.36737014e-06
Iter: 1897 loss: 2.36707456e-06
Iter: 1898 loss: 2.36613027e-06
Iter: 1899 loss: 2.3795908e-06
Iter: 1900 loss: 2.36610822e-06
Iter: 1901 loss: 2.36527239e-06
Iter: 1902 loss: 2.36454525e-06
Iter: 1903 loss: 2.36424626e-06
Iter: 1904 loss: 2.36332767e-06
Iter: 1905 loss: 2.37566837e-06
Iter: 1906 loss: 2.36333426e-06
Iter: 1907 loss: 2.36265578e-06
Iter: 1908 loss: 2.36135111e-06
Iter: 1909 loss: 2.39269548e-06
Iter: 1910 loss: 2.36132291e-06
Iter: 1911 loss: 2.36022879e-06
Iter: 1912 loss: 2.36018059e-06
Iter: 1913 loss: 2.35959533e-06
Iter: 1914 loss: 2.35880202e-06
Iter: 1915 loss: 2.3587163e-06
Iter: 1916 loss: 2.35759489e-06
Iter: 1917 loss: 2.36540359e-06
Iter: 1918 loss: 2.35752213e-06
Iter: 1919 loss: 2.3568648e-06
Iter: 1920 loss: 2.36111532e-06
Iter: 1921 loss: 2.35679136e-06
Iter: 1922 loss: 2.3558955e-06
Iter: 1923 loss: 2.35872312e-06
Iter: 1924 loss: 2.35574362e-06
Iter: 1925 loss: 2.35530433e-06
Iter: 1926 loss: 2.35466723e-06
Iter: 1927 loss: 2.35467041e-06
Iter: 1928 loss: 2.35388256e-06
Iter: 1929 loss: 2.35347488e-06
Iter: 1930 loss: 2.35311472e-06
Iter: 1931 loss: 2.35232756e-06
Iter: 1932 loss: 2.36488859e-06
Iter: 1933 loss: 2.35232073e-06
Iter: 1934 loss: 2.35162065e-06
Iter: 1935 loss: 2.35161974e-06
Iter: 1936 loss: 2.35115249e-06
Iter: 1937 loss: 2.35033895e-06
Iter: 1938 loss: 2.3553971e-06
Iter: 1939 loss: 2.35023526e-06
Iter: 1940 loss: 2.34945355e-06
Iter: 1941 loss: 2.35009975e-06
Iter: 1942 loss: 2.34896243e-06
Iter: 1943 loss: 2.34838e-06
Iter: 1944 loss: 2.35239509e-06
Iter: 1945 loss: 2.34831327e-06
Iter: 1946 loss: 2.3477246e-06
Iter: 1947 loss: 2.34696336e-06
Iter: 1948 loss: 2.34694471e-06
Iter: 1949 loss: 2.34606773e-06
Iter: 1950 loss: 2.35467405e-06
Iter: 1951 loss: 2.34605955e-06
Iter: 1952 loss: 2.34519507e-06
Iter: 1953 loss: 2.34432468e-06
Iter: 1954 loss: 2.34417348e-06
Iter: 1955 loss: 2.3450375e-06
Iter: 1956 loss: 2.3438306e-06
Iter: 1957 loss: 2.34353615e-06
Iter: 1958 loss: 2.34356548e-06
Iter: 1959 loss: 2.34331628e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3
+ date
Mon Oct 26 16:20:12 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3/300_300_300_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3/300_300_300_1 --optimizer lbfgs --function f1 --psi 3 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa19896fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1989f6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198a05840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198968840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198968158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1988da400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1988a6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa19886c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa19886c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198841950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1987cb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1987ce2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1987ce268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198791510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198750840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1986fc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198722158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1986df840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198722ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1986a8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1986a8b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa19862eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198623840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa198612598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1628fe268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa162935ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1985b2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1628dd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1628dd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1628a58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1628a5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa16283a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa162869598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa162869e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1628346a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa13c0cd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.62005849e-05
Iter: 2 loss: 3.056e-05
Iter: 3 loss: 9.30740862e-05
Iter: 4 loss: 3.044197e-05
Iter: 5 loss: 2.78259649e-05
Iter: 6 loss: 4.55699264e-05
Iter: 7 loss: 2.75747661e-05
Iter: 8 loss: 2.58762066e-05
Iter: 9 loss: 2.26896482e-05
Iter: 10 loss: 9.63189304e-05
Iter: 11 loss: 2.26828761e-05
Iter: 12 loss: 1.89437087e-05
Iter: 13 loss: 3.91985377e-05
Iter: 14 loss: 1.83780212e-05
Iter: 15 loss: 1.70800777e-05
Iter: 16 loss: 1.77967813e-05
Iter: 17 loss: 1.62312281e-05
Iter: 18 loss: 1.48520494e-05
Iter: 19 loss: 3.00624306e-05
Iter: 20 loss: 1.48230411e-05
Iter: 21 loss: 1.40246257e-05
Iter: 22 loss: 1.43915622e-05
Iter: 23 loss: 1.34824095e-05
Iter: 24 loss: 1.24146545e-05
Iter: 25 loss: 1.69809537e-05
Iter: 26 loss: 1.21941011e-05
Iter: 27 loss: 1.15666662e-05
Iter: 28 loss: 1.2024906e-05
Iter: 29 loss: 1.11799282e-05
Iter: 30 loss: 1.04093087e-05
Iter: 31 loss: 1.40682987e-05
Iter: 32 loss: 1.02712374e-05
Iter: 33 loss: 9.87367639e-06
Iter: 34 loss: 1.00706648e-05
Iter: 35 loss: 9.60751458e-06
Iter: 36 loss: 9.22285381e-06
Iter: 37 loss: 1.01953137e-05
Iter: 38 loss: 9.0896865e-06
Iter: 39 loss: 8.73087811e-06
Iter: 40 loss: 1.03677867e-05
Iter: 41 loss: 8.66252e-06
Iter: 42 loss: 8.3749419e-06
Iter: 43 loss: 1.16357887e-05
Iter: 44 loss: 8.36976e-06
Iter: 45 loss: 8.22510265e-06
Iter: 46 loss: 8.25567531e-06
Iter: 47 loss: 8.11803875e-06
Iter: 48 loss: 7.89808109e-06
Iter: 49 loss: 7.66611174e-06
Iter: 50 loss: 7.6263e-06
Iter: 51 loss: 7.39278e-06
Iter: 52 loss: 8.99175393e-06
Iter: 53 loss: 7.37038499e-06
Iter: 54 loss: 7.14514954e-06
Iter: 55 loss: 7.27288352e-06
Iter: 56 loss: 6.99851535e-06
Iter: 57 loss: 6.82974678e-06
Iter: 58 loss: 9.18006663e-06
Iter: 59 loss: 6.82934342e-06
Iter: 60 loss: 6.68656048e-06
Iter: 61 loss: 6.63248602e-06
Iter: 62 loss: 6.55425447e-06
Iter: 63 loss: 6.41689439e-06
Iter: 64 loss: 8.20537e-06
Iter: 65 loss: 6.41595307e-06
Iter: 66 loss: 6.3111429e-06
Iter: 67 loss: 6.14610826e-06
Iter: 68 loss: 6.14414921e-06
Iter: 69 loss: 5.99547275e-06
Iter: 70 loss: 7.44554791e-06
Iter: 71 loss: 5.99026498e-06
Iter: 72 loss: 5.85555881e-06
Iter: 73 loss: 6.17819933e-06
Iter: 74 loss: 5.80709548e-06
Iter: 75 loss: 5.8045548e-06
Iter: 76 loss: 5.76838647e-06
Iter: 77 loss: 5.72662657e-06
Iter: 78 loss: 5.64992479e-06
Iter: 79 loss: 7.44471e-06
Iter: 80 loss: 5.64991296e-06
Iter: 81 loss: 5.56026043e-06
Iter: 82 loss: 5.91906746e-06
Iter: 83 loss: 5.54015742e-06
Iter: 84 loss: 5.48075832e-06
Iter: 85 loss: 5.57922522e-06
Iter: 86 loss: 5.45366311e-06
Iter: 87 loss: 5.37467076e-06
Iter: 88 loss: 5.3254339e-06
Iter: 89 loss: 5.29388035e-06
Iter: 90 loss: 5.21812217e-06
Iter: 91 loss: 5.96032123e-06
Iter: 92 loss: 5.21555557e-06
Iter: 93 loss: 5.14872363e-06
Iter: 94 loss: 5.22223672e-06
Iter: 95 loss: 5.11231565e-06
Iter: 96 loss: 5.05058051e-06
Iter: 97 loss: 5.55207498e-06
Iter: 98 loss: 5.04667696e-06
Iter: 99 loss: 4.9960554e-06
Iter: 100 loss: 5.02922285e-06
Iter: 101 loss: 4.96413486e-06
Iter: 102 loss: 4.91379615e-06
Iter: 103 loss: 5.04724449e-06
Iter: 104 loss: 4.89687818e-06
Iter: 105 loss: 4.83129679e-06
Iter: 106 loss: 4.93792231e-06
Iter: 107 loss: 4.80166818e-06
Iter: 108 loss: 4.75636625e-06
Iter: 109 loss: 4.87969373e-06
Iter: 110 loss: 4.74162152e-06
Iter: 111 loss: 4.70835766e-06
Iter: 112 loss: 4.70564555e-06
Iter: 113 loss: 4.67713e-06
Iter: 114 loss: 4.64763434e-06
Iter: 115 loss: 4.64226832e-06
Iter: 116 loss: 4.60681531e-06
Iter: 117 loss: 4.62066146e-06
Iter: 118 loss: 4.5822926e-06
Iter: 119 loss: 4.53522898e-06
Iter: 120 loss: 4.88114028e-06
Iter: 121 loss: 4.53133907e-06
Iter: 122 loss: 4.50592142e-06
Iter: 123 loss: 4.47807497e-06
Iter: 124 loss: 4.47403772e-06
Iter: 125 loss: 4.42304e-06
Iter: 126 loss: 4.68245435e-06
Iter: 127 loss: 4.41464817e-06
Iter: 128 loss: 4.38918096e-06
Iter: 129 loss: 4.42686e-06
Iter: 130 loss: 4.37685594e-06
Iter: 131 loss: 4.33732293e-06
Iter: 132 loss: 4.44068e-06
Iter: 133 loss: 4.32400248e-06
Iter: 134 loss: 4.29831e-06
Iter: 135 loss: 4.46871127e-06
Iter: 136 loss: 4.29561715e-06
Iter: 137 loss: 4.27001214e-06
Iter: 138 loss: 4.24326481e-06
Iter: 139 loss: 4.23857637e-06
Iter: 140 loss: 4.20847573e-06
Iter: 141 loss: 4.4421331e-06
Iter: 142 loss: 4.20628658e-06
Iter: 143 loss: 4.17828142e-06
Iter: 144 loss: 4.29404645e-06
Iter: 145 loss: 4.1721014e-06
Iter: 146 loss: 4.15524937e-06
Iter: 147 loss: 4.15404293e-06
Iter: 148 loss: 4.14546321e-06
Iter: 149 loss: 4.12075588e-06
Iter: 150 loss: 4.22925223e-06
Iter: 151 loss: 4.11159454e-06
Iter: 152 loss: 4.0763307e-06
Iter: 153 loss: 4.33077639e-06
Iter: 154 loss: 4.07324706e-06
Iter: 155 loss: 4.0541513e-06
Iter: 156 loss: 4.19462e-06
Iter: 157 loss: 4.05257788e-06
Iter: 158 loss: 4.0362e-06
Iter: 159 loss: 4.0223631e-06
Iter: 160 loss: 4.01787338e-06
Iter: 161 loss: 3.99504279e-06
Iter: 162 loss: 4.04117236e-06
Iter: 163 loss: 3.98574775e-06
Iter: 164 loss: 3.95913867e-06
Iter: 165 loss: 4.09136646e-06
Iter: 166 loss: 3.95467714e-06
Iter: 167 loss: 3.93629898e-06
Iter: 168 loss: 3.9759534e-06
Iter: 169 loss: 3.92930906e-06
Iter: 170 loss: 3.90530749e-06
Iter: 171 loss: 3.99413329e-06
Iter: 172 loss: 3.89941852e-06
Iter: 173 loss: 3.88287026e-06
Iter: 174 loss: 3.87555792e-06
Iter: 175 loss: 3.8671833e-06
Iter: 176 loss: 3.84618579e-06
Iter: 177 loss: 4.12769214e-06
Iter: 178 loss: 3.84611576e-06
Iter: 179 loss: 3.8365074e-06
Iter: 180 loss: 3.93009486e-06
Iter: 181 loss: 3.83609495e-06
Iter: 182 loss: 3.82309236e-06
Iter: 183 loss: 3.80856818e-06
Iter: 184 loss: 3.80643564e-06
Iter: 185 loss: 3.79294306e-06
Iter: 186 loss: 3.8296389e-06
Iter: 187 loss: 3.78857953e-06
Iter: 188 loss: 3.77415518e-06
Iter: 189 loss: 3.76165508e-06
Iter: 190 loss: 3.75779291e-06
Iter: 191 loss: 3.73593389e-06
Iter: 192 loss: 4.03582635e-06
Iter: 193 loss: 3.73584703e-06
Iter: 194 loss: 3.72463614e-06
Iter: 195 loss: 3.72120917e-06
Iter: 196 loss: 3.71463602e-06
Iter: 197 loss: 3.69591839e-06
Iter: 198 loss: 3.7351524e-06
Iter: 199 loss: 3.68842893e-06
Iter: 200 loss: 3.67388293e-06
Iter: 201 loss: 3.67427947e-06
Iter: 202 loss: 3.6622821e-06
Iter: 203 loss: 3.6430406e-06
Iter: 204 loss: 3.90294281e-06
Iter: 205 loss: 3.64297011e-06
Iter: 206 loss: 3.63068057e-06
Iter: 207 loss: 3.63596496e-06
Iter: 208 loss: 3.62230207e-06
Iter: 209 loss: 3.60590866e-06
Iter: 210 loss: 3.6851236e-06
Iter: 211 loss: 3.60294644e-06
Iter: 212 loss: 3.5924179e-06
Iter: 213 loss: 3.59148385e-06
Iter: 214 loss: 3.58360967e-06
Iter: 215 loss: 3.57419367e-06
Iter: 216 loss: 3.57251952e-06
Iter: 217 loss: 3.56653709e-06
Iter: 218 loss: 3.56204509e-06
Iter: 219 loss: 3.55999532e-06
Iter: 220 loss: 3.55294924e-06
Iter: 221 loss: 3.54276449e-06
Iter: 222 loss: 3.54251097e-06
Iter: 223 loss: 3.53200335e-06
Iter: 224 loss: 3.69769054e-06
Iter: 225 loss: 3.53203609e-06
Iter: 226 loss: 3.52360257e-06
Iter: 227 loss: 3.52757934e-06
Iter: 228 loss: 3.51787367e-06
Iter: 229 loss: 3.5060898e-06
Iter: 230 loss: 3.53488849e-06
Iter: 231 loss: 3.50183473e-06
Iter: 232 loss: 3.49068023e-06
Iter: 233 loss: 3.48573758e-06
Iter: 234 loss: 3.48005415e-06
Iter: 235 loss: 3.46875527e-06
Iter: 236 loss: 3.46876277e-06
Iter: 237 loss: 3.45976082e-06
Iter: 238 loss: 3.45099238e-06
Iter: 239 loss: 3.4490181e-06
Iter: 240 loss: 3.44032674e-06
Iter: 241 loss: 3.43978923e-06
Iter: 242 loss: 3.43345482e-06
Iter: 243 loss: 3.41989971e-06
Iter: 244 loss: 3.6488459e-06
Iter: 245 loss: 3.41960117e-06
Iter: 246 loss: 3.41292071e-06
Iter: 247 loss: 3.41075975e-06
Iter: 248 loss: 3.40504221e-06
Iter: 249 loss: 3.47296509e-06
Iter: 250 loss: 3.40499173e-06
Iter: 251 loss: 3.40199449e-06
Iter: 252 loss: 3.39259054e-06
Iter: 253 loss: 3.41175746e-06
Iter: 254 loss: 3.38683981e-06
Iter: 255 loss: 3.37557594e-06
Iter: 256 loss: 3.49775109e-06
Iter: 257 loss: 3.37526012e-06
Iter: 258 loss: 3.36607036e-06
Iter: 259 loss: 3.39205872e-06
Iter: 260 loss: 3.36300309e-06
Iter: 261 loss: 3.35620371e-06
Iter: 262 loss: 3.4425052e-06
Iter: 263 loss: 3.3561455e-06
Iter: 264 loss: 3.35161553e-06
Iter: 265 loss: 3.34020297e-06
Iter: 266 loss: 3.44294199e-06
Iter: 267 loss: 3.33846447e-06
Iter: 268 loss: 3.32975924e-06
Iter: 269 loss: 3.32936816e-06
Iter: 270 loss: 3.32350783e-06
Iter: 271 loss: 3.31570595e-06
Iter: 272 loss: 3.31536012e-06
Iter: 273 loss: 3.30555031e-06
Iter: 274 loss: 3.42474937e-06
Iter: 275 loss: 3.30547846e-06
Iter: 276 loss: 3.29729596e-06
Iter: 277 loss: 3.30354214e-06
Iter: 278 loss: 3.29225804e-06
Iter: 279 loss: 3.28435726e-06
Iter: 280 loss: 3.33469961e-06
Iter: 281 loss: 3.2833882e-06
Iter: 282 loss: 3.27594034e-06
Iter: 283 loss: 3.27793441e-06
Iter: 284 loss: 3.27036105e-06
Iter: 285 loss: 3.26329427e-06
Iter: 286 loss: 3.26263125e-06
Iter: 287 loss: 3.26009354e-06
Iter: 288 loss: 3.25360566e-06
Iter: 289 loss: 3.3060353e-06
Iter: 290 loss: 3.25231213e-06
Iter: 291 loss: 3.24422876e-06
Iter: 292 loss: 3.27833504e-06
Iter: 293 loss: 3.24250186e-06
Iter: 294 loss: 3.23586573e-06
Iter: 295 loss: 3.23043128e-06
Iter: 296 loss: 3.22848973e-06
Iter: 297 loss: 3.21910215e-06
Iter: 298 loss: 3.21908783e-06
Iter: 299 loss: 3.21472521e-06
Iter: 300 loss: 3.2270782e-06
Iter: 301 loss: 3.21353195e-06
Iter: 302 loss: 3.20816912e-06
Iter: 303 loss: 3.19811511e-06
Iter: 304 loss: 3.42361682e-06
Iter: 305 loss: 3.19805167e-06
Iter: 306 loss: 3.19060882e-06
Iter: 307 loss: 3.27831617e-06
Iter: 308 loss: 3.19047422e-06
Iter: 309 loss: 3.18363504e-06
Iter: 310 loss: 3.19283117e-06
Iter: 311 loss: 3.18012417e-06
Iter: 312 loss: 3.17400531e-06
Iter: 313 loss: 3.19953642e-06
Iter: 314 loss: 3.17265039e-06
Iter: 315 loss: 3.16583146e-06
Iter: 316 loss: 3.19806782e-06
Iter: 317 loss: 3.16460955e-06
Iter: 318 loss: 3.1630093e-06
Iter: 319 loss: 3.16247952e-06
Iter: 320 loss: 3.16029809e-06
Iter: 321 loss: 3.15455e-06
Iter: 322 loss: 3.19380388e-06
Iter: 323 loss: 3.15318766e-06
Iter: 324 loss: 3.14575459e-06
Iter: 325 loss: 3.16588785e-06
Iter: 326 loss: 3.143296e-06
Iter: 327 loss: 3.13730652e-06
Iter: 328 loss: 3.14509884e-06
Iter: 329 loss: 3.13412738e-06
Iter: 330 loss: 3.12918564e-06
Iter: 331 loss: 3.18583852e-06
Iter: 332 loss: 3.12905922e-06
Iter: 333 loss: 3.12461407e-06
Iter: 334 loss: 3.12731254e-06
Iter: 335 loss: 3.12172892e-06
Iter: 336 loss: 3.11523672e-06
Iter: 337 loss: 3.1410832e-06
Iter: 338 loss: 3.11386111e-06
Iter: 339 loss: 3.10915743e-06
Iter: 340 loss: 3.10504879e-06
Iter: 341 loss: 3.10389828e-06
Iter: 342 loss: 3.09647112e-06
Iter: 343 loss: 3.16973092e-06
Iter: 344 loss: 3.09624556e-06
Iter: 345 loss: 3.09139659e-06
Iter: 346 loss: 3.083313e-06
Iter: 347 loss: 3.08327208e-06
Iter: 348 loss: 3.07997198e-06
Iter: 349 loss: 3.07837058e-06
Iter: 350 loss: 3.07522646e-06
Iter: 351 loss: 3.0855249e-06
Iter: 352 loss: 3.07436471e-06
Iter: 353 loss: 3.06985021e-06
Iter: 354 loss: 3.08421477e-06
Iter: 355 loss: 3.06853599e-06
Iter: 356 loss: 3.06587845e-06
Iter: 357 loss: 3.06844458e-06
Iter: 358 loss: 3.06433844e-06
Iter: 359 loss: 3.06151196e-06
Iter: 360 loss: 3.05511912e-06
Iter: 361 loss: 3.1376826e-06
Iter: 362 loss: 3.054638e-06
Iter: 363 loss: 3.04913169e-06
Iter: 364 loss: 3.04901687e-06
Iter: 365 loss: 3.04521973e-06
Iter: 366 loss: 3.03930437e-06
Iter: 367 loss: 3.03921752e-06
Iter: 368 loss: 3.0347378e-06
Iter: 369 loss: 3.03425918e-06
Iter: 370 loss: 3.03103911e-06
Iter: 371 loss: 3.03199226e-06
Iter: 372 loss: 3.02864032e-06
Iter: 373 loss: 3.02401168e-06
Iter: 374 loss: 3.03100433e-06
Iter: 375 loss: 3.02178728e-06
Iter: 376 loss: 3.01715181e-06
Iter: 377 loss: 3.01591945e-06
Iter: 378 loss: 3.0131182e-06
Iter: 379 loss: 3.00800889e-06
Iter: 380 loss: 3.08084441e-06
Iter: 381 loss: 3.00798388e-06
Iter: 382 loss: 3.00405827e-06
Iter: 383 loss: 3.00478951e-06
Iter: 384 loss: 3.00100692e-06
Iter: 385 loss: 3.00021566e-06
Iter: 386 loss: 2.99826547e-06
Iter: 387 loss: 2.99668136e-06
Iter: 388 loss: 2.99391013e-06
Iter: 389 loss: 2.99392605e-06
Iter: 390 loss: 2.99024055e-06
Iter: 391 loss: 2.990128e-06
Iter: 392 loss: 2.98716168e-06
Iter: 393 loss: 2.983179e-06
Iter: 394 loss: 2.9944008e-06
Iter: 395 loss: 2.98198665e-06
Iter: 396 loss: 2.97663496e-06
Iter: 397 loss: 2.97852421e-06
Iter: 398 loss: 2.97286465e-06
Iter: 399 loss: 2.9685466e-06
Iter: 400 loss: 3.00138595e-06
Iter: 401 loss: 2.96827307e-06
Iter: 402 loss: 2.9639566e-06
Iter: 403 loss: 2.96585358e-06
Iter: 404 loss: 2.96090866e-06
Iter: 405 loss: 2.95734617e-06
Iter: 406 loss: 2.9572941e-06
Iter: 407 loss: 2.95481937e-06
Iter: 408 loss: 2.94842e-06
Iter: 409 loss: 3.00907459e-06
Iter: 410 loss: 2.94751089e-06
Iter: 411 loss: 2.94291112e-06
Iter: 412 loss: 2.94292659e-06
Iter: 413 loss: 2.93840276e-06
Iter: 414 loss: 2.93611242e-06
Iter: 415 loss: 2.93403809e-06
Iter: 416 loss: 2.93466792e-06
Iter: 417 loss: 2.93221137e-06
Iter: 418 loss: 2.93037419e-06
Iter: 419 loss: 2.92760978e-06
Iter: 420 loss: 2.92759273e-06
Iter: 421 loss: 2.92342247e-06
Iter: 422 loss: 2.92396408e-06
Iter: 423 loss: 2.92034565e-06
Iter: 424 loss: 2.91658716e-06
Iter: 425 loss: 2.93143557e-06
Iter: 426 loss: 2.91565129e-06
Iter: 427 loss: 2.91113884e-06
Iter: 428 loss: 2.91542e-06
Iter: 429 loss: 2.90872413e-06
Iter: 430 loss: 2.90526668e-06
Iter: 431 loss: 2.91280253e-06
Iter: 432 loss: 2.90387584e-06
Iter: 433 loss: 2.89922968e-06
Iter: 434 loss: 2.90853063e-06
Iter: 435 loss: 2.8974182e-06
Iter: 436 loss: 2.8940774e-06
Iter: 437 loss: 2.91934089e-06
Iter: 438 loss: 2.89377977e-06
Iter: 439 loss: 2.88970978e-06
Iter: 440 loss: 2.89034824e-06
Iter: 441 loss: 2.88670299e-06
Iter: 442 loss: 2.88256956e-06
Iter: 443 loss: 2.89787727e-06
Iter: 444 loss: 2.88157071e-06
Iter: 445 loss: 2.87758576e-06
Iter: 446 loss: 2.88177762e-06
Iter: 447 loss: 2.87536022e-06
Iter: 448 loss: 2.87167177e-06
Iter: 449 loss: 2.88125784e-06
Iter: 450 loss: 2.8703173e-06
Iter: 451 loss: 2.86792692e-06
Iter: 452 loss: 2.8675895e-06
Iter: 453 loss: 2.86531804e-06
Iter: 454 loss: 2.86315958e-06
Iter: 455 loss: 2.86276509e-06
Iter: 456 loss: 2.85977603e-06
Iter: 457 loss: 2.85668511e-06
Iter: 458 loss: 2.85619717e-06
Iter: 459 loss: 2.85220085e-06
Iter: 460 loss: 2.90166759e-06
Iter: 461 loss: 2.85213378e-06
Iter: 462 loss: 2.84926637e-06
Iter: 463 loss: 2.84750172e-06
Iter: 464 loss: 2.84641624e-06
Iter: 465 loss: 2.84182215e-06
Iter: 466 loss: 2.87392299e-06
Iter: 467 loss: 2.84136422e-06
Iter: 468 loss: 2.83856548e-06
Iter: 469 loss: 2.83463373e-06
Iter: 470 loss: 2.83453483e-06
Iter: 471 loss: 2.83022928e-06
Iter: 472 loss: 2.83017516e-06
Iter: 473 loss: 2.82736187e-06
Iter: 474 loss: 2.83221539e-06
Iter: 475 loss: 2.82607516e-06
Iter: 476 loss: 2.82251312e-06
Iter: 477 loss: 2.82323344e-06
Iter: 478 loss: 2.81975986e-06
Iter: 479 loss: 2.81657481e-06
Iter: 480 loss: 2.81613757e-06
Iter: 481 loss: 2.8136958e-06
Iter: 482 loss: 2.80945233e-06
Iter: 483 loss: 2.87246849e-06
Iter: 484 loss: 2.80951417e-06
Iter: 485 loss: 2.80797121e-06
Iter: 486 loss: 2.80782388e-06
Iter: 487 loss: 2.80614199e-06
Iter: 488 loss: 2.80142945e-06
Iter: 489 loss: 2.8265606e-06
Iter: 490 loss: 2.79979758e-06
Iter: 491 loss: 2.79655228e-06
Iter: 492 loss: 2.81000325e-06
Iter: 493 loss: 2.79579172e-06
Iter: 494 loss: 2.79179108e-06
Iter: 495 loss: 2.79858477e-06
Iter: 496 loss: 2.78988182e-06
Iter: 497 loss: 2.7866854e-06
Iter: 498 loss: 2.80881159e-06
Iter: 499 loss: 2.78638981e-06
Iter: 500 loss: 2.78295624e-06
Iter: 501 loss: 2.78256721e-06
Iter: 502 loss: 2.78011771e-06
Iter: 503 loss: 2.77663685e-06
Iter: 504 loss: 2.79568849e-06
Iter: 505 loss: 2.77610297e-06
Iter: 506 loss: 2.77277059e-06
Iter: 507 loss: 2.77908839e-06
Iter: 508 loss: 2.7713636e-06
Iter: 509 loss: 2.76866376e-06
Iter: 510 loss: 2.79416508e-06
Iter: 511 loss: 2.76854325e-06
Iter: 512 loss: 2.76604032e-06
Iter: 513 loss: 2.76427613e-06
Iter: 514 loss: 2.7633323e-06
Iter: 515 loss: 2.75999923e-06
Iter: 516 loss: 2.78414677e-06
Iter: 517 loss: 2.75968114e-06
Iter: 518 loss: 2.7571657e-06
Iter: 519 loss: 2.75621051e-06
Iter: 520 loss: 2.75483194e-06
Iter: 521 loss: 2.75487741e-06
Iter: 522 loss: 2.75357888e-06
Iter: 523 loss: 2.75212301e-06
Iter: 524 loss: 2.74889885e-06
Iter: 525 loss: 2.80176528e-06
Iter: 526 loss: 2.74885588e-06
Iter: 527 loss: 2.74569129e-06
Iter: 528 loss: 2.75361253e-06
Iter: 529 loss: 2.74464537e-06
Iter: 530 loss: 2.74212562e-06
Iter: 531 loss: 2.73812725e-06
Iter: 532 loss: 2.73815272e-06
Iter: 533 loss: 2.73448654e-06
Iter: 534 loss: 2.73448495e-06
Iter: 535 loss: 2.73140404e-06
Iter: 536 loss: 2.73054138e-06
Iter: 537 loss: 2.72861075e-06
Iter: 538 loss: 2.7258493e-06
Iter: 539 loss: 2.73869546e-06
Iter: 540 loss: 2.72537227e-06
Iter: 541 loss: 2.72163879e-06
Iter: 542 loss: 2.72803527e-06
Iter: 543 loss: 2.71997374e-06
Iter: 544 loss: 2.71777935e-06
Iter: 545 loss: 2.74335503e-06
Iter: 546 loss: 2.71774479e-06
Iter: 547 loss: 2.71572844e-06
Iter: 548 loss: 2.71110366e-06
Iter: 549 loss: 2.76793071e-06
Iter: 550 loss: 2.71075032e-06
Iter: 551 loss: 2.70767919e-06
Iter: 552 loss: 2.70709324e-06
Iter: 553 loss: 2.70558712e-06
Iter: 554 loss: 2.7065837e-06
Iter: 555 loss: 2.70461715e-06
Iter: 556 loss: 2.70220494e-06
Iter: 557 loss: 2.70469718e-06
Iter: 558 loss: 2.70081318e-06
Iter: 559 loss: 2.69778911e-06
Iter: 560 loss: 2.74095578e-06
Iter: 561 loss: 2.69778684e-06
Iter: 562 loss: 2.69662814e-06
Iter: 563 loss: 2.69316388e-06
Iter: 564 loss: 2.70907276e-06
Iter: 565 loss: 2.69191651e-06
Iter: 566 loss: 2.68865733e-06
Iter: 567 loss: 2.73457226e-06
Iter: 568 loss: 2.68861095e-06
Iter: 569 loss: 2.68625195e-06
Iter: 570 loss: 2.68228632e-06
Iter: 571 loss: 2.68228587e-06
Iter: 572 loss: 2.67944483e-06
Iter: 573 loss: 2.67931864e-06
Iter: 574 loss: 2.67691985e-06
Iter: 575 loss: 2.67494306e-06
Iter: 576 loss: 2.67422274e-06
Iter: 577 loss: 2.67065411e-06
Iter: 578 loss: 2.69364614e-06
Iter: 579 loss: 2.67021437e-06
Iter: 580 loss: 2.66692177e-06
Iter: 581 loss: 2.67464634e-06
Iter: 582 loss: 2.66565894e-06
Iter: 583 loss: 2.66350185e-06
Iter: 584 loss: 2.68246959e-06
Iter: 585 loss: 2.66331404e-06
Iter: 586 loss: 2.66125153e-06
Iter: 587 loss: 2.6592711e-06
Iter: 588 loss: 2.65882977e-06
Iter: 589 loss: 2.65601966e-06
Iter: 590 loss: 2.67940095e-06
Iter: 591 loss: 2.65587278e-06
Iter: 592 loss: 2.6531302e-06
Iter: 593 loss: 2.65255585e-06
Iter: 594 loss: 2.65077233e-06
Iter: 595 loss: 2.64923165e-06
Iter: 596 loss: 2.64894493e-06
Iter: 597 loss: 2.64767641e-06
Iter: 598 loss: 2.65377844e-06
Iter: 599 loss: 2.64744085e-06
Iter: 600 loss: 2.64617324e-06
Iter: 601 loss: 2.64294522e-06
Iter: 602 loss: 2.67583846e-06
Iter: 603 loss: 2.64260348e-06
Iter: 604 loss: 2.64036521e-06
Iter: 605 loss: 2.64529854e-06
Iter: 606 loss: 2.63944298e-06
Iter: 607 loss: 2.63603283e-06
Iter: 608 loss: 2.64347591e-06
Iter: 609 loss: 2.63474499e-06
Iter: 610 loss: 2.63219977e-06
Iter: 611 loss: 2.6314051e-06
Iter: 612 loss: 2.62992376e-06
Iter: 613 loss: 2.62648427e-06
Iter: 614 loss: 2.67755786e-06
Iter: 615 loss: 2.62647745e-06
Iter: 616 loss: 2.62440108e-06
Iter: 617 loss: 2.62116737e-06
Iter: 618 loss: 2.62106414e-06
Iter: 619 loss: 2.61935429e-06
Iter: 620 loss: 2.61899027e-06
Iter: 621 loss: 2.61709874e-06
Iter: 622 loss: 2.61552805e-06
Iter: 623 loss: 2.61493096e-06
Iter: 624 loss: 2.61201217e-06
Iter: 625 loss: 2.6356015e-06
Iter: 626 loss: 2.61180094e-06
Iter: 627 loss: 2.60977117e-06
Iter: 628 loss: 2.61066657e-06
Iter: 629 loss: 2.60847742e-06
Iter: 630 loss: 2.60599222e-06
Iter: 631 loss: 2.60599859e-06
Iter: 632 loss: 2.60447905e-06
Iter: 633 loss: 2.60699289e-06
Iter: 634 loss: 2.60373622e-06
Iter: 635 loss: 2.60255774e-06
Iter: 636 loss: 2.60061893e-06
Iter: 637 loss: 2.6006071e-06
Iter: 638 loss: 2.59730473e-06
Iter: 639 loss: 2.59975877e-06
Iter: 640 loss: 2.59525405e-06
Iter: 641 loss: 2.59260378e-06
Iter: 642 loss: 2.60125898e-06
Iter: 643 loss: 2.59185981e-06
Iter: 644 loss: 2.5888769e-06
Iter: 645 loss: 2.59967646e-06
Iter: 646 loss: 2.58818091e-06
Iter: 647 loss: 2.58591535e-06
Iter: 648 loss: 2.58522755e-06
Iter: 649 loss: 2.58389673e-06
Iter: 650 loss: 2.58105911e-06
Iter: 651 loss: 2.61701553e-06
Iter: 652 loss: 2.58099135e-06
Iter: 653 loss: 2.57884403e-06
Iter: 654 loss: 2.57645797e-06
Iter: 655 loss: 2.57612487e-06
Iter: 656 loss: 2.5731008e-06
Iter: 657 loss: 2.58800083e-06
Iter: 658 loss: 2.57255078e-06
Iter: 659 loss: 2.56997146e-06
Iter: 660 loss: 2.59655872e-06
Iter: 661 loss: 2.56989915e-06
Iter: 662 loss: 2.56807743e-06
Iter: 663 loss: 2.57462443e-06
Iter: 664 loss: 2.5676427e-06
Iter: 665 loss: 2.56603812e-06
Iter: 666 loss: 2.57743568e-06
Iter: 667 loss: 2.56591625e-06
Iter: 668 loss: 2.56412386e-06
Iter: 669 loss: 2.5653344e-06
Iter: 670 loss: 2.56310523e-06
Iter: 671 loss: 2.56175917e-06
Iter: 672 loss: 2.56054682e-06
Iter: 673 loss: 2.56018575e-06
Iter: 674 loss: 2.55756026e-06
Iter: 675 loss: 2.5657323e-06
Iter: 676 loss: 2.55669147e-06
Iter: 677 loss: 2.55504506e-06
Iter: 678 loss: 2.55413261e-06
Iter: 679 loss: 2.55339046e-06
Iter: 680 loss: 2.55005648e-06
Iter: 681 loss: 2.56417934e-06
Iter: 682 loss: 2.54926454e-06
Iter: 683 loss: 2.54758288e-06
Iter: 684 loss: 2.54842985e-06
Iter: 685 loss: 2.54638439e-06
Iter: 686 loss: 2.54330871e-06
Iter: 687 loss: 2.55198893e-06
Iter: 688 loss: 2.54223164e-06
Iter: 689 loss: 2.54027077e-06
Iter: 690 loss: 2.54256042e-06
Iter: 691 loss: 2.539251e-06
Iter: 692 loss: 2.53626e-06
Iter: 693 loss: 2.54852375e-06
Iter: 694 loss: 2.53565304e-06
Iter: 695 loss: 2.53357575e-06
Iter: 696 loss: 2.53447115e-06
Iter: 697 loss: 2.53210851e-06
Iter: 698 loss: 2.53065627e-06
Iter: 699 loss: 2.53057465e-06
Iter: 700 loss: 2.52940299e-06
Iter: 701 loss: 2.53659346e-06
Iter: 702 loss: 2.52932887e-06
Iter: 703 loss: 2.52812811e-06
Iter: 704 loss: 2.52679342e-06
Iter: 705 loss: 2.52649761e-06
Iter: 706 loss: 2.52442442e-06
Iter: 707 loss: 2.52813652e-06
Iter: 708 loss: 2.5234649e-06
Iter: 709 loss: 2.52212249e-06
Iter: 710 loss: 2.52192012e-06
Iter: 711 loss: 2.52096152e-06
Iter: 712 loss: 2.5182344e-06
Iter: 713 loss: 2.52394784e-06
Iter: 714 loss: 2.51706138e-06
Iter: 715 loss: 2.51500933e-06
Iter: 716 loss: 2.51849315e-06
Iter: 717 loss: 2.51410484e-06
Iter: 718 loss: 2.51145138e-06
Iter: 719 loss: 2.51812276e-06
Iter: 720 loss: 2.51053484e-06
Iter: 721 loss: 2.50844414e-06
Iter: 722 loss: 2.50913786e-06
Iter: 723 loss: 2.50682842e-06
Iter: 724 loss: 2.50433959e-06
Iter: 725 loss: 2.5264444e-06
Iter: 726 loss: 2.50420408e-06
Iter: 727 loss: 2.50189714e-06
Iter: 728 loss: 2.50150742e-06
Iter: 729 loss: 2.49993445e-06
Iter: 730 loss: 2.49741561e-06
Iter: 731 loss: 2.52558766e-06
Iter: 732 loss: 2.49739651e-06
Iter: 733 loss: 2.49538493e-06
Iter: 734 loss: 2.49626692e-06
Iter: 735 loss: 2.49396021e-06
Iter: 736 loss: 2.49502409e-06
Iter: 737 loss: 2.49328832e-06
Iter: 738 loss: 2.49257482e-06
Iter: 739 loss: 2.49068466e-06
Iter: 740 loss: 2.49482423e-06
Iter: 741 loss: 2.48948891e-06
Iter: 742 loss: 2.4873948e-06
Iter: 743 loss: 2.48734932e-06
Iter: 744 loss: 2.48599395e-06
Iter: 745 loss: 2.48438209e-06
Iter: 746 loss: 2.48417882e-06
Iter: 747 loss: 2.48151309e-06
Iter: 748 loss: 2.48990955e-06
Iter: 749 loss: 2.48079868e-06
Iter: 750 loss: 2.47866387e-06
Iter: 751 loss: 2.47920093e-06
Iter: 752 loss: 2.47716434e-06
Iter: 753 loss: 2.47454477e-06
Iter: 754 loss: 2.50556468e-06
Iter: 755 loss: 2.4745159e-06
Iter: 756 loss: 2.47301341e-06
Iter: 757 loss: 2.47313073e-06
Iter: 758 loss: 2.47182697e-06
Iter: 759 loss: 2.46950071e-06
Iter: 760 loss: 2.48536753e-06
Iter: 761 loss: 2.46933791e-06
Iter: 762 loss: 2.46802097e-06
Iter: 763 loss: 2.46681407e-06
Iter: 764 loss: 2.46651598e-06
Iter: 765 loss: 2.46365494e-06
Iter: 766 loss: 2.47154139e-06
Iter: 767 loss: 2.46273044e-06
Iter: 768 loss: 2.46077934e-06
Iter: 769 loss: 2.46193986e-06
Iter: 770 loss: 2.45949423e-06
Iter: 771 loss: 2.45856427e-06
Iter: 772 loss: 2.45809269e-06
Iter: 773 loss: 2.45669276e-06
Iter: 774 loss: 2.4580238e-06
Iter: 775 loss: 2.45591536e-06
Iter: 776 loss: 2.45469437e-06
Iter: 777 loss: 2.45266233e-06
Iter: 778 loss: 2.45267393e-06
Iter: 779 loss: 2.4507367e-06
Iter: 780 loss: 2.47141315e-06
Iter: 781 loss: 2.45074466e-06
Iter: 782 loss: 2.44904072e-06
Iter: 783 loss: 2.44820649e-06
Iter: 784 loss: 2.44738749e-06
Iter: 785 loss: 2.4451565e-06
Iter: 786 loss: 2.4621495e-06
Iter: 787 loss: 2.44499938e-06
Iter: 788 loss: 2.44356761e-06
Iter: 789 loss: 2.44222451e-06
Iter: 790 loss: 2.44182047e-06
Iter: 791 loss: 2.43975273e-06
Iter: 792 loss: 2.45702472e-06
Iter: 793 loss: 2.43965496e-06
Iter: 794 loss: 2.4375413e-06
Iter: 795 loss: 2.43690283e-06
Iter: 796 loss: 2.43566137e-06
Iter: 797 loss: 2.43402496e-06
Iter: 798 loss: 2.45217734e-06
Iter: 799 loss: 2.43400427e-06
Iter: 800 loss: 2.43207546e-06
Iter: 801 loss: 2.43182058e-06
Iter: 802 loss: 2.4305034e-06
Iter: 803 loss: 2.42845363e-06
Iter: 804 loss: 2.44935563e-06
Iter: 805 loss: 2.42837814e-06
Iter: 806 loss: 2.4268968e-06
Iter: 807 loss: 2.4269134e-06
Iter: 808 loss: 2.42568603e-06
Iter: 809 loss: 2.42377519e-06
Iter: 810 loss: 2.42380975e-06
Iter: 811 loss: 2.4232022e-06
Iter: 812 loss: 2.42151191e-06
Iter: 813 loss: 2.43009799e-06
Iter: 814 loss: 2.4210367e-06
Iter: 815 loss: 2.41840917e-06
Iter: 816 loss: 2.4311812e-06
Iter: 817 loss: 2.41801126e-06
Iter: 818 loss: 2.41659563e-06
Iter: 819 loss: 2.42599162e-06
Iter: 820 loss: 2.41636462e-06
Iter: 821 loss: 2.41472435e-06
Iter: 822 loss: 2.41309203e-06
Iter: 823 loss: 2.41275757e-06
Iter: 824 loss: 2.41081761e-06
Iter: 825 loss: 2.42687315e-06
Iter: 826 loss: 2.41078578e-06
Iter: 827 loss: 2.40919621e-06
Iter: 828 loss: 2.40931149e-06
Iter: 829 loss: 2.40797658e-06
Iter: 830 loss: 2.40598342e-06
Iter: 831 loss: 2.40860777e-06
Iter: 832 loss: 2.40495956e-06
Iter: 833 loss: 2.40266081e-06
Iter: 834 loss: 2.42214628e-06
Iter: 835 loss: 2.40255758e-06
Iter: 836 loss: 2.40106738e-06
Iter: 837 loss: 2.40202439e-06
Iter: 838 loss: 2.40013719e-06
Iter: 839 loss: 2.39823521e-06
Iter: 840 loss: 2.41328644e-06
Iter: 841 loss: 2.39812357e-06
Iter: 842 loss: 2.39687142e-06
Iter: 843 loss: 2.40165537e-06
Iter: 844 loss: 2.39663882e-06
Iter: 845 loss: 2.39504107e-06
Iter: 846 loss: 2.40338841e-06
Iter: 847 loss: 2.39481369e-06
Iter: 848 loss: 2.39381234e-06
Iter: 849 loss: 2.39301835e-06
Iter: 850 loss: 2.39263454e-06
Iter: 851 loss: 2.3912271e-06
Iter: 852 loss: 2.38917028e-06
Iter: 853 loss: 2.38916073e-06
Iter: 854 loss: 2.38757912e-06
Iter: 855 loss: 2.38753091e-06
Iter: 856 loss: 2.38609573e-06
Iter: 857 loss: 2.38353982e-06
Iter: 858 loss: 2.38354733e-06
Iter: 859 loss: 2.38286384e-06
Iter: 860 loss: 2.3822704e-06
Iter: 861 loss: 2.38114649e-06
Iter: 862 loss: 2.3798093e-06
Iter: 863 loss: 2.37963559e-06
Iter: 864 loss: 2.37794325e-06
Iter: 865 loss: 2.39166e-06
Iter: 866 loss: 2.37782501e-06
Iter: 867 loss: 2.37643462e-06
Iter: 868 loss: 2.37428821e-06
Iter: 869 loss: 2.3742632e-06
Iter: 870 loss: 2.37229096e-06
Iter: 871 loss: 2.39690485e-06
Iter: 872 loss: 2.37221593e-06
Iter: 873 loss: 2.37037511e-06
Iter: 874 loss: 2.3731418e-06
Iter: 875 loss: 2.36946653e-06
Iter: 876 loss: 2.36895949e-06
Iter: 877 loss: 2.3686971e-06
Iter: 878 loss: 2.36788e-06
Iter: 879 loss: 2.36785559e-06
Iter: 880 loss: 2.36724372e-06
Iter: 881 loss: 2.36592678e-06
Iter: 882 loss: 2.36431697e-06
Iter: 883 loss: 2.36423398e-06
Iter: 884 loss: 2.36254346e-06
Iter: 885 loss: 2.37338986e-06
Iter: 886 loss: 2.36239339e-06
Iter: 887 loss: 2.36088022e-06
Iter: 888 loss: 2.3582827e-06
Iter: 889 loss: 2.35825246e-06
Iter: 890 loss: 2.35601351e-06
Iter: 891 loss: 2.38141479e-06
Iter: 892 loss: 2.35594871e-06
Iter: 893 loss: 2.35428115e-06
Iter: 894 loss: 2.3621983e-06
Iter: 895 loss: 2.35391872e-06
Iter: 896 loss: 2.35258312e-06
Iter: 897 loss: 2.35941889e-06
Iter: 898 loss: 2.352401e-06
Iter: 899 loss: 2.35086873e-06
Iter: 900 loss: 2.34935942e-06
Iter: 901 loss: 2.34912454e-06
Iter: 902 loss: 2.34729578e-06
Iter: 903 loss: 2.34923482e-06
Iter: 904 loss: 2.34633376e-06
Iter: 905 loss: 2.34416029e-06
Iter: 906 loss: 2.36707865e-06
Iter: 907 loss: 2.34410436e-06
Iter: 908 loss: 2.34286017e-06
Iter: 909 loss: 2.34140657e-06
Iter: 910 loss: 2.34127219e-06
Iter: 911 loss: 2.34181744e-06
Iter: 912 loss: 2.34027448e-06
Iter: 913 loss: 2.33967603e-06
Iter: 914 loss: 2.33896117e-06
Iter: 915 loss: 2.33888159e-06
Iter: 916 loss: 2.33780838e-06
Iter: 917 loss: 2.33601213e-06
Iter: 918 loss: 2.33602304e-06
Iter: 919 loss: 2.33430137e-06
Iter: 920 loss: 2.35393645e-06
Iter: 921 loss: 2.33427363e-06
Iter: 922 loss: 2.33294122e-06
Iter: 923 loss: 2.33138553e-06
Iter: 924 loss: 2.33117521e-06
Iter: 925 loss: 2.32976799e-06
Iter: 926 loss: 2.32976026e-06
Iter: 927 loss: 2.32850971e-06
Iter: 928 loss: 2.32788329e-06
Iter: 929 loss: 2.32734646e-06
Iter: 930 loss: 2.32580487e-06
Iter: 931 loss: 2.3258176e-06
Iter: 932 loss: 2.32518e-06
Iter: 933 loss: 2.32375305e-06
Iter: 934 loss: 2.34574713e-06
Iter: 935 loss: 2.32369894e-06
Iter: 936 loss: 2.32169646e-06
Iter: 937 loss: 2.33771925e-06
Iter: 938 loss: 2.32164757e-06
Iter: 939 loss: 2.32039065e-06
Iter: 940 loss: 2.31798435e-06
Iter: 941 loss: 2.37071799e-06
Iter: 942 loss: 2.3179814e-06
Iter: 943 loss: 2.31850618e-06
Iter: 944 loss: 2.31680838e-06
Iter: 945 loss: 2.31557078e-06
Iter: 946 loss: 2.32268394e-06
Iter: 947 loss: 2.3154173e-06
Iter: 948 loss: 2.3145833e-06
Iter: 949 loss: 2.31258355e-06
Iter: 950 loss: 2.33699302e-06
Iter: 951 loss: 2.3124237e-06
Iter: 952 loss: 2.31087756e-06
Iter: 953 loss: 2.3249072e-06
Iter: 954 loss: 2.31078502e-06
Iter: 955 loss: 2.30919795e-06
Iter: 956 loss: 2.30932847e-06
Iter: 957 loss: 2.30797218e-06
Iter: 958 loss: 2.30629939e-06
Iter: 959 loss: 2.31730519e-06
Iter: 960 loss: 2.30614251e-06
Iter: 961 loss: 2.3044995e-06
Iter: 962 loss: 2.30339219e-06
Iter: 963 loss: 2.30285764e-06
Iter: 964 loss: 2.30178193e-06
Iter: 965 loss: 2.30167916e-06
Iter: 966 loss: 2.30063961e-06
Iter: 967 loss: 2.30006322e-06
Iter: 968 loss: 2.29959096e-06
Iter: 969 loss: 2.29811621e-06
Iter: 970 loss: 2.30573914e-06
Iter: 971 loss: 2.29784e-06
Iter: 972 loss: 2.29669376e-06
Iter: 973 loss: 2.29509533e-06
Iter: 974 loss: 2.29501075e-06
Iter: 975 loss: 2.29346779e-06
Iter: 976 loss: 2.29345846e-06
Iter: 977 loss: 2.29215607e-06
Iter: 978 loss: 2.29071202e-06
Iter: 979 loss: 2.29056673e-06
Iter: 980 loss: 2.29180796e-06
Iter: 981 loss: 2.28974659e-06
Iter: 982 loss: 2.28928184e-06
Iter: 983 loss: 2.28809245e-06
Iter: 984 loss: 2.30103933e-06
Iter: 985 loss: 2.28788872e-06
Iter: 986 loss: 2.2863419e-06
Iter: 987 loss: 2.28826502e-06
Iter: 988 loss: 2.28546196e-06
Iter: 989 loss: 2.28421868e-06
Iter: 990 loss: 2.29187253e-06
Iter: 991 loss: 2.28398471e-06
Iter: 992 loss: 2.28272484e-06
Iter: 993 loss: 2.28544377e-06
Iter: 994 loss: 2.28221643e-06
Iter: 995 loss: 2.28102613e-06
Iter: 996 loss: 2.28389172e-06
Iter: 997 loss: 2.2806139e-06
Iter: 998 loss: 2.27909914e-06
Iter: 999 loss: 2.2821464e-06
Iter: 1000 loss: 2.27850092e-06
Iter: 1001 loss: 2.27719829e-06
Iter: 1002 loss: 2.28818135e-06
Iter: 1003 loss: 2.27712962e-06
Iter: 1004 loss: 2.27603277e-06
Iter: 1005 loss: 2.27451051e-06
Iter: 1006 loss: 2.27444343e-06
Iter: 1007 loss: 2.27272858e-06
Iter: 1008 loss: 2.28438557e-06
Iter: 1009 loss: 2.27258442e-06
Iter: 1010 loss: 2.27086866e-06
Iter: 1011 loss: 2.27136888e-06
Iter: 1012 loss: 2.26974316e-06
Iter: 1013 loss: 2.26934503e-06
Iter: 1014 loss: 2.26901852e-06
Iter: 1015 loss: 2.26821498e-06
Iter: 1016 loss: 2.26698239e-06
Iter: 1017 loss: 2.26700877e-06
Iter: 1018 loss: 2.26575548e-06
Iter: 1019 loss: 2.26882867e-06
Iter: 1020 loss: 2.26541465e-06
Iter: 1021 loss: 2.2644e-06
Iter: 1022 loss: 2.26339262e-06
Iter: 1023 loss: 2.26315569e-06
Iter: 1024 loss: 2.26175416e-06
Iter: 1025 loss: 2.28194176e-06
Iter: 1026 loss: 2.26172165e-06
Iter: 1027 loss: 2.26067232e-06
Iter: 1028 loss: 2.25981967e-06
Iter: 1029 loss: 2.25956887e-06
Iter: 1030 loss: 2.25752819e-06
Iter: 1031 loss: 2.26907378e-06
Iter: 1032 loss: 2.25727e-06
Iter: 1033 loss: 2.2563579e-06
Iter: 1034 loss: 2.2613026e-06
Iter: 1035 loss: 2.25614485e-06
Iter: 1036 loss: 2.25513259e-06
Iter: 1037 loss: 2.25460599e-06
Iter: 1038 loss: 2.2540662e-06
Iter: 1039 loss: 2.25266535e-06
Iter: 1040 loss: 2.25559575e-06
Iter: 1041 loss: 2.25207714e-06
Iter: 1042 loss: 2.25038298e-06
Iter: 1043 loss: 2.25505664e-06
Iter: 1044 loss: 2.2499828e-06
Iter: 1045 loss: 2.24868745e-06
Iter: 1046 loss: 2.24928272e-06
Iter: 1047 loss: 2.24791484e-06
Iter: 1048 loss: 2.2472459e-06
Iter: 1049 loss: 2.24677524e-06
Iter: 1050 loss: 2.24618725e-06
Iter: 1051 loss: 2.2453446e-06
Iter: 1052 loss: 2.24525616e-06
Iter: 1053 loss: 2.24432506e-06
Iter: 1054 loss: 2.24338396e-06
Iter: 1055 loss: 2.24315454e-06
Iter: 1056 loss: 2.24197197e-06
Iter: 1057 loss: 2.24593123e-06
Iter: 1058 loss: 2.2415777e-06
Iter: 1059 loss: 2.23998177e-06
Iter: 1060 loss: 2.24718633e-06
Iter: 1061 loss: 2.23977349e-06
Iter: 1062 loss: 2.23873485e-06
Iter: 1063 loss: 2.24183327e-06
Iter: 1064 loss: 2.23841448e-06
Iter: 1065 loss: 2.23699226e-06
Iter: 1066 loss: 2.23725647e-06
Iter: 1067 loss: 2.23596771e-06
Iter: 1068 loss: 2.23480947e-06
Iter: 1069 loss: 2.25152212e-06
Iter: 1070 loss: 2.23481538e-06
Iter: 1071 loss: 2.23396478e-06
Iter: 1072 loss: 2.23310758e-06
Iter: 1073 loss: 2.23294251e-06
Iter: 1074 loss: 2.23144525e-06
Iter: 1075 loss: 2.24040195e-06
Iter: 1076 loss: 2.23130269e-06
Iter: 1077 loss: 2.23027723e-06
Iter: 1078 loss: 2.22825611e-06
Iter: 1079 loss: 2.27578289e-06
Iter: 1080 loss: 2.22830863e-06
Iter: 1081 loss: 2.22833432e-06
Iter: 1082 loss: 2.22736594e-06
Iter: 1083 loss: 2.22655626e-06
Iter: 1084 loss: 2.23044708e-06
Iter: 1085 loss: 2.22649896e-06
Iter: 1086 loss: 2.22576045e-06
Iter: 1087 loss: 2.22384324e-06
Iter: 1088 loss: 2.23912798e-06
Iter: 1089 loss: 2.22347444e-06
Iter: 1090 loss: 2.22175822e-06
Iter: 1091 loss: 2.22777e-06
Iter: 1092 loss: 2.22126346e-06
Iter: 1093 loss: 2.21955406e-06
Iter: 1094 loss: 2.22935091e-06
Iter: 1095 loss: 2.21924279e-06
Iter: 1096 loss: 2.21811342e-06
Iter: 1097 loss: 2.21847245e-06
Iter: 1098 loss: 2.21717664e-06
Iter: 1099 loss: 2.21560367e-06
Iter: 1100 loss: 2.23444204e-06
Iter: 1101 loss: 2.21555683e-06
Iter: 1102 loss: 2.21468076e-06
Iter: 1103 loss: 2.21479218e-06
Iter: 1104 loss: 2.21401865e-06
Iter: 1105 loss: 2.21276605e-06
Iter: 1106 loss: 2.22086373e-06
Iter: 1107 loss: 2.21261644e-06
Iter: 1108 loss: 2.21163191e-06
Iter: 1109 loss: 2.212e-06
Iter: 1110 loss: 2.21101e-06
Iter: 1111 loss: 2.20954234e-06
Iter: 1112 loss: 2.2101824e-06
Iter: 1113 loss: 2.20854577e-06
Iter: 1114 loss: 2.20698985e-06
Iter: 1115 loss: 2.210616e-06
Iter: 1116 loss: 2.20650622e-06
Iter: 1117 loss: 2.20577567e-06
Iter: 1118 loss: 2.20550737e-06
Iter: 1119 loss: 2.20483321e-06
Iter: 1120 loss: 2.20488e-06
Iter: 1121 loss: 2.20425568e-06
Iter: 1122 loss: 2.20359652e-06
Iter: 1123 loss: 2.20188099e-06
Iter: 1124 loss: 2.21363916e-06
Iter: 1125 loss: 2.20152106e-06
Iter: 1126 loss: 2.2001459e-06
Iter: 1127 loss: 2.20012498e-06
Iter: 1128 loss: 2.19876119e-06
Iter: 1129 loss: 2.19727121e-06
Iter: 1130 loss: 2.19709818e-06
Iter: 1131 loss: 2.19583148e-06
Iter: 1132 loss: 2.2166023e-06
Iter: 1133 loss: 2.19581489e-06
Iter: 1134 loss: 2.19444109e-06
Iter: 1135 loss: 2.19477033e-06
Iter: 1136 loss: 2.19348271e-06
Iter: 1137 loss: 2.19220806e-06
Iter: 1138 loss: 2.20955553e-06
Iter: 1139 loss: 2.19225217e-06
Iter: 1140 loss: 2.19151343e-06
Iter: 1141 loss: 2.19081767e-06
Iter: 1142 loss: 2.19061621e-06
Iter: 1143 loss: 2.18924038e-06
Iter: 1144 loss: 2.1965634e-06
Iter: 1145 loss: 2.1890578e-06
Iter: 1146 loss: 2.18818309e-06
Iter: 1147 loss: 2.18805917e-06
Iter: 1148 loss: 2.18742389e-06
Iter: 1149 loss: 2.18604828e-06
Iter: 1150 loss: 2.19298181e-06
Iter: 1151 loss: 2.18590912e-06
Iter: 1152 loss: 2.18530204e-06
Iter: 1153 loss: 2.18519381e-06
Iter: 1154 loss: 2.18464265e-06
Iter: 1155 loss: 2.18337141e-06
Iter: 1156 loss: 2.19824028e-06
Iter: 1157 loss: 2.18322702e-06
Iter: 1158 loss: 2.18216792e-06
Iter: 1159 loss: 2.18639025e-06
Iter: 1160 loss: 2.18191144e-06
Iter: 1161 loss: 2.18073637e-06
Iter: 1162 loss: 2.17950469e-06
Iter: 1163 loss: 2.1791916e-06
Iter: 1164 loss: 2.17810225e-06
Iter: 1165 loss: 2.17806155e-06
Iter: 1166 loss: 2.17713341e-06
Iter: 1167 loss: 2.17587308e-06
Iter: 1168 loss: 2.17579804e-06
Iter: 1169 loss: 2.1744429e-06
Iter: 1170 loss: 2.18566151e-06
Iter: 1171 loss: 2.17436286e-06
Iter: 1172 loss: 2.17294155e-06
Iter: 1173 loss: 2.17504885e-06
Iter: 1174 loss: 2.17220327e-06
Iter: 1175 loss: 2.17102615e-06
Iter: 1176 loss: 2.17764773e-06
Iter: 1177 loss: 2.17085085e-06
Iter: 1178 loss: 2.16952071e-06
Iter: 1179 loss: 2.16891112e-06
Iter: 1180 loss: 2.16822809e-06
Iter: 1181 loss: 2.1670719e-06
Iter: 1182 loss: 2.17824572e-06
Iter: 1183 loss: 2.1670005e-06
Iter: 1184 loss: 2.16604326e-06
Iter: 1185 loss: 2.17247452e-06
Iter: 1186 loss: 2.16594594e-06
Iter: 1187 loss: 2.16488615e-06
Iter: 1188 loss: 2.16855028e-06
Iter: 1189 loss: 2.1645933e-06
Iter: 1190 loss: 2.16402e-06
Iter: 1191 loss: 2.16307103e-06
Iter: 1192 loss: 2.16305125e-06
Iter: 1193 loss: 2.16169883e-06
Iter: 1194 loss: 2.16701301e-06
Iter: 1195 loss: 2.16142e-06
Iter: 1196 loss: 2.16041371e-06
Iter: 1197 loss: 2.16511808e-06
Iter: 1198 loss: 2.16020931e-06
Iter: 1199 loss: 2.15928412e-06
Iter: 1200 loss: 2.15731598e-06
Iter: 1201 loss: 2.19528329e-06
Iter: 1202 loss: 2.15729369e-06
Iter: 1203 loss: 2.15552654e-06
Iter: 1204 loss: 2.17591105e-06
Iter: 1205 loss: 2.15555633e-06
Iter: 1206 loss: 2.15416071e-06
Iter: 1207 loss: 2.15873433e-06
Iter: 1208 loss: 2.15379396e-06
Iter: 1209 loss: 2.15281216e-06
Iter: 1210 loss: 2.15305681e-06
Iter: 1211 loss: 2.15207683e-06
Iter: 1212 loss: 2.15080581e-06
Iter: 1213 loss: 2.16234e-06
Iter: 1214 loss: 2.15076534e-06
Iter: 1215 loss: 2.14992815e-06
Iter: 1216 loss: 2.1491237e-06
Iter: 1217 loss: 2.1489268e-06
Iter: 1218 loss: 2.14784632e-06
Iter: 1219 loss: 2.14785223e-06
Iter: 1220 loss: 2.14727788e-06
Iter: 1221 loss: 2.15297632e-06
Iter: 1222 loss: 2.14727106e-06
Iter: 1223 loss: 2.146518e-06
Iter: 1224 loss: 2.14544457e-06
Iter: 1225 loss: 2.14541751e-06
Iter: 1226 loss: 2.14444117e-06
Iter: 1227 loss: 2.14877628e-06
Iter: 1228 loss: 2.1443168e-06
Iter: 1229 loss: 2.1435103e-06
Iter: 1230 loss: 2.14248803e-06
Iter: 1231 loss: 2.14235934e-06
Iter: 1232 loss: 2.14112538e-06
Iter: 1233 loss: 2.15967248e-06
Iter: 1234 loss: 2.14113334e-06
Iter: 1235 loss: 2.14038914e-06
Iter: 1236 loss: 2.14240254e-06
Iter: 1237 loss: 2.14018496e-06
Iter: 1238 loss: 2.13926455e-06
Iter: 1239 loss: 2.13845215e-06
Iter: 1240 loss: 2.13820249e-06
Iter: 1241 loss: 2.13701924e-06
Iter: 1242 loss: 2.13967314e-06
Iter: 1243 loss: 2.13653834e-06
Iter: 1244 loss: 2.13495537e-06
Iter: 1245 loss: 2.1417377e-06
Iter: 1246 loss: 2.13466728e-06
Iter: 1247 loss: 2.13358771e-06
Iter: 1248 loss: 2.13344833e-06
Iter: 1249 loss: 2.13261887e-06
Iter: 1250 loss: 2.13150429e-06
Iter: 1251 loss: 2.14666147e-06
Iter: 1252 loss: 2.13148519e-06
Iter: 1253 loss: 2.1305068e-06
Iter: 1254 loss: 2.13052704e-06
Iter: 1255 loss: 2.12973259e-06
Iter: 1256 loss: 2.12932446e-06
Iter: 1257 loss: 2.12898249e-06
Iter: 1258 loss: 2.12862778e-06
Iter: 1259 loss: 2.12766304e-06
Iter: 1260 loss: 2.13581825e-06
Iter: 1261 loss: 2.12754412e-06
Iter: 1262 loss: 2.12630925e-06
Iter: 1263 loss: 2.1310841e-06
Iter: 1264 loss: 2.12607665e-06
Iter: 1265 loss: 2.12514851e-06
Iter: 1266 loss: 2.12748273e-06
Iter: 1267 loss: 2.12486293e-06
Iter: 1268 loss: 2.12372356e-06
Iter: 1269 loss: 2.12334362e-06
Iter: 1270 loss: 2.12267491e-06
Iter: 1271 loss: 2.1219314e-06
Iter: 1272 loss: 2.12185569e-06
Iter: 1273 loss: 2.12117266e-06
Iter: 1274 loss: 2.11968472e-06
Iter: 1275 loss: 2.14561305e-06
Iter: 1276 loss: 2.11963925e-06
Iter: 1277 loss: 2.11818542e-06
Iter: 1278 loss: 2.13584917e-06
Iter: 1279 loss: 2.11812767e-06
Iter: 1280 loss: 2.11723227e-06
Iter: 1281 loss: 2.11618271e-06
Iter: 1282 loss: 2.11607357e-06
Iter: 1283 loss: 2.11479437e-06
Iter: 1284 loss: 2.13267117e-06
Iter: 1285 loss: 2.11478573e-06
Iter: 1286 loss: 2.11381666e-06
Iter: 1287 loss: 2.1136234e-06
Iter: 1288 loss: 2.11295583e-06
Iter: 1289 loss: 2.11317138e-06
Iter: 1290 loss: 2.11250199e-06
Iter: 1291 loss: 2.11206725e-06
Iter: 1292 loss: 2.11147903e-06
Iter: 1293 loss: 2.11144152e-06
Iter: 1294 loss: 2.11066435e-06
Iter: 1295 loss: 2.11070915e-06
Iter: 1296 loss: 2.1100484e-06
Iter: 1297 loss: 2.10904818e-06
Iter: 1298 loss: 2.11060433e-06
Iter: 1299 loss: 2.10857229e-06
Iter: 1300 loss: 2.107412e-06
Iter: 1301 loss: 2.1164692e-06
Iter: 1302 loss: 2.10742428e-06
Iter: 1303 loss: 2.1065664e-06
Iter: 1304 loss: 2.10635949e-06
Iter: 1305 loss: 2.10584972e-06
Iter: 1306 loss: 2.10444091e-06
Iter: 1307 loss: 2.11211591e-06
Iter: 1308 loss: 2.10428834e-06
Iter: 1309 loss: 2.10336202e-06
Iter: 1310 loss: 2.10584858e-06
Iter: 1311 loss: 2.10310213e-06
Iter: 1312 loss: 2.10213739e-06
Iter: 1313 loss: 2.10165126e-06
Iter: 1314 loss: 2.10120834e-06
Iter: 1315 loss: 2.10009216e-06
Iter: 1316 loss: 2.10639928e-06
Iter: 1317 loss: 2.09991867e-06
Iter: 1318 loss: 2.09861787e-06
Iter: 1319 loss: 2.09921e-06
Iter: 1320 loss: 2.09783889e-06
Iter: 1321 loss: 2.09689142e-06
Iter: 1322 loss: 2.10216058e-06
Iter: 1323 loss: 2.0967409e-06
Iter: 1324 loss: 2.09592e-06
Iter: 1325 loss: 2.09594555e-06
Iter: 1326 loss: 2.095235e-06
Iter: 1327 loss: 2.09461314e-06
Iter: 1328 loss: 2.09448444e-06
Iter: 1329 loss: 2.09387e-06
Iter: 1330 loss: 2.09288601e-06
Iter: 1331 loss: 2.09283826e-06
Iter: 1332 loss: 2.09155542e-06
Iter: 1333 loss: 2.10409121e-06
Iter: 1334 loss: 2.09150699e-06
Iter: 1335 loss: 2.09055e-06
Iter: 1336 loss: 2.0916068e-06
Iter: 1337 loss: 2.09004975e-06
Iter: 1338 loss: 2.08906295e-06
Iter: 1339 loss: 2.09847121e-06
Iter: 1340 loss: 2.0890152e-06
Iter: 1341 loss: 2.08838583e-06
Iter: 1342 loss: 2.08821325e-06
Iter: 1343 loss: 2.08787242e-06
Iter: 1344 loss: 2.08657639e-06
Iter: 1345 loss: 2.08930214e-06
Iter: 1346 loss: 2.08613733e-06
Iter: 1347 loss: 2.08500956e-06
Iter: 1348 loss: 2.0875982e-06
Iter: 1349 loss: 2.08467509e-06
Iter: 1350 loss: 2.08339725e-06
Iter: 1351 loss: 2.08452957e-06
Iter: 1352 loss: 2.08266465e-06
Iter: 1353 loss: 2.08142637e-06
Iter: 1354 loss: 2.08200618e-06
Iter: 1355 loss: 2.08068741e-06
Iter: 1356 loss: 2.0799198e-06
Iter: 1357 loss: 2.07975836e-06
Iter: 1358 loss: 2.07919265e-06
Iter: 1359 loss: 2.08697e-06
Iter: 1360 loss: 2.07919629e-06
Iter: 1361 loss: 2.07882931e-06
Iter: 1362 loss: 2.07776043e-06
Iter: 1363 loss: 2.07952326e-06
Iter: 1364 loss: 2.07696871e-06
Iter: 1365 loss: 2.07578432e-06
Iter: 1366 loss: 2.09036739e-06
Iter: 1367 loss: 2.07577818e-06
Iter: 1368 loss: 2.0746329e-06
Iter: 1369 loss: 2.07520452e-06
Iter: 1370 loss: 2.0738737e-06
Iter: 1371 loss: 2.07292487e-06
Iter: 1372 loss: 2.0842092e-06
Iter: 1373 loss: 2.07293397e-06
Iter: 1374 loss: 2.07200151e-06
Iter: 1375 loss: 2.07191442e-06
Iter: 1376 loss: 2.0712464e-06
Iter: 1377 loss: 2.07021776e-06
Iter: 1378 loss: 2.07937228e-06
Iter: 1379 loss: 2.07016251e-06
Iter: 1380 loss: 2.06938284e-06
Iter: 1381 loss: 2.07000448e-06
Iter: 1382 loss: 2.06896584e-06
Iter: 1383 loss: 2.067889e-06
Iter: 1384 loss: 2.06978598e-06
Iter: 1385 loss: 2.06741925e-06
Iter: 1386 loss: 2.06646655e-06
Iter: 1387 loss: 2.06656296e-06
Iter: 1388 loss: 2.06579512e-06
Iter: 1389 loss: 2.06451841e-06
Iter: 1390 loss: 2.07445214e-06
Iter: 1391 loss: 2.06445657e-06
Iter: 1392 loss: 2.06370601e-06
Iter: 1393 loss: 2.07189714e-06
Iter: 1394 loss: 2.06371851e-06
Iter: 1395 loss: 2.06282084e-06
Iter: 1396 loss: 2.06307777e-06
Iter: 1397 loss: 2.06226196e-06
Iter: 1398 loss: 2.06169716e-06
Iter: 1399 loss: 2.06104687e-06
Iter: 1400 loss: 2.06099298e-06
Iter: 1401 loss: 2.05966194e-06
Iter: 1402 loss: 2.06088748e-06
Iter: 1403 loss: 2.05889137e-06
Iter: 1404 loss: 2.05786273e-06
Iter: 1405 loss: 2.06230652e-06
Iter: 1406 loss: 2.05768629e-06
Iter: 1407 loss: 2.05648576e-06
Iter: 1408 loss: 2.05995775e-06
Iter: 1409 loss: 2.05619108e-06
Iter: 1410 loss: 2.05543665e-06
Iter: 1411 loss: 2.06232971e-06
Iter: 1412 loss: 2.05545e-06
Iter: 1413 loss: 2.05470974e-06
Iter: 1414 loss: 2.0535324e-06
Iter: 1415 loss: 2.05355036e-06
Iter: 1416 loss: 2.0523803e-06
Iter: 1417 loss: 2.06476489e-06
Iter: 1418 loss: 2.05234983e-06
Iter: 1419 loss: 2.05146966e-06
Iter: 1420 loss: 2.05199626e-06
Iter: 1421 loss: 2.05087599e-06
Iter: 1422 loss: 2.04995604e-06
Iter: 1423 loss: 2.05700667e-06
Iter: 1424 loss: 2.04989078e-06
Iter: 1425 loss: 2.04918979e-06
Iter: 1426 loss: 2.04803064e-06
Iter: 1427 loss: 2.04801859e-06
Iter: 1428 loss: 2.04886828e-06
Iter: 1429 loss: 2.04743583e-06
Iter: 1430 loss: 2.04711023e-06
Iter: 1431 loss: 2.04645085e-06
Iter: 1432 loss: 2.0606526e-06
Iter: 1433 loss: 2.04643698e-06
Iter: 1434 loss: 2.04559592e-06
Iter: 1435 loss: 2.04500384e-06
Iter: 1436 loss: 2.04471598e-06
Iter: 1437 loss: 2.04361777e-06
Iter: 1438 loss: 2.04518801e-06
Iter: 1439 loss: 2.04307707e-06
Iter: 1440 loss: 2.0418172e-06
Iter: 1441 loss: 2.05006017e-06
Iter: 1442 loss: 2.04170851e-06
Iter: 1443 loss: 2.04065532e-06
Iter: 1444 loss: 2.04052594e-06
Iter: 1445 loss: 2.03980494e-06
Iter: 1446 loss: 2.03848617e-06
Iter: 1447 loss: 2.03851596e-06
Iter: 1448 loss: 2.03772333e-06
Iter: 1449 loss: 2.03736408e-06
Iter: 1450 loss: 2.03693116e-06
Iter: 1451 loss: 2.03572154e-06
Iter: 1452 loss: 2.0409484e-06
Iter: 1453 loss: 2.03544687e-06
Iter: 1454 loss: 2.03463037e-06
Iter: 1455 loss: 2.03559193e-06
Iter: 1456 loss: 2.03412583e-06
Iter: 1457 loss: 2.03284617e-06
Iter: 1458 loss: 2.03517584e-06
Iter: 1459 loss: 2.03225545e-06
Iter: 1460 loss: 2.03152013e-06
Iter: 1461 loss: 2.04266553e-06
Iter: 1462 loss: 2.03151967e-06
Iter: 1463 loss: 2.03082e-06
Iter: 1464 loss: 2.03456511e-06
Iter: 1465 loss: 2.03072454e-06
Iter: 1466 loss: 2.03011587e-06
Iter: 1467 loss: 2.02915089e-06
Iter: 1468 loss: 2.05403649e-06
Iter: 1469 loss: 2.02915635e-06
Iter: 1470 loss: 2.02815863e-06
Iter: 1471 loss: 2.02798174e-06
Iter: 1472 loss: 2.02729188e-06
Iter: 1473 loss: 2.02604838e-06
Iter: 1474 loss: 2.03995432e-06
Iter: 1475 loss: 2.02600404e-06
Iter: 1476 loss: 2.02519209e-06
Iter: 1477 loss: 2.02350611e-06
Iter: 1478 loss: 2.0532384e-06
Iter: 1479 loss: 2.02349884e-06
Iter: 1480 loss: 2.02259753e-06
Iter: 1481 loss: 2.02247611e-06
Iter: 1482 loss: 2.02159595e-06
Iter: 1483 loss: 2.0229395e-06
Iter: 1484 loss: 2.02119099e-06
Iter: 1485 loss: 2.02014598e-06
Iter: 1486 loss: 2.02347928e-06
Iter: 1487 loss: 2.01982766e-06
Iter: 1488 loss: 2.01889088e-06
Iter: 1489 loss: 2.01854255e-06
Iter: 1490 loss: 2.01794273e-06
Iter: 1491 loss: 2.01684179e-06
Iter: 1492 loss: 2.0274133e-06
Iter: 1493 loss: 2.01681314e-06
Iter: 1494 loss: 2.01593866e-06
Iter: 1495 loss: 2.01603848e-06
Iter: 1496 loss: 2.01518696e-06
Iter: 1497 loss: 2.01460284e-06
Iter: 1498 loss: 2.01447415e-06
Iter: 1499 loss: 2.01397211e-06
Iter: 1500 loss: 2.01410671e-06
Iter: 1501 loss: 2.01365674e-06
Iter: 1502 loss: 2.01308512e-06
Iter: 1503 loss: 2.01183093e-06
Iter: 1504 loss: 2.03053901e-06
Iter: 1505 loss: 2.01179455e-06
Iter: 1506 loss: 2.01067746e-06
Iter: 1507 loss: 2.02288447e-06
Iter: 1508 loss: 2.0106645e-06
Iter: 1509 loss: 2.00975092e-06
Iter: 1510 loss: 2.00862655e-06
Iter: 1511 loss: 2.00846671e-06
Iter: 1512 loss: 2.00753561e-06
Iter: 1513 loss: 2.00755767e-06
Iter: 1514 loss: 2.00658815e-06
Iter: 1515 loss: 2.00676868e-06
Iter: 1516 loss: 2.00591148e-06
Iter: 1517 loss: 2.00512409e-06
Iter: 1518 loss: 2.01591183e-06
Iter: 1519 loss: 2.00508384e-06
Iter: 1520 loss: 2.00436716e-06
Iter: 1521 loss: 2.00425757e-06
Iter: 1522 loss: 2.00380055e-06
Iter: 1523 loss: 2.00286286e-06
Iter: 1524 loss: 2.00835734e-06
Iter: 1525 loss: 2.00272348e-06
Iter: 1526 loss: 2.00206478e-06
Iter: 1527 loss: 2.00159275e-06
Iter: 1528 loss: 2.00130626e-06
Iter: 1529 loss: 2.00104546e-06
Iter: 1530 loss: 2.00078284e-06
Iter: 1531 loss: 2.00029785e-06
Iter: 1532 loss: 2.00150566e-06
Iter: 1533 loss: 2.00016825e-06
Iter: 1534 loss: 1.99969895e-06
Iter: 1535 loss: 1.99875672e-06
Iter: 1536 loss: 2.01750754e-06
Iter: 1537 loss: 1.99870942e-06
Iter: 1538 loss: 1.99790043e-06
Iter: 1539 loss: 2.00142813e-06
Iter: 1540 loss: 1.99769283e-06
Iter: 1541 loss: 1.9967581e-06
Iter: 1542 loss: 1.99819306e-06
Iter: 1543 loss: 1.99636088e-06
Iter: 1544 loss: 1.99551732e-06
Iter: 1545 loss: 1.99613282e-06
Iter: 1546 loss: 1.99503711e-06
Iter: 1547 loss: 1.99380906e-06
Iter: 1548 loss: 2.00038357e-06
Iter: 1549 loss: 1.99365286e-06
Iter: 1550 loss: 1.99277156e-06
Iter: 1551 loss: 1.99301e-06
Iter: 1552 loss: 1.99216583e-06
Iter: 1553 loss: 1.99092119e-06
Iter: 1554 loss: 2.00141e-06
Iter: 1555 loss: 1.99084047e-06
Iter: 1556 loss: 1.99021952e-06
Iter: 1557 loss: 1.99292458e-06
Iter: 1558 loss: 1.9901031e-06
Iter: 1559 loss: 1.98941598e-06
Iter: 1560 loss: 1.98837188e-06
Iter: 1561 loss: 1.98835824e-06
Iter: 1562 loss: 1.98742555e-06
Iter: 1563 loss: 2.00028444e-06
Iter: 1564 loss: 1.98741827e-06
Iter: 1565 loss: 1.98662315e-06
Iter: 1566 loss: 1.99570877e-06
Iter: 1567 loss: 1.98662724e-06
Iter: 1568 loss: 1.98608018e-06
Iter: 1569 loss: 1.98540192e-06
Iter: 1570 loss: 1.9853328e-06
Iter: 1571 loss: 1.98463636e-06
Iter: 1572 loss: 1.98530142e-06
Iter: 1573 loss: 1.98426642e-06
Iter: 1574 loss: 1.98317571e-06
Iter: 1575 loss: 1.98473e-06
Iter: 1576 loss: 1.98272301e-06
Iter: 1577 loss: 1.98183216e-06
Iter: 1578 loss: 1.98286216e-06
Iter: 1579 loss: 1.98130738e-06
Iter: 1580 loss: 1.98029079e-06
Iter: 1581 loss: 1.98752377e-06
Iter: 1582 loss: 1.98018e-06
Iter: 1583 loss: 1.97934287e-06
Iter: 1584 loss: 1.97854934e-06
Iter: 1585 loss: 1.97832e-06
Iter: 1586 loss: 1.97741929e-06
Iter: 1587 loss: 1.9773986e-06
Iter: 1588 loss: 1.97673944e-06
Iter: 1589 loss: 1.97730378e-06
Iter: 1590 loss: 1.97631243e-06
Iter: 1591 loss: 1.97528198e-06
Iter: 1592 loss: 1.97608892e-06
Iter: 1593 loss: 1.97467034e-06
Iter: 1594 loss: 1.97372583e-06
Iter: 1595 loss: 1.97529312e-06
Iter: 1596 loss: 1.97324903e-06
Iter: 1597 loss: 1.97255122e-06
Iter: 1598 loss: 1.97250029e-06
Iter: 1599 loss: 1.97181976e-06
Iter: 1600 loss: 1.97334498e-06
Iter: 1601 loss: 1.97159852e-06
Iter: 1602 loss: 1.97114605e-06
Iter: 1603 loss: 1.96992278e-06
Iter: 1604 loss: 1.97792883e-06
Iter: 1605 loss: 1.96954966e-06
Iter: 1606 loss: 1.96862834e-06
Iter: 1607 loss: 1.96857263e-06
Iter: 1608 loss: 1.96803239e-06
Iter: 1609 loss: 1.96720885e-06
Iter: 1610 loss: 1.96722249e-06
Iter: 1611 loss: 1.96599149e-06
Iter: 1612 loss: 1.97342388e-06
Iter: 1613 loss: 1.9658064e-06
Iter: 1614 loss: 1.9650206e-06
Iter: 1615 loss: 1.96487372e-06
Iter: 1616 loss: 1.9643478e-06
Iter: 1617 loss: 1.96335486e-06
Iter: 1618 loss: 1.96955102e-06
Iter: 1619 loss: 1.96328779e-06
Iter: 1620 loss: 1.96231895e-06
Iter: 1621 loss: 1.96581686e-06
Iter: 1622 loss: 1.96204064e-06
Iter: 1623 loss: 1.96129417e-06
Iter: 1624 loss: 1.96710107e-06
Iter: 1625 loss: 1.96129349e-06
Iter: 1626 loss: 1.96067413e-06
Iter: 1627 loss: 1.95965777e-06
Iter: 1628 loss: 1.95963912e-06
Iter: 1629 loss: 1.95905295e-06
Iter: 1630 loss: 1.95898269e-06
Iter: 1631 loss: 1.95848679e-06
Iter: 1632 loss: 1.96225938e-06
Iter: 1633 loss: 1.95848133e-06
Iter: 1634 loss: 1.95805728e-06
Iter: 1635 loss: 1.957118e-06
Iter: 1636 loss: 1.96962264e-06
Iter: 1637 loss: 1.95701659e-06
Iter: 1638 loss: 1.95615917e-06
Iter: 1639 loss: 1.96269821e-06
Iter: 1640 loss: 1.95608072e-06
Iter: 1641 loss: 1.95536495e-06
Iter: 1642 loss: 1.95438975e-06
Iter: 1643 loss: 1.95435587e-06
Iter: 1644 loss: 1.95301982e-06
Iter: 1645 loss: 1.96746032e-06
Iter: 1646 loss: 1.95299299e-06
Iter: 1647 loss: 1.95222765e-06
Iter: 1648 loss: 1.95197686e-06
Iter: 1649 loss: 1.95153552e-06
Iter: 1650 loss: 1.9505992e-06
Iter: 1651 loss: 1.9590841e-06
Iter: 1652 loss: 1.95057e-06
Iter: 1653 loss: 1.94978747e-06
Iter: 1654 loss: 1.9486431e-06
Iter: 1655 loss: 1.94867243e-06
Iter: 1656 loss: 1.94771292e-06
Iter: 1657 loss: 1.96271276e-06
Iter: 1658 loss: 1.94767426e-06
Iter: 1659 loss: 1.94673953e-06
Iter: 1660 loss: 1.94620884e-06
Iter: 1661 loss: 1.94578774e-06
Iter: 1662 loss: 1.94543645e-06
Iter: 1663 loss: 1.94529412e-06
Iter: 1664 loss: 1.94485256e-06
Iter: 1665 loss: 1.94450149e-06
Iter: 1666 loss: 1.94435734e-06
Iter: 1667 loss: 1.94346603e-06
Iter: 1668 loss: 1.95042298e-06
Iter: 1669 loss: 1.943396e-06
Iter: 1670 loss: 1.94291329e-06
Iter: 1671 loss: 1.94297354e-06
Iter: 1672 loss: 1.94253016e-06
Iter: 1673 loss: 1.94199856e-06
Iter: 1674 loss: 1.94110748e-06
Iter: 1675 loss: 1.94107815e-06
Iter: 1676 loss: 1.94016297e-06
Iter: 1677 loss: 1.94950871e-06
Iter: 1678 loss: 1.94014069e-06
Iter: 1679 loss: 1.93930873e-06
Iter: 1680 loss: 1.93911592e-06
Iter: 1681 loss: 1.9386132e-06
Iter: 1682 loss: 1.93785445e-06
Iter: 1683 loss: 1.94793824e-06
Iter: 1684 loss: 1.93786195e-06
Iter: 1685 loss: 1.93716505e-06
Iter: 1686 loss: 1.93669e-06
Iter: 1687 loss: 1.93638789e-06
Iter: 1688 loss: 1.9354643e-06
Iter: 1689 loss: 1.94452969e-06
Iter: 1690 loss: 1.93535402e-06
Iter: 1691 loss: 1.93469577e-06
Iter: 1692 loss: 1.93367441e-06
Iter: 1693 loss: 1.93363257e-06
Iter: 1694 loss: 1.93259257e-06
Iter: 1695 loss: 1.94303084e-06
Iter: 1696 loss: 1.93251572e-06
Iter: 1697 loss: 1.93163419e-06
Iter: 1698 loss: 1.93824076e-06
Iter: 1699 loss: 1.93157257e-06
Iter: 1700 loss: 1.93108508e-06
Iter: 1701 loss: 1.93107599e-06
Iter: 1702 loss: 1.93068377e-06
Iter: 1703 loss: 1.93028245e-06
Iter: 1704 loss: 1.93025835e-06
Iter: 1705 loss: 1.9294946e-06
Iter: 1706 loss: 1.92876314e-06
Iter: 1707 loss: 1.92861899e-06
Iter: 1708 loss: 1.92779339e-06
Iter: 1709 loss: 1.93015967e-06
Iter: 1710 loss: 1.92749599e-06
Iter: 1711 loss: 1.92649372e-06
Iter: 1712 loss: 1.92763196e-06
Iter: 1713 loss: 1.92590733e-06
Iter: 1714 loss: 1.92531024e-06
Iter: 1715 loss: 1.93019696e-06
Iter: 1716 loss: 1.92520747e-06
Iter: 1717 loss: 1.92459106e-06
Iter: 1718 loss: 1.92573634e-06
Iter: 1719 loss: 1.92431253e-06
Iter: 1720 loss: 1.92373204e-06
Iter: 1721 loss: 1.92606763e-06
Iter: 1722 loss: 1.92358812e-06
Iter: 1723 loss: 1.92286916e-06
Iter: 1724 loss: 1.92247762e-06
Iter: 1725 loss: 1.92212133e-06
Iter: 1726 loss: 1.92146217e-06
Iter: 1727 loss: 1.929061e-06
Iter: 1728 loss: 1.921484e-06
Iter: 1729 loss: 1.92085e-06
Iter: 1730 loss: 1.91994241e-06
Iter: 1731 loss: 1.91990557e-06
Iter: 1732 loss: 1.92007133e-06
Iter: 1733 loss: 1.91953018e-06
Iter: 1734 loss: 1.91908566e-06
Iter: 1735 loss: 1.91854565e-06
Iter: 1736 loss: 1.91852041e-06
Iter: 1737 loss: 1.91782874e-06
Iter: 1738 loss: 1.92080097e-06
Iter: 1739 loss: 1.91770914e-06
Iter: 1740 loss: 1.91729919e-06
Iter: 1741 loss: 1.91689719e-06
Iter: 1742 loss: 1.91678578e-06
Iter: 1743 loss: 1.91586014e-06
Iter: 1744 loss: 1.91715708e-06
Iter: 1745 loss: 1.91535332e-06
Iter: 1746 loss: 1.91461368e-06
Iter: 1747 loss: 1.9160816e-06
Iter: 1748 loss: 1.91430081e-06
Iter: 1749 loss: 1.91342951e-06
Iter: 1750 loss: 1.91910499e-06
Iter: 1751 loss: 1.91339223e-06
Iter: 1752 loss: 1.91267372e-06
Iter: 1753 loss: 1.91248478e-06
Iter: 1754 loss: 1.91210415e-06
Iter: 1755 loss: 1.91140953e-06
Iter: 1756 loss: 1.9113902e-06
Iter: 1757 loss: 1.91092477e-06
Iter: 1758 loss: 1.91031313e-06
Iter: 1759 loss: 1.91032154e-06
Iter: 1760 loss: 1.90915625e-06
Iter: 1761 loss: 1.91282925e-06
Iter: 1762 loss: 1.90886522e-06
Iter: 1763 loss: 1.90810556e-06
Iter: 1764 loss: 1.90907849e-06
Iter: 1765 loss: 1.90776291e-06
Iter: 1766 loss: 1.90717117e-06
Iter: 1767 loss: 1.90709829e-06
Iter: 1768 loss: 1.90660091e-06
Iter: 1769 loss: 1.90626884e-06
Iter: 1770 loss: 1.90612877e-06
Iter: 1771 loss: 1.90542073e-06
Iter: 1772 loss: 1.90519654e-06
Iter: 1773 loss: 1.90476703e-06
Iter: 1774 loss: 1.90380968e-06
Iter: 1775 loss: 1.912681e-06
Iter: 1776 loss: 1.90375522e-06
Iter: 1777 loss: 1.90332639e-06
Iter: 1778 loss: 1.90254536e-06
Iter: 1779 loss: 1.9210247e-06
Iter: 1780 loss: 1.90255628e-06
Iter: 1781 loss: 1.90144056e-06
Iter: 1782 loss: 1.90722e-06
Iter: 1783 loss: 1.90126059e-06
Iter: 1784 loss: 1.90050014e-06
Iter: 1785 loss: 1.89995035e-06
Iter: 1786 loss: 1.89971581e-06
Iter: 1787 loss: 1.89887305e-06
Iter: 1788 loss: 1.89885543e-06
Iter: 1789 loss: 1.89820923e-06
Iter: 1790 loss: 1.89824493e-06
Iter: 1791 loss: 1.89775039e-06
Iter: 1792 loss: 1.89683442e-06
Iter: 1793 loss: 1.89961349e-06
Iter: 1794 loss: 1.89654156e-06
Iter: 1795 loss: 1.89574507e-06
Iter: 1796 loss: 1.89826983e-06
Iter: 1797 loss: 1.89553566e-06
Iter: 1798 loss: 1.8949072e-06
Iter: 1799 loss: 1.90200853e-06
Iter: 1800 loss: 1.89492448e-06
Iter: 1801 loss: 1.89448474e-06
Iter: 1802 loss: 1.8958915e-06
Iter: 1803 loss: 1.89430375e-06
Iter: 1804 loss: 1.89386151e-06
Iter: 1805 loss: 1.89317689e-06
Iter: 1806 loss: 1.89316734e-06
Iter: 1807 loss: 1.89258617e-06
Iter: 1808 loss: 1.9010298e-06
Iter: 1809 loss: 1.89259958e-06
Iter: 1810 loss: 1.89214518e-06
Iter: 1811 loss: 1.89139655e-06
Iter: 1812 loss: 1.90836499e-06
Iter: 1813 loss: 1.89140178e-06
Iter: 1814 loss: 1.89051968e-06
Iter: 1815 loss: 1.89831781e-06
Iter: 1816 loss: 1.89045795e-06
Iter: 1817 loss: 1.88994977e-06
Iter: 1818 loss: 1.8893619e-06
Iter: 1819 loss: 1.88927515e-06
Iter: 1820 loss: 1.88866409e-06
Iter: 1821 loss: 1.88866716e-06
Iter: 1822 loss: 1.88820673e-06
Iter: 1823 loss: 1.88858075e-06
Iter: 1824 loss: 1.88784895e-06
Iter: 1825 loss: 1.88723516e-06
Iter: 1826 loss: 1.89064804e-06
Iter: 1827 loss: 1.88713409e-06
Iter: 1828 loss: 1.8866549e-06
Iter: 1829 loss: 1.88755428e-06
Iter: 1830 loss: 1.88642377e-06
Iter: 1831 loss: 1.88599074e-06
Iter: 1832 loss: 1.89107323e-06
Iter: 1833 loss: 1.88598e-06
Iter: 1834 loss: 1.88563308e-06
Iter: 1835 loss: 1.88753859e-06
Iter: 1836 loss: 1.88560239e-06
Iter: 1837 loss: 1.88530203e-06
Iter: 1838 loss: 1.88490628e-06
Iter: 1839 loss: 1.88488059e-06
Iter: 1840 loss: 1.88443778e-06
Iter: 1841 loss: 1.88768013e-06
Iter: 1842 loss: 1.88440833e-06
Iter: 1843 loss: 1.88406773e-06
Iter: 1844 loss: 1.88380034e-06
Iter: 1845 loss: 1.88365743e-06
Iter: 1846 loss: 1.88323099e-06
Iter: 1847 loss: 1.88666604e-06
Iter: 1848 loss: 1.88320951e-06
Iter: 1849 loss: 1.88281047e-06
Iter: 1850 loss: 1.88216723e-06
Iter: 1851 loss: 1.88223e-06
Iter: 1852 loss: 1.88170532e-06
Iter: 1853 loss: 1.88927027e-06
Iter: 1854 loss: 1.88169827e-06
Iter: 1855 loss: 1.88115268e-06
Iter: 1856 loss: 1.88083015e-06
Iter: 1857 loss: 1.8806744e-06
Iter: 1858 loss: 1.88017361e-06
Iter: 1859 loss: 1.88016509e-06
Iter: 1860 loss: 1.87986814e-06
Iter: 1861 loss: 1.87939474e-06
Iter: 1862 loss: 1.8793844e-06
Iter: 1863 loss: 1.87898092e-06
Iter: 1864 loss: 1.87898206e-06
Iter: 1865 loss: 1.8786717e-06
Iter: 1866 loss: 1.87867715e-06
Iter: 1867 loss: 1.87848423e-06
Iter: 1868 loss: 1.87799992e-06
Iter: 1869 loss: 1.88289732e-06
Iter: 1870 loss: 1.87796547e-06
Iter: 1871 loss: 1.87749765e-06
Iter: 1872 loss: 1.88058436e-06
Iter: 1873 loss: 1.8774623e-06
Iter: 1874 loss: 1.87703415e-06
Iter: 1875 loss: 1.87682508e-06
Iter: 1876 loss: 1.87663272e-06
Iter: 1877 loss: 1.87602245e-06
Iter: 1878 loss: 1.87849901e-06
Iter: 1879 loss: 1.87593525e-06
Iter: 1880 loss: 1.8752603e-06
Iter: 1881 loss: 1.87514183e-06
Iter: 1882 loss: 1.87469038e-06
Iter: 1883 loss: 1.87412411e-06
Iter: 1884 loss: 1.88018021e-06
Iter: 1885 loss: 1.87412309e-06
Iter: 1886 loss: 1.87350156e-06
Iter: 1887 loss: 1.87286457e-06
Iter: 1888 loss: 1.87276885e-06
Iter: 1889 loss: 1.87217802e-06
Iter: 1890 loss: 1.88155605e-06
Iter: 1891 loss: 1.87214368e-06
Iter: 1892 loss: 1.87164108e-06
Iter: 1893 loss: 1.87237083e-06
Iter: 1894 loss: 1.87139119e-06
Iter: 1895 loss: 1.87090632e-06
Iter: 1896 loss: 1.87260105e-06
Iter: 1897 loss: 1.87082856e-06
Iter: 1898 loss: 1.87029423e-06
Iter: 1899 loss: 1.87248497e-06
Iter: 1900 loss: 1.87027013e-06
Iter: 1901 loss: 1.86971192e-06
Iter: 1902 loss: 1.87353351e-06
Iter: 1903 loss: 1.86971897e-06
Iter: 1904 loss: 1.86956663e-06
Iter: 1905 loss: 1.86916736e-06
Iter: 1906 loss: 1.87260798e-06
Iter: 1907 loss: 1.86911006e-06
Iter: 1908 loss: 1.86845273e-06
Iter: 1909 loss: 1.87066235e-06
Iter: 1910 loss: 1.8683138e-06
Iter: 1911 loss: 1.86787213e-06
Iter: 1912 loss: 1.86937496e-06
Iter: 1913 loss: 1.86772536e-06
Iter: 1914 loss: 1.86719535e-06
Iter: 1915 loss: 1.86729164e-06
Iter: 1916 loss: 1.86676709e-06
Iter: 1917 loss: 1.86627199e-06
Iter: 1918 loss: 1.86821353e-06
Iter: 1919 loss: 1.86615387e-06
Iter: 1920 loss: 1.86542457e-06
Iter: 1921 loss: 1.86548436e-06
Iter: 1922 loss: 1.86487011e-06
Iter: 1923 loss: 1.86419879e-06
Iter: 1924 loss: 1.86589762e-06
Iter: 1925 loss: 1.86392731e-06
Iter: 1926 loss: 1.86319221e-06
Iter: 1927 loss: 1.8694725e-06
Iter: 1928 loss: 1.86313991e-06
Iter: 1929 loss: 1.86249736e-06
Iter: 1930 loss: 1.86264742e-06
Iter: 1931 loss: 1.86206125e-06
Iter: 1932 loss: 1.86118859e-06
Iter: 1933 loss: 1.8663311e-06
Iter: 1934 loss: 1.86110503e-06
Iter: 1935 loss: 1.86055149e-06
Iter: 1936 loss: 1.86121633e-06
Iter: 1937 loss: 1.86030331e-06
Iter: 1938 loss: 1.85980218e-06
Iter: 1939 loss: 1.85978661e-06
Iter: 1940 loss: 1.8594759e-06
Iter: 1941 loss: 1.85914291e-06
Iter: 1942 loss: 1.85907982e-06
Iter: 1943 loss: 1.8586411e-06
Iter: 1944 loss: 1.85798831e-06
Iter: 1945 loss: 1.85794022e-06
Iter: 1946 loss: 1.85751833e-06
Iter: 1947 loss: 1.85741123e-06
Iter: 1948 loss: 1.85699037e-06
Iter: 1949 loss: 1.85630211e-06
Iter: 1950 loss: 1.85632939e-06
Iter: 1951 loss: 1.85560759e-06
Iter: 1952 loss: 1.86482725e-06
Iter: 1953 loss: 1.85561953e-06
Iter: 1954 loss: 1.85507986e-06
Iter: 1955 loss: 1.85413182e-06
Iter: 1956 loss: 1.87595185e-06
Iter: 1957 loss: 1.8540959e-06
Iter: 1958 loss: 1.85344766e-06
Iter: 1959 loss: 1.85346289e-06
Iter: 1960 loss: 1.85284489e-06
Iter: 1961 loss: 1.85206932e-06
Iter: 1962 loss: 1.85204772e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3/300_300_300_1
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0
+ date
Mon Oct 26 16:31:27 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8fdd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8fc7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8f87598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8f26400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f9024a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f90248c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8ef9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8ef9048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f9024ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8e7b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8ef9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f9024e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8de0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8d8b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8dfcb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8d90d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8d70400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8d17bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8ce09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8d17598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8c91620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8cb9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8c738c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8c2e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8c2e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8bc57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8bc59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8b957b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8b8e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8b63ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8b63d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8b118c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68f8b11950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68d2656400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68d2656e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f68d2656488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.06793777e-05
Iter: 2 loss: 8.65933725e-06
Iter: 3 loss: 7.94514744e-06
Iter: 4 loss: 7.44045838e-06
Iter: 5 loss: 6.85576833e-06
Iter: 6 loss: 6.78647802e-06
Iter: 7 loss: 6.31427611e-06
Iter: 8 loss: 8.30363842e-06
Iter: 9 loss: 6.21460822e-06
Iter: 10 loss: 5.72254476e-06
Iter: 11 loss: 8.78890205e-06
Iter: 12 loss: 5.66543167e-06
Iter: 13 loss: 5.44711747e-06
Iter: 14 loss: 5.6814788e-06
Iter: 15 loss: 5.32699914e-06
Iter: 16 loss: 5.13382292e-06
Iter: 17 loss: 5.32959166e-06
Iter: 18 loss: 5.02565945e-06
Iter: 19 loss: 4.71028352e-06
Iter: 20 loss: 6.59719262e-06
Iter: 21 loss: 4.67065638e-06
Iter: 22 loss: 4.5184056e-06
Iter: 23 loss: 4.12206782e-06
Iter: 24 loss: 7.24600159e-06
Iter: 25 loss: 4.04702905e-06
Iter: 26 loss: 4.06378877e-06
Iter: 27 loss: 3.85139765e-06
Iter: 28 loss: 3.70816451e-06
Iter: 29 loss: 3.8870462e-06
Iter: 30 loss: 3.63383288e-06
Iter: 31 loss: 3.56442115e-06
Iter: 32 loss: 3.41113127e-06
Iter: 33 loss: 5.63128287e-06
Iter: 34 loss: 3.40384486e-06
Iter: 35 loss: 3.41925306e-06
Iter: 36 loss: 3.35581694e-06
Iter: 37 loss: 3.30066632e-06
Iter: 38 loss: 3.35797426e-06
Iter: 39 loss: 3.26998133e-06
Iter: 40 loss: 3.20395293e-06
Iter: 41 loss: 3.07459072e-06
Iter: 42 loss: 5.65937717e-06
Iter: 43 loss: 3.07353184e-06
Iter: 44 loss: 2.96455937e-06
Iter: 45 loss: 2.96050803e-06
Iter: 46 loss: 2.86385239e-06
Iter: 47 loss: 3.01141608e-06
Iter: 48 loss: 2.81789198e-06
Iter: 49 loss: 2.71335261e-06
Iter: 50 loss: 2.63274978e-06
Iter: 51 loss: 2.59950139e-06
Iter: 52 loss: 2.57917327e-06
Iter: 53 loss: 2.55600935e-06
Iter: 54 loss: 2.51702227e-06
Iter: 55 loss: 2.41455473e-06
Iter: 56 loss: 3.19041601e-06
Iter: 57 loss: 2.39384644e-06
Iter: 58 loss: 2.31060608e-06
Iter: 59 loss: 3.18965976e-06
Iter: 60 loss: 2.3085704e-06
Iter: 61 loss: 2.27474402e-06
Iter: 62 loss: 2.272252e-06
Iter: 63 loss: 2.2443046e-06
Iter: 64 loss: 2.16509807e-06
Iter: 65 loss: 2.54633187e-06
Iter: 66 loss: 2.13772273e-06
Iter: 67 loss: 2.07244534e-06
Iter: 68 loss: 2.47559819e-06
Iter: 69 loss: 2.06472305e-06
Iter: 70 loss: 2.04525509e-06
Iter: 71 loss: 2.03649097e-06
Iter: 72 loss: 2.01094645e-06
Iter: 73 loss: 1.9995116e-06
Iter: 74 loss: 1.9866693e-06
Iter: 75 loss: 1.96223436e-06
Iter: 76 loss: 1.8963799e-06
Iter: 77 loss: 2.33243236e-06
Iter: 78 loss: 1.88035983e-06
Iter: 79 loss: 1.93068217e-06
Iter: 80 loss: 1.85131171e-06
Iter: 81 loss: 1.82765598e-06
Iter: 82 loss: 1.8328351e-06
Iter: 83 loss: 1.81025416e-06
Iter: 84 loss: 1.78862456e-06
Iter: 85 loss: 1.85643955e-06
Iter: 86 loss: 1.7824384e-06
Iter: 87 loss: 1.76159517e-06
Iter: 88 loss: 1.94661311e-06
Iter: 89 loss: 1.76057927e-06
Iter: 90 loss: 1.74960792e-06
Iter: 91 loss: 1.75147795e-06
Iter: 92 loss: 1.74139859e-06
Iter: 93 loss: 1.72808063e-06
Iter: 94 loss: 1.71333511e-06
Iter: 95 loss: 1.71125407e-06
Iter: 96 loss: 1.71042279e-06
Iter: 97 loss: 1.70115595e-06
Iter: 98 loss: 1.69352961e-06
Iter: 99 loss: 1.66656855e-06
Iter: 100 loss: 1.6232633e-06
Iter: 101 loss: 1.61971639e-06
Iter: 102 loss: 1.57773388e-06
Iter: 103 loss: 1.57551347e-06
Iter: 104 loss: 1.55648672e-06
Iter: 105 loss: 1.72901878e-06
Iter: 106 loss: 1.55562589e-06
Iter: 107 loss: 1.53199301e-06
Iter: 108 loss: 1.5607e-06
Iter: 109 loss: 1.51960171e-06
Iter: 110 loss: 1.51040626e-06
Iter: 111 loss: 1.50753704e-06
Iter: 112 loss: 1.50211031e-06
Iter: 113 loss: 1.49246148e-06
Iter: 114 loss: 1.49207449e-06
Iter: 115 loss: 1.48478375e-06
Iter: 116 loss: 1.47473725e-06
Iter: 117 loss: 1.47432115e-06
Iter: 118 loss: 1.46065747e-06
Iter: 119 loss: 1.47324579e-06
Iter: 120 loss: 1.45279887e-06
Iter: 121 loss: 1.43063596e-06
Iter: 122 loss: 1.55932707e-06
Iter: 123 loss: 1.42763929e-06
Iter: 124 loss: 1.41909527e-06
Iter: 125 loss: 1.41645728e-06
Iter: 126 loss: 1.41139788e-06
Iter: 127 loss: 1.39847327e-06
Iter: 128 loss: 1.41082319e-06
Iter: 129 loss: 1.39107806e-06
Iter: 130 loss: 1.37875622e-06
Iter: 131 loss: 1.37872394e-06
Iter: 132 loss: 1.36966651e-06
Iter: 133 loss: 1.38162943e-06
Iter: 134 loss: 1.36509641e-06
Iter: 135 loss: 1.35838206e-06
Iter: 136 loss: 1.34365632e-06
Iter: 137 loss: 1.55859061e-06
Iter: 138 loss: 1.34299341e-06
Iter: 139 loss: 1.3415729e-06
Iter: 140 loss: 1.33673734e-06
Iter: 141 loss: 1.32985315e-06
Iter: 142 loss: 1.329675e-06
Iter: 143 loss: 1.32427886e-06
Iter: 144 loss: 1.31726688e-06
Iter: 145 loss: 1.31641536e-06
Iter: 146 loss: 1.31138768e-06
Iter: 147 loss: 1.30794706e-06
Iter: 148 loss: 1.30686715e-06
Iter: 149 loss: 1.30207161e-06
Iter: 150 loss: 1.28826e-06
Iter: 151 loss: 1.34292509e-06
Iter: 152 loss: 1.2824803e-06
Iter: 153 loss: 1.28506395e-06
Iter: 154 loss: 1.27650981e-06
Iter: 155 loss: 1.27123417e-06
Iter: 156 loss: 1.26379814e-06
Iter: 157 loss: 1.26351779e-06
Iter: 158 loss: 1.2541866e-06
Iter: 159 loss: 1.25035911e-06
Iter: 160 loss: 1.24539633e-06
Iter: 161 loss: 1.24353505e-06
Iter: 162 loss: 1.24100939e-06
Iter: 163 loss: 1.2375508e-06
Iter: 164 loss: 1.24328562e-06
Iter: 165 loss: 1.23599432e-06
Iter: 166 loss: 1.23167047e-06
Iter: 167 loss: 1.22848746e-06
Iter: 168 loss: 1.22703966e-06
Iter: 169 loss: 1.22250208e-06
Iter: 170 loss: 1.22110032e-06
Iter: 171 loss: 1.21844369e-06
Iter: 172 loss: 1.21147207e-06
Iter: 173 loss: 1.21147696e-06
Iter: 174 loss: 1.2053539e-06
Iter: 175 loss: 1.19562992e-06
Iter: 176 loss: 1.19554602e-06
Iter: 177 loss: 1.18948947e-06
Iter: 178 loss: 1.22288986e-06
Iter: 179 loss: 1.18859441e-06
Iter: 180 loss: 1.17988679e-06
Iter: 181 loss: 1.19153128e-06
Iter: 182 loss: 1.17549848e-06
Iter: 183 loss: 1.17165598e-06
Iter: 184 loss: 1.18391347e-06
Iter: 185 loss: 1.17058744e-06
Iter: 186 loss: 1.16667024e-06
Iter: 187 loss: 1.20056541e-06
Iter: 188 loss: 1.16642968e-06
Iter: 189 loss: 1.16386889e-06
Iter: 190 loss: 1.1581219e-06
Iter: 191 loss: 1.23546852e-06
Iter: 192 loss: 1.15776561e-06
Iter: 193 loss: 1.15288935e-06
Iter: 194 loss: 1.17922684e-06
Iter: 195 loss: 1.1521646e-06
Iter: 196 loss: 1.14657769e-06
Iter: 197 loss: 1.18299931e-06
Iter: 198 loss: 1.14597447e-06
Iter: 199 loss: 1.14180898e-06
Iter: 200 loss: 1.14829311e-06
Iter: 201 loss: 1.13983833e-06
Iter: 202 loss: 1.13607393e-06
Iter: 203 loss: 1.1306322e-06
Iter: 204 loss: 1.13046985e-06
Iter: 205 loss: 1.12574548e-06
Iter: 206 loss: 1.12552414e-06
Iter: 207 loss: 1.12112525e-06
Iter: 208 loss: 1.12861619e-06
Iter: 209 loss: 1.11914846e-06
Iter: 210 loss: 1.11642748e-06
Iter: 211 loss: 1.11150121e-06
Iter: 212 loss: 1.22971142e-06
Iter: 213 loss: 1.11151076e-06
Iter: 214 loss: 1.10906103e-06
Iter: 215 loss: 1.10779217e-06
Iter: 216 loss: 1.10622364e-06
Iter: 217 loss: 1.10228223e-06
Iter: 218 loss: 1.13815884e-06
Iter: 219 loss: 1.10165513e-06
Iter: 220 loss: 1.09985024e-06
Iter: 221 loss: 1.09906091e-06
Iter: 222 loss: 1.0970225e-06
Iter: 223 loss: 1.09455971e-06
Iter: 224 loss: 1.09432756e-06
Iter: 225 loss: 1.09167513e-06
Iter: 226 loss: 1.09087e-06
Iter: 227 loss: 1.08928407e-06
Iter: 228 loss: 1.08503218e-06
Iter: 229 loss: 1.1034208e-06
Iter: 230 loss: 1.08412121e-06
Iter: 231 loss: 1.0813269e-06
Iter: 232 loss: 1.08137465e-06
Iter: 233 loss: 1.07913388e-06
Iter: 234 loss: 1.07425558e-06
Iter: 235 loss: 1.07594087e-06
Iter: 236 loss: 1.07080052e-06
Iter: 237 loss: 1.0660815e-06
Iter: 238 loss: 1.1218666e-06
Iter: 239 loss: 1.06599396e-06
Iter: 240 loss: 1.06299296e-06
Iter: 241 loss: 1.09569112e-06
Iter: 242 loss: 1.06292941e-06
Iter: 243 loss: 1.06156301e-06
Iter: 244 loss: 1.05809363e-06
Iter: 245 loss: 1.09139239e-06
Iter: 246 loss: 1.05765162e-06
Iter: 247 loss: 1.05813376e-06
Iter: 248 loss: 1.05616868e-06
Iter: 249 loss: 1.05497747e-06
Iter: 250 loss: 1.05163167e-06
Iter: 251 loss: 1.0667045e-06
Iter: 252 loss: 1.05043728e-06
Iter: 253 loss: 1.04749165e-06
Iter: 254 loss: 1.04743117e-06
Iter: 255 loss: 1.04418359e-06
Iter: 256 loss: 1.04635058e-06
Iter: 257 loss: 1.04215871e-06
Iter: 258 loss: 1.03909008e-06
Iter: 259 loss: 1.03568595e-06
Iter: 260 loss: 1.03520051e-06
Iter: 261 loss: 1.03026264e-06
Iter: 262 loss: 1.10864164e-06
Iter: 263 loss: 1.03028844e-06
Iter: 264 loss: 1.02839908e-06
Iter: 265 loss: 1.02678155e-06
Iter: 266 loss: 1.02624779e-06
Iter: 267 loss: 1.02284719e-06
Iter: 268 loss: 1.03141224e-06
Iter: 269 loss: 1.02161846e-06
Iter: 270 loss: 1.01935768e-06
Iter: 271 loss: 1.02518698e-06
Iter: 272 loss: 1.0185571e-06
Iter: 273 loss: 1.0165304e-06
Iter: 274 loss: 1.04368689e-06
Iter: 275 loss: 1.01650232e-06
Iter: 276 loss: 1.01491617e-06
Iter: 277 loss: 1.01149294e-06
Iter: 278 loss: 1.06114612e-06
Iter: 279 loss: 1.01133355e-06
Iter: 280 loss: 1.00994384e-06
Iter: 281 loss: 1.00964519e-06
Iter: 282 loss: 1.00768125e-06
Iter: 283 loss: 1.00309308e-06
Iter: 284 loss: 1.05828838e-06
Iter: 285 loss: 1.0027743e-06
Iter: 286 loss: 9.99495342e-07
Iter: 287 loss: 1.03158322e-06
Iter: 288 loss: 9.99376425e-07
Iter: 289 loss: 9.96625204e-07
Iter: 290 loss: 1.02690205e-06
Iter: 291 loss: 9.96555286e-07
Iter: 292 loss: 9.95046094e-07
Iter: 293 loss: 9.91834554e-07
Iter: 294 loss: 1.04458218e-06
Iter: 295 loss: 9.91724e-07
Iter: 296 loss: 9.90362196e-07
Iter: 297 loss: 9.8980081e-07
Iter: 298 loss: 9.88659622e-07
Iter: 299 loss: 9.85999804e-07
Iter: 300 loss: 1.01802425e-06
Iter: 301 loss: 9.85810289e-07
Iter: 302 loss: 9.82653546e-07
Iter: 303 loss: 1.00207455e-06
Iter: 304 loss: 9.82275e-07
Iter: 305 loss: 9.801837e-07
Iter: 306 loss: 9.80807272e-07
Iter: 307 loss: 9.78624939e-07
Iter: 308 loss: 9.76484e-07
Iter: 309 loss: 9.76483079e-07
Iter: 310 loss: 9.74324166e-07
Iter: 311 loss: 9.72598627e-07
Iter: 312 loss: 9.7194993e-07
Iter: 313 loss: 9.7018517e-07
Iter: 314 loss: 9.78861181e-07
Iter: 315 loss: 9.69888788e-07
Iter: 316 loss: 9.6728013e-07
Iter: 317 loss: 9.66388e-07
Iter: 318 loss: 9.64888841e-07
Iter: 319 loss: 9.62699914e-07
Iter: 320 loss: 9.61873184e-07
Iter: 321 loss: 9.6065969e-07
Iter: 322 loss: 9.59526e-07
Iter: 323 loss: 9.58785563e-07
Iter: 324 loss: 9.57234761e-07
Iter: 325 loss: 9.5421467e-07
Iter: 326 loss: 1.0164498e-06
Iter: 327 loss: 9.54198299e-07
Iter: 328 loss: 9.52608275e-07
Iter: 329 loss: 9.66068228e-07
Iter: 330 loss: 9.525005e-07
Iter: 331 loss: 9.50284516e-07
Iter: 332 loss: 9.50269111e-07
Iter: 333 loss: 9.48507648e-07
Iter: 334 loss: 9.47109072e-07
Iter: 335 loss: 9.55617224e-07
Iter: 336 loss: 9.46941441e-07
Iter: 337 loss: 9.45568615e-07
Iter: 338 loss: 9.43717055e-07
Iter: 339 loss: 9.43641339e-07
Iter: 340 loss: 9.41319627e-07
Iter: 341 loss: 9.69276243e-07
Iter: 342 loss: 9.41307917e-07
Iter: 343 loss: 9.39190841e-07
Iter: 344 loss: 9.44183228e-07
Iter: 345 loss: 9.38444259e-07
Iter: 346 loss: 9.36938477e-07
Iter: 347 loss: 9.35991125e-07
Iter: 348 loss: 9.35385629e-07
Iter: 349 loss: 9.3251839e-07
Iter: 350 loss: 9.5439691e-07
Iter: 351 loss: 9.32307444e-07
Iter: 352 loss: 9.31198e-07
Iter: 353 loss: 9.28752e-07
Iter: 354 loss: 9.62681383e-07
Iter: 355 loss: 9.28632971e-07
Iter: 356 loss: 9.28113309e-07
Iter: 357 loss: 9.274371e-07
Iter: 358 loss: 9.26262601e-07
Iter: 359 loss: 9.25661254e-07
Iter: 360 loss: 9.25106917e-07
Iter: 361 loss: 9.23729544e-07
Iter: 362 loss: 9.20853665e-07
Iter: 363 loss: 9.68223162e-07
Iter: 364 loss: 9.2078227e-07
Iter: 365 loss: 9.21075411e-07
Iter: 366 loss: 9.19196623e-07
Iter: 367 loss: 9.18428441e-07
Iter: 368 loss: 9.16220358e-07
Iter: 369 loss: 9.26440919e-07
Iter: 370 loss: 9.15435749e-07
Iter: 371 loss: 9.12713631e-07
Iter: 372 loss: 9.27867632e-07
Iter: 373 loss: 9.12337669e-07
Iter: 374 loss: 9.10621679e-07
Iter: 375 loss: 9.21163746e-07
Iter: 376 loss: 9.10435915e-07
Iter: 377 loss: 9.09301662e-07
Iter: 378 loss: 9.1701429e-07
Iter: 379 loss: 9.09194682e-07
Iter: 380 loss: 9.08096922e-07
Iter: 381 loss: 9.07677361e-07
Iter: 382 loss: 9.07036281e-07
Iter: 383 loss: 9.06276682e-07
Iter: 384 loss: 9.06268212e-07
Iter: 385 loss: 9.05499917e-07
Iter: 386 loss: 9.03353794e-07
Iter: 387 loss: 9.14308316e-07
Iter: 388 loss: 9.0266758e-07
Iter: 389 loss: 9.01022872e-07
Iter: 390 loss: 9.0091271e-07
Iter: 391 loss: 8.99253564e-07
Iter: 392 loss: 9.01373483e-07
Iter: 393 loss: 8.98371127e-07
Iter: 394 loss: 8.97240625e-07
Iter: 395 loss: 8.99075133e-07
Iter: 396 loss: 8.96679239e-07
Iter: 397 loss: 8.95380253e-07
Iter: 398 loss: 8.94798745e-07
Iter: 399 loss: 8.94174548e-07
Iter: 400 loss: 8.91695208e-07
Iter: 401 loss: 9.15412556e-07
Iter: 402 loss: 8.91599484e-07
Iter: 403 loss: 8.90631497e-07
Iter: 404 loss: 8.88644649e-07
Iter: 405 loss: 9.20333946e-07
Iter: 406 loss: 8.88573425e-07
Iter: 407 loss: 8.86332884e-07
Iter: 408 loss: 9.02266152e-07
Iter: 409 loss: 8.86142857e-07
Iter: 410 loss: 8.84751785e-07
Iter: 411 loss: 8.84704946e-07
Iter: 412 loss: 8.83894586e-07
Iter: 413 loss: 8.84111955e-07
Iter: 414 loss: 8.83266807e-07
Iter: 415 loss: 8.82109418e-07
Iter: 416 loss: 8.82556833e-07
Iter: 417 loss: 8.81280357e-07
Iter: 418 loss: 8.79982906e-07
Iter: 419 loss: 8.79996605e-07
Iter: 420 loss: 8.79523e-07
Iter: 421 loss: 8.78306309e-07
Iter: 422 loss: 8.87512613e-07
Iter: 423 loss: 8.78098263e-07
Iter: 424 loss: 8.7704052e-07
Iter: 425 loss: 8.7695679e-07
Iter: 426 loss: 8.76036324e-07
Iter: 427 loss: 8.75144792e-07
Iter: 428 loss: 8.74929469e-07
Iter: 429 loss: 8.74140483e-07
Iter: 430 loss: 8.74521675e-07
Iter: 431 loss: 8.73563295e-07
Iter: 432 loss: 8.72908629e-07
Iter: 433 loss: 8.72830867e-07
Iter: 434 loss: 8.72274086e-07
Iter: 435 loss: 8.71172574e-07
Iter: 436 loss: 8.9405961e-07
Iter: 437 loss: 8.71174166e-07
Iter: 438 loss: 8.70013594e-07
Iter: 439 loss: 8.70868234e-07
Iter: 440 loss: 8.69250869e-07
Iter: 441 loss: 8.68391965e-07
Iter: 442 loss: 8.81051903e-07
Iter: 443 loss: 8.68380539e-07
Iter: 444 loss: 8.67537608e-07
Iter: 445 loss: 8.66575476e-07
Iter: 446 loss: 8.66451614e-07
Iter: 447 loss: 8.64679578e-07
Iter: 448 loss: 8.70481927e-07
Iter: 449 loss: 8.64230913e-07
Iter: 450 loss: 8.63483137e-07
Iter: 451 loss: 8.63425385e-07
Iter: 452 loss: 8.62913339e-07
Iter: 453 loss: 8.6151357e-07
Iter: 454 loss: 8.71412112e-07
Iter: 455 loss: 8.61206217e-07
Iter: 456 loss: 8.60778414e-07
Iter: 457 loss: 8.60517957e-07
Iter: 458 loss: 8.59804118e-07
Iter: 459 loss: 8.59081524e-07
Iter: 460 loss: 8.58950557e-07
Iter: 461 loss: 8.57708471e-07
Iter: 462 loss: 8.56025622e-07
Iter: 463 loss: 8.55935809e-07
Iter: 464 loss: 8.55822918e-07
Iter: 465 loss: 8.55166e-07
Iter: 466 loss: 8.54444409e-07
Iter: 467 loss: 8.53026563e-07
Iter: 468 loss: 8.84721089e-07
Iter: 469 loss: 8.53027927e-07
Iter: 470 loss: 8.51629693e-07
Iter: 471 loss: 8.58782926e-07
Iter: 472 loss: 8.51411073e-07
Iter: 473 loss: 8.50658182e-07
Iter: 474 loss: 8.61984745e-07
Iter: 475 loss: 8.50668812e-07
Iter: 476 loss: 8.50015e-07
Iter: 477 loss: 8.49624257e-07
Iter: 478 loss: 8.49337e-07
Iter: 479 loss: 8.48371769e-07
Iter: 480 loss: 8.53575955e-07
Iter: 481 loss: 8.48274226e-07
Iter: 482 loss: 8.47654064e-07
Iter: 483 loss: 8.51814434e-07
Iter: 484 loss: 8.47580793e-07
Iter: 485 loss: 8.46896569e-07
Iter: 486 loss: 8.45752652e-07
Iter: 487 loss: 8.45743784e-07
Iter: 488 loss: 8.45017723e-07
Iter: 489 loss: 8.52699714e-07
Iter: 490 loss: 8.45020111e-07
Iter: 491 loss: 8.44301212e-07
Iter: 492 loss: 8.47826698e-07
Iter: 493 loss: 8.44209239e-07
Iter: 494 loss: 8.43676276e-07
Iter: 495 loss: 8.4238161e-07
Iter: 496 loss: 8.54123414e-07
Iter: 497 loss: 8.42173222e-07
Iter: 498 loss: 8.41298174e-07
Iter: 499 loss: 8.41259521e-07
Iter: 500 loss: 8.40152836e-07
Iter: 501 loss: 8.40061e-07
Iter: 502 loss: 8.39268523e-07
Iter: 503 loss: 8.3823852e-07
Iter: 504 loss: 8.40996e-07
Iter: 505 loss: 8.37931566e-07
Iter: 506 loss: 8.37144057e-07
Iter: 507 loss: 8.45044042e-07
Iter: 508 loss: 8.37133598e-07
Iter: 509 loss: 8.36299193e-07
Iter: 510 loss: 8.36314598e-07
Iter: 511 loss: 8.35624519e-07
Iter: 512 loss: 8.34733669e-07
Iter: 513 loss: 8.3975749e-07
Iter: 514 loss: 8.34629759e-07
Iter: 515 loss: 8.34108278e-07
Iter: 516 loss: 8.37148718e-07
Iter: 517 loss: 8.34021932e-07
Iter: 518 loss: 8.3344338e-07
Iter: 519 loss: 8.33076513e-07
Iter: 520 loss: 8.32824298e-07
Iter: 521 loss: 8.3205191e-07
Iter: 522 loss: 8.33059175e-07
Iter: 523 loss: 8.31696923e-07
Iter: 524 loss: 8.30871727e-07
Iter: 525 loss: 8.42916e-07
Iter: 526 loss: 8.30881902e-07
Iter: 527 loss: 8.30246904e-07
Iter: 528 loss: 8.28713667e-07
Iter: 529 loss: 8.42265592e-07
Iter: 530 loss: 8.28519546e-07
Iter: 531 loss: 8.27438441e-07
Iter: 532 loss: 8.43456121e-07
Iter: 533 loss: 8.27429517e-07
Iter: 534 loss: 8.26306064e-07
Iter: 535 loss: 8.28459065e-07
Iter: 536 loss: 8.25822667e-07
Iter: 537 loss: 8.24917095e-07
Iter: 538 loss: 8.25335178e-07
Iter: 539 loss: 8.24347467e-07
Iter: 540 loss: 8.23692744e-07
Iter: 541 loss: 8.33971399e-07
Iter: 542 loss: 8.23706102e-07
Iter: 543 loss: 8.23071161e-07
Iter: 544 loss: 8.23244363e-07
Iter: 545 loss: 8.22605045e-07
Iter: 546 loss: 8.21877165e-07
Iter: 547 loss: 8.24146582e-07
Iter: 548 loss: 8.21692197e-07
Iter: 549 loss: 8.21138e-07
Iter: 550 loss: 8.23088385e-07
Iter: 551 loss: 8.20989158e-07
Iter: 552 loss: 8.20263836e-07
Iter: 553 loss: 8.20961816e-07
Iter: 554 loss: 8.19904869e-07
Iter: 555 loss: 8.19246338e-07
Iter: 556 loss: 8.19649699e-07
Iter: 557 loss: 8.18868727e-07
Iter: 558 loss: 8.183099e-07
Iter: 559 loss: 8.18320927e-07
Iter: 560 loss: 8.17813827e-07
Iter: 561 loss: 8.16565603e-07
Iter: 562 loss: 8.25407e-07
Iter: 563 loss: 8.16296847e-07
Iter: 564 loss: 8.15173337e-07
Iter: 565 loss: 8.25834206e-07
Iter: 566 loss: 8.15119392e-07
Iter: 567 loss: 8.14019813e-07
Iter: 568 loss: 8.20544869e-07
Iter: 569 loss: 8.13868496e-07
Iter: 570 loss: 8.1328642e-07
Iter: 571 loss: 8.13098609e-07
Iter: 572 loss: 8.12752e-07
Iter: 573 loss: 8.12140115e-07
Iter: 574 loss: 8.17762384e-07
Iter: 575 loss: 8.12115786e-07
Iter: 576 loss: 8.11550478e-07
Iter: 577 loss: 8.12633914e-07
Iter: 578 loss: 8.1129707e-07
Iter: 579 loss: 8.10789857e-07
Iter: 580 loss: 8.12190819e-07
Iter: 581 loss: 8.10651215e-07
Iter: 582 loss: 8.10202664e-07
Iter: 583 loss: 8.11272628e-07
Iter: 584 loss: 8.10039e-07
Iter: 585 loss: 8.09455628e-07
Iter: 586 loss: 8.10732786e-07
Iter: 587 loss: 8.09223934e-07
Iter: 588 loss: 8.08677441e-07
Iter: 589 loss: 8.08322682e-07
Iter: 590 loss: 8.0813e-07
Iter: 591 loss: 8.07506126e-07
Iter: 592 loss: 8.07505899e-07
Iter: 593 loss: 8.06859589e-07
Iter: 594 loss: 8.05673e-07
Iter: 595 loss: 8.31591763e-07
Iter: 596 loss: 8.05654622e-07
Iter: 597 loss: 8.04989156e-07
Iter: 598 loss: 8.09748826e-07
Iter: 599 loss: 8.04913384e-07
Iter: 600 loss: 8.04231718e-07
Iter: 601 loss: 8.08290622e-07
Iter: 602 loss: 8.04126955e-07
Iter: 603 loss: 8.03690568e-07
Iter: 604 loss: 8.03360763e-07
Iter: 605 loss: 8.0321081e-07
Iter: 606 loss: 8.02677619e-07
Iter: 607 loss: 8.07116e-07
Iter: 608 loss: 8.02622083e-07
Iter: 609 loss: 8.02069792e-07
Iter: 610 loss: 8.03649414e-07
Iter: 611 loss: 8.01896817e-07
Iter: 612 loss: 8.01500846e-07
Iter: 613 loss: 8.02413524e-07
Iter: 614 loss: 8.01320141e-07
Iter: 615 loss: 8.0091246e-07
Iter: 616 loss: 8.01486067e-07
Iter: 617 loss: 8.0067764e-07
Iter: 618 loss: 8.00058331e-07
Iter: 619 loss: 8.02215254e-07
Iter: 620 loss: 7.99918894e-07
Iter: 621 loss: 7.99430836e-07
Iter: 622 loss: 7.99031568e-07
Iter: 623 loss: 7.98897872e-07
Iter: 624 loss: 7.98327733e-07
Iter: 625 loss: 7.98318e-07
Iter: 626 loss: 7.97813698e-07
Iter: 627 loss: 7.97060466e-07
Iter: 628 loss: 7.97024427e-07
Iter: 629 loss: 7.96431891e-07
Iter: 630 loss: 7.9768e-07
Iter: 631 loss: 7.96177915e-07
Iter: 632 loss: 7.95490735e-07
Iter: 633 loss: 8.04220804e-07
Iter: 634 loss: 7.95463848e-07
Iter: 635 loss: 7.95073e-07
Iter: 636 loss: 7.94717153e-07
Iter: 637 loss: 7.94614607e-07
Iter: 638 loss: 7.94111e-07
Iter: 639 loss: 7.97919256e-07
Iter: 640 loss: 7.94119217e-07
Iter: 641 loss: 7.93701588e-07
Iter: 642 loss: 7.95258075e-07
Iter: 643 loss: 7.93588811e-07
Iter: 644 loss: 7.93215406e-07
Iter: 645 loss: 7.93555841e-07
Iter: 646 loss: 7.93039703e-07
Iter: 647 loss: 7.92613946e-07
Iter: 648 loss: 7.93144181e-07
Iter: 649 loss: 7.92407e-07
Iter: 650 loss: 7.91820923e-07
Iter: 651 loss: 7.94511209e-07
Iter: 652 loss: 7.91725199e-07
Iter: 653 loss: 7.91274203e-07
Iter: 654 loss: 7.90889544e-07
Iter: 655 loss: 7.90787681e-07
Iter: 656 loss: 7.90275465e-07
Iter: 657 loss: 7.90256934e-07
Iter: 658 loss: 7.89822593e-07
Iter: 659 loss: 7.89368926e-07
Iter: 660 loss: 7.89275191e-07
Iter: 661 loss: 7.88806233e-07
Iter: 662 loss: 7.89150818e-07
Iter: 663 loss: 7.88512921e-07
Iter: 664 loss: 7.88008776e-07
Iter: 665 loss: 7.88008606e-07
Iter: 666 loss: 7.87721035e-07
Iter: 667 loss: 7.87387648e-07
Iter: 668 loss: 7.87351155e-07
Iter: 669 loss: 7.8690806e-07
Iter: 670 loss: 7.89542355e-07
Iter: 671 loss: 7.86846158e-07
Iter: 672 loss: 7.86418809e-07
Iter: 673 loss: 7.88820557e-07
Iter: 674 loss: 7.86348e-07
Iter: 675 loss: 7.86086389e-07
Iter: 676 loss: 7.86153748e-07
Iter: 677 loss: 7.85887323e-07
Iter: 678 loss: 7.85483223e-07
Iter: 679 loss: 7.86158353e-07
Iter: 680 loss: 7.85320537e-07
Iter: 681 loss: 7.84820486e-07
Iter: 682 loss: 7.87758154e-07
Iter: 683 loss: 7.84767906e-07
Iter: 684 loss: 7.84434633e-07
Iter: 685 loss: 7.84038662e-07
Iter: 686 loss: 7.83963628e-07
Iter: 687 loss: 7.83537416e-07
Iter: 688 loss: 7.83539861e-07
Iter: 689 loss: 7.83130815e-07
Iter: 690 loss: 7.82831933e-07
Iter: 691 loss: 7.82685106e-07
Iter: 692 loss: 7.82223481e-07
Iter: 693 loss: 7.82171583e-07
Iter: 694 loss: 7.81821768e-07
Iter: 695 loss: 7.81467634e-07
Iter: 696 loss: 7.81413519e-07
Iter: 697 loss: 7.81169831e-07
Iter: 698 loss: 7.80767721e-07
Iter: 699 loss: 7.80783e-07
Iter: 700 loss: 7.80304219e-07
Iter: 701 loss: 7.83129735e-07
Iter: 702 loss: 7.80250502e-07
Iter: 703 loss: 7.79883635e-07
Iter: 704 loss: 7.83300891e-07
Iter: 705 loss: 7.79878292e-07
Iter: 706 loss: 7.79666721e-07
Iter: 707 loss: 7.79495394e-07
Iter: 708 loss: 7.79395577e-07
Iter: 709 loss: 7.78986646e-07
Iter: 710 loss: 7.79773586e-07
Iter: 711 loss: 7.78782123e-07
Iter: 712 loss: 7.7827633e-07
Iter: 713 loss: 7.8138595e-07
Iter: 714 loss: 7.78203912e-07
Iter: 715 loss: 7.77824e-07
Iter: 716 loss: 7.77473929e-07
Iter: 717 loss: 7.77366722e-07
Iter: 718 loss: 7.76981324e-07
Iter: 719 loss: 7.76979846e-07
Iter: 720 loss: 7.76565287e-07
Iter: 721 loss: 7.76509069e-07
Iter: 722 loss: 7.76234856e-07
Iter: 723 loss: 7.75822059e-07
Iter: 724 loss: 7.75766694e-07
Iter: 725 loss: 7.75469402e-07
Iter: 726 loss: 7.75187686e-07
Iter: 727 loss: 7.75150056e-07
Iter: 728 loss: 7.74900741e-07
Iter: 729 loss: 7.74589239e-07
Iter: 730 loss: 7.74565e-07
Iter: 731 loss: 7.74193381e-07
Iter: 732 loss: 7.76600814e-07
Iter: 733 loss: 7.74165301e-07
Iter: 734 loss: 7.73902684e-07
Iter: 735 loss: 7.75902549e-07
Iter: 736 loss: 7.73899728e-07
Iter: 737 loss: 7.73691795e-07
Iter: 738 loss: 7.73580382e-07
Iter: 739 loss: 7.73462489e-07
Iter: 740 loss: 7.73113925e-07
Iter: 741 loss: 7.74137106e-07
Iter: 742 loss: 7.73039346e-07
Iter: 743 loss: 7.72667761e-07
Iter: 744 loss: 7.74665239e-07
Iter: 745 loss: 7.72616545e-07
Iter: 746 loss: 7.72307374e-07
Iter: 747 loss: 7.71959265e-07
Iter: 748 loss: 7.71945622e-07
Iter: 749 loss: 7.71570285e-07
Iter: 750 loss: 7.71578925e-07
Iter: 751 loss: 7.7125344e-07
Iter: 752 loss: 7.71267423e-07
Iter: 753 loss: 7.70986333e-07
Iter: 754 loss: 7.70668123e-07
Iter: 755 loss: 7.70323595e-07
Iter: 756 loss: 7.70267093e-07
Iter: 757 loss: 7.7008292e-07
Iter: 758 loss: 7.69977532e-07
Iter: 759 loss: 7.69804956e-07
Iter: 760 loss: 7.69607823e-07
Iter: 761 loss: 7.69588723e-07
Iter: 762 loss: 7.69323492e-07
Iter: 763 loss: 7.70196777e-07
Iter: 764 loss: 7.69252381e-07
Iter: 765 loss: 7.68988343e-07
Iter: 766 loss: 7.72740464e-07
Iter: 767 loss: 7.69004373e-07
Iter: 768 loss: 7.6882651e-07
Iter: 769 loss: 7.68677864e-07
Iter: 770 loss: 7.6864319e-07
Iter: 771 loss: 7.68342886e-07
Iter: 772 loss: 7.68976065e-07
Iter: 773 loss: 7.68240568e-07
Iter: 774 loss: 7.67884899e-07
Iter: 775 loss: 7.70307793e-07
Iter: 776 loss: 7.6783158e-07
Iter: 777 loss: 7.67584083e-07
Iter: 778 loss: 7.67276333e-07
Iter: 779 loss: 7.67229608e-07
Iter: 780 loss: 7.66932033e-07
Iter: 781 loss: 7.66939479e-07
Iter: 782 loss: 7.66666631e-07
Iter: 783 loss: 7.66767357e-07
Iter: 784 loss: 7.66473249e-07
Iter: 785 loss: 7.66182609e-07
Iter: 786 loss: 7.65967457e-07
Iter: 787 loss: 7.65902485e-07
Iter: 788 loss: 7.65719392e-07
Iter: 789 loss: 7.65648394e-07
Iter: 790 loss: 7.65514301e-07
Iter: 791 loss: 7.6525e-07
Iter: 792 loss: 7.6523969e-07
Iter: 793 loss: 7.64934271e-07
Iter: 794 loss: 7.65287552e-07
Iter: 795 loss: 7.64786e-07
Iter: 796 loss: 7.64513459e-07
Iter: 797 loss: 7.64494757e-07
Iter: 798 loss: 7.64324795e-07
Iter: 799 loss: 7.64007837e-07
Iter: 800 loss: 7.640121e-07
Iter: 801 loss: 7.63584e-07
Iter: 802 loss: 7.64628055e-07
Iter: 803 loss: 7.6342485e-07
Iter: 804 loss: 7.62981188e-07
Iter: 805 loss: 7.66714493e-07
Iter: 806 loss: 7.62946456e-07
Iter: 807 loss: 7.6265e-07
Iter: 808 loss: 7.62255809e-07
Iter: 809 loss: 7.62249215e-07
Iter: 810 loss: 7.61844205e-07
Iter: 811 loss: 7.61834826e-07
Iter: 812 loss: 7.61505817e-07
Iter: 813 loss: 7.61717899e-07
Iter: 814 loss: 7.61292085e-07
Iter: 815 loss: 7.60944886e-07
Iter: 816 loss: 7.60537205e-07
Iter: 817 loss: 7.60530156e-07
Iter: 818 loss: 7.60337969e-07
Iter: 819 loss: 7.60206035e-07
Iter: 820 loss: 7.59989632e-07
Iter: 821 loss: 7.59587124e-07
Iter: 822 loss: 7.59584282e-07
Iter: 823 loss: 7.59099407e-07
Iter: 824 loss: 7.58958322e-07
Iter: 825 loss: 7.58654892e-07
Iter: 826 loss: 7.5833907e-07
Iter: 827 loss: 7.58187412e-07
Iter: 828 loss: 7.5786204e-07
Iter: 829 loss: 7.57316968e-07
Iter: 830 loss: 7.57314e-07
Iter: 831 loss: 7.56620807e-07
Iter: 832 loss: 7.59771751e-07
Iter: 833 loss: 7.56501834e-07
Iter: 834 loss: 7.55948065e-07
Iter: 835 loss: 7.60932551e-07
Iter: 836 loss: 7.55911174e-07
Iter: 837 loss: 7.55544875e-07
Iter: 838 loss: 7.5495393e-07
Iter: 839 loss: 7.54938e-07
Iter: 840 loss: 7.54323253e-07
Iter: 841 loss: 7.61070908e-07
Iter: 842 loss: 7.5428909e-07
Iter: 843 loss: 7.53653069e-07
Iter: 844 loss: 7.54591213e-07
Iter: 845 loss: 7.53348104e-07
Iter: 846 loss: 7.52832136e-07
Iter: 847 loss: 7.52052301e-07
Iter: 848 loss: 7.5203144e-07
Iter: 849 loss: 7.51705272e-07
Iter: 850 loss: 7.51533548e-07
Iter: 851 loss: 7.51096877e-07
Iter: 852 loss: 7.50515e-07
Iter: 853 loss: 7.50492177e-07
Iter: 854 loss: 7.49660387e-07
Iter: 855 loss: 7.48526077e-07
Iter: 856 loss: 7.48497428e-07
Iter: 857 loss: 7.48531647e-07
Iter: 858 loss: 7.47816614e-07
Iter: 859 loss: 7.47358172e-07
Iter: 860 loss: 7.46559067e-07
Iter: 861 loss: 7.46550484e-07
Iter: 862 loss: 7.456307e-07
Iter: 863 loss: 7.49229287e-07
Iter: 864 loss: 7.4539588e-07
Iter: 865 loss: 7.44650663e-07
Iter: 866 loss: 7.52301275e-07
Iter: 867 loss: 7.44620706e-07
Iter: 868 loss: 7.43978489e-07
Iter: 869 loss: 7.42962754e-07
Iter: 870 loss: 7.42968837e-07
Iter: 871 loss: 7.42004204e-07
Iter: 872 loss: 7.54156531e-07
Iter: 873 loss: 7.41965e-07
Iter: 874 loss: 7.41101e-07
Iter: 875 loss: 7.43964051e-07
Iter: 876 loss: 7.40849714e-07
Iter: 877 loss: 7.40306348e-07
Iter: 878 loss: 7.39613313e-07
Iter: 879 loss: 7.39540496e-07
Iter: 880 loss: 7.39340578e-07
Iter: 881 loss: 7.39192046e-07
Iter: 882 loss: 7.38854624e-07
Iter: 883 loss: 7.38305175e-07
Iter: 884 loss: 7.51964762e-07
Iter: 885 loss: 7.38306e-07
Iter: 886 loss: 7.37607309e-07
Iter: 887 loss: 7.37997e-07
Iter: 888 loss: 7.37155062e-07
Iter: 889 loss: 7.37165635e-07
Iter: 890 loss: 7.3687454e-07
Iter: 891 loss: 7.36620905e-07
Iter: 892 loss: 7.36276775e-07
Iter: 893 loss: 7.36279674e-07
Iter: 894 loss: 7.35822596e-07
Iter: 895 loss: 7.37357936e-07
Iter: 896 loss: 7.35723916e-07
Iter: 897 loss: 7.35322601e-07
Iter: 898 loss: 7.38276412e-07
Iter: 899 loss: 7.3531578e-07
Iter: 900 loss: 7.34964772e-07
Iter: 901 loss: 7.3435848e-07
Iter: 902 loss: 7.3436388e-07
Iter: 903 loss: 7.33807497e-07
Iter: 904 loss: 7.39893e-07
Iter: 905 loss: 7.33776233e-07
Iter: 906 loss: 7.33282718e-07
Iter: 907 loss: 7.35689923e-07
Iter: 908 loss: 7.33194383e-07
Iter: 909 loss: 7.32879073e-07
Iter: 910 loss: 7.32356227e-07
Iter: 911 loss: 7.32350259e-07
Iter: 912 loss: 7.32087301e-07
Iter: 913 loss: 7.32047624e-07
Iter: 914 loss: 7.31743228e-07
Iter: 915 loss: 7.31285695e-07
Iter: 916 loss: 7.31263185e-07
Iter: 917 loss: 7.30721126e-07
Iter: 918 loss: 7.30610338e-07
Iter: 919 loss: 7.30216072e-07
Iter: 920 loss: 7.29827661e-07
Iter: 921 loss: 7.29804128e-07
Iter: 922 loss: 7.2929754e-07
Iter: 923 loss: 7.28685905e-07
Iter: 924 loss: 7.28643045e-07
Iter: 925 loss: 7.27868724e-07
Iter: 926 loss: 7.30729937e-07
Iter: 927 loss: 7.27683926e-07
Iter: 928 loss: 7.2699504e-07
Iter: 929 loss: 7.31685361e-07
Iter: 930 loss: 7.26932115e-07
Iter: 931 loss: 7.26229473e-07
Iter: 932 loss: 7.25360223e-07
Iter: 933 loss: 7.25286043e-07
Iter: 934 loss: 7.2440173e-07
Iter: 935 loss: 7.32098442e-07
Iter: 936 loss: 7.24336246e-07
Iter: 937 loss: 7.23552262e-07
Iter: 938 loss: 7.28278849e-07
Iter: 939 loss: 7.23486892e-07
Iter: 940 loss: 7.22946709e-07
Iter: 941 loss: 7.21857418e-07
Iter: 942 loss: 7.43370549e-07
Iter: 943 loss: 7.21854e-07
Iter: 944 loss: 7.21362767e-07
Iter: 945 loss: 7.21268862e-07
Iter: 946 loss: 7.20702246e-07
Iter: 947 loss: 7.20425646e-07
Iter: 948 loss: 7.20129151e-07
Iter: 949 loss: 7.19475565e-07
Iter: 950 loss: 7.20229195e-07
Iter: 951 loss: 7.1909426e-07
Iter: 952 loss: 7.18665092e-07
Iter: 953 loss: 7.18668275e-07
Iter: 954 loss: 7.18183969e-07
Iter: 955 loss: 7.18143042e-07
Iter: 956 loss: 7.17785952e-07
Iter: 957 loss: 7.1726231e-07
Iter: 958 loss: 7.18763715e-07
Iter: 959 loss: 7.17134697e-07
Iter: 960 loss: 7.16675345e-07
Iter: 961 loss: 7.19705e-07
Iter: 962 loss: 7.16660111e-07
Iter: 963 loss: 7.16196269e-07
Iter: 964 loss: 7.15879764e-07
Iter: 965 loss: 7.15718215e-07
Iter: 966 loss: 7.15277793e-07
Iter: 967 loss: 7.17956198e-07
Iter: 968 loss: 7.15208557e-07
Iter: 969 loss: 7.14794e-07
Iter: 970 loss: 7.18528099e-07
Iter: 971 loss: 7.14751309e-07
Iter: 972 loss: 7.14479711e-07
Iter: 973 loss: 7.13881263e-07
Iter: 974 loss: 7.2315629e-07
Iter: 975 loss: 7.1386421e-07
Iter: 976 loss: 7.13450845e-07
Iter: 977 loss: 7.13458803e-07
Iter: 978 loss: 7.12962617e-07
Iter: 979 loss: 7.13454597e-07
Iter: 980 loss: 7.12692213e-07
Iter: 981 loss: 7.12350698e-07
Iter: 982 loss: 7.12311646e-07
Iter: 983 loss: 7.1204596e-07
Iter: 984 loss: 7.1159036e-07
Iter: 985 loss: 7.14031557e-07
Iter: 986 loss: 7.11574501e-07
Iter: 987 loss: 7.10981453e-07
Iter: 988 loss: 7.12442329e-07
Iter: 989 loss: 7.10791937e-07
Iter: 990 loss: 7.10409608e-07
Iter: 991 loss: 7.10662789e-07
Iter: 992 loss: 7.10164102e-07
Iter: 993 loss: 7.09713163e-07
Iter: 994 loss: 7.12572273e-07
Iter: 995 loss: 7.09660526e-07
Iter: 996 loss: 7.09135918e-07
Iter: 997 loss: 7.09046958e-07
Iter: 998 loss: 7.08725e-07
Iter: 999 loss: 7.08218181e-07
Iter: 1000 loss: 7.09172184e-07
Iter: 1001 loss: 7.07985805e-07
Iter: 1002 loss: 7.07433287e-07
Iter: 1003 loss: 7.15112265e-07
Iter: 1004 loss: 7.07399749e-07
Iter: 1005 loss: 7.07013328e-07
Iter: 1006 loss: 7.06361106e-07
Iter: 1007 loss: 7.06351898e-07
Iter: 1008 loss: 7.05851335e-07
Iter: 1009 loss: 7.10043651e-07
Iter: 1010 loss: 7.05847356e-07
Iter: 1011 loss: 7.05314847e-07
Iter: 1012 loss: 7.07078e-07
Iter: 1013 loss: 7.05128343e-07
Iter: 1014 loss: 7.04833724e-07
Iter: 1015 loss: 7.04460831e-07
Iter: 1016 loss: 7.0439944e-07
Iter: 1017 loss: 7.0382896e-07
Iter: 1018 loss: 7.0546696e-07
Iter: 1019 loss: 7.03657236e-07
Iter: 1020 loss: 7.03025762e-07
Iter: 1021 loss: 7.11205189e-07
Iter: 1022 loss: 7.03037358e-07
Iter: 1023 loss: 7.0279475e-07
Iter: 1024 loss: 7.02604439e-07
Iter: 1025 loss: 7.02531111e-07
Iter: 1026 loss: 7.02171576e-07
Iter: 1027 loss: 7.05290745e-07
Iter: 1028 loss: 7.02165664e-07
Iter: 1029 loss: 7.01853878e-07
Iter: 1030 loss: 7.0208614e-07
Iter: 1031 loss: 7.01654869e-07
Iter: 1032 loss: 7.01336091e-07
Iter: 1033 loss: 7.01246222e-07
Iter: 1034 loss: 7.01058298e-07
Iter: 1035 loss: 7.00773967e-07
Iter: 1036 loss: 7.00732301e-07
Iter: 1037 loss: 7.00517148e-07
Iter: 1038 loss: 7.00114697e-07
Iter: 1039 loss: 7.00113674e-07
Iter: 1040 loss: 6.99739417e-07
Iter: 1041 loss: 7.00694443e-07
Iter: 1042 loss: 6.99607256e-07
Iter: 1043 loss: 6.99193549e-07
Iter: 1044 loss: 7.05411821e-07
Iter: 1045 loss: 6.99202872e-07
Iter: 1046 loss: 6.99025122e-07
Iter: 1047 loss: 6.98614713e-07
Iter: 1048 loss: 7.05630157e-07
Iter: 1049 loss: 6.98617043e-07
Iter: 1050 loss: 6.98176734e-07
Iter: 1051 loss: 6.98816677e-07
Iter: 1052 loss: 6.97899964e-07
Iter: 1053 loss: 6.97597955e-07
Iter: 1054 loss: 6.97493192e-07
Iter: 1055 loss: 6.97325618e-07
Iter: 1056 loss: 6.9686314e-07
Iter: 1057 loss: 7.0297574e-07
Iter: 1058 loss: 6.96853931e-07
Iter: 1059 loss: 6.96377469e-07
Iter: 1060 loss: 7.0248484e-07
Iter: 1061 loss: 6.96386792e-07
Iter: 1062 loss: 6.9604323e-07
Iter: 1063 loss: 6.96798111e-07
Iter: 1064 loss: 6.95902258e-07
Iter: 1065 loss: 6.9560565e-07
Iter: 1066 loss: 6.95336041e-07
Iter: 1067 loss: 6.95277e-07
Iter: 1068 loss: 6.95032782e-07
Iter: 1069 loss: 6.94975256e-07
Iter: 1070 loss: 6.9477926e-07
Iter: 1071 loss: 6.94403923e-07
Iter: 1072 loss: 6.94400228e-07
Iter: 1073 loss: 6.93985157e-07
Iter: 1074 loss: 6.94016535e-07
Iter: 1075 loss: 6.93657512e-07
Iter: 1076 loss: 6.93507957e-07
Iter: 1077 loss: 6.93385118e-07
Iter: 1078 loss: 6.93259096e-07
Iter: 1079 loss: 6.92914682e-07
Iter: 1080 loss: 6.97235066e-07
Iter: 1081 loss: 6.9287637e-07
Iter: 1082 loss: 6.92564072e-07
Iter: 1083 loss: 6.93012112e-07
Iter: 1084 loss: 6.92357958e-07
Iter: 1085 loss: 6.92286051e-07
Iter: 1086 loss: 6.92163326e-07
Iter: 1087 loss: 6.92015533e-07
Iter: 1088 loss: 6.91782589e-07
Iter: 1089 loss: 6.91772129e-07
Iter: 1090 loss: 6.91564253e-07
Iter: 1091 loss: 6.9362784e-07
Iter: 1092 loss: 6.91556295e-07
Iter: 1093 loss: 6.91352739e-07
Iter: 1094 loss: 6.91861374e-07
Iter: 1095 loss: 6.91302944e-07
Iter: 1096 loss: 6.91087564e-07
Iter: 1097 loss: 6.90868319e-07
Iter: 1098 loss: 6.90872582e-07
Iter: 1099 loss: 6.90678405e-07
Iter: 1100 loss: 6.90685511e-07
Iter: 1101 loss: 6.90506852e-07
Iter: 1102 loss: 6.90645606e-07
Iter: 1103 loss: 6.90395098e-07
Iter: 1104 loss: 6.90245656e-07
Iter: 1105 loss: 6.90069442e-07
Iter: 1106 loss: 6.90044e-07
Iter: 1107 loss: 6.89811486e-07
Iter: 1108 loss: 6.92460617e-07
Iter: 1109 loss: 6.89809553e-07
Iter: 1110 loss: 6.89509534e-07
Iter: 1111 loss: 6.8912334e-07
Iter: 1112 loss: 6.89096737e-07
Iter: 1113 loss: 6.88701391e-07
Iter: 1114 loss: 6.8868286e-07
Iter: 1115 loss: 6.8834197e-07
Iter: 1116 loss: 6.87914962e-07
Iter: 1117 loss: 6.9291417e-07
Iter: 1118 loss: 6.87921386e-07
Iter: 1119 loss: 6.87549687e-07
Iter: 1120 loss: 6.90840579e-07
Iter: 1121 loss: 6.87558e-07
Iter: 1122 loss: 6.87397744e-07
Iter: 1123 loss: 6.87278202e-07
Iter: 1124 loss: 6.87221473e-07
Iter: 1125 loss: 6.8696113e-07
Iter: 1126 loss: 6.8848675e-07
Iter: 1127 loss: 6.86920202e-07
Iter: 1128 loss: 6.86676401e-07
Iter: 1129 loss: 6.86563112e-07
Iter: 1130 loss: 6.86469662e-07
Iter: 1131 loss: 6.86095859e-07
Iter: 1132 loss: 6.86208693e-07
Iter: 1133 loss: 6.85849272e-07
Iter: 1134 loss: 6.85604e-07
Iter: 1135 loss: 6.85520604e-07
Iter: 1136 loss: 6.85417604e-07
Iter: 1137 loss: 6.85192333e-07
Iter: 1138 loss: 6.85187274e-07
Iter: 1139 loss: 6.84962515e-07
Iter: 1140 loss: 6.85667601e-07
Iter: 1141 loss: 6.84921417e-07
Iter: 1142 loss: 6.8472491e-07
Iter: 1143 loss: 6.8711779e-07
Iter: 1144 loss: 6.84726899e-07
Iter: 1145 loss: 6.84590759e-07
Iter: 1146 loss: 6.84306428e-07
Iter: 1147 loss: 6.88144e-07
Iter: 1148 loss: 6.84276188e-07
Iter: 1149 loss: 6.83931603e-07
Iter: 1150 loss: 6.85022e-07
Iter: 1151 loss: 6.83859923e-07
Iter: 1152 loss: 6.83572637e-07
Iter: 1153 loss: 6.8358429e-07
Iter: 1154 loss: 6.83371923e-07
Iter: 1155 loss: 6.82859877e-07
Iter: 1156 loss: 6.88092e-07
Iter: 1157 loss: 6.82811901e-07
Iter: 1158 loss: 6.82349537e-07
Iter: 1159 loss: 6.82343909e-07
Iter: 1160 loss: 6.82052359e-07
Iter: 1161 loss: 6.81987729e-07
Iter: 1162 loss: 6.81779966e-07
Iter: 1163 loss: 6.81360746e-07
Iter: 1164 loss: 6.81453116e-07
Iter: 1165 loss: 6.81075562e-07
Iter: 1166 loss: 6.80865298e-07
Iter: 1167 loss: 6.80819426e-07
Iter: 1168 loss: 6.80602511e-07
Iter: 1169 loss: 6.80062726e-07
Iter: 1170 loss: 6.86752117e-07
Iter: 1171 loss: 6.80015376e-07
Iter: 1172 loss: 6.79394361e-07
Iter: 1173 loss: 6.80448807e-07
Iter: 1174 loss: 6.79136747e-07
Iter: 1175 loss: 6.78878564e-07
Iter: 1176 loss: 6.78796823e-07
Iter: 1177 loss: 6.78543302e-07
Iter: 1178 loss: 6.77980324e-07
Iter: 1179 loss: 6.88066905e-07
Iter: 1180 loss: 6.77978619e-07
Iter: 1181 loss: 6.7753507e-07
Iter: 1182 loss: 6.78937681e-07
Iter: 1183 loss: 6.77405865e-07
Iter: 1184 loss: 6.7724568e-07
Iter: 1185 loss: 6.77220669e-07
Iter: 1186 loss: 6.77001367e-07
Iter: 1187 loss: 6.76628645e-07
Iter: 1188 loss: 6.76623e-07
Iter: 1189 loss: 6.76340051e-07
Iter: 1190 loss: 6.79582e-07
Iter: 1191 loss: 6.76309241e-07
Iter: 1192 loss: 6.75991885e-07
Iter: 1193 loss: 6.76012291e-07
Iter: 1194 loss: 6.75753e-07
Iter: 1195 loss: 6.75361207e-07
Iter: 1196 loss: 6.75600859e-07
Iter: 1197 loss: 6.75099159e-07
Iter: 1198 loss: 6.74841033e-07
Iter: 1199 loss: 6.74821e-07
Iter: 1200 loss: 6.74562e-07
Iter: 1201 loss: 6.74775833e-07
Iter: 1202 loss: 6.7441141e-07
Iter: 1203 loss: 6.74186708e-07
Iter: 1204 loss: 6.73978775e-07
Iter: 1205 loss: 6.73962859e-07
Iter: 1206 loss: 6.73688646e-07
Iter: 1207 loss: 6.77359594e-07
Iter: 1208 loss: 6.73693648e-07
Iter: 1209 loss: 6.73371403e-07
Iter: 1210 loss: 6.733502e-07
Iter: 1211 loss: 6.73122372e-07
Iter: 1212 loss: 6.72790179e-07
Iter: 1213 loss: 6.72282397e-07
Iter: 1214 loss: 6.72269493e-07
Iter: 1215 loss: 6.71743521e-07
Iter: 1216 loss: 6.79349341e-07
Iter: 1217 loss: 6.71752218e-07
Iter: 1218 loss: 6.71265411e-07
Iter: 1219 loss: 6.74072623e-07
Iter: 1220 loss: 6.71178668e-07
Iter: 1221 loss: 6.7097551e-07
Iter: 1222 loss: 6.70906729e-07
Iter: 1223 loss: 6.70773545e-07
Iter: 1224 loss: 6.70462725e-07
Iter: 1225 loss: 6.73713316e-07
Iter: 1226 loss: 6.70433792e-07
Iter: 1227 loss: 6.70269799e-07
Iter: 1228 loss: 6.70268719e-07
Iter: 1229 loss: 6.70137581e-07
Iter: 1230 loss: 6.6990583e-07
Iter: 1231 loss: 6.70130476e-07
Iter: 1232 loss: 6.6978771e-07
Iter: 1233 loss: 6.69470808e-07
Iter: 1234 loss: 6.7308963e-07
Iter: 1235 loss: 6.69452845e-07
Iter: 1236 loss: 6.69314772e-07
Iter: 1237 loss: 6.6888731e-07
Iter: 1238 loss: 6.73383113e-07
Iter: 1239 loss: 6.68881512e-07
Iter: 1240 loss: 6.68456266e-07
Iter: 1241 loss: 6.72426722e-07
Iter: 1242 loss: 6.6845962e-07
Iter: 1243 loss: 6.6817563e-07
Iter: 1244 loss: 6.7129514e-07
Iter: 1245 loss: 6.68183134e-07
Iter: 1246 loss: 6.68014764e-07
Iter: 1247 loss: 6.6770923e-07
Iter: 1248 loss: 6.73658747e-07
Iter: 1249 loss: 6.67718041e-07
Iter: 1250 loss: 6.67440702e-07
Iter: 1251 loss: 6.68991959e-07
Iter: 1252 loss: 6.67379254e-07
Iter: 1253 loss: 6.67202926e-07
Iter: 1254 loss: 6.67196105e-07
Iter: 1255 loss: 6.67059282e-07
Iter: 1256 loss: 6.6677319e-07
Iter: 1257 loss: 6.70629447e-07
Iter: 1258 loss: 6.66720211e-07
Iter: 1259 loss: 6.66578217e-07
Iter: 1260 loss: 6.66540132e-07
Iter: 1261 loss: 6.66393078e-07
Iter: 1262 loss: 6.66151209e-07
Iter: 1263 loss: 6.6614416e-07
Iter: 1264 loss: 6.65898938e-07
Iter: 1265 loss: 6.66897506e-07
Iter: 1266 loss: 6.65876371e-07
Iter: 1267 loss: 6.65735115e-07
Iter: 1268 loss: 6.65729e-07
Iter: 1269 loss: 6.65602101e-07
Iter: 1270 loss: 6.65306459e-07
Iter: 1271 loss: 6.68425628e-07
Iter: 1272 loss: 6.65255811e-07
Iter: 1273 loss: 6.64927427e-07
Iter: 1274 loss: 6.65473635e-07
Iter: 1275 loss: 6.64749166e-07
Iter: 1276 loss: 6.64536117e-07
Iter: 1277 loss: 6.64494166e-07
Iter: 1278 loss: 6.6428322e-07
Iter: 1279 loss: 6.63867695e-07
Iter: 1280 loss: 6.71959128e-07
Iter: 1281 loss: 6.63853712e-07
Iter: 1282 loss: 6.63440574e-07
Iter: 1283 loss: 6.64701474e-07
Iter: 1284 loss: 6.63311766e-07
Iter: 1285 loss: 6.63158403e-07
Iter: 1286 loss: 6.63112701e-07
Iter: 1287 loss: 6.62908235e-07
Iter: 1288 loss: 6.62652496e-07
Iter: 1289 loss: 6.62640673e-07
Iter: 1290 loss: 6.62460309e-07
Iter: 1291 loss: 6.64918559e-07
Iter: 1292 loss: 6.6246696e-07
Iter: 1293 loss: 6.62234186e-07
Iter: 1294 loss: 6.6227858e-07
Iter: 1295 loss: 6.6212209e-07
Iter: 1296 loss: 6.61930528e-07
Iter: 1297 loss: 6.6202108e-07
Iter: 1298 loss: 6.6178e-07
Iter: 1299 loss: 6.61560932e-07
Iter: 1300 loss: 6.63360083e-07
Iter: 1301 loss: 6.6154405e-07
Iter: 1302 loss: 6.61245394e-07
Iter: 1303 loss: 6.61530464e-07
Iter: 1304 loss: 6.61086858e-07
Iter: 1305 loss: 6.60876e-07
Iter: 1306 loss: 6.6060727e-07
Iter: 1307 loss: 6.6059215e-07
Iter: 1308 loss: 6.60299065e-07
Iter: 1309 loss: 6.64452045e-07
Iter: 1310 loss: 6.60287753e-07
Iter: 1311 loss: 6.59947943e-07
Iter: 1312 loss: 6.60392232e-07
Iter: 1313 loss: 6.59811235e-07
Iter: 1314 loss: 6.59558509e-07
Iter: 1315 loss: 6.59196928e-07
Iter: 1316 loss: 6.59196246e-07
Iter: 1317 loss: 6.58843419e-07
Iter: 1318 loss: 6.58846261e-07
Iter: 1319 loss: 6.58503609e-07
Iter: 1320 loss: 6.59290777e-07
Iter: 1321 loss: 6.58390377e-07
Iter: 1322 loss: 6.58226838e-07
Iter: 1323 loss: 6.58154306e-07
Iter: 1324 loss: 6.58031411e-07
Iter: 1325 loss: 6.57816e-07
Iter: 1326 loss: 6.57822341e-07
Iter: 1327 loss: 6.57704788e-07
Iter: 1328 loss: 6.57544206e-07
Iter: 1329 loss: 6.6231911e-07
Iter: 1330 loss: 6.57545229e-07
Iter: 1331 loss: 6.57276473e-07
Iter: 1332 loss: 6.58199724e-07
Iter: 1333 loss: 6.57243049e-07
Iter: 1334 loss: 6.5699237e-07
Iter: 1335 loss: 6.5901088e-07
Iter: 1336 loss: 6.56963948e-07
Iter: 1337 loss: 6.56797511e-07
Iter: 1338 loss: 6.56401141e-07
Iter: 1339 loss: 6.61006311e-07
Iter: 1340 loss: 6.56409952e-07
Iter: 1341 loss: 6.56041948e-07
Iter: 1342 loss: 6.5809229e-07
Iter: 1343 loss: 6.5600409e-07
Iter: 1344 loss: 6.55799568e-07
Iter: 1345 loss: 6.55801728e-07
Iter: 1346 loss: 6.55692247e-07
Iter: 1347 loss: 6.55416727e-07
Iter: 1348 loss: 6.59182319e-07
Iter: 1349 loss: 6.55424515e-07
Iter: 1350 loss: 6.5522056e-07
Iter: 1351 loss: 6.57072746e-07
Iter: 1352 loss: 6.5520419e-07
Iter: 1353 loss: 6.55064696e-07
Iter: 1354 loss: 6.56810926e-07
Iter: 1355 loss: 6.55060774e-07
Iter: 1356 loss: 6.54976e-07
Iter: 1357 loss: 6.54763539e-07
Iter: 1358 loss: 6.57520957e-07
Iter: 1359 loss: 6.54725397e-07
Iter: 1360 loss: 6.54575331e-07
Iter: 1361 loss: 6.54574364e-07
Iter: 1362 loss: 6.54417249e-07
Iter: 1363 loss: 6.54100177e-07
Iter: 1364 loss: 6.61048489e-07
Iter: 1365 loss: 6.54113421e-07
Iter: 1366 loss: 6.53789471e-07
Iter: 1367 loss: 6.54789403e-07
Iter: 1368 loss: 6.53693405e-07
Iter: 1369 loss: 6.53482687e-07
Iter: 1370 loss: 6.53467964e-07
Iter: 1371 loss: 6.53303744e-07
Iter: 1372 loss: 6.53138216e-07
Iter: 1373 loss: 6.53105872e-07
Iter: 1374 loss: 6.52898848e-07
Iter: 1375 loss: 6.5286747e-07
Iter: 1376 loss: 6.52735821e-07
Iter: 1377 loss: 6.52544713e-07
Iter: 1378 loss: 6.52549261e-07
Iter: 1379 loss: 6.52325866e-07
Iter: 1380 loss: 6.52434437e-07
Iter: 1381 loss: 6.52198537e-07
Iter: 1382 loss: 6.51983669e-07
Iter: 1383 loss: 6.51862251e-07
Iter: 1384 loss: 6.51797e-07
Iter: 1385 loss: 6.51660969e-07
Iter: 1386 loss: 6.51639937e-07
Iter: 1387 loss: 6.51464347e-07
Iter: 1388 loss: 6.51408072e-07
Iter: 1389 loss: 6.51287223e-07
Iter: 1390 loss: 6.51177345e-07
Iter: 1391 loss: 6.51353e-07
Iter: 1392 loss: 6.51094751e-07
Iter: 1393 loss: 6.50880963e-07
Iter: 1394 loss: 6.52462745e-07
Iter: 1395 loss: 6.50872664e-07
Iter: 1396 loss: 6.50758352e-07
Iter: 1397 loss: 6.50521372e-07
Iter: 1398 loss: 6.55169515e-07
Iter: 1399 loss: 6.50534957e-07
Iter: 1400 loss: 6.50275524e-07
Iter: 1401 loss: 6.52719791e-07
Iter: 1402 loss: 6.50255288e-07
Iter: 1403 loss: 6.49958224e-07
Iter: 1404 loss: 6.50734705e-07
Iter: 1405 loss: 6.49853177e-07
Iter: 1406 loss: 6.49626713e-07
Iter: 1407 loss: 6.4938547e-07
Iter: 1408 loss: 6.49373646e-07
Iter: 1409 loss: 6.49002459e-07
Iter: 1410 loss: 6.49906042e-07
Iter: 1411 loss: 6.48879222e-07
Iter: 1412 loss: 6.4893004e-07
Iter: 1413 loss: 6.48755758e-07
Iter: 1414 loss: 6.48689593e-07
Iter: 1415 loss: 6.48493938e-07
Iter: 1416 loss: 6.50904553e-07
Iter: 1417 loss: 6.48468301e-07
Iter: 1418 loss: 6.48358878e-07
Iter: 1419 loss: 6.48356774e-07
Iter: 1420 loss: 6.4824053e-07
Iter: 1421 loss: 6.4809683e-07
Iter: 1422 loss: 6.48080857e-07
Iter: 1423 loss: 6.47831484e-07
Iter: 1424 loss: 6.47476327e-07
Iter: 1425 loss: 6.47473485e-07
Iter: 1426 loss: 6.47235424e-07
Iter: 1427 loss: 6.47181253e-07
Iter: 1428 loss: 6.46927731e-07
Iter: 1429 loss: 6.46707747e-07
Iter: 1430 loss: 6.46635272e-07
Iter: 1431 loss: 6.4634196e-07
Iter: 1432 loss: 6.471e-07
Iter: 1433 loss: 6.46234e-07
Iter: 1434 loss: 6.46043077e-07
Iter: 1435 loss: 6.46029605e-07
Iter: 1436 loss: 6.4591211e-07
Iter: 1437 loss: 6.45714522e-07
Iter: 1438 loss: 6.4572032e-07
Iter: 1439 loss: 6.45479e-07
Iter: 1440 loss: 6.45679847e-07
Iter: 1441 loss: 6.45359364e-07
Iter: 1442 loss: 6.4511562e-07
Iter: 1443 loss: 6.45645684e-07
Iter: 1444 loss: 6.45004206e-07
Iter: 1445 loss: 6.44681677e-07
Iter: 1446 loss: 6.47546244e-07
Iter: 1447 loss: 6.44648651e-07
Iter: 1448 loss: 6.44479428e-07
Iter: 1449 loss: 6.44244494e-07
Iter: 1450 loss: 6.44235513e-07
Iter: 1451 loss: 6.43885301e-07
Iter: 1452 loss: 6.48179878e-07
Iter: 1453 loss: 6.43882572e-07
Iter: 1454 loss: 6.43657529e-07
Iter: 1455 loss: 6.43273324e-07
Iter: 1456 loss: 6.43265594e-07
Iter: 1457 loss: 6.43036742e-07
Iter: 1458 loss: 6.43036117e-07
Iter: 1459 loss: 6.42867121e-07
Iter: 1460 loss: 6.43899284e-07
Iter: 1461 loss: 6.4284086e-07
Iter: 1462 loss: 6.42709949e-07
Iter: 1463 loss: 6.42453188e-07
Iter: 1464 loss: 6.48146e-07
Iter: 1465 loss: 6.42468933e-07
Iter: 1466 loss: 6.42313e-07
Iter: 1467 loss: 6.4229738e-07
Iter: 1468 loss: 6.42114287e-07
Iter: 1469 loss: 6.41872703e-07
Iter: 1470 loss: 6.41853831e-07
Iter: 1471 loss: 6.41575525e-07
Iter: 1472 loss: 6.41967517e-07
Iter: 1473 loss: 6.4139806e-07
Iter: 1474 loss: 6.41055635e-07
Iter: 1475 loss: 6.41463487e-07
Iter: 1476 loss: 6.40867938e-07
Iter: 1477 loss: 6.40596795e-07
Iter: 1478 loss: 6.43421913e-07
Iter: 1479 loss: 6.40579e-07
Iter: 1480 loss: 6.40322469e-07
Iter: 1481 loss: 6.42264752e-07
Iter: 1482 loss: 6.40296e-07
Iter: 1483 loss: 6.40136136e-07
Iter: 1484 loss: 6.39897451e-07
Iter: 1485 loss: 6.39896143e-07
Iter: 1486 loss: 6.39681275e-07
Iter: 1487 loss: 6.39666439e-07
Iter: 1488 loss: 6.39570203e-07
Iter: 1489 loss: 6.39244263e-07
Iter: 1490 loss: 6.40871463e-07
Iter: 1491 loss: 6.39134214e-07
Iter: 1492 loss: 6.38975166e-07
Iter: 1493 loss: 6.38905249e-07
Iter: 1494 loss: 6.38727442e-07
Iter: 1495 loss: 6.38874326e-07
Iter: 1496 loss: 6.38629e-07
Iter: 1497 loss: 6.38390588e-07
Iter: 1498 loss: 6.38335109e-07
Iter: 1499 loss: 6.38193114e-07
Iter: 1500 loss: 6.37911739e-07
Iter: 1501 loss: 6.37914923e-07
Iter: 1502 loss: 6.37769745e-07
Iter: 1503 loss: 6.37431526e-07
Iter: 1504 loss: 6.42897589e-07
Iter: 1505 loss: 6.37426126e-07
Iter: 1506 loss: 6.37029927e-07
Iter: 1507 loss: 6.3784546e-07
Iter: 1508 loss: 6.36874802e-07
Iter: 1509 loss: 6.36439893e-07
Iter: 1510 loss: 6.38341362e-07
Iter: 1511 loss: 6.36371169e-07
Iter: 1512 loss: 6.36039715e-07
Iter: 1513 loss: 6.36676475e-07
Iter: 1514 loss: 6.35910396e-07
Iter: 1515 loss: 6.35855258e-07
Iter: 1516 loss: 6.35771357e-07
Iter: 1517 loss: 6.35671597e-07
Iter: 1518 loss: 6.35486629e-07
Iter: 1519 loss: 6.35490835e-07
Iter: 1520 loss: 6.35325193e-07
Iter: 1521 loss: 6.36574953e-07
Iter: 1522 loss: 6.35306947e-07
Iter: 1523 loss: 6.35102083e-07
Iter: 1524 loss: 6.34985895e-07
Iter: 1525 loss: 6.34908474e-07
Iter: 1526 loss: 6.34587877e-07
Iter: 1527 loss: 6.34571393e-07
Iter: 1528 loss: 6.34333276e-07
Iter: 1529 loss: 6.34082e-07
Iter: 1530 loss: 6.3404957e-07
Iter: 1531 loss: 6.33898765e-07
Iter: 1532 loss: 6.33430432e-07
Iter: 1533 loss: 6.3814872e-07
Iter: 1534 loss: 6.33376942e-07
Iter: 1535 loss: 6.32920319e-07
Iter: 1536 loss: 6.3470668e-07
Iter: 1537 loss: 6.32821411e-07
Iter: 1538 loss: 6.32514116e-07
Iter: 1539 loss: 6.36819891e-07
Iter: 1540 loss: 6.32518777e-07
Iter: 1541 loss: 6.3220034e-07
Iter: 1542 loss: 6.33499781e-07
Iter: 1543 loss: 6.32150829e-07
Iter: 1544 loss: 6.31955913e-07
Iter: 1545 loss: 6.31761679e-07
Iter: 1546 loss: 6.31702676e-07
Iter: 1547 loss: 6.31343767e-07
Iter: 1548 loss: 6.31487126e-07
Iter: 1549 loss: 6.31049375e-07
Iter: 1550 loss: 6.30774252e-07
Iter: 1551 loss: 6.30770955e-07
Iter: 1552 loss: 6.30475881e-07
Iter: 1553 loss: 6.31479281e-07
Iter: 1554 loss: 6.30408238e-07
Iter: 1555 loss: 6.30200248e-07
Iter: 1556 loss: 6.29737315e-07
Iter: 1557 loss: 6.37369908e-07
Iter: 1558 loss: 6.29722877e-07
Iter: 1559 loss: 6.29253861e-07
Iter: 1560 loss: 6.32590627e-07
Iter: 1561 loss: 6.29216629e-07
Iter: 1562 loss: 6.28708733e-07
Iter: 1563 loss: 6.31927e-07
Iter: 1564 loss: 6.28636144e-07
Iter: 1565 loss: 6.28414796e-07
Iter: 1566 loss: 6.27950726e-07
Iter: 1567 loss: 6.37280777e-07
Iter: 1568 loss: 6.27942882e-07
Iter: 1569 loss: 6.27547934e-07
Iter: 1570 loss: 6.33252114e-07
Iter: 1571 loss: 6.27542249e-07
Iter: 1572 loss: 6.27156282e-07
Iter: 1573 loss: 6.28486703e-07
Iter: 1574 loss: 6.27089548e-07
Iter: 1575 loss: 6.2687883e-07
Iter: 1576 loss: 6.26512588e-07
Iter: 1577 loss: 6.33757168e-07
Iter: 1578 loss: 6.2652191e-07
Iter: 1579 loss: 6.26169367e-07
Iter: 1580 loss: 6.29915462e-07
Iter: 1581 loss: 6.26160272e-07
Iter: 1582 loss: 6.25795906e-07
Iter: 1583 loss: 6.27817e-07
Iter: 1584 loss: 6.257618e-07
Iter: 1585 loss: 6.25519e-07
Iter: 1586 loss: 6.24958375e-07
Iter: 1587 loss: 6.31411694e-07
Iter: 1588 loss: 6.24927679e-07
Iter: 1589 loss: 6.2440597e-07
Iter: 1590 loss: 6.28629209e-07
Iter: 1591 loss: 6.24356403e-07
Iter: 1592 loss: 6.23861524e-07
Iter: 1593 loss: 6.28184353e-07
Iter: 1594 loss: 6.23841856e-07
Iter: 1595 loss: 6.23465e-07
Iter: 1596 loss: 6.23145752e-07
Iter: 1597 loss: 6.23050823e-07
Iter: 1598 loss: 6.22636662e-07
Iter: 1599 loss: 6.24874133e-07
Iter: 1600 loss: 6.22584e-07
Iter: 1601 loss: 6.22320499e-07
Iter: 1602 loss: 6.2233e-07
Iter: 1603 loss: 6.22127e-07
Iter: 1604 loss: 6.2182761e-07
Iter: 1605 loss: 6.21821812e-07
Iter: 1606 loss: 6.215555e-07
Iter: 1607 loss: 6.23779329e-07
Iter: 1608 loss: 6.21514346e-07
Iter: 1609 loss: 6.21163963e-07
Iter: 1610 loss: 6.20901403e-07
Iter: 1611 loss: 6.20797e-07
Iter: 1612 loss: 6.20386913e-07
Iter: 1613 loss: 6.19936145e-07
Iter: 1614 loss: 6.19865716e-07
Iter: 1615 loss: 6.19243906e-07
Iter: 1616 loss: 6.23486471e-07
Iter: 1617 loss: 6.19153298e-07
Iter: 1618 loss: 6.1895031e-07
Iter: 1619 loss: 6.18853505e-07
Iter: 1620 loss: 6.18687693e-07
Iter: 1621 loss: 6.18283764e-07
Iter: 1622 loss: 6.22736536e-07
Iter: 1623 loss: 6.18233457e-07
Iter: 1624 loss: 6.17889555e-07
Iter: 1625 loss: 6.18627155e-07
Iter: 1626 loss: 6.17735e-07
Iter: 1627 loss: 6.17505293e-07
Iter: 1628 loss: 6.17524279e-07
Iter: 1629 loss: 6.17251601e-07
Iter: 1630 loss: 6.17519731e-07
Iter: 1631 loss: 6.17131434e-07
Iter: 1632 loss: 6.169073e-07
Iter: 1633 loss: 6.1693521e-07
Iter: 1634 loss: 6.16753937e-07
Iter: 1635 loss: 6.16519685e-07
Iter: 1636 loss: 6.16530542e-07
Iter: 1637 loss: 6.16350235e-07
Iter: 1638 loss: 6.16189482e-07
Iter: 1639 loss: 6.16164414e-07
Iter: 1640 loss: 6.15900206e-07
Iter: 1641 loss: 6.16979207e-07
Iter: 1642 loss: 6.15871954e-07
Iter: 1643 loss: 6.15612521e-07
Iter: 1644 loss: 6.17194189e-07
Iter: 1645 loss: 6.15597628e-07
Iter: 1646 loss: 6.15429201e-07
Iter: 1647 loss: 6.15012596e-07
Iter: 1648 loss: 6.20246624e-07
Iter: 1649 loss: 6.14993098e-07
Iter: 1650 loss: 6.14553358e-07
Iter: 1651 loss: 6.15157887e-07
Iter: 1652 loss: 6.14363387e-07
Iter: 1653 loss: 6.1407178e-07
Iter: 1654 loss: 6.14039891e-07
Iter: 1655 loss: 6.13721738e-07
Iter: 1656 loss: 6.14557905e-07
Iter: 1657 loss: 6.13597706e-07
Iter: 1658 loss: 6.13391762e-07
Iter: 1659 loss: 6.13046097e-07
Iter: 1660 loss: 6.19939726e-07
Iter: 1661 loss: 6.13051157e-07
Iter: 1662 loss: 6.12637905e-07
Iter: 1663 loss: 6.14186774e-07
Iter: 1664 loss: 6.12535587e-07
Iter: 1665 loss: 6.12411213e-07
Iter: 1666 loss: 6.12321742e-07
Iter: 1667 loss: 6.12168e-07
Iter: 1668 loss: 6.11856478e-07
Iter: 1669 loss: 6.19366e-07
Iter: 1670 loss: 6.11861651e-07
Iter: 1671 loss: 6.11628764e-07
Iter: 1672 loss: 6.13285806e-07
Iter: 1673 loss: 6.11617452e-07
Iter: 1674 loss: 6.11351311e-07
Iter: 1675 loss: 6.11957489e-07
Iter: 1676 loss: 6.1125013e-07
Iter: 1677 loss: 6.11111886e-07
Iter: 1678 loss: 6.11158271e-07
Iter: 1679 loss: 6.11018038e-07
Iter: 1680 loss: 6.10880534e-07
Iter: 1681 loss: 6.10872519e-07
Iter: 1682 loss: 6.1077867e-07
Iter: 1683 loss: 6.1064884e-07
Iter: 1684 loss: 6.10643497e-07
Iter: 1685 loss: 6.1049991e-07
Iter: 1686 loss: 6.10891959e-07
Iter: 1687 loss: 6.10437951e-07
Iter: 1688 loss: 6.10265e-07
Iter: 1689 loss: 6.10449717e-07
Iter: 1690 loss: 6.10155212e-07
Iter: 1691 loss: 6.09926815e-07
Iter: 1692 loss: 6.1249915e-07
Iter: 1693 loss: 6.09923461e-07
Iter: 1694 loss: 6.09784195e-07
Iter: 1695 loss: 6.09475592e-07
Iter: 1696 loss: 6.12142628e-07
Iter: 1697 loss: 6.09435915e-07
Iter: 1698 loss: 6.09083941e-07
Iter: 1699 loss: 6.10175903e-07
Iter: 1700 loss: 6.08972869e-07
Iter: 1701 loss: 6.08878395e-07
Iter: 1702 loss: 6.08870209e-07
Iter: 1703 loss: 6.08727362e-07
Iter: 1704 loss: 6.09160622e-07
Iter: 1705 loss: 6.08703829e-07
Iter: 1706 loss: 6.08624305e-07
Iter: 1707 loss: 6.08398125e-07
Iter: 1708 loss: 6.11055839e-07
Iter: 1709 loss: 6.08389314e-07
Iter: 1710 loss: 6.08186213e-07
Iter: 1711 loss: 6.10201937e-07
Iter: 1712 loss: 6.08152277e-07
Iter: 1713 loss: 6.07920697e-07
Iter: 1714 loss: 6.09046879e-07
Iter: 1715 loss: 6.07880565e-07
Iter: 1716 loss: 6.07716856e-07
Iter: 1717 loss: 6.07350216e-07
Iter: 1718 loss: 6.1182709e-07
Iter: 1719 loss: 6.07321113e-07
Iter: 1720 loss: 6.07187758e-07
Iter: 1721 loss: 6.07080665e-07
Iter: 1722 loss: 6.06928097e-07
Iter: 1723 loss: 6.06741935e-07
Iter: 1724 loss: 6.06708682e-07
Iter: 1725 loss: 6.06533035e-07
Iter: 1726 loss: 6.06698791e-07
Iter: 1727 loss: 6.06409458e-07
Iter: 1728 loss: 6.06157869e-07
Iter: 1729 loss: 6.07845664e-07
Iter: 1730 loss: 6.06160199e-07
Iter: 1731 loss: 6.06059416e-07
Iter: 1732 loss: 6.06056233e-07
Iter: 1733 loss: 6.05979039e-07
Iter: 1734 loss: 6.05741434e-07
Iter: 1735 loss: 6.07687298e-07
Iter: 1736 loss: 6.0570062e-07
Iter: 1737 loss: 6.05567379e-07
Iter: 1738 loss: 6.0556448e-07
Iter: 1739 loss: 6.05424475e-07
Iter: 1740 loss: 6.05258379e-07
Iter: 1741 loss: 6.05247749e-07
Iter: 1742 loss: 6.05052151e-07
Iter: 1743 loss: 6.05016055e-07
Iter: 1744 loss: 6.04855074e-07
Iter: 1745 loss: 6.04922946e-07
Iter: 1746 loss: 6.04740421e-07
Iter: 1747 loss: 6.04636341e-07
Iter: 1748 loss: 6.04455181e-07
Iter: 1749 loss: 6.06637059e-07
Iter: 1750 loss: 6.04429886e-07
Iter: 1751 loss: 6.04288573e-07
Iter: 1752 loss: 6.04296247e-07
Iter: 1753 loss: 6.04191428e-07
Iter: 1754 loss: 6.04125034e-07
Iter: 1755 loss: 6.04051e-07
Iter: 1756 loss: 6.039146e-07
Iter: 1757 loss: 6.03720878e-07
Iter: 1758 loss: 6.0368393e-07
Iter: 1759 loss: 6.03482079e-07
Iter: 1760 loss: 6.03765443e-07
Iter: 1761 loss: 6.03387946e-07
Iter: 1762 loss: 6.03287e-07
Iter: 1763 loss: 6.03287958e-07
Iter: 1764 loss: 6.03170406e-07
Iter: 1765 loss: 6.0302267e-07
Iter: 1766 loss: 6.02993623e-07
Iter: 1767 loss: 6.02869761e-07
Iter: 1768 loss: 6.0353716e-07
Iter: 1769 loss: 6.02835883e-07
Iter: 1770 loss: 6.02679677e-07
Iter: 1771 loss: 6.03036597e-07
Iter: 1772 loss: 6.02589921e-07
Iter: 1773 loss: 6.02452246e-07
Iter: 1774 loss: 6.02222826e-07
Iter: 1775 loss: 6.02231353e-07
Iter: 1776 loss: 6.02034675e-07
Iter: 1777 loss: 6.04988259e-07
Iter: 1778 loss: 6.02040814e-07
Iter: 1779 loss: 6.01802526e-07
Iter: 1780 loss: 6.02100727e-07
Iter: 1781 loss: 6.01700776e-07
Iter: 1782 loss: 6.01557645e-07
Iter: 1783 loss: 6.0212335e-07
Iter: 1784 loss: 6.0150353e-07
Iter: 1785 loss: 6.01367333e-07
Iter: 1786 loss: 6.01988859e-07
Iter: 1787 loss: 6.01297131e-07
Iter: 1788 loss: 6.01246029e-07
Iter: 1789 loss: 6.01440263e-07
Iter: 1790 loss: 6.01207603e-07
Iter: 1791 loss: 6.01104603e-07
Iter: 1792 loss: 6.01112049e-07
Iter: 1793 loss: 6.01046963e-07
Iter: 1794 loss: 6.00871886e-07
Iter: 1795 loss: 6.00598923e-07
Iter: 1796 loss: 6.07197649e-07
Iter: 1797 loss: 6.00600742e-07
Iter: 1798 loss: 6.00339661e-07
Iter: 1799 loss: 6.02459181e-07
Iter: 1800 loss: 6.00310557e-07
Iter: 1801 loss: 6.00102567e-07
Iter: 1802 loss: 6.00090232e-07
Iter: 1803 loss: 5.99937152e-07
Iter: 1804 loss: 5.99807493e-07
Iter: 1805 loss: 5.99795612e-07
Iter: 1806 loss: 5.99660893e-07
Iter: 1807 loss: 5.99652935e-07
Iter: 1808 loss: 5.9953021e-07
Iter: 1809 loss: 5.99508894e-07
Iter: 1810 loss: 5.99427494e-07
Iter: 1811 loss: 5.99285e-07
Iter: 1812 loss: 5.99119176e-07
Iter: 1813 loss: 5.99110649e-07
Iter: 1814 loss: 5.98928807e-07
Iter: 1815 loss: 6.01893078e-07
Iter: 1816 loss: 5.98916415e-07
Iter: 1817 loss: 5.98712802e-07
Iter: 1818 loss: 5.99022314e-07
Iter: 1819 loss: 5.98581778e-07
Iter: 1820 loss: 5.98463e-07
Iter: 1821 loss: 5.98452232e-07
Iter: 1822 loss: 5.9834565e-07
Iter: 1823 loss: 5.98187512e-07
Iter: 1824 loss: 5.99602572e-07
Iter: 1825 loss: 5.98166253e-07
Iter: 1826 loss: 5.98012377e-07
Iter: 1827 loss: 5.98621568e-07
Iter: 1828 loss: 5.97986627e-07
Iter: 1829 loss: 5.97851113e-07
Iter: 1830 loss: 5.97928249e-07
Iter: 1831 loss: 5.97790631e-07
Iter: 1832 loss: 5.97656594e-07
Iter: 1833 loss: 5.97978726e-07
Iter: 1834 loss: 5.97587871e-07
Iter: 1835 loss: 5.97421604e-07
Iter: 1836 loss: 5.98255156e-07
Iter: 1837 loss: 5.973817e-07
Iter: 1838 loss: 5.97270684e-07
Iter: 1839 loss: 5.96975383e-07
Iter: 1840 loss: 6.00710564e-07
Iter: 1841 loss: 5.96955886e-07
Iter: 1842 loss: 5.96890743e-07
Iter: 1843 loss: 5.96798316e-07
Iter: 1844 loss: 5.96660584e-07
Iter: 1845 loss: 5.96605389e-07
Iter: 1846 loss: 5.96550649e-07
Iter: 1847 loss: 5.96433097e-07
Iter: 1848 loss: 5.96275356e-07
Iter: 1849 loss: 5.96258928e-07
Iter: 1850 loss: 5.96127904e-07
Iter: 1851 loss: 5.96119889e-07
Iter: 1852 loss: 5.95960557e-07
Iter: 1853 loss: 5.95890185e-07
Iter: 1854 loss: 5.95824531e-07
Iter: 1855 loss: 5.95700556e-07
Iter: 1856 loss: 5.95859e-07
Iter: 1857 loss: 5.95596362e-07
Iter: 1858 loss: 5.95395704e-07
Iter: 1859 loss: 5.96966629e-07
Iter: 1860 loss: 5.95392351e-07
Iter: 1861 loss: 5.95183167e-07
Iter: 1862 loss: 5.95619952e-07
Iter: 1863 loss: 5.95125471e-07
Iter: 1864 loss: 5.94996322e-07
Iter: 1865 loss: 5.95463462e-07
Iter: 1866 loss: 5.94962444e-07
Iter: 1867 loss: 5.94856488e-07
Iter: 1868 loss: 5.95483584e-07
Iter: 1869 loss: 5.94837388e-07
Iter: 1870 loss: 5.94734729e-07
Iter: 1871 loss: 5.94714948e-07
Iter: 1872 loss: 5.94657195e-07
Iter: 1873 loss: 5.94564426e-07
Iter: 1874 loss: 5.94786115e-07
Iter: 1875 loss: 5.94518781e-07
Iter: 1876 loss: 5.94302378e-07
Iter: 1877 loss: 5.94654807e-07
Iter: 1878 loss: 5.94197218e-07
Iter: 1879 loss: 5.94034304e-07
Iter: 1880 loss: 5.94055109e-07
Iter: 1881 loss: 5.93915729e-07
Iter: 1882 loss: 5.9374355e-07
Iter: 1883 loss: 5.93944719e-07
Iter: 1884 loss: 5.93624065e-07
Iter: 1885 loss: 5.9333513e-07
Iter: 1886 loss: 5.96776488e-07
Iter: 1887 loss: 5.93341667e-07
Iter: 1888 loss: 5.93214565e-07
Iter: 1889 loss: 5.93171649e-07
Iter: 1890 loss: 5.93104176e-07
Iter: 1891 loss: 5.92981792e-07
Iter: 1892 loss: 5.94054086e-07
Iter: 1893 loss: 5.92976221e-07
Iter: 1894 loss: 5.92856907e-07
Iter: 1895 loss: 5.93000323e-07
Iter: 1896 loss: 5.92793299e-07
Iter: 1897 loss: 5.9265426e-07
Iter: 1898 loss: 5.92953597e-07
Iter: 1899 loss: 5.92604e-07
Iter: 1900 loss: 5.92404092e-07
Iter: 1901 loss: 5.930778e-07
Iter: 1902 loss: 5.92364813e-07
Iter: 1903 loss: 5.9220082e-07
Iter: 1904 loss: 5.92232141e-07
Iter: 1905 loss: 5.92083211e-07
Iter: 1906 loss: 5.91953722e-07
Iter: 1907 loss: 5.92205652e-07
Iter: 1908 loss: 5.91858566e-07
Iter: 1909 loss: 5.9171316e-07
Iter: 1910 loss: 5.9405e-07
Iter: 1911 loss: 5.91698949e-07
Iter: 1912 loss: 5.91582591e-07
Iter: 1913 loss: 5.91213563e-07
Iter: 1914 loss: 5.94094899e-07
Iter: 1915 loss: 5.9112358e-07
Iter: 1916 loss: 5.90832883e-07
Iter: 1917 loss: 5.91875448e-07
Iter: 1918 loss: 5.9073551e-07
Iter: 1919 loss: 5.90455329e-07
Iter: 1920 loss: 5.93656182e-07
Iter: 1921 loss: 5.90428613e-07
Iter: 1922 loss: 5.90057709e-07
Iter: 1923 loss: 5.90284742e-07
Iter: 1924 loss: 5.89822491e-07
Iter: 1925 loss: 5.896934e-07
Iter: 1926 loss: 5.90240063e-07
Iter: 1927 loss: 5.89653723e-07
Iter: 1928 loss: 5.89547653e-07
Iter: 1929 loss: 5.90186573e-07
Iter: 1930 loss: 5.89530146e-07
Iter: 1931 loss: 5.89402134e-07
Iter: 1932 loss: 5.89400258e-07
Iter: 1933 loss: 5.89293791e-07
Iter: 1934 loss: 5.89141223e-07
Iter: 1935 loss: 5.90504044e-07
Iter: 1936 loss: 5.89133265e-07
Iter: 1937 loss: 5.890426e-07
Iter: 1938 loss: 5.88915498e-07
Iter: 1939 loss: 5.88911121e-07
Iter: 1940 loss: 5.88690568e-07
Iter: 1941 loss: 5.88744228e-07
Iter: 1942 loss: 5.88535386e-07
Iter: 1943 loss: 5.8834604e-07
Iter: 1944 loss: 5.88353146e-07
Iter: 1945 loss: 5.88180683e-07
Iter: 1946 loss: 5.88206547e-07
Iter: 1947 loss: 5.88032037e-07
Iter: 1948 loss: 5.87856562e-07
Iter: 1949 loss: 5.87932789e-07
Iter: 1950 loss: 5.87745944e-07
Iter: 1951 loss: 5.87571321e-07
Iter: 1952 loss: 5.87875e-07
Iter: 1953 loss: 5.87515274e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4
+ date
Mon Oct 26 16:57:54 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c24b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c277a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c277d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c302e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c3122f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c1c0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c13b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c12d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c12dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c12d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c0c8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c0cd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c0cd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c06d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492c07b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49107abb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49107b0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49107a7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f491073ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49107a7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f491073a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4910771bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f491068a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49106a0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49106a0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f491064f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4910619598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49105e5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49105e3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49105f5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f491058a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4910570840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49105702f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4910570730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49105252f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49104c5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.02843e-06
Iter: 2 loss: 6.17232718e-06
Iter: 3 loss: 3.07027076e-05
Iter: 4 loss: 6.1613041e-06
Iter: 5 loss: 5.48528624e-06
Iter: 6 loss: 8.3025916e-06
Iter: 7 loss: 5.33999628e-06
Iter: 8 loss: 5.05495063e-06
Iter: 9 loss: 4.84223801e-06
Iter: 10 loss: 4.74813351e-06
Iter: 11 loss: 4.55790314e-06
Iter: 12 loss: 4.51642e-06
Iter: 13 loss: 4.36729624e-06
Iter: 14 loss: 4.2978636e-06
Iter: 15 loss: 4.22413314e-06
Iter: 16 loss: 4.11358587e-06
Iter: 17 loss: 4.22627909e-06
Iter: 18 loss: 4.05174069e-06
Iter: 19 loss: 3.90151081e-06
Iter: 20 loss: 5.52780193e-06
Iter: 21 loss: 3.8981766e-06
Iter: 22 loss: 3.82067446e-06
Iter: 23 loss: 3.62159108e-06
Iter: 24 loss: 5.29746e-06
Iter: 25 loss: 3.58759144e-06
Iter: 26 loss: 3.41626946e-06
Iter: 27 loss: 3.41109626e-06
Iter: 28 loss: 3.25799692e-06
Iter: 29 loss: 3.28606666e-06
Iter: 30 loss: 3.14355111e-06
Iter: 31 loss: 3.05282492e-06
Iter: 32 loss: 3.19617902e-06
Iter: 33 loss: 3.01061959e-06
Iter: 34 loss: 2.95101108e-06
Iter: 35 loss: 2.85156216e-06
Iter: 36 loss: 2.85125066e-06
Iter: 37 loss: 2.77028312e-06
Iter: 38 loss: 3.17461308e-06
Iter: 39 loss: 2.75655657e-06
Iter: 40 loss: 2.68669464e-06
Iter: 41 loss: 2.56487374e-06
Iter: 42 loss: 2.56487147e-06
Iter: 43 loss: 2.43117711e-06
Iter: 44 loss: 3.87943965e-06
Iter: 45 loss: 2.42808801e-06
Iter: 46 loss: 2.31298486e-06
Iter: 47 loss: 3.77559263e-06
Iter: 48 loss: 2.31206923e-06
Iter: 49 loss: 2.23792676e-06
Iter: 50 loss: 2.17395973e-06
Iter: 51 loss: 2.15395494e-06
Iter: 52 loss: 2.09906148e-06
Iter: 53 loss: 2.63831907e-06
Iter: 54 loss: 2.09712061e-06
Iter: 55 loss: 2.04761614e-06
Iter: 56 loss: 2.29827265e-06
Iter: 57 loss: 2.03949867e-06
Iter: 58 loss: 1.99985334e-06
Iter: 59 loss: 1.97825648e-06
Iter: 60 loss: 1.96059045e-06
Iter: 61 loss: 1.93399319e-06
Iter: 62 loss: 2.30172191e-06
Iter: 63 loss: 1.93388678e-06
Iter: 64 loss: 1.90715218e-06
Iter: 65 loss: 1.94135077e-06
Iter: 66 loss: 1.89342086e-06
Iter: 67 loss: 1.86279931e-06
Iter: 68 loss: 1.80263578e-06
Iter: 69 loss: 2.99515659e-06
Iter: 70 loss: 1.80216341e-06
Iter: 71 loss: 1.7787703e-06
Iter: 72 loss: 1.77465677e-06
Iter: 73 loss: 1.74369347e-06
Iter: 74 loss: 1.76790763e-06
Iter: 75 loss: 1.72495459e-06
Iter: 76 loss: 1.69835903e-06
Iter: 77 loss: 1.6780001e-06
Iter: 78 loss: 1.66940254e-06
Iter: 79 loss: 1.62469109e-06
Iter: 80 loss: 1.62916865e-06
Iter: 81 loss: 1.59016736e-06
Iter: 82 loss: 1.55723615e-06
Iter: 83 loss: 1.55716623e-06
Iter: 84 loss: 1.5400467e-06
Iter: 85 loss: 1.53963856e-06
Iter: 86 loss: 1.52323923e-06
Iter: 87 loss: 1.49037055e-06
Iter: 88 loss: 2.11628503e-06
Iter: 89 loss: 1.48995423e-06
Iter: 90 loss: 1.47531284e-06
Iter: 91 loss: 1.63736433e-06
Iter: 92 loss: 1.47502806e-06
Iter: 93 loss: 1.46169759e-06
Iter: 94 loss: 1.55185285e-06
Iter: 95 loss: 1.46037883e-06
Iter: 96 loss: 1.45098943e-06
Iter: 97 loss: 1.44245632e-06
Iter: 98 loss: 1.44012688e-06
Iter: 99 loss: 1.4245137e-06
Iter: 100 loss: 1.43328248e-06
Iter: 101 loss: 1.4143302e-06
Iter: 102 loss: 1.38997666e-06
Iter: 103 loss: 1.5854207e-06
Iter: 104 loss: 1.38838755e-06
Iter: 105 loss: 1.36876508e-06
Iter: 106 loss: 1.34148831e-06
Iter: 107 loss: 1.34034553e-06
Iter: 108 loss: 1.32092782e-06
Iter: 109 loss: 1.51259917e-06
Iter: 110 loss: 1.32025218e-06
Iter: 111 loss: 1.29893419e-06
Iter: 112 loss: 1.36307278e-06
Iter: 113 loss: 1.29245961e-06
Iter: 114 loss: 1.28100623e-06
Iter: 115 loss: 1.2861974e-06
Iter: 116 loss: 1.27327166e-06
Iter: 117 loss: 1.26391956e-06
Iter: 118 loss: 1.26409236e-06
Iter: 119 loss: 1.25649683e-06
Iter: 120 loss: 1.24543556e-06
Iter: 121 loss: 1.30773492e-06
Iter: 122 loss: 1.24386247e-06
Iter: 123 loss: 1.2332099e-06
Iter: 124 loss: 1.36935682e-06
Iter: 125 loss: 1.23312236e-06
Iter: 126 loss: 1.22351821e-06
Iter: 127 loss: 1.20166055e-06
Iter: 128 loss: 1.48883987e-06
Iter: 129 loss: 1.20022719e-06
Iter: 130 loss: 1.19147853e-06
Iter: 131 loss: 1.19135325e-06
Iter: 132 loss: 1.18172716e-06
Iter: 133 loss: 1.201651e-06
Iter: 134 loss: 1.17788898e-06
Iter: 135 loss: 1.16804836e-06
Iter: 136 loss: 1.15759133e-06
Iter: 137 loss: 1.15594548e-06
Iter: 138 loss: 1.15067246e-06
Iter: 139 loss: 1.15003024e-06
Iter: 140 loss: 1.14406339e-06
Iter: 141 loss: 1.14416036e-06
Iter: 142 loss: 1.13934914e-06
Iter: 143 loss: 1.13115289e-06
Iter: 144 loss: 1.13310045e-06
Iter: 145 loss: 1.12512498e-06
Iter: 146 loss: 1.11709119e-06
Iter: 147 loss: 1.13502392e-06
Iter: 148 loss: 1.11408713e-06
Iter: 149 loss: 1.10436622e-06
Iter: 150 loss: 1.20856475e-06
Iter: 151 loss: 1.10406768e-06
Iter: 152 loss: 1.09951827e-06
Iter: 153 loss: 1.0923651e-06
Iter: 154 loss: 1.09228813e-06
Iter: 155 loss: 1.08321012e-06
Iter: 156 loss: 1.07416929e-06
Iter: 157 loss: 1.07227822e-06
Iter: 158 loss: 1.05825893e-06
Iter: 159 loss: 1.20836273e-06
Iter: 160 loss: 1.05792833e-06
Iter: 161 loss: 1.0509757e-06
Iter: 162 loss: 1.05098218e-06
Iter: 163 loss: 1.04273499e-06
Iter: 164 loss: 1.03400498e-06
Iter: 165 loss: 1.03255411e-06
Iter: 166 loss: 1.0267222e-06
Iter: 167 loss: 1.03704383e-06
Iter: 168 loss: 1.02413424e-06
Iter: 169 loss: 1.02085892e-06
Iter: 170 loss: 1.02034346e-06
Iter: 171 loss: 1.01732189e-06
Iter: 172 loss: 1.01405215e-06
Iter: 173 loss: 1.01352236e-06
Iter: 174 loss: 1.00982129e-06
Iter: 175 loss: 1.00763395e-06
Iter: 176 loss: 1.00607281e-06
Iter: 177 loss: 9.98776272e-07
Iter: 178 loss: 1.040592e-06
Iter: 179 loss: 9.9779686e-07
Iter: 180 loss: 9.9066051e-07
Iter: 181 loss: 1.03348384e-06
Iter: 182 loss: 9.89788077e-07
Iter: 183 loss: 9.8603914e-07
Iter: 184 loss: 9.78265462e-07
Iter: 185 loss: 1.11044028e-06
Iter: 186 loss: 9.7806435e-07
Iter: 187 loss: 9.67928713e-07
Iter: 188 loss: 1.004654e-06
Iter: 189 loss: 9.65380536e-07
Iter: 190 loss: 9.62939225e-07
Iter: 191 loss: 9.62324521e-07
Iter: 192 loss: 9.59069212e-07
Iter: 193 loss: 9.58332748e-07
Iter: 194 loss: 9.56175199e-07
Iter: 195 loss: 9.52860148e-07
Iter: 196 loss: 9.53189101e-07
Iter: 197 loss: 9.50298443e-07
Iter: 198 loss: 9.48519755e-07
Iter: 199 loss: 9.48110426e-07
Iter: 200 loss: 9.45761428e-07
Iter: 201 loss: 9.40124437e-07
Iter: 202 loss: 1.00004672e-06
Iter: 203 loss: 9.3949518e-07
Iter: 204 loss: 9.35005573e-07
Iter: 205 loss: 9.61824071e-07
Iter: 206 loss: 9.34414288e-07
Iter: 207 loss: 9.31116404e-07
Iter: 208 loss: 9.31130103e-07
Iter: 209 loss: 9.2806431e-07
Iter: 210 loss: 9.19272338e-07
Iter: 211 loss: 9.60752232e-07
Iter: 212 loss: 9.16193244e-07
Iter: 213 loss: 9.11113943e-07
Iter: 214 loss: 9.11065058e-07
Iter: 215 loss: 9.07438505e-07
Iter: 216 loss: 9.44280316e-07
Iter: 217 loss: 9.07334766e-07
Iter: 218 loss: 9.03972136e-07
Iter: 219 loss: 9.01557655e-07
Iter: 220 loss: 9.00389409e-07
Iter: 221 loss: 8.96783149e-07
Iter: 222 loss: 9.0638764e-07
Iter: 223 loss: 8.9556886e-07
Iter: 224 loss: 8.92579749e-07
Iter: 225 loss: 8.93802508e-07
Iter: 226 loss: 8.90521846e-07
Iter: 227 loss: 8.90010483e-07
Iter: 228 loss: 8.88694274e-07
Iter: 229 loss: 8.87341741e-07
Iter: 230 loss: 8.8358621e-07
Iter: 231 loss: 9.05488946e-07
Iter: 232 loss: 8.82570646e-07
Iter: 233 loss: 8.77235948e-07
Iter: 234 loss: 9.02610282e-07
Iter: 235 loss: 8.76238971e-07
Iter: 236 loss: 8.72260557e-07
Iter: 237 loss: 8.72231965e-07
Iter: 238 loss: 8.70469535e-07
Iter: 239 loss: 8.65312e-07
Iter: 240 loss: 8.85723125e-07
Iter: 241 loss: 8.63162938e-07
Iter: 242 loss: 8.59184865e-07
Iter: 243 loss: 8.5873171e-07
Iter: 244 loss: 8.55337248e-07
Iter: 245 loss: 8.78108267e-07
Iter: 246 loss: 8.54984592e-07
Iter: 247 loss: 8.53948677e-07
Iter: 248 loss: 8.51587401e-07
Iter: 249 loss: 8.85958571e-07
Iter: 250 loss: 8.51467178e-07
Iter: 251 loss: 8.4966581e-07
Iter: 252 loss: 8.49619141e-07
Iter: 253 loss: 8.47646447e-07
Iter: 254 loss: 8.48710158e-07
Iter: 255 loss: 8.46316311e-07
Iter: 256 loss: 8.43595444e-07
Iter: 257 loss: 8.38840265e-07
Iter: 258 loss: 8.38860387e-07
Iter: 259 loss: 8.34553589e-07
Iter: 260 loss: 8.82676943e-07
Iter: 261 loss: 8.34514e-07
Iter: 262 loss: 8.31363195e-07
Iter: 263 loss: 8.3537725e-07
Iter: 264 loss: 8.29759188e-07
Iter: 265 loss: 8.24868039e-07
Iter: 266 loss: 8.56123677e-07
Iter: 267 loss: 8.24300855e-07
Iter: 268 loss: 8.23032e-07
Iter: 269 loss: 8.2308793e-07
Iter: 270 loss: 8.22032291e-07
Iter: 271 loss: 8.20891842e-07
Iter: 272 loss: 8.20879563e-07
Iter: 273 loss: 8.19582397e-07
Iter: 274 loss: 8.1611023e-07
Iter: 275 loss: 8.36900199e-07
Iter: 276 loss: 8.15126327e-07
Iter: 277 loss: 8.12845542e-07
Iter: 278 loss: 8.4585929e-07
Iter: 279 loss: 8.12810868e-07
Iter: 280 loss: 8.10521215e-07
Iter: 281 loss: 8.22872607e-07
Iter: 282 loss: 8.10164352e-07
Iter: 283 loss: 8.08363097e-07
Iter: 284 loss: 8.04964372e-07
Iter: 285 loss: 8.79484901e-07
Iter: 286 loss: 8.04977674e-07
Iter: 287 loss: 8.03495482e-07
Iter: 288 loss: 8.03216722e-07
Iter: 289 loss: 8.01549504e-07
Iter: 290 loss: 8.01758745e-07
Iter: 291 loss: 8.00268253e-07
Iter: 292 loss: 7.98557153e-07
Iter: 293 loss: 7.97846042e-07
Iter: 294 loss: 7.96941e-07
Iter: 295 loss: 7.94189873e-07
Iter: 296 loss: 7.97200187e-07
Iter: 297 loss: 7.92652543e-07
Iter: 298 loss: 7.89973228e-07
Iter: 299 loss: 8.27912913e-07
Iter: 300 loss: 7.89928436e-07
Iter: 301 loss: 7.88191812e-07
Iter: 302 loss: 8.08101674e-07
Iter: 303 loss: 7.88168222e-07
Iter: 304 loss: 7.87287718e-07
Iter: 305 loss: 7.84731128e-07
Iter: 306 loss: 7.95028541e-07
Iter: 307 loss: 7.83741939e-07
Iter: 308 loss: 7.84715439e-07
Iter: 309 loss: 7.82405323e-07
Iter: 310 loss: 7.81431936e-07
Iter: 311 loss: 7.80199343e-07
Iter: 312 loss: 7.8009316e-07
Iter: 313 loss: 7.78427363e-07
Iter: 314 loss: 7.75496176e-07
Iter: 315 loss: 7.75498279e-07
Iter: 316 loss: 7.73743295e-07
Iter: 317 loss: 7.73077204e-07
Iter: 318 loss: 7.71662485e-07
Iter: 319 loss: 7.68875907e-07
Iter: 320 loss: 8.26016958e-07
Iter: 321 loss: 7.68874258e-07
Iter: 322 loss: 7.6669744e-07
Iter: 323 loss: 7.91125785e-07
Iter: 324 loss: 7.66650089e-07
Iter: 325 loss: 7.64812341e-07
Iter: 326 loss: 7.75238732e-07
Iter: 327 loss: 7.64522326e-07
Iter: 328 loss: 7.6383651e-07
Iter: 329 loss: 7.62637e-07
Iter: 330 loss: 7.62628e-07
Iter: 331 loss: 7.60858711e-07
Iter: 332 loss: 7.6248773e-07
Iter: 333 loss: 7.59834222e-07
Iter: 334 loss: 7.59079285e-07
Iter: 335 loss: 7.58920351e-07
Iter: 336 loss: 7.57955831e-07
Iter: 337 loss: 7.56189365e-07
Iter: 338 loss: 7.94781499e-07
Iter: 339 loss: 7.56175268e-07
Iter: 340 loss: 7.53453946e-07
Iter: 341 loss: 7.54500945e-07
Iter: 342 loss: 7.515589e-07
Iter: 343 loss: 7.50785148e-07
Iter: 344 loss: 7.50016284e-07
Iter: 345 loss: 7.49039373e-07
Iter: 346 loss: 7.47934848e-07
Iter: 347 loss: 7.4779615e-07
Iter: 348 loss: 7.46452599e-07
Iter: 349 loss: 7.47372e-07
Iter: 350 loss: 7.45605291e-07
Iter: 351 loss: 7.44658166e-07
Iter: 352 loss: 7.44537488e-07
Iter: 353 loss: 7.43939211e-07
Iter: 354 loss: 7.42420298e-07
Iter: 355 loss: 7.57507109e-07
Iter: 356 loss: 7.42224756e-07
Iter: 357 loss: 7.40798441e-07
Iter: 358 loss: 7.5576645e-07
Iter: 359 loss: 7.40743531e-07
Iter: 360 loss: 7.39381051e-07
Iter: 361 loss: 7.4601121e-07
Iter: 362 loss: 7.39138159e-07
Iter: 363 loss: 7.38217182e-07
Iter: 364 loss: 7.3568583e-07
Iter: 365 loss: 7.48992136e-07
Iter: 366 loss: 7.34871833e-07
Iter: 367 loss: 7.33805109e-07
Iter: 368 loss: 7.33244406e-07
Iter: 369 loss: 7.32145224e-07
Iter: 370 loss: 7.40497342e-07
Iter: 371 loss: 7.32097192e-07
Iter: 372 loss: 7.313526e-07
Iter: 373 loss: 7.29504109e-07
Iter: 374 loss: 7.4775528e-07
Iter: 375 loss: 7.29255646e-07
Iter: 376 loss: 7.27883332e-07
Iter: 377 loss: 7.27800284e-07
Iter: 378 loss: 7.26657845e-07
Iter: 379 loss: 7.31436387e-07
Iter: 380 loss: 7.26426379e-07
Iter: 381 loss: 7.25649784e-07
Iter: 382 loss: 7.23997e-07
Iter: 383 loss: 7.50581535e-07
Iter: 384 loss: 7.23920436e-07
Iter: 385 loss: 7.2236395e-07
Iter: 386 loss: 7.2234252e-07
Iter: 387 loss: 7.21021934e-07
Iter: 388 loss: 7.25737493e-07
Iter: 389 loss: 7.20653702e-07
Iter: 390 loss: 7.20000571e-07
Iter: 391 loss: 7.18823799e-07
Iter: 392 loss: 7.18805779e-07
Iter: 393 loss: 7.18108424e-07
Iter: 394 loss: 7.17968248e-07
Iter: 395 loss: 7.1722576e-07
Iter: 396 loss: 7.15683655e-07
Iter: 397 loss: 7.39948291e-07
Iter: 398 loss: 7.15650287e-07
Iter: 399 loss: 7.13832378e-07
Iter: 400 loss: 7.14629209e-07
Iter: 401 loss: 7.12557835e-07
Iter: 402 loss: 7.12450287e-07
Iter: 403 loss: 7.11573648e-07
Iter: 404 loss: 7.10964287e-07
Iter: 405 loss: 7.10024551e-07
Iter: 406 loss: 7.1000818e-07
Iter: 407 loss: 7.08859716e-07
Iter: 408 loss: 7.09949916e-07
Iter: 409 loss: 7.0818237e-07
Iter: 410 loss: 7.07586e-07
Iter: 411 loss: 7.07387699e-07
Iter: 412 loss: 7.07022139e-07
Iter: 413 loss: 7.06583e-07
Iter: 414 loss: 7.06547326e-07
Iter: 415 loss: 7.05830075e-07
Iter: 416 loss: 7.05272441e-07
Iter: 417 loss: 7.05061e-07
Iter: 418 loss: 7.04072818e-07
Iter: 419 loss: 7.04053605e-07
Iter: 420 loss: 7.03396609e-07
Iter: 421 loss: 7.02080683e-07
Iter: 422 loss: 7.266475e-07
Iter: 423 loss: 7.02052375e-07
Iter: 424 loss: 7.00374244e-07
Iter: 425 loss: 7.03692081e-07
Iter: 426 loss: 6.99681266e-07
Iter: 427 loss: 6.98002509e-07
Iter: 428 loss: 6.98001315e-07
Iter: 429 loss: 6.97385531e-07
Iter: 430 loss: 6.96091092e-07
Iter: 431 loss: 7.17029366e-07
Iter: 432 loss: 6.96044481e-07
Iter: 433 loss: 6.94944049e-07
Iter: 434 loss: 7.10498512e-07
Iter: 435 loss: 6.94931828e-07
Iter: 436 loss: 6.93991751e-07
Iter: 437 loss: 6.99294276e-07
Iter: 438 loss: 6.93871186e-07
Iter: 439 loss: 6.93431957e-07
Iter: 440 loss: 6.92555886e-07
Iter: 441 loss: 7.11755547e-07
Iter: 442 loss: 6.9257095e-07
Iter: 443 loss: 6.91633545e-07
Iter: 444 loss: 7.0485e-07
Iter: 445 loss: 6.91628543e-07
Iter: 446 loss: 6.90642935e-07
Iter: 447 loss: 6.8992972e-07
Iter: 448 loss: 6.89599e-07
Iter: 449 loss: 6.88309569e-07
Iter: 450 loss: 6.88215437e-07
Iter: 451 loss: 6.8726041e-07
Iter: 452 loss: 6.86126214e-07
Iter: 453 loss: 6.86094154e-07
Iter: 454 loss: 6.85088082e-07
Iter: 455 loss: 6.87735792e-07
Iter: 456 loss: 6.84788631e-07
Iter: 457 loss: 6.84164945e-07
Iter: 458 loss: 6.83131532e-07
Iter: 459 loss: 6.83107828e-07
Iter: 460 loss: 6.82913537e-07
Iter: 461 loss: 6.82574864e-07
Iter: 462 loss: 6.82163659e-07
Iter: 463 loss: 6.81906499e-07
Iter: 464 loss: 6.8172227e-07
Iter: 465 loss: 6.81135532e-07
Iter: 466 loss: 6.79947789e-07
Iter: 467 loss: 7.02285547e-07
Iter: 468 loss: 6.79909363e-07
Iter: 469 loss: 6.79529194e-07
Iter: 470 loss: 6.79090306e-07
Iter: 471 loss: 6.7853739e-07
Iter: 472 loss: 6.77757669e-07
Iter: 473 loss: 6.77720095e-07
Iter: 474 loss: 6.76900868e-07
Iter: 475 loss: 6.8085842e-07
Iter: 476 loss: 6.76762909e-07
Iter: 477 loss: 6.75677597e-07
Iter: 478 loss: 6.77695198e-07
Iter: 479 loss: 6.75215688e-07
Iter: 480 loss: 6.74409421e-07
Iter: 481 loss: 6.74603086e-07
Iter: 482 loss: 6.73842578e-07
Iter: 483 loss: 6.73007548e-07
Iter: 484 loss: 6.77593107e-07
Iter: 485 loss: 6.7290307e-07
Iter: 486 loss: 6.71963392e-07
Iter: 487 loss: 6.77866637e-07
Iter: 488 loss: 6.71889723e-07
Iter: 489 loss: 6.71306793e-07
Iter: 490 loss: 6.7080623e-07
Iter: 491 loss: 6.70653435e-07
Iter: 492 loss: 6.69822384e-07
Iter: 493 loss: 6.70983638e-07
Iter: 494 loss: 6.69375709e-07
Iter: 495 loss: 6.6812396e-07
Iter: 496 loss: 6.77456114e-07
Iter: 497 loss: 6.68051257e-07
Iter: 498 loss: 6.67486802e-07
Iter: 499 loss: 6.66933715e-07
Iter: 500 loss: 6.66828157e-07
Iter: 501 loss: 6.65973801e-07
Iter: 502 loss: 6.70754275e-07
Iter: 503 loss: 6.65874722e-07
Iter: 504 loss: 6.6474729e-07
Iter: 505 loss: 6.65884443e-07
Iter: 506 loss: 6.64086e-07
Iter: 507 loss: 6.63300227e-07
Iter: 508 loss: 6.64235586e-07
Iter: 509 loss: 6.62894763e-07
Iter: 510 loss: 6.6199118e-07
Iter: 511 loss: 6.7210749e-07
Iter: 512 loss: 6.62002321e-07
Iter: 513 loss: 6.61295189e-07
Iter: 514 loss: 6.59835223e-07
Iter: 515 loss: 6.85002647e-07
Iter: 516 loss: 6.59798502e-07
Iter: 517 loss: 6.58686247e-07
Iter: 518 loss: 6.66788878e-07
Iter: 519 loss: 6.58591603e-07
Iter: 520 loss: 6.5802e-07
Iter: 521 loss: 6.57995486e-07
Iter: 522 loss: 6.57481223e-07
Iter: 523 loss: 6.56930411e-07
Iter: 524 loss: 6.56862937e-07
Iter: 525 loss: 6.56178145e-07
Iter: 526 loss: 6.56511361e-07
Iter: 527 loss: 6.55739655e-07
Iter: 528 loss: 6.5496306e-07
Iter: 529 loss: 6.65078858e-07
Iter: 530 loss: 6.54953681e-07
Iter: 531 loss: 6.54216933e-07
Iter: 532 loss: 6.54006044e-07
Iter: 533 loss: 6.53541179e-07
Iter: 534 loss: 6.52860194e-07
Iter: 535 loss: 6.5240539e-07
Iter: 536 loss: 6.52131575e-07
Iter: 537 loss: 6.5118536e-07
Iter: 538 loss: 6.51181608e-07
Iter: 539 loss: 6.50590209e-07
Iter: 540 loss: 6.50295e-07
Iter: 541 loss: 6.49991193e-07
Iter: 542 loss: 6.49692538e-07
Iter: 543 loss: 6.49683955e-07
Iter: 544 loss: 6.49319475e-07
Iter: 545 loss: 6.48679247e-07
Iter: 546 loss: 6.48674359e-07
Iter: 547 loss: 6.4797689e-07
Iter: 548 loss: 6.48730634e-07
Iter: 549 loss: 6.47579611e-07
Iter: 550 loss: 6.47023967e-07
Iter: 551 loss: 6.52947506e-07
Iter: 552 loss: 6.47005777e-07
Iter: 553 loss: 6.463369e-07
Iter: 554 loss: 6.46890442e-07
Iter: 555 loss: 6.45932801e-07
Iter: 556 loss: 6.45084697e-07
Iter: 557 loss: 6.44386716e-07
Iter: 558 loss: 6.44165425e-07
Iter: 559 loss: 6.43446697e-07
Iter: 560 loss: 6.5415918e-07
Iter: 561 loss: 6.43447891e-07
Iter: 562 loss: 6.42834607e-07
Iter: 563 loss: 6.45157627e-07
Iter: 564 loss: 6.42689e-07
Iter: 565 loss: 6.42121506e-07
Iter: 566 loss: 6.41320526e-07
Iter: 567 loss: 6.41269366e-07
Iter: 568 loss: 6.408589e-07
Iter: 569 loss: 6.40804615e-07
Iter: 570 loss: 6.40284782e-07
Iter: 571 loss: 6.39966743e-07
Iter: 572 loss: 6.39754717e-07
Iter: 573 loss: 6.39163318e-07
Iter: 574 loss: 6.40802114e-07
Iter: 575 loss: 6.38983806e-07
Iter: 576 loss: 6.38499614e-07
Iter: 577 loss: 6.45999819e-07
Iter: 578 loss: 6.38485119e-07
Iter: 579 loss: 6.38145536e-07
Iter: 580 loss: 6.37236553e-07
Iter: 581 loss: 6.42473651e-07
Iter: 582 loss: 6.36941763e-07
Iter: 583 loss: 6.36023401e-07
Iter: 584 loss: 6.44486477e-07
Iter: 585 loss: 6.3596849e-07
Iter: 586 loss: 6.35567289e-07
Iter: 587 loss: 6.35516074e-07
Iter: 588 loss: 6.35099752e-07
Iter: 589 loss: 6.34103571e-07
Iter: 590 loss: 6.47367301e-07
Iter: 591 loss: 6.34023877e-07
Iter: 592 loss: 6.3318771e-07
Iter: 593 loss: 6.37491553e-07
Iter: 594 loss: 6.33035313e-07
Iter: 595 loss: 6.32452611e-07
Iter: 596 loss: 6.37224616e-07
Iter: 597 loss: 6.32414299e-07
Iter: 598 loss: 6.31764863e-07
Iter: 599 loss: 6.33541333e-07
Iter: 600 loss: 6.3157438e-07
Iter: 601 loss: 6.31219791e-07
Iter: 602 loss: 6.31037835e-07
Iter: 603 loss: 6.30862246e-07
Iter: 604 loss: 6.30390673e-07
Iter: 605 loss: 6.36687105e-07
Iter: 606 loss: 6.30396187e-07
Iter: 607 loss: 6.29863507e-07
Iter: 608 loss: 6.29004489e-07
Iter: 609 loss: 6.29012447e-07
Iter: 610 loss: 6.28387056e-07
Iter: 611 loss: 6.34777791e-07
Iter: 612 loss: 6.2837e-07
Iter: 613 loss: 6.27627173e-07
Iter: 614 loss: 6.28351813e-07
Iter: 615 loss: 6.27220629e-07
Iter: 616 loss: 6.26570909e-07
Iter: 617 loss: 6.26251676e-07
Iter: 618 loss: 6.25971211e-07
Iter: 619 loss: 6.25318535e-07
Iter: 620 loss: 6.2659683e-07
Iter: 621 loss: 6.25070697e-07
Iter: 622 loss: 6.24799213e-07
Iter: 623 loss: 6.24682571e-07
Iter: 624 loss: 6.2437806e-07
Iter: 625 loss: 6.24283189e-07
Iter: 626 loss: 6.24116694e-07
Iter: 627 loss: 6.23756819e-07
Iter: 628 loss: 6.2324591e-07
Iter: 629 loss: 6.23233063e-07
Iter: 630 loss: 6.22505809e-07
Iter: 631 loss: 6.28092494e-07
Iter: 632 loss: 6.22461471e-07
Iter: 633 loss: 6.2192214e-07
Iter: 634 loss: 6.28757391e-07
Iter: 635 loss: 6.21906452e-07
Iter: 636 loss: 6.21554136e-07
Iter: 637 loss: 6.20825062e-07
Iter: 638 loss: 6.31311536e-07
Iter: 639 loss: 6.20764467e-07
Iter: 640 loss: 6.20487867e-07
Iter: 641 loss: 6.20326887e-07
Iter: 642 loss: 6.20001401e-07
Iter: 643 loss: 6.20042272e-07
Iter: 644 loss: 6.19780337e-07
Iter: 645 loss: 6.19458433e-07
Iter: 646 loss: 6.19880552e-07
Iter: 647 loss: 6.19289665e-07
Iter: 648 loss: 6.18827869e-07
Iter: 649 loss: 6.20860362e-07
Iter: 650 loss: 6.18720833e-07
Iter: 651 loss: 6.18443096e-07
Iter: 652 loss: 6.17959813e-07
Iter: 653 loss: 6.17962939e-07
Iter: 654 loss: 6.17287185e-07
Iter: 655 loss: 6.18001195e-07
Iter: 656 loss: 6.16911223e-07
Iter: 657 loss: 6.16786792e-07
Iter: 658 loss: 6.16521334e-07
Iter: 659 loss: 6.16254852e-07
Iter: 660 loss: 6.15546526e-07
Iter: 661 loss: 6.21786455e-07
Iter: 662 loss: 6.15427e-07
Iter: 663 loss: 6.1460878e-07
Iter: 664 loss: 6.18072306e-07
Iter: 665 loss: 6.14442797e-07
Iter: 666 loss: 6.14074963e-07
Iter: 667 loss: 6.19222874e-07
Iter: 668 loss: 6.14066721e-07
Iter: 669 loss: 6.13690304e-07
Iter: 670 loss: 6.15011345e-07
Iter: 671 loss: 6.135989e-07
Iter: 672 loss: 6.1327404e-07
Iter: 673 loss: 6.12821509e-07
Iter: 674 loss: 6.127799e-07
Iter: 675 loss: 6.12506199e-07
Iter: 676 loss: 6.12456461e-07
Iter: 677 loss: 6.12186739e-07
Iter: 678 loss: 6.1167782e-07
Iter: 679 loss: 6.23049345e-07
Iter: 680 loss: 6.11679582e-07
Iter: 681 loss: 6.11232849e-07
Iter: 682 loss: 6.11230234e-07
Iter: 683 loss: 6.10870302e-07
Iter: 684 loss: 6.10937718e-07
Iter: 685 loss: 6.10559653e-07
Iter: 686 loss: 6.10198811e-07
Iter: 687 loss: 6.09703534e-07
Iter: 688 loss: 6.09685344e-07
Iter: 689 loss: 6.09056144e-07
Iter: 690 loss: 6.14180522e-07
Iter: 691 loss: 6.08997652e-07
Iter: 692 loss: 6.08773803e-07
Iter: 693 loss: 6.08733671e-07
Iter: 694 loss: 6.08528183e-07
Iter: 695 loss: 6.07921265e-07
Iter: 696 loss: 6.09453878e-07
Iter: 697 loss: 6.07576226e-07
Iter: 698 loss: 6.06930769e-07
Iter: 699 loss: 6.14264309e-07
Iter: 700 loss: 6.06905928e-07
Iter: 701 loss: 6.06443e-07
Iter: 702 loss: 6.07916093e-07
Iter: 703 loss: 6.062794e-07
Iter: 704 loss: 6.05773437e-07
Iter: 705 loss: 6.10973132e-07
Iter: 706 loss: 6.05760306e-07
Iter: 707 loss: 6.05485297e-07
Iter: 708 loss: 6.05396906e-07
Iter: 709 loss: 6.05231207e-07
Iter: 710 loss: 6.04944603e-07
Iter: 711 loss: 6.0924225e-07
Iter: 712 loss: 6.04940738e-07
Iter: 713 loss: 6.04657544e-07
Iter: 714 loss: 6.04320235e-07
Iter: 715 loss: 6.04302102e-07
Iter: 716 loss: 6.03943e-07
Iter: 717 loss: 6.07712082e-07
Iter: 718 loss: 6.03934268e-07
Iter: 719 loss: 6.03558647e-07
Iter: 720 loss: 6.03339117e-07
Iter: 721 loss: 6.03183707e-07
Iter: 722 loss: 6.02679961e-07
Iter: 723 loss: 6.02363684e-07
Iter: 724 loss: 6.02138641e-07
Iter: 725 loss: 6.01672468e-07
Iter: 726 loss: 6.07324409e-07
Iter: 727 loss: 6.01677812e-07
Iter: 728 loss: 6.01195097e-07
Iter: 729 loss: 6.03495835e-07
Iter: 730 loss: 6.01111537e-07
Iter: 731 loss: 6.0072324e-07
Iter: 732 loss: 6.00095632e-07
Iter: 733 loss: 6.00076191e-07
Iter: 734 loss: 5.9958694e-07
Iter: 735 loss: 6.01502677e-07
Iter: 736 loss: 5.9946e-07
Iter: 737 loss: 5.9899088e-07
Iter: 738 loss: 6.05345804e-07
Iter: 739 loss: 5.98997758e-07
Iter: 740 loss: 5.98555289e-07
Iter: 741 loss: 5.98732413e-07
Iter: 742 loss: 5.98277e-07
Iter: 743 loss: 5.97860549e-07
Iter: 744 loss: 5.98887368e-07
Iter: 745 loss: 5.97704911e-07
Iter: 746 loss: 5.97190876e-07
Iter: 747 loss: 6.00412591e-07
Iter: 748 loss: 5.97146141e-07
Iter: 749 loss: 5.96803034e-07
Iter: 750 loss: 5.96688722e-07
Iter: 751 loss: 5.96491361e-07
Iter: 752 loss: 5.9624756e-07
Iter: 753 loss: 5.96234258e-07
Iter: 754 loss: 5.96035534e-07
Iter: 755 loss: 5.95508482e-07
Iter: 756 loss: 5.9885258e-07
Iter: 757 loss: 5.95358529e-07
Iter: 758 loss: 5.94699259e-07
Iter: 759 loss: 5.97388293e-07
Iter: 760 loss: 5.94552603e-07
Iter: 761 loss: 5.94133155e-07
Iter: 762 loss: 5.98018346e-07
Iter: 763 loss: 5.94119854e-07
Iter: 764 loss: 5.93580467e-07
Iter: 765 loss: 5.94063181e-07
Iter: 766 loss: 5.93272375e-07
Iter: 767 loss: 5.92906417e-07
Iter: 768 loss: 5.92772778e-07
Iter: 769 loss: 5.92567517e-07
Iter: 770 loss: 5.92003175e-07
Iter: 771 loss: 5.91899038e-07
Iter: 772 loss: 5.91519324e-07
Iter: 773 loss: 5.91414107e-07
Iter: 774 loss: 5.91107096e-07
Iter: 775 loss: 5.90855905e-07
Iter: 776 loss: 5.90564696e-07
Iter: 777 loss: 5.90522745e-07
Iter: 778 loss: 5.90079196e-07
Iter: 779 loss: 5.91580488e-07
Iter: 780 loss: 5.8996244e-07
Iter: 781 loss: 5.89405374e-07
Iter: 782 loss: 5.913721e-07
Iter: 783 loss: 5.89227739e-07
Iter: 784 loss: 5.88911576e-07
Iter: 785 loss: 5.89717331e-07
Iter: 786 loss: 5.88811417e-07
Iter: 787 loss: 5.88488319e-07
Iter: 788 loss: 5.90877391e-07
Iter: 789 loss: 5.88452e-07
Iter: 790 loss: 5.88191085e-07
Iter: 791 loss: 5.87531247e-07
Iter: 792 loss: 5.93067966e-07
Iter: 793 loss: 5.87414718e-07
Iter: 794 loss: 5.86735496e-07
Iter: 795 loss: 5.9095e-07
Iter: 796 loss: 5.86648127e-07
Iter: 797 loss: 5.86271426e-07
Iter: 798 loss: 5.86265401e-07
Iter: 799 loss: 5.85866474e-07
Iter: 800 loss: 5.85364091e-07
Iter: 801 loss: 5.85330326e-07
Iter: 802 loss: 5.84866768e-07
Iter: 803 loss: 5.84909799e-07
Iter: 804 loss: 5.84496263e-07
Iter: 805 loss: 5.83919928e-07
Iter: 806 loss: 5.87138288e-07
Iter: 807 loss: 5.8384461e-07
Iter: 808 loss: 5.8359683e-07
Iter: 809 loss: 5.83567044e-07
Iter: 810 loss: 5.83345695e-07
Iter: 811 loss: 5.82855819e-07
Iter: 812 loss: 5.87885893e-07
Iter: 813 loss: 5.82808752e-07
Iter: 814 loss: 5.82387599e-07
Iter: 815 loss: 5.82366681e-07
Iter: 816 loss: 5.82041707e-07
Iter: 817 loss: 5.82404539e-07
Iter: 818 loss: 5.81866914e-07
Iter: 819 loss: 5.81562119e-07
Iter: 820 loss: 5.81939389e-07
Iter: 821 loss: 5.81403583e-07
Iter: 822 loss: 5.80856522e-07
Iter: 823 loss: 5.81680069e-07
Iter: 824 loss: 5.80585379e-07
Iter: 825 loss: 5.80165874e-07
Iter: 826 loss: 5.80314065e-07
Iter: 827 loss: 5.79838741e-07
Iter: 828 loss: 5.79449193e-07
Iter: 829 loss: 5.79781386e-07
Iter: 830 loss: 5.79203743e-07
Iter: 831 loss: 5.78936863e-07
Iter: 832 loss: 5.78862227e-07
Iter: 833 loss: 5.78648269e-07
Iter: 834 loss: 5.78292713e-07
Iter: 835 loss: 5.86361807e-07
Iter: 836 loss: 5.78301865e-07
Iter: 837 loss: 5.77786295e-07
Iter: 838 loss: 5.76953312e-07
Iter: 839 loss: 5.76943592e-07
Iter: 840 loss: 5.76257833e-07
Iter: 841 loss: 5.76259254e-07
Iter: 842 loss: 5.75962247e-07
Iter: 843 loss: 5.75951844e-07
Iter: 844 loss: 5.7565984e-07
Iter: 845 loss: 5.74996704e-07
Iter: 846 loss: 5.83404528e-07
Iter: 847 loss: 5.74904902e-07
Iter: 848 loss: 5.74711066e-07
Iter: 849 loss: 5.74626029e-07
Iter: 850 loss: 5.74353749e-07
Iter: 851 loss: 5.74426963e-07
Iter: 852 loss: 5.74180945e-07
Iter: 853 loss: 5.73875184e-07
Iter: 854 loss: 5.74394e-07
Iter: 855 loss: 5.73738362e-07
Iter: 856 loss: 5.73426178e-07
Iter: 857 loss: 5.76875379e-07
Iter: 858 loss: 5.73428679e-07
Iter: 859 loss: 5.73215175e-07
Iter: 860 loss: 5.72778958e-07
Iter: 861 loss: 5.79143716e-07
Iter: 862 loss: 5.72734905e-07
Iter: 863 loss: 5.72280555e-07
Iter: 864 loss: 5.75022796e-07
Iter: 865 loss: 5.72201316e-07
Iter: 866 loss: 5.7187367e-07
Iter: 867 loss: 5.71865826e-07
Iter: 868 loss: 5.71704504e-07
Iter: 869 loss: 5.71318083e-07
Iter: 870 loss: 5.75788363e-07
Iter: 871 loss: 5.71264195e-07
Iter: 872 loss: 5.70745101e-07
Iter: 873 loss: 5.71744749e-07
Iter: 874 loss: 5.70550355e-07
Iter: 875 loss: 5.69997155e-07
Iter: 876 loss: 5.69859822e-07
Iter: 877 loss: 5.69518e-07
Iter: 878 loss: 5.6943577e-07
Iter: 879 loss: 5.69178724e-07
Iter: 880 loss: 5.6886978e-07
Iter: 881 loss: 5.69409565e-07
Iter: 882 loss: 5.68728183e-07
Iter: 883 loss: 5.68477162e-07
Iter: 884 loss: 5.68041514e-07
Iter: 885 loss: 5.68025825e-07
Iter: 886 loss: 5.68008431e-07
Iter: 887 loss: 5.67802e-07
Iter: 888 loss: 5.67656343e-07
Iter: 889 loss: 5.67436473e-07
Iter: 890 loss: 5.73792192e-07
Iter: 891 loss: 5.67427151e-07
Iter: 892 loss: 5.67081713e-07
Iter: 893 loss: 5.67423967e-07
Iter: 894 loss: 5.6688026e-07
Iter: 895 loss: 5.6643529e-07
Iter: 896 loss: 5.72063527e-07
Iter: 897 loss: 5.66429719e-07
Iter: 898 loss: 5.66208314e-07
Iter: 899 loss: 5.65869755e-07
Iter: 900 loss: 5.65861569e-07
Iter: 901 loss: 5.65350661e-07
Iter: 902 loss: 5.64870334e-07
Iter: 903 loss: 5.64765628e-07
Iter: 904 loss: 5.65117944e-07
Iter: 905 loss: 5.64473794e-07
Iter: 906 loss: 5.64297522e-07
Iter: 907 loss: 5.640631e-07
Iter: 908 loss: 5.64041102e-07
Iter: 909 loss: 5.63770755e-07
Iter: 910 loss: 5.63519848e-07
Iter: 911 loss: 5.63452204e-07
Iter: 912 loss: 5.63118135e-07
Iter: 913 loss: 5.67719098e-07
Iter: 914 loss: 5.63101253e-07
Iter: 915 loss: 5.627208e-07
Iter: 916 loss: 5.63372851e-07
Iter: 917 loss: 5.6254504e-07
Iter: 918 loss: 5.62241894e-07
Iter: 919 loss: 5.62053287e-07
Iter: 920 loss: 5.61932211e-07
Iter: 921 loss: 5.61735078e-07
Iter: 922 loss: 5.61701427e-07
Iter: 923 loss: 5.61442789e-07
Iter: 924 loss: 5.60878391e-07
Iter: 925 loss: 5.66427104e-07
Iter: 926 loss: 5.60797048e-07
Iter: 927 loss: 5.60675119e-07
Iter: 928 loss: 5.60583601e-07
Iter: 929 loss: 5.60363901e-07
Iter: 930 loss: 5.60250044e-07
Iter: 931 loss: 5.60153524e-07
Iter: 932 loss: 5.59874934e-07
Iter: 933 loss: 5.59675527e-07
Iter: 934 loss: 5.59586681e-07
Iter: 935 loss: 5.59296495e-07
Iter: 936 loss: 5.62017e-07
Iter: 937 loss: 5.59294222e-07
Iter: 938 loss: 5.5889393e-07
Iter: 939 loss: 5.59339355e-07
Iter: 940 loss: 5.58698162e-07
Iter: 941 loss: 5.58283887e-07
Iter: 942 loss: 5.58480963e-07
Iter: 943 loss: 5.58030365e-07
Iter: 944 loss: 5.57670603e-07
Iter: 945 loss: 5.57823967e-07
Iter: 946 loss: 5.57426233e-07
Iter: 947 loss: 5.56862403e-07
Iter: 948 loss: 5.57972385e-07
Iter: 949 loss: 5.5661252e-07
Iter: 950 loss: 5.56350358e-07
Iter: 951 loss: 5.56272198e-07
Iter: 952 loss: 5.56090129e-07
Iter: 953 loss: 5.55685517e-07
Iter: 954 loss: 5.61412776e-07
Iter: 955 loss: 5.55683528e-07
Iter: 956 loss: 5.55288807e-07
Iter: 957 loss: 5.57418957e-07
Iter: 958 loss: 5.55229235e-07
Iter: 959 loss: 5.54930693e-07
Iter: 960 loss: 5.54924668e-07
Iter: 961 loss: 5.5476653e-07
Iter: 962 loss: 5.5429075e-07
Iter: 963 loss: 5.57179419e-07
Iter: 964 loss: 5.54169105e-07
Iter: 965 loss: 5.5412653e-07
Iter: 966 loss: 5.53922177e-07
Iter: 967 loss: 5.53699692e-07
Iter: 968 loss: 5.53335155e-07
Iter: 969 loss: 5.53341e-07
Iter: 970 loss: 5.52883307e-07
Iter: 971 loss: 5.52048505e-07
Iter: 972 loss: 5.71640498e-07
Iter: 973 loss: 5.52028837e-07
Iter: 974 loss: 5.52785309e-07
Iter: 975 loss: 5.51749849e-07
Iter: 976 loss: 5.51527478e-07
Iter: 977 loss: 5.51166522e-07
Iter: 978 loss: 5.51154926e-07
Iter: 979 loss: 5.50778168e-07
Iter: 980 loss: 5.51533333e-07
Iter: 981 loss: 5.50582968e-07
Iter: 982 loss: 5.50242476e-07
Iter: 983 loss: 5.50885943e-07
Iter: 984 loss: 5.50082859e-07
Iter: 985 loss: 5.49804e-07
Iter: 986 loss: 5.49796255e-07
Iter: 987 loss: 5.49569961e-07
Iter: 988 loss: 5.49175e-07
Iter: 989 loss: 5.49192e-07
Iter: 990 loss: 5.48837875e-07
Iter: 991 loss: 5.53026609e-07
Iter: 992 loss: 5.48833896e-07
Iter: 993 loss: 5.48446906e-07
Iter: 994 loss: 5.47935542e-07
Iter: 995 loss: 5.47904961e-07
Iter: 996 loss: 5.47460388e-07
Iter: 997 loss: 5.51574828e-07
Iter: 998 loss: 5.47438503e-07
Iter: 999 loss: 5.47142918e-07
Iter: 1000 loss: 5.5061e-07
Iter: 1001 loss: 5.47129389e-07
Iter: 1002 loss: 5.46977276e-07
Iter: 1003 loss: 5.46513e-07
Iter: 1004 loss: 5.48477374e-07
Iter: 1005 loss: 5.46327442e-07
Iter: 1006 loss: 5.45868829e-07
Iter: 1007 loss: 5.52313338e-07
Iter: 1008 loss: 5.4587457e-07
Iter: 1009 loss: 5.45535045e-07
Iter: 1010 loss: 5.49402102e-07
Iter: 1011 loss: 5.45520322e-07
Iter: 1012 loss: 5.45259581e-07
Iter: 1013 loss: 5.44601392e-07
Iter: 1014 loss: 5.51625817e-07
Iter: 1015 loss: 5.44569389e-07
Iter: 1016 loss: 5.44051943e-07
Iter: 1017 loss: 5.45672435e-07
Iter: 1018 loss: 5.43862e-07
Iter: 1019 loss: 5.43484703e-07
Iter: 1020 loss: 5.43479e-07
Iter: 1021 loss: 5.43160922e-07
Iter: 1022 loss: 5.44456611e-07
Iter: 1023 loss: 5.43090778e-07
Iter: 1024 loss: 5.4290706e-07
Iter: 1025 loss: 5.42662519e-07
Iter: 1026 loss: 5.42636826e-07
Iter: 1027 loss: 5.42319071e-07
Iter: 1028 loss: 5.42331804e-07
Iter: 1029 loss: 5.42123189e-07
Iter: 1030 loss: 5.4181686e-07
Iter: 1031 loss: 5.41800716e-07
Iter: 1032 loss: 5.41436236e-07
Iter: 1033 loss: 5.44728209e-07
Iter: 1034 loss: 5.41428108e-07
Iter: 1035 loss: 5.41044926e-07
Iter: 1036 loss: 5.40770202e-07
Iter: 1037 loss: 5.4063247e-07
Iter: 1038 loss: 5.40272595e-07
Iter: 1039 loss: 5.40741439e-07
Iter: 1040 loss: 5.40094504e-07
Iter: 1041 loss: 5.3978863e-07
Iter: 1042 loss: 5.43922511e-07
Iter: 1043 loss: 5.39776352e-07
Iter: 1044 loss: 5.39418863e-07
Iter: 1045 loss: 5.39437e-07
Iter: 1046 loss: 5.39144708e-07
Iter: 1047 loss: 5.38904544e-07
Iter: 1048 loss: 5.38757376e-07
Iter: 1049 loss: 5.38669497e-07
Iter: 1050 loss: 5.38196787e-07
Iter: 1051 loss: 5.39017094e-07
Iter: 1052 loss: 5.38015456e-07
Iter: 1053 loss: 5.37708161e-07
Iter: 1054 loss: 5.37671497e-07
Iter: 1055 loss: 5.37427923e-07
Iter: 1056 loss: 5.36886319e-07
Iter: 1057 loss: 5.45798684e-07
Iter: 1058 loss: 5.36878304e-07
Iter: 1059 loss: 5.3648057e-07
Iter: 1060 loss: 5.36481934e-07
Iter: 1061 loss: 5.36167704e-07
Iter: 1062 loss: 5.37415303e-07
Iter: 1063 loss: 5.36104096e-07
Iter: 1064 loss: 5.35925778e-07
Iter: 1065 loss: 5.35774575e-07
Iter: 1066 loss: 5.35733705e-07
Iter: 1067 loss: 5.35400545e-07
Iter: 1068 loss: 5.38243171e-07
Iter: 1069 loss: 5.35379627e-07
Iter: 1070 loss: 5.35173342e-07
Iter: 1071 loss: 5.3504607e-07
Iter: 1072 loss: 5.34978426e-07
Iter: 1073 loss: 5.34665219e-07
Iter: 1074 loss: 5.34218429e-07
Iter: 1075 loss: 5.34215872e-07
Iter: 1076 loss: 5.33969512e-07
Iter: 1077 loss: 5.33849231e-07
Iter: 1078 loss: 5.33520165e-07
Iter: 1079 loss: 5.33140224e-07
Iter: 1080 loss: 5.33106231e-07
Iter: 1081 loss: 5.32683543e-07
Iter: 1082 loss: 5.32460547e-07
Iter: 1083 loss: 5.32296951e-07
Iter: 1084 loss: 5.31942533e-07
Iter: 1085 loss: 5.31921216e-07
Iter: 1086 loss: 5.31607725e-07
Iter: 1087 loss: 5.33091224e-07
Iter: 1088 loss: 5.31563728e-07
Iter: 1089 loss: 5.31306796e-07
Iter: 1090 loss: 5.31148203e-07
Iter: 1091 loss: 5.31052251e-07
Iter: 1092 loss: 5.30912587e-07
Iter: 1093 loss: 5.30869158e-07
Iter: 1094 loss: 5.30703232e-07
Iter: 1095 loss: 5.3035933e-07
Iter: 1096 loss: 5.34568414e-07
Iter: 1097 loss: 5.30310558e-07
Iter: 1098 loss: 5.29978649e-07
Iter: 1099 loss: 5.34824608e-07
Iter: 1100 loss: 5.29977228e-07
Iter: 1101 loss: 5.29658337e-07
Iter: 1102 loss: 5.30207e-07
Iter: 1103 loss: 5.29536749e-07
Iter: 1104 loss: 5.29296585e-07
Iter: 1105 loss: 5.29000204e-07
Iter: 1106 loss: 5.28975306e-07
Iter: 1107 loss: 5.2859707e-07
Iter: 1108 loss: 5.30899172e-07
Iter: 1109 loss: 5.2854773e-07
Iter: 1110 loss: 5.28282214e-07
Iter: 1111 loss: 5.3214103e-07
Iter: 1112 loss: 5.28291594e-07
Iter: 1113 loss: 5.28030853e-07
Iter: 1114 loss: 5.27626923e-07
Iter: 1115 loss: 5.27610496e-07
Iter: 1116 loss: 5.27314e-07
Iter: 1117 loss: 5.2806638e-07
Iter: 1118 loss: 5.27210545e-07
Iter: 1119 loss: 5.26940539e-07
Iter: 1120 loss: 5.29374e-07
Iter: 1121 loss: 5.26928716e-07
Iter: 1122 loss: 5.26659051e-07
Iter: 1123 loss: 5.26824e-07
Iter: 1124 loss: 5.26443841e-07
Iter: 1125 loss: 5.26226415e-07
Iter: 1126 loss: 5.2646817e-07
Iter: 1127 loss: 5.26101758e-07
Iter: 1128 loss: 5.25832547e-07
Iter: 1129 loss: 5.28531814e-07
Iter: 1130 loss: 5.25833798e-07
Iter: 1131 loss: 5.25601592e-07
Iter: 1132 loss: 5.25212272e-07
Iter: 1133 loss: 5.25210226e-07
Iter: 1134 loss: 5.2521392e-07
Iter: 1135 loss: 5.25091764e-07
Iter: 1136 loss: 5.24969778e-07
Iter: 1137 loss: 5.24657139e-07
Iter: 1138 loss: 5.27844e-07
Iter: 1139 loss: 5.24645e-07
Iter: 1140 loss: 5.24284189e-07
Iter: 1141 loss: 5.25575956e-07
Iter: 1142 loss: 5.24206939e-07
Iter: 1143 loss: 5.23974e-07
Iter: 1144 loss: 5.2539167e-07
Iter: 1145 loss: 5.23936706e-07
Iter: 1146 loss: 5.23697111e-07
Iter: 1147 loss: 5.24925156e-07
Iter: 1148 loss: 5.23656e-07
Iter: 1149 loss: 5.23419885e-07
Iter: 1150 loss: 5.23010954e-07
Iter: 1151 loss: 5.23019139e-07
Iter: 1152 loss: 5.22721166e-07
Iter: 1153 loss: 5.23031304e-07
Iter: 1154 loss: 5.22520907e-07
Iter: 1155 loss: 5.2228097e-07
Iter: 1156 loss: 5.22277e-07
Iter: 1157 loss: 5.22024834e-07
Iter: 1158 loss: 5.22993616e-07
Iter: 1159 loss: 5.21975096e-07
Iter: 1160 loss: 5.21828611e-07
Iter: 1161 loss: 5.21598736e-07
Iter: 1162 loss: 5.27224245e-07
Iter: 1163 loss: 5.21588e-07
Iter: 1164 loss: 5.21510913e-07
Iter: 1165 loss: 5.21407742e-07
Iter: 1166 loss: 5.21316338e-07
Iter: 1167 loss: 5.21069467e-07
Iter: 1168 loss: 5.23374069e-07
Iter: 1169 loss: 5.21043376e-07
Iter: 1170 loss: 5.20810318e-07
Iter: 1171 loss: 5.23726499e-07
Iter: 1172 loss: 5.2080793e-07
Iter: 1173 loss: 5.20534684e-07
Iter: 1174 loss: 5.20713286e-07
Iter: 1175 loss: 5.20351e-07
Iter: 1176 loss: 5.20165599e-07
Iter: 1177 loss: 5.20018602e-07
Iter: 1178 loss: 5.19964033e-07
Iter: 1179 loss: 5.19726086e-07
Iter: 1180 loss: 5.21328218e-07
Iter: 1181 loss: 5.19699881e-07
Iter: 1182 loss: 5.19545836e-07
Iter: 1183 loss: 5.19531227e-07
Iter: 1184 loss: 5.19432831e-07
Iter: 1185 loss: 5.1919244e-07
Iter: 1186 loss: 5.22054393e-07
Iter: 1187 loss: 5.19153616e-07
Iter: 1188 loss: 5.18898219e-07
Iter: 1189 loss: 5.19901391e-07
Iter: 1190 loss: 5.18841148e-07
Iter: 1191 loss: 5.18626734e-07
Iter: 1192 loss: 5.21286438e-07
Iter: 1193 loss: 5.18613319e-07
Iter: 1194 loss: 5.18445745e-07
Iter: 1195 loss: 5.18152774e-07
Iter: 1196 loss: 5.18140439e-07
Iter: 1197 loss: 5.17841897e-07
Iter: 1198 loss: 5.19655089e-07
Iter: 1199 loss: 5.17801652e-07
Iter: 1200 loss: 5.17559442e-07
Iter: 1201 loss: 5.21030074e-07
Iter: 1202 loss: 5.17563137e-07
Iter: 1203 loss: 5.17477247e-07
Iter: 1204 loss: 5.17291141e-07
Iter: 1205 loss: 5.19394575e-07
Iter: 1206 loss: 5.17266756e-07
Iter: 1207 loss: 5.17093326e-07
Iter: 1208 loss: 5.17097419e-07
Iter: 1209 loss: 5.16938655e-07
Iter: 1210 loss: 5.16813088e-07
Iter: 1211 loss: 5.16777448e-07
Iter: 1212 loss: 5.16590774e-07
Iter: 1213 loss: 5.16226805e-07
Iter: 1214 loss: 5.23677045e-07
Iter: 1215 loss: 5.16221462e-07
Iter: 1216 loss: 5.15958959e-07
Iter: 1217 loss: 5.15945942e-07
Iter: 1218 loss: 5.15673946e-07
Iter: 1219 loss: 5.17574563e-07
Iter: 1220 loss: 5.15646491e-07
Iter: 1221 loss: 5.15472038e-07
Iter: 1222 loss: 5.15199872e-07
Iter: 1223 loss: 5.15203169e-07
Iter: 1224 loss: 5.14998419e-07
Iter: 1225 loss: 5.16270177e-07
Iter: 1226 loss: 5.14957662e-07
Iter: 1227 loss: 5.14772921e-07
Iter: 1228 loss: 5.15348688e-07
Iter: 1229 loss: 5.14704311e-07
Iter: 1230 loss: 5.14520138e-07
Iter: 1231 loss: 5.17131923e-07
Iter: 1232 loss: 5.14522924e-07
Iter: 1233 loss: 5.1444249e-07
Iter: 1234 loss: 5.14229669e-07
Iter: 1235 loss: 5.16399723e-07
Iter: 1236 loss: 5.14181124e-07
Iter: 1237 loss: 5.13998e-07
Iter: 1238 loss: 5.13989448e-07
Iter: 1239 loss: 5.13854502e-07
Iter: 1240 loss: 5.13643158e-07
Iter: 1241 loss: 5.13634518e-07
Iter: 1242 loss: 5.13432099e-07
Iter: 1243 loss: 5.14722046e-07
Iter: 1244 loss: 5.13429768e-07
Iter: 1245 loss: 5.13179884e-07
Iter: 1246 loss: 5.13180282e-07
Iter: 1247 loss: 5.12993267e-07
Iter: 1248 loss: 5.12799147e-07
Iter: 1249 loss: 5.13037094e-07
Iter: 1250 loss: 5.12709448e-07
Iter: 1251 loss: 5.12569613e-07
Iter: 1252 loss: 5.14563453e-07
Iter: 1253 loss: 5.12574559e-07
Iter: 1254 loss: 5.12398287e-07
Iter: 1255 loss: 5.12124302e-07
Iter: 1256 loss: 5.12129475e-07
Iter: 1257 loss: 5.11879307e-07
Iter: 1258 loss: 5.12344798e-07
Iter: 1259 loss: 5.11815301e-07
Iter: 1260 loss: 5.11586506e-07
Iter: 1261 loss: 5.1143536e-07
Iter: 1262 loss: 5.11322582e-07
Iter: 1263 loss: 5.11197811e-07
Iter: 1264 loss: 5.11131702e-07
Iter: 1265 loss: 5.10980044e-07
Iter: 1266 loss: 5.11441101e-07
Iter: 1267 loss: 5.10950883e-07
Iter: 1268 loss: 5.10801556e-07
Iter: 1269 loss: 5.10510233e-07
Iter: 1270 loss: 5.16849127e-07
Iter: 1271 loss: 5.10519953e-07
Iter: 1272 loss: 5.10420534e-07
Iter: 1273 loss: 5.10390464e-07
Iter: 1274 loss: 5.10226528e-07
Iter: 1275 loss: 5.09913662e-07
Iter: 1276 loss: 5.1491179e-07
Iter: 1277 loss: 5.09906044e-07
Iter: 1278 loss: 5.09655536e-07
Iter: 1279 loss: 5.12309839e-07
Iter: 1280 loss: 5.09646839e-07
Iter: 1281 loss: 5.09491e-07
Iter: 1282 loss: 5.11217536e-07
Iter: 1283 loss: 5.09484039e-07
Iter: 1284 loss: 5.09377e-07
Iter: 1285 loss: 5.09142069e-07
Iter: 1286 loss: 5.10814289e-07
Iter: 1287 loss: 5.09087386e-07
Iter: 1288 loss: 5.09029462e-07
Iter: 1289 loss: 5.08939763e-07
Iter: 1290 loss: 5.08804249e-07
Iter: 1291 loss: 5.08668904e-07
Iter: 1292 loss: 5.08674816e-07
Iter: 1293 loss: 5.08434709e-07
Iter: 1294 loss: 5.08083872e-07
Iter: 1295 loss: 5.08086714e-07
Iter: 1296 loss: 5.07716322e-07
Iter: 1297 loss: 5.09336473e-07
Iter: 1298 loss: 5.07633388e-07
Iter: 1299 loss: 5.0745291e-07
Iter: 1300 loss: 5.07418235e-07
Iter: 1301 loss: 5.07224399e-07
Iter: 1302 loss: 5.0728886e-07
Iter: 1303 loss: 5.07099571e-07
Iter: 1304 loss: 5.069287e-07
Iter: 1305 loss: 5.06940751e-07
Iter: 1306 loss: 5.0680319e-07
Iter: 1307 loss: 5.06642152e-07
Iter: 1308 loss: 5.0664903e-07
Iter: 1309 loss: 5.06510389e-07
Iter: 1310 loss: 5.06713718e-07
Iter: 1311 loss: 5.06440188e-07
Iter: 1312 loss: 5.06330821e-07
Iter: 1313 loss: 5.06163417e-07
Iter: 1314 loss: 5.06156e-07
Iter: 1315 loss: 5.05892331e-07
Iter: 1316 loss: 5.07914e-07
Iter: 1317 loss: 5.05861465e-07
Iter: 1318 loss: 5.05700655e-07
Iter: 1319 loss: 5.05562298e-07
Iter: 1320 loss: 5.05507444e-07
Iter: 1321 loss: 5.0531537e-07
Iter: 1322 loss: 5.05300363e-07
Iter: 1323 loss: 5.05129719e-07
Iter: 1324 loss: 5.0473875e-07
Iter: 1325 loss: 5.10635857e-07
Iter: 1326 loss: 5.04702427e-07
Iter: 1327 loss: 5.04471927e-07
Iter: 1328 loss: 5.06232823e-07
Iter: 1329 loss: 5.04449304e-07
Iter: 1330 loss: 5.04265472e-07
Iter: 1331 loss: 5.04085847e-07
Iter: 1332 loss: 5.04060779e-07
Iter: 1333 loss: 5.0403662e-07
Iter: 1334 loss: 5.03908552e-07
Iter: 1335 loss: 5.03815613e-07
Iter: 1336 loss: 5.03733361e-07
Iter: 1337 loss: 5.03704257e-07
Iter: 1338 loss: 5.03561807e-07
Iter: 1339 loss: 5.05178207e-07
Iter: 1340 loss: 5.03570334e-07
Iter: 1341 loss: 5.03380079e-07
Iter: 1342 loss: 5.03576871e-07
Iter: 1343 loss: 5.03289584e-07
Iter: 1344 loss: 5.03088586e-07
Iter: 1345 loss: 5.03462502e-07
Iter: 1346 loss: 5.03014917e-07
Iter: 1347 loss: 5.02872581e-07
Iter: 1348 loss: 5.04987497e-07
Iter: 1349 loss: 5.02875309e-07
Iter: 1350 loss: 5.0272422e-07
Iter: 1351 loss: 5.02548346e-07
Iter: 1352 loss: 5.0252288e-07
Iter: 1353 loss: 5.02315856e-07
Iter: 1354 loss: 5.0308563e-07
Iter: 1355 loss: 5.02249577e-07
Iter: 1356 loss: 5.02001512e-07
Iter: 1357 loss: 5.03685101e-07
Iter: 1358 loss: 5.01964053e-07
Iter: 1359 loss: 5.01848149e-07
Iter: 1360 loss: 5.01582349e-07
Iter: 1361 loss: 5.06023071e-07
Iter: 1362 loss: 5.01578e-07
Iter: 1363 loss: 5.01370891e-07
Iter: 1364 loss: 5.03890192e-07
Iter: 1365 loss: 5.0137777e-07
Iter: 1366 loss: 5.01260956e-07
Iter: 1367 loss: 5.02131456e-07
Iter: 1368 loss: 5.01255613e-07
Iter: 1369 loss: 5.01125442e-07
Iter: 1370 loss: 5.01138118e-07
Iter: 1371 loss: 5.01019713e-07
Iter: 1372 loss: 5.00884823e-07
Iter: 1373 loss: 5.01089687e-07
Iter: 1374 loss: 5.00825763e-07
Iter: 1375 loss: 5.00620274e-07
Iter: 1376 loss: 5.01032957e-07
Iter: 1377 loss: 5.00548595e-07
Iter: 1378 loss: 5.0032537e-07
Iter: 1379 loss: 5.00450483e-07
Iter: 1380 loss: 5.00152169e-07
Iter: 1381 loss: 4.99918087e-07
Iter: 1382 loss: 5.00576448e-07
Iter: 1383 loss: 4.99822e-07
Iter: 1384 loss: 4.99533371e-07
Iter: 1385 loss: 5.01278578e-07
Iter: 1386 loss: 4.99508246e-07
Iter: 1387 loss: 4.99319867e-07
Iter: 1388 loss: 4.9934448e-07
Iter: 1389 loss: 4.99156158e-07
Iter: 1390 loss: 4.99071405e-07
Iter: 1391 loss: 4.99051794e-07
Iter: 1392 loss: 4.98975169e-07
Iter: 1393 loss: 4.98783265e-07
Iter: 1394 loss: 5.00697e-07
Iter: 1395 loss: 4.98753252e-07
Iter: 1396 loss: 4.98572263e-07
Iter: 1397 loss: 4.99521e-07
Iter: 1398 loss: 4.98549241e-07
Iter: 1399 loss: 4.98384793e-07
Iter: 1400 loss: 4.98512918e-07
Iter: 1401 loss: 4.98296231e-07
Iter: 1402 loss: 4.98006784e-07
Iter: 1403 loss: 4.99341922e-07
Iter: 1404 loss: 4.97986548e-07
Iter: 1405 loss: 4.97777364e-07
Iter: 1406 loss: 4.97645942e-07
Iter: 1407 loss: 4.97549195e-07
Iter: 1408 loss: 4.97365136e-07
Iter: 1409 loss: 5.00181898e-07
Iter: 1410 loss: 4.97361839e-07
Iter: 1411 loss: 4.97156634e-07
Iter: 1412 loss: 4.97194833e-07
Iter: 1413 loss: 4.96994062e-07
Iter: 1414 loss: 4.9679528e-07
Iter: 1415 loss: 4.97519864e-07
Iter: 1416 loss: 4.96749522e-07
Iter: 1417 loss: 4.96657776e-07
Iter: 1418 loss: 4.98184818e-07
Iter: 1419 loss: 4.96658572e-07
Iter: 1420 loss: 4.96540054e-07
Iter: 1421 loss: 4.9630745e-07
Iter: 1422 loss: 5.00393867e-07
Iter: 1423 loss: 4.9630421e-07
Iter: 1424 loss: 4.96108555e-07
Iter: 1425 loss: 4.98663212e-07
Iter: 1426 loss: 4.96085704e-07
Iter: 1427 loss: 4.95927e-07
Iter: 1428 loss: 4.96623272e-07
Iter: 1429 loss: 4.95908e-07
Iter: 1430 loss: 4.95789266e-07
Iter: 1431 loss: 4.95516588e-07
Iter: 1432 loss: 4.98179247e-07
Iter: 1433 loss: 4.95487882e-07
Iter: 1434 loss: 4.95313e-07
Iter: 1435 loss: 4.95318659e-07
Iter: 1436 loss: 4.95150687e-07
Iter: 1437 loss: 4.96285054e-07
Iter: 1438 loss: 4.95141819e-07
Iter: 1439 loss: 4.9496964e-07
Iter: 1440 loss: 4.94683832e-07
Iter: 1441 loss: 5.00287229e-07
Iter: 1442 loss: 4.94665244e-07
Iter: 1443 loss: 4.94400751e-07
Iter: 1444 loss: 4.96262771e-07
Iter: 1445 loss: 4.94405526e-07
Iter: 1446 loss: 4.94164965e-07
Iter: 1447 loss: 4.96453936e-07
Iter: 1448 loss: 4.94167466e-07
Iter: 1449 loss: 4.94013193e-07
Iter: 1450 loss: 4.93738355e-07
Iter: 1451 loss: 4.93741254e-07
Iter: 1452 loss: 4.93594257e-07
Iter: 1453 loss: 4.93594484e-07
Iter: 1454 loss: 4.93448852e-07
Iter: 1455 loss: 4.93659627e-07
Iter: 1456 loss: 4.93412188e-07
Iter: 1457 loss: 4.93289917e-07
Iter: 1458 loss: 4.93231369e-07
Iter: 1459 loss: 4.93156733e-07
Iter: 1460 loss: 4.93025823e-07
Iter: 1461 loss: 4.9302821e-07
Iter: 1462 loss: 4.92939762e-07
Iter: 1463 loss: 4.92748e-07
Iter: 1464 loss: 4.95361633e-07
Iter: 1465 loss: 4.92735467e-07
Iter: 1466 loss: 4.9246e-07
Iter: 1467 loss: 4.92614731e-07
Iter: 1468 loss: 4.92289928e-07
Iter: 1469 loss: 4.92219328e-07
Iter: 1470 loss: 4.92144409e-07
Iter: 1471 loss: 4.92000254e-07
Iter: 1472 loss: 4.9180619e-07
Iter: 1473 loss: 4.91797834e-07
Iter: 1474 loss: 4.91544938e-07
Iter: 1475 loss: 4.92132642e-07
Iter: 1476 loss: 4.91472065e-07
Iter: 1477 loss: 4.91389471e-07
Iter: 1478 loss: 4.91405217e-07
Iter: 1479 loss: 4.91280048e-07
Iter: 1480 loss: 4.9106086e-07
Iter: 1481 loss: 4.94911603e-07
Iter: 1482 loss: 4.91060518e-07
Iter: 1483 loss: 4.90887942e-07
Iter: 1484 loss: 4.9225315e-07
Iter: 1485 loss: 4.90881689e-07
Iter: 1486 loss: 4.90774198e-07
Iter: 1487 loss: 4.91747528e-07
Iter: 1488 loss: 4.90731736e-07
Iter: 1489 loss: 4.90626576e-07
Iter: 1490 loss: 4.90405398e-07
Iter: 1491 loss: 4.94946391e-07
Iter: 1492 loss: 4.90403295e-07
Iter: 1493 loss: 4.90235436e-07
Iter: 1494 loss: 4.90232594e-07
Iter: 1495 loss: 4.90096568e-07
Iter: 1496 loss: 4.90152161e-07
Iter: 1497 loss: 4.89999309e-07
Iter: 1498 loss: 4.89841796e-07
Iter: 1499 loss: 4.89544618e-07
Iter: 1500 loss: 4.96168695e-07
Iter: 1501 loss: 4.8953541e-07
Iter: 1502 loss: 4.89345496e-07
Iter: 1503 loss: 4.89330205e-07
Iter: 1504 loss: 4.89127615e-07
Iter: 1505 loss: 4.90348498e-07
Iter: 1506 loss: 4.89102717e-07
Iter: 1507 loss: 4.88953674e-07
Iter: 1508 loss: 4.88708451e-07
Iter: 1509 loss: 4.88713567e-07
Iter: 1510 loss: 4.88542128e-07
Iter: 1511 loss: 4.88538831e-07
Iter: 1512 loss: 4.88382966e-07
Iter: 1513 loss: 4.89009835e-07
Iter: 1514 loss: 4.88366368e-07
Iter: 1515 loss: 4.88250294e-07
Iter: 1516 loss: 4.88071805e-07
Iter: 1517 loss: 4.88079536e-07
Iter: 1518 loss: 4.88004559e-07
Iter: 1519 loss: 4.87959483e-07
Iter: 1520 loss: 4.87875525e-07
Iter: 1521 loss: 4.87722104e-07
Iter: 1522 loss: 4.8772074e-07
Iter: 1523 loss: 4.87511784e-07
Iter: 1524 loss: 4.88114438e-07
Iter: 1525 loss: 4.87418731e-07
Iter: 1526 loss: 4.87162481e-07
Iter: 1527 loss: 4.88655e-07
Iter: 1528 loss: 4.87121383e-07
Iter: 1529 loss: 4.87006901e-07
Iter: 1530 loss: 4.86831254e-07
Iter: 1531 loss: 4.86813747e-07
Iter: 1532 loss: 4.86535214e-07
Iter: 1533 loss: 4.86700628e-07
Iter: 1534 loss: 4.86359909e-07
Iter: 1535 loss: 4.86416639e-07
Iter: 1536 loss: 4.86252702e-07
Iter: 1537 loss: 4.86158e-07
Iter: 1538 loss: 4.85985368e-07
Iter: 1539 loss: 4.87893487e-07
Iter: 1540 loss: 4.85967803e-07
Iter: 1541 loss: 4.85764872e-07
Iter: 1542 loss: 4.864321e-07
Iter: 1543 loss: 4.85678527e-07
Iter: 1544 loss: 4.85620888e-07
Iter: 1545 loss: 4.85577175e-07
Iter: 1546 loss: 4.8550163e-07
Iter: 1547 loss: 4.85298585e-07
Iter: 1548 loss: 4.86631279e-07
Iter: 1549 loss: 4.85228554e-07
Iter: 1550 loss: 4.85040403e-07
Iter: 1551 loss: 4.85039777e-07
Iter: 1552 loss: 4.84834914e-07
Iter: 1553 loss: 4.85448709e-07
Iter: 1554 loss: 4.84796715e-07
Iter: 1555 loss: 4.84631869e-07
Iter: 1556 loss: 4.84514203e-07
Iter: 1557 loss: 4.84475436e-07
Iter: 1558 loss: 4.8419281e-07
Iter: 1559 loss: 4.8686536e-07
Iter: 1560 loss: 4.84208215e-07
Iter: 1561 loss: 4.84036605e-07
Iter: 1562 loss: 4.84017903e-07
Iter: 1563 loss: 4.83908707e-07
Iter: 1564 loss: 4.83728172e-07
Iter: 1565 loss: 4.83590838e-07
Iter: 1566 loss: 4.83537178e-07
Iter: 1567 loss: 4.83343456e-07
Iter: 1568 loss: 4.83342603e-07
Iter: 1569 loss: 4.83180713e-07
Iter: 1570 loss: 4.83674853e-07
Iter: 1571 loss: 4.83136319e-07
Iter: 1572 loss: 4.83019789e-07
Iter: 1573 loss: 4.82815835e-07
Iter: 1574 loss: 4.85243049e-07
Iter: 1575 loss: 4.82785367e-07
Iter: 1576 loss: 4.82738074e-07
Iter: 1577 loss: 4.82653e-07
Iter: 1578 loss: 4.82523944e-07
Iter: 1579 loss: 4.82442033e-07
Iter: 1580 loss: 4.82413157e-07
Iter: 1581 loss: 4.82227733e-07
Iter: 1582 loss: 4.82005419e-07
Iter: 1583 loss: 4.81964207e-07
Iter: 1584 loss: 4.81731831e-07
Iter: 1585 loss: 4.81717564e-07
Iter: 1586 loss: 4.81586881e-07
Iter: 1587 loss: 4.81458471e-07
Iter: 1588 loss: 4.81427833e-07
Iter: 1589 loss: 4.81223367e-07
Iter: 1590 loss: 4.83200836e-07
Iter: 1591 loss: 4.81218308e-07
Iter: 1592 loss: 4.81071879e-07
Iter: 1593 loss: 4.81033908e-07
Iter: 1594 loss: 4.80922665e-07
Iter: 1595 loss: 4.80763674e-07
Iter: 1596 loss: 4.8087503e-07
Iter: 1597 loss: 4.80653455e-07
Iter: 1598 loss: 4.80427616e-07
Iter: 1599 loss: 4.8078914e-07
Iter: 1600 loss: 4.80319272e-07
Iter: 1601 loss: 4.80255324e-07
Iter: 1602 loss: 4.80205756e-07
Iter: 1603 loss: 4.8012464e-07
Iter: 1604 loss: 4.7981564e-07
Iter: 1605 loss: 4.81774691e-07
Iter: 1606 loss: 4.79720313e-07
Iter: 1607 loss: 4.79372204e-07
Iter: 1608 loss: 4.81136681e-07
Iter: 1609 loss: 4.79279151e-07
Iter: 1610 loss: 4.7909e-07
Iter: 1611 loss: 4.79053142e-07
Iter: 1612 loss: 4.78959691e-07
Iter: 1613 loss: 4.78697189e-07
Iter: 1614 loss: 4.80739686e-07
Iter: 1615 loss: 4.78655352e-07
Iter: 1616 loss: 4.78589641e-07
Iter: 1617 loss: 4.78513812e-07
Iter: 1618 loss: 4.78412289e-07
Iter: 1619 loss: 4.78475613e-07
Iter: 1620 loss: 4.78350898e-07
Iter: 1621 loss: 4.78244658e-07
Iter: 1622 loss: 4.7826552e-07
Iter: 1623 loss: 4.7815962e-07
Iter: 1624 loss: 4.77956064e-07
Iter: 1625 loss: 4.78610559e-07
Iter: 1626 loss: 4.77907065e-07
Iter: 1627 loss: 4.77768651e-07
Iter: 1628 loss: 4.77556057e-07
Iter: 1629 loss: 4.77557478e-07
Iter: 1630 loss: 4.77219e-07
Iter: 1631 loss: 4.77206e-07
Iter: 1632 loss: 4.7692771e-07
Iter: 1633 loss: 4.76674984e-07
Iter: 1634 loss: 4.76646449e-07
Iter: 1635 loss: 4.76439368e-07
Iter: 1636 loss: 4.77516096e-07
Iter: 1637 loss: 4.76406797e-07
Iter: 1638 loss: 4.76248772e-07
Iter: 1639 loss: 4.75976719e-07
Iter: 1640 loss: 4.81653274e-07
Iter: 1641 loss: 4.75979476e-07
Iter: 1642 loss: 4.7578439e-07
Iter: 1643 loss: 4.75790642e-07
Iter: 1644 loss: 4.75582368e-07
Iter: 1645 loss: 4.76480551e-07
Iter: 1646 loss: 4.75558153e-07
Iter: 1647 loss: 4.7543665e-07
Iter: 1648 loss: 4.7518472e-07
Iter: 1649 loss: 4.79953655e-07
Iter: 1650 loss: 4.75173238e-07
Iter: 1651 loss: 4.75139132e-07
Iter: 1652 loss: 4.75042555e-07
Iter: 1653 loss: 4.74939554e-07
Iter: 1654 loss: 4.74679553e-07
Iter: 1655 loss: 4.77468689e-07
Iter: 1656 loss: 4.74645589e-07
Iter: 1657 loss: 4.74478668e-07
Iter: 1658 loss: 4.74467271e-07
Iter: 1659 loss: 4.74307399e-07
Iter: 1660 loss: 4.74251976e-07
Iter: 1661 loss: 4.7416907e-07
Iter: 1662 loss: 4.73985665e-07
Iter: 1663 loss: 4.73655803e-07
Iter: 1664 loss: 4.73647901e-07
Iter: 1665 loss: 4.73353168e-07
Iter: 1666 loss: 4.77303729e-07
Iter: 1667 loss: 4.73343619e-07
Iter: 1668 loss: 4.73126875e-07
Iter: 1669 loss: 4.75306678e-07
Iter: 1670 loss: 4.73131536e-07
Iter: 1671 loss: 4.72916042e-07
Iter: 1672 loss: 4.72920874e-07
Iter: 1673 loss: 4.72759439e-07
Iter: 1674 loss: 4.72607553e-07
Iter: 1675 loss: 4.72863519e-07
Iter: 1676 loss: 4.72529905e-07
Iter: 1677 loss: 4.72340503e-07
Iter: 1678 loss: 4.73076568e-07
Iter: 1679 loss: 4.72302418e-07
Iter: 1680 loss: 4.72079876e-07
Iter: 1681 loss: 4.72546731e-07
Iter: 1682 loss: 4.7199012e-07
Iter: 1683 loss: 4.71767549e-07
Iter: 1684 loss: 4.71668898e-07
Iter: 1685 loss: 4.71557854e-07
Iter: 1686 loss: 4.71304276e-07
Iter: 1687 loss: 4.72138225e-07
Iter: 1688 loss: 4.7121847e-07
Iter: 1689 loss: 4.70889887e-07
Iter: 1690 loss: 4.72858773e-07
Iter: 1691 loss: 4.70855809e-07
Iter: 1692 loss: 4.70662343e-07
Iter: 1693 loss: 4.70405553e-07
Iter: 1694 loss: 4.70413255e-07
Iter: 1695 loss: 4.70233402e-07
Iter: 1696 loss: 4.70231981e-07
Iter: 1697 loss: 4.70048633e-07
Iter: 1698 loss: 4.69869775e-07
Iter: 1699 loss: 4.69847976e-07
Iter: 1700 loss: 4.69680373e-07
Iter: 1701 loss: 4.69721101e-07
Iter: 1702 loss: 4.69569784e-07
Iter: 1703 loss: 4.69384531e-07
Iter: 1704 loss: 4.70741099e-07
Iter: 1705 loss: 4.69371798e-07
Iter: 1706 loss: 4.69193793e-07
Iter: 1707 loss: 4.70953e-07
Iter: 1708 loss: 4.69178758e-07
Iter: 1709 loss: 4.69093663e-07
Iter: 1710 loss: 4.68847304e-07
Iter: 1711 loss: 4.70382389e-07
Iter: 1712 loss: 4.68780598e-07
Iter: 1713 loss: 4.68663444e-07
Iter: 1714 loss: 4.68630674e-07
Iter: 1715 loss: 4.68488736e-07
Iter: 1716 loss: 4.68703064e-07
Iter: 1717 loss: 4.68415578e-07
Iter: 1718 loss: 4.68293308e-07
Iter: 1719 loss: 4.6803666e-07
Iter: 1720 loss: 4.68043226e-07
Iter: 1721 loss: 4.67830631e-07
Iter: 1722 loss: 4.67843165e-07
Iter: 1723 loss: 4.6765939e-07
Iter: 1724 loss: 4.68475093e-07
Iter: 1725 loss: 4.67621419e-07
Iter: 1726 loss: 4.67506254e-07
Iter: 1727 loss: 4.67230649e-07
Iter: 1728 loss: 4.71201787e-07
Iter: 1729 loss: 4.6719606e-07
Iter: 1730 loss: 4.67073107e-07
Iter: 1731 loss: 4.67061426e-07
Iter: 1732 loss: 4.66938502e-07
Iter: 1733 loss: 4.67682696e-07
Iter: 1734 loss: 4.66909597e-07
Iter: 1735 loss: 4.66850196e-07
Iter: 1736 loss: 4.6666284e-07
Iter: 1737 loss: 4.6752325e-07
Iter: 1738 loss: 4.66597555e-07
Iter: 1739 loss: 4.66399712e-07
Iter: 1740 loss: 4.69088803e-07
Iter: 1741 loss: 4.66388485e-07
Iter: 1742 loss: 4.66232962e-07
Iter: 1743 loss: 4.68481716e-07
Iter: 1744 loss: 4.66220257e-07
Iter: 1745 loss: 4.66108759e-07
Iter: 1746 loss: 4.65801264e-07
Iter: 1747 loss: 4.6762375e-07
Iter: 1748 loss: 4.65707643e-07
Iter: 1749 loss: 4.65460431e-07
Iter: 1750 loss: 4.6545415e-07
Iter: 1751 loss: 4.6519466e-07
Iter: 1752 loss: 4.66062062e-07
Iter: 1753 loss: 4.65127101e-07
Iter: 1754 loss: 4.64997356e-07
Iter: 1755 loss: 4.64878298e-07
Iter: 1756 loss: 4.64846863e-07
Iter: 1757 loss: 4.64730874e-07
Iter: 1758 loss: 4.66317118e-07
Iter: 1759 loss: 4.64732153e-07
Iter: 1760 loss: 4.645959e-07
Iter: 1761 loss: 4.64599111e-07
Iter: 1762 loss: 4.64481843e-07
Iter: 1763 loss: 4.64362415e-07
Iter: 1764 loss: 4.64357299e-07
Iter: 1765 loss: 4.64250263e-07
Iter: 1766 loss: 4.64097951e-07
Iter: 1767 loss: 4.66095656e-07
Iter: 1768 loss: 4.64102e-07
Iter: 1769 loss: 4.63945696e-07
Iter: 1770 loss: 4.63917672e-07
Iter: 1771 loss: 4.63808021e-07
Iter: 1772 loss: 4.63599065e-07
Iter: 1773 loss: 4.63574764e-07
Iter: 1774 loss: 4.6343041e-07
Iter: 1775 loss: 4.63152361e-07
Iter: 1776 loss: 4.63176548e-07
Iter: 1777 loss: 4.62947753e-07
Iter: 1778 loss: 4.63079203e-07
Iter: 1779 loss: 4.62837193e-07
Iter: 1780 loss: 4.62757271e-07
Iter: 1781 loss: 4.62613286e-07
Iter: 1782 loss: 4.62628634e-07
Iter: 1783 loss: 4.62449862e-07
Iter: 1784 loss: 4.62700143e-07
Iter: 1785 loss: 4.62372839e-07
Iter: 1786 loss: 4.62222602e-07
Iter: 1787 loss: 4.64735194e-07
Iter: 1788 loss: 4.62215837e-07
Iter: 1789 loss: 4.62158539e-07
Iter: 1790 loss: 4.6198673e-07
Iter: 1791 loss: 4.62954176e-07
Iter: 1792 loss: 4.61944694e-07
Iter: 1793 loss: 4.61730536e-07
Iter: 1794 loss: 4.64200809e-07
Iter: 1795 loss: 4.61716695e-07
Iter: 1796 loss: 4.6155742e-07
Iter: 1797 loss: 4.63016022e-07
Iter: 1798 loss: 4.61544175e-07
Iter: 1799 loss: 4.61471529e-07
Iter: 1800 loss: 4.61228e-07
Iter: 1801 loss: 4.61982324e-07
Iter: 1802 loss: 4.61112421e-07
Iter: 1803 loss: 4.60838407e-07
Iter: 1804 loss: 4.64205073e-07
Iter: 1805 loss: 4.60845172e-07
Iter: 1806 loss: 4.60722191e-07
Iter: 1807 loss: 4.60708577e-07
Iter: 1808 loss: 4.60597789e-07
Iter: 1809 loss: 4.6037826e-07
Iter: 1810 loss: 4.64181312e-07
Iter: 1811 loss: 4.60371325e-07
Iter: 1812 loss: 4.60210373e-07
Iter: 1813 loss: 4.60718439e-07
Iter: 1814 loss: 4.60179706e-07
Iter: 1815 loss: 4.60075483e-07
Iter: 1816 loss: 4.6006511e-07
Iter: 1817 loss: 4.59966031e-07
Iter: 1818 loss: 4.59839356e-07
Iter: 1819 loss: 4.59822019e-07
Iter: 1820 loss: 4.59710208e-07
Iter: 1821 loss: 4.60435018e-07
Iter: 1822 loss: 4.59700289e-07
Iter: 1823 loss: 4.59559431e-07
Iter: 1824 loss: 4.5957745e-07
Iter: 1825 loss: 4.59431078e-07
Iter: 1826 loss: 4.59288515e-07
Iter: 1827 loss: 4.59067252e-07
Iter: 1828 loss: 4.5906981e-07
Iter: 1829 loss: 4.58855766e-07
Iter: 1830 loss: 4.58849456e-07
Iter: 1831 loss: 4.58670513e-07
Iter: 1832 loss: 4.59859905e-07
Iter: 1833 loss: 4.58644024e-07
Iter: 1834 loss: 4.58574334e-07
Iter: 1835 loss: 4.58417389e-07
Iter: 1836 loss: 4.61583113e-07
Iter: 1837 loss: 4.58422591e-07
Iter: 1838 loss: 4.58224378e-07
Iter: 1839 loss: 4.5834372e-07
Iter: 1840 loss: 4.58107593e-07
Iter: 1841 loss: 4.58039608e-07
Iter: 1842 loss: 4.58001466e-07
Iter: 1843 loss: 4.57905372e-07
Iter: 1844 loss: 4.58084315e-07
Iter: 1845 loss: 4.57871124e-07
Iter: 1846 loss: 4.57749536e-07
Iter: 1847 loss: 4.57577926e-07
Iter: 1848 loss: 4.57573833e-07
Iter: 1849 loss: 4.57382214e-07
Iter: 1850 loss: 4.58698224e-07
Iter: 1851 loss: 4.57349273e-07
Iter: 1852 loss: 4.57194574e-07
Iter: 1853 loss: 4.58509021e-07
Iter: 1854 loss: 4.57183461e-07
Iter: 1855 loss: 4.57087964e-07
Iter: 1856 loss: 4.56839018e-07
Iter: 1857 loss: 4.61469568e-07
Iter: 1858 loss: 4.56844475e-07
Iter: 1859 loss: 4.56823045e-07
Iter: 1860 loss: 4.56741304e-07
Iter: 1861 loss: 4.56640805e-07
Iter: 1862 loss: 4.56457258e-07
Iter: 1863 loss: 4.58360546e-07
Iter: 1864 loss: 4.56425767e-07
Iter: 1865 loss: 4.56271977e-07
Iter: 1866 loss: 4.56286472e-07
Iter: 1867 loss: 4.56157323e-07
Iter: 1868 loss: 4.57163907e-07
Iter: 1869 loss: 4.56173382e-07
Iter: 1870 loss: 4.56098661e-07
Iter: 1871 loss: 4.55980739e-07
Iter: 1872 loss: 4.56980558e-07
Iter: 1873 loss: 4.55949674e-07
Iter: 1874 loss: 4.5575004e-07
Iter: 1875 loss: 4.56313529e-07
Iter: 1876 loss: 4.55701667e-07
Iter: 1877 loss: 4.55568056e-07
Iter: 1878 loss: 4.55565953e-07
Iter: 1879 loss: 4.55414067e-07
Iter: 1880 loss: 4.55250813e-07
Iter: 1881 loss: 4.5523575e-07
Iter: 1882 loss: 4.55026168e-07
Iter: 1883 loss: 4.55632147e-07
Iter: 1884 loss: 4.54965743e-07
Iter: 1885 loss: 4.54815677e-07
Iter: 1886 loss: 4.56240741e-07
Iter: 1887 loss: 4.54802688e-07
Iter: 1888 loss: 4.54662768e-07
Iter: 1889 loss: 4.54827841e-07
Iter: 1890 loss: 4.54571023e-07
Iter: 1891 loss: 4.54499286e-07
Iter: 1892 loss: 4.54782935e-07
Iter: 1893 loss: 4.54455261e-07
Iter: 1894 loss: 4.54373492e-07
Iter: 1895 loss: 4.54835202e-07
Iter: 1896 loss: 4.54369456e-07
Iter: 1897 loss: 4.54303176e-07
Iter: 1898 loss: 4.54175023e-07
Iter: 1899 loss: 4.56929342e-07
Iter: 1900 loss: 4.54170333e-07
Iter: 1901 loss: 4.54088706e-07
Iter: 1902 loss: 4.54094e-07
Iter: 1903 loss: 4.54016e-07
Iter: 1904 loss: 4.53851385e-07
Iter: 1905 loss: 4.57070456e-07
Iter: 1906 loss: 4.53849054e-07
Iter: 1907 loss: 4.53670737e-07
Iter: 1908 loss: 4.53649534e-07
Iter: 1909 loss: 4.53529452e-07
Iter: 1910 loss: 4.53366596e-07
Iter: 1911 loss: 4.55113423e-07
Iter: 1912 loss: 4.53363668e-07
Iter: 1913 loss: 4.53195412e-07
Iter: 1914 loss: 4.53565178e-07
Iter: 1915 loss: 4.53127768e-07
Iter: 1916 loss: 4.530051e-07
Iter: 1917 loss: 4.53080247e-07
Iter: 1918 loss: 4.52919551e-07
Iter: 1919 loss: 4.52829198e-07
Iter: 1920 loss: 4.53235145e-07
Iter: 1921 loss: 4.5278756e-07
Iter: 1922 loss: 4.52672651e-07
Iter: 1923 loss: 4.53758446e-07
Iter: 1924 loss: 4.52662732e-07
Iter: 1925 loss: 4.52602194e-07
Iter: 1926 loss: 4.52486319e-07
Iter: 1927 loss: 4.52489815e-07
Iter: 1928 loss: 4.52377122e-07
Iter: 1929 loss: 4.53827766e-07
Iter: 1930 loss: 4.52375502e-07
Iter: 1931 loss: 4.52239789e-07
Iter: 1932 loss: 4.52158446e-07
Iter: 1933 loss: 4.52093929e-07
Iter: 1934 loss: 4.51989166e-07
Iter: 1935 loss: 4.52204802e-07
Iter: 1936 loss: 4.51942185e-07
Iter: 1937 loss: 4.51775975e-07
Iter: 1938 loss: 4.52658924e-07
Iter: 1939 loss: 4.51756705e-07
Iter: 1940 loss: 4.51640574e-07
Iter: 1941 loss: 4.51490507e-07
Iter: 1942 loss: 4.51491445e-07
Iter: 1943 loss: 4.51365253e-07
Iter: 1944 loss: 4.52157792e-07
Iter: 1945 loss: 4.51342373e-07
Iter: 1946 loss: 4.51202311e-07
Iter: 1947 loss: 4.52343e-07
Iter: 1948 loss: 4.51195774e-07
Iter: 1949 loss: 4.51111674e-07
Iter: 1950 loss: 4.51000972e-07
Iter: 1951 loss: 4.50995913e-07
Iter: 1952 loss: 4.50864718e-07
Iter: 1953 loss: 4.50964336e-07
Iter: 1954 loss: 4.50794033e-07
Iter: 1955 loss: 4.50662014e-07
Iter: 1956 loss: 4.50664714e-07
Iter: 1957 loss: 4.50573395e-07
Iter: 1958 loss: 4.50462665e-07
Iter: 1959 loss: 4.50438705e-07
Iter: 1960 loss: 4.50295971e-07
Iter: 1961 loss: 4.50722496e-07
Iter: 1962 loss: 4.50259847e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8
+ date
Mon Oct 26 17:24:24 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi0.8_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f16881e1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1688221a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1688221d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f16882e7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f16881af9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f16881b0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1688175e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f168813d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f16880fe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f16880feae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f168809f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f168809ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f168809eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1688042378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1688004950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687fbfc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687fee620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687fef400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687fb7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687fb7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687f57950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687f43d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687ec8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687f579d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687e7d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687e7d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687e508c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687e506a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687e1a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687e242f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687df1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687daa8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687db41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687d3e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687d659d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1687d31378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.11826612e-06
Iter: 2 loss: 6.73709474e-06
Iter: 3 loss: 2.72729576e-05
Iter: 4 loss: 6.73589602e-06
Iter: 5 loss: 6.12562189e-06
Iter: 6 loss: 6.77925527e-06
Iter: 7 loss: 5.79031166e-06
Iter: 8 loss: 5.46214687e-06
Iter: 9 loss: 5.794559e-06
Iter: 10 loss: 5.27844e-06
Iter: 11 loss: 4.86932731e-06
Iter: 12 loss: 8.83479879e-06
Iter: 13 loss: 4.85453e-06
Iter: 14 loss: 4.67033624e-06
Iter: 15 loss: 4.59741614e-06
Iter: 16 loss: 4.49855725e-06
Iter: 17 loss: 4.31502212e-06
Iter: 18 loss: 4.93632706e-06
Iter: 19 loss: 4.26546831e-06
Iter: 20 loss: 4.04425282e-06
Iter: 21 loss: 5.56879422e-06
Iter: 22 loss: 4.02317801e-06
Iter: 23 loss: 3.86961528e-06
Iter: 24 loss: 3.7655368e-06
Iter: 25 loss: 3.70883e-06
Iter: 26 loss: 3.50994333e-06
Iter: 27 loss: 5.79184461e-06
Iter: 28 loss: 3.50663777e-06
Iter: 29 loss: 3.35687764e-06
Iter: 30 loss: 3.4710115e-06
Iter: 31 loss: 3.26588747e-06
Iter: 32 loss: 3.15679858e-06
Iter: 33 loss: 3.08911149e-06
Iter: 34 loss: 3.04518562e-06
Iter: 35 loss: 2.90687763e-06
Iter: 36 loss: 3.61281377e-06
Iter: 37 loss: 2.88443516e-06
Iter: 38 loss: 2.76394962e-06
Iter: 39 loss: 3.15969578e-06
Iter: 40 loss: 2.7304352e-06
Iter: 41 loss: 2.6690609e-06
Iter: 42 loss: 2.65897688e-06
Iter: 43 loss: 2.60895422e-06
Iter: 44 loss: 2.5125164e-06
Iter: 45 loss: 4.51348387e-06
Iter: 46 loss: 2.51197162e-06
Iter: 47 loss: 2.4732276e-06
Iter: 48 loss: 2.46885702e-06
Iter: 49 loss: 2.42033252e-06
Iter: 50 loss: 2.32989714e-06
Iter: 51 loss: 4.36533082e-06
Iter: 52 loss: 2.32967318e-06
Iter: 53 loss: 2.24598625e-06
Iter: 54 loss: 2.70475334e-06
Iter: 55 loss: 2.23380221e-06
Iter: 56 loss: 2.18293371e-06
Iter: 57 loss: 2.18240257e-06
Iter: 58 loss: 2.15118689e-06
Iter: 59 loss: 2.08550819e-06
Iter: 60 loss: 3.18087677e-06
Iter: 61 loss: 2.08375377e-06
Iter: 62 loss: 2.02947967e-06
Iter: 63 loss: 2.02878709e-06
Iter: 64 loss: 1.98839962e-06
Iter: 65 loss: 1.97219128e-06
Iter: 66 loss: 1.95072039e-06
Iter: 67 loss: 1.90460923e-06
Iter: 68 loss: 1.87118769e-06
Iter: 69 loss: 1.85533554e-06
Iter: 70 loss: 1.78561913e-06
Iter: 71 loss: 2.43049635e-06
Iter: 72 loss: 1.7825804e-06
Iter: 73 loss: 1.74508102e-06
Iter: 74 loss: 1.73188289e-06
Iter: 75 loss: 1.71071167e-06
Iter: 76 loss: 1.71267311e-06
Iter: 77 loss: 1.68690906e-06
Iter: 78 loss: 1.67114536e-06
Iter: 79 loss: 1.64681683e-06
Iter: 80 loss: 1.64643689e-06
Iter: 81 loss: 1.62280696e-06
Iter: 82 loss: 1.75872981e-06
Iter: 83 loss: 1.61958064e-06
Iter: 84 loss: 1.59196929e-06
Iter: 85 loss: 1.66369432e-06
Iter: 86 loss: 1.58249634e-06
Iter: 87 loss: 1.56230203e-06
Iter: 88 loss: 1.55311295e-06
Iter: 89 loss: 1.54297857e-06
Iter: 90 loss: 1.5303325e-06
Iter: 91 loss: 1.52812186e-06
Iter: 92 loss: 1.51324639e-06
Iter: 93 loss: 1.47767514e-06
Iter: 94 loss: 1.8729055e-06
Iter: 95 loss: 1.4741729e-06
Iter: 96 loss: 1.46002446e-06
Iter: 97 loss: 1.45589422e-06
Iter: 98 loss: 1.44100977e-06
Iter: 99 loss: 1.42934641e-06
Iter: 100 loss: 1.4246873e-06
Iter: 101 loss: 1.40536736e-06
Iter: 102 loss: 1.3784238e-06
Iter: 103 loss: 1.37728057e-06
Iter: 104 loss: 1.33817116e-06
Iter: 105 loss: 1.6584836e-06
Iter: 106 loss: 1.33578669e-06
Iter: 107 loss: 1.30604553e-06
Iter: 108 loss: 1.31801698e-06
Iter: 109 loss: 1.28553097e-06
Iter: 110 loss: 1.29195882e-06
Iter: 111 loss: 1.27185183e-06
Iter: 112 loss: 1.26377586e-06
Iter: 113 loss: 1.24418e-06
Iter: 114 loss: 1.45295189e-06
Iter: 115 loss: 1.2420121e-06
Iter: 116 loss: 1.22759025e-06
Iter: 117 loss: 1.22738629e-06
Iter: 118 loss: 1.21604899e-06
Iter: 119 loss: 1.25910549e-06
Iter: 120 loss: 1.21335097e-06
Iter: 121 loss: 1.20687889e-06
Iter: 122 loss: 1.19643551e-06
Iter: 123 loss: 1.19631818e-06
Iter: 124 loss: 1.18633648e-06
Iter: 125 loss: 1.18601031e-06
Iter: 126 loss: 1.17794013e-06
Iter: 127 loss: 1.16136823e-06
Iter: 128 loss: 1.45052809e-06
Iter: 129 loss: 1.16109379e-06
Iter: 130 loss: 1.15147702e-06
Iter: 131 loss: 1.15098067e-06
Iter: 132 loss: 1.14113323e-06
Iter: 133 loss: 1.12613259e-06
Iter: 134 loss: 1.12587645e-06
Iter: 135 loss: 1.11183908e-06
Iter: 136 loss: 1.15629746e-06
Iter: 137 loss: 1.10773362e-06
Iter: 138 loss: 1.09690745e-06
Iter: 139 loss: 1.11941927e-06
Iter: 140 loss: 1.09254074e-06
Iter: 141 loss: 1.08136646e-06
Iter: 142 loss: 1.12980717e-06
Iter: 143 loss: 1.07906681e-06
Iter: 144 loss: 1.0748563e-06
Iter: 145 loss: 1.07386086e-06
Iter: 146 loss: 1.06956008e-06
Iter: 147 loss: 1.06250036e-06
Iter: 148 loss: 1.06246603e-06
Iter: 149 loss: 1.05202957e-06
Iter: 150 loss: 1.06106916e-06
Iter: 151 loss: 1.04592141e-06
Iter: 152 loss: 1.03791376e-06
Iter: 153 loss: 1.03748e-06
Iter: 154 loss: 1.03294019e-06
Iter: 155 loss: 1.02047989e-06
Iter: 156 loss: 1.09322036e-06
Iter: 157 loss: 1.01695377e-06
Iter: 158 loss: 1.0144845e-06
Iter: 159 loss: 1.00959755e-06
Iter: 160 loss: 1.00372199e-06
Iter: 161 loss: 1.00271041e-06
Iter: 162 loss: 9.98743189e-07
Iter: 163 loss: 9.93029744e-07
Iter: 164 loss: 9.97629058e-07
Iter: 165 loss: 9.8958219e-07
Iter: 166 loss: 9.82304755e-07
Iter: 167 loss: 1.05867105e-06
Iter: 168 loss: 9.82118763e-07
Iter: 169 loss: 9.781063e-07
Iter: 170 loss: 9.70782366e-07
Iter: 171 loss: 1.14742875e-06
Iter: 172 loss: 9.70797487e-07
Iter: 173 loss: 9.61147634e-07
Iter: 174 loss: 9.53248332e-07
Iter: 175 loss: 9.50448282e-07
Iter: 176 loss: 9.38197843e-07
Iter: 177 loss: 1.09925895e-06
Iter: 178 loss: 9.38133496e-07
Iter: 179 loss: 9.317273e-07
Iter: 180 loss: 9.31543468e-07
Iter: 181 loss: 9.2642415e-07
Iter: 182 loss: 9.23384846e-07
Iter: 183 loss: 9.21292838e-07
Iter: 184 loss: 9.15585588e-07
Iter: 185 loss: 9.40024165e-07
Iter: 186 loss: 9.14411885e-07
Iter: 187 loss: 9.10408062e-07
Iter: 188 loss: 9.69929147e-07
Iter: 189 loss: 9.10414542e-07
Iter: 190 loss: 9.08252105e-07
Iter: 191 loss: 9.03229875e-07
Iter: 192 loss: 9.66019115e-07
Iter: 193 loss: 9.02887678e-07
Iter: 194 loss: 8.97501536e-07
Iter: 195 loss: 9.7264342e-07
Iter: 196 loss: 8.97490509e-07
Iter: 197 loss: 8.92667288e-07
Iter: 198 loss: 9.02616591e-07
Iter: 199 loss: 8.90765591e-07
Iter: 200 loss: 8.87379088e-07
Iter: 201 loss: 8.82782103e-07
Iter: 202 loss: 8.82530458e-07
Iter: 203 loss: 8.78557671e-07
Iter: 204 loss: 8.78140895e-07
Iter: 205 loss: 8.75678779e-07
Iter: 206 loss: 8.69485916e-07
Iter: 207 loss: 9.26343034e-07
Iter: 208 loss: 8.68517532e-07
Iter: 209 loss: 8.62651063e-07
Iter: 210 loss: 9.02100624e-07
Iter: 211 loss: 8.62072625e-07
Iter: 212 loss: 8.56898453e-07
Iter: 213 loss: 8.60017053e-07
Iter: 214 loss: 8.53584652e-07
Iter: 215 loss: 8.49634148e-07
Iter: 216 loss: 8.49157e-07
Iter: 217 loss: 8.45515274e-07
Iter: 218 loss: 8.4444855e-07
Iter: 219 loss: 8.42210341e-07
Iter: 220 loss: 8.38751816e-07
Iter: 221 loss: 8.38490337e-07
Iter: 222 loss: 8.35917092e-07
Iter: 223 loss: 8.3089418e-07
Iter: 224 loss: 9.03983619e-07
Iter: 225 loss: 8.30898557e-07
Iter: 226 loss: 8.28750444e-07
Iter: 227 loss: 8.2763853e-07
Iter: 228 loss: 8.26626e-07
Iter: 229 loss: 8.2357252e-07
Iter: 230 loss: 8.33619481e-07
Iter: 231 loss: 8.22709922e-07
Iter: 232 loss: 8.19076945e-07
Iter: 233 loss: 8.40193e-07
Iter: 234 loss: 8.18594401e-07
Iter: 235 loss: 8.1619703e-07
Iter: 236 loss: 8.11901714e-07
Iter: 237 loss: 9.15426767e-07
Iter: 238 loss: 8.11883297e-07
Iter: 239 loss: 8.08131404e-07
Iter: 240 loss: 8.0809e-07
Iter: 241 loss: 8.04502065e-07
Iter: 242 loss: 7.99461e-07
Iter: 243 loss: 7.99276677e-07
Iter: 244 loss: 7.93752918e-07
Iter: 245 loss: 8.09082621e-07
Iter: 246 loss: 7.91950356e-07
Iter: 247 loss: 7.87627641e-07
Iter: 248 loss: 7.85934333e-07
Iter: 249 loss: 7.83608073e-07
Iter: 250 loss: 7.86472697e-07
Iter: 251 loss: 7.81600306e-07
Iter: 252 loss: 7.79952643e-07
Iter: 253 loss: 7.77971707e-07
Iter: 254 loss: 7.7778725e-07
Iter: 255 loss: 7.75186493e-07
Iter: 256 loss: 7.7462596e-07
Iter: 257 loss: 7.72952774e-07
Iter: 258 loss: 7.70532949e-07
Iter: 259 loss: 7.7034997e-07
Iter: 260 loss: 7.68497785e-07
Iter: 261 loss: 7.65433924e-07
Iter: 262 loss: 7.65424204e-07
Iter: 263 loss: 7.6152412e-07
Iter: 264 loss: 7.65372533e-07
Iter: 265 loss: 7.59272439e-07
Iter: 266 loss: 7.56791849e-07
Iter: 267 loss: 7.56299301e-07
Iter: 268 loss: 7.54722123e-07
Iter: 269 loss: 7.50955337e-07
Iter: 270 loss: 7.96920403e-07
Iter: 271 loss: 7.50682716e-07
Iter: 272 loss: 7.48136699e-07
Iter: 273 loss: 7.4805007e-07
Iter: 274 loss: 7.46338287e-07
Iter: 275 loss: 7.53336565e-07
Iter: 276 loss: 7.45994726e-07
Iter: 277 loss: 7.44592512e-07
Iter: 278 loss: 7.4178979e-07
Iter: 279 loss: 7.93145205e-07
Iter: 280 loss: 7.41761596e-07
Iter: 281 loss: 7.38559834e-07
Iter: 282 loss: 7.45990576e-07
Iter: 283 loss: 7.37450819e-07
Iter: 284 loss: 7.33899583e-07
Iter: 285 loss: 7.4606146e-07
Iter: 286 loss: 7.32969625e-07
Iter: 287 loss: 7.29936517e-07
Iter: 288 loss: 7.29906958e-07
Iter: 289 loss: 7.27962686e-07
Iter: 290 loss: 7.25281097e-07
Iter: 291 loss: 7.25137113e-07
Iter: 292 loss: 7.22904701e-07
Iter: 293 loss: 7.35886772e-07
Iter: 294 loss: 7.22636116e-07
Iter: 295 loss: 7.19649165e-07
Iter: 296 loss: 7.2427008e-07
Iter: 297 loss: 7.18225806e-07
Iter: 298 loss: 7.16277555e-07
Iter: 299 loss: 7.16720933e-07
Iter: 300 loss: 7.14849534e-07
Iter: 301 loss: 7.14134899e-07
Iter: 302 loss: 7.13758e-07
Iter: 303 loss: 7.12752126e-07
Iter: 304 loss: 7.10287054e-07
Iter: 305 loss: 7.33452168e-07
Iter: 306 loss: 7.09932579e-07
Iter: 307 loss: 7.06743208e-07
Iter: 308 loss: 7.1867612e-07
Iter: 309 loss: 7.05944217e-07
Iter: 310 loss: 7.03605565e-07
Iter: 311 loss: 7.37396306e-07
Iter: 312 loss: 7.03600676e-07
Iter: 313 loss: 7.01609224e-07
Iter: 314 loss: 6.98601809e-07
Iter: 315 loss: 6.98560711e-07
Iter: 316 loss: 6.95621452e-07
Iter: 317 loss: 7.03203341e-07
Iter: 318 loss: 6.94651703e-07
Iter: 319 loss: 6.91413106e-07
Iter: 320 loss: 7.009711e-07
Iter: 321 loss: 6.90426191e-07
Iter: 322 loss: 6.89816545e-07
Iter: 323 loss: 6.89407102e-07
Iter: 324 loss: 6.8836971e-07
Iter: 325 loss: 6.8629754e-07
Iter: 326 loss: 7.27427846e-07
Iter: 327 loss: 6.86274291e-07
Iter: 328 loss: 6.84267889e-07
Iter: 329 loss: 6.89688136e-07
Iter: 330 loss: 6.83599524e-07
Iter: 331 loss: 6.81865e-07
Iter: 332 loss: 6.81848576e-07
Iter: 333 loss: 6.80851883e-07
Iter: 334 loss: 6.78635956e-07
Iter: 335 loss: 7.08882055e-07
Iter: 336 loss: 6.78458377e-07
Iter: 337 loss: 6.76746936e-07
Iter: 338 loss: 6.7667861e-07
Iter: 339 loss: 6.75045385e-07
Iter: 340 loss: 6.75841932e-07
Iter: 341 loss: 6.73955e-07
Iter: 342 loss: 6.72605324e-07
Iter: 343 loss: 6.71512453e-07
Iter: 344 loss: 6.71134671e-07
Iter: 345 loss: 6.69260544e-07
Iter: 346 loss: 6.69256792e-07
Iter: 347 loss: 6.6807462e-07
Iter: 348 loss: 6.66308267e-07
Iter: 349 loss: 6.6628786e-07
Iter: 350 loss: 6.64396794e-07
Iter: 351 loss: 6.68482073e-07
Iter: 352 loss: 6.6370967e-07
Iter: 353 loss: 6.61553372e-07
Iter: 354 loss: 6.67843e-07
Iter: 355 loss: 6.6087e-07
Iter: 356 loss: 6.60285e-07
Iter: 357 loss: 6.60118189e-07
Iter: 358 loss: 6.59316413e-07
Iter: 359 loss: 6.5759258e-07
Iter: 360 loss: 6.86209717e-07
Iter: 361 loss: 6.57554779e-07
Iter: 362 loss: 6.56126076e-07
Iter: 363 loss: 6.78120784e-07
Iter: 364 loss: 6.56141196e-07
Iter: 365 loss: 6.5499421e-07
Iter: 366 loss: 6.57543296e-07
Iter: 367 loss: 6.54564133e-07
Iter: 368 loss: 6.53592224e-07
Iter: 369 loss: 6.5196275e-07
Iter: 370 loss: 6.51963603e-07
Iter: 371 loss: 6.50551e-07
Iter: 372 loss: 6.50487891e-07
Iter: 373 loss: 6.49219544e-07
Iter: 374 loss: 6.47152945e-07
Iter: 375 loss: 6.47123329e-07
Iter: 376 loss: 6.45124089e-07
Iter: 377 loss: 6.48697323e-07
Iter: 378 loss: 6.44218062e-07
Iter: 379 loss: 6.42805446e-07
Iter: 380 loss: 6.42702844e-07
Iter: 381 loss: 6.41856332e-07
Iter: 382 loss: 6.40660232e-07
Iter: 383 loss: 6.4061021e-07
Iter: 384 loss: 6.39055315e-07
Iter: 385 loss: 6.39975838e-07
Iter: 386 loss: 6.38046913e-07
Iter: 387 loss: 6.36715754e-07
Iter: 388 loss: 6.53537711e-07
Iter: 389 loss: 6.36713764e-07
Iter: 390 loss: 6.35795971e-07
Iter: 391 loss: 6.45686782e-07
Iter: 392 loss: 6.35766298e-07
Iter: 393 loss: 6.34980552e-07
Iter: 394 loss: 6.33943387e-07
Iter: 395 loss: 6.33899106e-07
Iter: 396 loss: 6.32395256e-07
Iter: 397 loss: 6.35795e-07
Iter: 398 loss: 6.3180039e-07
Iter: 399 loss: 6.29578722e-07
Iter: 400 loss: 6.35436265e-07
Iter: 401 loss: 6.28831e-07
Iter: 402 loss: 6.27677196e-07
Iter: 403 loss: 6.28755629e-07
Iter: 404 loss: 6.26980238e-07
Iter: 405 loss: 6.26076144e-07
Iter: 406 loss: 6.26037831e-07
Iter: 407 loss: 6.25434e-07
Iter: 408 loss: 6.24256188e-07
Iter: 409 loss: 6.50266543e-07
Iter: 410 loss: 6.24260565e-07
Iter: 411 loss: 6.22912694e-07
Iter: 412 loss: 6.24367033e-07
Iter: 413 loss: 6.22201526e-07
Iter: 414 loss: 6.2105596e-07
Iter: 415 loss: 6.21010827e-07
Iter: 416 loss: 6.20356559e-07
Iter: 417 loss: 6.18705542e-07
Iter: 418 loss: 6.34396088e-07
Iter: 419 loss: 6.18460319e-07
Iter: 420 loss: 6.16099555e-07
Iter: 421 loss: 6.20366507e-07
Iter: 422 loss: 6.1507933e-07
Iter: 423 loss: 6.13316956e-07
Iter: 424 loss: 6.37314088e-07
Iter: 425 loss: 6.13315876e-07
Iter: 426 loss: 6.11946348e-07
Iter: 427 loss: 6.23632729e-07
Iter: 428 loss: 6.11879841e-07
Iter: 429 loss: 6.10771849e-07
Iter: 430 loss: 6.0926061e-07
Iter: 431 loss: 6.09195e-07
Iter: 432 loss: 6.08818823e-07
Iter: 433 loss: 6.08533071e-07
Iter: 434 loss: 6.08057e-07
Iter: 435 loss: 6.07777679e-07
Iter: 436 loss: 6.07576681e-07
Iter: 437 loss: 6.06694925e-07
Iter: 438 loss: 6.05998252e-07
Iter: 439 loss: 6.05753598e-07
Iter: 440 loss: 6.04790216e-07
Iter: 441 loss: 6.0470029e-07
Iter: 442 loss: 6.04148738e-07
Iter: 443 loss: 6.02599812e-07
Iter: 444 loss: 6.10430334e-07
Iter: 445 loss: 6.02082196e-07
Iter: 446 loss: 6.0054856e-07
Iter: 447 loss: 6.00545661e-07
Iter: 448 loss: 5.99203304e-07
Iter: 449 loss: 6.04908792e-07
Iter: 450 loss: 5.98943643e-07
Iter: 451 loss: 5.98069732e-07
Iter: 452 loss: 5.96923485e-07
Iter: 453 loss: 5.96850782e-07
Iter: 454 loss: 5.95329084e-07
Iter: 455 loss: 5.98900897e-07
Iter: 456 loss: 5.94730409e-07
Iter: 457 loss: 5.94277253e-07
Iter: 458 loss: 5.94133e-07
Iter: 459 loss: 5.93501227e-07
Iter: 460 loss: 5.9341005e-07
Iter: 461 loss: 5.9296849e-07
Iter: 462 loss: 5.9198311e-07
Iter: 463 loss: 5.91039282e-07
Iter: 464 loss: 5.90829359e-07
Iter: 465 loss: 5.8994658e-07
Iter: 466 loss: 5.8985529e-07
Iter: 467 loss: 5.89124852e-07
Iter: 468 loss: 5.88836201e-07
Iter: 469 loss: 5.88443299e-07
Iter: 470 loss: 5.87580814e-07
Iter: 471 loss: 5.89231604e-07
Iter: 472 loss: 5.87189106e-07
Iter: 473 loss: 5.86111128e-07
Iter: 474 loss: 5.95062488e-07
Iter: 475 loss: 5.86054512e-07
Iter: 476 loss: 5.85482269e-07
Iter: 477 loss: 5.84444479e-07
Iter: 478 loss: 5.8446949e-07
Iter: 479 loss: 5.83129747e-07
Iter: 480 loss: 5.89318e-07
Iter: 481 loss: 5.82886e-07
Iter: 482 loss: 5.81545464e-07
Iter: 483 loss: 5.90995569e-07
Iter: 484 loss: 5.81455254e-07
Iter: 485 loss: 5.80792971e-07
Iter: 486 loss: 5.79258256e-07
Iter: 487 loss: 5.97433655e-07
Iter: 488 loss: 5.79115579e-07
Iter: 489 loss: 5.77520382e-07
Iter: 490 loss: 5.88855073e-07
Iter: 491 loss: 5.77396406e-07
Iter: 492 loss: 5.76343496e-07
Iter: 493 loss: 5.88114631e-07
Iter: 494 loss: 5.76313425e-07
Iter: 495 loss: 5.75372042e-07
Iter: 496 loss: 5.80638357e-07
Iter: 497 loss: 5.75237436e-07
Iter: 498 loss: 5.74726357e-07
Iter: 499 loss: 5.73738077e-07
Iter: 500 loss: 5.93934033e-07
Iter: 501 loss: 5.73739385e-07
Iter: 502 loss: 5.73012585e-07
Iter: 503 loss: 5.7297e-07
Iter: 504 loss: 5.72245654e-07
Iter: 505 loss: 5.71201326e-07
Iter: 506 loss: 5.7114687e-07
Iter: 507 loss: 5.7011664e-07
Iter: 508 loss: 5.77595756e-07
Iter: 509 loss: 5.70022678e-07
Iter: 510 loss: 5.6922454e-07
Iter: 511 loss: 5.76349862e-07
Iter: 512 loss: 5.6917338e-07
Iter: 513 loss: 5.68564815e-07
Iter: 514 loss: 5.6721268e-07
Iter: 515 loss: 5.85820658e-07
Iter: 516 loss: 5.67122186e-07
Iter: 517 loss: 5.661758e-07
Iter: 518 loss: 5.66165738e-07
Iter: 519 loss: 5.65472533e-07
Iter: 520 loss: 5.71103442e-07
Iter: 521 loss: 5.65443e-07
Iter: 522 loss: 5.65031542e-07
Iter: 523 loss: 5.64187417e-07
Iter: 524 loss: 5.78485924e-07
Iter: 525 loss: 5.64156e-07
Iter: 526 loss: 5.63104436e-07
Iter: 527 loss: 5.66919937e-07
Iter: 528 loss: 5.62863534e-07
Iter: 529 loss: 5.61855359e-07
Iter: 530 loss: 5.61169941e-07
Iter: 531 loss: 5.60821547e-07
Iter: 532 loss: 5.61041361e-07
Iter: 533 loss: 5.60200533e-07
Iter: 534 loss: 5.59557066e-07
Iter: 535 loss: 5.58008196e-07
Iter: 536 loss: 5.73904572e-07
Iter: 537 loss: 5.57807596e-07
Iter: 538 loss: 5.56790496e-07
Iter: 539 loss: 5.69169117e-07
Iter: 540 loss: 5.56773784e-07
Iter: 541 loss: 5.55836436e-07
Iter: 542 loss: 5.61873094e-07
Iter: 543 loss: 5.55741167e-07
Iter: 544 loss: 5.55187171e-07
Iter: 545 loss: 5.54656253e-07
Iter: 546 loss: 5.54538e-07
Iter: 547 loss: 5.54051553e-07
Iter: 548 loss: 5.54010171e-07
Iter: 549 loss: 5.5355622e-07
Iter: 550 loss: 5.52885638e-07
Iter: 551 loss: 5.52871541e-07
Iter: 552 loss: 5.52014171e-07
Iter: 553 loss: 5.51675043e-07
Iter: 554 loss: 5.51207677e-07
Iter: 555 loss: 5.50529876e-07
Iter: 556 loss: 5.50456e-07
Iter: 557 loss: 5.49882088e-07
Iter: 558 loss: 5.51707046e-07
Iter: 559 loss: 5.49674724e-07
Iter: 560 loss: 5.49161769e-07
Iter: 561 loss: 5.48215723e-07
Iter: 562 loss: 5.71565124e-07
Iter: 563 loss: 5.48196908e-07
Iter: 564 loss: 5.47029117e-07
Iter: 565 loss: 5.50786e-07
Iter: 566 loss: 5.46718e-07
Iter: 567 loss: 5.45878777e-07
Iter: 568 loss: 5.49649371e-07
Iter: 569 loss: 5.45697162e-07
Iter: 570 loss: 5.4496644e-07
Iter: 571 loss: 5.56751843e-07
Iter: 572 loss: 5.44974114e-07
Iter: 573 loss: 5.4444115e-07
Iter: 574 loss: 5.43946044e-07
Iter: 575 loss: 5.43798e-07
Iter: 576 loss: 5.43141709e-07
Iter: 577 loss: 5.43441274e-07
Iter: 578 loss: 5.42696739e-07
Iter: 579 loss: 5.4152008e-07
Iter: 580 loss: 5.50500204e-07
Iter: 581 loss: 5.41427426e-07
Iter: 582 loss: 5.41029067e-07
Iter: 583 loss: 5.40549706e-07
Iter: 584 loss: 5.4050173e-07
Iter: 585 loss: 5.39737925e-07
Iter: 586 loss: 5.49991114e-07
Iter: 587 loss: 5.39742e-07
Iter: 588 loss: 5.393523e-07
Iter: 589 loss: 5.38707695e-07
Iter: 590 loss: 5.38705876e-07
Iter: 591 loss: 5.38100721e-07
Iter: 592 loss: 5.41856139e-07
Iter: 593 loss: 5.38032509e-07
Iter: 594 loss: 5.37309234e-07
Iter: 595 loss: 5.39339e-07
Iter: 596 loss: 5.37085612e-07
Iter: 597 loss: 5.36528091e-07
Iter: 598 loss: 5.36415428e-07
Iter: 599 loss: 5.36056291e-07
Iter: 600 loss: 5.3540947e-07
Iter: 601 loss: 5.36277639e-07
Iter: 602 loss: 5.35074037e-07
Iter: 603 loss: 5.34310175e-07
Iter: 604 loss: 5.40276346e-07
Iter: 605 loss: 5.34258447e-07
Iter: 606 loss: 5.33781531e-07
Iter: 607 loss: 5.41098643e-07
Iter: 608 loss: 5.33772891e-07
Iter: 609 loss: 5.33446439e-07
Iter: 610 loss: 5.32596857e-07
Iter: 611 loss: 5.40951191e-07
Iter: 612 loss: 5.3248192e-07
Iter: 613 loss: 5.31991191e-07
Iter: 614 loss: 5.31991532e-07
Iter: 615 loss: 5.31373416e-07
Iter: 616 loss: 5.31583964e-07
Iter: 617 loss: 5.30928673e-07
Iter: 618 loss: 5.30270142e-07
Iter: 619 loss: 5.29904355e-07
Iter: 620 loss: 5.29594558e-07
Iter: 621 loss: 5.2926049e-07
Iter: 622 loss: 5.29064096e-07
Iter: 623 loss: 5.28733381e-07
Iter: 624 loss: 5.28330133e-07
Iter: 625 loss: 5.28286478e-07
Iter: 626 loss: 5.27711677e-07
Iter: 627 loss: 5.27172233e-07
Iter: 628 loss: 5.27036264e-07
Iter: 629 loss: 5.2687335e-07
Iter: 630 loss: 5.26588565e-07
Iter: 631 loss: 5.26299e-07
Iter: 632 loss: 5.25547193e-07
Iter: 633 loss: 5.31824639e-07
Iter: 634 loss: 5.25427822e-07
Iter: 635 loss: 5.24448e-07
Iter: 636 loss: 5.26490282e-07
Iter: 637 loss: 5.24065968e-07
Iter: 638 loss: 5.23096787e-07
Iter: 639 loss: 5.25795599e-07
Iter: 640 loss: 5.22775622e-07
Iter: 641 loss: 5.22047344e-07
Iter: 642 loss: 5.22036544e-07
Iter: 643 loss: 5.21343395e-07
Iter: 644 loss: 5.21997549e-07
Iter: 645 loss: 5.20934407e-07
Iter: 646 loss: 5.20453341e-07
Iter: 647 loss: 5.19827722e-07
Iter: 648 loss: 5.19808111e-07
Iter: 649 loss: 5.19745527e-07
Iter: 650 loss: 5.19379739e-07
Iter: 651 loss: 5.19194e-07
Iter: 652 loss: 5.18910497e-07
Iter: 653 loss: 5.18899469e-07
Iter: 654 loss: 5.18452907e-07
Iter: 655 loss: 5.18197794e-07
Iter: 656 loss: 5.18015327e-07
Iter: 657 loss: 5.17380499e-07
Iter: 658 loss: 5.23135441e-07
Iter: 659 loss: 5.1734537e-07
Iter: 660 loss: 5.16612772e-07
Iter: 661 loss: 5.17335309e-07
Iter: 662 loss: 5.16161265e-07
Iter: 663 loss: 5.15444754e-07
Iter: 664 loss: 5.15017518e-07
Iter: 665 loss: 5.14716476e-07
Iter: 666 loss: 5.1372092e-07
Iter: 667 loss: 5.18068418e-07
Iter: 668 loss: 5.1353129e-07
Iter: 669 loss: 5.12879069e-07
Iter: 670 loss: 5.12856957e-07
Iter: 671 loss: 5.12536644e-07
Iter: 672 loss: 5.11846224e-07
Iter: 673 loss: 5.26357212e-07
Iter: 674 loss: 5.11837072e-07
Iter: 675 loss: 5.11367375e-07
Iter: 676 loss: 5.13362693e-07
Iter: 677 loss: 5.11288476e-07
Iter: 678 loss: 5.10946222e-07
Iter: 679 loss: 5.10940083e-07
Iter: 680 loss: 5.10554685e-07
Iter: 681 loss: 5.10336235e-07
Iter: 682 loss: 5.101748e-07
Iter: 683 loss: 5.0967185e-07
Iter: 684 loss: 5.09175948e-07
Iter: 685 loss: 5.09070787e-07
Iter: 686 loss: 5.08339951e-07
Iter: 687 loss: 5.19624962e-07
Iter: 688 loss: 5.08340463e-07
Iter: 689 loss: 5.07586378e-07
Iter: 690 loss: 5.07973596e-07
Iter: 691 loss: 5.07089794e-07
Iter: 692 loss: 5.06600827e-07
Iter: 693 loss: 5.07204334e-07
Iter: 694 loss: 5.06350602e-07
Iter: 695 loss: 5.05578726e-07
Iter: 696 loss: 5.09742222e-07
Iter: 697 loss: 5.05468279e-07
Iter: 698 loss: 5.05121193e-07
Iter: 699 loss: 5.05192e-07
Iter: 700 loss: 5.04858e-07
Iter: 701 loss: 5.04452714e-07
Iter: 702 loss: 5.05039225e-07
Iter: 703 loss: 5.04262971e-07
Iter: 704 loss: 5.03803335e-07
Iter: 705 loss: 5.08659582e-07
Iter: 706 loss: 5.03780768e-07
Iter: 707 loss: 5.03405431e-07
Iter: 708 loss: 5.02856892e-07
Iter: 709 loss: 5.02816306e-07
Iter: 710 loss: 5.02155672e-07
Iter: 711 loss: 5.03170554e-07
Iter: 712 loss: 5.01797331e-07
Iter: 713 loss: 5.00996407e-07
Iter: 714 loss: 5.06155288e-07
Iter: 715 loss: 5.00910119e-07
Iter: 716 loss: 5.00034162e-07
Iter: 717 loss: 5.05094874e-07
Iter: 718 loss: 4.99960322e-07
Iter: 719 loss: 4.99607324e-07
Iter: 720 loss: 4.99097666e-07
Iter: 721 loss: 4.9907328e-07
Iter: 722 loss: 4.98645363e-07
Iter: 723 loss: 5.04115917e-07
Iter: 724 loss: 4.98651616e-07
Iter: 725 loss: 4.9817362e-07
Iter: 726 loss: 4.99384214e-07
Iter: 727 loss: 4.98022928e-07
Iter: 728 loss: 4.97751e-07
Iter: 729 loss: 4.97807491e-07
Iter: 730 loss: 4.97512929e-07
Iter: 731 loss: 4.97087683e-07
Iter: 732 loss: 5.0080871e-07
Iter: 733 loss: 4.97080464e-07
Iter: 734 loss: 4.96792893e-07
Iter: 735 loss: 4.96177677e-07
Iter: 736 loss: 5.06642664e-07
Iter: 737 loss: 4.96180121e-07
Iter: 738 loss: 4.95334e-07
Iter: 739 loss: 4.94819915e-07
Iter: 740 loss: 4.94469418e-07
Iter: 741 loss: 4.95532845e-07
Iter: 742 loss: 4.94127676e-07
Iter: 743 loss: 4.93942252e-07
Iter: 744 loss: 4.93464e-07
Iter: 745 loss: 4.97314659e-07
Iter: 746 loss: 4.93376433e-07
Iter: 747 loss: 4.9278708e-07
Iter: 748 loss: 4.95010283e-07
Iter: 749 loss: 4.92640424e-07
Iter: 750 loss: 4.92344043e-07
Iter: 751 loss: 4.92337222e-07
Iter: 752 loss: 4.92038907e-07
Iter: 753 loss: 4.9239793e-07
Iter: 754 loss: 4.91873891e-07
Iter: 755 loss: 4.91526066e-07
Iter: 756 loss: 4.90982302e-07
Iter: 757 loss: 4.90971331e-07
Iter: 758 loss: 4.902613e-07
Iter: 759 loss: 4.92867798e-07
Iter: 760 loss: 4.90118566e-07
Iter: 761 loss: 4.89581112e-07
Iter: 762 loss: 4.89576792e-07
Iter: 763 loss: 4.8907259e-07
Iter: 764 loss: 4.88744377e-07
Iter: 765 loss: 4.88537125e-07
Iter: 766 loss: 4.88233695e-07
Iter: 767 loss: 4.88228068e-07
Iter: 768 loss: 4.87908153e-07
Iter: 769 loss: 4.87705336e-07
Iter: 770 loss: 4.87555553e-07
Iter: 771 loss: 4.87198122e-07
Iter: 772 loss: 4.86836939e-07
Iter: 773 loss: 4.86747865e-07
Iter: 774 loss: 4.86133388e-07
Iter: 775 loss: 4.89706622e-07
Iter: 776 loss: 4.86047725e-07
Iter: 777 loss: 4.85705641e-07
Iter: 778 loss: 4.85694329e-07
Iter: 779 loss: 4.85411249e-07
Iter: 780 loss: 4.84901136e-07
Iter: 781 loss: 4.96278062e-07
Iter: 782 loss: 4.84879649e-07
Iter: 783 loss: 4.84353961e-07
Iter: 784 loss: 4.8383049e-07
Iter: 785 loss: 4.83692588e-07
Iter: 786 loss: 4.84523071e-07
Iter: 787 loss: 4.83409906e-07
Iter: 788 loss: 4.83219651e-07
Iter: 789 loss: 4.8269851e-07
Iter: 790 loss: 4.86462852e-07
Iter: 791 loss: 4.82603468e-07
Iter: 792 loss: 4.81962218e-07
Iter: 793 loss: 4.83724307e-07
Iter: 794 loss: 4.81760196e-07
Iter: 795 loss: 4.81397819e-07
Iter: 796 loss: 4.81364395e-07
Iter: 797 loss: 4.81017196e-07
Iter: 798 loss: 4.80632252e-07
Iter: 799 loss: 4.80570463e-07
Iter: 800 loss: 4.80085532e-07
Iter: 801 loss: 4.82774908e-07
Iter: 802 loss: 4.79979349e-07
Iter: 803 loss: 4.79551773e-07
Iter: 804 loss: 4.82871428e-07
Iter: 805 loss: 4.79515e-07
Iter: 806 loss: 4.79309506e-07
Iter: 807 loss: 4.78944514e-07
Iter: 808 loss: 4.8727793e-07
Iter: 809 loss: 4.78951847e-07
Iter: 810 loss: 4.78499715e-07
Iter: 811 loss: 4.80395784e-07
Iter: 812 loss: 4.78382731e-07
Iter: 813 loss: 4.77981246e-07
Iter: 814 loss: 4.78323159e-07
Iter: 815 loss: 4.77710898e-07
Iter: 816 loss: 4.77289802e-07
Iter: 817 loss: 4.7728156e-07
Iter: 818 loss: 4.76998707e-07
Iter: 819 loss: 4.76476231e-07
Iter: 820 loss: 4.88507226e-07
Iter: 821 loss: 4.76464606e-07
Iter: 822 loss: 4.75833986e-07
Iter: 823 loss: 4.76188575e-07
Iter: 824 loss: 4.75423e-07
Iter: 825 loss: 4.74830728e-07
Iter: 826 loss: 4.74850594e-07
Iter: 827 loss: 4.74434387e-07
Iter: 828 loss: 4.79046548e-07
Iter: 829 loss: 4.74413213e-07
Iter: 830 loss: 4.74237709e-07
Iter: 831 loss: 4.73853845e-07
Iter: 832 loss: 4.80472295e-07
Iter: 833 loss: 4.73843329e-07
Iter: 834 loss: 4.73440366e-07
Iter: 835 loss: 4.75292467e-07
Iter: 836 loss: 4.73377042e-07
Iter: 837 loss: 4.72981725e-07
Iter: 838 loss: 4.77072035e-07
Iter: 839 loss: 4.72993406e-07
Iter: 840 loss: 4.72716295e-07
Iter: 841 loss: 4.72363354e-07
Iter: 842 loss: 4.72329305e-07
Iter: 843 loss: 4.71969713e-07
Iter: 844 loss: 4.77928097e-07
Iter: 845 loss: 4.71951182e-07
Iter: 846 loss: 4.71647354e-07
Iter: 847 loss: 4.71505928e-07
Iter: 848 loss: 4.71351882e-07
Iter: 849 loss: 4.70946929e-07
Iter: 850 loss: 4.70640032e-07
Iter: 851 loss: 4.70533223e-07
Iter: 852 loss: 4.70073587e-07
Iter: 853 loss: 4.7006958e-07
Iter: 854 loss: 4.69766519e-07
Iter: 855 loss: 4.71688878e-07
Iter: 856 loss: 4.69716042e-07
Iter: 857 loss: 4.69472951e-07
Iter: 858 loss: 4.68994926e-07
Iter: 859 loss: 4.77812e-07
Iter: 860 loss: 4.68995154e-07
Iter: 861 loss: 4.6859077e-07
Iter: 862 loss: 4.70793054e-07
Iter: 863 loss: 4.68558085e-07
Iter: 864 loss: 4.68109505e-07
Iter: 865 loss: 4.71863e-07
Iter: 866 loss: 4.68095891e-07
Iter: 867 loss: 4.67780865e-07
Iter: 868 loss: 4.67314237e-07
Iter: 869 loss: 4.6729707e-07
Iter: 870 loss: 4.66869039e-07
Iter: 871 loss: 4.68213472e-07
Iter: 872 loss: 4.66737561e-07
Iter: 873 loss: 4.663504e-07
Iter: 874 loss: 4.70268418e-07
Iter: 875 loss: 4.66347586e-07
Iter: 876 loss: 4.65881385e-07
Iter: 877 loss: 4.65831e-07
Iter: 878 loss: 4.6549377e-07
Iter: 879 loss: 4.65191334e-07
Iter: 880 loss: 4.67631907e-07
Iter: 881 loss: 4.65176925e-07
Iter: 882 loss: 4.64867014e-07
Iter: 883 loss: 4.65541632e-07
Iter: 884 loss: 4.64729965e-07
Iter: 885 loss: 4.64487812e-07
Iter: 886 loss: 4.64117932e-07
Iter: 887 loss: 4.64111679e-07
Iter: 888 loss: 4.6363391e-07
Iter: 889 loss: 4.67038603e-07
Iter: 890 loss: 4.6358349e-07
Iter: 891 loss: 4.6330274e-07
Iter: 892 loss: 4.67391118e-07
Iter: 893 loss: 4.63300552e-07
Iter: 894 loss: 4.63062776e-07
Iter: 895 loss: 4.62607403e-07
Iter: 896 loss: 4.72293493e-07
Iter: 897 loss: 4.62602742e-07
Iter: 898 loss: 4.62174171e-07
Iter: 899 loss: 4.64303298e-07
Iter: 900 loss: 4.62098967e-07
Iter: 901 loss: 4.61735e-07
Iter: 902 loss: 4.62051e-07
Iter: 903 loss: 4.61504271e-07
Iter: 904 loss: 4.6112649e-07
Iter: 905 loss: 4.61127769e-07
Iter: 906 loss: 4.60927026e-07
Iter: 907 loss: 4.60394e-07
Iter: 908 loss: 4.6413993e-07
Iter: 909 loss: 4.60269888e-07
Iter: 910 loss: 4.59972853e-07
Iter: 911 loss: 4.59903617e-07
Iter: 912 loss: 4.59555963e-07
Iter: 913 loss: 4.59468708e-07
Iter: 914 loss: 4.59265436e-07
Iter: 915 loss: 4.58950467e-07
Iter: 916 loss: 4.59310456e-07
Iter: 917 loss: 4.58808813e-07
Iter: 918 loss: 4.58427792e-07
Iter: 919 loss: 4.62120823e-07
Iter: 920 loss: 4.5840676e-07
Iter: 921 loss: 4.58210195e-07
Iter: 922 loss: 4.57973613e-07
Iter: 923 loss: 4.57952183e-07
Iter: 924 loss: 4.5769869e-07
Iter: 925 loss: 4.58687e-07
Iter: 926 loss: 4.57623e-07
Iter: 927 loss: 4.5725821e-07
Iter: 928 loss: 4.57615215e-07
Iter: 929 loss: 4.57060821e-07
Iter: 930 loss: 4.56717203e-07
Iter: 931 loss: 4.56291218e-07
Iter: 932 loss: 4.56257908e-07
Iter: 933 loss: 4.55673671e-07
Iter: 934 loss: 4.60625159e-07
Iter: 935 loss: 4.55626974e-07
Iter: 936 loss: 4.55283214e-07
Iter: 937 loss: 4.58152215e-07
Iter: 938 loss: 4.55265024e-07
Iter: 939 loss: 4.55038844e-07
Iter: 940 loss: 4.58092586e-07
Iter: 941 loss: 4.55027191e-07
Iter: 942 loss: 4.54869138e-07
Iter: 943 loss: 4.54485757e-07
Iter: 944 loss: 4.58274599e-07
Iter: 945 loss: 4.54437e-07
Iter: 946 loss: 4.54277284e-07
Iter: 947 loss: 4.54220242e-07
Iter: 948 loss: 4.54008159e-07
Iter: 949 loss: 4.53985422e-07
Iter: 950 loss: 4.53874748e-07
Iter: 951 loss: 4.53628445e-07
Iter: 952 loss: 4.53751909e-07
Iter: 953 loss: 4.53466754e-07
Iter: 954 loss: 4.53049665e-07
Iter: 955 loss: 4.54400379e-07
Iter: 956 loss: 4.52907443e-07
Iter: 957 loss: 4.52572834e-07
Iter: 958 loss: 4.52165892e-07
Iter: 959 loss: 4.52113341e-07
Iter: 960 loss: 4.51787287e-07
Iter: 961 loss: 4.51754346e-07
Iter: 962 loss: 4.51482208e-07
Iter: 963 loss: 4.51168404e-07
Iter: 964 loss: 4.51139897e-07
Iter: 965 loss: 4.50825553e-07
Iter: 966 loss: 4.51422579e-07
Iter: 967 loss: 4.50713685e-07
Iter: 968 loss: 4.50366144e-07
Iter: 969 loss: 4.51203306e-07
Iter: 970 loss: 4.50253708e-07
Iter: 971 loss: 4.50023748e-07
Iter: 972 loss: 4.53556538e-07
Iter: 973 loss: 4.50023919e-07
Iter: 974 loss: 4.49734699e-07
Iter: 975 loss: 4.49394463e-07
Iter: 976 loss: 4.49334095e-07
Iter: 977 loss: 4.4889174e-07
Iter: 978 loss: 4.49514232e-07
Iter: 979 loss: 4.48650837e-07
Iter: 980 loss: 4.48206322e-07
Iter: 981 loss: 4.49487231e-07
Iter: 982 loss: 4.48067624e-07
Iter: 983 loss: 4.47743247e-07
Iter: 984 loss: 4.4772986e-07
Iter: 985 loss: 4.47524116e-07
Iter: 986 loss: 4.47193173e-07
Iter: 987 loss: 4.47207981e-07
Iter: 988 loss: 4.47004254e-07
Iter: 989 loss: 4.47004879e-07
Iter: 990 loss: 4.46779666e-07
Iter: 991 loss: 4.46545187e-07
Iter: 992 loss: 4.46501303e-07
Iter: 993 loss: 4.46241984e-07
Iter: 994 loss: 4.4713974e-07
Iter: 995 loss: 4.4615166e-07
Iter: 996 loss: 4.45919198e-07
Iter: 997 loss: 4.483731e-07
Iter: 998 loss: 4.45915418e-07
Iter: 999 loss: 4.45668491e-07
Iter: 1000 loss: 4.4517293e-07
Iter: 1001 loss: 4.52440048e-07
Iter: 1002 loss: 4.451569e-07
Iter: 1003 loss: 4.44629592e-07
Iter: 1004 loss: 4.46967476e-07
Iter: 1005 loss: 4.44552143e-07
Iter: 1006 loss: 4.44332414e-07
Iter: 1007 loss: 4.44321131e-07
Iter: 1008 loss: 4.4404527e-07
Iter: 1009 loss: 4.43902422e-07
Iter: 1010 loss: 4.4379874e-07
Iter: 1011 loss: 4.43437131e-07
Iter: 1012 loss: 4.43602232e-07
Iter: 1013 loss: 4.43216948e-07
Iter: 1014 loss: 4.42862898e-07
Iter: 1015 loss: 4.43742863e-07
Iter: 1016 loss: 4.42716129e-07
Iter: 1017 loss: 4.42523742e-07
Iter: 1018 loss: 4.42516495e-07
Iter: 1019 loss: 4.42314189e-07
Iter: 1020 loss: 4.42384248e-07
Iter: 1021 loss: 4.4215281e-07
Iter: 1022 loss: 4.41949794e-07
Iter: 1023 loss: 4.4190665e-07
Iter: 1024 loss: 4.41762836e-07
Iter: 1025 loss: 4.41476686e-07
Iter: 1026 loss: 4.45765949e-07
Iter: 1027 loss: 4.41478051e-07
Iter: 1028 loss: 4.41285408e-07
Iter: 1029 loss: 4.40903193e-07
Iter: 1030 loss: 4.45628586e-07
Iter: 1031 loss: 4.4087119e-07
Iter: 1032 loss: 4.40681731e-07
Iter: 1033 loss: 4.40635233e-07
Iter: 1034 loss: 4.40360651e-07
Iter: 1035 loss: 4.39980028e-07
Iter: 1036 loss: 4.399771e-07
Iter: 1037 loss: 4.39608584e-07
Iter: 1038 loss: 4.39978351e-07
Iter: 1039 loss: 4.39366914e-07
Iter: 1040 loss: 4.39079031e-07
Iter: 1041 loss: 4.3907778e-07
Iter: 1042 loss: 4.38827442e-07
Iter: 1043 loss: 4.39170719e-07
Iter: 1044 loss: 4.38710657e-07
Iter: 1045 loss: 4.38481379e-07
Iter: 1046 loss: 4.38108401e-07
Iter: 1047 loss: 4.38105332e-07
Iter: 1048 loss: 4.37732666e-07
Iter: 1049 loss: 4.4071453e-07
Iter: 1050 loss: 4.377099e-07
Iter: 1051 loss: 4.37479173e-07
Iter: 1052 loss: 4.40059637e-07
Iter: 1053 loss: 4.37468884e-07
Iter: 1054 loss: 4.37236082e-07
Iter: 1055 loss: 4.37335871e-07
Iter: 1056 loss: 4.37047959e-07
Iter: 1057 loss: 4.36776816e-07
Iter: 1058 loss: 4.36698315e-07
Iter: 1059 loss: 4.3652426e-07
Iter: 1060 loss: 4.36157165e-07
Iter: 1061 loss: 4.41658472e-07
Iter: 1062 loss: 4.36153783e-07
Iter: 1063 loss: 4.35957588e-07
Iter: 1064 loss: 4.35667772e-07
Iter: 1065 loss: 4.35653646e-07
Iter: 1066 loss: 4.35303804e-07
Iter: 1067 loss: 4.37259416e-07
Iter: 1068 loss: 4.35255117e-07
Iter: 1069 loss: 4.34915449e-07
Iter: 1070 loss: 4.36953485e-07
Iter: 1071 loss: 4.34891149e-07
Iter: 1072 loss: 4.34717322e-07
Iter: 1073 loss: 4.34348919e-07
Iter: 1074 loss: 4.39389453e-07
Iter: 1075 loss: 4.3432388e-07
Iter: 1076 loss: 4.34093721e-07
Iter: 1077 loss: 4.34072035e-07
Iter: 1078 loss: 4.33833179e-07
Iter: 1079 loss: 4.34521326e-07
Iter: 1080 loss: 4.3371432e-07
Iter: 1081 loss: 4.33542965e-07
Iter: 1082 loss: 4.33092225e-07
Iter: 1083 loss: 4.38017366e-07
Iter: 1084 loss: 4.33021768e-07
Iter: 1085 loss: 4.32449269e-07
Iter: 1086 loss: 4.3754082e-07
Iter: 1087 loss: 4.32457568e-07
Iter: 1088 loss: 4.3226396e-07
Iter: 1089 loss: 4.32243638e-07
Iter: 1090 loss: 4.32057192e-07
Iter: 1091 loss: 4.31807081e-07
Iter: 1092 loss: 4.31806285e-07
Iter: 1093 loss: 4.31558391e-07
Iter: 1094 loss: 4.33540947e-07
Iter: 1095 loss: 4.31565752e-07
Iter: 1096 loss: 4.31346791e-07
Iter: 1097 loss: 4.32018936e-07
Iter: 1098 loss: 4.31304017e-07
Iter: 1099 loss: 4.31127575e-07
Iter: 1100 loss: 4.31013234e-07
Iter: 1101 loss: 4.30940474e-07
Iter: 1102 loss: 4.30729017e-07
Iter: 1103 loss: 4.3293818e-07
Iter: 1104 loss: 4.30705086e-07
Iter: 1105 loss: 4.30513467e-07
Iter: 1106 loss: 4.30521396e-07
Iter: 1107 loss: 4.30326395e-07
Iter: 1108 loss: 4.30079638e-07
Iter: 1109 loss: 4.29756483e-07
Iter: 1110 loss: 4.29739686e-07
Iter: 1111 loss: 4.29577767e-07
Iter: 1112 loss: 4.29492786e-07
Iter: 1113 loss: 4.29268766e-07
Iter: 1114 loss: 4.29210502e-07
Iter: 1115 loss: 4.29070155e-07
Iter: 1116 loss: 4.28809045e-07
Iter: 1117 loss: 4.285194e-07
Iter: 1118 loss: 4.28469207e-07
Iter: 1119 loss: 4.28145086e-07
Iter: 1120 loss: 4.30407113e-07
Iter: 1121 loss: 4.28123911e-07
Iter: 1122 loss: 4.27951647e-07
Iter: 1123 loss: 4.27940051e-07
Iter: 1124 loss: 4.27810136e-07
Iter: 1125 loss: 4.27491074e-07
Iter: 1126 loss: 4.29976041e-07
Iter: 1127 loss: 4.27451511e-07
Iter: 1128 loss: 4.2724497e-07
Iter: 1129 loss: 4.27225984e-07
Iter: 1130 loss: 4.27032205e-07
Iter: 1131 loss: 4.26998099e-07
Iter: 1132 loss: 4.26867018e-07
Iter: 1133 loss: 4.26594227e-07
Iter: 1134 loss: 4.26622279e-07
Iter: 1135 loss: 4.26401755e-07
Iter: 1136 loss: 4.26068311e-07
Iter: 1137 loss: 4.30185423e-07
Iter: 1138 loss: 4.26064e-07
Iter: 1139 loss: 4.25807315e-07
Iter: 1140 loss: 4.25725972e-07
Iter: 1141 loss: 4.25571557e-07
Iter: 1142 loss: 4.25253234e-07
Iter: 1143 loss: 4.25702183e-07
Iter: 1144 loss: 4.25084693e-07
Iter: 1145 loss: 4.24853027e-07
Iter: 1146 loss: 4.24852601e-07
Iter: 1147 loss: 4.2467218e-07
Iter: 1148 loss: 4.24525354e-07
Iter: 1149 loss: 4.2448238e-07
Iter: 1150 loss: 4.24264e-07
Iter: 1151 loss: 4.23811628e-07
Iter: 1152 loss: 4.31989406e-07
Iter: 1153 loss: 4.23775163e-07
Iter: 1154 loss: 4.23802533e-07
Iter: 1155 loss: 4.23591388e-07
Iter: 1156 loss: 4.23397381e-07
Iter: 1157 loss: 4.23710162e-07
Iter: 1158 loss: 4.23320841e-07
Iter: 1159 loss: 4.23171059e-07
Iter: 1160 loss: 4.22979127e-07
Iter: 1161 loss: 4.22989871e-07
Iter: 1162 loss: 4.22745984e-07
Iter: 1163 loss: 4.227646e-07
Iter: 1164 loss: 4.22565421e-07
Iter: 1165 loss: 4.22426865e-07
Iter: 1166 loss: 4.22371158e-07
Iter: 1167 loss: 4.22160213e-07
Iter: 1168 loss: 4.22888888e-07
Iter: 1169 loss: 4.22114312e-07
Iter: 1170 loss: 4.21812985e-07
Iter: 1171 loss: 4.21984652e-07
Iter: 1172 loss: 4.2162651e-07
Iter: 1173 loss: 4.21348773e-07
Iter: 1174 loss: 4.21690061e-07
Iter: 1175 loss: 4.21219028e-07
Iter: 1176 loss: 4.20943252e-07
Iter: 1177 loss: 4.22399694e-07
Iter: 1178 loss: 4.20902666e-07
Iter: 1179 loss: 4.20633569e-07
Iter: 1180 loss: 4.22037658e-07
Iter: 1181 loss: 4.20601623e-07
Iter: 1182 loss: 4.20398834e-07
Iter: 1183 loss: 4.20166145e-07
Iter: 1184 loss: 4.20150428e-07
Iter: 1185 loss: 4.19925726e-07
Iter: 1186 loss: 4.20788211e-07
Iter: 1187 loss: 4.19856e-07
Iter: 1188 loss: 4.19710545e-07
Iter: 1189 loss: 4.19691958e-07
Iter: 1190 loss: 4.19529187e-07
Iter: 1191 loss: 4.19312244e-07
Iter: 1192 loss: 4.19310737e-07
Iter: 1193 loss: 4.19042919e-07
Iter: 1194 loss: 4.19064889e-07
Iter: 1195 loss: 4.18851727e-07
Iter: 1196 loss: 4.18541731e-07
Iter: 1197 loss: 4.18548325e-07
Iter: 1198 loss: 4.18351419e-07
Iter: 1199 loss: 4.17991487e-07
Iter: 1200 loss: 4.25012672e-07
Iter: 1201 loss: 4.17989213e-07
Iter: 1202 loss: 4.17804358e-07
Iter: 1203 loss: 4.17762521e-07
Iter: 1204 loss: 4.17596027e-07
Iter: 1205 loss: 4.17401054e-07
Iter: 1206 loss: 4.17370927e-07
Iter: 1207 loss: 4.1708995e-07
Iter: 1208 loss: 4.18091247e-07
Iter: 1209 loss: 4.17025262e-07
Iter: 1210 loss: 4.16855471e-07
Iter: 1211 loss: 4.16874e-07
Iter: 1212 loss: 4.16728483e-07
Iter: 1213 loss: 4.16557441e-07
Iter: 1214 loss: 4.16538853e-07
Iter: 1215 loss: 4.16346722e-07
Iter: 1216 loss: 4.16786975e-07
Iter: 1217 loss: 4.16265607e-07
Iter: 1218 loss: 4.16055371e-07
Iter: 1219 loss: 4.16076432e-07
Iter: 1220 loss: 4.15873558e-07
Iter: 1221 loss: 4.15571265e-07
Iter: 1222 loss: 4.15569815e-07
Iter: 1223 loss: 4.15423244e-07
Iter: 1224 loss: 4.15115977e-07
Iter: 1225 loss: 4.20924152e-07
Iter: 1226 loss: 4.15079057e-07
Iter: 1227 loss: 4.14863081e-07
Iter: 1228 loss: 4.14861859e-07
Iter: 1229 loss: 4.14634627e-07
Iter: 1230 loss: 4.14537396e-07
Iter: 1231 loss: 4.14441217e-07
Iter: 1232 loss: 4.14177293e-07
Iter: 1233 loss: 4.14278077e-07
Iter: 1234 loss: 4.1398431e-07
Iter: 1235 loss: 4.13718624e-07
Iter: 1236 loss: 4.14631359e-07
Iter: 1237 loss: 4.13636087e-07
Iter: 1238 loss: 4.13449527e-07
Iter: 1239 loss: 4.13437647e-07
Iter: 1240 loss: 4.13304804e-07
Iter: 1241 loss: 4.13092295e-07
Iter: 1242 loss: 4.13082461e-07
Iter: 1243 loss: 4.12973691e-07
Iter: 1244 loss: 4.1296e-07
Iter: 1245 loss: 4.12844201e-07
Iter: 1246 loss: 4.12522212e-07
Iter: 1247 loss: 4.14760478e-07
Iter: 1248 loss: 4.12436236e-07
Iter: 1249 loss: 4.12154435e-07
Iter: 1250 loss: 4.15962234e-07
Iter: 1251 loss: 4.12162791e-07
Iter: 1252 loss: 4.11974696e-07
Iter: 1253 loss: 4.12927136e-07
Iter: 1254 loss: 4.11932263e-07
Iter: 1255 loss: 4.11688802e-07
Iter: 1256 loss: 4.11840062e-07
Iter: 1257 loss: 4.11539133e-07
Iter: 1258 loss: 4.11309429e-07
Iter: 1259 loss: 4.11605129e-07
Iter: 1260 loss: 4.1118966e-07
Iter: 1261 loss: 4.10981897e-07
Iter: 1262 loss: 4.14240105e-07
Iter: 1263 loss: 4.10983432e-07
Iter: 1264 loss: 4.10851328e-07
Iter: 1265 loss: 4.10554037e-07
Iter: 1266 loss: 4.13899642e-07
Iter: 1267 loss: 4.10529537e-07
Iter: 1268 loss: 4.10250095e-07
Iter: 1269 loss: 4.11594584e-07
Iter: 1270 loss: 4.10191234e-07
Iter: 1271 loss: 4.10124414e-07
Iter: 1272 loss: 4.10065809e-07
Iter: 1273 loss: 4.09961274e-07
Iter: 1274 loss: 4.09768461e-07
Iter: 1275 loss: 4.09772383e-07
Iter: 1276 loss: 4.09564109e-07
Iter: 1277 loss: 4.10173755e-07
Iter: 1278 loss: 4.0950755e-07
Iter: 1279 loss: 4.09245132e-07
Iter: 1280 loss: 4.10101194e-07
Iter: 1281 loss: 4.0916126e-07
Iter: 1282 loss: 4.0898189e-07
Iter: 1283 loss: 4.0866081e-07
Iter: 1284 loss: 4.08670758e-07
Iter: 1285 loss: 4.08278396e-07
Iter: 1286 loss: 4.10138881e-07
Iter: 1287 loss: 4.08221581e-07
Iter: 1288 loss: 4.07934e-07
Iter: 1289 loss: 4.07929804e-07
Iter: 1290 loss: 4.0774421e-07
Iter: 1291 loss: 4.07647633e-07
Iter: 1292 loss: 4.07549862e-07
Iter: 1293 loss: 4.07411619e-07
Iter: 1294 loss: 4.09152335e-07
Iter: 1295 loss: 4.07404229e-07
Iter: 1296 loss: 4.07278094e-07
Iter: 1297 loss: 4.0719604e-07
Iter: 1298 loss: 4.07120524e-07
Iter: 1299 loss: 4.06939932e-07
Iter: 1300 loss: 4.06821272e-07
Iter: 1301 loss: 4.06743709e-07
Iter: 1302 loss: 4.06439e-07
Iter: 1303 loss: 4.07098753e-07
Iter: 1304 loss: 4.06320538e-07
Iter: 1305 loss: 4.06075372e-07
Iter: 1306 loss: 4.06088873e-07
Iter: 1307 loss: 4.05850926e-07
Iter: 1308 loss: 4.05698586e-07
Iter: 1309 loss: 4.05633955e-07
Iter: 1310 loss: 4.05424601e-07
Iter: 1311 loss: 4.074152e-07
Iter: 1312 loss: 4.05423123e-07
Iter: 1313 loss: 4.05229684e-07
Iter: 1314 loss: 4.05431422e-07
Iter: 1315 loss: 4.05105766e-07
Iter: 1316 loss: 4.04973832e-07
Iter: 1317 loss: 4.04820696e-07
Iter: 1318 loss: 4.04783037e-07
Iter: 1319 loss: 4.04630157e-07
Iter: 1320 loss: 4.06363597e-07
Iter: 1321 loss: 4.04618049e-07
Iter: 1322 loss: 4.04436207e-07
Iter: 1323 loss: 4.05115259e-07
Iter: 1324 loss: 4.04401561e-07
Iter: 1325 loss: 4.04229183e-07
Iter: 1326 loss: 4.03950111e-07
Iter: 1327 loss: 4.03946e-07
Iter: 1328 loss: 4.03784952e-07
Iter: 1329 loss: 4.03761589e-07
Iter: 1330 loss: 4.03605327e-07
Iter: 1331 loss: 4.03456227e-07
Iter: 1332 loss: 4.03414958e-07
Iter: 1333 loss: 4.03171384e-07
Iter: 1334 loss: 4.03128979e-07
Iter: 1335 loss: 4.02970386e-07
Iter: 1336 loss: 4.02699357e-07
Iter: 1337 loss: 4.04171033e-07
Iter: 1338 loss: 4.02647061e-07
Iter: 1339 loss: 4.02533885e-07
Iter: 1340 loss: 4.02516747e-07
Iter: 1341 loss: 4.02374638e-07
Iter: 1342 loss: 4.02278829e-07
Iter: 1343 loss: 4.02213658e-07
Iter: 1344 loss: 4.02062284e-07
Iter: 1345 loss: 4.02241312e-07
Iter: 1346 loss: 4.01987e-07
Iter: 1347 loss: 4.01809984e-07
Iter: 1348 loss: 4.04202552e-07
Iter: 1349 loss: 4.01806631e-07
Iter: 1350 loss: 4.01672452e-07
Iter: 1351 loss: 4.01377e-07
Iter: 1352 loss: 4.05138309e-07
Iter: 1353 loss: 4.01355464e-07
Iter: 1354 loss: 4.01109332e-07
Iter: 1355 loss: 4.03420813e-07
Iter: 1356 loss: 4.01088272e-07
Iter: 1357 loss: 4.00900092e-07
Iter: 1358 loss: 4.0358924e-07
Iter: 1359 loss: 4.00898386e-07
Iter: 1360 loss: 4.00778788e-07
Iter: 1361 loss: 4.00550732e-07
Iter: 1362 loss: 4.04114559e-07
Iter: 1363 loss: 4.00531178e-07
Iter: 1364 loss: 4.00415047e-07
Iter: 1365 loss: 4.00383556e-07
Iter: 1366 loss: 4.00273507e-07
Iter: 1367 loss: 4.00071826e-07
Iter: 1368 loss: 4.00092205e-07
Iter: 1369 loss: 3.99854855e-07
Iter: 1370 loss: 4.0024986e-07
Iter: 1371 loss: 3.99752935e-07
Iter: 1372 loss: 3.99509219e-07
Iter: 1373 loss: 4.00048833e-07
Iter: 1374 loss: 3.99423158e-07
Iter: 1375 loss: 3.99234665e-07
Iter: 1376 loss: 4.00988313e-07
Iter: 1377 loss: 3.99227304e-07
Iter: 1378 loss: 3.9900246e-07
Iter: 1379 loss: 3.99608382e-07
Iter: 1380 loss: 3.98941268e-07
Iter: 1381 loss: 3.9880527e-07
Iter: 1382 loss: 3.98704e-07
Iter: 1383 loss: 3.98655175e-07
Iter: 1384 loss: 3.98570705e-07
Iter: 1385 loss: 3.9854234e-07
Iter: 1386 loss: 3.98449316e-07
Iter: 1387 loss: 3.98310419e-07
Iter: 1388 loss: 3.98295583e-07
Iter: 1389 loss: 3.98131135e-07
Iter: 1390 loss: 3.98206879e-07
Iter: 1391 loss: 3.98019722e-07
Iter: 1392 loss: 3.97869229e-07
Iter: 1393 loss: 3.97853483e-07
Iter: 1394 loss: 3.97766257e-07
Iter: 1395 loss: 3.97535814e-07
Iter: 1396 loss: 3.99738468e-07
Iter: 1397 loss: 3.97499491e-07
Iter: 1398 loss: 3.97364403e-07
Iter: 1399 loss: 3.9736085e-07
Iter: 1400 loss: 3.97220219e-07
Iter: 1401 loss: 3.97281951e-07
Iter: 1402 loss: 3.97121966e-07
Iter: 1403 loss: 3.96963799e-07
Iter: 1404 loss: 3.96915681e-07
Iter: 1405 loss: 3.96829023e-07
Iter: 1406 loss: 3.96614894e-07
Iter: 1407 loss: 3.96630298e-07
Iter: 1408 loss: 3.96456926e-07
Iter: 1409 loss: 3.96279233e-07
Iter: 1410 loss: 3.96264682e-07
Iter: 1411 loss: 3.96101342e-07
Iter: 1412 loss: 3.96265165e-07
Iter: 1413 loss: 3.96022131e-07
Iter: 1414 loss: 3.9582369e-07
Iter: 1415 loss: 3.9572123e-07
Iter: 1416 loss: 3.95657253e-07
Iter: 1417 loss: 3.95383267e-07
Iter: 1418 loss: 3.97274619e-07
Iter: 1419 loss: 3.95372581e-07
Iter: 1420 loss: 3.95175334e-07
Iter: 1421 loss: 3.97149108e-07
Iter: 1422 loss: 3.95156803e-07
Iter: 1423 loss: 3.95055849e-07
Iter: 1424 loss: 3.94821313e-07
Iter: 1425 loss: 4.00183467e-07
Iter: 1426 loss: 3.94815174e-07
Iter: 1427 loss: 3.94634469e-07
Iter: 1428 loss: 3.97143594e-07
Iter: 1429 loss: 3.94642882e-07
Iter: 1430 loss: 3.94467719e-07
Iter: 1431 loss: 3.94997244e-07
Iter: 1432 loss: 3.94412211e-07
Iter: 1433 loss: 3.94288946e-07
Iter: 1434 loss: 3.94039e-07
Iter: 1435 loss: 3.94037244e-07
Iter: 1436 loss: 3.93829282e-07
Iter: 1437 loss: 3.95456709e-07
Iter: 1438 loss: 3.93806602e-07
Iter: 1439 loss: 3.93619075e-07
Iter: 1440 loss: 3.95210918e-07
Iter: 1441 loss: 3.93596792e-07
Iter: 1442 loss: 3.93472618e-07
Iter: 1443 loss: 3.93192437e-07
Iter: 1444 loss: 3.97155702e-07
Iter: 1445 loss: 3.93162736e-07
Iter: 1446 loss: 3.92907509e-07
Iter: 1447 loss: 3.94187225e-07
Iter: 1448 loss: 3.92877382e-07
Iter: 1449 loss: 3.9269321e-07
Iter: 1450 loss: 3.95051728e-07
Iter: 1451 loss: 3.92687809e-07
Iter: 1452 loss: 3.9252285e-07
Iter: 1453 loss: 3.93027847e-07
Iter: 1454 loss: 3.92482775e-07
Iter: 1455 loss: 3.92349051e-07
Iter: 1456 loss: 3.92131057e-07
Iter: 1457 loss: 3.92138901e-07
Iter: 1458 loss: 3.92041784e-07
Iter: 1459 loss: 3.92009213e-07
Iter: 1460 loss: 3.91888079e-07
Iter: 1461 loss: 3.91619892e-07
Iter: 1462 loss: 3.97150984e-07
Iter: 1463 loss: 3.91615686e-07
Iter: 1464 loss: 3.9133846e-07
Iter: 1465 loss: 3.9114974e-07
Iter: 1466 loss: 3.9106385e-07
Iter: 1467 loss: 3.91092385e-07
Iter: 1468 loss: 3.90879251e-07
Iter: 1469 loss: 3.90750728e-07
Iter: 1470 loss: 3.90653526e-07
Iter: 1471 loss: 3.90622546e-07
Iter: 1472 loss: 3.90454801e-07
Iter: 1473 loss: 3.90326e-07
Iter: 1474 loss: 3.90294701e-07
Iter: 1475 loss: 3.90144635e-07
Iter: 1476 loss: 3.90123347e-07
Iter: 1477 loss: 3.89993346e-07
Iter: 1478 loss: 3.90231122e-07
Iter: 1479 loss: 3.89917375e-07
Iter: 1480 loss: 3.89771458e-07
Iter: 1481 loss: 3.89630713e-07
Iter: 1482 loss: 3.89625058e-07
Iter: 1483 loss: 3.89356387e-07
Iter: 1484 loss: 3.89874941e-07
Iter: 1485 loss: 3.89275527e-07
Iter: 1486 loss: 3.89156355e-07
Iter: 1487 loss: 3.89124637e-07
Iter: 1488 loss: 3.89013678e-07
Iter: 1489 loss: 3.8877215e-07
Iter: 1490 loss: 3.93617e-07
Iter: 1491 loss: 3.88767546e-07
Iter: 1492 loss: 3.88541253e-07
Iter: 1493 loss: 3.89243553e-07
Iter: 1494 loss: 3.88469971e-07
Iter: 1495 loss: 3.88360775e-07
Iter: 1496 loss: 3.88325674e-07
Iter: 1497 loss: 3.88263828e-07
Iter: 1498 loss: 3.8809435e-07
Iter: 1499 loss: 3.8940567e-07
Iter: 1500 loss: 3.88042e-07
Iter: 1501 loss: 3.87812065e-07
Iter: 1502 loss: 3.89241478e-07
Iter: 1503 loss: 3.87779522e-07
Iter: 1504 loss: 3.87521084e-07
Iter: 1505 loss: 3.89297213e-07
Iter: 1506 loss: 3.8750585e-07
Iter: 1507 loss: 3.87360245e-07
Iter: 1508 loss: 3.87136197e-07
Iter: 1509 loss: 3.87136851e-07
Iter: 1510 loss: 3.86917037e-07
Iter: 1511 loss: 3.87260229e-07
Iter: 1512 loss: 3.86794795e-07
Iter: 1513 loss: 3.86688299e-07
Iter: 1514 loss: 3.86678096e-07
Iter: 1515 loss: 3.8653036e-07
Iter: 1516 loss: 3.86445606e-07
Iter: 1517 loss: 3.86389587e-07
Iter: 1518 loss: 3.86215618e-07
Iter: 1519 loss: 3.86235797e-07
Iter: 1520 loss: 3.86086867e-07
Iter: 1521 loss: 3.85852388e-07
Iter: 1522 loss: 3.86370914e-07
Iter: 1523 loss: 3.85759961e-07
Iter: 1524 loss: 3.85519371e-07
Iter: 1525 loss: 3.86819892e-07
Iter: 1526 loss: 3.85488249e-07
Iter: 1527 loss: 3.85292708e-07
Iter: 1528 loss: 3.87157513e-07
Iter: 1529 loss: 3.8527719e-07
Iter: 1530 loss: 3.85077215e-07
Iter: 1531 loss: 3.85024435e-07
Iter: 1532 loss: 3.84905718e-07
Iter: 1533 loss: 3.84788592e-07
Iter: 1534 loss: 3.84788109e-07
Iter: 1535 loss: 3.84692e-07
Iter: 1536 loss: 3.84750251e-07
Iter: 1537 loss: 3.84613458e-07
Iter: 1538 loss: 3.84524242e-07
Iter: 1539 loss: 3.84300193e-07
Iter: 1540 loss: 3.8894035e-07
Iter: 1541 loss: 3.84303917e-07
Iter: 1542 loss: 3.84286665e-07
Iter: 1543 loss: 3.84180254e-07
Iter: 1544 loss: 3.84105505e-07
Iter: 1545 loss: 3.83926931e-07
Iter: 1546 loss: 3.86117449e-07
Iter: 1547 loss: 3.8391363e-07
Iter: 1548 loss: 3.83676877e-07
Iter: 1549 loss: 3.8405102e-07
Iter: 1550 loss: 3.83584506e-07
Iter: 1551 loss: 3.83404142e-07
Iter: 1552 loss: 3.83415625e-07
Iter: 1553 loss: 3.83305178e-07
Iter: 1554 loss: 3.83069448e-07
Iter: 1555 loss: 3.85573117e-07
Iter: 1556 loss: 3.83049411e-07
Iter: 1557 loss: 3.82769429e-07
Iter: 1558 loss: 3.83420598e-07
Iter: 1559 loss: 3.8268837e-07
Iter: 1560 loss: 3.82500474e-07
Iter: 1561 loss: 3.83780218e-07
Iter: 1562 loss: 3.82482028e-07
Iter: 1563 loss: 3.82337618e-07
Iter: 1564 loss: 3.83781696e-07
Iter: 1565 loss: 3.82335685e-07
Iter: 1566 loss: 3.82224698e-07
Iter: 1567 loss: 3.82110386e-07
Iter: 1568 loss: 3.8205377e-07
Iter: 1569 loss: 3.81858456e-07
Iter: 1570 loss: 3.82255962e-07
Iter: 1571 loss: 3.81763186e-07
Iter: 1572 loss: 3.81593e-07
Iter: 1573 loss: 3.81591406e-07
Iter: 1574 loss: 3.8147806e-07
Iter: 1575 loss: 3.81261373e-07
Iter: 1576 loss: 3.81268933e-07
Iter: 1577 loss: 3.81044e-07
Iter: 1578 loss: 3.81763158e-07
Iter: 1579 loss: 3.80987899e-07
Iter: 1580 loss: 3.80870233e-07
Iter: 1581 loss: 3.8085787e-07
Iter: 1582 loss: 3.80733383e-07
Iter: 1583 loss: 3.80696861e-07
Iter: 1584 loss: 3.80613784e-07
Iter: 1585 loss: 3.80479975e-07
Iter: 1586 loss: 3.8031223e-07
Iter: 1587 loss: 3.80310667e-07
Iter: 1588 loss: 3.80149515e-07
Iter: 1589 loss: 3.80134793e-07
Iter: 1590 loss: 3.79996749e-07
Iter: 1591 loss: 3.80840703e-07
Iter: 1592 loss: 3.79981032e-07
Iter: 1593 loss: 3.79850064e-07
Iter: 1594 loss: 3.79603364e-07
Iter: 1595 loss: 3.84454381e-07
Iter: 1596 loss: 3.79596088e-07
Iter: 1597 loss: 3.79348762e-07
Iter: 1598 loss: 3.80369642e-07
Iter: 1599 loss: 3.79313406e-07
Iter: 1600 loss: 3.7919034e-07
Iter: 1601 loss: 3.79172832e-07
Iter: 1602 loss: 3.79045133e-07
Iter: 1603 loss: 3.78982918e-07
Iter: 1604 loss: 3.7891175e-07
Iter: 1605 loss: 3.7881108e-07
Iter: 1606 loss: 3.79918845e-07
Iter: 1607 loss: 3.78806277e-07
Iter: 1608 loss: 3.7870231e-07
Iter: 1609 loss: 3.78774303e-07
Iter: 1610 loss: 3.7859968e-07
Iter: 1611 loss: 3.78467291e-07
Iter: 1612 loss: 3.78357e-07
Iter: 1613 loss: 3.78300115e-07
Iter: 1614 loss: 3.78124696e-07
Iter: 1615 loss: 3.79667711e-07
Iter: 1616 loss: 3.78118159e-07
Iter: 1617 loss: 3.77921907e-07
Iter: 1618 loss: 3.787639e-07
Iter: 1619 loss: 3.77889876e-07
Iter: 1620 loss: 3.77790286e-07
Iter: 1621 loss: 3.77534121e-07
Iter: 1622 loss: 3.80947512e-07
Iter: 1623 loss: 3.7753253e-07
Iter: 1624 loss: 3.77291741e-07
Iter: 1625 loss: 3.79827384e-07
Iter: 1626 loss: 3.77301262e-07
Iter: 1627 loss: 3.77171773e-07
Iter: 1628 loss: 3.78413233e-07
Iter: 1629 loss: 3.77152048e-07
Iter: 1630 loss: 3.77030034e-07
Iter: 1631 loss: 3.76957274e-07
Iter: 1632 loss: 3.76893269e-07
Iter: 1633 loss: 3.76746812e-07
Iter: 1634 loss: 3.76561047e-07
Iter: 1635 loss: 3.76537827e-07
Iter: 1636 loss: 3.76285897e-07
Iter: 1637 loss: 3.78334789e-07
Iter: 1638 loss: 3.76274443e-07
Iter: 1639 loss: 3.76162603e-07
Iter: 1640 loss: 3.76160983e-07
Iter: 1641 loss: 3.76050423e-07
Iter: 1642 loss: 3.75810941e-07
Iter: 1643 loss: 3.80187828e-07
Iter: 1644 loss: 3.75812931e-07
Iter: 1645 loss: 3.75645925e-07
Iter: 1646 loss: 3.77681943e-07
Iter: 1647 loss: 3.75647e-07
Iter: 1648 loss: 3.75535706e-07
Iter: 1649 loss: 3.76516766e-07
Iter: 1650 loss: 3.75527e-07
Iter: 1651 loss: 3.75475281e-07
Iter: 1652 loss: 3.75305774e-07
Iter: 1653 loss: 3.76487037e-07
Iter: 1654 loss: 3.75272236e-07
Iter: 1655 loss: 3.75177478e-07
Iter: 1656 loss: 3.75152695e-07
Iter: 1657 loss: 3.75048756e-07
Iter: 1658 loss: 3.74865238e-07
Iter: 1659 loss: 3.77090203e-07
Iter: 1660 loss: 3.74842898e-07
Iter: 1661 loss: 3.74630787e-07
Iter: 1662 loss: 3.75138569e-07
Iter: 1663 loss: 3.74555185e-07
Iter: 1664 loss: 3.7445389e-07
Iter: 1665 loss: 3.74421177e-07
Iter: 1666 loss: 3.74333894e-07
Iter: 1667 loss: 3.74225635e-07
Iter: 1668 loss: 3.74208099e-07
Iter: 1669 loss: 3.74093247e-07
Iter: 1670 loss: 3.7405718e-07
Iter: 1671 loss: 3.73960717e-07
Iter: 1672 loss: 3.7384018e-07
Iter: 1673 loss: 3.75345422e-07
Iter: 1674 loss: 3.73836116e-07
Iter: 1675 loss: 3.73733087e-07
Iter: 1676 loss: 3.74532306e-07
Iter: 1677 loss: 3.73740818e-07
Iter: 1678 loss: 3.73607861e-07
Iter: 1679 loss: 3.73530128e-07
Iter: 1680 loss: 3.73502758e-07
Iter: 1681 loss: 3.73348939e-07
Iter: 1682 loss: 3.74014974e-07
Iter: 1683 loss: 3.73299315e-07
Iter: 1684 loss: 3.73157775e-07
Iter: 1685 loss: 3.7401395e-07
Iter: 1686 loss: 3.73155984e-07
Iter: 1687 loss: 3.73043065e-07
Iter: 1688 loss: 3.7287117e-07
Iter: 1689 loss: 3.76044397e-07
Iter: 1690 loss: 3.7288055e-07
Iter: 1691 loss: 3.7285912e-07
Iter: 1692 loss: 3.72798581e-07
Iter: 1693 loss: 3.72732245e-07
Iter: 1694 loss: 3.72627937e-07
Iter: 1695 loss: 3.7261853e-07
Iter: 1696 loss: 3.72513739e-07
Iter: 1697 loss: 3.72591614e-07
Iter: 1698 loss: 3.72431174e-07
Iter: 1699 loss: 3.72306943e-07
Iter: 1700 loss: 3.723041e-07
Iter: 1701 loss: 3.7221821e-07
Iter: 1702 loss: 3.72045179e-07
Iter: 1703 loss: 3.75694611e-07
Iter: 1704 loss: 3.72035458e-07
Iter: 1705 loss: 3.71836677e-07
Iter: 1706 loss: 3.72032389e-07
Iter: 1707 loss: 3.71737542e-07
Iter: 1708 loss: 3.71523527e-07
Iter: 1709 loss: 3.72821262e-07
Iter: 1710 loss: 3.71481093e-07
Iter: 1711 loss: 3.71332504e-07
Iter: 1712 loss: 3.71319743e-07
Iter: 1713 loss: 3.71196393e-07
Iter: 1714 loss: 3.71160525e-07
Iter: 1715 loss: 3.7108407e-07
Iter: 1716 loss: 3.71026033e-07
Iter: 1717 loss: 3.70930422e-07
Iter: 1718 loss: 3.70947873e-07
Iter: 1719 loss: 3.70786495e-07
Iter: 1720 loss: 3.71294931e-07
Iter: 1721 loss: 3.70773563e-07
Iter: 1722 loss: 3.70611986e-07
Iter: 1723 loss: 3.70529364e-07
Iter: 1724 loss: 3.70471298e-07
Iter: 1725 loss: 3.70303042e-07
Iter: 1726 loss: 3.71263667e-07
Iter: 1727 loss: 3.70280929e-07
Iter: 1728 loss: 3.70159057e-07
Iter: 1729 loss: 3.71821926e-07
Iter: 1730 loss: 3.70155959e-07
Iter: 1731 loss: 3.70063304e-07
Iter: 1732 loss: 3.6987521e-07
Iter: 1733 loss: 3.72587181e-07
Iter: 1734 loss: 3.69887516e-07
Iter: 1735 loss: 3.69732845e-07
Iter: 1736 loss: 3.69881263e-07
Iter: 1737 loss: 3.69629561e-07
Iter: 1738 loss: 3.69489385e-07
Iter: 1739 loss: 3.69490635e-07
Iter: 1740 loss: 3.69383258e-07
Iter: 1741 loss: 3.70106591e-07
Iter: 1742 loss: 3.69385532e-07
Iter: 1743 loss: 3.69301887e-07
Iter: 1744 loss: 3.6913724e-07
Iter: 1745 loss: 3.71450483e-07
Iter: 1746 loss: 3.69115583e-07
Iter: 1747 loss: 3.68910719e-07
Iter: 1748 loss: 3.69628538e-07
Iter: 1749 loss: 3.68849982e-07
Iter: 1750 loss: 3.68777791e-07
Iter: 1751 loss: 3.68750307e-07
Iter: 1752 loss: 3.6868272e-07
Iter: 1753 loss: 3.68563292e-07
Iter: 1754 loss: 3.68567726e-07
Iter: 1755 loss: 3.68423031e-07
Iter: 1756 loss: 3.69397043e-07
Iter: 1757 loss: 3.68418085e-07
Iter: 1758 loss: 3.6829266e-07
Iter: 1759 loss: 3.68553913e-07
Iter: 1760 loss: 3.68239739e-07
Iter: 1761 loss: 3.68160357e-07
Iter: 1762 loss: 3.68110676e-07
Iter: 1763 loss: 3.68077337e-07
Iter: 1764 loss: 3.67940117e-07
Iter: 1765 loss: 3.67944949e-07
Iter: 1766 loss: 3.67874804e-07
Iter: 1767 loss: 3.67746338e-07
Iter: 1768 loss: 3.70923772e-07
Iter: 1769 loss: 3.67744974e-07
Iter: 1770 loss: 3.67578082e-07
Iter: 1771 loss: 3.6780915e-07
Iter: 1772 loss: 3.67495318e-07
Iter: 1773 loss: 3.67305773e-07
Iter: 1774 loss: 3.68306985e-07
Iter: 1775 loss: 3.67275902e-07
Iter: 1776 loss: 3.67096334e-07
Iter: 1777 loss: 3.6873908e-07
Iter: 1778 loss: 3.67108271e-07
Iter: 1779 loss: 3.67007431e-07
Iter: 1780 loss: 3.66863105e-07
Iter: 1781 loss: 3.66871973e-07
Iter: 1782 loss: 3.66741403e-07
Iter: 1783 loss: 3.6848823e-07
Iter: 1784 loss: 3.66743933e-07
Iter: 1785 loss: 3.66644599e-07
Iter: 1786 loss: 3.67064786e-07
Iter: 1787 loss: 3.66632037e-07
Iter: 1788 loss: 3.66543929e-07
Iter: 1789 loss: 3.66431578e-07
Iter: 1790 loss: 3.66416401e-07
Iter: 1791 loss: 3.66277305e-07
Iter: 1792 loss: 3.67779933e-07
Iter: 1793 loss: 3.66285519e-07
Iter: 1794 loss: 3.66169218e-07
Iter: 1795 loss: 3.66048425e-07
Iter: 1796 loss: 3.66031827e-07
Iter: 1797 loss: 3.65905976e-07
Iter: 1798 loss: 3.66838577e-07
Iter: 1799 loss: 3.65894607e-07
Iter: 1800 loss: 3.65742721e-07
Iter: 1801 loss: 3.6648612e-07
Iter: 1802 loss: 3.65725384e-07
Iter: 1803 loss: 3.65646088e-07
Iter: 1804 loss: 3.65500114e-07
Iter: 1805 loss: 3.65508612e-07
Iter: 1806 loss: 3.65370653e-07
Iter: 1807 loss: 3.65973904e-07
Iter: 1808 loss: 3.65342544e-07
Iter: 1809 loss: 3.65244034e-07
Iter: 1810 loss: 3.66684105e-07
Iter: 1811 loss: 3.65249377e-07
Iter: 1812 loss: 3.65153426e-07
Iter: 1813 loss: 3.65163686e-07
Iter: 1814 loss: 3.65088852e-07
Iter: 1815 loss: 3.65000574e-07
Iter: 1816 loss: 3.64916218e-07
Iter: 1817 loss: 3.64878474e-07
Iter: 1818 loss: 3.64725793e-07
Iter: 1819 loss: 3.67215023e-07
Iter: 1820 loss: 3.6472224e-07
Iter: 1821 loss: 3.64614579e-07
Iter: 1822 loss: 3.6451371e-07
Iter: 1823 loss: 3.64459481e-07
Iter: 1824 loss: 3.64325558e-07
Iter: 1825 loss: 3.65325462e-07
Iter: 1826 loss: 3.64324961e-07
Iter: 1827 loss: 3.64194534e-07
Iter: 1828 loss: 3.64536731e-07
Iter: 1829 loss: 3.64135019e-07
Iter: 1830 loss: 3.64040829e-07
Iter: 1831 loss: 3.64049413e-07
Iter: 1832 loss: 3.63975857e-07
Iter: 1833 loss: 3.63900483e-07
Iter: 1834 loss: 3.63894401e-07
Iter: 1835 loss: 3.63799188e-07
Iter: 1836 loss: 3.63680954e-07
Iter: 1837 loss: 3.63684762e-07
Iter: 1838 loss: 3.63556751e-07
Iter: 1839 loss: 3.63636502e-07
Iter: 1840 loss: 3.63466938e-07
Iter: 1841 loss: 3.63302831e-07
Iter: 1842 loss: 3.64309358e-07
Iter: 1843 loss: 3.63269606e-07
Iter: 1844 loss: 3.63119e-07
Iter: 1845 loss: 3.64049384e-07
Iter: 1846 loss: 3.63098707e-07
Iter: 1847 loss: 3.62994427e-07
Iter: 1848 loss: 3.62889324e-07
Iter: 1849 loss: 3.62867041e-07
Iter: 1850 loss: 3.62727206e-07
Iter: 1851 loss: 3.63894628e-07
Iter: 1852 loss: 3.62727178e-07
Iter: 1853 loss: 3.62554545e-07
Iter: 1854 loss: 3.62910953e-07
Iter: 1855 loss: 3.62515721e-07
Iter: 1856 loss: 3.62448134e-07
Iter: 1857 loss: 3.62546729e-07
Iter: 1858 loss: 3.62385236e-07
Iter: 1859 loss: 3.62301734e-07
Iter: 1860 loss: 3.63349727e-07
Iter: 1861 loss: 3.62299431e-07
Iter: 1862 loss: 3.62261574e-07
Iter: 1863 loss: 3.62110683e-07
Iter: 1864 loss: 3.64487846e-07
Iter: 1865 loss: 3.62124638e-07
Iter: 1866 loss: 3.61994296e-07
Iter: 1867 loss: 3.63032711e-07
Iter: 1868 loss: 3.61982785e-07
Iter: 1869 loss: 3.61855768e-07
Iter: 1870 loss: 3.62503613e-07
Iter: 1871 loss: 3.61845508e-07
Iter: 1872 loss: 3.61757827e-07
Iter: 1873 loss: 3.61587354e-07
Iter: 1874 loss: 3.64557508e-07
Iter: 1875 loss: 3.6156348e-07
Iter: 1876 loss: 3.61355745e-07
Iter: 1877 loss: 3.62849619e-07
Iter: 1878 loss: 3.61344149e-07
Iter: 1879 loss: 3.61224977e-07
Iter: 1880 loss: 3.61238023e-07
Iter: 1881 loss: 3.61145084e-07
Iter: 1882 loss: 3.61010848e-07
Iter: 1883 loss: 3.61017243e-07
Iter: 1884 loss: 3.60863567e-07
Iter: 1885 loss: 3.61547478e-07
Iter: 1886 loss: 3.60833553e-07
Iter: 1887 loss: 3.60722197e-07
Iter: 1888 loss: 3.62219083e-07
Iter: 1889 loss: 3.6072305e-07
Iter: 1890 loss: 3.60641934e-07
Iter: 1891 loss: 3.60523927e-07
Iter: 1892 loss: 3.63937318e-07
Iter: 1893 loss: 3.60520318e-07
Iter: 1894 loss: 3.60383098e-07
Iter: 1895 loss: 3.61744355e-07
Iter: 1896 loss: 3.60387787e-07
Iter: 1897 loss: 3.60260714e-07
Iter: 1898 loss: 3.60358342e-07
Iter: 1899 loss: 3.602172e-07
Iter: 1900 loss: 3.60077593e-07
Iter: 1901 loss: 3.60121703e-07
Iter: 1902 loss: 3.5998508e-07
Iter: 1903 loss: 3.59877959e-07
Iter: 1904 loss: 3.59867386e-07
Iter: 1905 loss: 3.59796616e-07
Iter: 1906 loss: 3.59740369e-07
Iter: 1907 loss: 3.59713198e-07
Iter: 1908 loss: 3.59613324e-07
Iter: 1909 loss: 3.59568048e-07
Iter: 1910 loss: 3.59521721e-07
Iter: 1911 loss: 3.59352953e-07
Iter: 1912 loss: 3.60353e-07
Iter: 1913 loss: 3.59325554e-07
Iter: 1914 loss: 3.59187084e-07
Iter: 1915 loss: 3.60623034e-07
Iter: 1916 loss: 3.59197145e-07
Iter: 1917 loss: 3.59146668e-07
Iter: 1918 loss: 3.59026672e-07
Iter: 1919 loss: 3.61598808e-07
Iter: 1920 loss: 3.59023318e-07
Iter: 1921 loss: 3.58869954e-07
Iter: 1922 loss: 3.60227091e-07
Iter: 1923 loss: 3.58872626e-07
Iter: 1924 loss: 3.58746604e-07
Iter: 1925 loss: 3.59056457e-07
Iter: 1926 loss: 3.58692205e-07
Iter: 1927 loss: 3.58578802e-07
Iter: 1928 loss: 3.58569451e-07
Iter: 1929 loss: 3.58507663e-07
Iter: 1930 loss: 3.58377292e-07
Iter: 1931 loss: 3.59704472e-07
Iter: 1932 loss: 3.58366151e-07
Iter: 1933 loss: 3.58262952e-07
Iter: 1934 loss: 3.58233422e-07
Iter: 1935 loss: 3.58190192e-07
Iter: 1936 loss: 3.58101772e-07
Iter: 1937 loss: 3.59433358e-07
Iter: 1938 loss: 3.5810487e-07
Iter: 1939 loss: 3.58007497e-07
Iter: 1940 loss: 3.57948323e-07
Iter: 1941 loss: 3.57924023e-07
Iter: 1942 loss: 3.5778578e-07
Iter: 1943 loss: 3.57805931e-07
Iter: 1944 loss: 3.57693182e-07
Iter: 1945 loss: 3.57548515e-07
Iter: 1946 loss: 3.5805266e-07
Iter: 1947 loss: 3.5753007e-07
Iter: 1948 loss: 3.57366559e-07
Iter: 1949 loss: 3.58990661e-07
Iter: 1950 loss: 3.5736133e-07
Iter: 1951 loss: 3.57275667e-07
Iter: 1952 loss: 3.5719583e-07
Iter: 1953 loss: 3.5715118e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2
+ date
Mon Oct 26 17:49:56 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6923f80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6923f86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc69244fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6923ceea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc69237f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6923ae6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc69233b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6923087b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc692308e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc692308d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6922a9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6922ad8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6922ad598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6922402f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc692240598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc692232048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6921e2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6921f1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc692196510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6921e2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6921597b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc692159ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679c696a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679c8e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679c8e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679c2d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679be6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679bc2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679bb3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679bb3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc679b93a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc654421048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc654445268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6543da840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65440c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65439ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.9251738e-06
Iter: 2 loss: 7.83250835e-06
Iter: 3 loss: 7.68811697e-06
Iter: 4 loss: 7.05248658e-06
Iter: 5 loss: 7.28309351e-06
Iter: 6 loss: 6.6079765e-06
Iter: 7 loss: 6.20979245e-06
Iter: 8 loss: 8.67899689e-06
Iter: 9 loss: 6.16299531e-06
Iter: 10 loss: 5.81192e-06
Iter: 11 loss: 6.93430684e-06
Iter: 12 loss: 5.71167857e-06
Iter: 13 loss: 5.47171248e-06
Iter: 14 loss: 6.09564313e-06
Iter: 15 loss: 5.39008261e-06
Iter: 16 loss: 5.14391195e-06
Iter: 17 loss: 6.21245454e-06
Iter: 18 loss: 5.09364509e-06
Iter: 19 loss: 4.95037784e-06
Iter: 20 loss: 4.66579513e-06
Iter: 21 loss: 1.01859659e-05
Iter: 22 loss: 4.66270194e-06
Iter: 23 loss: 4.35485526e-06
Iter: 24 loss: 9.07799767e-06
Iter: 25 loss: 4.35472339e-06
Iter: 26 loss: 4.12892132e-06
Iter: 27 loss: 4.70746181e-06
Iter: 28 loss: 4.05144237e-06
Iter: 29 loss: 3.87955515e-06
Iter: 30 loss: 3.72116824e-06
Iter: 31 loss: 3.67971484e-06
Iter: 32 loss: 3.45680837e-06
Iter: 33 loss: 4.27836767e-06
Iter: 34 loss: 3.40159363e-06
Iter: 35 loss: 3.27232215e-06
Iter: 36 loss: 3.87263026e-06
Iter: 37 loss: 3.24812618e-06
Iter: 38 loss: 3.17737249e-06
Iter: 39 loss: 3.17288732e-06
Iter: 40 loss: 3.09686129e-06
Iter: 41 loss: 3.07443679e-06
Iter: 42 loss: 3.02875742e-06
Iter: 43 loss: 2.93857101e-06
Iter: 44 loss: 3.17813806e-06
Iter: 45 loss: 2.90828098e-06
Iter: 46 loss: 2.82711153e-06
Iter: 47 loss: 3.8146577e-06
Iter: 48 loss: 2.82621272e-06
Iter: 49 loss: 2.78024e-06
Iter: 50 loss: 2.71517956e-06
Iter: 51 loss: 2.71281533e-06
Iter: 52 loss: 2.60692332e-06
Iter: 53 loss: 3.23673703e-06
Iter: 54 loss: 2.59351509e-06
Iter: 55 loss: 2.52962582e-06
Iter: 56 loss: 2.48591823e-06
Iter: 57 loss: 2.46255695e-06
Iter: 58 loss: 2.3855805e-06
Iter: 59 loss: 3.12662814e-06
Iter: 60 loss: 2.38271286e-06
Iter: 61 loss: 2.32148568e-06
Iter: 62 loss: 2.61171954e-06
Iter: 63 loss: 2.31032959e-06
Iter: 64 loss: 2.26127258e-06
Iter: 65 loss: 2.20119e-06
Iter: 66 loss: 2.19569688e-06
Iter: 67 loss: 2.11791712e-06
Iter: 68 loss: 2.26936254e-06
Iter: 69 loss: 2.08552819e-06
Iter: 70 loss: 2.02466299e-06
Iter: 71 loss: 2.6542416e-06
Iter: 72 loss: 2.02293813e-06
Iter: 73 loss: 1.97064128e-06
Iter: 74 loss: 1.8862e-06
Iter: 75 loss: 1.88562149e-06
Iter: 76 loss: 1.94265454e-06
Iter: 77 loss: 1.85927615e-06
Iter: 78 loss: 1.83236546e-06
Iter: 79 loss: 1.78152482e-06
Iter: 80 loss: 2.89179025e-06
Iter: 81 loss: 1.78135542e-06
Iter: 82 loss: 1.75214655e-06
Iter: 83 loss: 1.75176933e-06
Iter: 84 loss: 1.73199851e-06
Iter: 85 loss: 1.85305271e-06
Iter: 86 loss: 1.72958039e-06
Iter: 87 loss: 1.71653232e-06
Iter: 88 loss: 1.69324289e-06
Iter: 89 loss: 2.27298597e-06
Iter: 90 loss: 1.69326017e-06
Iter: 91 loss: 1.66079087e-06
Iter: 92 loss: 1.92458242e-06
Iter: 93 loss: 1.65869767e-06
Iter: 94 loss: 1.63649736e-06
Iter: 95 loss: 1.61080879e-06
Iter: 96 loss: 1.6077521e-06
Iter: 97 loss: 1.58617615e-06
Iter: 98 loss: 1.84611122e-06
Iter: 99 loss: 1.58593e-06
Iter: 100 loss: 1.56086026e-06
Iter: 101 loss: 1.5635909e-06
Iter: 102 loss: 1.54160034e-06
Iter: 103 loss: 1.51427957e-06
Iter: 104 loss: 1.55538532e-06
Iter: 105 loss: 1.50133076e-06
Iter: 106 loss: 1.47338505e-06
Iter: 107 loss: 1.51008248e-06
Iter: 108 loss: 1.45923036e-06
Iter: 109 loss: 1.43203738e-06
Iter: 110 loss: 1.50584196e-06
Iter: 111 loss: 1.42299825e-06
Iter: 112 loss: 1.39998451e-06
Iter: 113 loss: 1.63966342e-06
Iter: 114 loss: 1.3993108e-06
Iter: 115 loss: 1.38765654e-06
Iter: 116 loss: 1.38764619e-06
Iter: 117 loss: 1.37608265e-06
Iter: 118 loss: 1.3516559e-06
Iter: 119 loss: 1.7517234e-06
Iter: 120 loss: 1.35098674e-06
Iter: 121 loss: 1.33928415e-06
Iter: 122 loss: 1.33818435e-06
Iter: 123 loss: 1.32585342e-06
Iter: 124 loss: 1.32493028e-06
Iter: 125 loss: 1.31575121e-06
Iter: 126 loss: 1.30431317e-06
Iter: 127 loss: 1.30847263e-06
Iter: 128 loss: 1.29630087e-06
Iter: 129 loss: 1.27519331e-06
Iter: 130 loss: 1.34310426e-06
Iter: 131 loss: 1.26924738e-06
Iter: 132 loss: 1.25458541e-06
Iter: 133 loss: 1.28364934e-06
Iter: 134 loss: 1.24854307e-06
Iter: 135 loss: 1.23666359e-06
Iter: 136 loss: 1.26308089e-06
Iter: 137 loss: 1.23213181e-06
Iter: 138 loss: 1.21609332e-06
Iter: 139 loss: 1.29398552e-06
Iter: 140 loss: 1.21326639e-06
Iter: 141 loss: 1.20334414e-06
Iter: 142 loss: 1.19085189e-06
Iter: 143 loss: 1.18984144e-06
Iter: 144 loss: 1.17373384e-06
Iter: 145 loss: 1.18342143e-06
Iter: 146 loss: 1.1633955e-06
Iter: 147 loss: 1.14637692e-06
Iter: 148 loss: 1.37895381e-06
Iter: 149 loss: 1.14632712e-06
Iter: 150 loss: 1.13694091e-06
Iter: 151 loss: 1.21975313e-06
Iter: 152 loss: 1.13647434e-06
Iter: 153 loss: 1.12607722e-06
Iter: 154 loss: 1.14234194e-06
Iter: 155 loss: 1.12119267e-06
Iter: 156 loss: 1.11479198e-06
Iter: 157 loss: 1.12465386e-06
Iter: 158 loss: 1.11175495e-06
Iter: 159 loss: 1.10307064e-06
Iter: 160 loss: 1.15195542e-06
Iter: 161 loss: 1.10193741e-06
Iter: 162 loss: 1.09511052e-06
Iter: 163 loss: 1.08751078e-06
Iter: 164 loss: 1.08646213e-06
Iter: 165 loss: 1.07584833e-06
Iter: 166 loss: 1.12658176e-06
Iter: 167 loss: 1.07401229e-06
Iter: 168 loss: 1.06262598e-06
Iter: 169 loss: 1.10933979e-06
Iter: 170 loss: 1.06013317e-06
Iter: 171 loss: 1.05360846e-06
Iter: 172 loss: 1.04562901e-06
Iter: 173 loss: 1.04489357e-06
Iter: 174 loss: 1.03705133e-06
Iter: 175 loss: 1.03687796e-06
Iter: 176 loss: 1.03006403e-06
Iter: 177 loss: 1.03266132e-06
Iter: 178 loss: 1.02531055e-06
Iter: 179 loss: 1.01797662e-06
Iter: 180 loss: 1.02007675e-06
Iter: 181 loss: 1.01278079e-06
Iter: 182 loss: 1.00221303e-06
Iter: 183 loss: 9.9444992e-07
Iter: 184 loss: 9.90937565e-07
Iter: 185 loss: 9.8598548e-07
Iter: 186 loss: 9.84877374e-07
Iter: 187 loss: 9.77960894e-07
Iter: 188 loss: 9.93307594e-07
Iter: 189 loss: 9.75301305e-07
Iter: 190 loss: 9.67463e-07
Iter: 191 loss: 9.62944796e-07
Iter: 192 loss: 9.59655836e-07
Iter: 193 loss: 9.56493068e-07
Iter: 194 loss: 9.54968e-07
Iter: 195 loss: 9.51759944e-07
Iter: 196 loss: 9.46681325e-07
Iter: 197 loss: 9.46592877e-07
Iter: 198 loss: 9.40935251e-07
Iter: 199 loss: 9.44947828e-07
Iter: 200 loss: 9.37393395e-07
Iter: 201 loss: 9.29039516e-07
Iter: 202 loss: 9.98170094e-07
Iter: 203 loss: 9.28512122e-07
Iter: 204 loss: 9.23713912e-07
Iter: 205 loss: 9.25343329e-07
Iter: 206 loss: 9.20247658e-07
Iter: 207 loss: 9.13992494e-07
Iter: 208 loss: 9.18687647e-07
Iter: 209 loss: 9.10160679e-07
Iter: 210 loss: 9.0424976e-07
Iter: 211 loss: 9.0422418e-07
Iter: 212 loss: 8.9964044e-07
Iter: 213 loss: 8.89656519e-07
Iter: 214 loss: 1.03981404e-06
Iter: 215 loss: 8.89232183e-07
Iter: 216 loss: 8.81190431e-07
Iter: 217 loss: 9.35539e-07
Iter: 218 loss: 8.80343407e-07
Iter: 219 loss: 8.74128716e-07
Iter: 220 loss: 9.00710518e-07
Iter: 221 loss: 8.72780049e-07
Iter: 222 loss: 8.70241934e-07
Iter: 223 loss: 8.69758e-07
Iter: 224 loss: 8.6728312e-07
Iter: 225 loss: 8.62264471e-07
Iter: 226 loss: 9.49824482e-07
Iter: 227 loss: 8.62116963e-07
Iter: 228 loss: 8.58467388e-07
Iter: 229 loss: 9.13799e-07
Iter: 230 loss: 8.58476142e-07
Iter: 231 loss: 8.54370739e-07
Iter: 232 loss: 8.52547032e-07
Iter: 233 loss: 8.50474066e-07
Iter: 234 loss: 8.46699891e-07
Iter: 235 loss: 8.47268439e-07
Iter: 236 loss: 8.43860391e-07
Iter: 237 loss: 8.39288418e-07
Iter: 238 loss: 8.9470592e-07
Iter: 239 loss: 8.39208269e-07
Iter: 240 loss: 8.35543347e-07
Iter: 241 loss: 8.41659812e-07
Iter: 242 loss: 8.33804847e-07
Iter: 243 loss: 8.30305225e-07
Iter: 244 loss: 8.24922836e-07
Iter: 245 loss: 8.24832455e-07
Iter: 246 loss: 8.22438267e-07
Iter: 247 loss: 8.21503079e-07
Iter: 248 loss: 8.18594515e-07
Iter: 249 loss: 8.17489934e-07
Iter: 250 loss: 8.15907413e-07
Iter: 251 loss: 8.1151e-07
Iter: 252 loss: 8.12539724e-07
Iter: 253 loss: 8.08289542e-07
Iter: 254 loss: 8.02664431e-07
Iter: 255 loss: 8.12738904e-07
Iter: 256 loss: 8.00187536e-07
Iter: 257 loss: 7.9609606e-07
Iter: 258 loss: 8.27521376e-07
Iter: 259 loss: 7.95765459e-07
Iter: 260 loss: 7.91469915e-07
Iter: 261 loss: 8.22383186e-07
Iter: 262 loss: 7.91123512e-07
Iter: 263 loss: 7.88689476e-07
Iter: 264 loss: 7.88769057e-07
Iter: 265 loss: 7.8679841e-07
Iter: 266 loss: 7.84460099e-07
Iter: 267 loss: 8.11037069e-07
Iter: 268 loss: 7.84447252e-07
Iter: 269 loss: 7.81886911e-07
Iter: 270 loss: 7.7687929e-07
Iter: 271 loss: 8.7306222e-07
Iter: 272 loss: 7.76795616e-07
Iter: 273 loss: 7.73093689e-07
Iter: 274 loss: 7.81706092e-07
Iter: 275 loss: 7.71712507e-07
Iter: 276 loss: 7.69408757e-07
Iter: 277 loss: 7.69253461e-07
Iter: 278 loss: 7.67038046e-07
Iter: 279 loss: 7.62927129e-07
Iter: 280 loss: 8.55505334e-07
Iter: 281 loss: 7.62889954e-07
Iter: 282 loss: 7.58919896e-07
Iter: 283 loss: 7.84833105e-07
Iter: 284 loss: 7.58534952e-07
Iter: 285 loss: 7.56051918e-07
Iter: 286 loss: 7.73072543e-07
Iter: 287 loss: 7.55778728e-07
Iter: 288 loss: 7.53087647e-07
Iter: 289 loss: 7.559305e-07
Iter: 290 loss: 7.51563562e-07
Iter: 291 loss: 7.48792104e-07
Iter: 292 loss: 7.44699e-07
Iter: 293 loss: 7.44589897e-07
Iter: 294 loss: 7.41628583e-07
Iter: 295 loss: 7.41612382e-07
Iter: 296 loss: 7.39410268e-07
Iter: 297 loss: 7.52471124e-07
Iter: 298 loss: 7.39178745e-07
Iter: 299 loss: 7.36323273e-07
Iter: 300 loss: 7.33108948e-07
Iter: 301 loss: 7.32634135e-07
Iter: 302 loss: 7.30420766e-07
Iter: 303 loss: 7.50928507e-07
Iter: 304 loss: 7.30349029e-07
Iter: 305 loss: 7.27893962e-07
Iter: 306 loss: 7.31500108e-07
Iter: 307 loss: 7.26732139e-07
Iter: 308 loss: 7.24126153e-07
Iter: 309 loss: 7.21557399e-07
Iter: 310 loss: 7.20994365e-07
Iter: 311 loss: 7.17994453e-07
Iter: 312 loss: 7.33978936e-07
Iter: 313 loss: 7.17485534e-07
Iter: 314 loss: 7.15357601e-07
Iter: 315 loss: 7.43470594e-07
Iter: 316 loss: 7.15362489e-07
Iter: 317 loss: 7.13222107e-07
Iter: 318 loss: 7.09608571e-07
Iter: 319 loss: 7.09601e-07
Iter: 320 loss: 7.06570802e-07
Iter: 321 loss: 7.14436396e-07
Iter: 322 loss: 7.05538e-07
Iter: 323 loss: 7.03194701e-07
Iter: 324 loss: 7.03120293e-07
Iter: 325 loss: 7.01557951e-07
Iter: 326 loss: 6.9909953e-07
Iter: 327 loss: 6.99069687e-07
Iter: 328 loss: 6.95508e-07
Iter: 329 loss: 6.99754423e-07
Iter: 330 loss: 6.93594359e-07
Iter: 331 loss: 6.9151622e-07
Iter: 332 loss: 6.91495188e-07
Iter: 333 loss: 6.89161254e-07
Iter: 334 loss: 6.91191417e-07
Iter: 335 loss: 6.87765805e-07
Iter: 336 loss: 6.86150088e-07
Iter: 337 loss: 6.86653607e-07
Iter: 338 loss: 6.850006e-07
Iter: 339 loss: 6.82680479e-07
Iter: 340 loss: 7.03825094e-07
Iter: 341 loss: 6.82581856e-07
Iter: 342 loss: 6.80857738e-07
Iter: 343 loss: 6.80639e-07
Iter: 344 loss: 6.79385494e-07
Iter: 345 loss: 6.77684852e-07
Iter: 346 loss: 6.76788432e-07
Iter: 347 loss: 6.75978526e-07
Iter: 348 loss: 6.73795057e-07
Iter: 349 loss: 7.02736543e-07
Iter: 350 loss: 6.73744921e-07
Iter: 351 loss: 6.71537805e-07
Iter: 352 loss: 6.73665227e-07
Iter: 353 loss: 6.70248482e-07
Iter: 354 loss: 6.6799555e-07
Iter: 355 loss: 6.71046223e-07
Iter: 356 loss: 6.66886933e-07
Iter: 357 loss: 6.64824597e-07
Iter: 358 loss: 6.68076041e-07
Iter: 359 loss: 6.63788342e-07
Iter: 360 loss: 6.60618866e-07
Iter: 361 loss: 6.77775461e-07
Iter: 362 loss: 6.60165142e-07
Iter: 363 loss: 6.58685053e-07
Iter: 364 loss: 6.5619156e-07
Iter: 365 loss: 6.56216912e-07
Iter: 366 loss: 6.54225289e-07
Iter: 367 loss: 6.54169583e-07
Iter: 368 loss: 6.52488325e-07
Iter: 369 loss: 6.63027492e-07
Iter: 370 loss: 6.52301082e-07
Iter: 371 loss: 6.51198434e-07
Iter: 372 loss: 6.48899345e-07
Iter: 373 loss: 6.90331035e-07
Iter: 374 loss: 6.4889332e-07
Iter: 375 loss: 6.46936712e-07
Iter: 376 loss: 6.46936257e-07
Iter: 377 loss: 6.45055593e-07
Iter: 378 loss: 6.43969145e-07
Iter: 379 loss: 6.43159183e-07
Iter: 380 loss: 6.41676934e-07
Iter: 381 loss: 6.4015012e-07
Iter: 382 loss: 6.39865107e-07
Iter: 383 loss: 6.36975244e-07
Iter: 384 loss: 6.6272753e-07
Iter: 385 loss: 6.36812501e-07
Iter: 386 loss: 6.35427398e-07
Iter: 387 loss: 6.35432912e-07
Iter: 388 loss: 6.34579635e-07
Iter: 389 loss: 6.32494903e-07
Iter: 390 loss: 6.53352913e-07
Iter: 391 loss: 6.32217734e-07
Iter: 392 loss: 6.29863962e-07
Iter: 393 loss: 6.5020447e-07
Iter: 394 loss: 6.29736633e-07
Iter: 395 loss: 6.27640816e-07
Iter: 396 loss: 6.41124245e-07
Iter: 397 loss: 6.27419581e-07
Iter: 398 loss: 6.26132874e-07
Iter: 399 loss: 6.25163807e-07
Iter: 400 loss: 6.24779034e-07
Iter: 401 loss: 6.22655875e-07
Iter: 402 loss: 6.27839313e-07
Iter: 403 loss: 6.21925437e-07
Iter: 404 loss: 6.21297261e-07
Iter: 405 loss: 6.20912488e-07
Iter: 406 loss: 6.20232811e-07
Iter: 407 loss: 6.184315e-07
Iter: 408 loss: 6.30114528e-07
Iter: 409 loss: 6.18012564e-07
Iter: 410 loss: 6.16965963e-07
Iter: 411 loss: 6.1690929e-07
Iter: 412 loss: 6.15643046e-07
Iter: 413 loss: 6.15187901e-07
Iter: 414 loss: 6.14456781e-07
Iter: 415 loss: 6.12918711e-07
Iter: 416 loss: 6.12222038e-07
Iter: 417 loss: 6.11437599e-07
Iter: 418 loss: 6.09058e-07
Iter: 419 loss: 6.13747432e-07
Iter: 420 loss: 6.08085543e-07
Iter: 421 loss: 6.06981303e-07
Iter: 422 loss: 6.06793037e-07
Iter: 423 loss: 6.05727848e-07
Iter: 424 loss: 6.0559438e-07
Iter: 425 loss: 6.04787e-07
Iter: 426 loss: 6.03614353e-07
Iter: 427 loss: 6.02870841e-07
Iter: 428 loss: 6.02396653e-07
Iter: 429 loss: 6.00715452e-07
Iter: 430 loss: 6.21204379e-07
Iter: 431 loss: 6.00685439e-07
Iter: 432 loss: 5.99498776e-07
Iter: 433 loss: 6.06217441e-07
Iter: 434 loss: 5.99359453e-07
Iter: 435 loss: 5.98302677e-07
Iter: 436 loss: 5.9600336e-07
Iter: 437 loss: 6.32294757e-07
Iter: 438 loss: 5.95911e-07
Iter: 439 loss: 5.9529134e-07
Iter: 440 loss: 5.94866719e-07
Iter: 441 loss: 5.93766345e-07
Iter: 442 loss: 5.93684206e-07
Iter: 443 loss: 5.92836273e-07
Iter: 444 loss: 5.91449805e-07
Iter: 445 loss: 5.91574349e-07
Iter: 446 loss: 5.90370632e-07
Iter: 447 loss: 5.8960137e-07
Iter: 448 loss: 5.89518777e-07
Iter: 449 loss: 5.8866317e-07
Iter: 450 loss: 5.87235775e-07
Iter: 451 loss: 5.87239242e-07
Iter: 452 loss: 5.85850898e-07
Iter: 453 loss: 5.84966074e-07
Iter: 454 loss: 5.84409747e-07
Iter: 455 loss: 5.82642031e-07
Iter: 456 loss: 6.02554451e-07
Iter: 457 loss: 5.82625319e-07
Iter: 458 loss: 5.81131303e-07
Iter: 459 loss: 5.90221134e-07
Iter: 460 loss: 5.8099539e-07
Iter: 461 loss: 5.79539e-07
Iter: 462 loss: 5.80996e-07
Iter: 463 loss: 5.78739559e-07
Iter: 464 loss: 5.77692617e-07
Iter: 465 loss: 5.76273635e-07
Iter: 466 loss: 5.7620764e-07
Iter: 467 loss: 5.75028e-07
Iter: 468 loss: 5.74855676e-07
Iter: 469 loss: 5.73852844e-07
Iter: 470 loss: 5.72100362e-07
Iter: 471 loss: 5.72104739e-07
Iter: 472 loss: 5.70681721e-07
Iter: 473 loss: 5.81349468e-07
Iter: 474 loss: 5.70553198e-07
Iter: 475 loss: 5.6943037e-07
Iter: 476 loss: 5.697608e-07
Iter: 477 loss: 5.68582e-07
Iter: 478 loss: 5.67067559e-07
Iter: 479 loss: 5.69249e-07
Iter: 480 loss: 5.66276924e-07
Iter: 481 loss: 5.65634309e-07
Iter: 482 loss: 5.65230778e-07
Iter: 483 loss: 5.64522793e-07
Iter: 484 loss: 5.63288722e-07
Iter: 485 loss: 5.63277524e-07
Iter: 486 loss: 5.61946e-07
Iter: 487 loss: 5.63888648e-07
Iter: 488 loss: 5.61299601e-07
Iter: 489 loss: 5.60722924e-07
Iter: 490 loss: 5.60667331e-07
Iter: 491 loss: 5.59898297e-07
Iter: 492 loss: 5.58193506e-07
Iter: 493 loss: 5.81654945e-07
Iter: 494 loss: 5.58118757e-07
Iter: 495 loss: 5.57074031e-07
Iter: 496 loss: 5.64470213e-07
Iter: 497 loss: 5.56987857e-07
Iter: 498 loss: 5.55958422e-07
Iter: 499 loss: 5.5488249e-07
Iter: 500 loss: 5.54686778e-07
Iter: 501 loss: 5.5303525e-07
Iter: 502 loss: 5.58732381e-07
Iter: 503 loss: 5.52592269e-07
Iter: 504 loss: 5.51396283e-07
Iter: 505 loss: 5.70303882e-07
Iter: 506 loss: 5.51409073e-07
Iter: 507 loss: 5.50062111e-07
Iter: 508 loss: 5.51146456e-07
Iter: 509 loss: 5.49278866e-07
Iter: 510 loss: 5.48157118e-07
Iter: 511 loss: 5.49994525e-07
Iter: 512 loss: 5.47680429e-07
Iter: 513 loss: 5.46508829e-07
Iter: 514 loss: 5.47645413e-07
Iter: 515 loss: 5.45878947e-07
Iter: 516 loss: 5.44849797e-07
Iter: 517 loss: 5.44812224e-07
Iter: 518 loss: 5.44135446e-07
Iter: 519 loss: 5.43083331e-07
Iter: 520 loss: 5.4306372e-07
Iter: 521 loss: 5.42240343e-07
Iter: 522 loss: 5.46560273e-07
Iter: 523 loss: 5.42113753e-07
Iter: 524 loss: 5.41269173e-07
Iter: 525 loss: 5.49098729e-07
Iter: 526 loss: 5.4124547e-07
Iter: 527 loss: 5.40505653e-07
Iter: 528 loss: 5.39421535e-07
Iter: 529 loss: 5.39386861e-07
Iter: 530 loss: 5.38490553e-07
Iter: 531 loss: 5.40789e-07
Iter: 532 loss: 5.38153529e-07
Iter: 533 loss: 5.37223798e-07
Iter: 534 loss: 5.49468041e-07
Iter: 535 loss: 5.37215783e-07
Iter: 536 loss: 5.36417588e-07
Iter: 537 loss: 5.35036293e-07
Iter: 538 loss: 5.35013555e-07
Iter: 539 loss: 5.33923185e-07
Iter: 540 loss: 5.42100338e-07
Iter: 541 loss: 5.33845821e-07
Iter: 542 loss: 5.33066554e-07
Iter: 543 loss: 5.32455829e-07
Iter: 544 loss: 5.3218173e-07
Iter: 545 loss: 5.31793489e-07
Iter: 546 loss: 5.31494265e-07
Iter: 547 loss: 5.31023204e-07
Iter: 548 loss: 5.2986e-07
Iter: 549 loss: 5.44320073e-07
Iter: 550 loss: 5.29762758e-07
Iter: 551 loss: 5.28572571e-07
Iter: 552 loss: 5.33809043e-07
Iter: 553 loss: 5.28321493e-07
Iter: 554 loss: 5.27411203e-07
Iter: 555 loss: 5.35205686e-07
Iter: 556 loss: 5.27332872e-07
Iter: 557 loss: 5.2644333e-07
Iter: 558 loss: 5.283365e-07
Iter: 559 loss: 5.26100393e-07
Iter: 560 loss: 5.25270252e-07
Iter: 561 loss: 5.24743e-07
Iter: 562 loss: 5.24428174e-07
Iter: 563 loss: 5.24126904e-07
Iter: 564 loss: 5.23820859e-07
Iter: 565 loss: 5.23405674e-07
Iter: 566 loss: 5.22309165e-07
Iter: 567 loss: 5.30276679e-07
Iter: 568 loss: 5.22073833e-07
Iter: 569 loss: 5.21071627e-07
Iter: 570 loss: 5.35594836e-07
Iter: 571 loss: 5.21071115e-07
Iter: 572 loss: 5.20269509e-07
Iter: 573 loss: 5.25038502e-07
Iter: 574 loss: 5.20173273e-07
Iter: 575 loss: 5.19584773e-07
Iter: 576 loss: 5.18526463e-07
Iter: 577 loss: 5.42160819e-07
Iter: 578 loss: 5.18521119e-07
Iter: 579 loss: 5.17491912e-07
Iter: 580 loss: 5.21306617e-07
Iter: 581 loss: 5.17223384e-07
Iter: 582 loss: 5.1659913e-07
Iter: 583 loss: 5.16592763e-07
Iter: 584 loss: 5.16038199e-07
Iter: 585 loss: 5.17319e-07
Iter: 586 loss: 5.15834586e-07
Iter: 587 loss: 5.15229885e-07
Iter: 588 loss: 5.14274348e-07
Iter: 589 loss: 5.14285603e-07
Iter: 590 loss: 5.13223199e-07
Iter: 591 loss: 5.18284253e-07
Iter: 592 loss: 5.13029931e-07
Iter: 593 loss: 5.12208771e-07
Iter: 594 loss: 5.23999802e-07
Iter: 595 loss: 5.12191832e-07
Iter: 596 loss: 5.11564963e-07
Iter: 597 loss: 5.11432233e-07
Iter: 598 loss: 5.10992777e-07
Iter: 599 loss: 5.10100278e-07
Iter: 600 loss: 5.13117243e-07
Iter: 601 loss: 5.09868869e-07
Iter: 602 loss: 5.08789071e-07
Iter: 603 loss: 5.14319765e-07
Iter: 604 loss: 5.08626158e-07
Iter: 605 loss: 5.08087624e-07
Iter: 606 loss: 5.06868901e-07
Iter: 607 loss: 5.23928065e-07
Iter: 608 loss: 5.06813592e-07
Iter: 609 loss: 5.06774484e-07
Iter: 610 loss: 5.06339063e-07
Iter: 611 loss: 5.05935873e-07
Iter: 612 loss: 5.05963783e-07
Iter: 613 loss: 5.05604589e-07
Iter: 614 loss: 5.05114372e-07
Iter: 615 loss: 5.04294576e-07
Iter: 616 loss: 5.04276272e-07
Iter: 617 loss: 5.0320449e-07
Iter: 618 loss: 5.07946e-07
Iter: 619 loss: 5.02992748e-07
Iter: 620 loss: 5.02272428e-07
Iter: 621 loss: 5.09452661e-07
Iter: 622 loss: 5.02272e-07
Iter: 623 loss: 5.01456384e-07
Iter: 624 loss: 5.0141017e-07
Iter: 625 loss: 5.00796659e-07
Iter: 626 loss: 4.99916325e-07
Iter: 627 loss: 5.02219336e-07
Iter: 628 loss: 4.9963694e-07
Iter: 629 loss: 4.98920656e-07
Iter: 630 loss: 5.02034425e-07
Iter: 631 loss: 4.98759732e-07
Iter: 632 loss: 4.9791123e-07
Iter: 633 loss: 5.00823205e-07
Iter: 634 loss: 4.97689086e-07
Iter: 635 loss: 4.97223596e-07
Iter: 636 loss: 4.98812938e-07
Iter: 637 loss: 4.97085466e-07
Iter: 638 loss: 4.96377311e-07
Iter: 639 loss: 4.96891175e-07
Iter: 640 loss: 4.95966901e-07
Iter: 641 loss: 4.95333268e-07
Iter: 642 loss: 4.94291385e-07
Iter: 643 loss: 4.94286212e-07
Iter: 644 loss: 4.93858408e-07
Iter: 645 loss: 4.93687e-07
Iter: 646 loss: 4.93169807e-07
Iter: 647 loss: 4.93981929e-07
Iter: 648 loss: 4.92907247e-07
Iter: 649 loss: 4.92329946e-07
Iter: 650 loss: 4.91498213e-07
Iter: 651 loss: 4.91477238e-07
Iter: 652 loss: 4.90361231e-07
Iter: 653 loss: 4.91632e-07
Iter: 654 loss: 4.89787794e-07
Iter: 655 loss: 4.89209583e-07
Iter: 656 loss: 4.89163369e-07
Iter: 657 loss: 4.88685032e-07
Iter: 658 loss: 4.91205128e-07
Iter: 659 loss: 4.8858152e-07
Iter: 660 loss: 4.8804776e-07
Iter: 661 loss: 4.87653097e-07
Iter: 662 loss: 4.87460397e-07
Iter: 663 loss: 4.86945623e-07
Iter: 664 loss: 4.88873638e-07
Iter: 665 loss: 4.8678794e-07
Iter: 666 loss: 4.86169e-07
Iter: 667 loss: 4.90242428e-07
Iter: 668 loss: 4.86098e-07
Iter: 669 loss: 4.85654368e-07
Iter: 670 loss: 4.86130034e-07
Iter: 671 loss: 4.85409657e-07
Iter: 672 loss: 4.84746522e-07
Iter: 673 loss: 4.86914757e-07
Iter: 674 loss: 4.84572297e-07
Iter: 675 loss: 4.84031489e-07
Iter: 676 loss: 4.83663371e-07
Iter: 677 loss: 4.8347448e-07
Iter: 678 loss: 4.82595567e-07
Iter: 679 loss: 4.8289246e-07
Iter: 680 loss: 4.81980578e-07
Iter: 681 loss: 4.81467e-07
Iter: 682 loss: 4.81274469e-07
Iter: 683 loss: 4.81000427e-07
Iter: 684 loss: 4.80461381e-07
Iter: 685 loss: 4.9093785e-07
Iter: 686 loss: 4.80448421e-07
Iter: 687 loss: 4.79877372e-07
Iter: 688 loss: 4.81199038e-07
Iter: 689 loss: 4.79690925e-07
Iter: 690 loss: 4.790557e-07
Iter: 691 loss: 4.79911193e-07
Iter: 692 loss: 4.78754089e-07
Iter: 693 loss: 4.78038146e-07
Iter: 694 loss: 4.80098379e-07
Iter: 695 loss: 4.77792071e-07
Iter: 696 loss: 4.77153208e-07
Iter: 697 loss: 4.7716037e-07
Iter: 698 loss: 4.76770197e-07
Iter: 699 loss: 4.75908394e-07
Iter: 700 loss: 4.90935918e-07
Iter: 701 loss: 4.7589117e-07
Iter: 702 loss: 4.74667132e-07
Iter: 703 loss: 4.76943683e-07
Iter: 704 loss: 4.74134026e-07
Iter: 705 loss: 4.73892783e-07
Iter: 706 loss: 4.73642274e-07
Iter: 707 loss: 4.732143e-07
Iter: 708 loss: 4.72664652e-07
Iter: 709 loss: 4.72610026e-07
Iter: 710 loss: 4.72141807e-07
Iter: 711 loss: 4.74671879e-07
Iter: 712 loss: 4.72093888e-07
Iter: 713 loss: 4.71587015e-07
Iter: 714 loss: 4.72913968e-07
Iter: 715 loss: 4.71412278e-07
Iter: 716 loss: 4.71039954e-07
Iter: 717 loss: 4.71112116e-07
Iter: 718 loss: 4.70764917e-07
Iter: 719 loss: 4.70273619e-07
Iter: 720 loss: 4.75651689e-07
Iter: 721 loss: 4.70238462e-07
Iter: 722 loss: 4.69756287e-07
Iter: 723 loss: 4.69168072e-07
Iter: 724 loss: 4.69124217e-07
Iter: 725 loss: 4.68396451e-07
Iter: 726 loss: 4.68541202e-07
Iter: 727 loss: 4.67851e-07
Iter: 728 loss: 4.66965901e-07
Iter: 729 loss: 4.70509377e-07
Iter: 730 loss: 4.66786474e-07
Iter: 731 loss: 4.65786258e-07
Iter: 732 loss: 4.67735788e-07
Iter: 733 loss: 4.65413336e-07
Iter: 734 loss: 4.64812672e-07
Iter: 735 loss: 4.65738793e-07
Iter: 736 loss: 4.64518394e-07
Iter: 737 loss: 4.63955047e-07
Iter: 738 loss: 4.72250349e-07
Iter: 739 loss: 4.63931855e-07
Iter: 740 loss: 4.63576441e-07
Iter: 741 loss: 4.67501678e-07
Iter: 742 loss: 4.63560298e-07
Iter: 743 loss: 4.63283357e-07
Iter: 744 loss: 4.62884884e-07
Iter: 745 loss: 4.62868826e-07
Iter: 746 loss: 4.62319377e-07
Iter: 747 loss: 4.68629935e-07
Iter: 748 loss: 4.62308037e-07
Iter: 749 loss: 4.61899162e-07
Iter: 750 loss: 4.61098693e-07
Iter: 751 loss: 4.77710159e-07
Iter: 752 loss: 4.61088973e-07
Iter: 753 loss: 4.60440504e-07
Iter: 754 loss: 4.65305561e-07
Iter: 755 loss: 4.60403527e-07
Iter: 756 loss: 4.59692586e-07
Iter: 757 loss: 4.60910769e-07
Iter: 758 loss: 4.59384808e-07
Iter: 759 loss: 4.58826776e-07
Iter: 760 loss: 4.60863646e-07
Iter: 761 loss: 4.58690209e-07
Iter: 762 loss: 4.58451268e-07
Iter: 763 loss: 4.58435295e-07
Iter: 764 loss: 4.58187912e-07
Iter: 765 loss: 4.57751185e-07
Iter: 766 loss: 4.57763633e-07
Iter: 767 loss: 4.57265713e-07
Iter: 768 loss: 4.57340889e-07
Iter: 769 loss: 4.56898476e-07
Iter: 770 loss: 4.56224484e-07
Iter: 771 loss: 4.58412131e-07
Iter: 772 loss: 4.56029824e-07
Iter: 773 loss: 4.55283612e-07
Iter: 774 loss: 4.55838972e-07
Iter: 775 loss: 4.54798908e-07
Iter: 776 loss: 4.54250369e-07
Iter: 777 loss: 4.5424008e-07
Iter: 778 loss: 4.53722862e-07
Iter: 779 loss: 4.56426392e-07
Iter: 780 loss: 4.53614575e-07
Iter: 781 loss: 4.53326038e-07
Iter: 782 loss: 4.54172778e-07
Iter: 783 loss: 4.53238044e-07
Iter: 784 loss: 4.52842812e-07
Iter: 785 loss: 4.52949422e-07
Iter: 786 loss: 4.5254032e-07
Iter: 787 loss: 4.52095946e-07
Iter: 788 loss: 4.52243739e-07
Iter: 789 loss: 4.51773474e-07
Iter: 790 loss: 4.51242499e-07
Iter: 791 loss: 4.51556673e-07
Iter: 792 loss: 4.50913348e-07
Iter: 793 loss: 4.50511379e-07
Iter: 794 loss: 4.50481423e-07
Iter: 795 loss: 4.5013249e-07
Iter: 796 loss: 4.49694653e-07
Iter: 797 loss: 4.49647587e-07
Iter: 798 loss: 4.4927674e-07
Iter: 799 loss: 4.49245192e-07
Iter: 800 loss: 4.48925e-07
Iter: 801 loss: 4.48618835e-07
Iter: 802 loss: 4.4852095e-07
Iter: 803 loss: 4.47977783e-07
Iter: 804 loss: 4.48504807e-07
Iter: 805 loss: 4.47698881e-07
Iter: 806 loss: 4.47148921e-07
Iter: 807 loss: 4.46909723e-07
Iter: 808 loss: 4.46644208e-07
Iter: 809 loss: 4.45822678e-07
Iter: 810 loss: 4.5271355e-07
Iter: 811 loss: 4.45782433e-07
Iter: 812 loss: 4.45328226e-07
Iter: 813 loss: 4.49503659e-07
Iter: 814 loss: 4.45318221e-07
Iter: 815 loss: 4.44921682e-07
Iter: 816 loss: 4.47422622e-07
Iter: 817 loss: 4.44859e-07
Iter: 818 loss: 4.44598214e-07
Iter: 819 loss: 4.44345e-07
Iter: 820 loss: 4.44307261e-07
Iter: 821 loss: 4.43796637e-07
Iter: 822 loss: 4.47359241e-07
Iter: 823 loss: 4.4374076e-07
Iter: 824 loss: 4.43453132e-07
Iter: 825 loss: 4.428897e-07
Iter: 826 loss: 4.55993586e-07
Iter: 827 loss: 4.42883902e-07
Iter: 828 loss: 4.42251775e-07
Iter: 829 loss: 4.46737772e-07
Iter: 830 loss: 4.42208375e-07
Iter: 831 loss: 4.41887664e-07
Iter: 832 loss: 4.47094976e-07
Iter: 833 loss: 4.4189e-07
Iter: 834 loss: 4.41599809e-07
Iter: 835 loss: 4.41163365e-07
Iter: 836 loss: 4.4115518e-07
Iter: 837 loss: 4.40848453e-07
Iter: 838 loss: 4.40829524e-07
Iter: 839 loss: 4.4059334e-07
Iter: 840 loss: 4.40222777e-07
Iter: 841 loss: 4.40240854e-07
Iter: 842 loss: 4.39727671e-07
Iter: 843 loss: 4.39778489e-07
Iter: 844 loss: 4.39366602e-07
Iter: 845 loss: 4.38677233e-07
Iter: 846 loss: 4.4037813e-07
Iter: 847 loss: 4.38381534e-07
Iter: 848 loss: 4.37769529e-07
Iter: 849 loss: 4.39067634e-07
Iter: 850 loss: 4.37500717e-07
Iter: 851 loss: 4.36771643e-07
Iter: 852 loss: 4.3977596e-07
Iter: 853 loss: 4.36596736e-07
Iter: 854 loss: 4.36184735e-07
Iter: 855 loss: 4.36160462e-07
Iter: 856 loss: 4.35801212e-07
Iter: 857 loss: 4.36741516e-07
Iter: 858 loss: 4.35679254e-07
Iter: 859 loss: 4.35426927e-07
Iter: 860 loss: 4.34824074e-07
Iter: 861 loss: 4.40441312e-07
Iter: 862 loss: 4.34748813e-07
Iter: 863 loss: 4.34294577e-07
Iter: 864 loss: 4.34243304e-07
Iter: 865 loss: 4.3392896e-07
Iter: 866 loss: 4.33949594e-07
Iter: 867 loss: 4.33737171e-07
Iter: 868 loss: 4.33415693e-07
Iter: 869 loss: 4.33472849e-07
Iter: 870 loss: 4.33157879e-07
Iter: 871 loss: 4.32786493e-07
Iter: 872 loss: 4.38329494e-07
Iter: 873 loss: 4.32799197e-07
Iter: 874 loss: 4.32428578e-07
Iter: 875 loss: 4.32334048e-07
Iter: 876 loss: 4.32101984e-07
Iter: 877 loss: 4.31812907e-07
Iter: 878 loss: 4.32835805e-07
Iter: 879 loss: 4.31725596e-07
Iter: 880 loss: 4.31297053e-07
Iter: 881 loss: 4.31443624e-07
Iter: 882 loss: 4.30967191e-07
Iter: 883 loss: 4.30442526e-07
Iter: 884 loss: 4.31297337e-07
Iter: 885 loss: 4.30157286e-07
Iter: 886 loss: 4.29744944e-07
Iter: 887 loss: 4.29653227e-07
Iter: 888 loss: 4.29361819e-07
Iter: 889 loss: 4.28917303e-07
Iter: 890 loss: 4.28907811e-07
Iter: 891 loss: 4.28588066e-07
Iter: 892 loss: 4.31308024e-07
Iter: 893 loss: 4.28569678e-07
Iter: 894 loss: 4.28317094e-07
Iter: 895 loss: 4.27890569e-07
Iter: 896 loss: 4.27876671e-07
Iter: 897 loss: 4.27387818e-07
Iter: 898 loss: 4.2865156e-07
Iter: 899 loss: 4.27217088e-07
Iter: 900 loss: 4.26854172e-07
Iter: 901 loss: 4.26851329e-07
Iter: 902 loss: 4.26628077e-07
Iter: 903 loss: 4.26156078e-07
Iter: 904 loss: 4.31366516e-07
Iter: 905 loss: 4.26113957e-07
Iter: 906 loss: 4.25527503e-07
Iter: 907 loss: 4.29551164e-07
Iter: 908 loss: 4.25459035e-07
Iter: 909 loss: 4.25051098e-07
Iter: 910 loss: 4.31538126e-07
Iter: 911 loss: 4.25041549e-07
Iter: 912 loss: 4.24789846e-07
Iter: 913 loss: 4.24495681e-07
Iter: 914 loss: 4.2449048e-07
Iter: 915 loss: 4.24134e-07
Iter: 916 loss: 4.25821781e-07
Iter: 917 loss: 4.24061113e-07
Iter: 918 loss: 4.23617792e-07
Iter: 919 loss: 4.23924632e-07
Iter: 920 loss: 4.23316862e-07
Iter: 921 loss: 4.22963069e-07
Iter: 922 loss: 4.23291908e-07
Iter: 923 loss: 4.22741039e-07
Iter: 924 loss: 4.22305675e-07
Iter: 925 loss: 4.22879964e-07
Iter: 926 loss: 4.2206014e-07
Iter: 927 loss: 4.2169475e-07
Iter: 928 loss: 4.21687162e-07
Iter: 929 loss: 4.21329844e-07
Iter: 930 loss: 4.21929542e-07
Iter: 931 loss: 4.21154169e-07
Iter: 932 loss: 4.20900676e-07
Iter: 933 loss: 4.20463891e-07
Iter: 934 loss: 4.20472702e-07
Iter: 935 loss: 4.19896708e-07
Iter: 936 loss: 4.23589199e-07
Iter: 937 loss: 4.19813375e-07
Iter: 938 loss: 4.19455887e-07
Iter: 939 loss: 4.25206451e-07
Iter: 940 loss: 4.19461742e-07
Iter: 941 loss: 4.19250028e-07
Iter: 942 loss: 4.1886733e-07
Iter: 943 loss: 4.18857354e-07
Iter: 944 loss: 4.18516208e-07
Iter: 945 loss: 4.22440223e-07
Iter: 946 loss: 4.18513878e-07
Iter: 947 loss: 4.18113984e-07
Iter: 948 loss: 4.18522802e-07
Iter: 949 loss: 4.17904715e-07
Iter: 950 loss: 4.17611801e-07
Iter: 951 loss: 4.17520852e-07
Iter: 952 loss: 4.17357541e-07
Iter: 953 loss: 4.169205e-07
Iter: 954 loss: 4.20401079e-07
Iter: 955 loss: 4.16880653e-07
Iter: 956 loss: 4.16515661e-07
Iter: 957 loss: 4.17630929e-07
Iter: 958 loss: 4.16404305e-07
Iter: 959 loss: 4.16123328e-07
Iter: 960 loss: 4.15507657e-07
Iter: 961 loss: 4.23897319e-07
Iter: 962 loss: 4.15450188e-07
Iter: 963 loss: 4.14773467e-07
Iter: 964 loss: 4.23553388e-07
Iter: 965 loss: 4.14792112e-07
Iter: 966 loss: 4.14558542e-07
Iter: 967 loss: 4.14536487e-07
Iter: 968 loss: 4.14309113e-07
Iter: 969 loss: 4.14101862e-07
Iter: 970 loss: 4.14064914e-07
Iter: 971 loss: 4.13816252e-07
Iter: 972 loss: 4.13440745e-07
Iter: 973 loss: 4.13412039e-07
Iter: 974 loss: 4.13024679e-07
Iter: 975 loss: 4.13029625e-07
Iter: 976 loss: 4.12679015e-07
Iter: 977 loss: 4.12873817e-07
Iter: 978 loss: 4.12445047e-07
Iter: 979 loss: 4.12077327e-07
Iter: 980 loss: 4.12692117e-07
Iter: 981 loss: 4.11911685e-07
Iter: 982 loss: 4.11680901e-07
Iter: 983 loss: 4.11676297e-07
Iter: 984 loss: 4.11472683e-07
Iter: 985 loss: 4.11044255e-07
Iter: 986 loss: 4.11052184e-07
Iter: 987 loss: 4.10729342e-07
Iter: 988 loss: 4.11412742e-07
Iter: 989 loss: 4.10609232e-07
Iter: 990 loss: 4.10241e-07
Iter: 991 loss: 4.14476119e-07
Iter: 992 loss: 4.10223436e-07
Iter: 993 loss: 4.09999217e-07
Iter: 994 loss: 4.09871404e-07
Iter: 995 loss: 4.09773946e-07
Iter: 996 loss: 4.09433e-07
Iter: 997 loss: 4.09525569e-07
Iter: 998 loss: 4.09157053e-07
Iter: 999 loss: 4.09097595e-07
Iter: 1000 loss: 4.08950029e-07
Iter: 1001 loss: 4.08783819e-07
Iter: 1002 loss: 4.08425819e-07
Iter: 1003 loss: 4.1552633e-07
Iter: 1004 loss: 4.08419936e-07
Iter: 1005 loss: 4.08030758e-07
Iter: 1006 loss: 4.08242101e-07
Iter: 1007 loss: 4.07762798e-07
Iter: 1008 loss: 4.07351138e-07
Iter: 1009 loss: 4.10968653e-07
Iter: 1010 loss: 4.07336e-07
Iter: 1011 loss: 4.07065897e-07
Iter: 1012 loss: 4.09996744e-07
Iter: 1013 loss: 4.07049214e-07
Iter: 1014 loss: 4.06816e-07
Iter: 1015 loss: 4.06364506e-07
Iter: 1016 loss: 4.15777066e-07
Iter: 1017 loss: 4.06366723e-07
Iter: 1018 loss: 4.06184711e-07
Iter: 1019 loss: 4.06111468e-07
Iter: 1020 loss: 4.05925164e-07
Iter: 1021 loss: 4.05914705e-07
Iter: 1022 loss: 4.05752303e-07
Iter: 1023 loss: 4.05448077e-07
Iter: 1024 loss: 4.04972411e-07
Iter: 1025 loss: 4.04969171e-07
Iter: 1026 loss: 4.04581186e-07
Iter: 1027 loss: 4.04580106e-07
Iter: 1028 loss: 4.04234811e-07
Iter: 1029 loss: 4.04613189e-07
Iter: 1030 loss: 4.04050809e-07
Iter: 1031 loss: 4.03759316e-07
Iter: 1032 loss: 4.03580401e-07
Iter: 1033 loss: 4.03468675e-07
Iter: 1034 loss: 4.03206656e-07
Iter: 1035 loss: 4.03175392e-07
Iter: 1036 loss: 4.02970045e-07
Iter: 1037 loss: 4.02768592e-07
Iter: 1038 loss: 4.02734827e-07
Iter: 1039 loss: 4.02479543e-07
Iter: 1040 loss: 4.02359746e-07
Iter: 1041 loss: 4.0220246e-07
Iter: 1042 loss: 4.01839344e-07
Iter: 1043 loss: 4.03131025e-07
Iter: 1044 loss: 4.01762e-07
Iter: 1045 loss: 4.01377406e-07
Iter: 1046 loss: 4.06016596e-07
Iter: 1047 loss: 4.01383971e-07
Iter: 1048 loss: 4.01149123e-07
Iter: 1049 loss: 4.00743374e-07
Iter: 1050 loss: 4.09459744e-07
Iter: 1051 loss: 4.00743943e-07
Iter: 1052 loss: 4.00418742e-07
Iter: 1053 loss: 4.00392935e-07
Iter: 1054 loss: 4.00222149e-07
Iter: 1055 loss: 4.00081035e-07
Iter: 1056 loss: 4.00008332e-07
Iter: 1057 loss: 3.99740429e-07
Iter: 1058 loss: 3.99875347e-07
Iter: 1059 loss: 3.99548412e-07
Iter: 1060 loss: 3.99295061e-07
Iter: 1061 loss: 4.03192246e-07
Iter: 1062 loss: 3.99294919e-07
Iter: 1063 loss: 3.99076384e-07
Iter: 1064 loss: 3.98845827e-07
Iter: 1065 loss: 3.98777331e-07
Iter: 1066 loss: 3.98533956e-07
Iter: 1067 loss: 3.99734631e-07
Iter: 1068 loss: 3.98505676e-07
Iter: 1069 loss: 3.98202701e-07
Iter: 1070 loss: 3.99317912e-07
Iter: 1071 loss: 3.98101918e-07
Iter: 1072 loss: 3.97841291e-07
Iter: 1073 loss: 3.9766806e-07
Iter: 1074 loss: 3.97568385e-07
Iter: 1075 loss: 3.97271947e-07
Iter: 1076 loss: 3.96966e-07
Iter: 1077 loss: 3.96916562e-07
Iter: 1078 loss: 3.96389368e-07
Iter: 1079 loss: 4.03425645e-07
Iter: 1080 loss: 3.9640554e-07
Iter: 1081 loss: 3.95987115e-07
Iter: 1082 loss: 3.98692407e-07
Iter: 1083 loss: 3.95959944e-07
Iter: 1084 loss: 3.9578606e-07
Iter: 1085 loss: 3.95730808e-07
Iter: 1086 loss: 3.95591883e-07
Iter: 1087 loss: 3.95334098e-07
Iter: 1088 loss: 3.97398253e-07
Iter: 1089 loss: 3.9531875e-07
Iter: 1090 loss: 3.9497715e-07
Iter: 1091 loss: 3.94654649e-07
Iter: 1092 loss: 3.94613096e-07
Iter: 1093 loss: 3.94346102e-07
Iter: 1094 loss: 3.9469333e-07
Iter: 1095 loss: 3.94216983e-07
Iter: 1096 loss: 3.93890673e-07
Iter: 1097 loss: 3.96934837e-07
Iter: 1098 loss: 3.93864752e-07
Iter: 1099 loss: 3.93564221e-07
Iter: 1100 loss: 3.93607365e-07
Iter: 1101 loss: 3.93326e-07
Iter: 1102 loss: 3.92983026e-07
Iter: 1103 loss: 3.94019082e-07
Iter: 1104 loss: 3.92908191e-07
Iter: 1105 loss: 3.9262477e-07
Iter: 1106 loss: 3.96620237e-07
Iter: 1107 loss: 3.92607831e-07
Iter: 1108 loss: 3.92449067e-07
Iter: 1109 loss: 3.92059093e-07
Iter: 1110 loss: 3.97136773e-07
Iter: 1111 loss: 3.92047525e-07
Iter: 1112 loss: 3.91656556e-07
Iter: 1113 loss: 3.93459231e-07
Iter: 1114 loss: 3.91569614e-07
Iter: 1115 loss: 3.91215451e-07
Iter: 1116 loss: 3.91919798e-07
Iter: 1117 loss: 3.91060041e-07
Iter: 1118 loss: 3.90779803e-07
Iter: 1119 loss: 3.90770822e-07
Iter: 1120 loss: 3.90563429e-07
Iter: 1121 loss: 3.90213302e-07
Iter: 1122 loss: 3.9020739e-07
Iter: 1123 loss: 3.90099331e-07
Iter: 1124 loss: 3.90039474e-07
Iter: 1125 loss: 3.89883326e-07
Iter: 1126 loss: 3.89507335e-07
Iter: 1127 loss: 3.94239123e-07
Iter: 1128 loss: 3.89457597e-07
Iter: 1129 loss: 3.89087973e-07
Iter: 1130 loss: 3.90625758e-07
Iter: 1131 loss: 3.890014e-07
Iter: 1132 loss: 3.88691973e-07
Iter: 1133 loss: 3.89525212e-07
Iter: 1134 loss: 3.88593094e-07
Iter: 1135 loss: 3.88282984e-07
Iter: 1136 loss: 3.90508802e-07
Iter: 1137 loss: 3.88248765e-07
Iter: 1138 loss: 3.88006242e-07
Iter: 1139 loss: 3.87945846e-07
Iter: 1140 loss: 3.87794671e-07
Iter: 1141 loss: 3.87631644e-07
Iter: 1142 loss: 3.87613454e-07
Iter: 1143 loss: 3.87465377e-07
Iter: 1144 loss: 3.87169734e-07
Iter: 1145 loss: 3.91072831e-07
Iter: 1146 loss: 3.87126192e-07
Iter: 1147 loss: 3.86722036e-07
Iter: 1148 loss: 3.87694797e-07
Iter: 1149 loss: 3.86568018e-07
Iter: 1150 loss: 3.8632669e-07
Iter: 1151 loss: 3.87238202e-07
Iter: 1152 loss: 3.86239577e-07
Iter: 1153 loss: 3.85959822e-07
Iter: 1154 loss: 3.88704819e-07
Iter: 1155 loss: 3.85946e-07
Iter: 1156 loss: 3.85726935e-07
Iter: 1157 loss: 3.85525368e-07
Iter: 1158 loss: 3.85483361e-07
Iter: 1159 loss: 3.85224496e-07
Iter: 1160 loss: 3.85242288e-07
Iter: 1161 loss: 3.8507082e-07
Iter: 1162 loss: 3.84822954e-07
Iter: 1163 loss: 3.90949424e-07
Iter: 1164 loss: 3.84820339e-07
Iter: 1165 loss: 3.84459327e-07
Iter: 1166 loss: 3.84564487e-07
Iter: 1167 loss: 3.84191253e-07
Iter: 1168 loss: 3.83830866e-07
Iter: 1169 loss: 3.87645571e-07
Iter: 1170 loss: 3.83837e-07
Iter: 1171 loss: 3.83474458e-07
Iter: 1172 loss: 3.84249489e-07
Iter: 1173 loss: 3.83344485e-07
Iter: 1174 loss: 3.83062172e-07
Iter: 1175 loss: 3.83771209e-07
Iter: 1176 loss: 3.82984581e-07
Iter: 1177 loss: 3.82708038e-07
Iter: 1178 loss: 3.85237172e-07
Iter: 1179 loss: 3.82654378e-07
Iter: 1180 loss: 3.82486888e-07
Iter: 1181 loss: 3.82329347e-07
Iter: 1182 loss: 3.82273242e-07
Iter: 1183 loss: 3.82015173e-07
Iter: 1184 loss: 3.81829977e-07
Iter: 1185 loss: 3.81735674e-07
Iter: 1186 loss: 3.813457e-07
Iter: 1187 loss: 3.83894104e-07
Iter: 1188 loss: 3.81332939e-07
Iter: 1189 loss: 3.81086181e-07
Iter: 1190 loss: 3.81064808e-07
Iter: 1191 loss: 3.80863469e-07
Iter: 1192 loss: 3.80637886e-07
Iter: 1193 loss: 3.80598948e-07
Iter: 1194 loss: 3.80218e-07
Iter: 1195 loss: 3.81646743e-07
Iter: 1196 loss: 3.80127148e-07
Iter: 1197 loss: 3.79784865e-07
Iter: 1198 loss: 3.82565162e-07
Iter: 1199 loss: 3.79770626e-07
Iter: 1200 loss: 3.79593075e-07
Iter: 1201 loss: 3.79235928e-07
Iter: 1202 loss: 3.84080209e-07
Iter: 1203 loss: 3.79203328e-07
Iter: 1204 loss: 3.78868435e-07
Iter: 1205 loss: 3.83243247e-07
Iter: 1206 loss: 3.78861188e-07
Iter: 1207 loss: 3.78597406e-07
Iter: 1208 loss: 3.79828464e-07
Iter: 1209 loss: 3.78552045e-07
Iter: 1210 loss: 3.783083e-07
Iter: 1211 loss: 3.78257823e-07
Iter: 1212 loss: 3.78089879e-07
Iter: 1213 loss: 3.7782732e-07
Iter: 1214 loss: 3.77833857e-07
Iter: 1215 loss: 3.77595541e-07
Iter: 1216 loss: 3.77717242e-07
Iter: 1217 loss: 3.77442774e-07
Iter: 1218 loss: 3.77262381e-07
Iter: 1219 loss: 3.76940761e-07
Iter: 1220 loss: 3.84777536e-07
Iter: 1221 loss: 3.76931609e-07
Iter: 1222 loss: 3.7652427e-07
Iter: 1223 loss: 3.78619063e-07
Iter: 1224 loss: 3.76445371e-07
Iter: 1225 loss: 3.76024616e-07
Iter: 1226 loss: 3.76329865e-07
Iter: 1227 loss: 3.75748868e-07
Iter: 1228 loss: 3.75605651e-07
Iter: 1229 loss: 3.75497223e-07
Iter: 1230 loss: 3.75319757e-07
Iter: 1231 loss: 3.7513945e-07
Iter: 1232 loss: 3.75099319e-07
Iter: 1233 loss: 3.74871576e-07
Iter: 1234 loss: 3.74887577e-07
Iter: 1235 loss: 3.74750016e-07
Iter: 1236 loss: 3.74502804e-07
Iter: 1237 loss: 3.79198241e-07
Iter: 1238 loss: 3.74493283e-07
Iter: 1239 loss: 3.74216938e-07
Iter: 1240 loss: 3.75458768e-07
Iter: 1241 loss: 3.74172771e-07
Iter: 1242 loss: 3.739178e-07
Iter: 1243 loss: 3.75161676e-07
Iter: 1244 loss: 3.73868772e-07
Iter: 1245 loss: 3.73535045e-07
Iter: 1246 loss: 3.74172487e-07
Iter: 1247 loss: 3.73390918e-07
Iter: 1248 loss: 3.73141205e-07
Iter: 1249 loss: 3.73640148e-07
Iter: 1250 loss: 3.73026921e-07
Iter: 1251 loss: 3.72653176e-07
Iter: 1252 loss: 3.75036677e-07
Iter: 1253 loss: 3.72621173e-07
Iter: 1254 loss: 3.7247446e-07
Iter: 1255 loss: 3.72155682e-07
Iter: 1256 loss: 3.76675303e-07
Iter: 1257 loss: 3.72171712e-07
Iter: 1258 loss: 3.71694398e-07
Iter: 1259 loss: 3.72920397e-07
Iter: 1260 loss: 3.71554847e-07
Iter: 1261 loss: 3.71266793e-07
Iter: 1262 loss: 3.72749412e-07
Iter: 1263 loss: 3.71234961e-07
Iter: 1264 loss: 3.70948499e-07
Iter: 1265 loss: 3.71014096e-07
Iter: 1266 loss: 3.70754208e-07
Iter: 1267 loss: 3.70387141e-07
Iter: 1268 loss: 3.73319267e-07
Iter: 1269 loss: 3.70356247e-07
Iter: 1270 loss: 3.70079533e-07
Iter: 1271 loss: 3.73193814e-07
Iter: 1272 loss: 3.70087719e-07
Iter: 1273 loss: 3.69889733e-07
Iter: 1274 loss: 3.69532785e-07
Iter: 1275 loss: 3.77631864e-07
Iter: 1276 loss: 3.69551344e-07
Iter: 1277 loss: 3.69345258e-07
Iter: 1278 loss: 3.69309419e-07
Iter: 1279 loss: 3.69174671e-07
Iter: 1280 loss: 3.68821844e-07
Iter: 1281 loss: 3.72798297e-07
Iter: 1282 loss: 3.68814483e-07
Iter: 1283 loss: 3.68424651e-07
Iter: 1284 loss: 3.70465756e-07
Iter: 1285 loss: 3.68344047e-07
Iter: 1286 loss: 3.68118094e-07
Iter: 1287 loss: 3.68108772e-07
Iter: 1288 loss: 3.67957966e-07
Iter: 1289 loss: 3.67976924e-07
Iter: 1290 loss: 3.67827568e-07
Iter: 1291 loss: 3.67645555e-07
Iter: 1292 loss: 3.69066811e-07
Iter: 1293 loss: 3.67631912e-07
Iter: 1294 loss: 3.6747042e-07
Iter: 1295 loss: 3.67126631e-07
Iter: 1296 loss: 3.72334171e-07
Iter: 1297 loss: 3.67107248e-07
Iter: 1298 loss: 3.66777385e-07
Iter: 1299 loss: 3.67509074e-07
Iter: 1300 loss: 3.66661112e-07
Iter: 1301 loss: 3.66260224e-07
Iter: 1302 loss: 3.67691825e-07
Iter: 1303 loss: 3.66152165e-07
Iter: 1304 loss: 3.65809541e-07
Iter: 1305 loss: 3.6633719e-07
Iter: 1306 loss: 3.65631479e-07
Iter: 1307 loss: 3.65377275e-07
Iter: 1308 loss: 3.68767e-07
Iter: 1309 loss: 3.65368862e-07
Iter: 1310 loss: 3.65158115e-07
Iter: 1311 loss: 3.66442919e-07
Iter: 1312 loss: 3.65124833e-07
Iter: 1313 loss: 3.64903258e-07
Iter: 1314 loss: 3.64787e-07
Iter: 1315 loss: 3.64676168e-07
Iter: 1316 loss: 3.64463062e-07
Iter: 1317 loss: 3.6699393e-07
Iter: 1318 loss: 3.64470907e-07
Iter: 1319 loss: 3.64286848e-07
Iter: 1320 loss: 3.64255783e-07
Iter: 1321 loss: 3.6411231e-07
Iter: 1322 loss: 3.63915206e-07
Iter: 1323 loss: 3.63669784e-07
Iter: 1324 loss: 3.63643068e-07
Iter: 1325 loss: 3.63421663e-07
Iter: 1326 loss: 3.63399238e-07
Iter: 1327 loss: 3.63169789e-07
Iter: 1328 loss: 3.63850603e-07
Iter: 1329 loss: 3.63108711e-07
Iter: 1330 loss: 3.62902824e-07
Iter: 1331 loss: 3.62688695e-07
Iter: 1332 loss: 3.62679771e-07
Iter: 1333 loss: 3.62453136e-07
Iter: 1334 loss: 3.62440062e-07
Iter: 1335 loss: 3.62288375e-07
Iter: 1336 loss: 3.62019534e-07
Iter: 1337 loss: 3.68445626e-07
Iter: 1338 loss: 3.62021495e-07
Iter: 1339 loss: 3.61671539e-07
Iter: 1340 loss: 3.62477095e-07
Iter: 1341 loss: 3.6156024e-07
Iter: 1342 loss: 3.61253228e-07
Iter: 1343 loss: 3.62555852e-07
Iter: 1344 loss: 3.61192946e-07
Iter: 1345 loss: 3.60881614e-07
Iter: 1346 loss: 3.60837788e-07
Iter: 1347 loss: 3.60630793e-07
Iter: 1348 loss: 3.60324748e-07
Iter: 1349 loss: 3.64188423e-07
Iter: 1350 loss: 3.60334724e-07
Iter: 1351 loss: 3.60104536e-07
Iter: 1352 loss: 3.61661534e-07
Iter: 1353 loss: 3.60077166e-07
Iter: 1354 loss: 3.59850588e-07
Iter: 1355 loss: 3.59946625e-07
Iter: 1356 loss: 3.59685828e-07
Iter: 1357 loss: 3.59519959e-07
Iter: 1358 loss: 3.61013122e-07
Iter: 1359 loss: 3.59502963e-07
Iter: 1360 loss: 3.59332091e-07
Iter: 1361 loss: 3.59214738e-07
Iter: 1362 loss: 3.59153404e-07
Iter: 1363 loss: 3.58923e-07
Iter: 1364 loss: 3.59011551e-07
Iter: 1365 loss: 3.58760616e-07
Iter: 1366 loss: 3.58540376e-07
Iter: 1367 loss: 3.58541087e-07
Iter: 1368 loss: 3.58345631e-07
Iter: 1369 loss: 3.58747513e-07
Iter: 1370 loss: 3.58245188e-07
Iter: 1371 loss: 3.5802978e-07
Iter: 1372 loss: 3.58046577e-07
Iter: 1373 loss: 3.57885767e-07
Iter: 1374 loss: 3.5763594e-07
Iter: 1375 loss: 3.60549564e-07
Iter: 1376 loss: 3.57628352e-07
Iter: 1377 loss: 3.57546298e-07
Iter: 1378 loss: 3.57304884e-07
Iter: 1379 loss: 3.58953798e-07
Iter: 1380 loss: 3.57251054e-07
Iter: 1381 loss: 3.5692068e-07
Iter: 1382 loss: 3.58686691e-07
Iter: 1383 loss: 3.56880776e-07
Iter: 1384 loss: 3.56589197e-07
Iter: 1385 loss: 3.57611782e-07
Iter: 1386 loss: 3.5651928e-07
Iter: 1387 loss: 3.56278e-07
Iter: 1388 loss: 3.57320317e-07
Iter: 1389 loss: 3.56221506e-07
Iter: 1390 loss: 3.55898095e-07
Iter: 1391 loss: 3.57206773e-07
Iter: 1392 loss: 3.55841081e-07
Iter: 1393 loss: 3.55661712e-07
Iter: 1394 loss: 3.55751723e-07
Iter: 1395 loss: 3.55523156e-07
Iter: 1396 loss: 3.553277e-07
Iter: 1397 loss: 3.57599077e-07
Iter: 1398 loss: 3.55326733e-07
Iter: 1399 loss: 3.55175644e-07
Iter: 1400 loss: 3.55005568e-07
Iter: 1401 loss: 3.54992608e-07
Iter: 1402 loss: 3.54757333e-07
Iter: 1403 loss: 3.55141481e-07
Iter: 1404 loss: 3.54624717e-07
Iter: 1405 loss: 3.54614713e-07
Iter: 1406 loss: 3.54538372e-07
Iter: 1407 loss: 3.54448105e-07
Iter: 1408 loss: 3.54234942e-07
Iter: 1409 loss: 3.55909549e-07
Iter: 1410 loss: 3.54194412e-07
Iter: 1411 loss: 3.53915112e-07
Iter: 1412 loss: 3.55725092e-07
Iter: 1413 loss: 3.53890869e-07
Iter: 1414 loss: 3.53649284e-07
Iter: 1415 loss: 3.5458288e-07
Iter: 1416 loss: 3.53588916e-07
Iter: 1417 loss: 3.53401788e-07
Iter: 1418 loss: 3.5323086e-07
Iter: 1419 loss: 3.53177739e-07
Iter: 1420 loss: 3.52875247e-07
Iter: 1421 loss: 3.53178137e-07
Iter: 1422 loss: 3.52681354e-07
Iter: 1423 loss: 3.52406204e-07
Iter: 1424 loss: 3.54145243e-07
Iter: 1425 loss: 3.52389065e-07
Iter: 1426 loss: 3.52206314e-07
Iter: 1427 loss: 3.52203699e-07
Iter: 1428 loss: 3.52076228e-07
Iter: 1429 loss: 3.52148163e-07
Iter: 1430 loss: 3.5196831e-07
Iter: 1431 loss: 3.5182353e-07
Iter: 1432 loss: 3.51839e-07
Iter: 1433 loss: 3.51732297e-07
Iter: 1434 loss: 3.5151885e-07
Iter: 1435 loss: 3.53383399e-07
Iter: 1436 loss: 3.51489348e-07
Iter: 1437 loss: 3.51394704e-07
Iter: 1438 loss: 3.51196206e-07
Iter: 1439 loss: 3.56168073e-07
Iter: 1440 loss: 3.51199e-07
Iter: 1441 loss: 3.509804e-07
Iter: 1442 loss: 3.53610943e-07
Iter: 1443 loss: 3.50975142e-07
Iter: 1444 loss: 3.50763315e-07
Iter: 1445 loss: 3.51716096e-07
Iter: 1446 loss: 3.50725884e-07
Iter: 1447 loss: 3.50571781e-07
Iter: 1448 loss: 3.50310671e-07
Iter: 1449 loss: 3.50305754e-07
Iter: 1450 loss: 3.5006147e-07
Iter: 1451 loss: 3.51153574e-07
Iter: 1452 loss: 3.50018865e-07
Iter: 1453 loss: 3.49797e-07
Iter: 1454 loss: 3.52198469e-07
Iter: 1455 loss: 3.49793e-07
Iter: 1456 loss: 3.49628181e-07
Iter: 1457 loss: 3.49504433e-07
Iter: 1458 loss: 3.49479365e-07
Iter: 1459 loss: 3.49244715e-07
Iter: 1460 loss: 3.49605443e-07
Iter: 1461 loss: 3.49139327e-07
Iter: 1462 loss: 3.48932502e-07
Iter: 1463 loss: 3.50026966e-07
Iter: 1464 loss: 3.48885379e-07
Iter: 1465 loss: 3.48639077e-07
Iter: 1466 loss: 3.49860471e-07
Iter: 1467 loss: 3.48573963e-07
Iter: 1468 loss: 3.48458713e-07
Iter: 1469 loss: 3.48408889e-07
Iter: 1470 loss: 3.48335249e-07
Iter: 1471 loss: 3.4815514e-07
Iter: 1472 loss: 3.49820937e-07
Iter: 1473 loss: 3.48157243e-07
Iter: 1474 loss: 3.4798876e-07
Iter: 1475 loss: 3.47870241e-07
Iter: 1476 loss: 3.47796174e-07
Iter: 1477 loss: 3.47598359e-07
Iter: 1478 loss: 3.48104692e-07
Iter: 1479 loss: 3.47502692e-07
Iter: 1480 loss: 3.47401965e-07
Iter: 1481 loss: 3.47390426e-07
Iter: 1482 loss: 3.47294076e-07
Iter: 1483 loss: 3.4706926e-07
Iter: 1484 loss: 3.48928978e-07
Iter: 1485 loss: 3.47004402e-07
Iter: 1486 loss: 3.46766569e-07
Iter: 1487 loss: 3.4754089e-07
Iter: 1488 loss: 3.46708276e-07
Iter: 1489 loss: 3.46450292e-07
Iter: 1490 loss: 3.47821583e-07
Iter: 1491 loss: 3.46401066e-07
Iter: 1492 loss: 3.46091468e-07
Iter: 1493 loss: 3.47275773e-07
Iter: 1494 loss: 3.4601959e-07
Iter: 1495 loss: 3.45864862e-07
Iter: 1496 loss: 3.45846274e-07
Iter: 1497 loss: 3.45713232e-07
Iter: 1498 loss: 3.45507459e-07
Iter: 1499 loss: 3.46320917e-07
Iter: 1500 loss: 3.45439844e-07
Iter: 1501 loss: 3.4519212e-07
Iter: 1502 loss: 3.47394064e-07
Iter: 1503 loss: 3.45169042e-07
Iter: 1504 loss: 3.4502969e-07
Iter: 1505 loss: 3.45063143e-07
Iter: 1506 loss: 3.44905459e-07
Iter: 1507 loss: 3.44788219e-07
Iter: 1508 loss: 3.45057799e-07
Iter: 1509 loss: 3.44727624e-07
Iter: 1510 loss: 3.44529127e-07
Iter: 1511 loss: 3.45374076e-07
Iter: 1512 loss: 3.44481577e-07
Iter: 1513 loss: 3.44387e-07
Iter: 1514 loss: 3.44346e-07
Iter: 1515 loss: 3.44304226e-07
Iter: 1516 loss: 3.44171212e-07
Iter: 1517 loss: 3.441736e-07
Iter: 1518 loss: 3.44067757e-07
Iter: 1519 loss: 3.43891202e-07
Iter: 1520 loss: 3.47905086e-07
Iter: 1521 loss: 3.43885461e-07
Iter: 1522 loss: 3.436312e-07
Iter: 1523 loss: 3.43312507e-07
Iter: 1524 loss: 3.43300144e-07
Iter: 1525 loss: 3.43039e-07
Iter: 1526 loss: 3.43023459e-07
Iter: 1527 loss: 3.42787558e-07
Iter: 1528 loss: 3.43696229e-07
Iter: 1529 loss: 3.42723382e-07
Iter: 1530 loss: 3.42582041e-07
Iter: 1531 loss: 3.42539e-07
Iter: 1532 loss: 3.42427199e-07
Iter: 1533 loss: 3.42268947e-07
Iter: 1534 loss: 3.43561254e-07
Iter: 1535 loss: 3.42257408e-07
Iter: 1536 loss: 3.42107569e-07
Iter: 1537 loss: 3.43250605e-07
Iter: 1538 loss: 3.42100577e-07
Iter: 1539 loss: 3.42005876e-07
Iter: 1540 loss: 3.41839041e-07
Iter: 1541 loss: 3.41825512e-07
Iter: 1542 loss: 3.41692385e-07
Iter: 1543 loss: 3.4249166e-07
Iter: 1544 loss: 3.41686e-07
Iter: 1545 loss: 3.41481552e-07
Iter: 1546 loss: 3.4146322e-07
Iter: 1547 loss: 3.41319634e-07
Iter: 1548 loss: 3.41109285e-07
Iter: 1549 loss: 3.4191828e-07
Iter: 1550 loss: 3.41042437e-07
Iter: 1551 loss: 3.40947082e-07
Iter: 1552 loss: 3.40940403e-07
Iter: 1553 loss: 3.40824016e-07
Iter: 1554 loss: 3.40647148e-07
Iter: 1555 loss: 3.43987949e-07
Iter: 1556 loss: 3.40626912e-07
Iter: 1557 loss: 3.40408491e-07
Iter: 1558 loss: 3.40640668e-07
Iter: 1559 loss: 3.40280906e-07
Iter: 1560 loss: 3.40083716e-07
Iter: 1561 loss: 3.4210575e-07
Iter: 1562 loss: 3.40082607e-07
Iter: 1563 loss: 3.39883769e-07
Iter: 1564 loss: 3.40580954e-07
Iter: 1565 loss: 3.39825249e-07
Iter: 1566 loss: 3.39654036e-07
Iter: 1567 loss: 3.39719747e-07
Iter: 1568 loss: 3.39512326e-07
Iter: 1569 loss: 3.39356461e-07
Iter: 1570 loss: 3.39690359e-07
Iter: 1571 loss: 3.39282622e-07
Iter: 1572 loss: 3.39028787e-07
Iter: 1573 loss: 3.40419433e-07
Iter: 1574 loss: 3.38987377e-07
Iter: 1575 loss: 3.38862492e-07
Iter: 1576 loss: 3.38680024e-07
Iter: 1577 loss: 3.38672635e-07
Iter: 1578 loss: 3.38451031e-07
Iter: 1579 loss: 3.39909946e-07
Iter: 1580 loss: 3.3840746e-07
Iter: 1581 loss: 3.38169684e-07
Iter: 1582 loss: 3.3944707e-07
Iter: 1583 loss: 3.3813788e-07
Iter: 1584 loss: 3.37975848e-07
Iter: 1585 loss: 3.38014843e-07
Iter: 1586 loss: 3.37874553e-07
Iter: 1587 loss: 3.37750663e-07
Iter: 1588 loss: 3.37758649e-07
Iter: 1589 loss: 3.37690892e-07
Iter: 1590 loss: 3.37487251e-07
Iter: 1591 loss: 3.38695429e-07
Iter: 1592 loss: 3.37445385e-07
Iter: 1593 loss: 3.37221252e-07
Iter: 1594 loss: 3.38197424e-07
Iter: 1595 loss: 3.37178619e-07
Iter: 1596 loss: 3.37010817e-07
Iter: 1597 loss: 3.38246281e-07
Iter: 1598 loss: 3.36991661e-07
Iter: 1599 loss: 3.36833153e-07
Iter: 1600 loss: 3.37337127e-07
Iter: 1601 loss: 3.36787934e-07
Iter: 1602 loss: 3.36635821e-07
Iter: 1603 loss: 3.36540609e-07
Iter: 1604 loss: 3.36464154e-07
Iter: 1605 loss: 3.36297376e-07
Iter: 1606 loss: 3.38662574e-07
Iter: 1607 loss: 3.36288878e-07
Iter: 1608 loss: 3.36106893e-07
Iter: 1609 loss: 3.36433459e-07
Iter: 1610 loss: 3.36055507e-07
Iter: 1611 loss: 3.35892622e-07
Iter: 1612 loss: 3.35839502e-07
Iter: 1613 loss: 3.35751707e-07
Iter: 1614 loss: 3.35572452e-07
Iter: 1615 loss: 3.36696644e-07
Iter: 1616 loss: 3.35548776e-07
Iter: 1617 loss: 3.3536972e-07
Iter: 1618 loss: 3.36417429e-07
Iter: 1619 loss: 3.35336154e-07
Iter: 1620 loss: 3.35213088e-07
Iter: 1621 loss: 3.35079108e-07
Iter: 1622 loss: 3.35070808e-07
Iter: 1623 loss: 3.34857049e-07
Iter: 1624 loss: 3.3485378e-07
Iter: 1625 loss: 3.34780623e-07
Iter: 1626 loss: 3.3458025e-07
Iter: 1627 loss: 3.35796727e-07
Iter: 1628 loss: 3.34498736e-07
Iter: 1629 loss: 3.3422657e-07
Iter: 1630 loss: 3.36238656e-07
Iter: 1631 loss: 3.34209631e-07
Iter: 1632 loss: 3.34054505e-07
Iter: 1633 loss: 3.3404325e-07
Iter: 1634 loss: 3.33919104e-07
Iter: 1635 loss: 3.33803484e-07
Iter: 1636 loss: 3.33768185e-07
Iter: 1637 loss: 3.33563321e-07
Iter: 1638 loss: 3.33491016e-07
Iter: 1639 loss: 3.33386e-07
Iter: 1640 loss: 3.33342427e-07
Iter: 1641 loss: 3.33255855e-07
Iter: 1642 loss: 3.33165616e-07
Iter: 1643 loss: 3.32934576e-07
Iter: 1644 loss: 3.3571132e-07
Iter: 1645 loss: 3.32930313e-07
Iter: 1646 loss: 3.32674858e-07
Iter: 1647 loss: 3.34254196e-07
Iter: 1648 loss: 3.32633959e-07
Iter: 1649 loss: 3.32477669e-07
Iter: 1650 loss: 3.34509735e-07
Iter: 1651 loss: 3.32472837e-07
Iter: 1652 loss: 3.32334224e-07
Iter: 1653 loss: 3.32335162e-07
Iter: 1654 loss: 3.32228e-07
Iter: 1655 loss: 3.32102701e-07
Iter: 1656 loss: 3.32779393e-07
Iter: 1657 loss: 3.32074279e-07
Iter: 1658 loss: 3.31930153e-07
Iter: 1659 loss: 3.32155764e-07
Iter: 1660 loss: 3.3184233e-07
Iter: 1661 loss: 3.31712386e-07
Iter: 1662 loss: 3.31712073e-07
Iter: 1663 loss: 3.31608391e-07
Iter: 1664 loss: 3.31439423e-07
Iter: 1665 loss: 3.31430783e-07
Iter: 1666 loss: 3.31291062e-07
Iter: 1667 loss: 3.31061585e-07
Iter: 1668 loss: 3.32297702e-07
Iter: 1669 loss: 3.31014462e-07
Iter: 1670 loss: 3.30813947e-07
Iter: 1671 loss: 3.33210266e-07
Iter: 1672 loss: 3.30812497e-07
Iter: 1673 loss: 3.30703358e-07
Iter: 1674 loss: 3.30687755e-07
Iter: 1675 loss: 3.30594389e-07
Iter: 1676 loss: 3.3043608e-07
Iter: 1677 loss: 3.30520294e-07
Iter: 1678 loss: 3.30345756e-07
Iter: 1679 loss: 3.30247332e-07
Iter: 1680 loss: 3.30213425e-07
Iter: 1681 loss: 3.30136572e-07
Iter: 1682 loss: 3.29949131e-07
Iter: 1683 loss: 3.3059888e-07
Iter: 1684 loss: 3.29845534e-07
Iter: 1685 loss: 3.2962555e-07
Iter: 1686 loss: 3.31986087e-07
Iter: 1687 loss: 3.29616938e-07
Iter: 1688 loss: 3.29496572e-07
Iter: 1689 loss: 3.29481935e-07
Iter: 1690 loss: 3.29378167e-07
Iter: 1691 loss: 3.29299581e-07
Iter: 1692 loss: 3.29253652e-07
Iter: 1693 loss: 3.29113504e-07
Iter: 1694 loss: 3.30980072e-07
Iter: 1695 loss: 3.29111089e-07
Iter: 1696 loss: 3.28989245e-07
Iter: 1697 loss: 3.28968099e-07
Iter: 1698 loss: 3.28919953e-07
Iter: 1699 loss: 3.2878512e-07
Iter: 1700 loss: 3.28561811e-07
Iter: 1701 loss: 3.28553824e-07
Iter: 1702 loss: 3.28308801e-07
Iter: 1703 loss: 3.31449655e-07
Iter: 1704 loss: 3.2829729e-07
Iter: 1705 loss: 3.28141283e-07
Iter: 1706 loss: 3.28038794e-07
Iter: 1707 loss: 3.27980217e-07
Iter: 1708 loss: 3.27801587e-07
Iter: 1709 loss: 3.27786324e-07
Iter: 1710 loss: 3.27623695e-07
Iter: 1711 loss: 3.27699752e-07
Iter: 1712 loss: 3.27511771e-07
Iter: 1713 loss: 3.27379951e-07
Iter: 1714 loss: 3.27380604e-07
Iter: 1715 loss: 3.2726453e-07
Iter: 1716 loss: 3.27085132e-07
Iter: 1717 loss: 3.27800592e-07
Iter: 1718 loss: 3.27045825e-07
Iter: 1719 loss: 3.26895218e-07
Iter: 1720 loss: 3.26883708e-07
Iter: 1721 loss: 3.26764052e-07
Iter: 1722 loss: 3.26678162e-07
Iter: 1723 loss: 3.26665628e-07
Iter: 1724 loss: 3.26537787e-07
Iter: 1725 loss: 3.2644391e-07
Iter: 1726 loss: 3.26410827e-07
Iter: 1727 loss: 3.2626312e-07
Iter: 1728 loss: 3.26542192e-07
Iter: 1729 loss: 3.26193799e-07
Iter: 1730 loss: 3.26061638e-07
Iter: 1731 loss: 3.26065731e-07
Iter: 1732 loss: 3.25950197e-07
Iter: 1733 loss: 3.25833e-07
Iter: 1734 loss: 3.25832161e-07
Iter: 1735 loss: 3.25689314e-07
Iter: 1736 loss: 3.25581937e-07
Iter: 1737 loss: 3.25535808e-07
Iter: 1738 loss: 3.25304541e-07
Iter: 1739 loss: 3.26119249e-07
Iter: 1740 loss: 3.2524548e-07
Iter: 1741 loss: 3.2520245e-07
Iter: 1742 loss: 3.25160386e-07
Iter: 1743 loss: 3.25084301e-07
Iter: 1744 loss: 3.2499571e-07
Iter: 1745 loss: 3.24991873e-07
Iter: 1746 loss: 3.24832428e-07
Iter: 1747 loss: 3.25068953e-07
Iter: 1748 loss: 3.24764073e-07
Iter: 1749 loss: 3.24553753e-07
Iter: 1750 loss: 3.25398844e-07
Iter: 1751 loss: 3.24527321e-07
Iter: 1752 loss: 3.2442108e-07
Iter: 1753 loss: 3.24324162e-07
Iter: 1754 loss: 3.24318194e-07
Iter: 1755 loss: 3.2414988e-07
Iter: 1756 loss: 3.25693748e-07
Iter: 1757 loss: 3.2415852e-07
Iter: 1758 loss: 3.24003906e-07
Iter: 1759 loss: 3.24617815e-07
Iter: 1760 loss: 3.23972387e-07
Iter: 1761 loss: 3.23888287e-07
Iter: 1762 loss: 3.23940441e-07
Iter: 1763 loss: 3.23840254e-07
Iter: 1764 loss: 3.23729921e-07
Iter: 1765 loss: 3.24581094e-07
Iter: 1766 loss: 3.23748e-07
Iter: 1767 loss: 3.23631383e-07
Iter: 1768 loss: 3.23474325e-07
Iter: 1769 loss: 3.23474779e-07
Iter: 1770 loss: 3.2332639e-07
Iter: 1771 loss: 3.23224356e-07
Iter: 1772 loss: 3.23172145e-07
Iter: 1773 loss: 3.22964496e-07
Iter: 1774 loss: 3.25223539e-07
Iter: 1775 loss: 3.22950314e-07
Iter: 1776 loss: 3.22829e-07
Iter: 1777 loss: 3.24561825e-07
Iter: 1778 loss: 3.2282253e-07
Iter: 1779 loss: 3.22702078e-07
Iter: 1780 loss: 3.22614397e-07
Iter: 1781 loss: 3.22578671e-07
Iter: 1782 loss: 3.2244742e-07
Iter: 1783 loss: 3.23782075e-07
Iter: 1784 loss: 3.22449637e-07
Iter: 1785 loss: 3.22323615e-07
Iter: 1786 loss: 3.22221808e-07
Iter: 1787 loss: 3.22177925e-07
Iter: 1788 loss: 3.22055598e-07
Iter: 1789 loss: 3.2254934e-07
Iter: 1790 loss: 3.22031042e-07
Iter: 1791 loss: 3.21944185e-07
Iter: 1792 loss: 3.23164727e-07
Iter: 1793 loss: 3.21948e-07
Iter: 1794 loss: 3.21867645e-07
Iter: 1795 loss: 3.21784114e-07
Iter: 1796 loss: 3.21782e-07
Iter: 1797 loss: 3.2164121e-07
Iter: 1798 loss: 3.22000801e-07
Iter: 1799 loss: 3.21607018e-07
Iter: 1800 loss: 3.21450216e-07
Iter: 1801 loss: 3.22468651e-07
Iter: 1802 loss: 3.21432651e-07
Iter: 1803 loss: 3.21344118e-07
Iter: 1804 loss: 3.21144455e-07
Iter: 1805 loss: 3.23405914e-07
Iter: 1806 loss: 3.211386e-07
Iter: 1807 loss: 3.20880503e-07
Iter: 1808 loss: 3.22331232e-07
Iter: 1809 loss: 3.2086794e-07
Iter: 1810 loss: 3.20700224e-07
Iter: 1811 loss: 3.21094802e-07
Iter: 1812 loss: 3.20633973e-07
Iter: 1813 loss: 3.20422856e-07
Iter: 1814 loss: 3.22661606e-07
Iter: 1815 loss: 3.2043215e-07
Iter: 1816 loss: 3.20350722e-07
Iter: 1817 loss: 3.2029152e-07
Iter: 1818 loss: 3.20283505e-07
Iter: 1819 loss: 3.20155124e-07
Iter: 1820 loss: 3.21166937e-07
Iter: 1821 loss: 3.2014114e-07
Iter: 1822 loss: 3.20064686e-07
Iter: 1823 loss: 3.20047491e-07
Iter: 1824 loss: 3.19977289e-07
Iter: 1825 loss: 3.19872925e-07
Iter: 1826 loss: 3.20595632e-07
Iter: 1827 loss: 3.19868832e-07
Iter: 1828 loss: 3.19741332e-07
Iter: 1829 loss: 3.1993477e-07
Iter: 1830 loss: 3.19684489e-07
Iter: 1831 loss: 3.19575577e-07
Iter: 1832 loss: 3.19424885e-07
Iter: 1833 loss: 3.1942966e-07
Iter: 1834 loss: 3.19318417e-07
Iter: 1835 loss: 3.19280076e-07
Iter: 1836 loss: 3.1919825e-07
Iter: 1837 loss: 3.19038719e-07
Iter: 1838 loss: 3.22216039e-07
Iter: 1839 loss: 3.19039259e-07
Iter: 1840 loss: 3.1885827e-07
Iter: 1841 loss: 3.19444808e-07
Iter: 1842 loss: 3.18813079e-07
Iter: 1843 loss: 3.18651303e-07
Iter: 1844 loss: 3.1898665e-07
Iter: 1845 loss: 3.18613445e-07
Iter: 1846 loss: 3.18549667e-07
Iter: 1847 loss: 3.18533353e-07
Iter: 1848 loss: 3.18477646e-07
Iter: 1849 loss: 3.1836305e-07
Iter: 1850 loss: 3.20600947e-07
Iter: 1851 loss: 3.18364926e-07
Iter: 1852 loss: 3.18250386e-07
Iter: 1853 loss: 3.19222522e-07
Iter: 1854 loss: 3.18248112e-07
Iter: 1855 loss: 3.18139598e-07
Iter: 1856 loss: 3.18093157e-07
Iter: 1857 loss: 3.18033472e-07
Iter: 1858 loss: 3.17906682e-07
Iter: 1859 loss: 3.17757582e-07
Iter: 1860 loss: 3.17723334e-07
Iter: 1861 loss: 3.17570624e-07
Iter: 1862 loss: 3.19091924e-07
Iter: 1863 loss: 3.17562e-07
Iter: 1864 loss: 3.17379374e-07
Iter: 1865 loss: 3.17771594e-07
Iter: 1866 loss: 3.17331e-07
Iter: 1867 loss: 3.17194377e-07
Iter: 1868 loss: 3.17228142e-07
Iter: 1869 loss: 3.1711204e-07
Iter: 1870 loss: 3.16949041e-07
Iter: 1871 loss: 3.18606226e-07
Iter: 1872 loss: 3.16962797e-07
Iter: 1873 loss: 3.16827766e-07
Iter: 1874 loss: 3.1684e-07
Iter: 1875 loss: 3.1672397e-07
Iter: 1876 loss: 3.16604712e-07
Iter: 1877 loss: 3.16476985e-07
Iter: 1878 loss: 3.16444243e-07
Iter: 1879 loss: 3.16238356e-07
Iter: 1880 loss: 3.17507386e-07
Iter: 1881 loss: 3.16235514e-07
Iter: 1882 loss: 3.1612268e-07
Iter: 1883 loss: 3.16127512e-07
Iter: 1884 loss: 3.16031276e-07
Iter: 1885 loss: 3.15953741e-07
Iter: 1886 loss: 3.15933164e-07
Iter: 1887 loss: 3.15790146e-07
Iter: 1888 loss: 3.16388594e-07
Iter: 1889 loss: 3.15767977e-07
Iter: 1890 loss: 3.15635589e-07
Iter: 1891 loss: 3.15863389e-07
Iter: 1892 loss: 3.15562914e-07
Iter: 1893 loss: 3.15443884e-07
Iter: 1894 loss: 3.15278527e-07
Iter: 1895 loss: 3.15279e-07
Iter: 1896 loss: 3.15233393e-07
Iter: 1897 loss: 3.15165749e-07
Iter: 1898 loss: 3.1507534e-07
Iter: 1899 loss: 3.14954491e-07
Iter: 1900 loss: 3.14948579e-07
Iter: 1901 loss: 3.14811956e-07
Iter: 1902 loss: 3.15104216e-07
Iter: 1903 loss: 3.14749343e-07
Iter: 1904 loss: 3.14662202e-07
Iter: 1905 loss: 3.14653107e-07
Iter: 1906 loss: 3.14557212e-07
Iter: 1907 loss: 3.14363831e-07
Iter: 1908 loss: 3.18588178e-07
Iter: 1909 loss: 3.14370425e-07
Iter: 1910 loss: 3.14183353e-07
Iter: 1911 loss: 3.14643586e-07
Iter: 1912 loss: 3.14136912e-07
Iter: 1913 loss: 3.13988949e-07
Iter: 1914 loss: 3.1461397e-07
Iter: 1915 loss: 3.13953819e-07
Iter: 1916 loss: 3.13820067e-07
Iter: 1917 loss: 3.14644183e-07
Iter: 1918 loss: 3.13796619e-07
Iter: 1919 loss: 3.13663151e-07
Iter: 1920 loss: 3.14680364e-07
Iter: 1921 loss: 3.13661e-07
Iter: 1922 loss: 3.1359798e-07
Iter: 1923 loss: 3.13465279e-07
Iter: 1924 loss: 3.15526762e-07
Iter: 1925 loss: 3.13469968e-07
Iter: 1926 loss: 3.13306373e-07
Iter: 1927 loss: 3.14799308e-07
Iter: 1928 loss: 3.13312114e-07
Iter: 1929 loss: 3.13225058e-07
Iter: 1930 loss: 3.13103271e-07
Iter: 1931 loss: 3.1306692e-07
Iter: 1932 loss: 3.12911112e-07
Iter: 1933 loss: 3.13839905e-07
Iter: 1934 loss: 3.12881411e-07
Iter: 1935 loss: 3.12781765e-07
Iter: 1936 loss: 3.12783669e-07
Iter: 1937 loss: 3.12716708e-07
Iter: 1938 loss: 3.12591567e-07
Iter: 1939 loss: 3.12596086e-07
Iter: 1940 loss: 3.12470547e-07
Iter: 1941 loss: 3.12757237e-07
Iter: 1942 loss: 3.12430046e-07
Iter: 1943 loss: 3.12278019e-07
Iter: 1944 loss: 3.13384817e-07
Iter: 1945 loss: 3.12251416e-07
Iter: 1946 loss: 3.12179395e-07
Iter: 1947 loss: 3.12185563e-07
Iter: 1948 loss: 3.12118487e-07
Iter: 1949 loss: 3.12011935e-07
Iter: 1950 loss: 3.11934059e-07
Iter: 1951 loss: 3.11905495e-07
Iter: 1952 loss: 3.11812528e-07
Iter: 1953 loss: 3.11795361e-07
Iter: 1954 loss: 3.11689519e-07
Iter: 1955 loss: 3.11662e-07
Iter: 1956 loss: 3.11594818e-07
Iter: 1957 loss: 3.11508757e-07
Iter: 1958 loss: 3.11780241e-07
Iter: 1959 loss: 3.11472206e-07
Iter: 1960 loss: 3.11339363e-07
Iter: 1961 loss: 3.11784504e-07
Iter: 1962 loss: 3.11304291e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6
+ date
Mon Oct 26 18:15:48 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi1.6_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a0693158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a06aaea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a0702d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a07a0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a06889d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a067d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a0644e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a060fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a05f0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a05b6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a057a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a057ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a057eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a051d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a04d88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a0492c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a04b2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a04adae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a040a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a040af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a042e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a042e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a038a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a03519d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a0351a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a034d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a030a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a030a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a02fa6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36a02faae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36971508c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3697150840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3697150268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f36970b96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f369708e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3697077e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.79177094e-06
Iter: 2 loss: 8.00770613e-06
Iter: 3 loss: 2.91327433e-05
Iter: 4 loss: 7.98270776e-06
Iter: 5 loss: 7.43419696e-06
Iter: 6 loss: 1.00639618e-05
Iter: 7 loss: 7.33599154e-06
Iter: 8 loss: 6.98779513e-06
Iter: 9 loss: 9.4504021e-06
Iter: 10 loss: 6.9565981e-06
Iter: 11 loss: 6.6664179e-06
Iter: 12 loss: 6.40849066e-06
Iter: 13 loss: 6.3340658e-06
Iter: 14 loss: 5.99628402e-06
Iter: 15 loss: 6.5248646e-06
Iter: 16 loss: 5.83849533e-06
Iter: 17 loss: 5.62566493e-06
Iter: 18 loss: 5.61679462e-06
Iter: 19 loss: 5.48693697e-06
Iter: 20 loss: 5.28324927e-06
Iter: 21 loss: 5.28068722e-06
Iter: 22 loss: 4.97139808e-06
Iter: 23 loss: 7.28999157e-06
Iter: 24 loss: 4.94692722e-06
Iter: 25 loss: 4.74199351e-06
Iter: 26 loss: 4.90113325e-06
Iter: 27 loss: 4.61768832e-06
Iter: 28 loss: 4.38478492e-06
Iter: 29 loss: 4.16380226e-06
Iter: 30 loss: 4.11061546e-06
Iter: 31 loss: 3.83428778e-06
Iter: 32 loss: 4.60228966e-06
Iter: 33 loss: 3.745203e-06
Iter: 34 loss: 3.58174816e-06
Iter: 35 loss: 3.5808107e-06
Iter: 36 loss: 3.45903572e-06
Iter: 37 loss: 3.5630228e-06
Iter: 38 loss: 3.38709788e-06
Iter: 39 loss: 3.26838335e-06
Iter: 40 loss: 4.18683976e-06
Iter: 41 loss: 3.25974975e-06
Iter: 42 loss: 3.13746659e-06
Iter: 43 loss: 3.96134783e-06
Iter: 44 loss: 3.12520615e-06
Iter: 45 loss: 3.06079914e-06
Iter: 46 loss: 3.40523093e-06
Iter: 47 loss: 3.05095637e-06
Iter: 48 loss: 2.99809858e-06
Iter: 49 loss: 2.89560376e-06
Iter: 50 loss: 4.99476573e-06
Iter: 51 loss: 2.89494847e-06
Iter: 52 loss: 2.7687106e-06
Iter: 53 loss: 3.21307743e-06
Iter: 54 loss: 2.73597198e-06
Iter: 55 loss: 2.64970186e-06
Iter: 56 loss: 3.80450433e-06
Iter: 57 loss: 2.64925802e-06
Iter: 58 loss: 2.58351974e-06
Iter: 59 loss: 2.6637822e-06
Iter: 60 loss: 2.54919973e-06
Iter: 61 loss: 2.4907315e-06
Iter: 62 loss: 2.82106885e-06
Iter: 63 loss: 2.4825431e-06
Iter: 64 loss: 2.41950397e-06
Iter: 65 loss: 2.38219809e-06
Iter: 66 loss: 2.35573498e-06
Iter: 67 loss: 2.30224077e-06
Iter: 68 loss: 2.29154284e-06
Iter: 69 loss: 2.25596978e-06
Iter: 70 loss: 2.19109666e-06
Iter: 71 loss: 2.81251732e-06
Iter: 72 loss: 2.18861123e-06
Iter: 73 loss: 2.13478597e-06
Iter: 74 loss: 2.15796194e-06
Iter: 75 loss: 2.09784366e-06
Iter: 76 loss: 2.02531601e-06
Iter: 77 loss: 2.02460888e-06
Iter: 78 loss: 1.96715973e-06
Iter: 79 loss: 1.92307016e-06
Iter: 80 loss: 1.91471463e-06
Iter: 81 loss: 1.88240426e-06
Iter: 82 loss: 1.89159766e-06
Iter: 83 loss: 1.85917827e-06
Iter: 84 loss: 1.8443036e-06
Iter: 85 loss: 1.83895077e-06
Iter: 86 loss: 1.82113263e-06
Iter: 87 loss: 1.81189034e-06
Iter: 88 loss: 1.80372922e-06
Iter: 89 loss: 1.76680328e-06
Iter: 90 loss: 1.84429257e-06
Iter: 91 loss: 1.75223136e-06
Iter: 92 loss: 1.73340345e-06
Iter: 93 loss: 1.72225248e-06
Iter: 94 loss: 1.71433487e-06
Iter: 95 loss: 1.68590827e-06
Iter: 96 loss: 1.95141547e-06
Iter: 97 loss: 1.68473252e-06
Iter: 98 loss: 1.66336054e-06
Iter: 99 loss: 1.72650016e-06
Iter: 100 loss: 1.65683423e-06
Iter: 101 loss: 1.63710274e-06
Iter: 102 loss: 1.65618826e-06
Iter: 103 loss: 1.62576293e-06
Iter: 104 loss: 1.59324213e-06
Iter: 105 loss: 1.62724302e-06
Iter: 106 loss: 1.57519889e-06
Iter: 107 loss: 1.55498083e-06
Iter: 108 loss: 1.54971917e-06
Iter: 109 loss: 1.53705719e-06
Iter: 110 loss: 1.51192967e-06
Iter: 111 loss: 1.61220373e-06
Iter: 112 loss: 1.50618337e-06
Iter: 113 loss: 1.47669539e-06
Iter: 114 loss: 1.54846748e-06
Iter: 115 loss: 1.46609318e-06
Iter: 116 loss: 1.442403e-06
Iter: 117 loss: 1.43817806e-06
Iter: 118 loss: 1.42216936e-06
Iter: 119 loss: 1.39569556e-06
Iter: 120 loss: 1.53629367e-06
Iter: 121 loss: 1.39154974e-06
Iter: 122 loss: 1.37499194e-06
Iter: 123 loss: 1.37368988e-06
Iter: 124 loss: 1.35818686e-06
Iter: 125 loss: 1.38914265e-06
Iter: 126 loss: 1.35189919e-06
Iter: 127 loss: 1.34299728e-06
Iter: 128 loss: 1.32922423e-06
Iter: 129 loss: 1.32905427e-06
Iter: 130 loss: 1.30741046e-06
Iter: 131 loss: 1.45667605e-06
Iter: 132 loss: 1.30531794e-06
Iter: 133 loss: 1.29145519e-06
Iter: 134 loss: 1.30158264e-06
Iter: 135 loss: 1.28291094e-06
Iter: 136 loss: 1.27417377e-06
Iter: 137 loss: 1.27379462e-06
Iter: 138 loss: 1.26656164e-06
Iter: 139 loss: 1.2517155e-06
Iter: 140 loss: 1.51609231e-06
Iter: 141 loss: 1.25144186e-06
Iter: 142 loss: 1.2335347e-06
Iter: 143 loss: 1.34155971e-06
Iter: 144 loss: 1.23130553e-06
Iter: 145 loss: 1.22144343e-06
Iter: 146 loss: 1.3211112e-06
Iter: 147 loss: 1.2211342e-06
Iter: 148 loss: 1.21314974e-06
Iter: 149 loss: 1.19584877e-06
Iter: 150 loss: 1.46268906e-06
Iter: 151 loss: 1.19518359e-06
Iter: 152 loss: 1.17760123e-06
Iter: 153 loss: 1.20841537e-06
Iter: 154 loss: 1.1699176e-06
Iter: 155 loss: 1.15355465e-06
Iter: 156 loss: 1.29727528e-06
Iter: 157 loss: 1.15271109e-06
Iter: 158 loss: 1.14010152e-06
Iter: 159 loss: 1.21808171e-06
Iter: 160 loss: 1.13871215e-06
Iter: 161 loss: 1.1306339e-06
Iter: 162 loss: 1.13047111e-06
Iter: 163 loss: 1.12452426e-06
Iter: 164 loss: 1.10695669e-06
Iter: 165 loss: 1.16965748e-06
Iter: 166 loss: 1.09910786e-06
Iter: 167 loss: 1.0912994e-06
Iter: 168 loss: 1.09010102e-06
Iter: 169 loss: 1.0818294e-06
Iter: 170 loss: 1.09792461e-06
Iter: 171 loss: 1.07836649e-06
Iter: 172 loss: 1.06957475e-06
Iter: 173 loss: 1.09372047e-06
Iter: 174 loss: 1.06675043e-06
Iter: 175 loss: 1.0601882e-06
Iter: 176 loss: 1.11485781e-06
Iter: 177 loss: 1.05979177e-06
Iter: 178 loss: 1.05336937e-06
Iter: 179 loss: 1.04098444e-06
Iter: 180 loss: 1.29486909e-06
Iter: 181 loss: 1.04089213e-06
Iter: 182 loss: 1.03204627e-06
Iter: 183 loss: 1.11653708e-06
Iter: 184 loss: 1.03171647e-06
Iter: 185 loss: 1.02370313e-06
Iter: 186 loss: 1.06463926e-06
Iter: 187 loss: 1.02241643e-06
Iter: 188 loss: 1.01746991e-06
Iter: 189 loss: 1.00869806e-06
Iter: 190 loss: 1.22078438e-06
Iter: 191 loss: 1.00869613e-06
Iter: 192 loss: 9.96777544e-07
Iter: 193 loss: 1.07611754e-06
Iter: 194 loss: 9.95550863e-07
Iter: 195 loss: 9.89528e-07
Iter: 196 loss: 9.88480792e-07
Iter: 197 loss: 9.84334861e-07
Iter: 198 loss: 9.82865e-07
Iter: 199 loss: 9.79821834e-07
Iter: 200 loss: 9.75646117e-07
Iter: 201 loss: 9.68895165e-07
Iter: 202 loss: 9.68912445e-07
Iter: 203 loss: 9.63278353e-07
Iter: 204 loss: 9.76560614e-07
Iter: 205 loss: 9.61262458e-07
Iter: 206 loss: 9.54763664e-07
Iter: 207 loss: 9.49148216e-07
Iter: 208 loss: 9.47432e-07
Iter: 209 loss: 9.43227576e-07
Iter: 210 loss: 9.41267501e-07
Iter: 211 loss: 9.37148741e-07
Iter: 212 loss: 9.31393231e-07
Iter: 213 loss: 9.31120326e-07
Iter: 214 loss: 9.25157792e-07
Iter: 215 loss: 1.01809883e-06
Iter: 216 loss: 9.25146253e-07
Iter: 217 loss: 9.21191599e-07
Iter: 218 loss: 9.16201827e-07
Iter: 219 loss: 9.15829276e-07
Iter: 220 loss: 9.10836832e-07
Iter: 221 loss: 9.6000656e-07
Iter: 222 loss: 9.10686367e-07
Iter: 223 loss: 9.07049809e-07
Iter: 224 loss: 9.17844829e-07
Iter: 225 loss: 9.05905836e-07
Iter: 226 loss: 9.01304816e-07
Iter: 227 loss: 8.99215934e-07
Iter: 228 loss: 8.968766e-07
Iter: 229 loss: 8.91110176e-07
Iter: 230 loss: 8.85800773e-07
Iter: 231 loss: 8.84403676e-07
Iter: 232 loss: 8.77587354e-07
Iter: 233 loss: 8.77459172e-07
Iter: 234 loss: 8.72636235e-07
Iter: 235 loss: 8.70377448e-07
Iter: 236 loss: 8.67981726e-07
Iter: 237 loss: 8.65025527e-07
Iter: 238 loss: 8.63309481e-07
Iter: 239 loss: 8.61368164e-07
Iter: 240 loss: 8.55817746e-07
Iter: 241 loss: 8.79869901e-07
Iter: 242 loss: 8.53708968e-07
Iter: 243 loss: 8.47780143e-07
Iter: 244 loss: 8.7232354e-07
Iter: 245 loss: 8.46505372e-07
Iter: 246 loss: 8.41042265e-07
Iter: 247 loss: 8.75061858e-07
Iter: 248 loss: 8.40380721e-07
Iter: 249 loss: 8.37536845e-07
Iter: 250 loss: 8.67931135e-07
Iter: 251 loss: 8.37481593e-07
Iter: 252 loss: 8.33770457e-07
Iter: 253 loss: 8.27728513e-07
Iter: 254 loss: 8.2773e-07
Iter: 255 loss: 8.23661651e-07
Iter: 256 loss: 8.4474442e-07
Iter: 257 loss: 8.23083838e-07
Iter: 258 loss: 8.19181878e-07
Iter: 259 loss: 8.41606891e-07
Iter: 260 loss: 8.18660965e-07
Iter: 261 loss: 8.15489102e-07
Iter: 262 loss: 8.17572527e-07
Iter: 263 loss: 8.13481e-07
Iter: 264 loss: 8.08633786e-07
Iter: 265 loss: 8.05229206e-07
Iter: 266 loss: 8.0351748e-07
Iter: 267 loss: 8.02974569e-07
Iter: 268 loss: 8.00853911e-07
Iter: 269 loss: 7.99232851e-07
Iter: 270 loss: 7.9546561e-07
Iter: 271 loss: 8.44547799e-07
Iter: 272 loss: 7.95214191e-07
Iter: 273 loss: 7.91164439e-07
Iter: 274 loss: 8.13435e-07
Iter: 275 loss: 7.90559682e-07
Iter: 276 loss: 7.86938472e-07
Iter: 277 loss: 7.86939722e-07
Iter: 278 loss: 7.85204065e-07
Iter: 279 loss: 7.8271e-07
Iter: 280 loss: 7.82645429e-07
Iter: 281 loss: 7.79430138e-07
Iter: 282 loss: 7.76181594e-07
Iter: 283 loss: 7.75528747e-07
Iter: 284 loss: 7.69981739e-07
Iter: 285 loss: 7.90497324e-07
Iter: 286 loss: 7.68608572e-07
Iter: 287 loss: 7.66392873e-07
Iter: 288 loss: 7.65810285e-07
Iter: 289 loss: 7.63475e-07
Iter: 290 loss: 7.6336903e-07
Iter: 291 loss: 7.61585966e-07
Iter: 292 loss: 7.58483736e-07
Iter: 293 loss: 7.5871435e-07
Iter: 294 loss: 7.56046063e-07
Iter: 295 loss: 7.52813946e-07
Iter: 296 loss: 7.66644632e-07
Iter: 297 loss: 7.52172809e-07
Iter: 298 loss: 7.49398509e-07
Iter: 299 loss: 7.8283017e-07
Iter: 300 loss: 7.49361163e-07
Iter: 301 loss: 7.47863169e-07
Iter: 302 loss: 7.43889473e-07
Iter: 303 loss: 7.70913175e-07
Iter: 304 loss: 7.42934276e-07
Iter: 305 loss: 7.41153201e-07
Iter: 306 loss: 7.40220116e-07
Iter: 307 loss: 7.37930748e-07
Iter: 308 loss: 7.35904507e-07
Iter: 309 loss: 7.35265644e-07
Iter: 310 loss: 7.32347758e-07
Iter: 311 loss: 7.51526557e-07
Iter: 312 loss: 7.32019771e-07
Iter: 313 loss: 7.29364331e-07
Iter: 314 loss: 7.55298856e-07
Iter: 315 loss: 7.29287535e-07
Iter: 316 loss: 7.27346e-07
Iter: 317 loss: 7.23107462e-07
Iter: 318 loss: 7.87764066e-07
Iter: 319 loss: 7.22992411e-07
Iter: 320 loss: 7.19909394e-07
Iter: 321 loss: 7.21236688e-07
Iter: 322 loss: 7.17844273e-07
Iter: 323 loss: 7.14597945e-07
Iter: 324 loss: 7.64788808e-07
Iter: 325 loss: 7.14611701e-07
Iter: 326 loss: 7.12509632e-07
Iter: 327 loss: 7.10312634e-07
Iter: 328 loss: 7.09893243e-07
Iter: 329 loss: 7.09865731e-07
Iter: 330 loss: 7.08273319e-07
Iter: 331 loss: 7.07234676e-07
Iter: 332 loss: 7.04944171e-07
Iter: 333 loss: 7.34064429e-07
Iter: 334 loss: 7.04775857e-07
Iter: 335 loss: 7.02157649e-07
Iter: 336 loss: 7.00627879e-07
Iter: 337 loss: 6.99452301e-07
Iter: 338 loss: 6.93940194e-07
Iter: 339 loss: 7.16471959e-07
Iter: 340 loss: 6.92732101e-07
Iter: 341 loss: 6.90313584e-07
Iter: 342 loss: 7.13820214e-07
Iter: 343 loss: 6.90213767e-07
Iter: 344 loss: 6.87457032e-07
Iter: 345 loss: 6.89780336e-07
Iter: 346 loss: 6.8582068e-07
Iter: 347 loss: 6.8448378e-07
Iter: 348 loss: 6.99026657e-07
Iter: 349 loss: 6.84415966e-07
Iter: 350 loss: 6.82750738e-07
Iter: 351 loss: 6.83527105e-07
Iter: 352 loss: 6.81599488e-07
Iter: 353 loss: 6.803524e-07
Iter: 354 loss: 6.83261874e-07
Iter: 355 loss: 6.79868151e-07
Iter: 356 loss: 6.78271761e-07
Iter: 357 loss: 6.7990743e-07
Iter: 358 loss: 6.77384946e-07
Iter: 359 loss: 6.75596311e-07
Iter: 360 loss: 6.73611623e-07
Iter: 361 loss: 6.73332465e-07
Iter: 362 loss: 6.70199597e-07
Iter: 363 loss: 6.93628408e-07
Iter: 364 loss: 6.69955398e-07
Iter: 365 loss: 6.68048528e-07
Iter: 366 loss: 6.71661837e-07
Iter: 367 loss: 6.67237373e-07
Iter: 368 loss: 6.6441271e-07
Iter: 369 loss: 6.80527e-07
Iter: 370 loss: 6.63984224e-07
Iter: 371 loss: 6.62456728e-07
Iter: 372 loss: 6.60722208e-07
Iter: 373 loss: 6.6048824e-07
Iter: 374 loss: 6.58116448e-07
Iter: 375 loss: 6.67867198e-07
Iter: 376 loss: 6.57588032e-07
Iter: 377 loss: 6.55533142e-07
Iter: 378 loss: 6.57148576e-07
Iter: 379 loss: 6.54294752e-07
Iter: 380 loss: 6.52262656e-07
Iter: 381 loss: 6.56707357e-07
Iter: 382 loss: 6.51482139e-07
Iter: 383 loss: 6.49507228e-07
Iter: 384 loss: 6.49494154e-07
Iter: 385 loss: 6.48431183e-07
Iter: 386 loss: 6.46002718e-07
Iter: 387 loss: 6.76910872e-07
Iter: 388 loss: 6.45817408e-07
Iter: 389 loss: 6.454718e-07
Iter: 390 loss: 6.44419629e-07
Iter: 391 loss: 6.43352166e-07
Iter: 392 loss: 6.42988539e-07
Iter: 393 loss: 6.42387249e-07
Iter: 394 loss: 6.40782e-07
Iter: 395 loss: 6.42519808e-07
Iter: 396 loss: 6.39943948e-07
Iter: 397 loss: 6.37877349e-07
Iter: 398 loss: 6.40916255e-07
Iter: 399 loss: 6.36935226e-07
Iter: 400 loss: 6.35146762e-07
Iter: 401 loss: 6.34721971e-07
Iter: 402 loss: 6.33555715e-07
Iter: 403 loss: 6.32435047e-07
Iter: 404 loss: 6.32357683e-07
Iter: 405 loss: 6.30978434e-07
Iter: 406 loss: 6.30513e-07
Iter: 407 loss: 6.29736405e-07
Iter: 408 loss: 6.27951181e-07
Iter: 409 loss: 6.31414423e-07
Iter: 410 loss: 6.27235181e-07
Iter: 411 loss: 6.2557092e-07
Iter: 412 loss: 6.24549557e-07
Iter: 413 loss: 6.23868573e-07
Iter: 414 loss: 6.21807e-07
Iter: 415 loss: 6.30081672e-07
Iter: 416 loss: 6.21332276e-07
Iter: 417 loss: 6.18948206e-07
Iter: 418 loss: 6.27683107e-07
Iter: 419 loss: 6.18379431e-07
Iter: 420 loss: 6.16288219e-07
Iter: 421 loss: 6.1900289e-07
Iter: 422 loss: 6.15181136e-07
Iter: 423 loss: 6.13789098e-07
Iter: 424 loss: 6.13766929e-07
Iter: 425 loss: 6.12399e-07
Iter: 426 loss: 6.13469297e-07
Iter: 427 loss: 6.11589314e-07
Iter: 428 loss: 6.09971e-07
Iter: 429 loss: 6.1024781e-07
Iter: 430 loss: 6.08711844e-07
Iter: 431 loss: 6.06908429e-07
Iter: 432 loss: 6.25355483e-07
Iter: 433 loss: 6.06864e-07
Iter: 434 loss: 6.05755872e-07
Iter: 435 loss: 6.05757577e-07
Iter: 436 loss: 6.05246555e-07
Iter: 437 loss: 6.04852403e-07
Iter: 438 loss: 6.04677325e-07
Iter: 439 loss: 6.03477531e-07
Iter: 440 loss: 6.02253465e-07
Iter: 441 loss: 6.02021771e-07
Iter: 442 loss: 6.00499902e-07
Iter: 443 loss: 6.00694648e-07
Iter: 444 loss: 5.99358714e-07
Iter: 445 loss: 5.97739358e-07
Iter: 446 loss: 6.13077646e-07
Iter: 447 loss: 5.97665348e-07
Iter: 448 loss: 5.96239261e-07
Iter: 449 loss: 5.99831708e-07
Iter: 450 loss: 5.9570209e-07
Iter: 451 loss: 5.94068922e-07
Iter: 452 loss: 6.08947516e-07
Iter: 453 loss: 5.93968878e-07
Iter: 454 loss: 5.93127652e-07
Iter: 455 loss: 5.91090838e-07
Iter: 456 loss: 6.12283429e-07
Iter: 457 loss: 5.90834418e-07
Iter: 458 loss: 5.89077672e-07
Iter: 459 loss: 6.06375e-07
Iter: 460 loss: 5.89055617e-07
Iter: 461 loss: 5.87466275e-07
Iter: 462 loss: 5.91488515e-07
Iter: 463 loss: 5.86964347e-07
Iter: 464 loss: 5.85766657e-07
Iter: 465 loss: 5.95914e-07
Iter: 466 loss: 5.85726696e-07
Iter: 467 loss: 5.84337045e-07
Iter: 468 loss: 5.83175222e-07
Iter: 469 loss: 5.82796872e-07
Iter: 470 loss: 5.81282507e-07
Iter: 471 loss: 5.96142399e-07
Iter: 472 loss: 5.81256074e-07
Iter: 473 loss: 5.79525363e-07
Iter: 474 loss: 5.83283281e-07
Iter: 475 loss: 5.78885647e-07
Iter: 476 loss: 5.77851e-07
Iter: 477 loss: 5.79325103e-07
Iter: 478 loss: 5.77269475e-07
Iter: 479 loss: 5.76282446e-07
Iter: 480 loss: 5.79966297e-07
Iter: 481 loss: 5.76049501e-07
Iter: 482 loss: 5.7481e-07
Iter: 483 loss: 5.73868192e-07
Iter: 484 loss: 5.73478076e-07
Iter: 485 loss: 5.72202282e-07
Iter: 486 loss: 5.72528222e-07
Iter: 487 loss: 5.71265048e-07
Iter: 488 loss: 5.69739598e-07
Iter: 489 loss: 5.91578782e-07
Iter: 490 loss: 5.69724648e-07
Iter: 491 loss: 5.68948963e-07
Iter: 492 loss: 5.80051278e-07
Iter: 493 loss: 5.68970165e-07
Iter: 494 loss: 5.68254677e-07
Iter: 495 loss: 5.66602353e-07
Iter: 496 loss: 5.83840404e-07
Iter: 497 loss: 5.66386234e-07
Iter: 498 loss: 5.6459055e-07
Iter: 499 loss: 5.69571057e-07
Iter: 500 loss: 5.64013533e-07
Iter: 501 loss: 5.62312266e-07
Iter: 502 loss: 5.70792338e-07
Iter: 503 loss: 5.62060336e-07
Iter: 504 loss: 5.60517151e-07
Iter: 505 loss: 5.62420837e-07
Iter: 506 loss: 5.59670752e-07
Iter: 507 loss: 5.58307192e-07
Iter: 508 loss: 5.6882277e-07
Iter: 509 loss: 5.58199417e-07
Iter: 510 loss: 5.56750706e-07
Iter: 511 loss: 5.67861719e-07
Iter: 512 loss: 5.56623661e-07
Iter: 513 loss: 5.56117e-07
Iter: 514 loss: 5.55794941e-07
Iter: 515 loss: 5.5559758e-07
Iter: 516 loss: 5.5467109e-07
Iter: 517 loss: 5.57573458e-07
Iter: 518 loss: 5.54448775e-07
Iter: 519 loss: 5.53550194e-07
Iter: 520 loss: 5.53571681e-07
Iter: 521 loss: 5.52850622e-07
Iter: 522 loss: 5.51532708e-07
Iter: 523 loss: 5.53951622e-07
Iter: 524 loss: 5.5095586e-07
Iter: 525 loss: 5.50094342e-07
Iter: 526 loss: 5.50115374e-07
Iter: 527 loss: 5.49340598e-07
Iter: 528 loss: 5.47830041e-07
Iter: 529 loss: 5.76066441e-07
Iter: 530 loss: 5.47826971e-07
Iter: 531 loss: 5.46718638e-07
Iter: 532 loss: 5.46726142e-07
Iter: 533 loss: 5.45667376e-07
Iter: 534 loss: 5.47399e-07
Iter: 535 loss: 5.4518523e-07
Iter: 536 loss: 5.44169211e-07
Iter: 537 loss: 5.44633394e-07
Iter: 538 loss: 5.43501415e-07
Iter: 539 loss: 5.4242696e-07
Iter: 540 loss: 5.41050838e-07
Iter: 541 loss: 5.40962105e-07
Iter: 542 loss: 5.39484631e-07
Iter: 543 loss: 5.55445865e-07
Iter: 544 loss: 5.39437792e-07
Iter: 545 loss: 5.38467816e-07
Iter: 546 loss: 5.385e-07
Iter: 547 loss: 5.37554e-07
Iter: 548 loss: 5.38675351e-07
Iter: 549 loss: 5.37104086e-07
Iter: 550 loss: 5.36431742e-07
Iter: 551 loss: 5.34983201e-07
Iter: 552 loss: 5.56358543e-07
Iter: 553 loss: 5.34920844e-07
Iter: 554 loss: 5.34069272e-07
Iter: 555 loss: 5.34015328e-07
Iter: 556 loss: 5.33024945e-07
Iter: 557 loss: 5.31930823e-07
Iter: 558 loss: 5.31778483e-07
Iter: 559 loss: 5.30564193e-07
Iter: 560 loss: 5.4344207e-07
Iter: 561 loss: 5.30554189e-07
Iter: 562 loss: 5.29586714e-07
Iter: 563 loss: 5.32124034e-07
Iter: 564 loss: 5.2928533e-07
Iter: 565 loss: 5.28477187e-07
Iter: 566 loss: 5.2992317e-07
Iter: 567 loss: 5.28131636e-07
Iter: 568 loss: 5.2743917e-07
Iter: 569 loss: 5.3474389e-07
Iter: 570 loss: 5.2744042e-07
Iter: 571 loss: 5.26813494e-07
Iter: 572 loss: 5.26182419e-07
Iter: 573 loss: 5.26053384e-07
Iter: 574 loss: 5.25257235e-07
Iter: 575 loss: 5.25525138e-07
Iter: 576 loss: 5.24666234e-07
Iter: 577 loss: 5.23588142e-07
Iter: 578 loss: 5.28250212e-07
Iter: 579 loss: 5.23346102e-07
Iter: 580 loss: 5.22340429e-07
Iter: 581 loss: 5.234931e-07
Iter: 582 loss: 5.21799166e-07
Iter: 583 loss: 5.21763e-07
Iter: 584 loss: 5.21359482e-07
Iter: 585 loss: 5.2087637e-07
Iter: 586 loss: 5.19531227e-07
Iter: 587 loss: 5.25957148e-07
Iter: 588 loss: 5.19085859e-07
Iter: 589 loss: 5.1761873e-07
Iter: 590 loss: 5.2475616e-07
Iter: 591 loss: 5.17374303e-07
Iter: 592 loss: 5.16341515e-07
Iter: 593 loss: 5.22274377e-07
Iter: 594 loss: 5.16165585e-07
Iter: 595 loss: 5.15491536e-07
Iter: 596 loss: 5.20919343e-07
Iter: 597 loss: 5.15439e-07
Iter: 598 loss: 5.14611258e-07
Iter: 599 loss: 5.13453358e-07
Iter: 600 loss: 5.13409532e-07
Iter: 601 loss: 5.1247514e-07
Iter: 602 loss: 5.18449554e-07
Iter: 603 loss: 5.12398799e-07
Iter: 604 loss: 5.1137863e-07
Iter: 605 loss: 5.14476824e-07
Iter: 606 loss: 5.10996813e-07
Iter: 607 loss: 5.10254267e-07
Iter: 608 loss: 5.14805379e-07
Iter: 609 loss: 5.10159794e-07
Iter: 610 loss: 5.09450842e-07
Iter: 611 loss: 5.1068389e-07
Iter: 612 loss: 5.09182655e-07
Iter: 613 loss: 5.08324e-07
Iter: 614 loss: 5.07666869e-07
Iter: 615 loss: 5.07403342e-07
Iter: 616 loss: 5.06474692e-07
Iter: 617 loss: 5.06173137e-07
Iter: 618 loss: 5.05648586e-07
Iter: 619 loss: 5.05449123e-07
Iter: 620 loss: 5.05097034e-07
Iter: 621 loss: 5.04447485e-07
Iter: 622 loss: 5.04328909e-07
Iter: 623 loss: 5.0387996e-07
Iter: 624 loss: 5.03305955e-07
Iter: 625 loss: 5.0304061e-07
Iter: 626 loss: 5.02768785e-07
Iter: 627 loss: 5.01709e-07
Iter: 628 loss: 5.02221269e-07
Iter: 629 loss: 5.01044951e-07
Iter: 630 loss: 5.00359079e-07
Iter: 631 loss: 5.00355e-07
Iter: 632 loss: 4.99606472e-07
Iter: 633 loss: 4.99349198e-07
Iter: 634 loss: 4.98914176e-07
Iter: 635 loss: 4.98157647e-07
Iter: 636 loss: 5.0108747e-07
Iter: 637 loss: 4.98014856e-07
Iter: 638 loss: 4.97237863e-07
Iter: 639 loss: 5.00124315e-07
Iter: 640 loss: 4.9705011e-07
Iter: 641 loss: 4.96262658e-07
Iter: 642 loss: 4.99392854e-07
Iter: 643 loss: 4.96096334e-07
Iter: 644 loss: 4.95547056e-07
Iter: 645 loss: 4.97003157e-07
Iter: 646 loss: 4.95314339e-07
Iter: 647 loss: 4.94597487e-07
Iter: 648 loss: 4.94908e-07
Iter: 649 loss: 4.94105564e-07
Iter: 650 loss: 4.93506377e-07
Iter: 651 loss: 4.93669518e-07
Iter: 652 loss: 4.93041341e-07
Iter: 653 loss: 4.9216078e-07
Iter: 654 loss: 4.95279323e-07
Iter: 655 loss: 4.91927267e-07
Iter: 656 loss: 4.91547212e-07
Iter: 657 loss: 4.91463e-07
Iter: 658 loss: 4.9101817e-07
Iter: 659 loss: 4.90180469e-07
Iter: 660 loss: 5.0680751e-07
Iter: 661 loss: 4.90194338e-07
Iter: 662 loss: 4.89456511e-07
Iter: 663 loss: 4.89025865e-07
Iter: 664 loss: 4.88721753e-07
Iter: 665 loss: 4.87681518e-07
Iter: 666 loss: 4.91049093e-07
Iter: 667 loss: 4.87404122e-07
Iter: 668 loss: 4.86501563e-07
Iter: 669 loss: 4.99197654e-07
Iter: 670 loss: 4.86494457e-07
Iter: 671 loss: 4.85867872e-07
Iter: 672 loss: 4.88501257e-07
Iter: 673 loss: 4.85689725e-07
Iter: 674 loss: 4.85106227e-07
Iter: 675 loss: 4.84322641e-07
Iter: 676 loss: 4.84283419e-07
Iter: 677 loss: 4.83913368e-07
Iter: 678 loss: 4.83795418e-07
Iter: 679 loss: 4.83305598e-07
Iter: 680 loss: 4.82519795e-07
Iter: 681 loss: 4.82528833e-07
Iter: 682 loss: 4.81793109e-07
Iter: 683 loss: 4.91805793e-07
Iter: 684 loss: 4.81768666e-07
Iter: 685 loss: 4.8122331e-07
Iter: 686 loss: 4.80912888e-07
Iter: 687 loss: 4.80651693e-07
Iter: 688 loss: 4.79895505e-07
Iter: 689 loss: 4.83004328e-07
Iter: 690 loss: 4.79728328e-07
Iter: 691 loss: 4.79227538e-07
Iter: 692 loss: 4.80256631e-07
Iter: 693 loss: 4.79019263e-07
Iter: 694 loss: 4.78303832e-07
Iter: 695 loss: 4.83628696e-07
Iter: 696 loss: 4.78248523e-07
Iter: 697 loss: 4.77937419e-07
Iter: 698 loss: 4.77104209e-07
Iter: 699 loss: 4.82564189e-07
Iter: 700 loss: 4.7691185e-07
Iter: 701 loss: 4.75904329e-07
Iter: 702 loss: 4.83725159e-07
Iter: 703 loss: 4.75835122e-07
Iter: 704 loss: 4.75038206e-07
Iter: 705 loss: 4.75900038e-07
Iter: 706 loss: 4.74582691e-07
Iter: 707 loss: 4.74298872e-07
Iter: 708 loss: 4.74163443e-07
Iter: 709 loss: 4.73850861e-07
Iter: 710 loss: 4.73127926e-07
Iter: 711 loss: 4.82522864e-07
Iter: 712 loss: 4.73104421e-07
Iter: 713 loss: 4.7270629e-07
Iter: 714 loss: 4.72613578e-07
Iter: 715 loss: 4.72256431e-07
Iter: 716 loss: 4.7236162e-07
Iter: 717 loss: 4.72019877e-07
Iter: 718 loss: 4.71476909e-07
Iter: 719 loss: 4.72127454e-07
Iter: 720 loss: 4.7120929e-07
Iter: 721 loss: 4.70667686e-07
Iter: 722 loss: 4.71448573e-07
Iter: 723 loss: 4.70393161e-07
Iter: 724 loss: 4.69766661e-07
Iter: 725 loss: 4.70211432e-07
Iter: 726 loss: 4.6942e-07
Iter: 727 loss: 4.68860236e-07
Iter: 728 loss: 4.75124381e-07
Iter: 729 loss: 4.68824481e-07
Iter: 730 loss: 4.6820665e-07
Iter: 731 loss: 4.68434621e-07
Iter: 732 loss: 4.67700488e-07
Iter: 733 loss: 4.67292409e-07
Iter: 734 loss: 4.66854971e-07
Iter: 735 loss: 4.66786389e-07
Iter: 736 loss: 4.66071782e-07
Iter: 737 loss: 4.69676422e-07
Iter: 738 loss: 4.65906425e-07
Iter: 739 loss: 4.65270205e-07
Iter: 740 loss: 4.65676607e-07
Iter: 741 loss: 4.64848597e-07
Iter: 742 loss: 4.6432163e-07
Iter: 743 loss: 4.64291702e-07
Iter: 744 loss: 4.63854434e-07
Iter: 745 loss: 4.63681801e-07
Iter: 746 loss: 4.63461845e-07
Iter: 747 loss: 4.6308719e-07
Iter: 748 loss: 4.63075708e-07
Iter: 749 loss: 4.62780463e-07
Iter: 750 loss: 4.6228007e-07
Iter: 751 loss: 4.74938361e-07
Iter: 752 loss: 4.62290473e-07
Iter: 753 loss: 4.61467948e-07
Iter: 754 loss: 4.6285345e-07
Iter: 755 loss: 4.61132629e-07
Iter: 756 loss: 4.60640535e-07
Iter: 757 loss: 4.60673476e-07
Iter: 758 loss: 4.60325481e-07
Iter: 759 loss: 4.5963796e-07
Iter: 760 loss: 4.67674909e-07
Iter: 761 loss: 4.59574153e-07
Iter: 762 loss: 4.59459955e-07
Iter: 763 loss: 4.59197167e-07
Iter: 764 loss: 4.58792101e-07
Iter: 765 loss: 4.57972021e-07
Iter: 766 loss: 4.73296495e-07
Iter: 767 loss: 4.57969861e-07
Iter: 768 loss: 4.57379741e-07
Iter: 769 loss: 4.58398802e-07
Iter: 770 loss: 4.57124486e-07
Iter: 771 loss: 4.56397345e-07
Iter: 772 loss: 4.57008127e-07
Iter: 773 loss: 4.55941972e-07
Iter: 774 loss: 4.55182828e-07
Iter: 775 loss: 4.55973861e-07
Iter: 776 loss: 4.54762187e-07
Iter: 777 loss: 4.54109e-07
Iter: 778 loss: 4.59599477e-07
Iter: 779 loss: 4.54083875e-07
Iter: 780 loss: 4.53546193e-07
Iter: 781 loss: 4.55445161e-07
Iter: 782 loss: 4.53413037e-07
Iter: 783 loss: 4.52873678e-07
Iter: 784 loss: 4.56794027e-07
Iter: 785 loss: 4.52823485e-07
Iter: 786 loss: 4.52458551e-07
Iter: 787 loss: 4.52875128e-07
Iter: 788 loss: 4.52249878e-07
Iter: 789 loss: 4.51764e-07
Iter: 790 loss: 4.53790619e-07
Iter: 791 loss: 4.51676414e-07
Iter: 792 loss: 4.51229369e-07
Iter: 793 loss: 4.51367896e-07
Iter: 794 loss: 4.50902803e-07
Iter: 795 loss: 4.50325558e-07
Iter: 796 loss: 4.51213936e-07
Iter: 797 loss: 4.50066523e-07
Iter: 798 loss: 4.49615925e-07
Iter: 799 loss: 4.49606375e-07
Iter: 800 loss: 4.49335118e-07
Iter: 801 loss: 4.50018149e-07
Iter: 802 loss: 4.49241412e-07
Iter: 803 loss: 4.48926755e-07
Iter: 804 loss: 4.48380831e-07
Iter: 805 loss: 4.48367871e-07
Iter: 806 loss: 4.47768969e-07
Iter: 807 loss: 4.48778138e-07
Iter: 808 loss: 4.47487537e-07
Iter: 809 loss: 4.46929107e-07
Iter: 810 loss: 4.49556751e-07
Iter: 811 loss: 4.46798765e-07
Iter: 812 loss: 4.46291665e-07
Iter: 813 loss: 4.4575728e-07
Iter: 814 loss: 4.45678779e-07
Iter: 815 loss: 4.44845028e-07
Iter: 816 loss: 4.50815e-07
Iter: 817 loss: 4.44768943e-07
Iter: 818 loss: 4.43937495e-07
Iter: 819 loss: 4.46487888e-07
Iter: 820 loss: 4.43699548e-07
Iter: 821 loss: 4.4327939e-07
Iter: 822 loss: 4.43280271e-07
Iter: 823 loss: 4.42871226e-07
Iter: 824 loss: 4.42558786e-07
Iter: 825 loss: 4.42460845e-07
Iter: 826 loss: 4.42021275e-07
Iter: 827 loss: 4.49058064e-07
Iter: 828 loss: 4.42019513e-07
Iter: 829 loss: 4.41644772e-07
Iter: 830 loss: 4.41432348e-07
Iter: 831 loss: 4.41286488e-07
Iter: 832 loss: 4.40815768e-07
Iter: 833 loss: 4.4319e-07
Iter: 834 loss: 4.40741303e-07
Iter: 835 loss: 4.40341722e-07
Iter: 836 loss: 4.43704891e-07
Iter: 837 loss: 4.4033834e-07
Iter: 838 loss: 4.39985797e-07
Iter: 839 loss: 4.4011216e-07
Iter: 840 loss: 4.39758878e-07
Iter: 841 loss: 4.39238818e-07
Iter: 842 loss: 4.39523802e-07
Iter: 843 loss: 4.38907023e-07
Iter: 844 loss: 4.38459068e-07
Iter: 845 loss: 4.37856954e-07
Iter: 846 loss: 4.37823644e-07
Iter: 847 loss: 4.37155023e-07
Iter: 848 loss: 4.46760964e-07
Iter: 849 loss: 4.37153744e-07
Iter: 850 loss: 4.36749986e-07
Iter: 851 loss: 4.36248399e-07
Iter: 852 loss: 4.36170922e-07
Iter: 853 loss: 4.354564e-07
Iter: 854 loss: 4.3752874e-07
Iter: 855 loss: 4.35220102e-07
Iter: 856 loss: 4.34975277e-07
Iter: 857 loss: 4.34827598e-07
Iter: 858 loss: 4.34572371e-07
Iter: 859 loss: 4.3429867e-07
Iter: 860 loss: 4.34264933e-07
Iter: 861 loss: 4.33756071e-07
Iter: 862 loss: 4.36981964e-07
Iter: 863 loss: 4.33721823e-07
Iter: 864 loss: 4.33274238e-07
Iter: 865 loss: 4.33708976e-07
Iter: 866 loss: 4.33055703e-07
Iter: 867 loss: 4.32607237e-07
Iter: 868 loss: 4.34090765e-07
Iter: 869 loss: 4.32477634e-07
Iter: 870 loss: 4.31994181e-07
Iter: 871 loss: 4.351852e-07
Iter: 872 loss: 4.3194342e-07
Iter: 873 loss: 4.31665967e-07
Iter: 874 loss: 4.32114746e-07
Iter: 875 loss: 4.31530907e-07
Iter: 876 loss: 4.31147612e-07
Iter: 877 loss: 4.30807518e-07
Iter: 878 loss: 4.30737941e-07
Iter: 879 loss: 4.30330772e-07
Iter: 880 loss: 4.31353101e-07
Iter: 881 loss: 4.30178829e-07
Iter: 882 loss: 4.29626454e-07
Iter: 883 loss: 4.30193779e-07
Iter: 884 loss: 4.29335444e-07
Iter: 885 loss: 4.28757176e-07
Iter: 886 loss: 4.29097184e-07
Iter: 887 loss: 4.28380474e-07
Iter: 888 loss: 4.27786233e-07
Iter: 889 loss: 4.31948564e-07
Iter: 890 loss: 4.27685535e-07
Iter: 891 loss: 4.27273619e-07
Iter: 892 loss: 4.27272255e-07
Iter: 893 loss: 4.26943473e-07
Iter: 894 loss: 4.26554294e-07
Iter: 895 loss: 4.26511491e-07
Iter: 896 loss: 4.25944847e-07
Iter: 897 loss: 4.32267399e-07
Iter: 898 loss: 4.25941465e-07
Iter: 899 loss: 4.25613706e-07
Iter: 900 loss: 4.25844604e-07
Iter: 901 loss: 4.25410406e-07
Iter: 902 loss: 4.25088274e-07
Iter: 903 loss: 4.28317e-07
Iter: 904 loss: 4.25074433e-07
Iter: 905 loss: 4.24753438e-07
Iter: 906 loss: 4.24848338e-07
Iter: 907 loss: 4.24534676e-07
Iter: 908 loss: 4.24210924e-07
Iter: 909 loss: 4.25233935e-07
Iter: 910 loss: 4.241287e-07
Iter: 911 loss: 4.23771894e-07
Iter: 912 loss: 4.23412274e-07
Iter: 913 loss: 4.2333059e-07
Iter: 914 loss: 4.22849268e-07
Iter: 915 loss: 4.23347359e-07
Iter: 916 loss: 4.22585515e-07
Iter: 917 loss: 4.21870794e-07
Iter: 918 loss: 4.24691734e-07
Iter: 919 loss: 4.21753668e-07
Iter: 920 loss: 4.21258875e-07
Iter: 921 loss: 4.21069643e-07
Iter: 922 loss: 4.20787103e-07
Iter: 923 loss: 4.20203776e-07
Iter: 924 loss: 4.25499366e-07
Iter: 925 loss: 4.20173933e-07
Iter: 926 loss: 4.19770032e-07
Iter: 927 loss: 4.19762273e-07
Iter: 928 loss: 4.1952552e-07
Iter: 929 loss: 4.19671665e-07
Iter: 930 loss: 4.1936056e-07
Iter: 931 loss: 4.1903894e-07
Iter: 932 loss: 4.19998173e-07
Iter: 933 loss: 4.1891775e-07
Iter: 934 loss: 4.18536757e-07
Iter: 935 loss: 4.1909658e-07
Iter: 936 loss: 4.18357473e-07
Iter: 937 loss: 4.18160255e-07
Iter: 938 loss: 4.18148e-07
Iter: 939 loss: 4.17932199e-07
Iter: 940 loss: 4.17402504e-07
Iter: 941 loss: 4.25032681e-07
Iter: 942 loss: 4.17398667e-07
Iter: 943 loss: 4.17053741e-07
Iter: 944 loss: 4.17073863e-07
Iter: 945 loss: 4.16787771e-07
Iter: 946 loss: 4.16235878e-07
Iter: 947 loss: 4.25723982e-07
Iter: 948 loss: 4.16243665e-07
Iter: 949 loss: 4.1566679e-07
Iter: 950 loss: 4.1969858e-07
Iter: 951 loss: 4.15603154e-07
Iter: 952 loss: 4.15192432e-07
Iter: 953 loss: 4.15160798e-07
Iter: 954 loss: 4.14832328e-07
Iter: 955 loss: 4.14251417e-07
Iter: 956 loss: 4.15108815e-07
Iter: 957 loss: 4.13993376e-07
Iter: 958 loss: 4.13583962e-07
Iter: 959 loss: 4.13585553e-07
Iter: 960 loss: 4.13201064e-07
Iter: 961 loss: 4.14706278e-07
Iter: 962 loss: 4.13119494e-07
Iter: 963 loss: 4.12788438e-07
Iter: 964 loss: 4.13244095e-07
Iter: 965 loss: 4.12624217e-07
Iter: 966 loss: 4.12314e-07
Iter: 967 loss: 4.14617261e-07
Iter: 968 loss: 4.12301205e-07
Iter: 969 loss: 4.12020711e-07
Iter: 970 loss: 4.11968529e-07
Iter: 971 loss: 4.11789983e-07
Iter: 972 loss: 4.11450458e-07
Iter: 973 loss: 4.16779585e-07
Iter: 974 loss: 4.114342e-07
Iter: 975 loss: 4.11271571e-07
Iter: 976 loss: 4.10816966e-07
Iter: 977 loss: 4.14849296e-07
Iter: 978 loss: 4.10751881e-07
Iter: 979 loss: 4.1025271e-07
Iter: 980 loss: 4.16604763e-07
Iter: 981 loss: 4.10247083e-07
Iter: 982 loss: 4.09882659e-07
Iter: 983 loss: 4.09591252e-07
Iter: 984 loss: 4.09500046e-07
Iter: 985 loss: 4.08997124e-07
Iter: 986 loss: 4.1150173e-07
Iter: 987 loss: 4.08908818e-07
Iter: 988 loss: 4.08503411e-07
Iter: 989 loss: 4.08553461e-07
Iter: 990 loss: 4.08206375e-07
Iter: 991 loss: 4.07717522e-07
Iter: 992 loss: 4.09450024e-07
Iter: 993 loss: 4.07601021e-07
Iter: 994 loss: 4.07310978e-07
Iter: 995 loss: 4.07316122e-07
Iter: 996 loss: 4.070682e-07
Iter: 997 loss: 4.07517774e-07
Iter: 998 loss: 4.06948828e-07
Iter: 999 loss: 4.06676065e-07
Iter: 1000 loss: 4.06819595e-07
Iter: 1001 loss: 4.06510935e-07
Iter: 1002 loss: 4.06078897e-07
Iter: 1003 loss: 4.08207e-07
Iter: 1004 loss: 4.06026743e-07
Iter: 1005 loss: 4.0582745e-07
Iter: 1006 loss: 4.08122617e-07
Iter: 1007 loss: 4.05802268e-07
Iter: 1008 loss: 4.05591607e-07
Iter: 1009 loss: 4.05006404e-07
Iter: 1010 loss: 4.09149607e-07
Iter: 1011 loss: 4.0485e-07
Iter: 1012 loss: 4.04390079e-07
Iter: 1013 loss: 4.04383e-07
Iter: 1014 loss: 4.04017726e-07
Iter: 1015 loss: 4.04364755e-07
Iter: 1016 loss: 4.0381093e-07
Iter: 1017 loss: 4.03405181e-07
Iter: 1018 loss: 4.03595124e-07
Iter: 1019 loss: 4.03137904e-07
Iter: 1020 loss: 4.02673237e-07
Iter: 1021 loss: 4.04624103e-07
Iter: 1022 loss: 4.02561597e-07
Iter: 1023 loss: 4.02175743e-07
Iter: 1024 loss: 4.01958033e-07
Iter: 1025 loss: 4.01796513e-07
Iter: 1026 loss: 4.01401735e-07
Iter: 1027 loss: 4.01409181e-07
Iter: 1028 loss: 4.01095122e-07
Iter: 1029 loss: 4.03594271e-07
Iter: 1030 loss: 4.01068689e-07
Iter: 1031 loss: 4.00825684e-07
Iter: 1032 loss: 4.00789872e-07
Iter: 1033 loss: 4.00580092e-07
Iter: 1034 loss: 4.00314093e-07
Iter: 1035 loss: 4.02599539e-07
Iter: 1036 loss: 4.00291185e-07
Iter: 1037 loss: 4.0005358e-07
Iter: 1038 loss: 4.00212e-07
Iter: 1039 loss: 3.99906583e-07
Iter: 1040 loss: 3.99501857e-07
Iter: 1041 loss: 4.01528325e-07
Iter: 1042 loss: 3.99446094e-07
Iter: 1043 loss: 3.99236484e-07
Iter: 1044 loss: 3.98700422e-07
Iter: 1045 loss: 4.053677e-07
Iter: 1046 loss: 3.98667311e-07
Iter: 1047 loss: 3.9828862e-07
Iter: 1048 loss: 3.98262614e-07
Iter: 1049 loss: 3.98019466e-07
Iter: 1050 loss: 3.98249483e-07
Iter: 1051 loss: 3.97873663e-07
Iter: 1052 loss: 3.97611643e-07
Iter: 1053 loss: 3.97550195e-07
Iter: 1054 loss: 3.97350277e-07
Iter: 1055 loss: 3.96942113e-07
Iter: 1056 loss: 3.97199159e-07
Iter: 1057 loss: 3.9664215e-07
Iter: 1058 loss: 3.96189023e-07
Iter: 1059 loss: 3.99712746e-07
Iter: 1060 loss: 3.96102848e-07
Iter: 1061 loss: 3.95770769e-07
Iter: 1062 loss: 3.98082761e-07
Iter: 1063 loss: 3.95734787e-07
Iter: 1064 loss: 3.95380681e-07
Iter: 1065 loss: 3.97458052e-07
Iter: 1066 loss: 3.95329437e-07
Iter: 1067 loss: 3.95047522e-07
Iter: 1068 loss: 3.94841408e-07
Iter: 1069 loss: 3.94745626e-07
Iter: 1070 loss: 3.94360427e-07
Iter: 1071 loss: 3.94353293e-07
Iter: 1072 loss: 3.94182081e-07
Iter: 1073 loss: 3.94899104e-07
Iter: 1074 loss: 3.94130609e-07
Iter: 1075 loss: 3.93886523e-07
Iter: 1076 loss: 3.93643631e-07
Iter: 1077 loss: 3.93595741e-07
Iter: 1078 loss: 3.9333861e-07
Iter: 1079 loss: 3.9343621e-07
Iter: 1080 loss: 3.93112742e-07
Iter: 1081 loss: 3.9267988e-07
Iter: 1082 loss: 3.95392561e-07
Iter: 1083 loss: 3.92631847e-07
Iter: 1084 loss: 3.92312e-07
Iter: 1085 loss: 3.92947726e-07
Iter: 1086 loss: 3.92177071e-07
Iter: 1087 loss: 3.91823335e-07
Iter: 1088 loss: 3.91342155e-07
Iter: 1089 loss: 3.91342894e-07
Iter: 1090 loss: 3.90787818e-07
Iter: 1091 loss: 3.93425523e-07
Iter: 1092 loss: 3.90657931e-07
Iter: 1093 loss: 3.90129912e-07
Iter: 1094 loss: 3.93141079e-07
Iter: 1095 loss: 3.90082562e-07
Iter: 1096 loss: 3.8976674e-07
Iter: 1097 loss: 3.92822017e-07
Iter: 1098 loss: 3.89740023e-07
Iter: 1099 loss: 3.89441453e-07
Iter: 1100 loss: 3.89930904e-07
Iter: 1101 loss: 3.89282206e-07
Iter: 1102 loss: 3.89063871e-07
Iter: 1103 loss: 3.90433939e-07
Iter: 1104 loss: 3.89057902e-07
Iter: 1105 loss: 3.88804494e-07
Iter: 1106 loss: 3.89143679e-07
Iter: 1107 loss: 3.88694957e-07
Iter: 1108 loss: 3.88456442e-07
Iter: 1109 loss: 3.89456773e-07
Iter: 1110 loss: 3.88405084e-07
Iter: 1111 loss: 3.88150312e-07
Iter: 1112 loss: 3.87902901e-07
Iter: 1113 loss: 3.87854129e-07
Iter: 1114 loss: 3.87494254e-07
Iter: 1115 loss: 3.88644082e-07
Iter: 1116 loss: 3.87375167e-07
Iter: 1117 loss: 3.87091973e-07
Iter: 1118 loss: 3.89960661e-07
Iter: 1119 loss: 3.87066734e-07
Iter: 1120 loss: 3.86792294e-07
Iter: 1121 loss: 3.86518195e-07
Iter: 1122 loss: 3.86458e-07
Iter: 1123 loss: 3.85991171e-07
Iter: 1124 loss: 3.86056541e-07
Iter: 1125 loss: 3.85651674e-07
Iter: 1126 loss: 3.85185217e-07
Iter: 1127 loss: 3.90378375e-07
Iter: 1128 loss: 3.85197154e-07
Iter: 1129 loss: 3.84801183e-07
Iter: 1130 loss: 3.85641272e-07
Iter: 1131 loss: 3.8469e-07
Iter: 1132 loss: 3.84428972e-07
Iter: 1133 loss: 3.84436248e-07
Iter: 1134 loss: 3.84177042e-07
Iter: 1135 loss: 3.83790649e-07
Iter: 1136 loss: 3.83797328e-07
Iter: 1137 loss: 3.83660478e-07
Iter: 1138 loss: 3.83620034e-07
Iter: 1139 loss: 3.83426283e-07
Iter: 1140 loss: 3.83262659e-07
Iter: 1141 loss: 3.83227331e-07
Iter: 1142 loss: 3.82903522e-07
Iter: 1143 loss: 3.83765212e-07
Iter: 1144 loss: 3.82786453e-07
Iter: 1145 loss: 3.82522273e-07
Iter: 1146 loss: 3.83122426e-07
Iter: 1147 loss: 3.82423394e-07
Iter: 1148 loss: 3.82233623e-07
Iter: 1149 loss: 3.82307576e-07
Iter: 1150 loss: 3.82075456e-07
Iter: 1151 loss: 3.81686164e-07
Iter: 1152 loss: 3.82492317e-07
Iter: 1153 loss: 3.8154144e-07
Iter: 1154 loss: 3.81201062e-07
Iter: 1155 loss: 3.81273196e-07
Iter: 1156 loss: 3.80982101e-07
Iter: 1157 loss: 3.80581866e-07
Iter: 1158 loss: 3.81078735e-07
Iter: 1159 loss: 3.80373649e-07
Iter: 1160 loss: 3.7990975e-07
Iter: 1161 loss: 3.82202387e-07
Iter: 1162 loss: 3.79847421e-07
Iter: 1163 loss: 3.79501216e-07
Iter: 1164 loss: 3.81554287e-07
Iter: 1165 loss: 3.79464609e-07
Iter: 1166 loss: 3.79153732e-07
Iter: 1167 loss: 3.81730757e-07
Iter: 1168 loss: 3.79120735e-07
Iter: 1169 loss: 3.78945316e-07
Iter: 1170 loss: 3.78792265e-07
Iter: 1171 loss: 3.78755715e-07
Iter: 1172 loss: 3.78423806e-07
Iter: 1173 loss: 3.81833075e-07
Iter: 1174 loss: 3.78410505e-07
Iter: 1175 loss: 3.78236734e-07
Iter: 1176 loss: 3.78425e-07
Iter: 1177 loss: 3.78137884e-07
Iter: 1178 loss: 3.77900278e-07
Iter: 1179 loss: 3.78114578e-07
Iter: 1180 loss: 3.77778775e-07
Iter: 1181 loss: 3.77494786e-07
Iter: 1182 loss: 3.77762e-07
Iter: 1183 loss: 3.77346851e-07
Iter: 1184 loss: 3.77078038e-07
Iter: 1185 loss: 3.7826095e-07
Iter: 1186 loss: 3.77035065e-07
Iter: 1187 loss: 3.7670452e-07
Iter: 1188 loss: 3.76771197e-07
Iter: 1189 loss: 3.76452533e-07
Iter: 1190 loss: 3.76149899e-07
Iter: 1191 loss: 3.76206174e-07
Iter: 1192 loss: 3.75946172e-07
Iter: 1193 loss: 3.75540367e-07
Iter: 1194 loss: 3.77673558e-07
Iter: 1195 loss: 3.75479942e-07
Iter: 1196 loss: 3.75130043e-07
Iter: 1197 loss: 3.75568959e-07
Iter: 1198 loss: 3.74981767e-07
Iter: 1199 loss: 3.74785287e-07
Iter: 1200 loss: 3.74766273e-07
Iter: 1201 loss: 3.74554361e-07
Iter: 1202 loss: 3.7442345e-07
Iter: 1203 loss: 3.74338981e-07
Iter: 1204 loss: 3.74105923e-07
Iter: 1205 loss: 3.76480841e-07
Iter: 1206 loss: 3.74098562e-07
Iter: 1207 loss: 3.73871728e-07
Iter: 1208 loss: 3.74471938e-07
Iter: 1209 loss: 3.73809314e-07
Iter: 1210 loss: 3.73628779e-07
Iter: 1211 loss: 3.73663966e-07
Iter: 1212 loss: 3.73499148e-07
Iter: 1213 loss: 3.7322036e-07
Iter: 1214 loss: 3.73668513e-07
Iter: 1215 loss: 3.73127307e-07
Iter: 1216 loss: 3.72817681e-07
Iter: 1217 loss: 3.72639704e-07
Iter: 1218 loss: 3.72524084e-07
Iter: 1219 loss: 3.72265788e-07
Iter: 1220 loss: 3.72257603e-07
Iter: 1221 loss: 3.71966337e-07
Iter: 1222 loss: 3.71950478e-07
Iter: 1223 loss: 3.71725264e-07
Iter: 1224 loss: 3.71441956e-07
Iter: 1225 loss: 3.71576e-07
Iter: 1226 loss: 3.71249172e-07
Iter: 1227 loss: 3.70787831e-07
Iter: 1228 loss: 3.72031081e-07
Iter: 1229 loss: 3.70646774e-07
Iter: 1230 loss: 3.70346527e-07
Iter: 1231 loss: 3.71217624e-07
Iter: 1232 loss: 3.70263223e-07
Iter: 1233 loss: 3.700371e-07
Iter: 1234 loss: 3.70026498e-07
Iter: 1235 loss: 3.69878279e-07
Iter: 1236 loss: 3.69699364e-07
Iter: 1237 loss: 3.69675433e-07
Iter: 1238 loss: 3.69469035e-07
Iter: 1239 loss: 3.69476766e-07
Iter: 1240 loss: 3.69330763e-07
Iter: 1241 loss: 3.69198233e-07
Iter: 1242 loss: 3.6913525e-07
Iter: 1243 loss: 3.68942636e-07
Iter: 1244 loss: 3.69471763e-07
Iter: 1245 loss: 3.68854842e-07
Iter: 1246 loss: 3.6857034e-07
Iter: 1247 loss: 3.68812607e-07
Iter: 1248 loss: 3.68405779e-07
Iter: 1249 loss: 3.68210635e-07
Iter: 1250 loss: 3.68385599e-07
Iter: 1251 loss: 3.68069493e-07
Iter: 1252 loss: 3.67769701e-07
Iter: 1253 loss: 3.69906587e-07
Iter: 1254 loss: 3.67738437e-07
Iter: 1255 loss: 3.67458341e-07
Iter: 1256 loss: 3.6754e-07
Iter: 1257 loss: 3.67297901e-07
Iter: 1258 loss: 3.66957153e-07
Iter: 1259 loss: 3.67420057e-07
Iter: 1260 loss: 3.66814078e-07
Iter: 1261 loss: 3.66497261e-07
Iter: 1262 loss: 3.67042304e-07
Iter: 1263 loss: 3.66345546e-07
Iter: 1264 loss: 3.66089324e-07
Iter: 1265 loss: 3.6851759e-07
Iter: 1266 loss: 3.66064455e-07
Iter: 1267 loss: 3.65804738e-07
Iter: 1268 loss: 3.66966361e-07
Iter: 1269 loss: 3.65742807e-07
Iter: 1270 loss: 3.65606866e-07
Iter: 1271 loss: 3.66217165e-07
Iter: 1272 loss: 3.65566734e-07
Iter: 1273 loss: 3.65394669e-07
Iter: 1274 loss: 3.65613971e-07
Iter: 1275 loss: 3.65308495e-07
Iter: 1276 loss: 3.65113493e-07
Iter: 1277 loss: 3.65066342e-07
Iter: 1278 loss: 3.64964706e-07
Iter: 1279 loss: 3.64736195e-07
Iter: 1280 loss: 3.66810497e-07
Iter: 1281 loss: 3.64737559e-07
Iter: 1282 loss: 3.64560833e-07
Iter: 1283 loss: 3.64226878e-07
Iter: 1284 loss: 3.71040386e-07
Iter: 1285 loss: 3.64215623e-07
Iter: 1286 loss: 3.63916683e-07
Iter: 1287 loss: 3.67468715e-07
Iter: 1288 loss: 3.63887096e-07
Iter: 1289 loss: 3.63621666e-07
Iter: 1290 loss: 3.64490433e-07
Iter: 1291 loss: 3.63517898e-07
Iter: 1292 loss: 3.63255054e-07
Iter: 1293 loss: 3.6340964e-07
Iter: 1294 loss: 3.63102146e-07
Iter: 1295 loss: 3.62769583e-07
Iter: 1296 loss: 3.62907258e-07
Iter: 1297 loss: 3.62547866e-07
Iter: 1298 loss: 3.62196204e-07
Iter: 1299 loss: 3.63872772e-07
Iter: 1300 loss: 3.62153e-07
Iter: 1301 loss: 3.61974685e-07
Iter: 1302 loss: 3.61955102e-07
Iter: 1303 loss: 3.61814671e-07
Iter: 1304 loss: 3.61634847e-07
Iter: 1305 loss: 3.61611512e-07
Iter: 1306 loss: 3.61420945e-07
Iter: 1307 loss: 3.61416539e-07
Iter: 1308 loss: 3.61262863e-07
Iter: 1309 loss: 3.61145624e-07
Iter: 1310 loss: 3.6110373e-07
Iter: 1311 loss: 3.60919898e-07
Iter: 1312 loss: 3.61284719e-07
Iter: 1313 loss: 3.60826505e-07
Iter: 1314 loss: 3.60643156e-07
Iter: 1315 loss: 3.61580135e-07
Iter: 1316 loss: 3.60606919e-07
Iter: 1317 loss: 3.60458387e-07
Iter: 1318 loss: 3.60140746e-07
Iter: 1319 loss: 3.64606706e-07
Iter: 1320 loss: 3.60103343e-07
Iter: 1321 loss: 3.59855449e-07
Iter: 1322 loss: 3.59858888e-07
Iter: 1323 loss: 3.59666501e-07
Iter: 1324 loss: 3.600166e-07
Iter: 1325 loss: 3.59537864e-07
Iter: 1326 loss: 3.59332574e-07
Iter: 1327 loss: 3.59503986e-07
Iter: 1328 loss: 3.59217609e-07
Iter: 1329 loss: 3.5890551e-07
Iter: 1330 loss: 3.58909233e-07
Iter: 1331 loss: 3.58665034e-07
Iter: 1332 loss: 3.58391731e-07
Iter: 1333 loss: 3.58398552e-07
Iter: 1334 loss: 3.58214436e-07
Iter: 1335 loss: 3.59989087e-07
Iter: 1336 loss: 3.58193518e-07
Iter: 1337 loss: 3.58067126e-07
Iter: 1338 loss: 3.58203806e-07
Iter: 1339 loss: 3.58006304e-07
Iter: 1340 loss: 3.57855214e-07
Iter: 1341 loss: 3.59025279e-07
Iter: 1342 loss: 3.57839781e-07
Iter: 1343 loss: 3.57729391e-07
Iter: 1344 loss: 3.575189e-07
Iter: 1345 loss: 3.61373367e-07
Iter: 1346 loss: 3.57504916e-07
Iter: 1347 loss: 3.57268959e-07
Iter: 1348 loss: 3.5945385e-07
Iter: 1349 loss: 3.57242e-07
Iter: 1350 loss: 3.57014102e-07
Iter: 1351 loss: 3.56935686e-07
Iter: 1352 loss: 3.56784028e-07
Iter: 1353 loss: 3.56521667e-07
Iter: 1354 loss: 3.56925511e-07
Iter: 1355 loss: 3.56402438e-07
Iter: 1356 loss: 3.56109609e-07
Iter: 1357 loss: 3.58479554e-07
Iter: 1358 loss: 3.56092357e-07
Iter: 1359 loss: 3.55884652e-07
Iter: 1360 loss: 3.56746682e-07
Iter: 1361 loss: 3.558157e-07
Iter: 1362 loss: 3.55584632e-07
Iter: 1363 loss: 3.55254713e-07
Iter: 1364 loss: 3.552517e-07
Iter: 1365 loss: 3.54953499e-07
Iter: 1366 loss: 3.56744749e-07
Iter: 1367 loss: 3.54931899e-07
Iter: 1368 loss: 3.54732748e-07
Iter: 1369 loss: 3.54725444e-07
Iter: 1370 loss: 3.54552839e-07
Iter: 1371 loss: 3.54665929e-07
Iter: 1372 loss: 3.5446098e-07
Iter: 1373 loss: 3.54304632e-07
Iter: 1374 loss: 3.55934731e-07
Iter: 1375 loss: 3.542998e-07
Iter: 1376 loss: 3.54157692e-07
Iter: 1377 loss: 3.53985911e-07
Iter: 1378 loss: 3.53971444e-07
Iter: 1379 loss: 3.53772e-07
Iter: 1380 loss: 3.5393515e-07
Iter: 1381 loss: 3.53648971e-07
Iter: 1382 loss: 3.53372059e-07
Iter: 1383 loss: 3.55314398e-07
Iter: 1384 loss: 3.53344262e-07
Iter: 1385 loss: 3.53155485e-07
Iter: 1386 loss: 3.53110295e-07
Iter: 1387 loss: 3.53003969e-07
Iter: 1388 loss: 3.527378e-07
Iter: 1389 loss: 3.53214602e-07
Iter: 1390 loss: 3.52626898e-07
Iter: 1391 loss: 3.52373632e-07
Iter: 1392 loss: 3.54601468e-07
Iter: 1393 loss: 3.52370819e-07
Iter: 1394 loss: 3.5214822e-07
Iter: 1395 loss: 3.52540582e-07
Iter: 1396 loss: 3.52047607e-07
Iter: 1397 loss: 3.51888644e-07
Iter: 1398 loss: 3.51711321e-07
Iter: 1399 loss: 3.51683411e-07
Iter: 1400 loss: 3.51420681e-07
Iter: 1401 loss: 3.53673698e-07
Iter: 1402 loss: 3.51419658e-07
Iter: 1403 loss: 3.51189101e-07
Iter: 1404 loss: 3.5282028e-07
Iter: 1405 loss: 3.51183473e-07
Iter: 1406 loss: 3.51009191e-07
Iter: 1407 loss: 3.51202431e-07
Iter: 1408 loss: 3.50903122e-07
Iter: 1409 loss: 3.50717755e-07
Iter: 1410 loss: 3.52785122e-07
Iter: 1411 loss: 3.50726623e-07
Iter: 1412 loss: 3.50620667e-07
Iter: 1413 loss: 3.50306834e-07
Iter: 1414 loss: 3.52270263e-07
Iter: 1415 loss: 3.50257039e-07
Iter: 1416 loss: 3.49995958e-07
Iter: 1417 loss: 3.50007156e-07
Iter: 1418 loss: 3.49800729e-07
Iter: 1419 loss: 3.50002267e-07
Iter: 1420 loss: 3.4971103e-07
Iter: 1421 loss: 3.49489341e-07
Iter: 1422 loss: 3.4962892e-07
Iter: 1423 loss: 3.49337427e-07
Iter: 1424 loss: 3.4909641e-07
Iter: 1425 loss: 3.49665839e-07
Iter: 1426 loss: 3.49041159e-07
Iter: 1427 loss: 3.48822368e-07
Iter: 1428 loss: 3.51049863e-07
Iter: 1429 loss: 3.48835243e-07
Iter: 1430 loss: 3.48659654e-07
Iter: 1431 loss: 3.48554096e-07
Iter: 1432 loss: 3.48462493e-07
Iter: 1433 loss: 3.48249046e-07
Iter: 1434 loss: 3.48579277e-07
Iter: 1435 loss: 3.48139e-07
Iter: 1436 loss: 3.47842416e-07
Iter: 1437 loss: 3.49145409e-07
Iter: 1438 loss: 3.47809362e-07
Iter: 1439 loss: 3.47650143e-07
Iter: 1440 loss: 3.47654066e-07
Iter: 1441 loss: 3.47530431e-07
Iter: 1442 loss: 3.47411117e-07
Iter: 1443 loss: 3.47351119e-07
Iter: 1444 loss: 3.47104105e-07
Iter: 1445 loss: 3.48585218e-07
Iter: 1446 loss: 3.47073808e-07
Iter: 1447 loss: 3.46966289e-07
Iter: 1448 loss: 3.46660471e-07
Iter: 1449 loss: 3.50865378e-07
Iter: 1450 loss: 3.46669424e-07
Iter: 1451 loss: 3.46421132e-07
Iter: 1452 loss: 3.49203162e-07
Iter: 1453 loss: 3.46411099e-07
Iter: 1454 loss: 3.4620075e-07
Iter: 1455 loss: 3.47309197e-07
Iter: 1456 loss: 3.46185345e-07
Iter: 1457 loss: 3.45972495e-07
Iter: 1458 loss: 3.45847184e-07
Iter: 1459 loss: 3.45799094e-07
Iter: 1460 loss: 3.45578542e-07
Iter: 1461 loss: 3.46075581e-07
Iter: 1462 loss: 3.45500325e-07
Iter: 1463 loss: 3.45304443e-07
Iter: 1464 loss: 3.47344354e-07
Iter: 1465 loss: 3.45309189e-07
Iter: 1466 loss: 3.45141046e-07
Iter: 1467 loss: 3.45534545e-07
Iter: 1468 loss: 3.45112028e-07
Iter: 1469 loss: 3.44941128e-07
Iter: 1470 loss: 3.44866322e-07
Iter: 1471 loss: 3.44785917e-07
Iter: 1472 loss: 3.4451142e-07
Iter: 1473 loss: 3.44522391e-07
Iter: 1474 loss: 3.44329e-07
Iter: 1475 loss: 3.44217426e-07
Iter: 1476 loss: 3.44123634e-07
Iter: 1477 loss: 3.43963194e-07
Iter: 1478 loss: 3.44018758e-07
Iter: 1479 loss: 3.4384334e-07
Iter: 1480 loss: 3.43675254e-07
Iter: 1481 loss: 3.45220371e-07
Iter: 1482 loss: 3.43666102e-07
Iter: 1483 loss: 3.43557588e-07
Iter: 1484 loss: 3.43357073e-07
Iter: 1485 loss: 3.48482104e-07
Iter: 1486 loss: 3.43350052e-07
Iter: 1487 loss: 3.43095195e-07
Iter: 1488 loss: 3.43584873e-07
Iter: 1489 loss: 3.43008139e-07
Iter: 1490 loss: 3.42815241e-07
Iter: 1491 loss: 3.44400718e-07
Iter: 1492 loss: 3.42826752e-07
Iter: 1493 loss: 3.42639737e-07
Iter: 1494 loss: 3.42798955e-07
Iter: 1495 loss: 3.42523379e-07
Iter: 1496 loss: 3.42382805e-07
Iter: 1497 loss: 3.42246523e-07
Iter: 1498 loss: 3.42200792e-07
Iter: 1499 loss: 3.41963386e-07
Iter: 1500 loss: 3.43866645e-07
Iter: 1501 loss: 3.41952557e-07
Iter: 1502 loss: 3.41788336e-07
Iter: 1503 loss: 3.42521304e-07
Iter: 1504 loss: 3.41751388e-07
Iter: 1505 loss: 3.41545615e-07
Iter: 1506 loss: 3.41826421e-07
Iter: 1507 loss: 3.41457337e-07
Iter: 1508 loss: 3.41303632e-07
Iter: 1509 loss: 3.41387647e-07
Iter: 1510 loss: 3.41186876e-07
Iter: 1511 loss: 3.41082028e-07
Iter: 1512 loss: 3.41059149e-07
Iter: 1513 loss: 3.40964135e-07
Iter: 1514 loss: 3.40924487e-07
Iter: 1515 loss: 3.40873612e-07
Iter: 1516 loss: 3.40714962e-07
Iter: 1517 loss: 3.41516341e-07
Iter: 1518 loss: 3.4071e-07
Iter: 1519 loss: 3.40554493e-07
Iter: 1520 loss: 3.40447343e-07
Iter: 1521 loss: 3.40397463e-07
Iter: 1522 loss: 3.4023563e-07
Iter: 1523 loss: 3.40178588e-07
Iter: 1524 loss: 3.40114411e-07
Iter: 1525 loss: 3.39883371e-07
Iter: 1526 loss: 3.40596785e-07
Iter: 1527 loss: 3.39832866e-07
Iter: 1528 loss: 3.39588752e-07
Iter: 1529 loss: 3.42110155e-07
Iter: 1530 loss: 3.39553367e-07
Iter: 1531 loss: 3.39455141e-07
Iter: 1532 loss: 3.39301607e-07
Iter: 1533 loss: 3.39296264e-07
Iter: 1534 loss: 3.39046608e-07
Iter: 1535 loss: 3.39971791e-07
Iter: 1536 loss: 3.39018015e-07
Iter: 1537 loss: 3.38810736e-07
Iter: 1538 loss: 3.38788624e-07
Iter: 1539 loss: 3.38653479e-07
Iter: 1540 loss: 3.38497046e-07
Iter: 1541 loss: 3.38475786e-07
Iter: 1542 loss: 3.38356898e-07
Iter: 1543 loss: 3.38205496e-07
Iter: 1544 loss: 3.38185941e-07
Iter: 1545 loss: 3.38011546e-07
Iter: 1546 loss: 3.38024506e-07
Iter: 1547 loss: 3.37870915e-07
Iter: 1548 loss: 3.38235168e-07
Iter: 1549 loss: 3.3783968e-07
Iter: 1550 loss: 3.37715505e-07
Iter: 1551 loss: 3.37795427e-07
Iter: 1552 loss: 3.37645531e-07
Iter: 1553 loss: 3.37457493e-07
Iter: 1554 loss: 3.38066286e-07
Iter: 1555 loss: 3.37394738e-07
Iter: 1556 loss: 3.37275139e-07
Iter: 1557 loss: 3.37076358e-07
Iter: 1558 loss: 3.3706209e-07
Iter: 1559 loss: 3.36875615e-07
Iter: 1560 loss: 3.38274106e-07
Iter: 1561 loss: 3.36840429e-07
Iter: 1562 loss: 3.36700282e-07
Iter: 1563 loss: 3.37581298e-07
Iter: 1564 loss: 3.36640454e-07
Iter: 1565 loss: 3.3646927e-07
Iter: 1566 loss: 3.36656569e-07
Iter: 1567 loss: 3.36394635e-07
Iter: 1568 loss: 3.36204977e-07
Iter: 1569 loss: 3.36274e-07
Iter: 1570 loss: 3.36098424e-07
Iter: 1571 loss: 3.35886739e-07
Iter: 1572 loss: 3.35849307e-07
Iter: 1573 loss: 3.35706602e-07
Iter: 1574 loss: 3.35415223e-07
Iter: 1575 loss: 3.38487382e-07
Iter: 1576 loss: 3.3543688e-07
Iter: 1577 loss: 3.35223746e-07
Iter: 1578 loss: 3.35675793e-07
Iter: 1579 loss: 3.35164941e-07
Iter: 1580 loss: 3.34999356e-07
Iter: 1581 loss: 3.37213578e-07
Iter: 1582 loss: 3.34998816e-07
Iter: 1583 loss: 3.3488044e-07
Iter: 1584 loss: 3.34641157e-07
Iter: 1585 loss: 3.38249123e-07
Iter: 1586 loss: 3.3463175e-07
Iter: 1587 loss: 3.34385845e-07
Iter: 1588 loss: 3.37029576e-07
Iter: 1589 loss: 3.34384083e-07
Iter: 1590 loss: 3.34290092e-07
Iter: 1591 loss: 3.3428222e-07
Iter: 1592 loss: 3.34216821e-07
Iter: 1593 loss: 3.34136445e-07
Iter: 1594 loss: 3.34131414e-07
Iter: 1595 loss: 3.3398581e-07
Iter: 1596 loss: 3.34930348e-07
Iter: 1597 loss: 3.33967279e-07
Iter: 1598 loss: 3.33850409e-07
Iter: 1599 loss: 3.33635569e-07
Iter: 1600 loss: 3.37213038e-07
Iter: 1601 loss: 3.33634461e-07
Iter: 1602 loss: 3.33487094e-07
Iter: 1603 loss: 3.33474077e-07
Iter: 1604 loss: 3.33363118e-07
Iter: 1605 loss: 3.33233572e-07
Iter: 1606 loss: 3.3321092e-07
Iter: 1607 loss: 3.32997189e-07
Iter: 1608 loss: 3.33273931e-07
Iter: 1609 loss: 3.32902658e-07
Iter: 1610 loss: 3.32666616e-07
Iter: 1611 loss: 3.33182982e-07
Iter: 1612 loss: 3.32596301e-07
Iter: 1613 loss: 3.3235608e-07
Iter: 1614 loss: 3.32607073e-07
Iter: 1615 loss: 3.32226534e-07
Iter: 1616 loss: 3.32048785e-07
Iter: 1617 loss: 3.32034404e-07
Iter: 1618 loss: 3.31915e-07
Iter: 1619 loss: 3.31908552e-07
Iter: 1620 loss: 3.31805438e-07
Iter: 1621 loss: 3.31639512e-07
Iter: 1622 loss: 3.3223e-07
Iter: 1623 loss: 3.31568202e-07
Iter: 1624 loss: 3.31478134e-07
Iter: 1625 loss: 3.31469238e-07
Iter: 1626 loss: 3.31384342e-07
Iter: 1627 loss: 3.31244564e-07
Iter: 1628 loss: 3.34391927e-07
Iter: 1629 loss: 3.31228364e-07
Iter: 1630 loss: 3.31078951e-07
Iter: 1631 loss: 3.31082873e-07
Iter: 1632 loss: 3.3098587e-07
Iter: 1633 loss: 3.30824832e-07
Iter: 1634 loss: 3.32554976e-07
Iter: 1635 loss: 3.30787742e-07
Iter: 1636 loss: 3.30640404e-07
Iter: 1637 loss: 3.30627785e-07
Iter: 1638 loss: 3.30498125e-07
Iter: 1639 loss: 3.30390662e-07
Iter: 1640 loss: 3.30350417e-07
Iter: 1641 loss: 3.30147429e-07
Iter: 1642 loss: 3.3062318e-07
Iter: 1643 loss: 3.30061e-07
Iter: 1644 loss: 3.29854686e-07
Iter: 1645 loss: 3.29906925e-07
Iter: 1646 loss: 3.29698508e-07
Iter: 1647 loss: 3.29493e-07
Iter: 1648 loss: 3.31111181e-07
Iter: 1649 loss: 3.29492138e-07
Iter: 1650 loss: 3.29318254e-07
Iter: 1651 loss: 3.30346893e-07
Iter: 1652 loss: 3.29287786e-07
Iter: 1653 loss: 3.29103329e-07
Iter: 1654 loss: 3.29397523e-07
Iter: 1655 loss: 3.29005957e-07
Iter: 1656 loss: 3.28837388e-07
Iter: 1657 loss: 3.2921065e-07
Iter: 1658 loss: 3.28750104e-07
Iter: 1659 loss: 3.2866e-07
Iter: 1660 loss: 3.28642273e-07
Iter: 1661 loss: 3.28556581e-07
Iter: 1662 loss: 3.28472368e-07
Iter: 1663 loss: 3.28469696e-07
Iter: 1664 loss: 3.2831332e-07
Iter: 1665 loss: 3.29322233e-07
Iter: 1666 loss: 3.28306271e-07
Iter: 1667 loss: 3.2820779e-07
Iter: 1668 loss: 3.280079e-07
Iter: 1669 loss: 3.30462683e-07
Iter: 1670 loss: 3.28011083e-07
Iter: 1671 loss: 3.27794169e-07
Iter: 1672 loss: 3.30499745e-07
Iter: 1673 loss: 3.27795476e-07
Iter: 1674 loss: 3.27675423e-07
Iter: 1675 loss: 3.28351177e-07
Iter: 1676 loss: 3.27647399e-07
Iter: 1677 loss: 3.27487726e-07
Iter: 1678 loss: 3.2727246e-07
Iter: 1679 loss: 3.27268538e-07
Iter: 1680 loss: 3.27029539e-07
Iter: 1681 loss: 3.2751143e-07
Iter: 1682 loss: 3.26945525e-07
Iter: 1683 loss: 3.2676104e-07
Iter: 1684 loss: 3.28634e-07
Iter: 1685 loss: 3.26765985e-07
Iter: 1686 loss: 3.26589202e-07
Iter: 1687 loss: 3.26836073e-07
Iter: 1688 loss: 3.26515874e-07
Iter: 1689 loss: 3.26361828e-07
Iter: 1690 loss: 3.28155e-07
Iter: 1691 loss: 3.26349664e-07
Iter: 1692 loss: 3.26212e-07
Iter: 1693 loss: 3.26104725e-07
Iter: 1694 loss: 3.26098814e-07
Iter: 1695 loss: 3.25954261e-07
Iter: 1696 loss: 3.25954915e-07
Iter: 1697 loss: 3.25880364e-07
Iter: 1698 loss: 3.2577546e-07
Iter: 1699 loss: 3.25758322e-07
Iter: 1700 loss: 3.25614394e-07
Iter: 1701 loss: 3.27045512e-07
Iter: 1702 loss: 3.25592282e-07
Iter: 1703 loss: 3.25518556e-07
Iter: 1704 loss: 3.25353312e-07
Iter: 1705 loss: 3.2879268e-07
Iter: 1706 loss: 3.25342029e-07
Iter: 1707 loss: 3.25143105e-07
Iter: 1708 loss: 3.25677433e-07
Iter: 1709 loss: 3.25069891e-07
Iter: 1710 loss: 3.24905216e-07
Iter: 1711 loss: 3.27136433e-07
Iter: 1712 loss: 3.24908569e-07
Iter: 1713 loss: 3.24753756e-07
Iter: 1714 loss: 3.24769218e-07
Iter: 1715 loss: 3.24649761e-07
Iter: 1716 loss: 3.24507653e-07
Iter: 1717 loss: 3.24431568e-07
Iter: 1718 loss: 3.24368045e-07
Iter: 1719 loss: 3.2414755e-07
Iter: 1720 loss: 3.25529186e-07
Iter: 1721 loss: 3.24098124e-07
Iter: 1722 loss: 3.23942629e-07
Iter: 1723 loss: 3.2452445e-07
Iter: 1724 loss: 3.23883057e-07
Iter: 1725 loss: 3.23677739e-07
Iter: 1726 loss: 3.24674062e-07
Iter: 1727 loss: 3.23637494e-07
Iter: 1728 loss: 3.23506129e-07
Iter: 1729 loss: 3.24013712e-07
Iter: 1730 loss: 3.23494675e-07
Iter: 1731 loss: 3.23310871e-07
Iter: 1732 loss: 3.2361811e-07
Iter: 1733 loss: 3.23248969e-07
Iter: 1734 loss: 3.23149834e-07
Iter: 1735 loss: 3.23648749e-07
Iter: 1736 loss: 3.23137982e-07
Iter: 1737 loss: 3.23038932e-07
Iter: 1738 loss: 3.22986125e-07
Iter: 1739 loss: 3.22921778e-07
Iter: 1740 loss: 3.22779812e-07
Iter: 1741 loss: 3.22783677e-07
Iter: 1742 loss: 3.226518e-07
Iter: 1743 loss: 3.22471976e-07
Iter: 1744 loss: 3.23137783e-07
Iter: 1745 loss: 3.22438183e-07
Iter: 1746 loss: 3.22275071e-07
Iter: 1747 loss: 3.24133737e-07
Iter: 1748 loss: 3.22274332e-07
Iter: 1749 loss: 3.22173833e-07
Iter: 1750 loss: 3.22003558e-07
Iter: 1751 loss: 3.21976358e-07
Iter: 1752 loss: 3.21786899e-07
Iter: 1753 loss: 3.22501734e-07
Iter: 1754 loss: 3.2175106e-07
Iter: 1755 loss: 3.21562e-07
Iter: 1756 loss: 3.21879213e-07
Iter: 1757 loss: 3.21436829e-07
Iter: 1758 loss: 3.21279288e-07
Iter: 1759 loss: 3.23273639e-07
Iter: 1760 loss: 3.21264764e-07
Iter: 1761 loss: 3.21091903e-07
Iter: 1762 loss: 3.21270761e-07
Iter: 1763 loss: 3.20986828e-07
Iter: 1764 loss: 3.20886e-07
Iter: 1765 loss: 3.20883942e-07
Iter: 1766 loss: 3.20806606e-07
Iter: 1767 loss: 3.2060646e-07
Iter: 1768 loss: 3.22801156e-07
Iter: 1769 loss: 3.20585229e-07
Iter: 1770 loss: 3.20490756e-07
Iter: 1771 loss: 3.20444258e-07
Iter: 1772 loss: 3.20355355e-07
Iter: 1773 loss: 3.20247523e-07
Iter: 1774 loss: 3.20241327e-07
Iter: 1775 loss: 3.20062043e-07
Iter: 1776 loss: 3.20326649e-07
Iter: 1777 loss: 3.19993319e-07
Iter: 1778 loss: 3.19853086e-07
Iter: 1779 loss: 3.19966432e-07
Iter: 1780 loss: 3.19714985e-07
Iter: 1781 loss: 3.19509098e-07
Iter: 1782 loss: 3.21513369e-07
Iter: 1783 loss: 3.19492926e-07
Iter: 1784 loss: 3.19340131e-07
Iter: 1785 loss: 3.19367558e-07
Iter: 1786 loss: 3.19253814e-07
Iter: 1787 loss: 3.19041192e-07
Iter: 1788 loss: 3.19094397e-07
Iter: 1789 loss: 3.18890471e-07
Iter: 1790 loss: 3.18649711e-07
Iter: 1791 loss: 3.19974902e-07
Iter: 1792 loss: 3.18600172e-07
Iter: 1793 loss: 3.18476509e-07
Iter: 1794 loss: 3.18460536e-07
Iter: 1795 loss: 3.18355831e-07
Iter: 1796 loss: 3.18377317e-07
Iter: 1797 loss: 3.18264597e-07
Iter: 1798 loss: 3.18103389e-07
Iter: 1799 loss: 3.18519255e-07
Iter: 1800 loss: 3.17997205e-07
Iter: 1801 loss: 3.1791177e-07
Iter: 1802 loss: 3.18285572e-07
Iter: 1803 loss: 3.17887668e-07
Iter: 1804 loss: 3.17774834e-07
Iter: 1805 loss: 3.17875759e-07
Iter: 1806 loss: 3.17716e-07
Iter: 1807 loss: 3.17598364e-07
Iter: 1808 loss: 3.17558317e-07
Iter: 1809 loss: 3.17490333e-07
Iter: 1810 loss: 3.17320882e-07
Iter: 1811 loss: 3.17683515e-07
Iter: 1812 loss: 3.1724602e-07
Iter: 1813 loss: 3.17131367e-07
Iter: 1814 loss: 3.19132369e-07
Iter: 1815 loss: 3.17124432e-07
Iter: 1816 loss: 3.16976582e-07
Iter: 1817 loss: 3.1674864e-07
Iter: 1818 loss: 3.16746565e-07
Iter: 1819 loss: 3.16469794e-07
Iter: 1820 loss: 3.18234385e-07
Iter: 1821 loss: 3.16451633e-07
Iter: 1822 loss: 3.16259445e-07
Iter: 1823 loss: 3.16219428e-07
Iter: 1824 loss: 3.16114949e-07
Iter: 1825 loss: 3.15917049e-07
Iter: 1826 loss: 3.15918669e-07
Iter: 1827 loss: 3.15753425e-07
Iter: 1828 loss: 3.1649904e-07
Iter: 1829 loss: 3.15728755e-07
Iter: 1830 loss: 3.15607679e-07
Iter: 1831 loss: 3.16539683e-07
Iter: 1832 loss: 3.15592388e-07
Iter: 1833 loss: 3.15506725e-07
Iter: 1834 loss: 3.15327355e-07
Iter: 1835 loss: 3.18476509e-07
Iter: 1836 loss: 3.15311922e-07
Iter: 1837 loss: 3.15209775e-07
Iter: 1838 loss: 3.15203835e-07
Iter: 1839 loss: 3.15118569e-07
Iter: 1840 loss: 3.14909869e-07
Iter: 1841 loss: 3.17756871e-07
Iter: 1842 loss: 3.14895829e-07
Iter: 1843 loss: 3.14654358e-07
Iter: 1844 loss: 3.15695218e-07
Iter: 1845 loss: 3.14625908e-07
Iter: 1846 loss: 3.14465353e-07
Iter: 1847 loss: 3.15123373e-07
Iter: 1848 loss: 3.14429968e-07
Iter: 1849 loss: 3.14235109e-07
Iter: 1850 loss: 3.14982827e-07
Iter: 1851 loss: 3.14207057e-07
Iter: 1852 loss: 3.14036356e-07
Iter: 1853 loss: 3.13995372e-07
Iter: 1854 loss: 3.13899136e-07
Iter: 1855 loss: 3.13685206e-07
Iter: 1856 loss: 3.14378752e-07
Iter: 1857 loss: 3.13643341e-07
Iter: 1858 loss: 3.13437539e-07
Iter: 1859 loss: 3.13421225e-07
Iter: 1860 loss: 3.13280452e-07
Iter: 1861 loss: 3.13164378e-07
Iter: 1862 loss: 3.13116914e-07
Iter: 1863 loss: 3.13010275e-07
Iter: 1864 loss: 3.1323961e-07
Iter: 1865 loss: 3.12986401e-07
Iter: 1866 loss: 3.12859981e-07
Iter: 1867 loss: 3.12856486e-07
Iter: 1868 loss: 3.12750046e-07
Iter: 1869 loss: 3.12606517e-07
Iter: 1870 loss: 3.12768094e-07
Iter: 1871 loss: 3.1252236e-07
Iter: 1872 loss: 3.12357542e-07
Iter: 1873 loss: 3.1374077e-07
Iter: 1874 loss: 3.12336311e-07
Iter: 1875 loss: 3.1221262e-07
Iter: 1876 loss: 3.12165639e-07
Iter: 1877 loss: 3.12124143e-07
Iter: 1878 loss: 3.11917375e-07
Iter: 1879 loss: 3.11901772e-07
Iter: 1880 loss: 3.11785755e-07
Iter: 1881 loss: 3.11602491e-07
Iter: 1882 loss: 3.13746028e-07
Iter: 1883 loss: 3.11585552e-07
Iter: 1884 loss: 3.11403539e-07
Iter: 1885 loss: 3.11811618e-07
Iter: 1886 loss: 3.11342149e-07
Iter: 1887 loss: 3.11176819e-07
Iter: 1888 loss: 3.11233e-07
Iter: 1889 loss: 3.11094482e-07
Iter: 1890 loss: 3.10848264e-07
Iter: 1891 loss: 3.1091534e-07
Iter: 1892 loss: 3.10695e-07
Iter: 1893 loss: 3.10509648e-07
Iter: 1894 loss: 3.11664877e-07
Iter: 1895 loss: 3.10479692e-07
Iter: 1896 loss: 3.10314306e-07
Iter: 1897 loss: 3.12645e-07
Iter: 1898 loss: 3.10308e-07
Iter: 1899 loss: 3.10220571e-07
Iter: 1900 loss: 3.10467527e-07
Iter: 1901 loss: 3.10175039e-07
Iter: 1902 loss: 3.10043532e-07
Iter: 1903 loss: 3.10017356e-07
Iter: 1904 loss: 3.09916544e-07
Iter: 1905 loss: 3.09765085e-07
Iter: 1906 loss: 3.10329483e-07
Iter: 1907 loss: 3.09733622e-07
Iter: 1908 loss: 3.09591513e-07
Iter: 1909 loss: 3.10482591e-07
Iter: 1910 loss: 3.09583641e-07
Iter: 1911 loss: 3.09456709e-07
Iter: 1912 loss: 3.09246843e-07
Iter: 1913 loss: 3.09254574e-07
Iter: 1914 loss: 3.09015093e-07
Iter: 1915 loss: 3.09205689e-07
Iter: 1916 loss: 3.08874064e-07
Iter: 1917 loss: 3.0872414e-07
Iter: 1918 loss: 3.08711634e-07
Iter: 1919 loss: 3.08567792e-07
Iter: 1920 loss: 3.0876447e-07
Iter: 1921 loss: 3.08494606e-07
Iter: 1922 loss: 3.08316089e-07
Iter: 1923 loss: 3.08262258e-07
Iter: 1924 loss: 3.0817219e-07
Iter: 1925 loss: 3.07932339e-07
Iter: 1926 loss: 3.08680114e-07
Iter: 1927 loss: 3.07850598e-07
Iter: 1928 loss: 3.07687543e-07
Iter: 1929 loss: 3.07559191e-07
Iter: 1930 loss: 3.07523862e-07
Iter: 1931 loss: 3.07463097e-07
Iter: 1932 loss: 3.07394657e-07
Iter: 1933 loss: 3.07292026e-07
Iter: 1934 loss: 3.07570019e-07
Iter: 1935 loss: 3.07252634e-07
Iter: 1936 loss: 3.0714935e-07
Iter: 1937 loss: 3.07178e-07
Iter: 1938 loss: 3.07082814e-07
Iter: 1939 loss: 3.06904496e-07
Iter: 1940 loss: 3.07070223e-07
Iter: 1941 loss: 3.06820255e-07
Iter: 1942 loss: 3.06703214e-07
Iter: 1943 loss: 3.07737821e-07
Iter: 1944 loss: 3.06706198e-07
Iter: 1945 loss: 3.06577789e-07
Iter: 1946 loss: 3.06525692e-07
Iter: 1947 loss: 3.06469246e-07
Iter: 1948 loss: 3.06331572e-07
Iter: 1949 loss: 3.06135178e-07
Iter: 1950 loss: 3.06126935e-07
Iter: 1951 loss: 3.05938499e-07
Iter: 1952 loss: 3.07358135e-07
Iter: 1953 loss: 3.05915023e-07
Iter: 1954 loss: 3.05727553e-07
Iter: 1955 loss: 3.06368349e-07
Iter: 1956 loss: 3.05678157e-07
Iter: 1957 loss: 3.05505949e-07
Iter: 1958 loss: 3.05968314e-07
Iter: 1959 loss: 3.05430376e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2
+ date
Mon Oct 26 18:41:26 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd964146158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd964124a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd964124d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9641efe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9641d99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9640b7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd964071b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd96400c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd96400c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd96400c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963f9f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963fa2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963fa2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963f40378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963f298c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963f26c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963edc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963ee7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963e8e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963e8eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963e4f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963e0fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963dcc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963dfa730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd963dfa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94193a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9418f5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9418c0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9418b8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd9418e02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94189b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94185e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94185e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd91c0e16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd91c105840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd91c0c0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.48621175e-05
Iter: 2 loss: 1.22713891e-05
Iter: 3 loss: 1.21934627e-05
Iter: 4 loss: 1.12051903e-05
Iter: 5 loss: 2.28426507e-05
Iter: 6 loss: 1.11916761e-05
Iter: 7 loss: 1.08366075e-05
Iter: 8 loss: 1.02262566e-05
Iter: 9 loss: 1.02254162e-05
Iter: 10 loss: 9.44746e-06
Iter: 11 loss: 1.41788878e-05
Iter: 12 loss: 9.3529361e-06
Iter: 13 loss: 8.98054623e-06
Iter: 14 loss: 9.58688088e-06
Iter: 15 loss: 8.80946391e-06
Iter: 16 loss: 8.3756222e-06
Iter: 17 loss: 9.03598811e-06
Iter: 18 loss: 8.16987904e-06
Iter: 19 loss: 7.75834269e-06
Iter: 20 loss: 8.40130269e-06
Iter: 21 loss: 7.56578265e-06
Iter: 22 loss: 7.06606352e-06
Iter: 23 loss: 8.17034197e-06
Iter: 24 loss: 6.87451802e-06
Iter: 25 loss: 6.43509429e-06
Iter: 26 loss: 8.22211587e-06
Iter: 27 loss: 6.33804711e-06
Iter: 28 loss: 5.9296e-06
Iter: 29 loss: 8.8277975e-06
Iter: 30 loss: 5.8933515e-06
Iter: 31 loss: 5.68205451e-06
Iter: 32 loss: 5.73764282e-06
Iter: 33 loss: 5.52876463e-06
Iter: 34 loss: 5.2289015e-06
Iter: 35 loss: 5.84457666e-06
Iter: 36 loss: 5.10823793e-06
Iter: 37 loss: 4.83938038e-06
Iter: 38 loss: 5.8632113e-06
Iter: 39 loss: 4.7752992e-06
Iter: 40 loss: 4.6135774e-06
Iter: 41 loss: 5.59443242e-06
Iter: 42 loss: 4.59367857e-06
Iter: 43 loss: 4.48502669e-06
Iter: 44 loss: 6.08394157e-06
Iter: 45 loss: 4.48500714e-06
Iter: 46 loss: 4.36344089e-06
Iter: 47 loss: 4.51227061e-06
Iter: 48 loss: 4.29995907e-06
Iter: 49 loss: 4.23637766e-06
Iter: 50 loss: 4.11295423e-06
Iter: 51 loss: 6.64315803e-06
Iter: 52 loss: 4.11208066e-06
Iter: 53 loss: 3.96376709e-06
Iter: 54 loss: 4.77987123e-06
Iter: 55 loss: 3.94226072e-06
Iter: 56 loss: 3.80638721e-06
Iter: 57 loss: 4.3151058e-06
Iter: 58 loss: 3.77332526e-06
Iter: 59 loss: 3.61023694e-06
Iter: 60 loss: 4.10776e-06
Iter: 61 loss: 3.56181272e-06
Iter: 62 loss: 3.47750461e-06
Iter: 63 loss: 3.47366836e-06
Iter: 64 loss: 3.40890642e-06
Iter: 65 loss: 3.26533564e-06
Iter: 66 loss: 3.96077303e-06
Iter: 67 loss: 3.23991662e-06
Iter: 68 loss: 3.18250932e-06
Iter: 69 loss: 3.07563869e-06
Iter: 70 loss: 5.52475422e-06
Iter: 71 loss: 3.0754868e-06
Iter: 72 loss: 2.98410396e-06
Iter: 73 loss: 2.97873476e-06
Iter: 74 loss: 2.92647064e-06
Iter: 75 loss: 3.00555666e-06
Iter: 76 loss: 2.90152138e-06
Iter: 77 loss: 2.83250347e-06
Iter: 78 loss: 2.90442699e-06
Iter: 79 loss: 2.79425285e-06
Iter: 80 loss: 2.74174818e-06
Iter: 81 loss: 3.05691674e-06
Iter: 82 loss: 2.73518458e-06
Iter: 83 loss: 2.66894131e-06
Iter: 84 loss: 2.99323756e-06
Iter: 85 loss: 2.65731501e-06
Iter: 86 loss: 2.6302796e-06
Iter: 87 loss: 2.60884644e-06
Iter: 88 loss: 2.60077e-06
Iter: 89 loss: 2.55343252e-06
Iter: 90 loss: 2.48460901e-06
Iter: 91 loss: 2.48249489e-06
Iter: 92 loss: 2.40978625e-06
Iter: 93 loss: 3.14961039e-06
Iter: 94 loss: 2.40757731e-06
Iter: 95 loss: 2.35918674e-06
Iter: 96 loss: 3.07129812e-06
Iter: 97 loss: 2.35913467e-06
Iter: 98 loss: 2.32983757e-06
Iter: 99 loss: 2.32517527e-06
Iter: 100 loss: 2.30506384e-06
Iter: 101 loss: 2.27168061e-06
Iter: 102 loss: 2.29297052e-06
Iter: 103 loss: 2.25034978e-06
Iter: 104 loss: 2.21120831e-06
Iter: 105 loss: 2.44785224e-06
Iter: 106 loss: 2.20659467e-06
Iter: 107 loss: 2.16857e-06
Iter: 108 loss: 2.25394388e-06
Iter: 109 loss: 2.15421232e-06
Iter: 110 loss: 2.11784936e-06
Iter: 111 loss: 2.11559563e-06
Iter: 112 loss: 2.08806478e-06
Iter: 113 loss: 2.03487616e-06
Iter: 114 loss: 2.3944533e-06
Iter: 115 loss: 2.02959291e-06
Iter: 116 loss: 2.0132461e-06
Iter: 117 loss: 2.01248577e-06
Iter: 118 loss: 1.99784358e-06
Iter: 119 loss: 2.04331491e-06
Iter: 120 loss: 1.99345413e-06
Iter: 121 loss: 1.97437066e-06
Iter: 122 loss: 1.93273786e-06
Iter: 123 loss: 2.56024737e-06
Iter: 124 loss: 1.93112578e-06
Iter: 125 loss: 1.90493779e-06
Iter: 126 loss: 2.0423995e-06
Iter: 127 loss: 1.90074934e-06
Iter: 128 loss: 1.87243904e-06
Iter: 129 loss: 1.85543274e-06
Iter: 130 loss: 1.84359851e-06
Iter: 131 loss: 1.80426446e-06
Iter: 132 loss: 1.99249257e-06
Iter: 133 loss: 1.79706285e-06
Iter: 134 loss: 1.78613982e-06
Iter: 135 loss: 1.77977972e-06
Iter: 136 loss: 1.77122388e-06
Iter: 137 loss: 1.75994205e-06
Iter: 138 loss: 1.75929927e-06
Iter: 139 loss: 1.7384408e-06
Iter: 140 loss: 1.72540808e-06
Iter: 141 loss: 1.71715919e-06
Iter: 142 loss: 1.69433406e-06
Iter: 143 loss: 1.74290244e-06
Iter: 144 loss: 1.68527299e-06
Iter: 145 loss: 1.66432733e-06
Iter: 146 loss: 1.916678e-06
Iter: 147 loss: 1.66403402e-06
Iter: 148 loss: 1.64261223e-06
Iter: 149 loss: 1.64106348e-06
Iter: 150 loss: 1.62499964e-06
Iter: 151 loss: 1.61299045e-06
Iter: 152 loss: 1.61160142e-06
Iter: 153 loss: 1.60026093e-06
Iter: 154 loss: 1.65316976e-06
Iter: 155 loss: 1.59828937e-06
Iter: 156 loss: 1.58811872e-06
Iter: 157 loss: 1.56247472e-06
Iter: 158 loss: 1.78845619e-06
Iter: 159 loss: 1.55841576e-06
Iter: 160 loss: 1.54133284e-06
Iter: 161 loss: 1.54128475e-06
Iter: 162 loss: 1.52733401e-06
Iter: 163 loss: 1.52046687e-06
Iter: 164 loss: 1.51389929e-06
Iter: 165 loss: 1.49222444e-06
Iter: 166 loss: 1.57349689e-06
Iter: 167 loss: 1.4869338e-06
Iter: 168 loss: 1.47356434e-06
Iter: 169 loss: 1.51859967e-06
Iter: 170 loss: 1.46996251e-06
Iter: 171 loss: 1.45782042e-06
Iter: 172 loss: 1.61159323e-06
Iter: 173 loss: 1.45765466e-06
Iter: 174 loss: 1.44843375e-06
Iter: 175 loss: 1.43292e-06
Iter: 176 loss: 1.43283705e-06
Iter: 177 loss: 1.41957162e-06
Iter: 178 loss: 1.50242499e-06
Iter: 179 loss: 1.4179991e-06
Iter: 180 loss: 1.40425982e-06
Iter: 181 loss: 1.40200495e-06
Iter: 182 loss: 1.39265399e-06
Iter: 183 loss: 1.37718098e-06
Iter: 184 loss: 1.43219745e-06
Iter: 185 loss: 1.37316408e-06
Iter: 186 loss: 1.35805374e-06
Iter: 187 loss: 1.4816801e-06
Iter: 188 loss: 1.35711957e-06
Iter: 189 loss: 1.35210848e-06
Iter: 190 loss: 1.35168307e-06
Iter: 191 loss: 1.34602442e-06
Iter: 192 loss: 1.3417349e-06
Iter: 193 loss: 1.33980461e-06
Iter: 194 loss: 1.33084632e-06
Iter: 195 loss: 1.34121206e-06
Iter: 196 loss: 1.32598348e-06
Iter: 197 loss: 1.3183801e-06
Iter: 198 loss: 1.30654007e-06
Iter: 199 loss: 1.30636988e-06
Iter: 200 loss: 1.29772707e-06
Iter: 201 loss: 1.29696048e-06
Iter: 202 loss: 1.2902799e-06
Iter: 203 loss: 1.28249133e-06
Iter: 204 loss: 1.28160264e-06
Iter: 205 loss: 1.26632142e-06
Iter: 206 loss: 1.30908347e-06
Iter: 207 loss: 1.26150019e-06
Iter: 208 loss: 1.25311863e-06
Iter: 209 loss: 1.27208648e-06
Iter: 210 loss: 1.24997484e-06
Iter: 211 loss: 1.2425927e-06
Iter: 212 loss: 1.34198513e-06
Iter: 213 loss: 1.2425827e-06
Iter: 214 loss: 1.23584505e-06
Iter: 215 loss: 1.24166991e-06
Iter: 216 loss: 1.23192262e-06
Iter: 217 loss: 1.2234143e-06
Iter: 218 loss: 1.22448841e-06
Iter: 219 loss: 1.21687981e-06
Iter: 220 loss: 1.20853088e-06
Iter: 221 loss: 1.22036306e-06
Iter: 222 loss: 1.2042899e-06
Iter: 223 loss: 1.19384367e-06
Iter: 224 loss: 1.23505765e-06
Iter: 225 loss: 1.19144715e-06
Iter: 226 loss: 1.18311141e-06
Iter: 227 loss: 1.21793119e-06
Iter: 228 loss: 1.1813255e-06
Iter: 229 loss: 1.1750576e-06
Iter: 230 loss: 1.17492186e-06
Iter: 231 loss: 1.17116701e-06
Iter: 232 loss: 1.17087723e-06
Iter: 233 loss: 1.16814567e-06
Iter: 234 loss: 1.16319097e-06
Iter: 235 loss: 1.15301123e-06
Iter: 236 loss: 1.3314484e-06
Iter: 237 loss: 1.15278885e-06
Iter: 238 loss: 1.13943224e-06
Iter: 239 loss: 1.21214725e-06
Iter: 240 loss: 1.13756425e-06
Iter: 241 loss: 1.1297227e-06
Iter: 242 loss: 1.17507329e-06
Iter: 243 loss: 1.12868065e-06
Iter: 244 loss: 1.12346424e-06
Iter: 245 loss: 1.15831926e-06
Iter: 246 loss: 1.12293856e-06
Iter: 247 loss: 1.11834913e-06
Iter: 248 loss: 1.11078498e-06
Iter: 249 loss: 1.11084705e-06
Iter: 250 loss: 1.10293786e-06
Iter: 251 loss: 1.14934937e-06
Iter: 252 loss: 1.10189853e-06
Iter: 253 loss: 1.09506698e-06
Iter: 254 loss: 1.17515674e-06
Iter: 255 loss: 1.09495534e-06
Iter: 256 loss: 1.09027212e-06
Iter: 257 loss: 1.09780694e-06
Iter: 258 loss: 1.08805466e-06
Iter: 259 loss: 1.08273605e-06
Iter: 260 loss: 1.07705091e-06
Iter: 261 loss: 1.07617802e-06
Iter: 262 loss: 1.06912876e-06
Iter: 263 loss: 1.07425706e-06
Iter: 264 loss: 1.06485493e-06
Iter: 265 loss: 1.06501898e-06
Iter: 266 loss: 1.06035202e-06
Iter: 267 loss: 1.05759386e-06
Iter: 268 loss: 1.05689514e-06
Iter: 269 loss: 1.05527738e-06
Iter: 270 loss: 1.05224012e-06
Iter: 271 loss: 1.04785374e-06
Iter: 272 loss: 1.04770186e-06
Iter: 273 loss: 1.03879211e-06
Iter: 274 loss: 1.04121432e-06
Iter: 275 loss: 1.03220145e-06
Iter: 276 loss: 1.02790523e-06
Iter: 277 loss: 1.09228154e-06
Iter: 278 loss: 1.02789784e-06
Iter: 279 loss: 1.02401668e-06
Iter: 280 loss: 1.01825844e-06
Iter: 281 loss: 1.01815453e-06
Iter: 282 loss: 1.01150522e-06
Iter: 283 loss: 1.11739723e-06
Iter: 284 loss: 1.01152273e-06
Iter: 285 loss: 1.00795614e-06
Iter: 286 loss: 1.0032137e-06
Iter: 287 loss: 1.00292777e-06
Iter: 288 loss: 9.96520839e-07
Iter: 289 loss: 1.03774732e-06
Iter: 290 loss: 9.95868163e-07
Iter: 291 loss: 9.90195531e-07
Iter: 292 loss: 9.95224696e-07
Iter: 293 loss: 9.86959094e-07
Iter: 294 loss: 9.84079179e-07
Iter: 295 loss: 9.83934569e-07
Iter: 296 loss: 9.80751111e-07
Iter: 297 loss: 9.79641527e-07
Iter: 298 loss: 9.77790137e-07
Iter: 299 loss: 9.75010266e-07
Iter: 300 loss: 1.01292903e-06
Iter: 301 loss: 9.75045168e-07
Iter: 302 loss: 9.72219254e-07
Iter: 303 loss: 9.7790371e-07
Iter: 304 loss: 9.71110239e-07
Iter: 305 loss: 9.69034318e-07
Iter: 306 loss: 9.65195341e-07
Iter: 307 loss: 1.05071149e-06
Iter: 308 loss: 9.65194e-07
Iter: 309 loss: 9.59760541e-07
Iter: 310 loss: 9.56076e-07
Iter: 311 loss: 9.54012194e-07
Iter: 312 loss: 9.50228866e-07
Iter: 313 loss: 9.50060155e-07
Iter: 314 loss: 9.46354589e-07
Iter: 315 loss: 9.4751573e-07
Iter: 316 loss: 9.43765258e-07
Iter: 317 loss: 9.39335962e-07
Iter: 318 loss: 9.72834414e-07
Iter: 319 loss: 9.39073743e-07
Iter: 320 loss: 9.35582818e-07
Iter: 321 loss: 9.37945e-07
Iter: 322 loss: 9.33365e-07
Iter: 323 loss: 9.29451346e-07
Iter: 324 loss: 9.28018494e-07
Iter: 325 loss: 9.25891072e-07
Iter: 326 loss: 9.19662341e-07
Iter: 327 loss: 9.83536438e-07
Iter: 328 loss: 9.19523927e-07
Iter: 329 loss: 9.15688247e-07
Iter: 330 loss: 9.30124884e-07
Iter: 331 loss: 9.14789894e-07
Iter: 332 loss: 9.10944436e-07
Iter: 333 loss: 9.11836764e-07
Iter: 334 loss: 9.08034281e-07
Iter: 335 loss: 9.05957052e-07
Iter: 336 loss: 9.05291529e-07
Iter: 337 loss: 9.03784667e-07
Iter: 338 loss: 9.07692424e-07
Iter: 339 loss: 9.03215266e-07
Iter: 340 loss: 9.01274e-07
Iter: 341 loss: 8.98428652e-07
Iter: 342 loss: 8.98343956e-07
Iter: 343 loss: 8.94856953e-07
Iter: 344 loss: 8.96612733e-07
Iter: 345 loss: 8.92560251e-07
Iter: 346 loss: 8.88250725e-07
Iter: 347 loss: 8.90692718e-07
Iter: 348 loss: 8.855327e-07
Iter: 349 loss: 8.82213271e-07
Iter: 350 loss: 8.97704354e-07
Iter: 351 loss: 8.81606184e-07
Iter: 352 loss: 8.77254e-07
Iter: 353 loss: 8.83744519e-07
Iter: 354 loss: 8.75156672e-07
Iter: 355 loss: 8.71720772e-07
Iter: 356 loss: 8.69154803e-07
Iter: 357 loss: 8.67977064e-07
Iter: 358 loss: 8.63241382e-07
Iter: 359 loss: 9.37422328e-07
Iter: 360 loss: 8.63253831e-07
Iter: 361 loss: 8.59631086e-07
Iter: 362 loss: 8.6462677e-07
Iter: 363 loss: 8.57820737e-07
Iter: 364 loss: 8.54857774e-07
Iter: 365 loss: 8.91072432e-07
Iter: 366 loss: 8.54789164e-07
Iter: 367 loss: 8.526481e-07
Iter: 368 loss: 8.55667281e-07
Iter: 369 loss: 8.5159752e-07
Iter: 370 loss: 8.49842138e-07
Iter: 371 loss: 8.49872436e-07
Iter: 372 loss: 8.48095965e-07
Iter: 373 loss: 8.47099102e-07
Iter: 374 loss: 8.46406238e-07
Iter: 375 loss: 8.43315547e-07
Iter: 376 loss: 8.48796503e-07
Iter: 377 loss: 8.41909184e-07
Iter: 378 loss: 8.39814e-07
Iter: 379 loss: 8.4402518e-07
Iter: 380 loss: 8.39013467e-07
Iter: 381 loss: 8.36956531e-07
Iter: 382 loss: 8.36871777e-07
Iter: 383 loss: 8.35320066e-07
Iter: 384 loss: 8.32610226e-07
Iter: 385 loss: 8.52727339e-07
Iter: 386 loss: 8.32379101e-07
Iter: 387 loss: 8.29689952e-07
Iter: 388 loss: 8.26568794e-07
Iter: 389 loss: 8.26279347e-07
Iter: 390 loss: 8.22851e-07
Iter: 391 loss: 8.58437318e-07
Iter: 392 loss: 8.22765287e-07
Iter: 393 loss: 8.20096602e-07
Iter: 394 loss: 8.16246882e-07
Iter: 395 loss: 8.16078796e-07
Iter: 396 loss: 8.12675182e-07
Iter: 397 loss: 8.67615654e-07
Iter: 398 loss: 8.12657902e-07
Iter: 399 loss: 8.09872063e-07
Iter: 400 loss: 8.12694907e-07
Iter: 401 loss: 8.08319612e-07
Iter: 402 loss: 8.0631645e-07
Iter: 403 loss: 8.21179356e-07
Iter: 404 loss: 8.06208391e-07
Iter: 405 loss: 8.04089495e-07
Iter: 406 loss: 8.18071385e-07
Iter: 407 loss: 8.038744e-07
Iter: 408 loss: 8.01931265e-07
Iter: 409 loss: 8.10345341e-07
Iter: 410 loss: 8.01529666e-07
Iter: 411 loss: 8.00490739e-07
Iter: 412 loss: 8.01075601e-07
Iter: 413 loss: 7.99780537e-07
Iter: 414 loss: 7.9810718e-07
Iter: 415 loss: 7.97241e-07
Iter: 416 loss: 7.96483448e-07
Iter: 417 loss: 7.93818458e-07
Iter: 418 loss: 8.03684202e-07
Iter: 419 loss: 7.93126333e-07
Iter: 420 loss: 7.91264824e-07
Iter: 421 loss: 7.91506864e-07
Iter: 422 loss: 7.89791e-07
Iter: 423 loss: 7.87874512e-07
Iter: 424 loss: 8.08132882e-07
Iter: 425 loss: 7.87801412e-07
Iter: 426 loss: 7.8589909e-07
Iter: 427 loss: 7.85918587e-07
Iter: 428 loss: 7.84364829e-07
Iter: 429 loss: 7.82152256e-07
Iter: 430 loss: 7.8290276e-07
Iter: 431 loss: 7.80584e-07
Iter: 432 loss: 7.77035666e-07
Iter: 433 loss: 7.91580646e-07
Iter: 434 loss: 7.76286129e-07
Iter: 435 loss: 7.73296961e-07
Iter: 436 loss: 7.76834e-07
Iter: 437 loss: 7.71749e-07
Iter: 438 loss: 7.69872145e-07
Iter: 439 loss: 7.94094888e-07
Iter: 440 loss: 7.69862254e-07
Iter: 441 loss: 7.68373184e-07
Iter: 442 loss: 7.73016e-07
Iter: 443 loss: 7.67959932e-07
Iter: 444 loss: 7.6557842e-07
Iter: 445 loss: 7.71064265e-07
Iter: 446 loss: 7.64729805e-07
Iter: 447 loss: 7.63666e-07
Iter: 448 loss: 7.64736967e-07
Iter: 449 loss: 7.63087769e-07
Iter: 450 loss: 7.61680496e-07
Iter: 451 loss: 7.63862602e-07
Iter: 452 loss: 7.61047772e-07
Iter: 453 loss: 7.58949113e-07
Iter: 454 loss: 7.58073838e-07
Iter: 455 loss: 7.57013652e-07
Iter: 456 loss: 7.54985706e-07
Iter: 457 loss: 7.72502176e-07
Iter: 458 loss: 7.54883729e-07
Iter: 459 loss: 7.53148583e-07
Iter: 460 loss: 7.54959729e-07
Iter: 461 loss: 7.52243466e-07
Iter: 462 loss: 7.50312324e-07
Iter: 463 loss: 7.48661932e-07
Iter: 464 loss: 7.48175694e-07
Iter: 465 loss: 7.45850684e-07
Iter: 466 loss: 7.45749958e-07
Iter: 467 loss: 7.44543e-07
Iter: 468 loss: 7.43474459e-07
Iter: 469 loss: 7.43146586e-07
Iter: 470 loss: 7.40341704e-07
Iter: 471 loss: 7.44225645e-07
Iter: 472 loss: 7.38961e-07
Iter: 473 loss: 7.36909783e-07
Iter: 474 loss: 7.41044e-07
Iter: 475 loss: 7.36122786e-07
Iter: 476 loss: 7.3565343e-07
Iter: 477 loss: 7.35124104e-07
Iter: 478 loss: 7.340401e-07
Iter: 479 loss: 7.32496744e-07
Iter: 480 loss: 7.32447234e-07
Iter: 481 loss: 7.30745114e-07
Iter: 482 loss: 7.3153069e-07
Iter: 483 loss: 7.29671228e-07
Iter: 484 loss: 7.2795774e-07
Iter: 485 loss: 7.47303773e-07
Iter: 486 loss: 7.27948191e-07
Iter: 487 loss: 7.26459234e-07
Iter: 488 loss: 7.2615444e-07
Iter: 489 loss: 7.2519174e-07
Iter: 490 loss: 7.23691e-07
Iter: 491 loss: 7.26564281e-07
Iter: 492 loss: 7.23100698e-07
Iter: 493 loss: 7.2131968e-07
Iter: 494 loss: 7.2815385e-07
Iter: 495 loss: 7.20882497e-07
Iter: 496 loss: 7.19521211e-07
Iter: 497 loss: 7.23785718e-07
Iter: 498 loss: 7.191e-07
Iter: 499 loss: 7.17427952e-07
Iter: 500 loss: 7.15125452e-07
Iter: 501 loss: 7.15021486e-07
Iter: 502 loss: 7.12976828e-07
Iter: 503 loss: 7.13000134e-07
Iter: 504 loss: 7.11383905e-07
Iter: 505 loss: 7.11590587e-07
Iter: 506 loss: 7.10207871e-07
Iter: 507 loss: 7.08234666e-07
Iter: 508 loss: 7.19142747e-07
Iter: 509 loss: 7.07899744e-07
Iter: 510 loss: 7.07018614e-07
Iter: 511 loss: 7.07005768e-07
Iter: 512 loss: 7.05893967e-07
Iter: 513 loss: 7.03913599e-07
Iter: 514 loss: 7.03924e-07
Iter: 515 loss: 7.02804073e-07
Iter: 516 loss: 7.08208518e-07
Iter: 517 loss: 7.02632178e-07
Iter: 518 loss: 7.01488887e-07
Iter: 519 loss: 7.02203351e-07
Iter: 520 loss: 7.00842065e-07
Iter: 521 loss: 6.98810823e-07
Iter: 522 loss: 7.01681699e-07
Iter: 523 loss: 6.97878e-07
Iter: 524 loss: 6.96382813e-07
Iter: 525 loss: 6.95902486e-07
Iter: 526 loss: 6.95057054e-07
Iter: 527 loss: 6.92948674e-07
Iter: 528 loss: 7.10468044e-07
Iter: 529 loss: 6.92804178e-07
Iter: 530 loss: 6.91525088e-07
Iter: 531 loss: 6.95444442e-07
Iter: 532 loss: 6.91144521e-07
Iter: 533 loss: 6.89716785e-07
Iter: 534 loss: 6.9075395e-07
Iter: 535 loss: 6.88858e-07
Iter: 536 loss: 6.86937369e-07
Iter: 537 loss: 6.86769454e-07
Iter: 538 loss: 6.85405098e-07
Iter: 539 loss: 6.83748e-07
Iter: 540 loss: 6.8367433e-07
Iter: 541 loss: 6.82514724e-07
Iter: 542 loss: 6.81098072e-07
Iter: 543 loss: 6.80966878e-07
Iter: 544 loss: 6.81393317e-07
Iter: 545 loss: 6.80194034e-07
Iter: 546 loss: 6.79595303e-07
Iter: 547 loss: 6.78203492e-07
Iter: 548 loss: 6.95383505e-07
Iter: 549 loss: 6.78062065e-07
Iter: 550 loss: 6.7672454e-07
Iter: 551 loss: 6.81498193e-07
Iter: 552 loss: 6.76368813e-07
Iter: 553 loss: 6.75361889e-07
Iter: 554 loss: 6.82984592e-07
Iter: 555 loss: 6.7529777e-07
Iter: 556 loss: 6.74251396e-07
Iter: 557 loss: 6.73942623e-07
Iter: 558 loss: 6.73298359e-07
Iter: 559 loss: 6.72148e-07
Iter: 560 loss: 6.72983788e-07
Iter: 561 loss: 6.71438215e-07
Iter: 562 loss: 6.69600695e-07
Iter: 563 loss: 6.71033717e-07
Iter: 564 loss: 6.68530561e-07
Iter: 565 loss: 6.67250333e-07
Iter: 566 loss: 6.67279096e-07
Iter: 567 loss: 6.66218625e-07
Iter: 568 loss: 6.66692415e-07
Iter: 569 loss: 6.65536163e-07
Iter: 570 loss: 6.64184199e-07
Iter: 571 loss: 6.67234531e-07
Iter: 572 loss: 6.63662604e-07
Iter: 573 loss: 6.62142384e-07
Iter: 574 loss: 6.64182494e-07
Iter: 575 loss: 6.61420358e-07
Iter: 576 loss: 6.60355909e-07
Iter: 577 loss: 6.77283538e-07
Iter: 578 loss: 6.60338173e-07
Iter: 579 loss: 6.59479724e-07
Iter: 580 loss: 6.63012315e-07
Iter: 581 loss: 6.59204034e-07
Iter: 582 loss: 6.57865485e-07
Iter: 583 loss: 6.56182e-07
Iter: 584 loss: 6.55994143e-07
Iter: 585 loss: 6.55133874e-07
Iter: 586 loss: 6.60832029e-07
Iter: 587 loss: 6.55041049e-07
Iter: 588 loss: 6.54226255e-07
Iter: 589 loss: 6.52814379e-07
Iter: 590 loss: 6.52832341e-07
Iter: 591 loss: 6.50534844e-07
Iter: 592 loss: 6.6755797e-07
Iter: 593 loss: 6.5035772e-07
Iter: 594 loss: 6.49454932e-07
Iter: 595 loss: 6.47970239e-07
Iter: 596 loss: 6.47966885e-07
Iter: 597 loss: 6.46378453e-07
Iter: 598 loss: 6.62907951e-07
Iter: 599 loss: 6.46371404e-07
Iter: 600 loss: 6.45197474e-07
Iter: 601 loss: 6.44622e-07
Iter: 602 loss: 6.44155079e-07
Iter: 603 loss: 6.42739906e-07
Iter: 604 loss: 6.62442744e-07
Iter: 605 loss: 6.42717794e-07
Iter: 606 loss: 6.41664315e-07
Iter: 607 loss: 6.40738563e-07
Iter: 608 loss: 6.40426038e-07
Iter: 609 loss: 6.38806e-07
Iter: 610 loss: 6.53843699e-07
Iter: 611 loss: 6.38710901e-07
Iter: 612 loss: 6.37929588e-07
Iter: 613 loss: 6.38870063e-07
Iter: 614 loss: 6.37484504e-07
Iter: 615 loss: 6.363274e-07
Iter: 616 loss: 6.44140584e-07
Iter: 617 loss: 6.36198365e-07
Iter: 618 loss: 6.34948435e-07
Iter: 619 loss: 6.35570359e-07
Iter: 620 loss: 6.3413097e-07
Iter: 621 loss: 6.33522575e-07
Iter: 622 loss: 6.32904744e-07
Iter: 623 loss: 6.32734441e-07
Iter: 624 loss: 6.31704211e-07
Iter: 625 loss: 6.38876827e-07
Iter: 626 loss: 6.31577223e-07
Iter: 627 loss: 6.30440127e-07
Iter: 628 loss: 6.33528657e-07
Iter: 629 loss: 6.30104864e-07
Iter: 630 loss: 6.29024498e-07
Iter: 631 loss: 6.29295585e-07
Iter: 632 loss: 6.28226076e-07
Iter: 633 loss: 6.27071e-07
Iter: 634 loss: 6.27428108e-07
Iter: 635 loss: 6.26202223e-07
Iter: 636 loss: 6.24910626e-07
Iter: 637 loss: 6.35482252e-07
Iter: 638 loss: 6.24846393e-07
Iter: 639 loss: 6.23781716e-07
Iter: 640 loss: 6.25714335e-07
Iter: 641 loss: 6.23352e-07
Iter: 642 loss: 6.22265e-07
Iter: 643 loss: 6.31141461e-07
Iter: 644 loss: 6.22235802e-07
Iter: 645 loss: 6.21550384e-07
Iter: 646 loss: 6.20979e-07
Iter: 647 loss: 6.20760716e-07
Iter: 648 loss: 6.19620323e-07
Iter: 649 loss: 6.32900878e-07
Iter: 650 loss: 6.19574053e-07
Iter: 651 loss: 6.18721174e-07
Iter: 652 loss: 6.27461873e-07
Iter: 653 loss: 6.18689285e-07
Iter: 654 loss: 6.1810681e-07
Iter: 655 loss: 6.16846648e-07
Iter: 656 loss: 6.32801402e-07
Iter: 657 loss: 6.16775651e-07
Iter: 658 loss: 6.15443696e-07
Iter: 659 loss: 6.26191e-07
Iter: 660 loss: 6.15319664e-07
Iter: 661 loss: 6.14563589e-07
Iter: 662 loss: 6.14802843e-07
Iter: 663 loss: 6.14052965e-07
Iter: 664 loss: 6.12853569e-07
Iter: 665 loss: 6.18765057e-07
Iter: 666 loss: 6.12623865e-07
Iter: 667 loss: 6.1177559e-07
Iter: 668 loss: 6.12700092e-07
Iter: 669 loss: 6.11385872e-07
Iter: 670 loss: 6.10351378e-07
Iter: 671 loss: 6.0929267e-07
Iter: 672 loss: 6.09091671e-07
Iter: 673 loss: 6.07787683e-07
Iter: 674 loss: 6.13337363e-07
Iter: 675 loss: 6.07524498e-07
Iter: 676 loss: 6.06331639e-07
Iter: 677 loss: 6.17142e-07
Iter: 678 loss: 6.06272636e-07
Iter: 679 loss: 6.0540026e-07
Iter: 680 loss: 6.06390302e-07
Iter: 681 loss: 6.04906063e-07
Iter: 682 loss: 6.03850481e-07
Iter: 683 loss: 6.08611685e-07
Iter: 684 loss: 6.03611284e-07
Iter: 685 loss: 6.02985381e-07
Iter: 686 loss: 6.11613814e-07
Iter: 687 loss: 6.02984358e-07
Iter: 688 loss: 6.02159844e-07
Iter: 689 loss: 6.01043894e-07
Iter: 690 loss: 6.00989893e-07
Iter: 691 loss: 5.99832106e-07
Iter: 692 loss: 6.05109335e-07
Iter: 693 loss: 5.99616e-07
Iter: 694 loss: 5.9882683e-07
Iter: 695 loss: 5.98741735e-07
Iter: 696 loss: 5.98233044e-07
Iter: 697 loss: 5.97137159e-07
Iter: 698 loss: 6.05834e-07
Iter: 699 loss: 5.97067185e-07
Iter: 700 loss: 5.96539564e-07
Iter: 701 loss: 6.0228831e-07
Iter: 702 loss: 5.96553832e-07
Iter: 703 loss: 5.96064581e-07
Iter: 704 loss: 5.94880419e-07
Iter: 705 loss: 6.05298908e-07
Iter: 706 loss: 5.94745927e-07
Iter: 707 loss: 5.93191203e-07
Iter: 708 loss: 6.01321915e-07
Iter: 709 loss: 5.92956781e-07
Iter: 710 loss: 5.91901824e-07
Iter: 711 loss: 5.95192091e-07
Iter: 712 loss: 5.91594414e-07
Iter: 713 loss: 5.9054446e-07
Iter: 714 loss: 5.91918308e-07
Iter: 715 loss: 5.90054e-07
Iter: 716 loss: 5.88842e-07
Iter: 717 loss: 5.98030397e-07
Iter: 718 loss: 5.88783e-07
Iter: 719 loss: 5.87955924e-07
Iter: 720 loss: 5.91514322e-07
Iter: 721 loss: 5.87838713e-07
Iter: 722 loss: 5.87155682e-07
Iter: 723 loss: 5.95120355e-07
Iter: 724 loss: 5.87132888e-07
Iter: 725 loss: 5.86581905e-07
Iter: 726 loss: 5.86258238e-07
Iter: 727 loss: 5.85967427e-07
Iter: 728 loss: 5.85302416e-07
Iter: 729 loss: 5.84520308e-07
Iter: 730 loss: 5.84439e-07
Iter: 731 loss: 5.83504459e-07
Iter: 732 loss: 5.95140477e-07
Iter: 733 loss: 5.83539133e-07
Iter: 734 loss: 5.8287128e-07
Iter: 735 loss: 5.82793064e-07
Iter: 736 loss: 5.82340761e-07
Iter: 737 loss: 5.81250902e-07
Iter: 738 loss: 5.88584896e-07
Iter: 739 loss: 5.81144661e-07
Iter: 740 loss: 5.80612891e-07
Iter: 741 loss: 5.8332796e-07
Iter: 742 loss: 5.80550136e-07
Iter: 743 loss: 5.80087885e-07
Iter: 744 loss: 5.78824597e-07
Iter: 745 loss: 5.82509472e-07
Iter: 746 loss: 5.7819e-07
Iter: 747 loss: 5.77485764e-07
Iter: 748 loss: 5.77212347e-07
Iter: 749 loss: 5.76365e-07
Iter: 750 loss: 5.75142849e-07
Iter: 751 loss: 5.75110789e-07
Iter: 752 loss: 5.74213686e-07
Iter: 753 loss: 5.74189244e-07
Iter: 754 loss: 5.73561181e-07
Iter: 755 loss: 5.81655627e-07
Iter: 756 loss: 5.73578404e-07
Iter: 757 loss: 5.73078864e-07
Iter: 758 loss: 5.75069862e-07
Iter: 759 loss: 5.72974386e-07
Iter: 760 loss: 5.72627e-07
Iter: 761 loss: 5.7214038e-07
Iter: 762 loss: 5.7212219e-07
Iter: 763 loss: 5.71407668e-07
Iter: 764 loss: 5.71842293e-07
Iter: 765 loss: 5.70969064e-07
Iter: 766 loss: 5.70094699e-07
Iter: 767 loss: 5.73610748e-07
Iter: 768 loss: 5.69868575e-07
Iter: 769 loss: 5.69158885e-07
Iter: 770 loss: 5.74921501e-07
Iter: 771 loss: 5.69124325e-07
Iter: 772 loss: 5.68579e-07
Iter: 773 loss: 5.70534667e-07
Iter: 774 loss: 5.68462156e-07
Iter: 775 loss: 5.67783218e-07
Iter: 776 loss: 5.6748388e-07
Iter: 777 loss: 5.67171696e-07
Iter: 778 loss: 5.66393e-07
Iter: 779 loss: 5.67709549e-07
Iter: 780 loss: 5.66062283e-07
Iter: 781 loss: 5.65105779e-07
Iter: 782 loss: 5.66404822e-07
Iter: 783 loss: 5.64619086e-07
Iter: 784 loss: 5.63630749e-07
Iter: 785 loss: 5.65501068e-07
Iter: 786 loss: 5.63321066e-07
Iter: 787 loss: 5.62161688e-07
Iter: 788 loss: 5.68794462e-07
Iter: 789 loss: 5.61956313e-07
Iter: 790 loss: 5.61790159e-07
Iter: 791 loss: 5.61569436e-07
Iter: 792 loss: 5.61236334e-07
Iter: 793 loss: 5.60716103e-07
Iter: 794 loss: 5.73224725e-07
Iter: 795 loss: 5.60717808e-07
Iter: 796 loss: 5.60004935e-07
Iter: 797 loss: 5.60759759e-07
Iter: 798 loss: 5.59580542e-07
Iter: 799 loss: 5.58982151e-07
Iter: 800 loss: 5.59744535e-07
Iter: 801 loss: 5.58662919e-07
Iter: 802 loss: 5.57917303e-07
Iter: 803 loss: 5.61530783e-07
Iter: 804 loss: 5.57794e-07
Iter: 805 loss: 5.57202611e-07
Iter: 806 loss: 5.60949275e-07
Iter: 807 loss: 5.57133092e-07
Iter: 808 loss: 5.56577049e-07
Iter: 809 loss: 5.56832561e-07
Iter: 810 loss: 5.56190685e-07
Iter: 811 loss: 5.55508e-07
Iter: 812 loss: 5.58130864e-07
Iter: 813 loss: 5.55354518e-07
Iter: 814 loss: 5.54698e-07
Iter: 815 loss: 5.53464588e-07
Iter: 816 loss: 5.81877941e-07
Iter: 817 loss: 5.53438213e-07
Iter: 818 loss: 5.5257658e-07
Iter: 819 loss: 5.66355197e-07
Iter: 820 loss: 5.52550944e-07
Iter: 821 loss: 5.51836081e-07
Iter: 822 loss: 5.51990865e-07
Iter: 823 loss: 5.51248149e-07
Iter: 824 loss: 5.50604909e-07
Iter: 825 loss: 5.50605819e-07
Iter: 826 loss: 5.49914375e-07
Iter: 827 loss: 5.53228517e-07
Iter: 828 loss: 5.49821038e-07
Iter: 829 loss: 5.49464175e-07
Iter: 830 loss: 5.48919218e-07
Iter: 831 loss: 5.4890404e-07
Iter: 832 loss: 5.48142793e-07
Iter: 833 loss: 5.50301763e-07
Iter: 834 loss: 5.47935656e-07
Iter: 835 loss: 5.47357388e-07
Iter: 836 loss: 5.50322397e-07
Iter: 837 loss: 5.47261266e-07
Iter: 838 loss: 5.46713579e-07
Iter: 839 loss: 5.45976491e-07
Iter: 840 loss: 5.45894807e-07
Iter: 841 loss: 5.45104626e-07
Iter: 842 loss: 5.45065916e-07
Iter: 843 loss: 5.44686714e-07
Iter: 844 loss: 5.44365435e-07
Iter: 845 loss: 5.44263344e-07
Iter: 846 loss: 5.43425472e-07
Iter: 847 loss: 5.44107252e-07
Iter: 848 loss: 5.4287932e-07
Iter: 849 loss: 5.42115231e-07
Iter: 850 loss: 5.4620574e-07
Iter: 851 loss: 5.4203116e-07
Iter: 852 loss: 5.41350971e-07
Iter: 853 loss: 5.42196403e-07
Iter: 854 loss: 5.41058512e-07
Iter: 855 loss: 5.40459382e-07
Iter: 856 loss: 5.39580469e-07
Iter: 857 loss: 5.39527719e-07
Iter: 858 loss: 5.39953305e-07
Iter: 859 loss: 5.39040684e-07
Iter: 860 loss: 5.38614472e-07
Iter: 861 loss: 5.38840141e-07
Iter: 862 loss: 5.38317408e-07
Iter: 863 loss: 5.37936785e-07
Iter: 864 loss: 5.37130063e-07
Iter: 865 loss: 5.50871391e-07
Iter: 866 loss: 5.37053722e-07
Iter: 867 loss: 5.3627349e-07
Iter: 868 loss: 5.43912165e-07
Iter: 869 loss: 5.36237053e-07
Iter: 870 loss: 5.35562208e-07
Iter: 871 loss: 5.37700146e-07
Iter: 872 loss: 5.35375534e-07
Iter: 873 loss: 5.34782373e-07
Iter: 874 loss: 5.35661286e-07
Iter: 875 loss: 5.34492131e-07
Iter: 876 loss: 5.33810066e-07
Iter: 877 loss: 5.39342182e-07
Iter: 878 loss: 5.33780678e-07
Iter: 879 loss: 5.33272441e-07
Iter: 880 loss: 5.33440812e-07
Iter: 881 loss: 5.32919387e-07
Iter: 882 loss: 5.32308e-07
Iter: 883 loss: 5.31972546e-07
Iter: 884 loss: 5.31681394e-07
Iter: 885 loss: 5.308749e-07
Iter: 886 loss: 5.42865166e-07
Iter: 887 loss: 5.30893146e-07
Iter: 888 loss: 5.30450336e-07
Iter: 889 loss: 5.3010848e-07
Iter: 890 loss: 5.29987233e-07
Iter: 891 loss: 5.29316935e-07
Iter: 892 loss: 5.33923185e-07
Iter: 893 loss: 5.29244062e-07
Iter: 894 loss: 5.29042154e-07
Iter: 895 loss: 5.28978376e-07
Iter: 896 loss: 5.28763053e-07
Iter: 897 loss: 5.28046542e-07
Iter: 898 loss: 5.34355252e-07
Iter: 899 loss: 5.27943371e-07
Iter: 900 loss: 5.27291377e-07
Iter: 901 loss: 5.27573548e-07
Iter: 902 loss: 5.26831627e-07
Iter: 903 loss: 5.26057647e-07
Iter: 904 loss: 5.33496689e-07
Iter: 905 loss: 5.26044801e-07
Iter: 906 loss: 5.25548614e-07
Iter: 907 loss: 5.27663417e-07
Iter: 908 loss: 5.25498535e-07
Iter: 909 loss: 5.24960342e-07
Iter: 910 loss: 5.2442806e-07
Iter: 911 loss: 5.24320058e-07
Iter: 912 loss: 5.23963763e-07
Iter: 913 loss: 5.23878725e-07
Iter: 914 loss: 5.23616677e-07
Iter: 915 loss: 5.22940923e-07
Iter: 916 loss: 5.28001635e-07
Iter: 917 loss: 5.22825871e-07
Iter: 918 loss: 5.21984589e-07
Iter: 919 loss: 5.30220518e-07
Iter: 920 loss: 5.21977313e-07
Iter: 921 loss: 5.21413881e-07
Iter: 922 loss: 5.22134314e-07
Iter: 923 loss: 5.21123866e-07
Iter: 924 loss: 5.20542812e-07
Iter: 925 loss: 5.23965298e-07
Iter: 926 loss: 5.20447372e-07
Iter: 927 loss: 5.20016556e-07
Iter: 928 loss: 5.21357322e-07
Iter: 929 loss: 5.19899629e-07
Iter: 930 loss: 5.19297771e-07
Iter: 931 loss: 5.23322e-07
Iter: 932 loss: 5.19273385e-07
Iter: 933 loss: 5.18997069e-07
Iter: 934 loss: 5.18504e-07
Iter: 935 loss: 5.29211206e-07
Iter: 936 loss: 5.18532033e-07
Iter: 937 loss: 5.17860883e-07
Iter: 938 loss: 5.18944e-07
Iter: 939 loss: 5.17581384e-07
Iter: 940 loss: 5.16813429e-07
Iter: 941 loss: 5.19834714e-07
Iter: 942 loss: 5.16665068e-07
Iter: 943 loss: 5.16065597e-07
Iter: 944 loss: 5.18282036e-07
Iter: 945 loss: 5.15937586e-07
Iter: 946 loss: 5.15326576e-07
Iter: 947 loss: 5.1514462e-07
Iter: 948 loss: 5.14798785e-07
Iter: 949 loss: 5.14449084e-07
Iter: 950 loss: 5.1429879e-07
Iter: 951 loss: 5.13997861e-07
Iter: 952 loss: 5.13611212e-07
Iter: 953 loss: 5.1353021e-07
Iter: 954 loss: 5.12921531e-07
Iter: 955 loss: 5.15647798e-07
Iter: 956 loss: 5.12786073e-07
Iter: 957 loss: 5.12308304e-07
Iter: 958 loss: 5.12232589e-07
Iter: 959 loss: 5.118319e-07
Iter: 960 loss: 5.11075768e-07
Iter: 961 loss: 5.13671807e-07
Iter: 962 loss: 5.10867096e-07
Iter: 963 loss: 5.10701852e-07
Iter: 964 loss: 5.1057475e-07
Iter: 965 loss: 5.10294171e-07
Iter: 966 loss: 5.09886945e-07
Iter: 967 loss: 5.09888309e-07
Iter: 968 loss: 5.09551342e-07
Iter: 969 loss: 5.09319307e-07
Iter: 970 loss: 5.09139909e-07
Iter: 971 loss: 5.08491325e-07
Iter: 972 loss: 5.08883e-07
Iter: 973 loss: 5.08035896e-07
Iter: 974 loss: 5.07328423e-07
Iter: 975 loss: 5.13999908e-07
Iter: 976 loss: 5.07293748e-07
Iter: 977 loss: 5.0672827e-07
Iter: 978 loss: 5.07814036e-07
Iter: 979 loss: 5.06481229e-07
Iter: 980 loss: 5.05940307e-07
Iter: 981 loss: 5.06921879e-07
Iter: 982 loss: 5.0572595e-07
Iter: 983 loss: 5.05221e-07
Iter: 984 loss: 5.07164714e-07
Iter: 985 loss: 5.05072819e-07
Iter: 986 loss: 5.04679633e-07
Iter: 987 loss: 5.09688789e-07
Iter: 988 loss: 5.04656668e-07
Iter: 989 loss: 5.04278944e-07
Iter: 990 loss: 5.03988815e-07
Iter: 991 loss: 5.03875071e-07
Iter: 992 loss: 5.03425724e-07
Iter: 993 loss: 5.04890863e-07
Iter: 994 loss: 5.03295098e-07
Iter: 995 loss: 5.02784928e-07
Iter: 996 loss: 5.03371609e-07
Iter: 997 loss: 5.02545333e-07
Iter: 998 loss: 5.02047556e-07
Iter: 999 loss: 5.05938601e-07
Iter: 1000 loss: 5.01997874e-07
Iter: 1001 loss: 5.01643058e-07
Iter: 1002 loss: 5.03669412e-07
Iter: 1003 loss: 5.01615773e-07
Iter: 1004 loss: 5.0122776e-07
Iter: 1005 loss: 5.01758564e-07
Iter: 1006 loss: 5.00989188e-07
Iter: 1007 loss: 5.00721171e-07
Iter: 1008 loss: 5.00200315e-07
Iter: 1009 loss: 5.08223366e-07
Iter: 1010 loss: 5.00200258e-07
Iter: 1011 loss: 4.99594762e-07
Iter: 1012 loss: 5.03339493e-07
Iter: 1013 loss: 4.99495172e-07
Iter: 1014 loss: 4.98960162e-07
Iter: 1015 loss: 4.99104942e-07
Iter: 1016 loss: 4.98608074e-07
Iter: 1017 loss: 4.97960571e-07
Iter: 1018 loss: 5.0352412e-07
Iter: 1019 loss: 4.97912197e-07
Iter: 1020 loss: 4.97448468e-07
Iter: 1021 loss: 4.98330564e-07
Iter: 1022 loss: 4.97257e-07
Iter: 1023 loss: 4.96709447e-07
Iter: 1024 loss: 4.98222391e-07
Iter: 1025 loss: 4.96523853e-07
Iter: 1026 loss: 4.96138227e-07
Iter: 1027 loss: 4.9894129e-07
Iter: 1028 loss: 4.96072744e-07
Iter: 1029 loss: 4.95719178e-07
Iter: 1030 loss: 4.97183464e-07
Iter: 1031 loss: 4.95598329e-07
Iter: 1032 loss: 4.95258803e-07
Iter: 1033 loss: 4.94714072e-07
Iter: 1034 loss: 4.9470043e-07
Iter: 1035 loss: 4.94029337e-07
Iter: 1036 loss: 4.98187092e-07
Iter: 1037 loss: 4.93946516e-07
Iter: 1038 loss: 4.93645643e-07
Iter: 1039 loss: 4.97900658e-07
Iter: 1040 loss: 4.93612731e-07
Iter: 1041 loss: 4.93387802e-07
Iter: 1042 loss: 4.9501989e-07
Iter: 1043 loss: 4.93380412e-07
Iter: 1044 loss: 4.93121775e-07
Iter: 1045 loss: 4.92716936e-07
Iter: 1046 loss: 4.92726372e-07
Iter: 1047 loss: 4.92261e-07
Iter: 1048 loss: 4.92e-07
Iter: 1049 loss: 4.91832452e-07
Iter: 1050 loss: 4.91353092e-07
Iter: 1051 loss: 4.97753376e-07
Iter: 1052 loss: 4.91343485e-07
Iter: 1053 loss: 4.9093569e-07
Iter: 1054 loss: 4.90323e-07
Iter: 1055 loss: 4.90316893e-07
Iter: 1056 loss: 4.89814852e-07
Iter: 1057 loss: 4.89794388e-07
Iter: 1058 loss: 4.89430874e-07
Iter: 1059 loss: 4.89664615e-07
Iter: 1060 loss: 4.89195088e-07
Iter: 1061 loss: 4.88702142e-07
Iter: 1062 loss: 4.90799835e-07
Iter: 1063 loss: 4.88656724e-07
Iter: 1064 loss: 4.88316459e-07
Iter: 1065 loss: 4.91127e-07
Iter: 1066 loss: 4.88316346e-07
Iter: 1067 loss: 4.87985346e-07
Iter: 1068 loss: 4.87626494e-07
Iter: 1069 loss: 4.8757272e-07
Iter: 1070 loss: 4.87110469e-07
Iter: 1071 loss: 4.89271656e-07
Iter: 1072 loss: 4.87009572e-07
Iter: 1073 loss: 4.86695455e-07
Iter: 1074 loss: 4.89537e-07
Iter: 1075 loss: 4.86647878e-07
Iter: 1076 loss: 4.86297779e-07
Iter: 1077 loss: 4.87882403e-07
Iter: 1078 loss: 4.86240765e-07
Iter: 1079 loss: 4.85957344e-07
Iter: 1080 loss: 4.85723262e-07
Iter: 1081 loss: 4.85651867e-07
Iter: 1082 loss: 4.85284659e-07
Iter: 1083 loss: 4.8551226e-07
Iter: 1084 loss: 4.85047451e-07
Iter: 1085 loss: 4.84646819e-07
Iter: 1086 loss: 4.84882321e-07
Iter: 1087 loss: 4.84350608e-07
Iter: 1088 loss: 4.83899157e-07
Iter: 1089 loss: 4.88240175e-07
Iter: 1090 loss: 4.83868121e-07
Iter: 1091 loss: 4.83545477e-07
Iter: 1092 loss: 4.8349375e-07
Iter: 1093 loss: 4.83208453e-07
Iter: 1094 loss: 4.82718747e-07
Iter: 1095 loss: 4.87862735e-07
Iter: 1096 loss: 4.82719145e-07
Iter: 1097 loss: 4.8239e-07
Iter: 1098 loss: 4.82650819e-07
Iter: 1099 loss: 4.82209202e-07
Iter: 1100 loss: 4.81933512e-07
Iter: 1101 loss: 4.81906113e-07
Iter: 1102 loss: 4.81730638e-07
Iter: 1103 loss: 4.81406801e-07
Iter: 1104 loss: 4.81414e-07
Iter: 1105 loss: 4.80926246e-07
Iter: 1106 loss: 4.81679479e-07
Iter: 1107 loss: 4.80678636e-07
Iter: 1108 loss: 4.80687618e-07
Iter: 1109 loss: 4.805093e-07
Iter: 1110 loss: 4.803357e-07
Iter: 1111 loss: 4.79937285e-07
Iter: 1112 loss: 4.84542966e-07
Iter: 1113 loss: 4.79928246e-07
Iter: 1114 loss: 4.79444452e-07
Iter: 1115 loss: 4.81052439e-07
Iter: 1116 loss: 4.79298e-07
Iter: 1117 loss: 4.78829747e-07
Iter: 1118 loss: 4.78944173e-07
Iter: 1119 loss: 4.78546781e-07
Iter: 1120 loss: 4.78127163e-07
Iter: 1121 loss: 4.80753442e-07
Iter: 1122 loss: 4.78107381e-07
Iter: 1123 loss: 4.77758476e-07
Iter: 1124 loss: 4.77610513e-07
Iter: 1125 loss: 4.7744112e-07
Iter: 1126 loss: 4.76887067e-07
Iter: 1127 loss: 4.78742038e-07
Iter: 1128 loss: 4.76670778e-07
Iter: 1129 loss: 4.7615049e-07
Iter: 1130 loss: 4.80084566e-07
Iter: 1131 loss: 4.76135e-07
Iter: 1132 loss: 4.75827733e-07
Iter: 1133 loss: 4.77724427e-07
Iter: 1134 loss: 4.75759492e-07
Iter: 1135 loss: 4.75409308e-07
Iter: 1136 loss: 4.75991044e-07
Iter: 1137 loss: 4.75289426e-07
Iter: 1138 loss: 4.74905903e-07
Iter: 1139 loss: 4.76009205e-07
Iter: 1140 loss: 4.7480205e-07
Iter: 1141 loss: 4.74477019e-07
Iter: 1142 loss: 4.74223896e-07
Iter: 1143 loss: 4.74182627e-07
Iter: 1144 loss: 4.73927486e-07
Iter: 1145 loss: 4.73875218e-07
Iter: 1146 loss: 4.73688829e-07
Iter: 1147 loss: 4.7326e-07
Iter: 1148 loss: 4.76608136e-07
Iter: 1149 loss: 4.73184798e-07
Iter: 1150 loss: 4.72605677e-07
Iter: 1151 loss: 4.7466375e-07
Iter: 1152 loss: 4.72452427e-07
Iter: 1153 loss: 4.72117904e-07
Iter: 1154 loss: 4.76017107e-07
Iter: 1155 loss: 4.72097668e-07
Iter: 1156 loss: 4.71869669e-07
Iter: 1157 loss: 4.71341e-07
Iter: 1158 loss: 4.81414475e-07
Iter: 1159 loss: 4.71366235e-07
Iter: 1160 loss: 4.70877382e-07
Iter: 1161 loss: 4.74253341e-07
Iter: 1162 loss: 4.70826308e-07
Iter: 1163 loss: 4.70345185e-07
Iter: 1164 loss: 4.71266787e-07
Iter: 1165 loss: 4.70131056e-07
Iter: 1166 loss: 4.69675456e-07
Iter: 1167 loss: 4.71795886e-07
Iter: 1168 loss: 4.6954321e-07
Iter: 1169 loss: 4.69247908e-07
Iter: 1170 loss: 4.73696389e-07
Iter: 1171 loss: 4.69226677e-07
Iter: 1172 loss: 4.6903142e-07
Iter: 1173 loss: 4.69367137e-07
Iter: 1174 loss: 4.68933735e-07
Iter: 1175 loss: 4.68622233e-07
Iter: 1176 loss: 4.68501298e-07
Iter: 1177 loss: 4.68331564e-07
Iter: 1178 loss: 4.67948382e-07
Iter: 1179 loss: 4.70717623e-07
Iter: 1180 loss: 4.67880426e-07
Iter: 1181 loss: 4.67450832e-07
Iter: 1182 loss: 4.69873783e-07
Iter: 1183 loss: 4.67414452e-07
Iter: 1184 loss: 4.67162153e-07
Iter: 1185 loss: 4.66848491e-07
Iter: 1186 loss: 4.66815436e-07
Iter: 1187 loss: 4.6645016e-07
Iter: 1188 loss: 4.6654668e-07
Iter: 1189 loss: 4.66141927e-07
Iter: 1190 loss: 4.65547913e-07
Iter: 1191 loss: 4.69850136e-07
Iter: 1192 loss: 4.65460772e-07
Iter: 1193 loss: 4.6515089e-07
Iter: 1194 loss: 4.66496743e-07
Iter: 1195 loss: 4.65112038e-07
Iter: 1196 loss: 4.64860591e-07
Iter: 1197 loss: 4.64517456e-07
Iter: 1198 loss: 4.64452711e-07
Iter: 1199 loss: 4.63974942e-07
Iter: 1200 loss: 4.66145764e-07
Iter: 1201 loss: 4.63890274e-07
Iter: 1202 loss: 4.63437686e-07
Iter: 1203 loss: 4.66292022e-07
Iter: 1204 loss: 4.63386016e-07
Iter: 1205 loss: 4.63009172e-07
Iter: 1206 loss: 4.64486391e-07
Iter: 1207 loss: 4.62896566e-07
Iter: 1208 loss: 4.62397054e-07
Iter: 1209 loss: 4.62627725e-07
Iter: 1210 loss: 4.62082426e-07
Iter: 1211 loss: 4.6169859e-07
Iter: 1212 loss: 4.66463462e-07
Iter: 1213 loss: 4.61670936e-07
Iter: 1214 loss: 4.61475e-07
Iter: 1215 loss: 4.63661053e-07
Iter: 1216 loss: 4.61424747e-07
Iter: 1217 loss: 4.61219315e-07
Iter: 1218 loss: 4.60879818e-07
Iter: 1219 loss: 4.60871888e-07
Iter: 1220 loss: 4.60538786e-07
Iter: 1221 loss: 4.60345433e-07
Iter: 1222 loss: 4.60171975e-07
Iter: 1223 loss: 4.59841516e-07
Iter: 1224 loss: 4.64488693e-07
Iter: 1225 loss: 4.5982722e-07
Iter: 1226 loss: 4.59566365e-07
Iter: 1227 loss: 4.59668e-07
Iter: 1228 loss: 4.59365623e-07
Iter: 1229 loss: 4.58948193e-07
Iter: 1230 loss: 4.60611403e-07
Iter: 1231 loss: 4.58886177e-07
Iter: 1232 loss: 4.5861475e-07
Iter: 1233 loss: 4.58632258e-07
Iter: 1234 loss: 4.58414206e-07
Iter: 1235 loss: 4.58109099e-07
Iter: 1236 loss: 4.6017783e-07
Iter: 1237 loss: 4.58049101e-07
Iter: 1238 loss: 4.57751497e-07
Iter: 1239 loss: 4.57985095e-07
Iter: 1240 loss: 4.57571105e-07
Iter: 1241 loss: 4.57205772e-07
Iter: 1242 loss: 4.61118475e-07
Iter: 1243 loss: 4.57202816e-07
Iter: 1244 loss: 4.56982463e-07
Iter: 1245 loss: 4.56762933e-07
Iter: 1246 loss: 4.56696966e-07
Iter: 1247 loss: 4.56313757e-07
Iter: 1248 loss: 4.61378903e-07
Iter: 1249 loss: 4.56323505e-07
Iter: 1250 loss: 4.56053044e-07
Iter: 1251 loss: 4.56921953e-07
Iter: 1252 loss: 4.56003534e-07
Iter: 1253 loss: 4.55801882e-07
Iter: 1254 loss: 4.55509678e-07
Iter: 1255 loss: 4.55513259e-07
Iter: 1256 loss: 4.55098245e-07
Iter: 1257 loss: 4.55734721e-07
Iter: 1258 loss: 4.54908047e-07
Iter: 1259 loss: 4.54589269e-07
Iter: 1260 loss: 4.56314126e-07
Iter: 1261 loss: 4.54524582e-07
Iter: 1262 loss: 4.54195174e-07
Iter: 1263 loss: 4.54975066e-07
Iter: 1264 loss: 4.54046187e-07
Iter: 1265 loss: 4.5364294e-07
Iter: 1266 loss: 4.54193895e-07
Iter: 1267 loss: 4.53469454e-07
Iter: 1268 loss: 4.52993277e-07
Iter: 1269 loss: 4.54098029e-07
Iter: 1270 loss: 4.52832e-07
Iter: 1271 loss: 4.5238761e-07
Iter: 1272 loss: 4.52443317e-07
Iter: 1273 loss: 4.52040979e-07
Iter: 1274 loss: 4.51791095e-07
Iter: 1275 loss: 4.5176705e-07
Iter: 1276 loss: 4.51498806e-07
Iter: 1277 loss: 4.51888042e-07
Iter: 1278 loss: 4.51384579e-07
Iter: 1279 loss: 4.51058554e-07
Iter: 1280 loss: 4.5175824e-07
Iter: 1281 loss: 4.50953507e-07
Iter: 1282 loss: 4.50756545e-07
Iter: 1283 loss: 4.50750889e-07
Iter: 1284 loss: 4.50584906e-07
Iter: 1285 loss: 4.50245e-07
Iter: 1286 loss: 4.55835675e-07
Iter: 1287 loss: 4.50239099e-07
Iter: 1288 loss: 4.49809306e-07
Iter: 1289 loss: 4.51288656e-07
Iter: 1290 loss: 4.49717106e-07
Iter: 1291 loss: 4.49403728e-07
Iter: 1292 loss: 4.49241611e-07
Iter: 1293 loss: 4.49094671e-07
Iter: 1294 loss: 4.4881898e-07
Iter: 1295 loss: 4.53215705e-07
Iter: 1296 loss: 4.48803831e-07
Iter: 1297 loss: 4.4856634e-07
Iter: 1298 loss: 4.48462202e-07
Iter: 1299 loss: 4.48309493e-07
Iter: 1300 loss: 4.47959508e-07
Iter: 1301 loss: 4.51011203e-07
Iter: 1302 loss: 4.47952317e-07
Iter: 1303 loss: 4.47696777e-07
Iter: 1304 loss: 4.47284094e-07
Iter: 1305 loss: 4.47277216e-07
Iter: 1306 loss: 4.46893893e-07
Iter: 1307 loss: 4.52113682e-07
Iter: 1308 loss: 4.46878147e-07
Iter: 1309 loss: 4.4662832e-07
Iter: 1310 loss: 4.47556118e-07
Iter: 1311 loss: 4.46553173e-07
Iter: 1312 loss: 4.46311219e-07
Iter: 1313 loss: 4.46889317e-07
Iter: 1314 loss: 4.46228682e-07
Iter: 1315 loss: 4.46008528e-07
Iter: 1316 loss: 4.4873957e-07
Iter: 1317 loss: 4.45995738e-07
Iter: 1318 loss: 4.45751027e-07
Iter: 1319 loss: 4.4545925e-07
Iter: 1320 loss: 4.45419943e-07
Iter: 1321 loss: 4.45102728e-07
Iter: 1322 loss: 4.46206883e-07
Iter: 1323 loss: 4.45050148e-07
Iter: 1324 loss: 4.44752914e-07
Iter: 1325 loss: 4.44665119e-07
Iter: 1326 loss: 4.4454589e-07
Iter: 1327 loss: 4.44110185e-07
Iter: 1328 loss: 4.45342607e-07
Iter: 1329 loss: 4.43993258e-07
Iter: 1330 loss: 4.43625936e-07
Iter: 1331 loss: 4.45243899e-07
Iter: 1332 loss: 4.43508043e-07
Iter: 1333 loss: 4.4334277e-07
Iter: 1334 loss: 4.45056514e-07
Iter: 1335 loss: 4.43304856e-07
Iter: 1336 loss: 4.43093512e-07
Iter: 1337 loss: 4.42768055e-07
Iter: 1338 loss: 4.42771608e-07
Iter: 1339 loss: 4.422877e-07
Iter: 1340 loss: 4.44929981e-07
Iter: 1341 loss: 4.42233898e-07
Iter: 1342 loss: 4.42015846e-07
Iter: 1343 loss: 4.42867929e-07
Iter: 1344 loss: 4.4191944e-07
Iter: 1345 loss: 4.41597251e-07
Iter: 1346 loss: 4.42790565e-07
Iter: 1347 loss: 4.41472025e-07
Iter: 1348 loss: 4.41200541e-07
Iter: 1349 loss: 4.43133388e-07
Iter: 1350 loss: 4.41183545e-07
Iter: 1351 loss: 4.40925248e-07
Iter: 1352 loss: 4.41318548e-07
Iter: 1353 loss: 4.40806133e-07
Iter: 1354 loss: 4.40558381e-07
Iter: 1355 loss: 4.40568556e-07
Iter: 1356 loss: 4.40379154e-07
Iter: 1357 loss: 4.40102781e-07
Iter: 1358 loss: 4.40455779e-07
Iter: 1359 loss: 4.39926396e-07
Iter: 1360 loss: 4.39605344e-07
Iter: 1361 loss: 4.40670419e-07
Iter: 1362 loss: 4.39484182e-07
Iter: 1363 loss: 4.39161198e-07
Iter: 1364 loss: 4.39247771e-07
Iter: 1365 loss: 4.38933796e-07
Iter: 1366 loss: 4.38618201e-07
Iter: 1367 loss: 4.41349499e-07
Iter: 1368 loss: 4.38627865e-07
Iter: 1369 loss: 4.38287032e-07
Iter: 1370 loss: 4.38690705e-07
Iter: 1371 loss: 4.38090922e-07
Iter: 1372 loss: 4.37760207e-07
Iter: 1373 loss: 4.39492254e-07
Iter: 1374 loss: 4.37744461e-07
Iter: 1375 loss: 4.3746104e-07
Iter: 1376 loss: 4.37452712e-07
Iter: 1377 loss: 4.37252595e-07
Iter: 1378 loss: 4.36983669e-07
Iter: 1379 loss: 4.369995e-07
Iter: 1380 loss: 4.36824109e-07
Iter: 1381 loss: 4.36766982e-07
Iter: 1382 loss: 4.3662385e-07
Iter: 1383 loss: 4.36292765e-07
Iter: 1384 loss: 4.39621829e-07
Iter: 1385 loss: 4.3628549e-07
Iter: 1386 loss: 4.36104415e-07
Iter: 1387 loss: 4.3601932e-07
Iter: 1388 loss: 4.35898528e-07
Iter: 1389 loss: 4.35688747e-07
Iter: 1390 loss: 4.35429257e-07
Iter: 1391 loss: 4.35402512e-07
Iter: 1392 loss: 4.35040249e-07
Iter: 1393 loss: 4.38285582e-07
Iter: 1394 loss: 4.35004551e-07
Iter: 1395 loss: 4.34757197e-07
Iter: 1396 loss: 4.34831776e-07
Iter: 1397 loss: 4.34582859e-07
Iter: 1398 loss: 4.34253934e-07
Iter: 1399 loss: 4.34473463e-07
Iter: 1400 loss: 4.34034433e-07
Iter: 1401 loss: 4.33585626e-07
Iter: 1402 loss: 4.37349229e-07
Iter: 1403 loss: 4.33548e-07
Iter: 1404 loss: 4.33251074e-07
Iter: 1405 loss: 4.34491142e-07
Iter: 1406 loss: 4.33184709e-07
Iter: 1407 loss: 4.32894183e-07
Iter: 1408 loss: 4.33068067e-07
Iter: 1409 loss: 4.32758583e-07
Iter: 1410 loss: 4.324462e-07
Iter: 1411 loss: 4.33380364e-07
Iter: 1412 loss: 4.32322622e-07
Iter: 1413 loss: 4.32055856e-07
Iter: 1414 loss: 4.36005763e-07
Iter: 1415 loss: 4.32061938e-07
Iter: 1416 loss: 4.31947853e-07
Iter: 1417 loss: 4.33121102e-07
Iter: 1418 loss: 4.31928385e-07
Iter: 1419 loss: 4.31799151e-07
Iter: 1420 loss: 4.31828539e-07
Iter: 1421 loss: 4.31712181e-07
Iter: 1422 loss: 4.31528179e-07
Iter: 1423 loss: 4.31099693e-07
Iter: 1424 loss: 4.35729874e-07
Iter: 1425 loss: 4.31055867e-07
Iter: 1426 loss: 4.30638522e-07
Iter: 1427 loss: 4.3645332e-07
Iter: 1428 loss: 4.3064739e-07
Iter: 1429 loss: 4.30389093e-07
Iter: 1430 loss: 4.30794614e-07
Iter: 1431 loss: 4.30268614e-07
Iter: 1432 loss: 4.30017565e-07
Iter: 1433 loss: 4.30704034e-07
Iter: 1434 loss: 4.29916838e-07
Iter: 1435 loss: 4.29630802e-07
Iter: 1436 loss: 4.29610679e-07
Iter: 1437 loss: 4.29390582e-07
Iter: 1438 loss: 4.29099657e-07
Iter: 1439 loss: 4.33077162e-07
Iter: 1440 loss: 4.29113925e-07
Iter: 1441 loss: 4.28856538e-07
Iter: 1442 loss: 4.2920783e-07
Iter: 1443 loss: 4.28704851e-07
Iter: 1444 loss: 4.28474152e-07
Iter: 1445 loss: 4.28842355e-07
Iter: 1446 loss: 4.28293106e-07
Iter: 1447 loss: 4.27994166e-07
Iter: 1448 loss: 4.29505803e-07
Iter: 1449 loss: 4.27928143e-07
Iter: 1450 loss: 4.27688747e-07
Iter: 1451 loss: 4.30855408e-07
Iter: 1452 loss: 4.27703526e-07
Iter: 1453 loss: 4.27573497e-07
Iter: 1454 loss: 4.28237428e-07
Iter: 1455 loss: 4.27551299e-07
Iter: 1456 loss: 4.27382417e-07
Iter: 1457 loss: 4.27063753e-07
Iter: 1458 loss: 4.33777984e-07
Iter: 1459 loss: 4.27054317e-07
Iter: 1460 loss: 4.26763421e-07
Iter: 1461 loss: 4.27418342e-07
Iter: 1462 loss: 4.26668635e-07
Iter: 1463 loss: 4.26319048e-07
Iter: 1464 loss: 4.27384236e-07
Iter: 1465 loss: 4.26220737e-07
Iter: 1466 loss: 4.25966249e-07
Iter: 1467 loss: 4.26837858e-07
Iter: 1468 loss: 4.2589582e-07
Iter: 1469 loss: 4.25567038e-07
Iter: 1470 loss: 4.25783384e-07
Iter: 1471 loss: 4.25368853e-07
Iter: 1472 loss: 4.25143327e-07
Iter: 1473 loss: 4.25994358e-07
Iter: 1474 loss: 4.25083471e-07
Iter: 1475 loss: 4.24850839e-07
Iter: 1476 loss: 4.26205588e-07
Iter: 1477 loss: 4.24814118e-07
Iter: 1478 loss: 4.2459726e-07
Iter: 1479 loss: 4.24840493e-07
Iter: 1480 loss: 4.24500342e-07
Iter: 1481 loss: 4.24261088e-07
Iter: 1482 loss: 4.25142218e-07
Iter: 1483 loss: 4.24213596e-07
Iter: 1484 loss: 4.23991821e-07
Iter: 1485 loss: 4.25084e-07
Iter: 1486 loss: 4.2398807e-07
Iter: 1487 loss: 4.23744439e-07
Iter: 1488 loss: 4.24615564e-07
Iter: 1489 loss: 4.23670343e-07
Iter: 1490 loss: 4.23448341e-07
Iter: 1491 loss: 4.24162522e-07
Iter: 1492 loss: 4.23388428e-07
Iter: 1493 loss: 4.23232876e-07
Iter: 1494 loss: 4.22937092e-07
Iter: 1495 loss: 4.2983325e-07
Iter: 1496 loss: 4.22934932e-07
Iter: 1497 loss: 4.22598106e-07
Iter: 1498 loss: 4.24301959e-07
Iter: 1499 loss: 4.22599044e-07
Iter: 1500 loss: 4.22296409e-07
Iter: 1501 loss: 4.2254743e-07
Iter: 1502 loss: 4.2216513e-07
Iter: 1503 loss: 4.21805112e-07
Iter: 1504 loss: 4.24076234e-07
Iter: 1505 loss: 4.2179596e-07
Iter: 1506 loss: 4.21543831e-07
Iter: 1507 loss: 4.21279964e-07
Iter: 1508 loss: 4.21226105e-07
Iter: 1509 loss: 4.20921737e-07
Iter: 1510 loss: 4.25193662e-07
Iter: 1511 loss: 4.20938875e-07
Iter: 1512 loss: 4.20692203e-07
Iter: 1513 loss: 4.21283261e-07
Iter: 1514 loss: 4.20570018e-07
Iter: 1515 loss: 4.2034506e-07
Iter: 1516 loss: 4.20802451e-07
Iter: 1517 loss: 4.2022063e-07
Iter: 1518 loss: 4.19986037e-07
Iter: 1519 loss: 4.20792844e-07
Iter: 1520 loss: 4.19942154e-07
Iter: 1521 loss: 4.19696619e-07
Iter: 1522 loss: 4.21509753e-07
Iter: 1523 loss: 4.19634716e-07
Iter: 1524 loss: 4.19420189e-07
Iter: 1525 loss: 4.19815137e-07
Iter: 1526 loss: 4.19332366e-07
Iter: 1527 loss: 4.19066225e-07
Iter: 1528 loss: 4.19413624e-07
Iter: 1529 loss: 4.18948161e-07
Iter: 1530 loss: 4.18725364e-07
Iter: 1531 loss: 4.18676564e-07
Iter: 1532 loss: 4.18552816e-07
Iter: 1533 loss: 4.18312936e-07
Iter: 1534 loss: 4.18829899e-07
Iter: 1535 loss: 4.18177933e-07
Iter: 1536 loss: 4.17917818e-07
Iter: 1537 loss: 4.19726092e-07
Iter: 1538 loss: 4.17890078e-07
Iter: 1539 loss: 4.17651449e-07
Iter: 1540 loss: 4.17819138e-07
Iter: 1541 loss: 4.1747694e-07
Iter: 1542 loss: 4.172079e-07
Iter: 1543 loss: 4.18126888e-07
Iter: 1544 loss: 4.17122749e-07
Iter: 1545 loss: 4.16824179e-07
Iter: 1546 loss: 4.16892163e-07
Iter: 1547 loss: 4.16594105e-07
Iter: 1548 loss: 4.16282717e-07
Iter: 1549 loss: 4.21301934e-07
Iter: 1550 loss: 4.16296956e-07
Iter: 1551 loss: 4.16067735e-07
Iter: 1552 loss: 4.15953821e-07
Iter: 1553 loss: 4.15864577e-07
Iter: 1554 loss: 4.15787895e-07
Iter: 1555 loss: 4.15735514e-07
Iter: 1556 loss: 4.15572771e-07
Iter: 1557 loss: 4.15899535e-07
Iter: 1558 loss: 4.15549835e-07
Iter: 1559 loss: 4.1538857e-07
Iter: 1560 loss: 4.15356737e-07
Iter: 1561 loss: 4.15280027e-07
Iter: 1562 loss: 4.15065216e-07
Iter: 1563 loss: 4.15317231e-07
Iter: 1564 loss: 4.14926717e-07
Iter: 1565 loss: 4.14723985e-07
Iter: 1566 loss: 4.1444008e-07
Iter: 1567 loss: 4.14423084e-07
Iter: 1568 loss: 4.14081313e-07
Iter: 1569 loss: 4.18321918e-07
Iter: 1570 loss: 4.14063749e-07
Iter: 1571 loss: 4.13806845e-07
Iter: 1572 loss: 4.14312694e-07
Iter: 1573 loss: 4.13643136e-07
Iter: 1574 loss: 4.13392826e-07
Iter: 1575 loss: 4.14862143e-07
Iter: 1576 loss: 4.13329019e-07
Iter: 1577 loss: 4.13113611e-07
Iter: 1578 loss: 4.12928557e-07
Iter: 1579 loss: 4.12837551e-07
Iter: 1580 loss: 4.12546513e-07
Iter: 1581 loss: 4.15429781e-07
Iter: 1582 loss: 4.12536622e-07
Iter: 1583 loss: 4.12327097e-07
Iter: 1584 loss: 4.12880411e-07
Iter: 1585 loss: 4.12195618e-07
Iter: 1586 loss: 4.11961821e-07
Iter: 1587 loss: 4.12365182e-07
Iter: 1588 loss: 4.11821759e-07
Iter: 1589 loss: 4.11580345e-07
Iter: 1590 loss: 4.13751053e-07
Iter: 1591 loss: 4.11568635e-07
Iter: 1592 loss: 4.11322503e-07
Iter: 1593 loss: 4.13419968e-07
Iter: 1594 loss: 4.11352858e-07
Iter: 1595 loss: 4.11232918e-07
Iter: 1596 loss: 4.11207679e-07
Iter: 1597 loss: 4.11143475e-07
Iter: 1598 loss: 4.10958648e-07
Iter: 1599 loss: 4.10855137e-07
Iter: 1600 loss: 4.1079258e-07
Iter: 1601 loss: 4.10567054e-07
Iter: 1602 loss: 4.10822196e-07
Iter: 1603 loss: 4.10471898e-07
Iter: 1604 loss: 4.10194303e-07
Iter: 1605 loss: 4.10614575e-07
Iter: 1606 loss: 4.10075017e-07
Iter: 1607 loss: 4.09876634e-07
Iter: 1608 loss: 4.10656128e-07
Iter: 1609 loss: 4.09807541e-07
Iter: 1610 loss: 4.09479583e-07
Iter: 1611 loss: 4.10946171e-07
Iter: 1612 loss: 4.09439878e-07
Iter: 1613 loss: 4.09260508e-07
Iter: 1614 loss: 4.09914946e-07
Iter: 1615 loss: 4.09219439e-07
Iter: 1616 loss: 4.09002951e-07
Iter: 1617 loss: 4.08904498e-07
Iter: 1618 loss: 4.08815879e-07
Iter: 1619 loss: 4.08571651e-07
Iter: 1620 loss: 4.10337464e-07
Iter: 1621 loss: 4.08544366e-07
Iter: 1622 loss: 4.08318783e-07
Iter: 1623 loss: 4.08921096e-07
Iter: 1624 loss: 4.08237327e-07
Iter: 1625 loss: 4.08038829e-07
Iter: 1626 loss: 4.09421546e-07
Iter: 1627 loss: 4.08022288e-07
Iter: 1628 loss: 4.07843487e-07
Iter: 1629 loss: 4.09454543e-07
Iter: 1630 loss: 4.07837092e-07
Iter: 1631 loss: 4.07724173e-07
Iter: 1632 loss: 4.07588e-07
Iter: 1633 loss: 4.07562197e-07
Iter: 1634 loss: 4.07413324e-07
Iter: 1635 loss: 4.09057435e-07
Iter: 1636 loss: 4.07417019e-07
Iter: 1637 loss: 4.07293953e-07
Iter: 1638 loss: 4.07079938e-07
Iter: 1639 loss: 4.11687665e-07
Iter: 1640 loss: 4.0707323e-07
Iter: 1641 loss: 4.06804929e-07
Iter: 1642 loss: 4.06612457e-07
Iter: 1643 loss: 4.06487743e-07
Iter: 1644 loss: 4.061651e-07
Iter: 1645 loss: 4.0620219e-07
Iter: 1646 loss: 4.05993e-07
Iter: 1647 loss: 4.05963618e-07
Iter: 1648 loss: 4.05796271e-07
Iter: 1649 loss: 4.05545165e-07
Iter: 1650 loss: 4.07720108e-07
Iter: 1651 loss: 4.05509695e-07
Iter: 1652 loss: 4.05285192e-07
Iter: 1653 loss: 4.0559479e-07
Iter: 1654 loss: 4.05168976e-07
Iter: 1655 loss: 4.05018966e-07
Iter: 1656 loss: 4.06298426e-07
Iter: 1657 loss: 4.05016181e-07
Iter: 1658 loss: 4.04861851e-07
Iter: 1659 loss: 4.04696607e-07
Iter: 1660 loss: 4.04672392e-07
Iter: 1661 loss: 4.04405796e-07
Iter: 1662 loss: 4.06442496e-07
Iter: 1663 loss: 4.04383172e-07
Iter: 1664 loss: 4.04297907e-07
Iter: 1665 loss: 4.04291654e-07
Iter: 1666 loss: 4.04146533e-07
Iter: 1667 loss: 4.039494e-07
Iter: 1668 loss: 4.09171093e-07
Iter: 1669 loss: 4.03968158e-07
Iter: 1670 loss: 4.03720946e-07
Iter: 1671 loss: 4.05355877e-07
Iter: 1672 loss: 4.03732599e-07
Iter: 1673 loss: 4.03569857e-07
Iter: 1674 loss: 4.03671208e-07
Iter: 1675 loss: 4.03479874e-07
Iter: 1676 loss: 4.03304739e-07
Iter: 1677 loss: 4.03142735e-07
Iter: 1678 loss: 4.03066451e-07
Iter: 1679 loss: 4.02798662e-07
Iter: 1680 loss: 4.03703496e-07
Iter: 1681 loss: 4.02692706e-07
Iter: 1682 loss: 4.02413434e-07
Iter: 1683 loss: 4.03558374e-07
Iter: 1684 loss: 4.02328396e-07
Iter: 1685 loss: 4.02054326e-07
Iter: 1686 loss: 4.02922467e-07
Iter: 1687 loss: 4.01975143e-07
Iter: 1688 loss: 4.01753539e-07
Iter: 1689 loss: 4.0348138e-07
Iter: 1690 loss: 4.0172884e-07
Iter: 1691 loss: 4.01552313e-07
Iter: 1692 loss: 4.01392526e-07
Iter: 1693 loss: 4.01366549e-07
Iter: 1694 loss: 4.01106831e-07
Iter: 1695 loss: 4.03672686e-07
Iter: 1696 loss: 4.01115756e-07
Iter: 1697 loss: 4.00866128e-07
Iter: 1698 loss: 4.01103506e-07
Iter: 1699 loss: 4.00755312e-07
Iter: 1700 loss: 4.00675873e-07
Iter: 1701 loss: 4.00627528e-07
Iter: 1702 loss: 4.00539136e-07
Iter: 1703 loss: 4.00514381e-07
Iter: 1704 loss: 4.00426842e-07
Iter: 1705 loss: 4.0028138e-07
Iter: 1706 loss: 4.00120456e-07
Iter: 1707 loss: 4.0012435e-07
Iter: 1708 loss: 3.99860681e-07
Iter: 1709 loss: 4.02334422e-07
Iter: 1710 loss: 3.99851e-07
Iter: 1711 loss: 3.99703538e-07
Iter: 1712 loss: 3.99429894e-07
Iter: 1713 loss: 4.0516349e-07
Iter: 1714 loss: 3.99447856e-07
Iter: 1715 loss: 3.99150423e-07
Iter: 1716 loss: 4.01495981e-07
Iter: 1717 loss: 3.99147552e-07
Iter: 1718 loss: 3.98959742e-07
Iter: 1719 loss: 3.98916598e-07
Iter: 1720 loss: 3.98773636e-07
Iter: 1721 loss: 3.98503687e-07
Iter: 1722 loss: 4.00408908e-07
Iter: 1723 loss: 3.98509627e-07
Iter: 1724 loss: 3.98288137e-07
Iter: 1725 loss: 3.98549673e-07
Iter: 1726 loss: 3.98188661e-07
Iter: 1727 loss: 3.98001589e-07
Iter: 1728 loss: 3.99028067e-07
Iter: 1729 loss: 3.97946508e-07
Iter: 1730 loss: 3.97805223e-07
Iter: 1731 loss: 3.97741815e-07
Iter: 1732 loss: 3.97628071e-07
Iter: 1733 loss: 3.97539281e-07
Iter: 1734 loss: 3.97502731e-07
Iter: 1735 loss: 3.97426561e-07
Iter: 1736 loss: 3.97587115e-07
Iter: 1737 loss: 3.97371025e-07
Iter: 1738 loss: 3.97227154e-07
Iter: 1739 loss: 3.97080328e-07
Iter: 1740 loss: 3.97051082e-07
Iter: 1741 loss: 3.96804751e-07
Iter: 1742 loss: 3.9766465e-07
Iter: 1743 loss: 3.96768314e-07
Iter: 1744 loss: 3.9654293e-07
Iter: 1745 loss: 3.97570432e-07
Iter: 1746 loss: 3.96503594e-07
Iter: 1747 loss: 3.96337e-07
Iter: 1748 loss: 3.96077866e-07
Iter: 1749 loss: 3.96047568e-07
Iter: 1750 loss: 3.95755791e-07
Iter: 1751 loss: 3.97116764e-07
Iter: 1752 loss: 3.95717166e-07
Iter: 1753 loss: 3.95481408e-07
Iter: 1754 loss: 3.964592e-07
Iter: 1755 loss: 3.95443806e-07
Iter: 1756 loss: 3.95193837e-07
Iter: 1757 loss: 3.95411291e-07
Iter: 1758 loss: 3.95010886e-07
Iter: 1759 loss: 3.94651892e-07
Iter: 1760 loss: 3.956971e-07
Iter: 1761 loss: 3.94578706e-07
Iter: 1762 loss: 3.94328737e-07
Iter: 1763 loss: 3.95217967e-07
Iter: 1764 loss: 3.942597e-07
Iter: 1765 loss: 3.9404091e-07
Iter: 1766 loss: 3.94411785e-07
Iter: 1767 loss: 3.93880157e-07
Iter: 1768 loss: 3.93696638e-07
Iter: 1769 loss: 3.93733018e-07
Iter: 1770 loss: 3.93508572e-07
Iter: 1771 loss: 3.93926541e-07
Iter: 1772 loss: 3.93464546e-07
Iter: 1773 loss: 3.93290975e-07
Iter: 1774 loss: 3.93355322e-07
Iter: 1775 loss: 3.93202072e-07
Iter: 1776 loss: 3.93078778e-07
Iter: 1777 loss: 3.93434902e-07
Iter: 1778 loss: 3.93024891e-07
Iter: 1779 loss: 3.92826905e-07
Iter: 1780 loss: 3.92731181e-07
Iter: 1781 loss: 3.92660752e-07
Iter: 1782 loss: 3.92283198e-07
Iter: 1783 loss: 3.93268976e-07
Iter: 1784 loss: 3.92178379e-07
Iter: 1785 loss: 3.91981303e-07
Iter: 1786 loss: 3.91819498e-07
Iter: 1787 loss: 3.91788205e-07
Iter: 1788 loss: 3.91489351e-07
Iter: 1789 loss: 3.95264493e-07
Iter: 1790 loss: 3.91481279e-07
Iter: 1791 loss: 3.91285e-07
Iter: 1792 loss: 3.91646608e-07
Iter: 1793 loss: 3.91190099e-07
Iter: 1794 loss: 3.90944251e-07
Iter: 1795 loss: 3.91726672e-07
Iter: 1796 loss: 3.90873709e-07
Iter: 1797 loss: 3.90621665e-07
Iter: 1798 loss: 3.90788244e-07
Iter: 1799 loss: 3.90514572e-07
Iter: 1800 loss: 3.9022e-07
Iter: 1801 loss: 3.92704521e-07
Iter: 1802 loss: 3.90221174e-07
Iter: 1803 loss: 3.90129145e-07
Iter: 1804 loss: 3.90136847e-07
Iter: 1805 loss: 3.90034984e-07
Iter: 1806 loss: 3.89869541e-07
Iter: 1807 loss: 3.93619985e-07
Iter: 1808 loss: 3.89883468e-07
Iter: 1809 loss: 3.89668372e-07
Iter: 1810 loss: 3.89929085e-07
Iter: 1811 loss: 3.89562274e-07
Iter: 1812 loss: 3.89383501e-07
Iter: 1813 loss: 3.9037036e-07
Iter: 1814 loss: 3.89379409e-07
Iter: 1815 loss: 3.8917409e-07
Iter: 1816 loss: 3.89364345e-07
Iter: 1817 loss: 3.8907919e-07
Iter: 1818 loss: 3.88872422e-07
Iter: 1819 loss: 3.89237755e-07
Iter: 1820 loss: 3.88776982e-07
Iter: 1821 loss: 3.88544152e-07
Iter: 1822 loss: 3.88286367e-07
Iter: 1823 loss: 3.88261384e-07
Iter: 1824 loss: 3.87984358e-07
Iter: 1825 loss: 3.92302297e-07
Iter: 1826 loss: 3.87994817e-07
Iter: 1827 loss: 3.87767983e-07
Iter: 1828 loss: 3.88438082e-07
Iter: 1829 loss: 3.87709122e-07
Iter: 1830 loss: 3.87511221e-07
Iter: 1831 loss: 3.87777789e-07
Iter: 1832 loss: 3.87361581e-07
Iter: 1833 loss: 3.87145548e-07
Iter: 1834 loss: 3.87926036e-07
Iter: 1835 loss: 3.87092115e-07
Iter: 1836 loss: 3.86922494e-07
Iter: 1837 loss: 3.88065018e-07
Iter: 1838 loss: 3.86914877e-07
Iter: 1839 loss: 3.86749662e-07
Iter: 1840 loss: 3.88038274e-07
Iter: 1841 loss: 3.86709644e-07
Iter: 1842 loss: 3.86577568e-07
Iter: 1843 loss: 3.86486846e-07
Iter: 1844 loss: 3.86447084e-07
Iter: 1845 loss: 3.86275474e-07
Iter: 1846 loss: 3.86628699e-07
Iter: 1847 loss: 3.86215561e-07
Iter: 1848 loss: 3.86024e-07
Iter: 1849 loss: 3.86619661e-07
Iter: 1850 loss: 3.85961755e-07
Iter: 1851 loss: 3.85813138e-07
Iter: 1852 loss: 3.86307647e-07
Iter: 1853 loss: 3.85749644e-07
Iter: 1854 loss: 3.85615408e-07
Iter: 1855 loss: 3.85393832e-07
Iter: 1856 loss: 3.85391047e-07
Iter: 1857 loss: 3.85168164e-07
Iter: 1858 loss: 3.8780766e-07
Iter: 1859 loss: 3.85154578e-07
Iter: 1860 loss: 3.84967109e-07
Iter: 1861 loss: 3.8458225e-07
Iter: 1862 loss: 3.91183164e-07
Iter: 1863 loss: 3.84611269e-07
Iter: 1864 loss: 3.84614822e-07
Iter: 1865 loss: 3.8442289e-07
Iter: 1866 loss: 3.84308493e-07
Iter: 1867 loss: 3.84169766e-07
Iter: 1868 loss: 3.84152372e-07
Iter: 1869 loss: 3.83922156e-07
Iter: 1870 loss: 3.85175412e-07
Iter: 1871 loss: 3.83924373e-07
Iter: 1872 loss: 3.83757083e-07
Iter: 1873 loss: 3.84170164e-07
Iter: 1874 loss: 3.83660506e-07
Iter: 1875 loss: 3.83527606e-07
Iter: 1876 loss: 3.86157751e-07
Iter: 1877 loss: 3.83508564e-07
Iter: 1878 loss: 3.83362305e-07
Iter: 1879 loss: 3.8351439e-07
Iter: 1880 loss: 3.83291649e-07
Iter: 1881 loss: 3.83135e-07
Iter: 1882 loss: 3.83200359e-07
Iter: 1883 loss: 3.83046228e-07
Iter: 1884 loss: 3.8281371e-07
Iter: 1885 loss: 3.82936719e-07
Iter: 1886 loss: 3.82671516e-07
Iter: 1887 loss: 3.82478e-07
Iter: 1888 loss: 3.84318469e-07
Iter: 1889 loss: 3.82446615e-07
Iter: 1890 loss: 3.82322213e-07
Iter: 1891 loss: 3.82345206e-07
Iter: 1892 loss: 3.82212448e-07
Iter: 1893 loss: 3.82017305e-07
Iter: 1894 loss: 3.82365499e-07
Iter: 1895 loss: 3.81962082e-07
Iter: 1896 loss: 3.81717939e-07
Iter: 1897 loss: 3.82018982e-07
Iter: 1898 loss: 3.81623238e-07
Iter: 1899 loss: 3.81391715e-07
Iter: 1900 loss: 3.81819461e-07
Iter: 1901 loss: 3.81302499e-07
Iter: 1902 loss: 3.81104712e-07
Iter: 1903 loss: 3.82940868e-07
Iter: 1904 loss: 3.81053326e-07
Iter: 1905 loss: 3.80876543e-07
Iter: 1906 loss: 3.81153825e-07
Iter: 1907 loss: 3.80758479e-07
Iter: 1908 loss: 3.80619497e-07
Iter: 1909 loss: 3.8303375e-07
Iter: 1910 loss: 3.80593036e-07
Iter: 1911 loss: 3.8048637e-07
Iter: 1912 loss: 3.81327652e-07
Iter: 1913 loss: 3.80496147e-07
Iter: 1914 loss: 3.80402327e-07
Iter: 1915 loss: 3.80237651e-07
Iter: 1916 loss: 3.83015532e-07
Iter: 1917 loss: 3.80219319e-07
Iter: 1918 loss: 3.79988393e-07
Iter: 1919 loss: 3.82019607e-07
Iter: 1920 loss: 3.79978928e-07
Iter: 1921 loss: 3.798894e-07
Iter: 1922 loss: 3.7990921e-07
Iter: 1923 loss: 3.79781028e-07
Iter: 1924 loss: 3.79584719e-07
Iter: 1925 loss: 3.79867544e-07
Iter: 1926 loss: 3.7950241e-07
Iter: 1927 loss: 3.79317612e-07
Iter: 1928 loss: 3.79776623e-07
Iter: 1929 loss: 3.79273615e-07
Iter: 1930 loss: 3.79092512e-07
Iter: 1931 loss: 3.79327361e-07
Iter: 1932 loss: 3.79037658e-07
Iter: 1933 loss: 3.78847801e-07
Iter: 1934 loss: 3.78822278e-07
Iter: 1935 loss: 3.78661753e-07
Iter: 1936 loss: 3.78410562e-07
Iter: 1937 loss: 3.8114058e-07
Iter: 1938 loss: 3.78381088e-07
Iter: 1939 loss: 3.78247677e-07
Iter: 1940 loss: 3.77939614e-07
Iter: 1941 loss: 3.77934668e-07
Iter: 1942 loss: 3.7775888e-07
Iter: 1943 loss: 3.77727474e-07
Iter: 1944 loss: 3.77605062e-07
Iter: 1945 loss: 3.77611514e-07
Iter: 1946 loss: 3.77493279e-07
Iter: 1947 loss: 3.77379365e-07
Iter: 1948 loss: 3.77374647e-07
Iter: 1949 loss: 3.7721847e-07
Iter: 1950 loss: 3.77531421e-07
Iter: 1951 loss: 3.77144573e-07
Iter: 1952 loss: 3.77018949e-07
Iter: 1953 loss: 3.78314667e-07
Iter: 1954 loss: 3.77009201e-07
Iter: 1955 loss: 3.76865103e-07
Iter: 1956 loss: 3.76804337e-07
Iter: 1957 loss: 3.76774665e-07
Iter: 1958 loss: 3.76597484e-07
Iter: 1959 loss: 3.77381184e-07
Iter: 1960 loss: 3.76546836e-07
Iter: 1961 loss: 3.76398162e-07
Iter: 1962 loss: 3.76493858e-07
Iter: 1963 loss: 3.76290188e-07
Iter: 1964 loss: 3.76162092e-07
Iter: 1965 loss: 3.76573382e-07
Iter: 1966 loss: 3.7611e-07
Iter: 1967 loss: 3.75912236e-07
Iter: 1968 loss: 3.75942875e-07
Iter: 1969 loss: 3.75835924e-07
Iter: 1970 loss: 3.75621397e-07
Iter: 1971 loss: 3.75973116e-07
Iter: 1972 loss: 3.75511462e-07
Iter: 1973 loss: 3.75325556e-07
Iter: 1974 loss: 3.76968785e-07
Iter: 1975 loss: 3.75331041e-07
Iter: 1976 loss: 3.75133652e-07
Iter: 1977 loss: 3.75422019e-07
Iter: 1978 loss: 3.75048444e-07
Iter: 1979 loss: 3.74827209e-07
Iter: 1980 loss: 3.74850686e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4
+ date
Mon Oct 26 19:07:17 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab01210d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab00a5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab00a5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab01b7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab01b5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab0076950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ab01b56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a900900d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a900b0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a900b0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a90033510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a900398c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a90039840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c7cb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c77d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c73aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c757840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c7708c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c6c8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c6c8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c6f7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c6f7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c64a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c670400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c670048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c61e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c5d08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c59c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c58e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c58ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c55d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c50b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c5197b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c4dabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c50b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3a3c48c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.60365445e-05
Iter: 2 loss: 0.000204138982
Iter: 3 loss: 3.66256063e-05
Iter: 4 loss: 3.52796815e-05
Iter: 5 loss: 3.21439366e-05
Iter: 6 loss: 7.06833307e-05
Iter: 7 loss: 3.18977727e-05
Iter: 8 loss: 2.93562371e-05
Iter: 9 loss: 4.66145902e-05
Iter: 10 loss: 2.91069791e-05
Iter: 11 loss: 2.7094482e-05
Iter: 12 loss: 2.82337332e-05
Iter: 13 loss: 2.57835563e-05
Iter: 14 loss: 2.48936958e-05
Iter: 15 loss: 2.66128809e-05
Iter: 16 loss: 2.4521989e-05
Iter: 17 loss: 2.40142799e-05
Iter: 18 loss: 2.25873519e-05
Iter: 19 loss: 3.00913744e-05
Iter: 20 loss: 2.21332866e-05
Iter: 21 loss: 2.05295364e-05
Iter: 22 loss: 2.04475637e-05
Iter: 23 loss: 1.92228326e-05
Iter: 24 loss: 1.7924036e-05
Iter: 25 loss: 2.08723777e-05
Iter: 26 loss: 1.74353991e-05
Iter: 27 loss: 1.59505835e-05
Iter: 28 loss: 2.20290422e-05
Iter: 29 loss: 1.56251372e-05
Iter: 30 loss: 1.44431206e-05
Iter: 31 loss: 1.69657724e-05
Iter: 32 loss: 1.39786825e-05
Iter: 33 loss: 1.29122873e-05
Iter: 34 loss: 2.074445e-05
Iter: 35 loss: 1.28242082e-05
Iter: 36 loss: 1.22531828e-05
Iter: 37 loss: 1.37830775e-05
Iter: 38 loss: 1.2063826e-05
Iter: 39 loss: 1.13614196e-05
Iter: 40 loss: 1.17435156e-05
Iter: 41 loss: 1.08974073e-05
Iter: 42 loss: 1.04809387e-05
Iter: 43 loss: 1.4772022e-05
Iter: 44 loss: 1.04693581e-05
Iter: 45 loss: 1.0122907e-05
Iter: 46 loss: 1.30327007e-05
Iter: 47 loss: 1.01027354e-05
Iter: 48 loss: 9.76685e-06
Iter: 49 loss: 1.02653121e-05
Iter: 50 loss: 9.60508896e-06
Iter: 51 loss: 9.39183155e-06
Iter: 52 loss: 9.1797674e-06
Iter: 53 loss: 9.13587246e-06
Iter: 54 loss: 8.94162531e-06
Iter: 55 loss: 8.8679908e-06
Iter: 56 loss: 8.72579767e-06
Iter: 57 loss: 8.34915954e-06
Iter: 58 loss: 1.10611727e-05
Iter: 59 loss: 8.26800442e-06
Iter: 60 loss: 8.00599355e-06
Iter: 61 loss: 8.69693849e-06
Iter: 62 loss: 7.91838829e-06
Iter: 63 loss: 7.60526427e-06
Iter: 64 loss: 8.1685821e-06
Iter: 65 loss: 7.46933438e-06
Iter: 66 loss: 7.2545954e-06
Iter: 67 loss: 8.90983392e-06
Iter: 68 loss: 7.23900075e-06
Iter: 69 loss: 7.01101544e-06
Iter: 70 loss: 7.00684586e-06
Iter: 71 loss: 6.82817517e-06
Iter: 72 loss: 6.60444312e-06
Iter: 73 loss: 8.37264452e-06
Iter: 74 loss: 6.58904264e-06
Iter: 75 loss: 6.37060566e-06
Iter: 76 loss: 6.70549662e-06
Iter: 77 loss: 6.26751535e-06
Iter: 78 loss: 6.08773371e-06
Iter: 79 loss: 6.92400727e-06
Iter: 80 loss: 6.0542925e-06
Iter: 81 loss: 5.95090796e-06
Iter: 82 loss: 5.94911307e-06
Iter: 83 loss: 5.84947065e-06
Iter: 84 loss: 5.879539e-06
Iter: 85 loss: 5.77798846e-06
Iter: 86 loss: 5.68538508e-06
Iter: 87 loss: 5.67486632e-06
Iter: 88 loss: 5.60801618e-06
Iter: 89 loss: 5.58025295e-06
Iter: 90 loss: 5.53109294e-06
Iter: 91 loss: 5.49397464e-06
Iter: 92 loss: 5.40094e-06
Iter: 93 loss: 6.29324131e-06
Iter: 94 loss: 5.38881068e-06
Iter: 95 loss: 5.30873695e-06
Iter: 96 loss: 5.17715307e-06
Iter: 97 loss: 5.17690387e-06
Iter: 98 loss: 5.02337707e-06
Iter: 99 loss: 7.20848129e-06
Iter: 100 loss: 5.02308285e-06
Iter: 101 loss: 4.95309e-06
Iter: 102 loss: 4.93166726e-06
Iter: 103 loss: 4.89037575e-06
Iter: 104 loss: 4.76526e-06
Iter: 105 loss: 5.3551712e-06
Iter: 106 loss: 4.74240733e-06
Iter: 107 loss: 4.66214e-06
Iter: 108 loss: 4.70179975e-06
Iter: 109 loss: 4.60807496e-06
Iter: 110 loss: 4.49595427e-06
Iter: 111 loss: 5.38587847e-06
Iter: 112 loss: 4.48809305e-06
Iter: 113 loss: 4.42727651e-06
Iter: 114 loss: 5.0566664e-06
Iter: 115 loss: 4.42559849e-06
Iter: 116 loss: 4.38604957e-06
Iter: 117 loss: 4.3859377e-06
Iter: 118 loss: 4.35160928e-06
Iter: 119 loss: 4.28821e-06
Iter: 120 loss: 5.75569311e-06
Iter: 121 loss: 4.28807289e-06
Iter: 122 loss: 4.22744e-06
Iter: 123 loss: 4.83822669e-06
Iter: 124 loss: 4.22575476e-06
Iter: 125 loss: 4.16741204e-06
Iter: 126 loss: 4.72363672e-06
Iter: 127 loss: 4.16519106e-06
Iter: 128 loss: 4.14533679e-06
Iter: 129 loss: 4.09683435e-06
Iter: 130 loss: 4.5719471e-06
Iter: 131 loss: 4.090527e-06
Iter: 132 loss: 4.03444847e-06
Iter: 133 loss: 3.98840666e-06
Iter: 134 loss: 3.97239774e-06
Iter: 135 loss: 3.89937259e-06
Iter: 136 loss: 4.73185401e-06
Iter: 137 loss: 3.89826e-06
Iter: 138 loss: 3.83925499e-06
Iter: 139 loss: 3.84652913e-06
Iter: 140 loss: 3.79431549e-06
Iter: 141 loss: 3.75512514e-06
Iter: 142 loss: 3.75478726e-06
Iter: 143 loss: 3.72153067e-06
Iter: 144 loss: 3.6428462e-06
Iter: 145 loss: 4.54725387e-06
Iter: 146 loss: 3.63548043e-06
Iter: 147 loss: 3.61178854e-06
Iter: 148 loss: 3.59263549e-06
Iter: 149 loss: 3.56275291e-06
Iter: 150 loss: 3.72224326e-06
Iter: 151 loss: 3.55809152e-06
Iter: 152 loss: 3.52149e-06
Iter: 153 loss: 3.62766946e-06
Iter: 154 loss: 3.50990604e-06
Iter: 155 loss: 3.48340245e-06
Iter: 156 loss: 3.59220167e-06
Iter: 157 loss: 3.47787977e-06
Iter: 158 loss: 3.47258674e-06
Iter: 159 loss: 3.46620391e-06
Iter: 160 loss: 3.45867261e-06
Iter: 161 loss: 3.43316674e-06
Iter: 162 loss: 3.43136981e-06
Iter: 163 loss: 3.40640304e-06
Iter: 164 loss: 3.3633155e-06
Iter: 165 loss: 3.57590034e-06
Iter: 166 loss: 3.35626737e-06
Iter: 167 loss: 3.32213767e-06
Iter: 168 loss: 3.3604972e-06
Iter: 169 loss: 3.30366811e-06
Iter: 170 loss: 3.26914142e-06
Iter: 171 loss: 3.47998343e-06
Iter: 172 loss: 3.26493591e-06
Iter: 173 loss: 3.23147628e-06
Iter: 174 loss: 3.23285849e-06
Iter: 175 loss: 3.20507252e-06
Iter: 176 loss: 3.16878391e-06
Iter: 177 loss: 3.41797477e-06
Iter: 178 loss: 3.16513547e-06
Iter: 179 loss: 3.1290374e-06
Iter: 180 loss: 3.13826718e-06
Iter: 181 loss: 3.10266933e-06
Iter: 182 loss: 3.07712799e-06
Iter: 183 loss: 3.37718166e-06
Iter: 184 loss: 3.07690107e-06
Iter: 185 loss: 3.05301887e-06
Iter: 186 loss: 3.07709706e-06
Iter: 187 loss: 3.03975276e-06
Iter: 188 loss: 3.00657098e-06
Iter: 189 loss: 3.32918648e-06
Iter: 190 loss: 3.00538932e-06
Iter: 191 loss: 2.9949415e-06
Iter: 192 loss: 2.99418684e-06
Iter: 193 loss: 2.98635109e-06
Iter: 194 loss: 2.95815289e-06
Iter: 195 loss: 2.96902363e-06
Iter: 196 loss: 2.93861081e-06
Iter: 197 loss: 2.92456821e-06
Iter: 198 loss: 2.92081745e-06
Iter: 199 loss: 2.91237143e-06
Iter: 200 loss: 2.89665195e-06
Iter: 201 loss: 2.8657214e-06
Iter: 202 loss: 3.46374873e-06
Iter: 203 loss: 2.86550221e-06
Iter: 204 loss: 2.84418729e-06
Iter: 205 loss: 2.84348334e-06
Iter: 206 loss: 2.82336305e-06
Iter: 207 loss: 2.82238398e-06
Iter: 208 loss: 2.80687254e-06
Iter: 209 loss: 2.78303287e-06
Iter: 210 loss: 2.97276893e-06
Iter: 211 loss: 2.78130142e-06
Iter: 212 loss: 2.76428e-06
Iter: 213 loss: 2.77329787e-06
Iter: 214 loss: 2.75296361e-06
Iter: 215 loss: 2.73025103e-06
Iter: 216 loss: 2.78277298e-06
Iter: 217 loss: 2.72186412e-06
Iter: 218 loss: 2.69443626e-06
Iter: 219 loss: 2.72053e-06
Iter: 220 loss: 2.67885343e-06
Iter: 221 loss: 2.66111374e-06
Iter: 222 loss: 2.6609855e-06
Iter: 223 loss: 2.6463531e-06
Iter: 224 loss: 2.63695983e-06
Iter: 225 loss: 2.63121501e-06
Iter: 226 loss: 2.60589491e-06
Iter: 227 loss: 2.95354039e-06
Iter: 228 loss: 2.60565366e-06
Iter: 229 loss: 2.60176694e-06
Iter: 230 loss: 2.59966259e-06
Iter: 231 loss: 2.59692297e-06
Iter: 232 loss: 2.58725686e-06
Iter: 233 loss: 2.57387319e-06
Iter: 234 loss: 2.57168335e-06
Iter: 235 loss: 2.54597171e-06
Iter: 236 loss: 2.6633204e-06
Iter: 237 loss: 2.54112229e-06
Iter: 238 loss: 2.52592326e-06
Iter: 239 loss: 2.549697e-06
Iter: 240 loss: 2.51867641e-06
Iter: 241 loss: 2.49529239e-06
Iter: 242 loss: 2.5464044e-06
Iter: 243 loss: 2.48613333e-06
Iter: 244 loss: 2.47392154e-06
Iter: 245 loss: 2.61419382e-06
Iter: 246 loss: 2.47373555e-06
Iter: 247 loss: 2.46165814e-06
Iter: 248 loss: 2.43303339e-06
Iter: 249 loss: 2.77495519e-06
Iter: 250 loss: 2.43059139e-06
Iter: 251 loss: 2.41211683e-06
Iter: 252 loss: 2.41179259e-06
Iter: 253 loss: 2.3951668e-06
Iter: 254 loss: 2.40063264e-06
Iter: 255 loss: 2.38338293e-06
Iter: 256 loss: 2.36958203e-06
Iter: 257 loss: 2.50387961e-06
Iter: 258 loss: 2.36916981e-06
Iter: 259 loss: 2.36421738e-06
Iter: 260 loss: 2.36332471e-06
Iter: 261 loss: 2.35793368e-06
Iter: 262 loss: 2.3770408e-06
Iter: 263 loss: 2.35653829e-06
Iter: 264 loss: 2.34955337e-06
Iter: 265 loss: 2.35562857e-06
Iter: 266 loss: 2.34553727e-06
Iter: 267 loss: 2.33943e-06
Iter: 268 loss: 2.32473849e-06
Iter: 269 loss: 2.47382923e-06
Iter: 270 loss: 2.32298498e-06
Iter: 271 loss: 2.31216927e-06
Iter: 272 loss: 2.41945691e-06
Iter: 273 loss: 2.31181434e-06
Iter: 274 loss: 2.30244041e-06
Iter: 275 loss: 2.29164039e-06
Iter: 276 loss: 2.29043735e-06
Iter: 277 loss: 2.27867258e-06
Iter: 278 loss: 2.27860255e-06
Iter: 279 loss: 2.27019359e-06
Iter: 280 loss: 2.2543918e-06
Iter: 281 loss: 2.60461502e-06
Iter: 282 loss: 2.25451049e-06
Iter: 283 loss: 2.24133919e-06
Iter: 284 loss: 2.24082441e-06
Iter: 285 loss: 2.23313646e-06
Iter: 286 loss: 2.22692688e-06
Iter: 287 loss: 2.22466747e-06
Iter: 288 loss: 2.21043092e-06
Iter: 289 loss: 2.25428721e-06
Iter: 290 loss: 2.2063391e-06
Iter: 291 loss: 2.19938556e-06
Iter: 292 loss: 2.27708961e-06
Iter: 293 loss: 2.19923095e-06
Iter: 294 loss: 2.19235972e-06
Iter: 295 loss: 2.23158054e-06
Iter: 296 loss: 2.19151934e-06
Iter: 297 loss: 2.18383457e-06
Iter: 298 loss: 2.19874028e-06
Iter: 299 loss: 2.18044534e-06
Iter: 300 loss: 2.17238744e-06
Iter: 301 loss: 2.15955379e-06
Iter: 302 loss: 2.15946648e-06
Iter: 303 loss: 2.15118575e-06
Iter: 304 loss: 2.16844683e-06
Iter: 305 loss: 2.14809643e-06
Iter: 306 loss: 2.13834937e-06
Iter: 307 loss: 2.13912313e-06
Iter: 308 loss: 2.13074804e-06
Iter: 309 loss: 2.12219538e-06
Iter: 310 loss: 2.23251527e-06
Iter: 311 loss: 2.12219197e-06
Iter: 312 loss: 2.11536917e-06
Iter: 313 loss: 2.11004317e-06
Iter: 314 loss: 2.10799362e-06
Iter: 315 loss: 2.09948621e-06
Iter: 316 loss: 2.15285741e-06
Iter: 317 loss: 2.09857421e-06
Iter: 318 loss: 2.09037398e-06
Iter: 319 loss: 2.11191036e-06
Iter: 320 loss: 2.08758638e-06
Iter: 321 loss: 2.0800403e-06
Iter: 322 loss: 2.10211601e-06
Iter: 323 loss: 2.07800076e-06
Iter: 324 loss: 2.06887466e-06
Iter: 325 loss: 2.0824657e-06
Iter: 326 loss: 2.0645648e-06
Iter: 327 loss: 2.05902688e-06
Iter: 328 loss: 2.08452798e-06
Iter: 329 loss: 2.05795686e-06
Iter: 330 loss: 2.05396191e-06
Iter: 331 loss: 2.11437327e-06
Iter: 332 loss: 2.05386459e-06
Iter: 333 loss: 2.04848834e-06
Iter: 334 loss: 2.04677599e-06
Iter: 335 loss: 2.0435e-06
Iter: 336 loss: 2.04060871e-06
Iter: 337 loss: 2.05209926e-06
Iter: 338 loss: 2.03979653e-06
Iter: 339 loss: 2.03633704e-06
Iter: 340 loss: 2.03151103e-06
Iter: 341 loss: 2.0312973e-06
Iter: 342 loss: 2.02446518e-06
Iter: 343 loss: 2.02775209e-06
Iter: 344 loss: 2.01978105e-06
Iter: 345 loss: 2.01520106e-06
Iter: 346 loss: 2.02914862e-06
Iter: 347 loss: 2.01399257e-06
Iter: 348 loss: 2.00758609e-06
Iter: 349 loss: 2.00781233e-06
Iter: 350 loss: 2.00260774e-06
Iter: 351 loss: 1.99651231e-06
Iter: 352 loss: 2.03643617e-06
Iter: 353 loss: 1.99601573e-06
Iter: 354 loss: 1.98965972e-06
Iter: 355 loss: 1.99421811e-06
Iter: 356 loss: 1.98562816e-06
Iter: 357 loss: 1.98085627e-06
Iter: 358 loss: 2.01247622e-06
Iter: 359 loss: 1.98017278e-06
Iter: 360 loss: 1.97466693e-06
Iter: 361 loss: 1.97299e-06
Iter: 362 loss: 1.96955398e-06
Iter: 363 loss: 1.96362953e-06
Iter: 364 loss: 1.99868691e-06
Iter: 365 loss: 1.96285328e-06
Iter: 366 loss: 1.95826715e-06
Iter: 367 loss: 2.01481362e-06
Iter: 368 loss: 1.95820257e-06
Iter: 369 loss: 1.95433e-06
Iter: 370 loss: 2.0020359e-06
Iter: 371 loss: 1.95421057e-06
Iter: 372 loss: 1.95290158e-06
Iter: 373 loss: 1.94881568e-06
Iter: 374 loss: 1.95917073e-06
Iter: 375 loss: 1.94660925e-06
Iter: 376 loss: 1.93971732e-06
Iter: 377 loss: 1.96944438e-06
Iter: 378 loss: 1.93838787e-06
Iter: 379 loss: 1.93558753e-06
Iter: 380 loss: 1.93563096e-06
Iter: 381 loss: 1.93255096e-06
Iter: 382 loss: 1.92944572e-06
Iter: 383 loss: 1.92891389e-06
Iter: 384 loss: 1.92361358e-06
Iter: 385 loss: 1.9236702e-06
Iter: 386 loss: 1.91930621e-06
Iter: 387 loss: 1.9138165e-06
Iter: 388 loss: 1.91589447e-06
Iter: 389 loss: 1.90988021e-06
Iter: 390 loss: 1.90286096e-06
Iter: 391 loss: 1.97609734e-06
Iter: 392 loss: 1.9026329e-06
Iter: 393 loss: 1.89862476e-06
Iter: 394 loss: 1.89370928e-06
Iter: 395 loss: 1.89321122e-06
Iter: 396 loss: 1.88541662e-06
Iter: 397 loss: 1.97429563e-06
Iter: 398 loss: 1.88546983e-06
Iter: 399 loss: 1.88180468e-06
Iter: 400 loss: 1.87875321e-06
Iter: 401 loss: 1.87753892e-06
Iter: 402 loss: 1.86971693e-06
Iter: 403 loss: 1.90678929e-06
Iter: 404 loss: 1.86827447e-06
Iter: 405 loss: 1.87759872e-06
Iter: 406 loss: 1.86658554e-06
Iter: 407 loss: 1.86577824e-06
Iter: 408 loss: 1.86302407e-06
Iter: 409 loss: 1.86473619e-06
Iter: 410 loss: 1.86045986e-06
Iter: 411 loss: 1.85468491e-06
Iter: 412 loss: 1.87931232e-06
Iter: 413 loss: 1.85323097e-06
Iter: 414 loss: 1.84858311e-06
Iter: 415 loss: 1.90154105e-06
Iter: 416 loss: 1.8484775e-06
Iter: 417 loss: 1.84637497e-06
Iter: 418 loss: 1.84404803e-06
Iter: 419 loss: 1.8433991e-06
Iter: 420 loss: 1.83866803e-06
Iter: 421 loss: 1.83968052e-06
Iter: 422 loss: 1.83507598e-06
Iter: 423 loss: 1.83027089e-06
Iter: 424 loss: 1.86376928e-06
Iter: 425 loss: 1.82982558e-06
Iter: 426 loss: 1.82525582e-06
Iter: 427 loss: 1.82057147e-06
Iter: 428 loss: 1.81984603e-06
Iter: 429 loss: 1.8133544e-06
Iter: 430 loss: 1.86780642e-06
Iter: 431 loss: 1.81298265e-06
Iter: 432 loss: 1.80735651e-06
Iter: 433 loss: 1.81124017e-06
Iter: 434 loss: 1.80393477e-06
Iter: 435 loss: 1.79816743e-06
Iter: 436 loss: 1.82438816e-06
Iter: 437 loss: 1.7971347e-06
Iter: 438 loss: 1.79218114e-06
Iter: 439 loss: 1.85081819e-06
Iter: 440 loss: 1.79231256e-06
Iter: 441 loss: 1.78744267e-06
Iter: 442 loss: 1.82236965e-06
Iter: 443 loss: 1.78688583e-06
Iter: 444 loss: 1.78595565e-06
Iter: 445 loss: 1.78263963e-06
Iter: 446 loss: 1.79384654e-06
Iter: 447 loss: 1.78112691e-06
Iter: 448 loss: 1.77575043e-06
Iter: 449 loss: 1.82248766e-06
Iter: 450 loss: 1.77555762e-06
Iter: 451 loss: 1.77220977e-06
Iter: 452 loss: 1.77718664e-06
Iter: 453 loss: 1.77048264e-06
Iter: 454 loss: 1.76692845e-06
Iter: 455 loss: 1.76220249e-06
Iter: 456 loss: 1.76183528e-06
Iter: 457 loss: 1.75377716e-06
Iter: 458 loss: 1.79282483e-06
Iter: 459 loss: 1.75244929e-06
Iter: 460 loss: 1.74824515e-06
Iter: 461 loss: 1.78458583e-06
Iter: 462 loss: 1.74800425e-06
Iter: 463 loss: 1.74445563e-06
Iter: 464 loss: 1.7393096e-06
Iter: 465 loss: 1.73919534e-06
Iter: 466 loss: 1.73423859e-06
Iter: 467 loss: 1.79485096e-06
Iter: 468 loss: 1.73403566e-06
Iter: 469 loss: 1.72927662e-06
Iter: 470 loss: 1.72390514e-06
Iter: 471 loss: 1.72311286e-06
Iter: 472 loss: 1.71911779e-06
Iter: 473 loss: 1.71869976e-06
Iter: 474 loss: 1.71937791e-06
Iter: 475 loss: 1.71751026e-06
Iter: 476 loss: 1.71650129e-06
Iter: 477 loss: 1.71341958e-06
Iter: 478 loss: 1.70925136e-06
Iter: 479 loss: 1.70850058e-06
Iter: 480 loss: 1.70340036e-06
Iter: 481 loss: 1.73841784e-06
Iter: 482 loss: 1.7030012e-06
Iter: 483 loss: 1.69757527e-06
Iter: 484 loss: 1.69857412e-06
Iter: 485 loss: 1.69347788e-06
Iter: 486 loss: 1.69006603e-06
Iter: 487 loss: 1.68912879e-06
Iter: 488 loss: 1.68637541e-06
Iter: 489 loss: 1.68228394e-06
Iter: 490 loss: 1.68227405e-06
Iter: 491 loss: 1.67634846e-06
Iter: 492 loss: 1.68058523e-06
Iter: 493 loss: 1.6727497e-06
Iter: 494 loss: 1.66733173e-06
Iter: 495 loss: 1.67554663e-06
Iter: 496 loss: 1.66482505e-06
Iter: 497 loss: 1.65724248e-06
Iter: 498 loss: 1.6831732e-06
Iter: 499 loss: 1.65544623e-06
Iter: 500 loss: 1.65053325e-06
Iter: 501 loss: 1.67067151e-06
Iter: 502 loss: 1.64947392e-06
Iter: 503 loss: 1.64360165e-06
Iter: 504 loss: 1.64976e-06
Iter: 505 loss: 1.64045923e-06
Iter: 506 loss: 1.63610389e-06
Iter: 507 loss: 1.67537894e-06
Iter: 508 loss: 1.63589289e-06
Iter: 509 loss: 1.63682353e-06
Iter: 510 loss: 1.63472816e-06
Iter: 511 loss: 1.63356458e-06
Iter: 512 loss: 1.62998833e-06
Iter: 513 loss: 1.63278105e-06
Iter: 514 loss: 1.62689662e-06
Iter: 515 loss: 1.62271635e-06
Iter: 516 loss: 1.641984e-06
Iter: 517 loss: 1.62188428e-06
Iter: 518 loss: 1.61788898e-06
Iter: 519 loss: 1.61292417e-06
Iter: 520 loss: 1.61258583e-06
Iter: 521 loss: 1.61071262e-06
Iter: 522 loss: 1.60956483e-06
Iter: 523 loss: 1.60731406e-06
Iter: 524 loss: 1.61932974e-06
Iter: 525 loss: 1.60710601e-06
Iter: 526 loss: 1.60424793e-06
Iter: 527 loss: 1.59942215e-06
Iter: 528 loss: 1.5994533e-06
Iter: 529 loss: 1.59515434e-06
Iter: 530 loss: 1.61635603e-06
Iter: 531 loss: 1.59449633e-06
Iter: 532 loss: 1.59063313e-06
Iter: 533 loss: 1.58725675e-06
Iter: 534 loss: 1.58638909e-06
Iter: 535 loss: 1.58167018e-06
Iter: 536 loss: 1.58165949e-06
Iter: 537 loss: 1.57860211e-06
Iter: 538 loss: 1.57889735e-06
Iter: 539 loss: 1.57611703e-06
Iter: 540 loss: 1.57495094e-06
Iter: 541 loss: 1.57388013e-06
Iter: 542 loss: 1.57179352e-06
Iter: 543 loss: 1.57858619e-06
Iter: 544 loss: 1.57113027e-06
Iter: 545 loss: 1.57034833e-06
Iter: 546 loss: 1.56806823e-06
Iter: 547 loss: 1.57536806e-06
Iter: 548 loss: 1.56697683e-06
Iter: 549 loss: 1.56328485e-06
Iter: 550 loss: 1.57886279e-06
Iter: 551 loss: 1.56251031e-06
Iter: 552 loss: 1.55929456e-06
Iter: 553 loss: 1.5662157e-06
Iter: 554 loss: 1.55805446e-06
Iter: 555 loss: 1.55533053e-06
Iter: 556 loss: 1.5904991e-06
Iter: 557 loss: 1.55530449e-06
Iter: 558 loss: 1.55301348e-06
Iter: 559 loss: 1.56867918e-06
Iter: 560 loss: 1.55275688e-06
Iter: 561 loss: 1.55133216e-06
Iter: 562 loss: 1.54766258e-06
Iter: 563 loss: 1.57523141e-06
Iter: 564 loss: 1.54692179e-06
Iter: 565 loss: 1.54282316e-06
Iter: 566 loss: 1.58536056e-06
Iter: 567 loss: 1.54267741e-06
Iter: 568 loss: 1.53961264e-06
Iter: 569 loss: 1.54005738e-06
Iter: 570 loss: 1.53738665e-06
Iter: 571 loss: 1.53366705e-06
Iter: 572 loss: 1.56012993e-06
Iter: 573 loss: 1.53326323e-06
Iter: 574 loss: 1.53160465e-06
Iter: 575 loss: 1.5315992e-06
Iter: 576 loss: 1.52981102e-06
Iter: 577 loss: 1.54061752e-06
Iter: 578 loss: 1.52960399e-06
Iter: 579 loss: 1.52851658e-06
Iter: 580 loss: 1.52546886e-06
Iter: 581 loss: 1.55098155e-06
Iter: 582 loss: 1.525068e-06
Iter: 583 loss: 1.52334144e-06
Iter: 584 loss: 1.52227017e-06
Iter: 585 loss: 1.52148368e-06
Iter: 586 loss: 1.51762231e-06
Iter: 587 loss: 1.52728433e-06
Iter: 588 loss: 1.51613347e-06
Iter: 589 loss: 1.51366896e-06
Iter: 590 loss: 1.51341419e-06
Iter: 591 loss: 1.51154177e-06
Iter: 592 loss: 1.51001723e-06
Iter: 593 loss: 1.50945675e-06
Iter: 594 loss: 1.5080318e-06
Iter: 595 loss: 1.51767722e-06
Iter: 596 loss: 1.50805272e-06
Iter: 597 loss: 1.5068581e-06
Iter: 598 loss: 1.50397409e-06
Iter: 599 loss: 1.51573602e-06
Iter: 600 loss: 1.50280073e-06
Iter: 601 loss: 1.50009009e-06
Iter: 602 loss: 1.50007759e-06
Iter: 603 loss: 1.49854645e-06
Iter: 604 loss: 1.49774507e-06
Iter: 605 loss: 1.49701896e-06
Iter: 606 loss: 1.49449045e-06
Iter: 607 loss: 1.50712549e-06
Iter: 608 loss: 1.49415098e-06
Iter: 609 loss: 1.49302127e-06
Iter: 610 loss: 1.49307789e-06
Iter: 611 loss: 1.49155949e-06
Iter: 612 loss: 1.49267294e-06
Iter: 613 loss: 1.49067091e-06
Iter: 614 loss: 1.48978597e-06
Iter: 615 loss: 1.48813911e-06
Iter: 616 loss: 1.52586335e-06
Iter: 617 loss: 1.48817264e-06
Iter: 618 loss: 1.48614095e-06
Iter: 619 loss: 1.48412369e-06
Iter: 620 loss: 1.4837284e-06
Iter: 621 loss: 1.48101117e-06
Iter: 622 loss: 1.48096888e-06
Iter: 623 loss: 1.4796417e-06
Iter: 624 loss: 1.47981427e-06
Iter: 625 loss: 1.4785868e-06
Iter: 626 loss: 1.47645642e-06
Iter: 627 loss: 1.49660139e-06
Iter: 628 loss: 1.47644437e-06
Iter: 629 loss: 1.47486185e-06
Iter: 630 loss: 1.48195033e-06
Iter: 631 loss: 1.47459423e-06
Iter: 632 loss: 1.47365984e-06
Iter: 633 loss: 1.47181652e-06
Iter: 634 loss: 1.515495e-06
Iter: 635 loss: 1.47179389e-06
Iter: 636 loss: 1.46966829e-06
Iter: 637 loss: 1.47934679e-06
Iter: 638 loss: 1.46933928e-06
Iter: 639 loss: 1.46754087e-06
Iter: 640 loss: 1.46753268e-06
Iter: 641 loss: 1.46612763e-06
Iter: 642 loss: 1.46381262e-06
Iter: 643 loss: 1.48984145e-06
Iter: 644 loss: 1.46381058e-06
Iter: 645 loss: 1.4650484e-06
Iter: 646 loss: 1.46343677e-06
Iter: 647 loss: 1.46305922e-06
Iter: 648 loss: 1.46186653e-06
Iter: 649 loss: 1.46133823e-06
Iter: 650 loss: 1.46044908e-06
Iter: 651 loss: 1.45820309e-06
Iter: 652 loss: 1.46809066e-06
Iter: 653 loss: 1.45755052e-06
Iter: 654 loss: 1.45620845e-06
Iter: 655 loss: 1.46031471e-06
Iter: 656 loss: 1.45570175e-06
Iter: 657 loss: 1.4536447e-06
Iter: 658 loss: 1.45479794e-06
Iter: 659 loss: 1.45218348e-06
Iter: 660 loss: 1.45039644e-06
Iter: 661 loss: 1.45563104e-06
Iter: 662 loss: 1.44974229e-06
Iter: 663 loss: 1.44787464e-06
Iter: 664 loss: 1.46236835e-06
Iter: 665 loss: 1.44765886e-06
Iter: 666 loss: 1.44644628e-06
Iter: 667 loss: 1.46349669e-06
Iter: 668 loss: 1.44637488e-06
Iter: 669 loss: 1.44551086e-06
Iter: 670 loss: 1.44373007e-06
Iter: 671 loss: 1.47374294e-06
Iter: 672 loss: 1.44371597e-06
Iter: 673 loss: 1.44141723e-06
Iter: 674 loss: 1.44981686e-06
Iter: 675 loss: 1.44093315e-06
Iter: 676 loss: 1.43908278e-06
Iter: 677 loss: 1.4377456e-06
Iter: 678 loss: 1.4371542e-06
Iter: 679 loss: 1.43609395e-06
Iter: 680 loss: 1.43574073e-06
Iter: 681 loss: 1.43478474e-06
Iter: 682 loss: 1.43465695e-06
Iter: 683 loss: 1.43428815e-06
Iter: 684 loss: 1.43298189e-06
Iter: 685 loss: 1.43457112e-06
Iter: 686 loss: 1.43187447e-06
Iter: 687 loss: 1.43066325e-06
Iter: 688 loss: 1.44429339e-06
Iter: 689 loss: 1.43059833e-06
Iter: 690 loss: 1.42955696e-06
Iter: 691 loss: 1.42846147e-06
Iter: 692 loss: 1.42818794e-06
Iter: 693 loss: 1.4265263e-06
Iter: 694 loss: 1.44160754e-06
Iter: 695 loss: 1.42645058e-06
Iter: 696 loss: 1.42509816e-06
Iter: 697 loss: 1.4251699e-06
Iter: 698 loss: 1.42413796e-06
Iter: 699 loss: 1.42202384e-06
Iter: 700 loss: 1.43000557e-06
Iter: 701 loss: 1.42163117e-06
Iter: 702 loss: 1.42077056e-06
Iter: 703 loss: 1.42072599e-06
Iter: 704 loss: 1.41993087e-06
Iter: 705 loss: 1.41829128e-06
Iter: 706 loss: 1.44043429e-06
Iter: 707 loss: 1.41818305e-06
Iter: 708 loss: 1.41690623e-06
Iter: 709 loss: 1.42126339e-06
Iter: 710 loss: 1.4165837e-06
Iter: 711 loss: 1.41554415e-06
Iter: 712 loss: 1.41404234e-06
Iter: 713 loss: 1.41406417e-06
Iter: 714 loss: 1.41286955e-06
Iter: 715 loss: 1.42294459e-06
Iter: 716 loss: 1.41282351e-06
Iter: 717 loss: 1.41207863e-06
Iter: 718 loss: 1.41207704e-06
Iter: 719 loss: 1.41153703e-06
Iter: 720 loss: 1.41037e-06
Iter: 721 loss: 1.41479904e-06
Iter: 722 loss: 1.40970519e-06
Iter: 723 loss: 1.40872589e-06
Iter: 724 loss: 1.40956388e-06
Iter: 725 loss: 1.40808777e-06
Iter: 726 loss: 1.40616453e-06
Iter: 727 loss: 1.4100782e-06
Iter: 728 loss: 1.40527311e-06
Iter: 729 loss: 1.40375869e-06
Iter: 730 loss: 1.41331157e-06
Iter: 731 loss: 1.4036159e-06
Iter: 732 loss: 1.40191855e-06
Iter: 733 loss: 1.40106306e-06
Iter: 734 loss: 1.40016778e-06
Iter: 735 loss: 1.39912549e-06
Iter: 736 loss: 1.39884514e-06
Iter: 737 loss: 1.39790154e-06
Iter: 738 loss: 1.40172e-06
Iter: 739 loss: 1.39763381e-06
Iter: 740 loss: 1.39674592e-06
Iter: 741 loss: 1.39516237e-06
Iter: 742 loss: 1.39512542e-06
Iter: 743 loss: 1.39363e-06
Iter: 744 loss: 1.40359202e-06
Iter: 745 loss: 1.39353688e-06
Iter: 746 loss: 1.39227575e-06
Iter: 747 loss: 1.39739359e-06
Iter: 748 loss: 1.39197084e-06
Iter: 749 loss: 1.39110375e-06
Iter: 750 loss: 1.39113513e-06
Iter: 751 loss: 1.39044982e-06
Iter: 752 loss: 1.38898736e-06
Iter: 753 loss: 1.41253508e-06
Iter: 754 loss: 1.38902601e-06
Iter: 755 loss: 1.38784458e-06
Iter: 756 loss: 1.38674488e-06
Iter: 757 loss: 1.3865731e-06
Iter: 758 loss: 1.3848985e-06
Iter: 759 loss: 1.39903864e-06
Iter: 760 loss: 1.38479857e-06
Iter: 761 loss: 1.38363953e-06
Iter: 762 loss: 1.38334485e-06
Iter: 763 loss: 1.38266603e-06
Iter: 764 loss: 1.38106736e-06
Iter: 765 loss: 1.39270924e-06
Iter: 766 loss: 1.38099597e-06
Iter: 767 loss: 1.37997677e-06
Iter: 768 loss: 1.38997041e-06
Iter: 769 loss: 1.37989809e-06
Iter: 770 loss: 1.37909592e-06
Iter: 771 loss: 1.38387759e-06
Iter: 772 loss: 1.37880852e-06
Iter: 773 loss: 1.37780739e-06
Iter: 774 loss: 1.37726215e-06
Iter: 775 loss: 1.37680672e-06
Iter: 776 loss: 1.37577433e-06
Iter: 777 loss: 1.37676693e-06
Iter: 778 loss: 1.37519419e-06
Iter: 779 loss: 1.3737349e-06
Iter: 780 loss: 1.37792131e-06
Iter: 781 loss: 1.37327015e-06
Iter: 782 loss: 1.37320285e-06
Iter: 783 loss: 1.37267898e-06
Iter: 784 loss: 1.37219365e-06
Iter: 785 loss: 1.37133793e-06
Iter: 786 loss: 1.39175563e-06
Iter: 787 loss: 1.37136885e-06
Iter: 788 loss: 1.37051336e-06
Iter: 789 loss: 1.36872063e-06
Iter: 790 loss: 1.39149029e-06
Iter: 791 loss: 1.36861274e-06
Iter: 792 loss: 1.36650397e-06
Iter: 793 loss: 1.38129451e-06
Iter: 794 loss: 1.3662127e-06
Iter: 795 loss: 1.36471101e-06
Iter: 796 loss: 1.36817664e-06
Iter: 797 loss: 1.36412336e-06
Iter: 798 loss: 1.36277492e-06
Iter: 799 loss: 1.36325593e-06
Iter: 800 loss: 1.36185349e-06
Iter: 801 loss: 1.36003268e-06
Iter: 802 loss: 1.3697354e-06
Iter: 803 loss: 1.35983169e-06
Iter: 804 loss: 1.35848722e-06
Iter: 805 loss: 1.37487916e-06
Iter: 806 loss: 1.35846631e-06
Iter: 807 loss: 1.35736025e-06
Iter: 808 loss: 1.36042979e-06
Iter: 809 loss: 1.35699042e-06
Iter: 810 loss: 1.35603341e-06
Iter: 811 loss: 1.3538945e-06
Iter: 812 loss: 1.38638802e-06
Iter: 813 loss: 1.35377945e-06
Iter: 814 loss: 1.35201753e-06
Iter: 815 loss: 1.3521344e-06
Iter: 816 loss: 1.35200912e-06
Iter: 817 loss: 1.35169921e-06
Iter: 818 loss: 1.35116375e-06
Iter: 819 loss: 1.34966172e-06
Iter: 820 loss: 1.36365338e-06
Iter: 821 loss: 1.34947163e-06
Iter: 822 loss: 1.34792208e-06
Iter: 823 loss: 1.34707591e-06
Iter: 824 loss: 1.34626919e-06
Iter: 825 loss: 1.34488528e-06
Iter: 826 loss: 1.34899597e-06
Iter: 827 loss: 1.34444076e-06
Iter: 828 loss: 1.34269806e-06
Iter: 829 loss: 1.34241645e-06
Iter: 830 loss: 1.34121024e-06
Iter: 831 loss: 1.33940011e-06
Iter: 832 loss: 1.36536028e-06
Iter: 833 loss: 1.3394183e-06
Iter: 834 loss: 1.33835852e-06
Iter: 835 loss: 1.33756271e-06
Iter: 836 loss: 1.33724666e-06
Iter: 837 loss: 1.33580556e-06
Iter: 838 loss: 1.35227356e-06
Iter: 839 loss: 1.33584945e-06
Iter: 840 loss: 1.33490062e-06
Iter: 841 loss: 1.33492938e-06
Iter: 842 loss: 1.33436367e-06
Iter: 843 loss: 1.33348271e-06
Iter: 844 loss: 1.33344645e-06
Iter: 845 loss: 1.33230492e-06
Iter: 846 loss: 1.33368303e-06
Iter: 847 loss: 1.33164519e-06
Iter: 848 loss: 1.33083881e-06
Iter: 849 loss: 1.3309193e-06
Iter: 850 loss: 1.32998321e-06
Iter: 851 loss: 1.33134631e-06
Iter: 852 loss: 1.32948e-06
Iter: 853 loss: 1.32890386e-06
Iter: 854 loss: 1.32812193e-06
Iter: 855 loss: 1.32806099e-06
Iter: 856 loss: 1.326796e-06
Iter: 857 loss: 1.32520302e-06
Iter: 858 loss: 1.32505033e-06
Iter: 859 loss: 1.32355626e-06
Iter: 860 loss: 1.34523862e-06
Iter: 861 loss: 1.32351579e-06
Iter: 862 loss: 1.32239074e-06
Iter: 863 loss: 1.32195396e-06
Iter: 864 loss: 1.32136552e-06
Iter: 865 loss: 1.31940442e-06
Iter: 866 loss: 1.32853665e-06
Iter: 867 loss: 1.31906927e-06
Iter: 868 loss: 1.31780632e-06
Iter: 869 loss: 1.32260743e-06
Iter: 870 loss: 1.31732895e-06
Iter: 871 loss: 1.31603485e-06
Iter: 872 loss: 1.32768389e-06
Iter: 873 loss: 1.31595232e-06
Iter: 874 loss: 1.31488332e-06
Iter: 875 loss: 1.31801448e-06
Iter: 876 loss: 1.31454044e-06
Iter: 877 loss: 1.31391982e-06
Iter: 878 loss: 1.31391721e-06
Iter: 879 loss: 1.31338481e-06
Iter: 880 loss: 1.31254092e-06
Iter: 881 loss: 1.32222317e-06
Iter: 882 loss: 1.31255911e-06
Iter: 883 loss: 1.31157e-06
Iter: 884 loss: 1.31555328e-06
Iter: 885 loss: 1.31151137e-06
Iter: 886 loss: 1.31088404e-06
Iter: 887 loss: 1.3095231e-06
Iter: 888 loss: 1.3242834e-06
Iter: 889 loss: 1.30937156e-06
Iter: 890 loss: 1.30812111e-06
Iter: 891 loss: 1.31346337e-06
Iter: 892 loss: 1.30784656e-06
Iter: 893 loss: 1.30674744e-06
Iter: 894 loss: 1.30574756e-06
Iter: 895 loss: 1.30552507e-06
Iter: 896 loss: 1.30358194e-06
Iter: 897 loss: 1.31938714e-06
Iter: 898 loss: 1.30350054e-06
Iter: 899 loss: 1.30229103e-06
Iter: 900 loss: 1.3040368e-06
Iter: 901 loss: 1.30158946e-06
Iter: 902 loss: 1.30017634e-06
Iter: 903 loss: 1.30224373e-06
Iter: 904 loss: 1.29938189e-06
Iter: 905 loss: 1.29866328e-06
Iter: 906 loss: 1.29858108e-06
Iter: 907 loss: 1.29783268e-06
Iter: 908 loss: 1.29814862e-06
Iter: 909 loss: 1.29735508e-06
Iter: 910 loss: 1.29601972e-06
Iter: 911 loss: 1.29463615e-06
Iter: 912 loss: 1.29449108e-06
Iter: 913 loss: 1.29350269e-06
Iter: 914 loss: 1.29342982e-06
Iter: 915 loss: 1.29273803e-06
Iter: 916 loss: 1.30077035e-06
Iter: 917 loss: 1.29271621e-06
Iter: 918 loss: 1.29224691e-06
Iter: 919 loss: 1.29083764e-06
Iter: 920 loss: 1.29746752e-06
Iter: 921 loss: 1.29048567e-06
Iter: 922 loss: 1.2886145e-06
Iter: 923 loss: 1.2933067e-06
Iter: 924 loss: 1.28797626e-06
Iter: 925 loss: 1.28639078e-06
Iter: 926 loss: 1.28837121e-06
Iter: 927 loss: 1.28563124e-06
Iter: 928 loss: 1.28418867e-06
Iter: 929 loss: 1.29350065e-06
Iter: 930 loss: 1.28405804e-06
Iter: 931 loss: 1.28278839e-06
Iter: 932 loss: 1.28345891e-06
Iter: 933 loss: 1.28214128e-06
Iter: 934 loss: 1.28076397e-06
Iter: 935 loss: 1.29088232e-06
Iter: 936 loss: 1.28067404e-06
Iter: 937 loss: 1.27965143e-06
Iter: 938 loss: 1.28167278e-06
Iter: 939 loss: 1.27918929e-06
Iter: 940 loss: 1.2781411e-06
Iter: 941 loss: 1.29351054e-06
Iter: 942 loss: 1.2782175e-06
Iter: 943 loss: 1.27757278e-06
Iter: 944 loss: 1.2784144e-06
Iter: 945 loss: 1.27726412e-06
Iter: 946 loss: 1.27663645e-06
Iter: 947 loss: 1.27673911e-06
Iter: 948 loss: 1.27613953e-06
Iter: 949 loss: 1.27533963e-06
Iter: 950 loss: 1.28807983e-06
Iter: 951 loss: 1.27529643e-06
Iter: 952 loss: 1.27460498e-06
Iter: 953 loss: 1.27319936e-06
Iter: 954 loss: 1.29291925e-06
Iter: 955 loss: 1.27308203e-06
Iter: 956 loss: 1.27212593e-06
Iter: 957 loss: 1.27542626e-06
Iter: 958 loss: 1.27194585e-06
Iter: 959 loss: 1.27106614e-06
Iter: 960 loss: 1.27025567e-06
Iter: 961 loss: 1.27004228e-06
Iter: 962 loss: 1.26875284e-06
Iter: 963 loss: 1.27798694e-06
Iter: 964 loss: 1.26860505e-06
Iter: 965 loss: 1.26758e-06
Iter: 966 loss: 1.26883083e-06
Iter: 967 loss: 1.26698717e-06
Iter: 968 loss: 1.26587202e-06
Iter: 969 loss: 1.26986583e-06
Iter: 970 loss: 1.26552709e-06
Iter: 971 loss: 1.26439704e-06
Iter: 972 loss: 1.26848477e-06
Iter: 973 loss: 1.26409441e-06
Iter: 974 loss: 1.2634564e-06
Iter: 975 loss: 1.26342388e-06
Iter: 976 loss: 1.26276746e-06
Iter: 977 loss: 1.26214286e-06
Iter: 978 loss: 1.26202235e-06
Iter: 979 loss: 1.26099349e-06
Iter: 980 loss: 1.26403177e-06
Iter: 981 loss: 1.26060229e-06
Iter: 982 loss: 1.26023201e-06
Iter: 983 loss: 1.25996564e-06
Iter: 984 loss: 1.25964493e-06
Iter: 985 loss: 1.25884617e-06
Iter: 986 loss: 1.2727088e-06
Iter: 987 loss: 1.25883184e-06
Iter: 988 loss: 1.25803308e-06
Iter: 989 loss: 1.2567607e-06
Iter: 990 loss: 1.25673353e-06
Iter: 991 loss: 1.2550895e-06
Iter: 992 loss: 1.26648229e-06
Iter: 993 loss: 1.25495114e-06
Iter: 994 loss: 1.25414977e-06
Iter: 995 loss: 1.25485087e-06
Iter: 996 loss: 1.25367637e-06
Iter: 997 loss: 1.25254678e-06
Iter: 998 loss: 1.2548262e-06
Iter: 999 loss: 1.25194379e-06
Iter: 1000 loss: 1.25092879e-06
Iter: 1001 loss: 1.2577957e-06
Iter: 1002 loss: 1.25086467e-06
Iter: 1003 loss: 1.24988969e-06
Iter: 1004 loss: 1.24983376e-06
Iter: 1005 loss: 1.24910889e-06
Iter: 1006 loss: 1.24819883e-06
Iter: 1007 loss: 1.2481064e-06
Iter: 1008 loss: 1.24742974e-06
Iter: 1009 loss: 1.24773794e-06
Iter: 1010 loss: 1.24694657e-06
Iter: 1011 loss: 1.24605253e-06
Iter: 1012 loss: 1.24832491e-06
Iter: 1013 loss: 1.24586097e-06
Iter: 1014 loss: 1.24539304e-06
Iter: 1015 loss: 1.24532312e-06
Iter: 1016 loss: 1.24496876e-06
Iter: 1017 loss: 1.24409871e-06
Iter: 1018 loss: 1.2562142e-06
Iter: 1019 loss: 1.24413236e-06
Iter: 1020 loss: 1.24312101e-06
Iter: 1021 loss: 1.24306302e-06
Iter: 1022 loss: 1.24233759e-06
Iter: 1023 loss: 1.24143287e-06
Iter: 1024 loss: 1.24726068e-06
Iter: 1025 loss: 1.24149096e-06
Iter: 1026 loss: 1.24068163e-06
Iter: 1027 loss: 1.23941902e-06
Iter: 1028 loss: 1.23933978e-06
Iter: 1029 loss: 1.23800851e-06
Iter: 1030 loss: 1.25374152e-06
Iter: 1031 loss: 1.23795553e-06
Iter: 1032 loss: 1.23717496e-06
Iter: 1033 loss: 1.23711925e-06
Iter: 1034 loss: 1.2364153e-06
Iter: 1035 loss: 1.23494738e-06
Iter: 1036 loss: 1.24379017e-06
Iter: 1037 loss: 1.23480777e-06
Iter: 1038 loss: 1.23415782e-06
Iter: 1039 loss: 1.24496148e-06
Iter: 1040 loss: 1.23416021e-06
Iter: 1041 loss: 1.23350605e-06
Iter: 1042 loss: 1.23331552e-06
Iter: 1043 loss: 1.23292239e-06
Iter: 1044 loss: 1.23206337e-06
Iter: 1045 loss: 1.23516747e-06
Iter: 1046 loss: 1.23189443e-06
Iter: 1047 loss: 1.23169389e-06
Iter: 1048 loss: 1.23143877e-06
Iter: 1049 loss: 1.23114194e-06
Iter: 1050 loss: 1.2304381e-06
Iter: 1051 loss: 1.24232622e-06
Iter: 1052 loss: 1.23046357e-06
Iter: 1053 loss: 1.22972074e-06
Iter: 1054 loss: 1.22926315e-06
Iter: 1055 loss: 1.22895563e-06
Iter: 1056 loss: 1.2279703e-06
Iter: 1057 loss: 1.23000711e-06
Iter: 1058 loss: 1.22751896e-06
Iter: 1059 loss: 1.22636277e-06
Iter: 1060 loss: 1.23013535e-06
Iter: 1061 loss: 1.22591598e-06
Iter: 1062 loss: 1.2251071e-06
Iter: 1063 loss: 1.22754648e-06
Iter: 1064 loss: 1.22492361e-06
Iter: 1065 loss: 1.22396796e-06
Iter: 1066 loss: 1.22328652e-06
Iter: 1067 loss: 1.2228486e-06
Iter: 1068 loss: 1.22181814e-06
Iter: 1069 loss: 1.23764994e-06
Iter: 1070 loss: 1.22175993e-06
Iter: 1071 loss: 1.22085828e-06
Iter: 1072 loss: 1.22226788e-06
Iter: 1073 loss: 1.22040592e-06
Iter: 1074 loss: 1.21909397e-06
Iter: 1075 loss: 1.22693905e-06
Iter: 1076 loss: 1.21893345e-06
Iter: 1077 loss: 1.2182195e-06
Iter: 1078 loss: 1.21829532e-06
Iter: 1079 loss: 1.21759513e-06
Iter: 1080 loss: 1.21729272e-06
Iter: 1081 loss: 1.21704807e-06
Iter: 1082 loss: 1.21658104e-06
Iter: 1083 loss: 1.21568712e-06
Iter: 1084 loss: 1.21565631e-06
Iter: 1085 loss: 1.21474352e-06
Iter: 1086 loss: 1.21473647e-06
Iter: 1087 loss: 1.21406879e-06
Iter: 1088 loss: 1.21308733e-06
Iter: 1089 loss: 1.21501535e-06
Iter: 1090 loss: 1.21266885e-06
Iter: 1091 loss: 1.21170888e-06
Iter: 1092 loss: 1.21557991e-06
Iter: 1093 loss: 1.21142796e-06
Iter: 1094 loss: 1.21052153e-06
Iter: 1095 loss: 1.21029052e-06
Iter: 1096 loss: 1.20965797e-06
Iter: 1097 loss: 1.2082387e-06
Iter: 1098 loss: 1.21509697e-06
Iter: 1099 loss: 1.20805703e-06
Iter: 1100 loss: 1.20704215e-06
Iter: 1101 loss: 1.20755681e-06
Iter: 1102 loss: 1.20649804e-06
Iter: 1103 loss: 1.20506252e-06
Iter: 1104 loss: 1.21525568e-06
Iter: 1105 loss: 1.20495088e-06
Iter: 1106 loss: 1.20430536e-06
Iter: 1107 loss: 1.20423488e-06
Iter: 1108 loss: 1.20394157e-06
Iter: 1109 loss: 1.20297273e-06
Iter: 1110 loss: 1.21356652e-06
Iter: 1111 loss: 1.20287382e-06
Iter: 1112 loss: 1.20190521e-06
Iter: 1113 loss: 1.20188497e-06
Iter: 1114 loss: 1.20101663e-06
Iter: 1115 loss: 1.20505956e-06
Iter: 1116 loss: 1.20078448e-06
Iter: 1117 loss: 1.20032109e-06
Iter: 1118 loss: 1.19963374e-06
Iter: 1119 loss: 1.21289213e-06
Iter: 1120 loss: 1.19970923e-06
Iter: 1121 loss: 1.1984846e-06
Iter: 1122 loss: 1.198409e-06
Iter: 1123 loss: 1.19759102e-06
Iter: 1124 loss: 1.19614992e-06
Iter: 1125 loss: 1.20273478e-06
Iter: 1126 loss: 1.19590345e-06
Iter: 1127 loss: 1.19475612e-06
Iter: 1128 loss: 1.19692061e-06
Iter: 1129 loss: 1.19431638e-06
Iter: 1130 loss: 1.19303968e-06
Iter: 1131 loss: 1.19630067e-06
Iter: 1132 loss: 1.19251422e-06
Iter: 1133 loss: 1.19127276e-06
Iter: 1134 loss: 1.19292918e-06
Iter: 1135 loss: 1.19050742e-06
Iter: 1136 loss: 1.18968615e-06
Iter: 1137 loss: 1.20108371e-06
Iter: 1138 loss: 1.18955211e-06
Iter: 1139 loss: 1.18882349e-06
Iter: 1140 loss: 1.19337119e-06
Iter: 1141 loss: 1.18885498e-06
Iter: 1142 loss: 1.18783601e-06
Iter: 1143 loss: 1.18800472e-06
Iter: 1144 loss: 1.18721209e-06
Iter: 1145 loss: 1.18655987e-06
Iter: 1146 loss: 1.18947025e-06
Iter: 1147 loss: 1.1863799e-06
Iter: 1148 loss: 1.18564822e-06
Iter: 1149 loss: 1.18569733e-06
Iter: 1150 loss: 1.18528033e-06
Iter: 1151 loss: 1.18400226e-06
Iter: 1152 loss: 1.19166862e-06
Iter: 1153 loss: 1.18367871e-06
Iter: 1154 loss: 1.1823513e-06
Iter: 1155 loss: 1.18899766e-06
Iter: 1156 loss: 1.18224091e-06
Iter: 1157 loss: 1.18127218e-06
Iter: 1158 loss: 1.18070727e-06
Iter: 1159 loss: 1.18038247e-06
Iter: 1160 loss: 1.17837851e-06
Iter: 1161 loss: 1.18227581e-06
Iter: 1162 loss: 1.1776491e-06
Iter: 1163 loss: 1.17613479e-06
Iter: 1164 loss: 1.18270202e-06
Iter: 1165 loss: 1.17582522e-06
Iter: 1166 loss: 1.1744313e-06
Iter: 1167 loss: 1.17598461e-06
Iter: 1168 loss: 1.17361355e-06
Iter: 1169 loss: 1.17227864e-06
Iter: 1170 loss: 1.17673608e-06
Iter: 1171 loss: 1.17180412e-06
Iter: 1172 loss: 1.17042521e-06
Iter: 1173 loss: 1.18276648e-06
Iter: 1174 loss: 1.17043714e-06
Iter: 1175 loss: 1.16930221e-06
Iter: 1176 loss: 1.17900061e-06
Iter: 1177 loss: 1.16926617e-06
Iter: 1178 loss: 1.16856074e-06
Iter: 1179 loss: 1.16759281e-06
Iter: 1180 loss: 1.16755109e-06
Iter: 1181 loss: 1.16810486e-06
Iter: 1182 loss: 1.1671109e-06
Iter: 1183 loss: 1.16674232e-06
Iter: 1184 loss: 1.1661175e-06
Iter: 1185 loss: 1.17889272e-06
Iter: 1186 loss: 1.16614433e-06
Iter: 1187 loss: 1.16552542e-06
Iter: 1188 loss: 1.16447768e-06
Iter: 1189 loss: 1.16445835e-06
Iter: 1190 loss: 1.16277363e-06
Iter: 1191 loss: 1.1672463e-06
Iter: 1192 loss: 1.16210663e-06
Iter: 1193 loss: 1.16105764e-06
Iter: 1194 loss: 1.17129787e-06
Iter: 1195 loss: 1.16097408e-06
Iter: 1196 loss: 1.15998546e-06
Iter: 1197 loss: 1.15905084e-06
Iter: 1198 loss: 1.15888247e-06
Iter: 1199 loss: 1.15754278e-06
Iter: 1200 loss: 1.17383195e-06
Iter: 1201 loss: 1.15752471e-06
Iter: 1202 loss: 1.15674015e-06
Iter: 1203 loss: 1.15620321e-06
Iter: 1204 loss: 1.15588739e-06
Iter: 1205 loss: 1.15515206e-06
Iter: 1206 loss: 1.1550519e-06
Iter: 1207 loss: 1.1546307e-06
Iter: 1208 loss: 1.15583339e-06
Iter: 1209 loss: 1.15448904e-06
Iter: 1210 loss: 1.15384569e-06
Iter: 1211 loss: 1.15322155e-06
Iter: 1212 loss: 1.1530949e-06
Iter: 1213 loss: 1.15264106e-06
Iter: 1214 loss: 1.15256557e-06
Iter: 1215 loss: 1.15206876e-06
Iter: 1216 loss: 1.15167711e-06
Iter: 1217 loss: 1.1515292e-06
Iter: 1218 loss: 1.15085675e-06
Iter: 1219 loss: 1.14988177e-06
Iter: 1220 loss: 1.14983914e-06
Iter: 1221 loss: 1.14905242e-06
Iter: 1222 loss: 1.1531489e-06
Iter: 1223 loss: 1.14884278e-06
Iter: 1224 loss: 1.14798604e-06
Iter: 1225 loss: 1.14736895e-06
Iter: 1226 loss: 1.14704892e-06
Iter: 1227 loss: 1.14595798e-06
Iter: 1228 loss: 1.15873297e-06
Iter: 1229 loss: 1.14590648e-06
Iter: 1230 loss: 1.1452787e-06
Iter: 1231 loss: 1.14503939e-06
Iter: 1232 loss: 1.14460227e-06
Iter: 1233 loss: 1.14346972e-06
Iter: 1234 loss: 1.15059083e-06
Iter: 1235 loss: 1.14341105e-06
Iter: 1236 loss: 1.14263753e-06
Iter: 1237 loss: 1.14184218e-06
Iter: 1238 loss: 1.14171849e-06
Iter: 1239 loss: 1.14089517e-06
Iter: 1240 loss: 1.14091858e-06
Iter: 1241 loss: 1.14037607e-06
Iter: 1242 loss: 1.14510306e-06
Iter: 1243 loss: 1.14039062e-06
Iter: 1244 loss: 1.1401205e-06
Iter: 1245 loss: 1.14044565e-06
Iter: 1246 loss: 1.14004956e-06
Iter: 1247 loss: 1.13975295e-06
Iter: 1248 loss: 1.14029274e-06
Iter: 1249 loss: 1.13947794e-06
Iter: 1250 loss: 1.13918441e-06
Iter: 1251 loss: 1.13870919e-06
Iter: 1252 loss: 1.13865065e-06
Iter: 1253 loss: 1.13827855e-06
Iter: 1254 loss: 1.13860528e-06
Iter: 1255 loss: 1.13813712e-06
Iter: 1256 loss: 1.13747933e-06
Iter: 1257 loss: 1.13738918e-06
Iter: 1258 loss: 1.13680608e-06
Iter: 1259 loss: 1.13605176e-06
Iter: 1260 loss: 1.14186923e-06
Iter: 1261 loss: 1.13604563e-06
Iter: 1262 loss: 1.13529723e-06
Iter: 1263 loss: 1.13523265e-06
Iter: 1264 loss: 1.13462613e-06
Iter: 1265 loss: 1.13372721e-06
Iter: 1266 loss: 1.14142722e-06
Iter: 1267 loss: 1.13356737e-06
Iter: 1268 loss: 1.13295073e-06
Iter: 1269 loss: 1.1321788e-06
Iter: 1270 loss: 1.13223678e-06
Iter: 1271 loss: 1.13124497e-06
Iter: 1272 loss: 1.1312e-06
Iter: 1273 loss: 1.13084457e-06
Iter: 1274 loss: 1.13610395e-06
Iter: 1275 loss: 1.13082785e-06
Iter: 1276 loss: 1.13040983e-06
Iter: 1277 loss: 1.13075203e-06
Iter: 1278 loss: 1.13017813e-06
Iter: 1279 loss: 1.12954046e-06
Iter: 1280 loss: 1.13405702e-06
Iter: 1281 loss: 1.12950829e-06
Iter: 1282 loss: 1.12919543e-06
Iter: 1283 loss: 1.12874545e-06
Iter: 1284 loss: 1.12881537e-06
Iter: 1285 loss: 1.1283646e-06
Iter: 1286 loss: 1.12789644e-06
Iter: 1287 loss: 1.12773637e-06
Iter: 1288 loss: 1.12688861e-06
Iter: 1289 loss: 1.13096178e-06
Iter: 1290 loss: 1.12674024e-06
Iter: 1291 loss: 1.12608041e-06
Iter: 1292 loss: 1.12718112e-06
Iter: 1293 loss: 1.12574651e-06
Iter: 1294 loss: 1.12488385e-06
Iter: 1295 loss: 1.12655198e-06
Iter: 1296 loss: 1.12453097e-06
Iter: 1297 loss: 1.1239174e-06
Iter: 1298 loss: 1.12982013e-06
Iter: 1299 loss: 1.12392149e-06
Iter: 1300 loss: 1.12343605e-06
Iter: 1301 loss: 1.12388238e-06
Iter: 1302 loss: 1.12310352e-06
Iter: 1303 loss: 1.12272858e-06
Iter: 1304 loss: 1.12355769e-06
Iter: 1305 loss: 1.12247403e-06
Iter: 1306 loss: 1.12190753e-06
Iter: 1307 loss: 1.1272648e-06
Iter: 1308 loss: 1.12200382e-06
Iter: 1309 loss: 1.12154498e-06
Iter: 1310 loss: 1.12361295e-06
Iter: 1311 loss: 1.12142197e-06
Iter: 1312 loss: 1.12128305e-06
Iter: 1313 loss: 1.12133671e-06
Iter: 1314 loss: 1.12113867e-06
Iter: 1315 loss: 1.12068869e-06
Iter: 1316 loss: 1.12210648e-06
Iter: 1317 loss: 1.12047906e-06
Iter: 1318 loss: 1.11995496e-06
Iter: 1319 loss: 1.12146972e-06
Iter: 1320 loss: 1.11974225e-06
Iter: 1321 loss: 1.11941199e-06
Iter: 1322 loss: 1.1209022e-06
Iter: 1323 loss: 1.1193747e-06
Iter: 1324 loss: 1.11896952e-06
Iter: 1325 loss: 1.11821191e-06
Iter: 1326 loss: 1.13507747e-06
Iter: 1327 loss: 1.11813597e-06
Iter: 1328 loss: 1.11771e-06
Iter: 1329 loss: 1.11763813e-06
Iter: 1330 loss: 1.11726445e-06
Iter: 1331 loss: 1.11698296e-06
Iter: 1332 loss: 1.11689644e-06
Iter: 1333 loss: 1.11616532e-06
Iter: 1334 loss: 1.12073826e-06
Iter: 1335 loss: 1.11612303e-06
Iter: 1336 loss: 1.11563861e-06
Iter: 1337 loss: 1.11652298e-06
Iter: 1338 loss: 1.11539066e-06
Iter: 1339 loss: 1.11480256e-06
Iter: 1340 loss: 1.11608e-06
Iter: 1341 loss: 1.11451914e-06
Iter: 1342 loss: 1.11434053e-06
Iter: 1343 loss: 1.11426698e-06
Iter: 1344 loss: 1.11403961e-06
Iter: 1345 loss: 1.11413351e-06
Iter: 1346 loss: 1.11395684e-06
Iter: 1347 loss: 1.11355371e-06
Iter: 1348 loss: 1.1148876e-06
Iter: 1349 loss: 1.11343877e-06
Iter: 1350 loss: 1.11317536e-06
Iter: 1351 loss: 1.11259214e-06
Iter: 1352 loss: 1.11965335e-06
Iter: 1353 loss: 1.11258373e-06
Iter: 1354 loss: 1.11196641e-06
Iter: 1355 loss: 1.11284976e-06
Iter: 1356 loss: 1.11171039e-06
Iter: 1357 loss: 1.11120323e-06
Iter: 1358 loss: 1.1140603e-06
Iter: 1359 loss: 1.11106476e-06
Iter: 1360 loss: 1.11067516e-06
Iter: 1361 loss: 1.11013446e-06
Iter: 1362 loss: 1.11007728e-06
Iter: 1363 loss: 1.10921837e-06
Iter: 1364 loss: 1.11464556e-06
Iter: 1365 loss: 1.10909446e-06
Iter: 1366 loss: 1.10866e-06
Iter: 1367 loss: 1.10893689e-06
Iter: 1368 loss: 1.10833662e-06
Iter: 1369 loss: 1.10765029e-06
Iter: 1370 loss: 1.10774681e-06
Iter: 1371 loss: 1.10718406e-06
Iter: 1372 loss: 1.10673761e-06
Iter: 1373 loss: 1.10895417e-06
Iter: 1374 loss: 1.10666542e-06
Iter: 1375 loss: 1.10604901e-06
Iter: 1376 loss: 1.10620249e-06
Iter: 1377 loss: 1.10558619e-06
Iter: 1378 loss: 1.10570011e-06
Iter: 1379 loss: 1.10543795e-06
Iter: 1380 loss: 1.10522956e-06
Iter: 1381 loss: 1.10533131e-06
Iter: 1382 loss: 1.1051784e-06
Iter: 1383 loss: 1.10478027e-06
Iter: 1384 loss: 1.10524309e-06
Iter: 1385 loss: 1.1045704e-06
Iter: 1386 loss: 1.10421047e-06
Iter: 1387 loss: 1.10387657e-06
Iter: 1388 loss: 1.10375595e-06
Iter: 1389 loss: 1.10333258e-06
Iter: 1390 loss: 1.10394922e-06
Iter: 1391 loss: 1.10302744e-06
Iter: 1392 loss: 1.10240865e-06
Iter: 1393 loss: 1.10330313e-06
Iter: 1394 loss: 1.10215456e-06
Iter: 1395 loss: 1.1014597e-06
Iter: 1396 loss: 1.1052731e-06
Iter: 1397 loss: 1.10139649e-06
Iter: 1398 loss: 1.10083693e-06
Iter: 1399 loss: 1.10065946e-06
Iter: 1400 loss: 1.10035944e-06
Iter: 1401 loss: 1.09972802e-06
Iter: 1402 loss: 1.10499923e-06
Iter: 1403 loss: 1.09968846e-06
Iter: 1404 loss: 1.09909206e-06
Iter: 1405 loss: 1.0996589e-06
Iter: 1406 loss: 1.09877305e-06
Iter: 1407 loss: 1.09842426e-06
Iter: 1408 loss: 1.10091901e-06
Iter: 1409 loss: 1.09834832e-06
Iter: 1410 loss: 1.09783389e-06
Iter: 1411 loss: 1.09707764e-06
Iter: 1412 loss: 1.09709504e-06
Iter: 1413 loss: 1.09674579e-06
Iter: 1414 loss: 1.096598e-06
Iter: 1415 loss: 1.09621215e-06
Iter: 1416 loss: 1.09622692e-06
Iter: 1417 loss: 1.09608288e-06
Iter: 1418 loss: 1.09582277e-06
Iter: 1419 loss: 1.09571465e-06
Iter: 1420 loss: 1.09532061e-06
Iter: 1421 loss: 1.09439429e-06
Iter: 1422 loss: 1.10878909e-06
Iter: 1423 loss: 1.09434689e-06
Iter: 1424 loss: 1.09375253e-06
Iter: 1425 loss: 1.09379414e-06
Iter: 1426 loss: 1.09329949e-06
Iter: 1427 loss: 1.09295638e-06
Iter: 1428 loss: 1.09273969e-06
Iter: 1429 loss: 1.09203756e-06
Iter: 1430 loss: 1.09721623e-06
Iter: 1431 loss: 1.0919166e-06
Iter: 1432 loss: 1.09161419e-06
Iter: 1433 loss: 1.09187704e-06
Iter: 1434 loss: 1.09140854e-06
Iter: 1435 loss: 1.09075199e-06
Iter: 1436 loss: 1.09074608e-06
Iter: 1437 loss: 1.09020948e-06
Iter: 1438 loss: 1.08946e-06
Iter: 1439 loss: 1.09438201e-06
Iter: 1440 loss: 1.08931931e-06
Iter: 1441 loss: 1.0887793e-06
Iter: 1442 loss: 1.08818335e-06
Iter: 1443 loss: 1.08802851e-06
Iter: 1444 loss: 1.08749623e-06
Iter: 1445 loss: 1.08750078e-06
Iter: 1446 loss: 1.08731706e-06
Iter: 1447 loss: 1.08731228e-06
Iter: 1448 loss: 1.08705217e-06
Iter: 1449 loss: 1.08685322e-06
Iter: 1450 loss: 1.08683753e-06
Iter: 1451 loss: 1.08645008e-06
Iter: 1452 loss: 1.08732911e-06
Iter: 1453 loss: 1.08630366e-06
Iter: 1454 loss: 1.08615018e-06
Iter: 1455 loss: 1.08551319e-06
Iter: 1456 loss: 1.09092821e-06
Iter: 1457 loss: 1.08552365e-06
Iter: 1458 loss: 1.08487529e-06
Iter: 1459 loss: 1.0881904e-06
Iter: 1460 loss: 1.08479344e-06
Iter: 1461 loss: 1.08417885e-06
Iter: 1462 loss: 1.08587346e-06
Iter: 1463 loss: 1.08396557e-06
Iter: 1464 loss: 1.08339873e-06
Iter: 1465 loss: 1.08668826e-06
Iter: 1466 loss: 1.08335416e-06
Iter: 1467 loss: 1.08292534e-06
Iter: 1468 loss: 1.08275708e-06
Iter: 1469 loss: 1.08254494e-06
Iter: 1470 loss: 1.08178551e-06
Iter: 1471 loss: 1.08417714e-06
Iter: 1472 loss: 1.08155223e-06
Iter: 1473 loss: 1.08102904e-06
Iter: 1474 loss: 1.08217637e-06
Iter: 1475 loss: 1.08082759e-06
Iter: 1476 loss: 1.08006213e-06
Iter: 1477 loss: 1.08012864e-06
Iter: 1478 loss: 1.07947403e-06
Iter: 1479 loss: 1.0796083e-06
Iter: 1480 loss: 1.07918959e-06
Iter: 1481 loss: 1.07901212e-06
Iter: 1482 loss: 1.07966696e-06
Iter: 1483 loss: 1.07895971e-06
Iter: 1484 loss: 1.07873666e-06
Iter: 1485 loss: 1.07865935e-06
Iter: 1486 loss: 1.0785318e-06
Iter: 1487 loss: 1.07810047e-06
Iter: 1488 loss: 1.07749906e-06
Iter: 1489 loss: 1.09254734e-06
Iter: 1490 loss: 1.07750679e-06
Iter: 1491 loss: 1.07691608e-06
Iter: 1492 loss: 1.07809137e-06
Iter: 1493 loss: 1.07680273e-06
Iter: 1494 loss: 1.07615142e-06
Iter: 1495 loss: 1.07725134e-06
Iter: 1496 loss: 1.07578205e-06
Iter: 1497 loss: 1.07530707e-06
Iter: 1498 loss: 1.08259655e-06
Iter: 1499 loss: 1.07530025e-06
Iter: 1500 loss: 1.07491928e-06
Iter: 1501 loss: 1.07429514e-06
Iter: 1502 loss: 1.07424489e-06
Iter: 1503 loss: 1.07355402e-06
Iter: 1504 loss: 1.07840617e-06
Iter: 1505 loss: 1.07346887e-06
Iter: 1506 loss: 1.07305129e-06
Iter: 1507 loss: 1.07312985e-06
Iter: 1508 loss: 1.07271057e-06
Iter: 1509 loss: 1.0720355e-06
Iter: 1510 loss: 1.07540882e-06
Iter: 1511 loss: 1.07188453e-06
Iter: 1512 loss: 1.07202732e-06
Iter: 1513 loss: 1.07172684e-06
Iter: 1514 loss: 1.07159735e-06
Iter: 1515 loss: 1.07185269e-06
Iter: 1516 loss: 1.0715e-06
Iter: 1517 loss: 1.07140272e-06
Iter: 1518 loss: 1.0715205e-06
Iter: 1519 loss: 1.07122173e-06
Iter: 1520 loss: 1.07099913e-06
Iter: 1521 loss: 1.07072083e-06
Iter: 1522 loss: 1.07071719e-06
Iter: 1523 loss: 1.07032758e-06
Iter: 1524 loss: 1.07024334e-06
Iter: 1525 loss: 1.07008145e-06
Iter: 1526 loss: 1.0694032e-06
Iter: 1527 loss: 1.07143433e-06
Iter: 1528 loss: 1.06921641e-06
Iter: 1529 loss: 1.06864718e-06
Iter: 1530 loss: 1.07029155e-06
Iter: 1531 loss: 1.06862149e-06
Iter: 1532 loss: 1.06801531e-06
Iter: 1533 loss: 1.06929895e-06
Iter: 1534 loss: 1.06783921e-06
Iter: 1535 loss: 1.06741163e-06
Iter: 1536 loss: 1.069277e-06
Iter: 1537 loss: 1.06725895e-06
Iter: 1538 loss: 1.06670234e-06
Iter: 1539 loss: 1.06662901e-06
Iter: 1540 loss: 1.06627499e-06
Iter: 1541 loss: 1.06565972e-06
Iter: 1542 loss: 1.07180301e-06
Iter: 1543 loss: 1.0656272e-06
Iter: 1544 loss: 1.06524612e-06
Iter: 1545 loss: 1.06459993e-06
Iter: 1546 loss: 1.06452433e-06
Iter: 1547 loss: 1.06647326e-06
Iter: 1548 loss: 1.06435277e-06
Iter: 1549 loss: 1.06427603e-06
Iter: 1550 loss: 1.0640108e-06
Iter: 1551 loss: 1.06408402e-06
Iter: 1552 loss: 1.06372022e-06
Iter: 1553 loss: 1.06352798e-06
Iter: 1554 loss: 1.06330549e-06
Iter: 1555 loss: 1.06274342e-06
Iter: 1556 loss: 1.0623653e-06
Iter: 1557 loss: 1.06213599e-06
Iter: 1558 loss: 1.06173229e-06
Iter: 1559 loss: 1.06335597e-06
Iter: 1560 loss: 1.06166272e-06
Iter: 1561 loss: 1.06109883e-06
Iter: 1562 loss: 1.06143978e-06
Iter: 1563 loss: 1.06076561e-06
Iter: 1564 loss: 1.06023992e-06
Iter: 1565 loss: 1.06374216e-06
Iter: 1566 loss: 1.06027164e-06
Iter: 1567 loss: 1.05969957e-06
Iter: 1568 loss: 1.05942809e-06
Iter: 1569 loss: 1.059292e-06
Iter: 1570 loss: 1.05882782e-06
Iter: 1571 loss: 1.05886636e-06
Iter: 1572 loss: 1.05843378e-06
Iter: 1573 loss: 1.05818981e-06
Iter: 1574 loss: 1.05801109e-06
Iter: 1575 loss: 1.05766696e-06
Iter: 1576 loss: 1.05825404e-06
Iter: 1577 loss: 1.05746e-06
Iter: 1578 loss: 1.05728111e-06
Iter: 1579 loss: 1.05699223e-06
Iter: 1580 loss: 1.05695335e-06
Iter: 1581 loss: 1.0568981e-06
Iter: 1582 loss: 1.05661979e-06
Iter: 1583 loss: 1.05662275e-06
Iter: 1584 loss: 1.05661059e-06
Iter: 1585 loss: 1.05662866e-06
Iter: 1586 loss: 1.05663094e-06
Iter: 1587 loss: 1.05657739e-06
Iter: 1588 loss: 1.05662298e-06
Iter: 1589 loss: 1.05660251e-06
Iter: 1590 loss: 1.0565841e-06
Iter: 1591 loss: 1.05661547e-06
Iter: 1592 loss: 1.05662207e-06
Iter: 1593 loss: 1.05663128e-06
Iter: 1594 loss: 1.05661991e-06
Iter: 1595 loss: 1.05663526e-06
Iter: 1596 loss: 1.05663355e-06
Iter: 1597 loss: 1.05664e-06
Iter: 1598 loss: 1.05661366e-06
Iter: 1599 loss: 1.05663253e-06
Iter: 1600 loss: 1.05662866e-06
Iter: 1601 loss: 1.05661729e-06
Iter: 1602 loss: 1.05661957e-06
Iter: 1603 loss: 1.05661911e-06
Iter: 1604 loss: 1.05663139e-06
Iter: 1605 loss: 1.05661877e-06
Iter: 1606 loss: 1.05663094e-06
Iter: 1607 loss: 1.05661877e-06
Iter: 1608 loss: 1.05663094e-06
Iter: 1609 loss: 1.05621382e-06
Iter: 1610 loss: 1.05971367e-06
Iter: 1611 loss: 1.05608251e-06
Iter: 1612 loss: 1.05571144e-06
Iter: 1613 loss: 1.05535321e-06
Iter: 1614 loss: 1.05526624e-06
Iter: 1615 loss: 1.05484605e-06
Iter: 1616 loss: 1.05482195e-06
Iter: 1617 loss: 1.05456559e-06
Iter: 1618 loss: 1.05392689e-06
Iter: 1619 loss: 1.05661809e-06
Iter: 1620 loss: 1.05379468e-06
Iter: 1621 loss: 1.05346362e-06
Iter: 1622 loss: 1.05412266e-06
Iter: 1623 loss: 1.05334459e-06
Iter: 1624 loss: 1.0529908e-06
Iter: 1625 loss: 1.05268305e-06
Iter: 1626 loss: 1.0526154e-06
Iter: 1627 loss: 1.05219374e-06
Iter: 1628 loss: 1.0561721e-06
Iter: 1629 loss: 1.05226411e-06
Iter: 1630 loss: 1.0520057e-06
Iter: 1631 loss: 1.05186234e-06
Iter: 1632 loss: 1.05165816e-06
Iter: 1633 loss: 1.05120853e-06
Iter: 1634 loss: 1.05607091e-06
Iter: 1635 loss: 1.05110257e-06
Iter: 1636 loss: 1.05115828e-06
Iter: 1637 loss: 1.05096e-06
Iter: 1638 loss: 1.05078948e-06
Iter: 1639 loss: 1.05070762e-06
Iter: 1640 loss: 1.05138326e-06
Iter: 1641 loss: 1.0505679e-06
Iter: 1642 loss: 1.05013237e-06
Iter: 1643 loss: 1.04960395e-06
Iter: 1644 loss: 1.0495794e-06
Iter: 1645 loss: 1.04911146e-06
Iter: 1646 loss: 1.0559786e-06
Iter: 1647 loss: 1.04908395e-06
Iter: 1648 loss: 1.04860806e-06
Iter: 1649 loss: 1.04861215e-06
Iter: 1650 loss: 1.04829701e-06
Iter: 1651 loss: 1.04800074e-06
Iter: 1652 loss: 1.04793901e-06
Iter: 1653 loss: 1.04766639e-06
Iter: 1654 loss: 1.04735091e-06
Iter: 1655 loss: 1.04729475e-06
Iter: 1656 loss: 1.04689866e-06
Iter: 1657 loss: 1.04717355e-06
Iter: 1658 loss: 1.04656147e-06
Iter: 1659 loss: 1.04625542e-06
Iter: 1660 loss: 1.04562491e-06
Iter: 1661 loss: 1.04562491e-06
Iter: 1662 loss: 1.04510809e-06
Iter: 1663 loss: 1.0513869e-06
Iter: 1664 loss: 1.04507637e-06
Iter: 1665 loss: 1.04471133e-06
Iter: 1666 loss: 1.04397645e-06
Iter: 1667 loss: 1.04400715e-06
Iter: 1668 loss: 1.04367768e-06
Iter: 1669 loss: 1.04351625e-06
Iter: 1670 loss: 1.04335788e-06
Iter: 1671 loss: 1.04329365e-06
Iter: 1672 loss: 1.04317667e-06
Iter: 1673 loss: 1.0428671e-06
Iter: 1674 loss: 1.04414221e-06
Iter: 1675 loss: 1.04283856e-06
Iter: 1676 loss: 1.0422284e-06
Iter: 1677 loss: 1.04265223e-06
Iter: 1678 loss: 1.04184016e-06
Iter: 1679 loss: 1.04140622e-06
Iter: 1680 loss: 1.0426395e-06
Iter: 1681 loss: 1.04138076e-06
Iter: 1682 loss: 1.04084404e-06
Iter: 1683 loss: 1.04077583e-06
Iter: 1684 loss: 1.04032642e-06
Iter: 1685 loss: 1.04019227e-06
Iter: 1686 loss: 1.0401194e-06
Iter: 1687 loss: 1.03988737e-06
Iter: 1688 loss: 1.03977436e-06
Iter: 1689 loss: 1.0395479e-06
Iter: 1690 loss: 1.0391193e-06
Iter: 1691 loss: 1.03888271e-06
Iter: 1692 loss: 1.03863431e-06
Iter: 1693 loss: 1.03817706e-06
Iter: 1694 loss: 1.04232197e-06
Iter: 1695 loss: 1.03818388e-06
Iter: 1696 loss: 1.03773982e-06
Iter: 1697 loss: 1.03728689e-06
Iter: 1698 loss: 1.03726563e-06
Iter: 1699 loss: 1.03667583e-06
Iter: 1700 loss: 1.04491687e-06
Iter: 1701 loss: 1.03661591e-06
Iter: 1702 loss: 1.03667242e-06
Iter: 1703 loss: 1.03638013e-06
Iter: 1704 loss: 1.03632738e-06
Iter: 1705 loss: 1.0359322e-06
Iter: 1706 loss: 1.03874618e-06
Iter: 1707 loss: 1.03590389e-06
Iter: 1708 loss: 1.03525304e-06
Iter: 1709 loss: 1.03493892e-06
Iter: 1710 loss: 1.0346439e-06
Iter: 1711 loss: 1.03406228e-06
Iter: 1712 loss: 1.03962361e-06
Iter: 1713 loss: 1.03399793e-06
Iter: 1714 loss: 1.03345883e-06
Iter: 1715 loss: 1.03301977e-06
Iter: 1716 loss: 1.03295076e-06
Iter: 1717 loss: 1.03231173e-06
Iter: 1718 loss: 1.03867217e-06
Iter: 1719 loss: 1.03233697e-06
Iter: 1720 loss: 1.03210584e-06
Iter: 1721 loss: 1.036502e-06
Iter: 1722 loss: 1.03206389e-06
Iter: 1723 loss: 1.03174943e-06
Iter: 1724 loss: 1.0315548e-06
Iter: 1725 loss: 1.03140167e-06
Iter: 1726 loss: 1.0311611e-06
Iter: 1727 loss: 1.03066043e-06
Iter: 1728 loss: 1.03066418e-06
Iter: 1729 loss: 1.02990703e-06
Iter: 1730 loss: 1.03165701e-06
Iter: 1731 loss: 1.02963645e-06
Iter: 1732 loss: 1.02930039e-06
Iter: 1733 loss: 1.032623e-06
Iter: 1734 loss: 1.02928379e-06
Iter: 1735 loss: 1.02911804e-06
Iter: 1736 loss: 1.02909587e-06
Iter: 1737 loss: 1.02879153e-06
Iter: 1738 loss: 1.02861441e-06
Iter: 1739 loss: 1.02848844e-06
Iter: 1740 loss: 1.02820877e-06
Iter: 1741 loss: 1.02823992e-06
Iter: 1742 loss: 1.02796537e-06
Iter: 1743 loss: 1.02766376e-06
Iter: 1744 loss: 1.02688784e-06
Iter: 1745 loss: 1.04032529e-06
Iter: 1746 loss: 1.02689671e-06
Iter: 1747 loss: 1.02608351e-06
Iter: 1748 loss: 1.03564639e-06
Iter: 1749 loss: 1.02599665e-06
Iter: 1750 loss: 1.02565741e-06
Iter: 1751 loss: 1.02564661e-06
Iter: 1752 loss: 1.02533591e-06
Iter: 1753 loss: 1.0246041e-06
Iter: 1754 loss: 1.02665115e-06
Iter: 1755 loss: 1.02440436e-06
Iter: 1756 loss: 1.02423337e-06
Iter: 1757 loss: 1.02403556e-06
Iter: 1758 loss: 1.02382569e-06
Iter: 1759 loss: 1.02320178e-06
Iter: 1760 loss: 1.02831598e-06
Iter: 1761 loss: 1.02306967e-06
Iter: 1762 loss: 1.02225158e-06
Iter: 1763 loss: 1.02641411e-06
Iter: 1764 loss: 1.02210333e-06
Iter: 1765 loss: 1.02164643e-06
Iter: 1766 loss: 1.02260697e-06
Iter: 1767 loss: 1.02134516e-06
Iter: 1768 loss: 1.02103286e-06
Iter: 1769 loss: 1.02103854e-06
Iter: 1770 loss: 1.02062245e-06
Iter: 1771 loss: 1.02148078e-06
Iter: 1772 loss: 1.02046101e-06
Iter: 1773 loss: 1.02007755e-06
Iter: 1774 loss: 1.01967873e-06
Iter: 1775 loss: 1.0305348e-06
Iter: 1776 loss: 1.01959972e-06
Iter: 1777 loss: 1.01891146e-06
Iter: 1778 loss: 1.02015042e-06
Iter: 1779 loss: 1.0186111e-06
Iter: 1780 loss: 1.01792125e-06
Iter: 1781 loss: 1.02072181e-06
Iter: 1782 loss: 1.01776368e-06
Iter: 1783 loss: 1.01704177e-06
Iter: 1784 loss: 1.01686442e-06
Iter: 1785 loss: 1.01648038e-06
Iter: 1786 loss: 1.0156773e-06
Iter: 1787 loss: 1.02015792e-06
Iter: 1788 loss: 1.01562955e-06
Iter: 1789 loss: 1.01497017e-06
Iter: 1790 loss: 1.01791647e-06
Iter: 1791 loss: 1.0148774e-06
Iter: 1792 loss: 1.01388275e-06
Iter: 1793 loss: 1.01559328e-06
Iter: 1794 loss: 1.01349008e-06
Iter: 1795 loss: 1.01307069e-06
Iter: 1796 loss: 1.01383262e-06
Iter: 1797 loss: 1.01290038e-06
Iter: 1798 loss: 1.01248554e-06
Iter: 1799 loss: 1.01181752e-06
Iter: 1800 loss: 1.01185071e-06
Iter: 1801 loss: 1.01159276e-06
Iter: 1802 loss: 1.01140495e-06
Iter: 1803 loss: 1.01098556e-06
Iter: 1804 loss: 1.01444971e-06
Iter: 1805 loss: 1.01104479e-06
Iter: 1806 loss: 1.01079604e-06
Iter: 1807 loss: 1.01029661e-06
Iter: 1808 loss: 1.01239857e-06
Iter: 1809 loss: 1.00997659e-06
Iter: 1810 loss: 1.00910074e-06
Iter: 1811 loss: 1.01119326e-06
Iter: 1812 loss: 1.008666e-06
Iter: 1813 loss: 1.0081593e-06
Iter: 1814 loss: 1.01246405e-06
Iter: 1815 loss: 1.00807245e-06
Iter: 1816 loss: 1.0075828e-06
Iter: 1817 loss: 1.00724105e-06
Iter: 1818 loss: 1.00706552e-06
Iter: 1819 loss: 1.00632644e-06
Iter: 1820 loss: 1.01139312e-06
Iter: 1821 loss: 1.00630621e-06
Iter: 1822 loss: 1.00570333e-06
Iter: 1823 loss: 1.0064623e-06
Iter: 1824 loss: 1.00537818e-06
Iter: 1825 loss: 1.00525847e-06
Iter: 1826 loss: 1.00507987e-06
Iter: 1827 loss: 1.00484817e-06
Iter: 1828 loss: 1.00433238e-06
Iter: 1829 loss: 1.00905413e-06
Iter: 1830 loss: 1.00425291e-06
Iter: 1831 loss: 1.0038234e-06
Iter: 1832 loss: 1.00425291e-06
Iter: 1833 loss: 1.00348689e-06
Iter: 1834 loss: 1.00311343e-06
Iter: 1835 loss: 1.0042603e-06
Iter: 1836 loss: 1.0030742e-06
Iter: 1837 loss: 1.0028657e-06
Iter: 1838 loss: 1.00281216e-06
Iter: 1839 loss: 1.00261229e-06
Iter: 1840 loss: 1.00196098e-06
Iter: 1841 loss: 1.00718944e-06
Iter: 1842 loss: 1.00191789e-06
Iter: 1843 loss: 1.00155137e-06
Iter: 1844 loss: 1.00275929e-06
Iter: 1845 loss: 1.00132615e-06
Iter: 1846 loss: 1.00090074e-06
Iter: 1847 loss: 1.00137663e-06
Iter: 1848 loss: 1.00070088e-06
Iter: 1849 loss: 1.00013551e-06
Iter: 1850 loss: 1.00392754e-06
Iter: 1851 loss: 1.00008629e-06
Iter: 1852 loss: 9.99751933e-07
Iter: 1853 loss: 9.99569238e-07
Iter: 1854 loss: 9.99471467e-07
Iter: 1855 loss: 9.98882797e-07
Iter: 1856 loss: 1.00064472e-06
Iter: 1857 loss: 9.98711926e-07
Iter: 1858 loss: 9.98503765e-07
Iter: 1859 loss: 9.98583801e-07
Iter: 1860 loss: 9.98284349e-07
Iter: 1861 loss: 9.98120186e-07
Iter: 1862 loss: 9.9804015e-07
Iter: 1863 loss: 9.97697271e-07
Iter: 1864 loss: 9.97737402e-07
Iter: 1865 loss: 9.97412144e-07
Iter: 1866 loss: 9.96949211e-07
Iter: 1867 loss: 9.99740337e-07
Iter: 1868 loss: 9.96972e-07
Iter: 1869 loss: 9.96801873e-07
Iter: 1870 loss: 9.9678789e-07
Iter: 1871 loss: 9.9662e-07
Iter: 1872 loss: 9.96294261e-07
Iter: 1873 loss: 9.96307563e-07
Iter: 1874 loss: 9.96073481e-07
Iter: 1875 loss: 9.95730943e-07
Iter: 1876 loss: 9.95732648e-07
Iter: 1877 loss: 9.95328605e-07
Iter: 1878 loss: 9.9765964e-07
Iter: 1879 loss: 9.9524857e-07
Iter: 1880 loss: 9.9493468e-07
Iter: 1881 loss: 9.96426706e-07
Iter: 1882 loss: 9.94954e-07
Iter: 1883 loss: 9.94620223e-07
Iter: 1884 loss: 9.94180141e-07
Iter: 1885 loss: 9.9426029e-07
Iter: 1886 loss: 9.93761432e-07
Iter: 1887 loss: 9.93687081e-07
Iter: 1888 loss: 9.93435833e-07
Iter: 1889 loss: 9.93291906e-07
Iter: 1890 loss: 9.93145e-07
Iter: 1891 loss: 9.92865239e-07
Iter: 1892 loss: 9.92862169e-07
Iter: 1893 loss: 9.92715741e-07
Iter: 1894 loss: 9.92643322e-07
Iter: 1895 loss: 9.92618425e-07
Iter: 1896 loss: 9.92434593e-07
Iter: 1897 loss: 9.92068749e-07
Iter: 1898 loss: 9.98219548e-07
Iter: 1899 loss: 9.92116611e-07
Iter: 1900 loss: 9.92319656e-07
Iter: 1901 loss: 9.9205e-07
Iter: 1902 loss: 9.9194574e-07
Iter: 1903 loss: 9.91933348e-07
Iter: 1904 loss: 9.91890374e-07
Iter: 1905 loss: 9.91719276e-07
Iter: 1906 loss: 9.91576144e-07
Iter: 1907 loss: 9.91449497e-07
Iter: 1908 loss: 9.91142e-07
Iter: 1909 loss: 9.91311936e-07
Iter: 1910 loss: 9.90881063e-07
Iter: 1911 loss: 9.90554327e-07
Iter: 1912 loss: 9.9064539e-07
Iter: 1913 loss: 9.90289436e-07
Iter: 1914 loss: 9.90038e-07
Iter: 1915 loss: 9.90002491e-07
Iter: 1916 loss: 9.89713e-07
Iter: 1917 loss: 9.92399123e-07
Iter: 1918 loss: 9.89682576e-07
Iter: 1919 loss: 9.89552063e-07
Iter: 1920 loss: 9.8969781e-07
Iter: 1921 loss: 9.89382e-07
Iter: 1922 loss: 9.89114596e-07
Iter: 1923 loss: 9.90790795e-07
Iter: 1924 loss: 9.89119599e-07
Iter: 1925 loss: 9.88899274e-07
Iter: 1926 loss: 9.89374485e-07
Iter: 1927 loss: 9.88866645e-07
Iter: 1928 loss: 9.886096e-07
Iter: 1929 loss: 9.88697593e-07
Iter: 1930 loss: 9.88525471e-07
Iter: 1931 loss: 9.88530246e-07
Iter: 1932 loss: 9.88422812e-07
Iter: 1933 loss: 9.88289457e-07
Iter: 1934 loss: 9.88337774e-07
Iter: 1935 loss: 9.88179e-07
Iter: 1936 loss: 9.88055262e-07
Iter: 1937 loss: 9.87819e-07
Iter: 1938 loss: 9.90077751e-07
Iter: 1939 loss: 9.87749e-07
Iter: 1940 loss: 9.87425665e-07
Iter: 1941 loss: 9.88210104e-07
Iter: 1942 loss: 9.87363364e-07
Iter: 1943 loss: 9.87139288e-07
Iter: 1944 loss: 9.88418492e-07
Iter: 1945 loss: 9.87011276e-07
Iter: 1946 loss: 9.86772534e-07
Iter: 1947 loss: 9.86831651e-07
Iter: 1948 loss: 9.86541e-07
Iter: 1949 loss: 9.86189889e-07
Iter: 1950 loss: 9.89901537e-07
Iter: 1951 loss: 9.86170903e-07
Iter: 1952 loss: 9.85962515e-07
Iter: 1953 loss: 9.87603698e-07
Iter: 1954 loss: 9.8593091e-07
Iter: 1955 loss: 9.8568853e-07
Iter: 1956 loss: 9.85458655e-07
Iter: 1957 loss: 9.8549026e-07
Iter: 1958 loss: 9.85151928e-07
Iter: 1959 loss: 9.851301e-07
Iter: 1960 loss: 9.8490932e-07
Iter: 1961 loss: 9.8480939e-07
Iter: 1962 loss: 9.84698545e-07
Iter: 1963 loss: 9.84571443e-07
Iter: 1964 loss: 9.84559847e-07
Iter: 1965 loss: 9.84432745e-07
Iter: 1966 loss: 9.84377721e-07
Iter: 1967 loss: 9.84325197e-07
Iter: 1968 loss: 9.84010853e-07
Iter: 1969 loss: 9.83854875e-07
Iter: 1970 loss: 9.83727546e-07
Iter: 1971 loss: 9.83383416e-07
Iter: 1972 loss: 9.84657618e-07
Iter: 1973 loss: 9.83321911e-07
Iter: 1974 loss: 9.83109544e-07
Iter: 1975 loss: 9.82943902e-07
Iter: 1976 loss: 9.82783831e-07
Iter: 1977 loss: 9.82343636e-07
Iter: 1978 loss: 9.84704e-07
Iter: 1979 loss: 9.82292e-07
Iter: 1980 loss: 9.82087386e-07
Iter: 1981 loss: 9.85095312e-07
Iter: 1982 loss: 9.82095116e-07
Iter: 1983 loss: 9.82003712e-07
Iter: 1984 loss: 9.81931635e-07
Iter: 1985 loss: 9.81777475e-07
Iter: 1986 loss: 9.81497351e-07
Iter: 1987 loss: 9.83087602e-07
Iter: 1988 loss: 9.81466201e-07
Iter: 1989 loss: 9.81243147e-07
Iter: 1990 loss: 9.83120344e-07
Iter: 1991 loss: 9.81230414e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8
+ date
Mon Oct 26 19:33:13 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 2.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi2.8_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c5a3158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c536620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c536ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c5360d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c635598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c4c5d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c4fe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c50ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c478488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c4787b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c478620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c4789d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c4788c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c3d3c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c38c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c338730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c338158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c351510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c303598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c2b6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c2b67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c2b6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c255950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c2b6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c2b6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c1e0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c211840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c195840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c19a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c19a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c16f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c0fb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c0fbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c0cac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c0dc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f301c094d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.64745468e-05
Iter: 2 loss: 2.78010157e-05
Iter: 3 loss: 2.23126699e-05
Iter: 4 loss: 2.10268445e-05
Iter: 5 loss: 2.05618526e-05
Iter: 6 loss: 1.98447815e-05
Iter: 7 loss: 1.89948e-05
Iter: 8 loss: 1.69652594e-05
Iter: 9 loss: 3.972794e-05
Iter: 10 loss: 1.67671897e-05
Iter: 11 loss: 1.55293983e-05
Iter: 12 loss: 1.54522168e-05
Iter: 13 loss: 1.45972426e-05
Iter: 14 loss: 1.35007376e-05
Iter: 15 loss: 1.34216534e-05
Iter: 16 loss: 1.26288651e-05
Iter: 17 loss: 1.83043649e-05
Iter: 18 loss: 1.25596707e-05
Iter: 19 loss: 1.20768182e-05
Iter: 20 loss: 1.17236232e-05
Iter: 21 loss: 1.15594667e-05
Iter: 22 loss: 1.10798146e-05
Iter: 23 loss: 1.18391408e-05
Iter: 24 loss: 1.08568938e-05
Iter: 25 loss: 1.06453135e-05
Iter: 26 loss: 1.00013885e-05
Iter: 27 loss: 1.16282426e-05
Iter: 28 loss: 9.64157152e-06
Iter: 29 loss: 9.28279769e-06
Iter: 30 loss: 9.24148117e-06
Iter: 31 loss: 8.86553062e-06
Iter: 32 loss: 8.28165139e-06
Iter: 33 loss: 8.2736542e-06
Iter: 34 loss: 7.85612247e-06
Iter: 35 loss: 1.27119074e-05
Iter: 36 loss: 7.84980693e-06
Iter: 37 loss: 7.48032653e-06
Iter: 38 loss: 8.46887542e-06
Iter: 39 loss: 7.35720596e-06
Iter: 40 loss: 7.0987e-06
Iter: 41 loss: 7.40936866e-06
Iter: 42 loss: 6.96214101e-06
Iter: 43 loss: 6.6990242e-06
Iter: 44 loss: 6.69900464e-06
Iter: 45 loss: 6.5873769e-06
Iter: 46 loss: 6.68417442e-06
Iter: 47 loss: 6.52136487e-06
Iter: 48 loss: 6.35911465e-06
Iter: 49 loss: 6.21112031e-06
Iter: 50 loss: 6.17137493e-06
Iter: 51 loss: 5.98400584e-06
Iter: 52 loss: 8.78921128e-06
Iter: 53 loss: 5.9837239e-06
Iter: 54 loss: 5.87372733e-06
Iter: 55 loss: 6.69150177e-06
Iter: 56 loss: 5.86510851e-06
Iter: 57 loss: 5.74310889e-06
Iter: 58 loss: 5.79605512e-06
Iter: 59 loss: 5.65974642e-06
Iter: 60 loss: 5.55821225e-06
Iter: 61 loss: 5.80624555e-06
Iter: 62 loss: 5.52187385e-06
Iter: 63 loss: 5.41450663e-06
Iter: 64 loss: 5.2438827e-06
Iter: 65 loss: 5.24250527e-06
Iter: 66 loss: 5.05971593e-06
Iter: 67 loss: 6.18445938e-06
Iter: 68 loss: 5.03798765e-06
Iter: 69 loss: 4.87876787e-06
Iter: 70 loss: 6.07857874e-06
Iter: 71 loss: 4.86636964e-06
Iter: 72 loss: 4.77447838e-06
Iter: 73 loss: 4.84511747e-06
Iter: 74 loss: 4.71813746e-06
Iter: 75 loss: 4.5936672e-06
Iter: 76 loss: 5.39209941e-06
Iter: 77 loss: 4.57998476e-06
Iter: 78 loss: 4.51798905e-06
Iter: 79 loss: 5.20172716e-06
Iter: 80 loss: 4.51672e-06
Iter: 81 loss: 4.46234844e-06
Iter: 82 loss: 4.36123e-06
Iter: 83 loss: 6.64237177e-06
Iter: 84 loss: 4.36083974e-06
Iter: 85 loss: 4.28942394e-06
Iter: 86 loss: 4.28932e-06
Iter: 87 loss: 4.23616e-06
Iter: 88 loss: 4.26716906e-06
Iter: 89 loss: 4.20163315e-06
Iter: 90 loss: 4.13100952e-06
Iter: 91 loss: 5.03695082e-06
Iter: 92 loss: 4.13047383e-06
Iter: 93 loss: 4.10140274e-06
Iter: 94 loss: 4.07219886e-06
Iter: 95 loss: 4.06650088e-06
Iter: 96 loss: 4.004326e-06
Iter: 97 loss: 3.95498228e-06
Iter: 98 loss: 3.9361521e-06
Iter: 99 loss: 3.86876809e-06
Iter: 100 loss: 4.37473182e-06
Iter: 101 loss: 3.86354168e-06
Iter: 102 loss: 3.79858739e-06
Iter: 103 loss: 3.87846467e-06
Iter: 104 loss: 3.76463959e-06
Iter: 105 loss: 3.71674332e-06
Iter: 106 loss: 3.76682101e-06
Iter: 107 loss: 3.69023019e-06
Iter: 108 loss: 3.630827e-06
Iter: 109 loss: 4.2716e-06
Iter: 110 loss: 3.62948185e-06
Iter: 111 loss: 3.59740466e-06
Iter: 112 loss: 3.71772e-06
Iter: 113 loss: 3.58958141e-06
Iter: 114 loss: 3.5457881e-06
Iter: 115 loss: 3.55877773e-06
Iter: 116 loss: 3.51468316e-06
Iter: 117 loss: 3.47683363e-06
Iter: 118 loss: 3.82127973e-06
Iter: 119 loss: 3.47490322e-06
Iter: 120 loss: 3.44843124e-06
Iter: 121 loss: 3.41495297e-06
Iter: 122 loss: 3.4124655e-06
Iter: 123 loss: 3.38634504e-06
Iter: 124 loss: 3.38085283e-06
Iter: 125 loss: 3.36183393e-06
Iter: 126 loss: 3.36044559e-06
Iter: 127 loss: 3.34609877e-06
Iter: 128 loss: 3.32134277e-06
Iter: 129 loss: 3.2789917e-06
Iter: 130 loss: 3.27880866e-06
Iter: 131 loss: 3.24563621e-06
Iter: 132 loss: 3.24555458e-06
Iter: 133 loss: 3.21533935e-06
Iter: 134 loss: 3.16758496e-06
Iter: 135 loss: 3.16724299e-06
Iter: 136 loss: 3.12711882e-06
Iter: 137 loss: 3.70632461e-06
Iter: 138 loss: 3.12702514e-06
Iter: 139 loss: 3.09104121e-06
Iter: 140 loss: 3.06874063e-06
Iter: 141 loss: 3.05429876e-06
Iter: 142 loss: 3.02302851e-06
Iter: 143 loss: 3.02301987e-06
Iter: 144 loss: 2.98983878e-06
Iter: 145 loss: 3.06404058e-06
Iter: 146 loss: 2.97735164e-06
Iter: 147 loss: 2.95022073e-06
Iter: 148 loss: 3.09384814e-06
Iter: 149 loss: 2.94587289e-06
Iter: 150 loss: 2.92729078e-06
Iter: 151 loss: 2.91882907e-06
Iter: 152 loss: 2.90963021e-06
Iter: 153 loss: 2.88704064e-06
Iter: 154 loss: 2.88721026e-06
Iter: 155 loss: 2.87189096e-06
Iter: 156 loss: 2.93963285e-06
Iter: 157 loss: 2.86896739e-06
Iter: 158 loss: 2.85885608e-06
Iter: 159 loss: 2.83332952e-06
Iter: 160 loss: 3.08010112e-06
Iter: 161 loss: 2.82988663e-06
Iter: 162 loss: 2.80596987e-06
Iter: 163 loss: 3.15984062e-06
Iter: 164 loss: 2.80601034e-06
Iter: 165 loss: 2.78911375e-06
Iter: 166 loss: 2.76457331e-06
Iter: 167 loss: 2.76384435e-06
Iter: 168 loss: 2.73452497e-06
Iter: 169 loss: 3.14543831e-06
Iter: 170 loss: 2.73446653e-06
Iter: 171 loss: 2.71589124e-06
Iter: 172 loss: 2.68371105e-06
Iter: 173 loss: 2.68373151e-06
Iter: 174 loss: 2.66214374e-06
Iter: 175 loss: 2.66093753e-06
Iter: 176 loss: 2.64265782e-06
Iter: 177 loss: 2.65051858e-06
Iter: 178 loss: 2.63039647e-06
Iter: 179 loss: 2.60259208e-06
Iter: 180 loss: 2.86976979e-06
Iter: 181 loss: 2.60167508e-06
Iter: 182 loss: 2.5915956e-06
Iter: 183 loss: 2.58918635e-06
Iter: 184 loss: 2.58274031e-06
Iter: 185 loss: 2.564851e-06
Iter: 186 loss: 2.60488014e-06
Iter: 187 loss: 2.55802934e-06
Iter: 188 loss: 2.54356632e-06
Iter: 189 loss: 2.71174349e-06
Iter: 190 loss: 2.54334896e-06
Iter: 191 loss: 2.53421376e-06
Iter: 192 loss: 2.51692268e-06
Iter: 193 loss: 2.89157106e-06
Iter: 194 loss: 2.51688971e-06
Iter: 195 loss: 2.49641062e-06
Iter: 196 loss: 2.60310344e-06
Iter: 197 loss: 2.49314871e-06
Iter: 198 loss: 2.47993444e-06
Iter: 199 loss: 2.46965942e-06
Iter: 200 loss: 2.46564196e-06
Iter: 201 loss: 2.43954969e-06
Iter: 202 loss: 2.61459445e-06
Iter: 203 loss: 2.43701243e-06
Iter: 204 loss: 2.4237554e-06
Iter: 205 loss: 2.43833847e-06
Iter: 206 loss: 2.41653288e-06
Iter: 207 loss: 2.39663291e-06
Iter: 208 loss: 2.4402791e-06
Iter: 209 loss: 2.38916073e-06
Iter: 210 loss: 2.37328049e-06
Iter: 211 loss: 2.40115605e-06
Iter: 212 loss: 2.36653341e-06
Iter: 213 loss: 2.35166863e-06
Iter: 214 loss: 2.35169091e-06
Iter: 215 loss: 2.34471509e-06
Iter: 216 loss: 2.3662e-06
Iter: 217 loss: 2.34259187e-06
Iter: 218 loss: 2.33539663e-06
Iter: 219 loss: 2.33445508e-06
Iter: 220 loss: 2.32936532e-06
Iter: 221 loss: 2.31753074e-06
Iter: 222 loss: 2.39663677e-06
Iter: 223 loss: 2.31624699e-06
Iter: 224 loss: 2.30874252e-06
Iter: 225 loss: 2.32061211e-06
Iter: 226 loss: 2.30524051e-06
Iter: 227 loss: 2.29751754e-06
Iter: 228 loss: 2.28492627e-06
Iter: 229 loss: 2.28487988e-06
Iter: 230 loss: 2.27164628e-06
Iter: 231 loss: 2.37017139e-06
Iter: 232 loss: 2.27045734e-06
Iter: 233 loss: 2.25619806e-06
Iter: 234 loss: 2.2553395e-06
Iter: 235 loss: 2.24462201e-06
Iter: 236 loss: 2.23512143e-06
Iter: 237 loss: 2.23501956e-06
Iter: 238 loss: 2.22636572e-06
Iter: 239 loss: 2.21185292e-06
Iter: 240 loss: 2.21190339e-06
Iter: 241 loss: 2.20006518e-06
Iter: 242 loss: 2.36644973e-06
Iter: 243 loss: 2.20004426e-06
Iter: 244 loss: 2.18946411e-06
Iter: 245 loss: 2.21305049e-06
Iter: 246 loss: 2.18546643e-06
Iter: 247 loss: 2.17564912e-06
Iter: 248 loss: 2.30235651e-06
Iter: 249 loss: 2.17569186e-06
Iter: 250 loss: 2.17097636e-06
Iter: 251 loss: 2.17466527e-06
Iter: 252 loss: 2.16807689e-06
Iter: 253 loss: 2.16081867e-06
Iter: 254 loss: 2.18408832e-06
Iter: 255 loss: 2.15874343e-06
Iter: 256 loss: 2.15183263e-06
Iter: 257 loss: 2.17246702e-06
Iter: 258 loss: 2.14962574e-06
Iter: 259 loss: 2.14459851e-06
Iter: 260 loss: 2.13772387e-06
Iter: 261 loss: 2.13743238e-06
Iter: 262 loss: 2.12503892e-06
Iter: 263 loss: 2.14552665e-06
Iter: 264 loss: 2.1195151e-06
Iter: 265 loss: 2.10854046e-06
Iter: 266 loss: 2.12709438e-06
Iter: 267 loss: 2.10365874e-06
Iter: 268 loss: 2.09066e-06
Iter: 269 loss: 2.18968717e-06
Iter: 270 loss: 2.08966685e-06
Iter: 271 loss: 2.08178062e-06
Iter: 272 loss: 2.07539961e-06
Iter: 273 loss: 2.07308335e-06
Iter: 274 loss: 2.05843685e-06
Iter: 275 loss: 2.17097863e-06
Iter: 276 loss: 2.05753304e-06
Iter: 277 loss: 2.04943763e-06
Iter: 278 loss: 2.05440097e-06
Iter: 279 loss: 2.04434264e-06
Iter: 280 loss: 2.03376408e-06
Iter: 281 loss: 2.17438014e-06
Iter: 282 loss: 2.03375839e-06
Iter: 283 loss: 2.02890874e-06
Iter: 284 loss: 2.05102742e-06
Iter: 285 loss: 2.02804358e-06
Iter: 286 loss: 2.02403226e-06
Iter: 287 loss: 2.02992828e-06
Iter: 288 loss: 2.0221e-06
Iter: 289 loss: 2.01594867e-06
Iter: 290 loss: 2.0164025e-06
Iter: 291 loss: 2.01124476e-06
Iter: 292 loss: 2.00464456e-06
Iter: 293 loss: 2.0205573e-06
Iter: 294 loss: 2.00225713e-06
Iter: 295 loss: 1.99435112e-06
Iter: 296 loss: 1.98372027e-06
Iter: 297 loss: 1.98324688e-06
Iter: 298 loss: 1.97454642e-06
Iter: 299 loss: 2.0913717e-06
Iter: 300 loss: 1.97446934e-06
Iter: 301 loss: 1.96576275e-06
Iter: 302 loss: 1.96229485e-06
Iter: 303 loss: 1.9576662e-06
Iter: 304 loss: 1.9487527e-06
Iter: 305 loss: 2.04644448e-06
Iter: 306 loss: 1.94865447e-06
Iter: 307 loss: 1.9403908e-06
Iter: 308 loss: 1.93625738e-06
Iter: 309 loss: 1.93247411e-06
Iter: 310 loss: 1.92420885e-06
Iter: 311 loss: 2.00858267e-06
Iter: 312 loss: 1.9239892e-06
Iter: 313 loss: 1.91666e-06
Iter: 314 loss: 1.94569725e-06
Iter: 315 loss: 1.91507525e-06
Iter: 316 loss: 1.9087804e-06
Iter: 317 loss: 1.9622762e-06
Iter: 318 loss: 1.90845731e-06
Iter: 319 loss: 1.90548894e-06
Iter: 320 loss: 1.9134568e-06
Iter: 321 loss: 1.90464095e-06
Iter: 322 loss: 1.90081892e-06
Iter: 323 loss: 1.89891557e-06
Iter: 324 loss: 1.89720856e-06
Iter: 325 loss: 1.89027014e-06
Iter: 326 loss: 1.8989947e-06
Iter: 327 loss: 1.88659953e-06
Iter: 328 loss: 1.88149011e-06
Iter: 329 loss: 1.88952095e-06
Iter: 330 loss: 1.87896262e-06
Iter: 331 loss: 1.87200931e-06
Iter: 332 loss: 1.88248237e-06
Iter: 333 loss: 1.86861496e-06
Iter: 334 loss: 1.86266732e-06
Iter: 335 loss: 1.86099555e-06
Iter: 336 loss: 1.85746853e-06
Iter: 337 loss: 1.8473969e-06
Iter: 338 loss: 1.93960204e-06
Iter: 339 loss: 1.84692863e-06
Iter: 340 loss: 1.84202952e-06
Iter: 341 loss: 1.84541068e-06
Iter: 342 loss: 1.83901716e-06
Iter: 343 loss: 1.83153747e-06
Iter: 344 loss: 1.8589368e-06
Iter: 345 loss: 1.82995041e-06
Iter: 346 loss: 1.82516794e-06
Iter: 347 loss: 1.84954968e-06
Iter: 348 loss: 1.82433314e-06
Iter: 349 loss: 1.81915993e-06
Iter: 350 loss: 1.84476153e-06
Iter: 351 loss: 1.81832263e-06
Iter: 352 loss: 1.81507494e-06
Iter: 353 loss: 1.82979466e-06
Iter: 354 loss: 1.81445785e-06
Iter: 355 loss: 1.81194332e-06
Iter: 356 loss: 1.81815631e-06
Iter: 357 loss: 1.8110029e-06
Iter: 358 loss: 1.80762754e-06
Iter: 359 loss: 1.8026517e-06
Iter: 360 loss: 1.80264453e-06
Iter: 361 loss: 1.79750191e-06
Iter: 362 loss: 1.84440091e-06
Iter: 363 loss: 1.79739436e-06
Iter: 364 loss: 1.79360529e-06
Iter: 365 loss: 1.78714276e-06
Iter: 366 loss: 1.94516406e-06
Iter: 367 loss: 1.787217e-06
Iter: 368 loss: 1.7808652e-06
Iter: 369 loss: 1.87028616e-06
Iter: 370 loss: 1.78089692e-06
Iter: 371 loss: 1.77569768e-06
Iter: 372 loss: 1.77056177e-06
Iter: 373 loss: 1.76941478e-06
Iter: 374 loss: 1.76652804e-06
Iter: 375 loss: 1.76558137e-06
Iter: 376 loss: 1.76265132e-06
Iter: 377 loss: 1.75667719e-06
Iter: 378 loss: 1.8681767e-06
Iter: 379 loss: 1.75665946e-06
Iter: 380 loss: 1.75254934e-06
Iter: 381 loss: 1.75236255e-06
Iter: 382 loss: 1.74945671e-06
Iter: 383 loss: 1.75811681e-06
Iter: 384 loss: 1.74851436e-06
Iter: 385 loss: 1.74477168e-06
Iter: 386 loss: 1.76399021e-06
Iter: 387 loss: 1.7442303e-06
Iter: 388 loss: 1.74156071e-06
Iter: 389 loss: 1.75109869e-06
Iter: 390 loss: 1.74084767e-06
Iter: 391 loss: 1.73858e-06
Iter: 392 loss: 1.73775697e-06
Iter: 393 loss: 1.73655917e-06
Iter: 394 loss: 1.73230092e-06
Iter: 395 loss: 1.73013e-06
Iter: 396 loss: 1.72817727e-06
Iter: 397 loss: 1.72352441e-06
Iter: 398 loss: 1.75294053e-06
Iter: 399 loss: 1.72282728e-06
Iter: 400 loss: 1.7176792e-06
Iter: 401 loss: 1.71406009e-06
Iter: 402 loss: 1.71231932e-06
Iter: 403 loss: 1.70625071e-06
Iter: 404 loss: 1.73242699e-06
Iter: 405 loss: 1.70492967e-06
Iter: 406 loss: 1.69751422e-06
Iter: 407 loss: 1.7163793e-06
Iter: 408 loss: 1.69506473e-06
Iter: 409 loss: 1.6905617e-06
Iter: 410 loss: 1.7192308e-06
Iter: 411 loss: 1.69006967e-06
Iter: 412 loss: 1.68523093e-06
Iter: 413 loss: 1.68558836e-06
Iter: 414 loss: 1.68139798e-06
Iter: 415 loss: 1.67877579e-06
Iter: 416 loss: 1.67854591e-06
Iter: 417 loss: 1.6762308e-06
Iter: 418 loss: 1.67957501e-06
Iter: 419 loss: 1.67504481e-06
Iter: 420 loss: 1.67206349e-06
Iter: 421 loss: 1.67889289e-06
Iter: 422 loss: 1.67090377e-06
Iter: 423 loss: 1.66838288e-06
Iter: 424 loss: 1.67691815e-06
Iter: 425 loss: 1.66766381e-06
Iter: 426 loss: 1.66536813e-06
Iter: 427 loss: 1.6614631e-06
Iter: 428 loss: 1.66142217e-06
Iter: 429 loss: 1.6563572e-06
Iter: 430 loss: 1.69696693e-06
Iter: 431 loss: 1.65593542e-06
Iter: 432 loss: 1.65302322e-06
Iter: 433 loss: 1.6500037e-06
Iter: 434 loss: 1.64941775e-06
Iter: 435 loss: 1.64514859e-06
Iter: 436 loss: 1.7016996e-06
Iter: 437 loss: 1.64513358e-06
Iter: 438 loss: 1.64204755e-06
Iter: 439 loss: 1.6379945e-06
Iter: 440 loss: 1.6378325e-06
Iter: 441 loss: 1.63502546e-06
Iter: 442 loss: 1.63475647e-06
Iter: 443 loss: 1.6320887e-06
Iter: 444 loss: 1.62881975e-06
Iter: 445 loss: 1.62852007e-06
Iter: 446 loss: 1.62587526e-06
Iter: 447 loss: 1.62575634e-06
Iter: 448 loss: 1.62383321e-06
Iter: 449 loss: 1.65151096e-06
Iter: 450 loss: 1.6238713e-06
Iter: 451 loss: 1.62245101e-06
Iter: 452 loss: 1.62237791e-06
Iter: 453 loss: 1.62128572e-06
Iter: 454 loss: 1.61895571e-06
Iter: 455 loss: 1.62509423e-06
Iter: 456 loss: 1.61817763e-06
Iter: 457 loss: 1.61634125e-06
Iter: 458 loss: 1.61440653e-06
Iter: 459 loss: 1.6141596e-06
Iter: 460 loss: 1.61020466e-06
Iter: 461 loss: 1.62211245e-06
Iter: 462 loss: 1.60911031e-06
Iter: 463 loss: 1.60625621e-06
Iter: 464 loss: 1.60684249e-06
Iter: 465 loss: 1.60410218e-06
Iter: 466 loss: 1.59950355e-06
Iter: 467 loss: 1.62118613e-06
Iter: 468 loss: 1.59877959e-06
Iter: 469 loss: 1.59583374e-06
Iter: 470 loss: 1.59261083e-06
Iter: 471 loss: 1.59214596e-06
Iter: 472 loss: 1.58676653e-06
Iter: 473 loss: 1.64706489e-06
Iter: 474 loss: 1.58677597e-06
Iter: 475 loss: 1.5831888e-06
Iter: 476 loss: 1.58356193e-06
Iter: 477 loss: 1.58037483e-06
Iter: 478 loss: 1.57653903e-06
Iter: 479 loss: 1.63022673e-06
Iter: 480 loss: 1.57659815e-06
Iter: 481 loss: 1.57485158e-06
Iter: 482 loss: 1.5748235e-06
Iter: 483 loss: 1.57328759e-06
Iter: 484 loss: 1.5720583e-06
Iter: 485 loss: 1.57153727e-06
Iter: 486 loss: 1.56872318e-06
Iter: 487 loss: 1.57826912e-06
Iter: 488 loss: 1.56792748e-06
Iter: 489 loss: 1.56628971e-06
Iter: 490 loss: 1.56610008e-06
Iter: 491 loss: 1.56472549e-06
Iter: 492 loss: 1.5618109e-06
Iter: 493 loss: 1.56811666e-06
Iter: 494 loss: 1.56074532e-06
Iter: 495 loss: 1.55831492e-06
Iter: 496 loss: 1.5579036e-06
Iter: 497 loss: 1.55622979e-06
Iter: 498 loss: 1.55204543e-06
Iter: 499 loss: 1.57278828e-06
Iter: 500 loss: 1.55136809e-06
Iter: 501 loss: 1.54870725e-06
Iter: 502 loss: 1.5453079e-06
Iter: 503 loss: 1.54513441e-06
Iter: 504 loss: 1.54176928e-06
Iter: 505 loss: 1.54160966e-06
Iter: 506 loss: 1.53934593e-06
Iter: 507 loss: 1.53709709e-06
Iter: 508 loss: 1.53646397e-06
Iter: 509 loss: 1.5335977e-06
Iter: 510 loss: 1.53361e-06
Iter: 511 loss: 1.53187568e-06
Iter: 512 loss: 1.54094801e-06
Iter: 513 loss: 1.53164501e-06
Iter: 514 loss: 1.52976736e-06
Iter: 515 loss: 1.53119856e-06
Iter: 516 loss: 1.5286447e-06
Iter: 517 loss: 1.52643463e-06
Iter: 518 loss: 1.53425549e-06
Iter: 519 loss: 1.52591372e-06
Iter: 520 loss: 1.52453435e-06
Iter: 521 loss: 1.5235762e-06
Iter: 522 loss: 1.52311213e-06
Iter: 523 loss: 1.52070766e-06
Iter: 524 loss: 1.53073211e-06
Iter: 525 loss: 1.52020766e-06
Iter: 526 loss: 1.51845688e-06
Iter: 527 loss: 1.51635129e-06
Iter: 528 loss: 1.51602137e-06
Iter: 529 loss: 1.51259417e-06
Iter: 530 loss: 1.54464487e-06
Iter: 531 loss: 1.51242102e-06
Iter: 532 loss: 1.510429e-06
Iter: 533 loss: 1.50766891e-06
Iter: 534 loss: 1.50756546e-06
Iter: 535 loss: 1.50503502e-06
Iter: 536 loss: 1.50494202e-06
Iter: 537 loss: 1.50302287e-06
Iter: 538 loss: 1.5016326e-06
Iter: 539 loss: 1.50101869e-06
Iter: 540 loss: 1.49884318e-06
Iter: 541 loss: 1.49879543e-06
Iter: 542 loss: 1.4973989e-06
Iter: 543 loss: 1.50451399e-06
Iter: 544 loss: 1.49717744e-06
Iter: 545 loss: 1.49553273e-06
Iter: 546 loss: 1.49461562e-06
Iter: 547 loss: 1.49388234e-06
Iter: 548 loss: 1.49184848e-06
Iter: 549 loss: 1.50473625e-06
Iter: 550 loss: 1.49161303e-06
Iter: 551 loss: 1.49029495e-06
Iter: 552 loss: 1.48862796e-06
Iter: 553 loss: 1.4883143e-06
Iter: 554 loss: 1.48564379e-06
Iter: 555 loss: 1.49618154e-06
Iter: 556 loss: 1.4850142e-06
Iter: 557 loss: 1.48281265e-06
Iter: 558 loss: 1.48484742e-06
Iter: 559 loss: 1.48163031e-06
Iter: 560 loss: 1.4786101e-06
Iter: 561 loss: 1.48857407e-06
Iter: 562 loss: 1.4777745e-06
Iter: 563 loss: 1.47553737e-06
Iter: 564 loss: 1.47398066e-06
Iter: 565 loss: 1.47322771e-06
Iter: 566 loss: 1.47110381e-06
Iter: 567 loss: 1.47083961e-06
Iter: 568 loss: 1.46953039e-06
Iter: 569 loss: 1.46739671e-06
Iter: 570 loss: 1.46734487e-06
Iter: 571 loss: 1.46538787e-06
Iter: 572 loss: 1.46543789e-06
Iter: 573 loss: 1.46426373e-06
Iter: 574 loss: 1.46677019e-06
Iter: 575 loss: 1.46380819e-06
Iter: 576 loss: 1.46195543e-06
Iter: 577 loss: 1.4702548e-06
Iter: 578 loss: 1.46164518e-06
Iter: 579 loss: 1.46052025e-06
Iter: 580 loss: 1.46422371e-06
Iter: 581 loss: 1.46024695e-06
Iter: 582 loss: 1.4592963e-06
Iter: 583 loss: 1.45766762e-06
Iter: 584 loss: 1.45755575e-06
Iter: 585 loss: 1.45547756e-06
Iter: 586 loss: 1.4699533e-06
Iter: 587 loss: 1.45544323e-06
Iter: 588 loss: 1.45398383e-06
Iter: 589 loss: 1.4539213e-06
Iter: 590 loss: 1.45289823e-06
Iter: 591 loss: 1.45077706e-06
Iter: 592 loss: 1.46120362e-06
Iter: 593 loss: 1.45040644e-06
Iter: 594 loss: 1.44887622e-06
Iter: 595 loss: 1.44626722e-06
Iter: 596 loss: 1.44629621e-06
Iter: 597 loss: 1.4442935e-06
Iter: 598 loss: 1.44417095e-06
Iter: 599 loss: 1.44256501e-06
Iter: 600 loss: 1.44042053e-06
Iter: 601 loss: 1.44027126e-06
Iter: 602 loss: 1.43795182e-06
Iter: 603 loss: 1.43799275e-06
Iter: 604 loss: 1.43644752e-06
Iter: 605 loss: 1.436057e-06
Iter: 606 loss: 1.43516343e-06
Iter: 607 loss: 1.43264492e-06
Iter: 608 loss: 1.45996125e-06
Iter: 609 loss: 1.43265561e-06
Iter: 610 loss: 1.43154068e-06
Iter: 611 loss: 1.43280181e-06
Iter: 612 loss: 1.4308514e-06
Iter: 613 loss: 1.42953559e-06
Iter: 614 loss: 1.42847603e-06
Iter: 615 loss: 1.42812019e-06
Iter: 616 loss: 1.42534282e-06
Iter: 617 loss: 1.43239845e-06
Iter: 618 loss: 1.42451518e-06
Iter: 619 loss: 1.4223499e-06
Iter: 620 loss: 1.42446208e-06
Iter: 621 loss: 1.42107751e-06
Iter: 622 loss: 1.41819896e-06
Iter: 623 loss: 1.43365855e-06
Iter: 624 loss: 1.41773694e-06
Iter: 625 loss: 1.41573594e-06
Iter: 626 loss: 1.41306805e-06
Iter: 627 loss: 1.41285807e-06
Iter: 628 loss: 1.40904615e-06
Iter: 629 loss: 1.4519112e-06
Iter: 630 loss: 1.40904149e-06
Iter: 631 loss: 1.40710733e-06
Iter: 632 loss: 1.40584598e-06
Iter: 633 loss: 1.40516363e-06
Iter: 634 loss: 1.40251336e-06
Iter: 635 loss: 1.43333568e-06
Iter: 636 loss: 1.40243174e-06
Iter: 637 loss: 1.4010825e-06
Iter: 638 loss: 1.40131544e-06
Iter: 639 loss: 1.39995109e-06
Iter: 640 loss: 1.39880854e-06
Iter: 641 loss: 1.39867439e-06
Iter: 642 loss: 1.39768247e-06
Iter: 643 loss: 1.39880046e-06
Iter: 644 loss: 1.39718941e-06
Iter: 645 loss: 1.39635131e-06
Iter: 646 loss: 1.39485564e-06
Iter: 647 loss: 1.39484177e-06
Iter: 648 loss: 1.39263273e-06
Iter: 649 loss: 1.40301154e-06
Iter: 650 loss: 1.39213068e-06
Iter: 651 loss: 1.39086865e-06
Iter: 652 loss: 1.39421877e-06
Iter: 653 loss: 1.39024064e-06
Iter: 654 loss: 1.38869837e-06
Iter: 655 loss: 1.39412555e-06
Iter: 656 loss: 1.38832968e-06
Iter: 657 loss: 1.38737175e-06
Iter: 658 loss: 1.38671805e-06
Iter: 659 loss: 1.38620203e-06
Iter: 660 loss: 1.38456016e-06
Iter: 661 loss: 1.39856172e-06
Iter: 662 loss: 1.3843943e-06
Iter: 663 loss: 1.38327073e-06
Iter: 664 loss: 1.38286396e-06
Iter: 665 loss: 1.38227654e-06
Iter: 666 loss: 1.38064729e-06
Iter: 667 loss: 1.39795054e-06
Iter: 668 loss: 1.38053929e-06
Iter: 669 loss: 1.37953248e-06
Iter: 670 loss: 1.3795493e-06
Iter: 671 loss: 1.37868744e-06
Iter: 672 loss: 1.37733582e-06
Iter: 673 loss: 1.37734492e-06
Iter: 674 loss: 1.37630059e-06
Iter: 675 loss: 1.37958693e-06
Iter: 676 loss: 1.37597294e-06
Iter: 677 loss: 1.37531606e-06
Iter: 678 loss: 1.37373263e-06
Iter: 679 loss: 1.39631254e-06
Iter: 680 loss: 1.37368193e-06
Iter: 681 loss: 1.37139307e-06
Iter: 682 loss: 1.37880738e-06
Iter: 683 loss: 1.37069446e-06
Iter: 684 loss: 1.36919584e-06
Iter: 685 loss: 1.37450638e-06
Iter: 686 loss: 1.36883386e-06
Iter: 687 loss: 1.36692086e-06
Iter: 688 loss: 1.36893118e-06
Iter: 689 loss: 1.36591905e-06
Iter: 690 loss: 1.36402218e-06
Iter: 691 loss: 1.36602216e-06
Iter: 692 loss: 1.36293147e-06
Iter: 693 loss: 1.36024232e-06
Iter: 694 loss: 1.36953827e-06
Iter: 695 loss: 1.35954883e-06
Iter: 696 loss: 1.3576115e-06
Iter: 697 loss: 1.35698531e-06
Iter: 698 loss: 1.35585606e-06
Iter: 699 loss: 1.35359085e-06
Iter: 700 loss: 1.35359562e-06
Iter: 701 loss: 1.35239281e-06
Iter: 702 loss: 1.35239895e-06
Iter: 703 loss: 1.35129699e-06
Iter: 704 loss: 1.34977722e-06
Iter: 705 loss: 1.37342704e-06
Iter: 706 loss: 1.34977756e-06
Iter: 707 loss: 1.34861102e-06
Iter: 708 loss: 1.35485061e-06
Iter: 709 loss: 1.34842867e-06
Iter: 710 loss: 1.34760296e-06
Iter: 711 loss: 1.34574111e-06
Iter: 712 loss: 1.36638437e-06
Iter: 713 loss: 1.34559605e-06
Iter: 714 loss: 1.34324637e-06
Iter: 715 loss: 1.35898301e-06
Iter: 716 loss: 1.34297125e-06
Iter: 717 loss: 1.34154766e-06
Iter: 718 loss: 1.34332481e-06
Iter: 719 loss: 1.34086952e-06
Iter: 720 loss: 1.33880394e-06
Iter: 721 loss: 1.34179822e-06
Iter: 722 loss: 1.33775688e-06
Iter: 723 loss: 1.33600111e-06
Iter: 724 loss: 1.33762853e-06
Iter: 725 loss: 1.33487106e-06
Iter: 726 loss: 1.3326021e-06
Iter: 727 loss: 1.3466223e-06
Iter: 728 loss: 1.33224398e-06
Iter: 729 loss: 1.33070193e-06
Iter: 730 loss: 1.32960463e-06
Iter: 731 loss: 1.32904017e-06
Iter: 732 loss: 1.32735272e-06
Iter: 733 loss: 1.32725449e-06
Iter: 734 loss: 1.32622927e-06
Iter: 735 loss: 1.3250858e-06
Iter: 736 loss: 1.32485957e-06
Iter: 737 loss: 1.3228057e-06
Iter: 738 loss: 1.34840411e-06
Iter: 739 loss: 1.32290268e-06
Iter: 740 loss: 1.32160051e-06
Iter: 741 loss: 1.33304172e-06
Iter: 742 loss: 1.32155162e-06
Iter: 743 loss: 1.32078958e-06
Iter: 744 loss: 1.3192365e-06
Iter: 745 loss: 1.34386585e-06
Iter: 746 loss: 1.31916238e-06
Iter: 747 loss: 1.31743673e-06
Iter: 748 loss: 1.32640025e-06
Iter: 749 loss: 1.3170885e-06
Iter: 750 loss: 1.31597744e-06
Iter: 751 loss: 1.31632373e-06
Iter: 752 loss: 1.31517299e-06
Iter: 753 loss: 1.31309457e-06
Iter: 754 loss: 1.31911156e-06
Iter: 755 loss: 1.31239085e-06
Iter: 756 loss: 1.31119623e-06
Iter: 757 loss: 1.31295019e-06
Iter: 758 loss: 1.31053389e-06
Iter: 759 loss: 1.30900139e-06
Iter: 760 loss: 1.31573222e-06
Iter: 761 loss: 1.30863077e-06
Iter: 762 loss: 1.30743888e-06
Iter: 763 loss: 1.30667217e-06
Iter: 764 loss: 1.30624517e-06
Iter: 765 loss: 1.30451622e-06
Iter: 766 loss: 1.32547302e-06
Iter: 767 loss: 1.30440492e-06
Iter: 768 loss: 1.30346461e-06
Iter: 769 loss: 1.30402395e-06
Iter: 770 loss: 1.3028739e-06
Iter: 771 loss: 1.30158389e-06
Iter: 772 loss: 1.31777108e-06
Iter: 773 loss: 1.30155627e-06
Iter: 774 loss: 1.30075523e-06
Iter: 775 loss: 1.30959177e-06
Iter: 776 loss: 1.30080946e-06
Iter: 777 loss: 1.30046544e-06
Iter: 778 loss: 1.29959017e-06
Iter: 779 loss: 1.31234344e-06
Iter: 780 loss: 1.29954969e-06
Iter: 781 loss: 1.29843647e-06
Iter: 782 loss: 1.30130275e-06
Iter: 783 loss: 1.29801333e-06
Iter: 784 loss: 1.29696468e-06
Iter: 785 loss: 1.29629882e-06
Iter: 786 loss: 1.29586203e-06
Iter: 787 loss: 1.29396744e-06
Iter: 788 loss: 1.30939225e-06
Iter: 789 loss: 1.29383909e-06
Iter: 790 loss: 1.29288264e-06
Iter: 791 loss: 1.29297473e-06
Iter: 792 loss: 1.29210639e-06
Iter: 793 loss: 1.29034345e-06
Iter: 794 loss: 1.29457067e-06
Iter: 795 loss: 1.28964302e-06
Iter: 796 loss: 1.28823785e-06
Iter: 797 loss: 1.28791578e-06
Iter: 798 loss: 1.28691852e-06
Iter: 799 loss: 1.28489899e-06
Iter: 800 loss: 1.30486069e-06
Iter: 801 loss: 1.2849091e-06
Iter: 802 loss: 1.28354827e-06
Iter: 803 loss: 1.28399927e-06
Iter: 804 loss: 1.28266777e-06
Iter: 805 loss: 1.28112379e-06
Iter: 806 loss: 1.30469618e-06
Iter: 807 loss: 1.28115096e-06
Iter: 808 loss: 1.28044962e-06
Iter: 809 loss: 1.2804187e-06
Iter: 810 loss: 1.2800383e-06
Iter: 811 loss: 1.27906901e-06
Iter: 812 loss: 1.29329123e-06
Iter: 813 loss: 1.27900557e-06
Iter: 814 loss: 1.27764838e-06
Iter: 815 loss: 1.28070792e-06
Iter: 816 loss: 1.27712883e-06
Iter: 817 loss: 1.2758519e-06
Iter: 818 loss: 1.27519866e-06
Iter: 819 loss: 1.27460305e-06
Iter: 820 loss: 1.27264548e-06
Iter: 821 loss: 1.29514672e-06
Iter: 822 loss: 1.27261671e-06
Iter: 823 loss: 1.2717469e-06
Iter: 824 loss: 1.272394e-06
Iter: 825 loss: 1.27115936e-06
Iter: 826 loss: 1.26957184e-06
Iter: 827 loss: 1.27165208e-06
Iter: 828 loss: 1.26877671e-06
Iter: 829 loss: 1.26760847e-06
Iter: 830 loss: 1.26791383e-06
Iter: 831 loss: 1.2666867e-06
Iter: 832 loss: 1.26488021e-06
Iter: 833 loss: 1.27768544e-06
Iter: 834 loss: 1.26472605e-06
Iter: 835 loss: 1.2635976e-06
Iter: 836 loss: 1.26491761e-06
Iter: 837 loss: 1.26305099e-06
Iter: 838 loss: 1.26212615e-06
Iter: 839 loss: 1.26210239e-06
Iter: 840 loss: 1.26137581e-06
Iter: 841 loss: 1.26811369e-06
Iter: 842 loss: 1.26139378e-06
Iter: 843 loss: 1.26096768e-06
Iter: 844 loss: 1.25982399e-06
Iter: 845 loss: 1.27741032e-06
Iter: 846 loss: 1.25991e-06
Iter: 847 loss: 1.25861789e-06
Iter: 848 loss: 1.26181385e-06
Iter: 849 loss: 1.25822589e-06
Iter: 850 loss: 1.2570348e-06
Iter: 851 loss: 1.25679264e-06
Iter: 852 loss: 1.25619806e-06
Iter: 853 loss: 1.25442773e-06
Iter: 854 loss: 1.26815121e-06
Iter: 855 loss: 1.25442239e-06
Iter: 856 loss: 1.25342694e-06
Iter: 857 loss: 1.25524798e-06
Iter: 858 loss: 1.25303472e-06
Iter: 859 loss: 1.2517138e-06
Iter: 860 loss: 1.25221027e-06
Iter: 861 loss: 1.25075e-06
Iter: 862 loss: 1.24950839e-06
Iter: 863 loss: 1.25106021e-06
Iter: 864 loss: 1.24883718e-06
Iter: 865 loss: 1.247005e-06
Iter: 866 loss: 1.2545446e-06
Iter: 867 loss: 1.24663575e-06
Iter: 868 loss: 1.24533551e-06
Iter: 869 loss: 1.2463554e-06
Iter: 870 loss: 1.24465259e-06
Iter: 871 loss: 1.24330541e-06
Iter: 872 loss: 1.26063821e-06
Iter: 873 loss: 1.24324743e-06
Iter: 874 loss: 1.24250846e-06
Iter: 875 loss: 1.25125848e-06
Iter: 876 loss: 1.2424855e-06
Iter: 877 loss: 1.24192559e-06
Iter: 878 loss: 1.2411324e-06
Iter: 879 loss: 1.24110124e-06
Iter: 880 loss: 1.23989219e-06
Iter: 881 loss: 1.24173857e-06
Iter: 882 loss: 1.23936672e-06
Iter: 883 loss: 1.23826658e-06
Iter: 884 loss: 1.23820746e-06
Iter: 885 loss: 1.23747748e-06
Iter: 886 loss: 1.2356345e-06
Iter: 887 loss: 1.24475287e-06
Iter: 888 loss: 1.23540246e-06
Iter: 889 loss: 1.23429299e-06
Iter: 890 loss: 1.23663176e-06
Iter: 891 loss: 1.23381483e-06
Iter: 892 loss: 1.23240397e-06
Iter: 893 loss: 1.23494453e-06
Iter: 894 loss: 1.23178745e-06
Iter: 895 loss: 1.23061864e-06
Iter: 896 loss: 1.23141149e-06
Iter: 897 loss: 1.230007e-06
Iter: 898 loss: 1.22850383e-06
Iter: 899 loss: 1.23656332e-06
Iter: 900 loss: 1.22818778e-06
Iter: 901 loss: 1.2272601e-06
Iter: 902 loss: 1.22714221e-06
Iter: 903 loss: 1.22648476e-06
Iter: 904 loss: 1.22564234e-06
Iter: 905 loss: 1.22552467e-06
Iter: 906 loss: 1.22497306e-06
Iter: 907 loss: 1.22968299e-06
Iter: 908 loss: 1.22494703e-06
Iter: 909 loss: 1.22451684e-06
Iter: 910 loss: 1.22396705e-06
Iter: 911 loss: 1.22384756e-06
Iter: 912 loss: 1.22291704e-06
Iter: 913 loss: 1.22353867e-06
Iter: 914 loss: 1.22233484e-06
Iter: 915 loss: 1.2214108e-06
Iter: 916 loss: 1.22104109e-06
Iter: 917 loss: 1.22049823e-06
Iter: 918 loss: 1.21897972e-06
Iter: 919 loss: 1.22921119e-06
Iter: 920 loss: 1.21880441e-06
Iter: 921 loss: 1.21792971e-06
Iter: 922 loss: 1.21809558e-06
Iter: 923 loss: 1.21723065e-06
Iter: 924 loss: 1.21564483e-06
Iter: 925 loss: 1.22310485e-06
Iter: 926 loss: 1.2152932e-06
Iter: 927 loss: 1.2143239e-06
Iter: 928 loss: 1.21529547e-06
Iter: 929 loss: 1.21381572e-06
Iter: 930 loss: 1.21244466e-06
Iter: 931 loss: 1.2149145e-06
Iter: 932 loss: 1.21176458e-06
Iter: 933 loss: 1.21055109e-06
Iter: 934 loss: 1.2105977e-06
Iter: 935 loss: 1.20960226e-06
Iter: 936 loss: 1.20847324e-06
Iter: 937 loss: 1.20842333e-06
Iter: 938 loss: 1.207786e-06
Iter: 939 loss: 1.21520293e-06
Iter: 940 loss: 1.20782374e-06
Iter: 941 loss: 1.20722177e-06
Iter: 942 loss: 1.20639811e-06
Iter: 943 loss: 1.20632876e-06
Iter: 944 loss: 1.20509389e-06
Iter: 945 loss: 1.20700611e-06
Iter: 946 loss: 1.20443269e-06
Iter: 947 loss: 1.20352161e-06
Iter: 948 loss: 1.20399602e-06
Iter: 949 loss: 1.20283016e-06
Iter: 950 loss: 1.20167647e-06
Iter: 951 loss: 1.2094722e-06
Iter: 952 loss: 1.20157858e-06
Iter: 953 loss: 1.20061941e-06
Iter: 954 loss: 1.20027312e-06
Iter: 955 loss: 1.19984043e-06
Iter: 956 loss: 1.1983318e-06
Iter: 957 loss: 1.20932418e-06
Iter: 958 loss: 1.19826677e-06
Iter: 959 loss: 1.19743993e-06
Iter: 960 loss: 1.19776666e-06
Iter: 961 loss: 1.19690139e-06
Iter: 962 loss: 1.19539447e-06
Iter: 963 loss: 1.19706692e-06
Iter: 964 loss: 1.19468473e-06
Iter: 965 loss: 1.1935515e-06
Iter: 966 loss: 1.19441961e-06
Iter: 967 loss: 1.19287677e-06
Iter: 968 loss: 1.19170693e-06
Iter: 969 loss: 1.20902951e-06
Iter: 970 loss: 1.19166668e-06
Iter: 971 loss: 1.1910264e-06
Iter: 972 loss: 1.19102901e-06
Iter: 973 loss: 1.19049196e-06
Iter: 974 loss: 1.1896941e-06
Iter: 975 loss: 1.18968569e-06
Iter: 976 loss: 1.18859748e-06
Iter: 977 loss: 1.19153538e-06
Iter: 978 loss: 1.18828325e-06
Iter: 979 loss: 1.18753223e-06
Iter: 980 loss: 1.18729326e-06
Iter: 981 loss: 1.18690139e-06
Iter: 982 loss: 1.18567766e-06
Iter: 983 loss: 1.1923e-06
Iter: 984 loss: 1.18559035e-06
Iter: 985 loss: 1.1847485e-06
Iter: 986 loss: 1.18472417e-06
Iter: 987 loss: 1.1840591e-06
Iter: 988 loss: 1.18280991e-06
Iter: 989 loss: 1.19145227e-06
Iter: 990 loss: 1.1826636e-06
Iter: 991 loss: 1.18176e-06
Iter: 992 loss: 1.18252365e-06
Iter: 993 loss: 1.18127559e-06
Iter: 994 loss: 1.1799691e-06
Iter: 995 loss: 1.1812142e-06
Iter: 996 loss: 1.17919831e-06
Iter: 997 loss: 1.17821639e-06
Iter: 998 loss: 1.1798686e-06
Iter: 999 loss: 1.17769923e-06
Iter: 1000 loss: 1.17635045e-06
Iter: 1001 loss: 1.18519176e-06
Iter: 1002 loss: 1.17617151e-06
Iter: 1003 loss: 1.17566287e-06
Iter: 1004 loss: 1.17565457e-06
Iter: 1005 loss: 1.17500474e-06
Iter: 1006 loss: 1.17467846e-06
Iter: 1007 loss: 1.1744421e-06
Iter: 1008 loss: 1.17358661e-06
Iter: 1009 loss: 1.17620925e-06
Iter: 1010 loss: 1.1733332e-06
Iter: 1011 loss: 1.17282116e-06
Iter: 1012 loss: 1.17232753e-06
Iter: 1013 loss: 1.17225363e-06
Iter: 1014 loss: 1.17126388e-06
Iter: 1015 loss: 1.1775262e-06
Iter: 1016 loss: 1.17117838e-06
Iter: 1017 loss: 1.17053298e-06
Iter: 1018 loss: 1.16973615e-06
Iter: 1019 loss: 1.16962929e-06
Iter: 1020 loss: 1.1686592e-06
Iter: 1021 loss: 1.18350067e-06
Iter: 1022 loss: 1.16862452e-06
Iter: 1023 loss: 1.16795172e-06
Iter: 1024 loss: 1.16806393e-06
Iter: 1025 loss: 1.1675329e-06
Iter: 1026 loss: 1.16652268e-06
Iter: 1027 loss: 1.17097818e-06
Iter: 1028 loss: 1.16626188e-06
Iter: 1029 loss: 1.16553758e-06
Iter: 1030 loss: 1.16527042e-06
Iter: 1031 loss: 1.16494539e-06
Iter: 1032 loss: 1.16385627e-06
Iter: 1033 loss: 1.17260879e-06
Iter: 1034 loss: 1.16374576e-06
Iter: 1035 loss: 1.16310207e-06
Iter: 1036 loss: 1.17065804e-06
Iter: 1037 loss: 1.16314402e-06
Iter: 1038 loss: 1.16235583e-06
Iter: 1039 loss: 1.16257024e-06
Iter: 1040 loss: 1.16194292e-06
Iter: 1041 loss: 1.16126625e-06
Iter: 1042 loss: 1.16259707e-06
Iter: 1043 loss: 1.16097692e-06
Iter: 1044 loss: 1.16031879e-06
Iter: 1045 loss: 1.15942294e-06
Iter: 1046 loss: 1.15944624e-06
Iter: 1047 loss: 1.15808075e-06
Iter: 1048 loss: 1.16954038e-06
Iter: 1049 loss: 1.15809667e-06
Iter: 1050 loss: 1.15718126e-06
Iter: 1051 loss: 1.15622368e-06
Iter: 1052 loss: 1.15594889e-06
Iter: 1053 loss: 1.15449109e-06
Iter: 1054 loss: 1.17014827e-06
Iter: 1055 loss: 1.15442697e-06
Iter: 1056 loss: 1.15357398e-06
Iter: 1057 loss: 1.15359398e-06
Iter: 1058 loss: 1.15285798e-06
Iter: 1059 loss: 1.15140915e-06
Iter: 1060 loss: 1.15694854e-06
Iter: 1061 loss: 1.15107446e-06
Iter: 1062 loss: 1.15003377e-06
Iter: 1063 loss: 1.14948296e-06
Iter: 1064 loss: 1.14909437e-06
Iter: 1065 loss: 1.14779516e-06
Iter: 1066 loss: 1.16266756e-06
Iter: 1067 loss: 1.14767545e-06
Iter: 1068 loss: 1.14682621e-06
Iter: 1069 loss: 1.14686043e-06
Iter: 1070 loss: 1.1462248e-06
Iter: 1071 loss: 1.14580416e-06
Iter: 1072 loss: 1.14537374e-06
Iter: 1073 loss: 1.14499585e-06
Iter: 1074 loss: 1.14471027e-06
Iter: 1075 loss: 1.1445552e-06
Iter: 1076 loss: 1.14399609e-06
Iter: 1077 loss: 1.14311024e-06
Iter: 1078 loss: 1.14308284e-06
Iter: 1079 loss: 1.14164186e-06
Iter: 1080 loss: 1.14839759e-06
Iter: 1081 loss: 1.14154329e-06
Iter: 1082 loss: 1.1403331e-06
Iter: 1083 loss: 1.1397608e-06
Iter: 1084 loss: 1.13926149e-06
Iter: 1085 loss: 1.13807846e-06
Iter: 1086 loss: 1.13805231e-06
Iter: 1087 loss: 1.13728902e-06
Iter: 1088 loss: 1.13707165e-06
Iter: 1089 loss: 1.13661361e-06
Iter: 1090 loss: 1.13542546e-06
Iter: 1091 loss: 1.14201055e-06
Iter: 1092 loss: 1.13526812e-06
Iter: 1093 loss: 1.13445799e-06
Iter: 1094 loss: 1.13444412e-06
Iter: 1095 loss: 1.13379065e-06
Iter: 1096 loss: 1.13272336e-06
Iter: 1097 loss: 1.14355748e-06
Iter: 1098 loss: 1.13264718e-06
Iter: 1099 loss: 1.1320783e-06
Iter: 1100 loss: 1.1304644e-06
Iter: 1101 loss: 1.15335024e-06
Iter: 1102 loss: 1.13043779e-06
Iter: 1103 loss: 1.13257124e-06
Iter: 1104 loss: 1.13006342e-06
Iter: 1105 loss: 1.12980285e-06
Iter: 1106 loss: 1.12964574e-06
Iter: 1107 loss: 1.12962243e-06
Iter: 1108 loss: 1.12923271e-06
Iter: 1109 loss: 1.12851933e-06
Iter: 1110 loss: 1.14417639e-06
Iter: 1111 loss: 1.12857356e-06
Iter: 1112 loss: 1.12784926e-06
Iter: 1113 loss: 1.13825809e-06
Iter: 1114 loss: 1.12780799e-06
Iter: 1115 loss: 1.12745556e-06
Iter: 1116 loss: 1.12753924e-06
Iter: 1117 loss: 1.12717282e-06
Iter: 1118 loss: 1.12663656e-06
Iter: 1119 loss: 1.12746511e-06
Iter: 1120 loss: 1.12647353e-06
Iter: 1121 loss: 1.12582393e-06
Iter: 1122 loss: 1.1254117e-06
Iter: 1123 loss: 1.12527027e-06
Iter: 1124 loss: 1.12469388e-06
Iter: 1125 loss: 1.12469115e-06
Iter: 1126 loss: 1.1242214e-06
Iter: 1127 loss: 1.12403086e-06
Iter: 1128 loss: 1.12371958e-06
Iter: 1129 loss: 1.12311227e-06
Iter: 1130 loss: 1.12639418e-06
Iter: 1131 loss: 1.12301905e-06
Iter: 1132 loss: 1.12235512e-06
Iter: 1133 loss: 1.12268754e-06
Iter: 1134 loss: 1.12178532e-06
Iter: 1135 loss: 1.12183295e-06
Iter: 1136 loss: 1.1215825e-06
Iter: 1137 loss: 1.12132329e-06
Iter: 1138 loss: 1.12099428e-06
Iter: 1139 loss: 1.12100724e-06
Iter: 1140 loss: 1.12046109e-06
Iter: 1141 loss: 1.11884788e-06
Iter: 1142 loss: 1.12783891e-06
Iter: 1143 loss: 1.11827455e-06
Iter: 1144 loss: 1.11737836e-06
Iter: 1145 loss: 1.11730571e-06
Iter: 1146 loss: 1.11646477e-06
Iter: 1147 loss: 1.11643885e-06
Iter: 1148 loss: 1.11581642e-06
Iter: 1149 loss: 1.11530653e-06
Iter: 1150 loss: 1.11530619e-06
Iter: 1151 loss: 1.1149325e-06
Iter: 1152 loss: 1.11386419e-06
Iter: 1153 loss: 1.12380428e-06
Iter: 1154 loss: 1.11374891e-06
Iter: 1155 loss: 1.11288432e-06
Iter: 1156 loss: 1.11287272e-06
Iter: 1157 loss: 1.11201473e-06
Iter: 1158 loss: 1.11082613e-06
Iter: 1159 loss: 1.11071802e-06
Iter: 1160 loss: 1.10963879e-06
Iter: 1161 loss: 1.12346925e-06
Iter: 1162 loss: 1.10963174e-06
Iter: 1163 loss: 1.10879284e-06
Iter: 1164 loss: 1.11300801e-06
Iter: 1165 loss: 1.10865074e-06
Iter: 1166 loss: 1.10823203e-06
Iter: 1167 loss: 1.11047939e-06
Iter: 1168 loss: 1.10807207e-06
Iter: 1169 loss: 1.10767417e-06
Iter: 1170 loss: 1.10769702e-06
Iter: 1171 loss: 1.10730809e-06
Iter: 1172 loss: 1.10634619e-06
Iter: 1173 loss: 1.11360373e-06
Iter: 1174 loss: 1.10628343e-06
Iter: 1175 loss: 1.10554583e-06
Iter: 1176 loss: 1.10693338e-06
Iter: 1177 loss: 1.1052432e-06
Iter: 1178 loss: 1.10422934e-06
Iter: 1179 loss: 1.10534802e-06
Iter: 1180 loss: 1.10366454e-06
Iter: 1181 loss: 1.10259884e-06
Iter: 1182 loss: 1.10486565e-06
Iter: 1183 loss: 1.10210385e-06
Iter: 1184 loss: 1.10048779e-06
Iter: 1185 loss: 1.10560438e-06
Iter: 1186 loss: 1.10001406e-06
Iter: 1187 loss: 1.09942562e-06
Iter: 1188 loss: 1.1085383e-06
Iter: 1189 loss: 1.0993981e-06
Iter: 1190 loss: 1.09892494e-06
Iter: 1191 loss: 1.09796508e-06
Iter: 1192 loss: 1.0979694e-06
Iter: 1193 loss: 1.09712471e-06
Iter: 1194 loss: 1.10249982e-06
Iter: 1195 loss: 1.09700591e-06
Iter: 1196 loss: 1.0959219e-06
Iter: 1197 loss: 1.09620055e-06
Iter: 1198 loss: 1.0951901e-06
Iter: 1199 loss: 1.09454663e-06
Iter: 1200 loss: 1.09874554e-06
Iter: 1201 loss: 1.09451207e-06
Iter: 1202 loss: 1.09401174e-06
Iter: 1203 loss: 1.10127007e-06
Iter: 1204 loss: 1.09402754e-06
Iter: 1205 loss: 1.09347491e-06
Iter: 1206 loss: 1.09378084e-06
Iter: 1207 loss: 1.0931908e-06
Iter: 1208 loss: 1.09277494e-06
Iter: 1209 loss: 1.09198277e-06
Iter: 1210 loss: 1.10606766e-06
Iter: 1211 loss: 1.09194502e-06
Iter: 1212 loss: 1.09093253e-06
Iter: 1213 loss: 1.09794757e-06
Iter: 1214 loss: 1.09070038e-06
Iter: 1215 loss: 1.09016219e-06
Iter: 1216 loss: 1.08952509e-06
Iter: 1217 loss: 1.08946324e-06
Iter: 1218 loss: 1.08873814e-06
Iter: 1219 loss: 1.08872223e-06
Iter: 1220 loss: 1.08812378e-06
Iter: 1221 loss: 1.08775839e-06
Iter: 1222 loss: 1.08759218e-06
Iter: 1223 loss: 1.08693371e-06
Iter: 1224 loss: 1.08696872e-06
Iter: 1225 loss: 1.08645611e-06
Iter: 1226 loss: 1.08545873e-06
Iter: 1227 loss: 1.10071255e-06
Iter: 1228 loss: 1.08551262e-06
Iter: 1229 loss: 1.08470715e-06
Iter: 1230 loss: 1.08468976e-06
Iter: 1231 loss: 1.08419033e-06
Iter: 1232 loss: 1.08361269e-06
Iter: 1233 loss: 1.08357619e-06
Iter: 1234 loss: 1.08440656e-06
Iter: 1235 loss: 1.08322081e-06
Iter: 1236 loss: 1.08286554e-06
Iter: 1237 loss: 1.08392942e-06
Iter: 1238 loss: 1.08270342e-06
Iter: 1239 loss: 1.08240772e-06
Iter: 1240 loss: 1.08177881e-06
Iter: 1241 loss: 1.09089854e-06
Iter: 1242 loss: 1.08170877e-06
Iter: 1243 loss: 1.08100437e-06
Iter: 1244 loss: 1.08471193e-06
Iter: 1245 loss: 1.08085771e-06
Iter: 1246 loss: 1.08011523e-06
Iter: 1247 loss: 1.08064728e-06
Iter: 1248 loss: 1.07952019e-06
Iter: 1249 loss: 1.07893288e-06
Iter: 1250 loss: 1.08133429e-06
Iter: 1251 loss: 1.07874234e-06
Iter: 1252 loss: 1.07808637e-06
Iter: 1253 loss: 1.07919129e-06
Iter: 1254 loss: 1.07758115e-06
Iter: 1255 loss: 1.07713515e-06
Iter: 1256 loss: 1.07698509e-06
Iter: 1257 loss: 1.0766006e-06
Iter: 1258 loss: 1.07568405e-06
Iter: 1259 loss: 1.07566348e-06
Iter: 1260 loss: 1.07515052e-06
Iter: 1261 loss: 1.07565404e-06
Iter: 1262 loss: 1.07492883e-06
Iter: 1263 loss: 1.07430526e-06
Iter: 1264 loss: 1.0735705e-06
Iter: 1265 loss: 1.07347387e-06
Iter: 1266 loss: 1.07288065e-06
Iter: 1267 loss: 1.07436858e-06
Iter: 1268 loss: 1.07257847e-06
Iter: 1269 loss: 1.07203323e-06
Iter: 1270 loss: 1.07193409e-06
Iter: 1271 loss: 1.0715039e-06
Iter: 1272 loss: 1.07163498e-06
Iter: 1273 loss: 1.07112135e-06
Iter: 1274 loss: 1.07067228e-06
Iter: 1275 loss: 1.06971504e-06
Iter: 1276 loss: 1.08035101e-06
Iter: 1277 loss: 1.0695926e-06
Iter: 1278 loss: 1.06866491e-06
Iter: 1279 loss: 1.06868549e-06
Iter: 1280 loss: 1.06819141e-06
Iter: 1281 loss: 1.06762718e-06
Iter: 1282 loss: 1.06762809e-06
Iter: 1283 loss: 1.06694392e-06
Iter: 1284 loss: 1.07584458e-06
Iter: 1285 loss: 1.06684729e-06
Iter: 1286 loss: 1.06636946e-06
Iter: 1287 loss: 1.06566358e-06
Iter: 1288 loss: 1.06562243e-06
Iter: 1289 loss: 1.06479797e-06
Iter: 1290 loss: 1.07342555e-06
Iter: 1291 loss: 1.06483208e-06
Iter: 1292 loss: 1.06430275e-06
Iter: 1293 loss: 1.06436573e-06
Iter: 1294 loss: 1.06389246e-06
Iter: 1295 loss: 1.06319226e-06
Iter: 1296 loss: 1.06429343e-06
Iter: 1297 loss: 1.06292214e-06
Iter: 1298 loss: 1.0626527e-06
Iter: 1299 loss: 1.06278185e-06
Iter: 1300 loss: 1.06246273e-06
Iter: 1301 loss: 1.06199218e-06
Iter: 1302 loss: 1.06223388e-06
Iter: 1303 loss: 1.06168841e-06
Iter: 1304 loss: 1.06136019e-06
Iter: 1305 loss: 1.06140601e-06
Iter: 1306 loss: 1.06119319e-06
Iter: 1307 loss: 1.061087e-06
Iter: 1308 loss: 1.06094967e-06
Iter: 1309 loss: 1.0604715e-06
Iter: 1310 loss: 1.06031393e-06
Iter: 1311 loss: 1.05998913e-06
Iter: 1312 loss: 1.05942377e-06
Iter: 1313 loss: 1.0610031e-06
Iter: 1314 loss: 1.05920435e-06
Iter: 1315 loss: 1.05845891e-06
Iter: 1316 loss: 1.05912727e-06
Iter: 1317 loss: 1.05809488e-06
Iter: 1318 loss: 1.05736717e-06
Iter: 1319 loss: 1.0595661e-06
Iter: 1320 loss: 1.05712445e-06
Iter: 1321 loss: 1.05634172e-06
Iter: 1322 loss: 1.06165987e-06
Iter: 1323 loss: 1.05629169e-06
Iter: 1324 loss: 1.05587037e-06
Iter: 1325 loss: 1.05552419e-06
Iter: 1326 loss: 1.05544541e-06
Iter: 1327 loss: 1.05464255e-06
Iter: 1328 loss: 1.0622698e-06
Iter: 1329 loss: 1.05461709e-06
Iter: 1330 loss: 1.05428444e-06
Iter: 1331 loss: 1.05424499e-06
Iter: 1332 loss: 1.05407958e-06
Iter: 1333 loss: 1.05340177e-06
Iter: 1334 loss: 1.05718e-06
Iter: 1335 loss: 1.05329786e-06
Iter: 1336 loss: 1.05273148e-06
Iter: 1337 loss: 1.05271897e-06
Iter: 1338 loss: 1.05244044e-06
Iter: 1339 loss: 1.05369168e-06
Iter: 1340 loss: 1.05230822e-06
Iter: 1341 loss: 1.05199592e-06
Iter: 1342 loss: 1.0513686e-06
Iter: 1343 loss: 1.06314769e-06
Iter: 1344 loss: 1.05135518e-06
Iter: 1345 loss: 1.05064441e-06
Iter: 1346 loss: 1.05549316e-06
Iter: 1347 loss: 1.05057768e-06
Iter: 1348 loss: 1.05008644e-06
Iter: 1349 loss: 1.04940978e-06
Iter: 1350 loss: 1.04930109e-06
Iter: 1351 loss: 1.04868059e-06
Iter: 1352 loss: 1.04871742e-06
Iter: 1353 loss: 1.04816718e-06
Iter: 1354 loss: 1.04771175e-06
Iter: 1355 loss: 1.04756566e-06
Iter: 1356 loss: 1.04713149e-06
Iter: 1357 loss: 1.05266668e-06
Iter: 1358 loss: 1.04713843e-06
Iter: 1359 loss: 1.04669061e-06
Iter: 1360 loss: 1.04585592e-06
Iter: 1361 loss: 1.06449443e-06
Iter: 1362 loss: 1.04587446e-06
Iter: 1363 loss: 1.04542596e-06
Iter: 1364 loss: 1.04539902e-06
Iter: 1365 loss: 1.04476862e-06
Iter: 1366 loss: 1.04647472e-06
Iter: 1367 loss: 1.04460128e-06
Iter: 1368 loss: 1.04429955e-06
Iter: 1369 loss: 1.04438163e-06
Iter: 1370 loss: 1.04393143e-06
Iter: 1371 loss: 1.04372384e-06
Iter: 1372 loss: 1.0432168e-06
Iter: 1373 loss: 1.04319565e-06
Iter: 1374 loss: 1.04248306e-06
Iter: 1375 loss: 1.04655919e-06
Iter: 1376 loss: 1.04240621e-06
Iter: 1377 loss: 1.04190838e-06
Iter: 1378 loss: 1.04221056e-06
Iter: 1379 loss: 1.04160335e-06
Iter: 1380 loss: 1.04088633e-06
Iter: 1381 loss: 1.04222579e-06
Iter: 1382 loss: 1.0405538e-06
Iter: 1383 loss: 1.04001731e-06
Iter: 1384 loss: 1.04103663e-06
Iter: 1385 loss: 1.03977163e-06
Iter: 1386 loss: 1.03903312e-06
Iter: 1387 loss: 1.04294804e-06
Iter: 1388 loss: 1.03891898e-06
Iter: 1389 loss: 1.03844945e-06
Iter: 1390 loss: 1.03810282e-06
Iter: 1391 loss: 1.03795651e-06
Iter: 1392 loss: 1.03718389e-06
Iter: 1393 loss: 1.04321907e-06
Iter: 1394 loss: 1.03719321e-06
Iter: 1395 loss: 1.03664684e-06
Iter: 1396 loss: 1.03647835e-06
Iter: 1397 loss: 1.03609568e-06
Iter: 1398 loss: 1.03561115e-06
Iter: 1399 loss: 1.03566583e-06
Iter: 1400 loss: 1.03548427e-06
Iter: 1401 loss: 1.03539355e-06
Iter: 1402 loss: 1.03529078e-06
Iter: 1403 loss: 1.03488856e-06
Iter: 1404 loss: 1.03485195e-06
Iter: 1405 loss: 1.03433899e-06
Iter: 1406 loss: 1.03362606e-06
Iter: 1407 loss: 1.04271226e-06
Iter: 1408 loss: 1.03363118e-06
Iter: 1409 loss: 1.03318189e-06
Iter: 1410 loss: 1.03308855e-06
Iter: 1411 loss: 1.03284128e-06
Iter: 1412 loss: 1.03238267e-06
Iter: 1413 loss: 1.03670436e-06
Iter: 1414 loss: 1.03236437e-06
Iter: 1415 loss: 1.03200705e-06
Iter: 1416 loss: 1.03218599e-06
Iter: 1417 loss: 1.03181526e-06
Iter: 1418 loss: 1.03118509e-06
Iter: 1419 loss: 1.03104185e-06
Iter: 1420 loss: 1.03072489e-06
Iter: 1421 loss: 1.03005323e-06
Iter: 1422 loss: 1.03078673e-06
Iter: 1423 loss: 1.02968147e-06
Iter: 1424 loss: 1.02911667e-06
Iter: 1425 loss: 1.0381915e-06
Iter: 1426 loss: 1.02902618e-06
Iter: 1427 loss: 1.0285554e-06
Iter: 1428 loss: 1.02816659e-06
Iter: 1429 loss: 1.02807758e-06
Iter: 1430 loss: 1.0276392e-06
Iter: 1431 loss: 1.03335242e-06
Iter: 1432 loss: 1.02761726e-06
Iter: 1433 loss: 1.02727677e-06
Iter: 1434 loss: 1.02676495e-06
Iter: 1435 loss: 1.02678041e-06
Iter: 1436 loss: 1.02665729e-06
Iter: 1437 loss: 1.02645095e-06
Iter: 1438 loss: 1.02616968e-06
Iter: 1439 loss: 1.0263891e-06
Iter: 1440 loss: 1.02603451e-06
Iter: 1441 loss: 1.02572335e-06
Iter: 1442 loss: 1.02490344e-06
Iter: 1443 loss: 1.03573086e-06
Iter: 1444 loss: 1.02491788e-06
Iter: 1445 loss: 1.02434774e-06
Iter: 1446 loss: 1.02810918e-06
Iter: 1447 loss: 1.02433501e-06
Iter: 1448 loss: 1.02365618e-06
Iter: 1449 loss: 1.02365095e-06
Iter: 1450 loss: 1.02310491e-06
Iter: 1451 loss: 1.02258264e-06
Iter: 1452 loss: 1.02453953e-06
Iter: 1453 loss: 1.02244121e-06
Iter: 1454 loss: 1.02163017e-06
Iter: 1455 loss: 1.02183151e-06
Iter: 1456 loss: 1.02114495e-06
Iter: 1457 loss: 1.02059664e-06
Iter: 1458 loss: 1.02392187e-06
Iter: 1459 loss: 1.02054321e-06
Iter: 1460 loss: 1.02001184e-06
Iter: 1461 loss: 1.02097442e-06
Iter: 1462 loss: 1.01971864e-06
Iter: 1463 loss: 1.01933665e-06
Iter: 1464 loss: 1.0210739e-06
Iter: 1465 loss: 1.01921682e-06
Iter: 1466 loss: 1.01875685e-06
Iter: 1467 loss: 1.01983483e-06
Iter: 1468 loss: 1.01849173e-06
Iter: 1469 loss: 1.01820319e-06
Iter: 1470 loss: 1.02235845e-06
Iter: 1471 loss: 1.01819546e-06
Iter: 1472 loss: 1.01795808e-06
Iter: 1473 loss: 1.01865885e-06
Iter: 1474 loss: 1.01785e-06
Iter: 1475 loss: 1.01752187e-06
Iter: 1476 loss: 1.01696469e-06
Iter: 1477 loss: 1.02869217e-06
Iter: 1478 loss: 1.01697196e-06
Iter: 1479 loss: 1.01647777e-06
Iter: 1480 loss: 1.02191166e-06
Iter: 1481 loss: 1.01648106e-06
Iter: 1482 loss: 1.01629826e-06
Iter: 1483 loss: 1.01587875e-06
Iter: 1484 loss: 1.01583214e-06
Iter: 1485 loss: 1.0153293e-06
Iter: 1486 loss: 1.01971636e-06
Iter: 1487 loss: 1.01532032e-06
Iter: 1488 loss: 1.01490832e-06
Iter: 1489 loss: 1.01488558e-06
Iter: 1490 loss: 1.01451133e-06
Iter: 1491 loss: 1.01412581e-06
Iter: 1492 loss: 1.01801663e-06
Iter: 1493 loss: 1.0140933e-06
Iter: 1494 loss: 1.01370961e-06
Iter: 1495 loss: 1.01328283e-06
Iter: 1496 loss: 1.01316107e-06
Iter: 1497 loss: 1.0127643e-06
Iter: 1498 loss: 1.01604121e-06
Iter: 1499 loss: 1.01267256e-06
Iter: 1500 loss: 1.01247929e-06
Iter: 1501 loss: 1.01242267e-06
Iter: 1502 loss: 1.0122244e-06
Iter: 1503 loss: 1.01183014e-06
Iter: 1504 loss: 1.0140817e-06
Iter: 1505 loss: 1.01183718e-06
Iter: 1506 loss: 1.01165017e-06
Iter: 1507 loss: 1.0116114e-06
Iter: 1508 loss: 1.01140722e-06
Iter: 1509 loss: 1.01130377e-06
Iter: 1510 loss: 1.0112135e-06
Iter: 1511 loss: 1.01102967e-06
Iter: 1512 loss: 1.01096373e-06
Iter: 1513 loss: 1.01084379e-06
Iter: 1514 loss: 1.01052046e-06
Iter: 1515 loss: 1.0105075e-06
Iter: 1516 loss: 1.01021101e-06
Iter: 1517 loss: 1.00996795e-06
Iter: 1518 loss: 1.01364822e-06
Iter: 1519 loss: 1.00992338e-06
Iter: 1520 loss: 1.0097217e-06
Iter: 1521 loss: 1.00947739e-06
Iter: 1522 loss: 1.00937177e-06
Iter: 1523 loss: 1.00899115e-06
Iter: 1524 loss: 1.0104859e-06
Iter: 1525 loss: 1.00888838e-06
Iter: 1526 loss: 1.00849832e-06
Iter: 1527 loss: 1.00927707e-06
Iter: 1528 loss: 1.00829607e-06
Iter: 1529 loss: 1.00802549e-06
Iter: 1530 loss: 1.01062153e-06
Iter: 1531 loss: 1.00801299e-06
Iter: 1532 loss: 1.00777834e-06
Iter: 1533 loss: 1.0076086e-06
Iter: 1534 loss: 1.00747161e-06
Iter: 1535 loss: 1.00712646e-06
Iter: 1536 loss: 1.00919021e-06
Iter: 1537 loss: 1.00704301e-06
Iter: 1538 loss: 1.00676539e-06
Iter: 1539 loss: 1.00867692e-06
Iter: 1540 loss: 1.00673014e-06
Iter: 1541 loss: 1.00643956e-06
Iter: 1542 loss: 1.00753709e-06
Iter: 1543 loss: 1.00639522e-06
Iter: 1544 loss: 1.0062862e-06
Iter: 1545 loss: 1.00590182e-06
Iter: 1546 loss: 1.0120043e-06
Iter: 1547 loss: 1.00593593e-06
Iter: 1548 loss: 1.00538182e-06
Iter: 1549 loss: 1.00615637e-06
Iter: 1550 loss: 1.005076e-06
Iter: 1551 loss: 1.00485056e-06
Iter: 1552 loss: 1.0055885e-06
Iter: 1553 loss: 1.0047105e-06
Iter: 1554 loss: 1.00419186e-06
Iter: 1555 loss: 1.00510124e-06
Iter: 1556 loss: 1.00398211e-06
Iter: 1557 loss: 1.0035385e-06
Iter: 1558 loss: 1.00455895e-06
Iter: 1559 loss: 1.00344255e-06
Iter: 1560 loss: 1.00302714e-06
Iter: 1561 loss: 1.00515513e-06
Iter: 1562 loss: 1.00302088e-06
Iter: 1563 loss: 1.00270404e-06
Iter: 1564 loss: 1.0029662e-06
Iter: 1565 loss: 1.00255295e-06
Iter: 1566 loss: 1.00213492e-06
Iter: 1567 loss: 1.00445311e-06
Iter: 1568 loss: 1.00210946e-06
Iter: 1569 loss: 1.00176453e-06
Iter: 1570 loss: 1.00226384e-06
Iter: 1571 loss: 1.0015824e-06
Iter: 1572 loss: 1.00126294e-06
Iter: 1573 loss: 1.00331715e-06
Iter: 1574 loss: 1.00121292e-06
Iter: 1575 loss: 1.00093177e-06
Iter: 1576 loss: 1.00418981e-06
Iter: 1577 loss: 1.00098714e-06
Iter: 1578 loss: 1.0008057e-06
Iter: 1579 loss: 1.00045395e-06
Iter: 1580 loss: 1.0030991e-06
Iter: 1581 loss: 1.00048908e-06
Iter: 1582 loss: 1.00004218e-06
Iter: 1583 loss: 1.00250361e-06
Iter: 1584 loss: 1.00004547e-06
Iter: 1585 loss: 9.99688609e-07
Iter: 1586 loss: 9.99648478e-07
Iter: 1587 loss: 9.99423719e-07
Iter: 1588 loss: 9.99057875e-07
Iter: 1589 loss: 1.00309785e-06
Iter: 1590 loss: 9.99045824e-07
Iter: 1591 loss: 9.98826636e-07
Iter: 1592 loss: 9.98393261e-07
Iter: 1593 loss: 9.98378255e-07
Iter: 1594 loss: 9.9804322e-07
Iter: 1595 loss: 1.00392867e-06
Iter: 1596 loss: 9.97972847e-07
Iter: 1597 loss: 9.97834832e-07
Iter: 1598 loss: 9.97427719e-07
Iter: 1599 loss: 1.0068668e-06
Iter: 1600 loss: 9.97407369e-07
Iter: 1601 loss: 9.97025495e-07
Iter: 1602 loss: 1.00128375e-06
Iter: 1603 loss: 9.97029701e-07
Iter: 1604 loss: 9.96725362e-07
Iter: 1605 loss: 9.97770599e-07
Iter: 1606 loss: 9.96631343e-07
Iter: 1607 loss: 9.96385211e-07
Iter: 1608 loss: 9.97530719e-07
Iter: 1609 loss: 9.9624458e-07
Iter: 1610 loss: 9.95899882e-07
Iter: 1611 loss: 9.95926825e-07
Iter: 1612 loss: 9.95826554e-07
Iter: 1613 loss: 9.95367145e-07
Iter: 1614 loss: 9.96356903e-07
Iter: 1615 loss: 9.95048595e-07
Iter: 1616 loss: 9.94613174e-07
Iter: 1617 loss: 1.00077227e-06
Iter: 1618 loss: 9.94603624e-07
Iter: 1619 loss: 9.94178436e-07
Iter: 1620 loss: 9.94423544e-07
Iter: 1621 loss: 9.938218e-07
Iter: 1622 loss: 9.93535878e-07
Iter: 1623 loss: 9.9493684e-07
Iter: 1624 loss: 9.93335789e-07
Iter: 1625 loss: 9.92832156e-07
Iter: 1626 loss: 9.93289632e-07
Iter: 1627 loss: 9.92512355e-07
Iter: 1628 loss: 9.92065907e-07
Iter: 1629 loss: 9.96834274e-07
Iter: 1630 loss: 9.92006e-07
Iter: 1631 loss: 9.91672664e-07
Iter: 1632 loss: 9.91123215e-07
Iter: 1633 loss: 1.0051649e-06
Iter: 1634 loss: 9.91161642e-07
Iter: 1635 loss: 9.90602189e-07
Iter: 1636 loss: 9.94619768e-07
Iter: 1637 loss: 9.90511353e-07
Iter: 1638 loss: 9.9006445e-07
Iter: 1639 loss: 9.92646619e-07
Iter: 1640 loss: 9.90036369e-07
Iter: 1641 loss: 9.89727596e-07
Iter: 1642 loss: 9.89896193e-07
Iter: 1643 loss: 9.8954456e-07
Iter: 1644 loss: 9.89237151e-07
Iter: 1645 loss: 9.92943569e-07
Iter: 1646 loss: 9.89284331e-07
Iter: 1647 loss: 9.89096407e-07
Iter: 1648 loss: 9.89060823e-07
Iter: 1649 loss: 9.88879492e-07
Iter: 1650 loss: 9.88682814e-07
Iter: 1651 loss: 9.88697e-07
Iter: 1652 loss: 9.88583452e-07
Iter: 1653 loss: 9.89024443e-07
Iter: 1654 loss: 9.88436568e-07
Iter: 1655 loss: 9.88370175e-07
Iter: 1656 loss: 9.87997851e-07
Iter: 1657 loss: 9.89062755e-07
Iter: 1658 loss: 9.8784426e-07
Iter: 1659 loss: 9.87413387e-07
Iter: 1660 loss: 9.93077492e-07
Iter: 1661 loss: 9.87385874e-07
Iter: 1662 loss: 9.86992e-07
Iter: 1663 loss: 9.87979e-07
Iter: 1664 loss: 9.86888836e-07
Iter: 1665 loss: 9.86479108e-07
Iter: 1666 loss: 9.88190777e-07
Iter: 1667 loss: 9.86398391e-07
Iter: 1668 loss: 9.86137138e-07
Iter: 1669 loss: 9.861119e-07
Iter: 1670 loss: 9.8589021e-07
Iter: 1671 loss: 9.85525844e-07
Iter: 1672 loss: 9.88381544e-07
Iter: 1673 loss: 9.85471388e-07
Iter: 1674 loss: 9.8524049e-07
Iter: 1675 loss: 9.84903e-07
Iter: 1676 loss: 9.8493183e-07
Iter: 1677 loss: 9.843817e-07
Iter: 1678 loss: 9.88525244e-07
Iter: 1679 loss: 9.84327471e-07
Iter: 1680 loss: 9.84073722e-07
Iter: 1681 loss: 9.84001417e-07
Iter: 1682 loss: 9.83781092e-07
Iter: 1683 loss: 9.83376822e-07
Iter: 1684 loss: 9.87561862e-07
Iter: 1685 loss: 9.83360678e-07
Iter: 1686 loss: 9.8304e-07
Iter: 1687 loss: 9.84613e-07
Iter: 1688 loss: 9.83137284e-07
Iter: 1689 loss: 9.82928441e-07
Iter: 1690 loss: 9.82395363e-07
Iter: 1691 loss: 9.85425118e-07
Iter: 1692 loss: 9.82202e-07
Iter: 1693 loss: 9.81666403e-07
Iter: 1694 loss: 9.88407237e-07
Iter: 1695 loss: 9.81663334e-07
Iter: 1696 loss: 9.81099447e-07
Iter: 1697 loss: 9.81273161e-07
Iter: 1698 loss: 9.80816139e-07
Iter: 1699 loss: 9.80322e-07
Iter: 1700 loss: 9.8596e-07
Iter: 1701 loss: 9.80262371e-07
Iter: 1702 loss: 9.79837e-07
Iter: 1703 loss: 9.79670858e-07
Iter: 1704 loss: 9.79446e-07
Iter: 1705 loss: 9.79011e-07
Iter: 1706 loss: 9.79026822e-07
Iter: 1707 loss: 9.78762159e-07
Iter: 1708 loss: 9.78488174e-07
Iter: 1709 loss: 9.78422122e-07
Iter: 1710 loss: 9.7796169e-07
Iter: 1711 loss: 9.81355811e-07
Iter: 1712 loss: 9.77912464e-07
Iter: 1713 loss: 9.77595732e-07
Iter: 1714 loss: 9.7794657e-07
Iter: 1715 loss: 9.77413379e-07
Iter: 1716 loss: 9.77181799e-07
Iter: 1717 loss: 9.77140189e-07
Iter: 1718 loss: 9.76996e-07
Iter: 1719 loss: 9.77154514e-07
Iter: 1720 loss: 9.76893e-07
Iter: 1721 loss: 9.76694309e-07
Iter: 1722 loss: 9.76136334e-07
Iter: 1723 loss: 9.85028464e-07
Iter: 1724 loss: 9.76074e-07
Iter: 1725 loss: 9.75640205e-07
Iter: 1726 loss: 9.79959e-07
Iter: 1727 loss: 9.75665671e-07
Iter: 1728 loss: 9.75405783e-07
Iter: 1729 loss: 9.75109288e-07
Iter: 1730 loss: 9.74979685e-07
Iter: 1731 loss: 9.7458e-07
Iter: 1732 loss: 9.78681783e-07
Iter: 1733 loss: 9.74553814e-07
Iter: 1734 loss: 9.74267891e-07
Iter: 1735 loss: 9.74253908e-07
Iter: 1736 loss: 9.73936267e-07
Iter: 1737 loss: 9.73582473e-07
Iter: 1738 loss: 9.76522415e-07
Iter: 1739 loss: 9.73575879e-07
Iter: 1740 loss: 9.7326415e-07
Iter: 1741 loss: 9.72915814e-07
Iter: 1742 loss: 9.72874e-07
Iter: 1743 loss: 9.72545081e-07
Iter: 1744 loss: 9.77366199e-07
Iter: 1745 loss: 9.72516546e-07
Iter: 1746 loss: 9.72221e-07
Iter: 1747 loss: 9.71943336e-07
Iter: 1748 loss: 9.71936174e-07
Iter: 1749 loss: 9.7167549e-07
Iter: 1750 loss: 9.71622399e-07
Iter: 1751 loss: 9.71480745e-07
Iter: 1752 loss: 9.71482677e-07
Iter: 1753 loss: 9.71440613e-07
Iter: 1754 loss: 9.71234613e-07
Iter: 1755 loss: 9.7157465e-07
Iter: 1756 loss: 9.71168333e-07
Iter: 1757 loss: 9.70887868e-07
Iter: 1758 loss: 9.71288273e-07
Iter: 1759 loss: 9.70799874e-07
Iter: 1760 loss: 9.70586484e-07
Iter: 1761 loss: 9.70355359e-07
Iter: 1762 loss: 9.70262249e-07
Iter: 1763 loss: 9.69920734e-07
Iter: 1764 loss: 9.72712314e-07
Iter: 1765 loss: 9.69903567e-07
Iter: 1766 loss: 9.69553e-07
Iter: 1767 loss: 9.6988731e-07
Iter: 1768 loss: 9.69327e-07
Iter: 1769 loss: 9.6893973e-07
Iter: 1770 loss: 9.71256782e-07
Iter: 1771 loss: 9.68888116e-07
Iter: 1772 loss: 9.68598215e-07
Iter: 1773 loss: 9.68666541e-07
Iter: 1774 loss: 9.68402446e-07
Iter: 1775 loss: 9.68203722e-07
Iter: 1776 loss: 9.71435725e-07
Iter: 1777 loss: 9.68178369e-07
Iter: 1778 loss: 9.67946789e-07
Iter: 1779 loss: 9.6753854e-07
Iter: 1780 loss: 9.78032858e-07
Iter: 1781 loss: 9.67492e-07
Iter: 1782 loss: 9.67456913e-07
Iter: 1783 loss: 9.67275923e-07
Iter: 1784 loss: 9.67115e-07
Iter: 1785 loss: 9.67368237e-07
Iter: 1786 loss: 9.67111646e-07
Iter: 1787 loss: 9.66912808e-07
Iter: 1788 loss: 9.66746256e-07
Iter: 1789 loss: 9.66666221e-07
Iter: 1790 loss: 9.66359835e-07
Iter: 1791 loss: 9.67743631e-07
Iter: 1792 loss: 9.66257062e-07
Iter: 1793 loss: 9.66073458e-07
Iter: 1794 loss: 9.66055836e-07
Iter: 1795 loss: 9.65920663e-07
Iter: 1796 loss: 9.65558e-07
Iter: 1797 loss: 9.66096195e-07
Iter: 1798 loss: 9.65321e-07
Iter: 1799 loss: 9.64882e-07
Iter: 1800 loss: 9.6578583e-07
Iter: 1801 loss: 9.64734454e-07
Iter: 1802 loss: 9.64215587e-07
Iter: 1803 loss: 9.66511152e-07
Iter: 1804 loss: 9.64149194e-07
Iter: 1805 loss: 9.63789489e-07
Iter: 1806 loss: 9.64218316e-07
Iter: 1807 loss: 9.63634193e-07
Iter: 1808 loss: 9.63219e-07
Iter: 1809 loss: 9.65502409e-07
Iter: 1810 loss: 9.63131924e-07
Iter: 1811 loss: 9.62908416e-07
Iter: 1812 loss: 9.62839522e-07
Iter: 1813 loss: 9.62672516e-07
Iter: 1814 loss: 9.62209356e-07
Iter: 1815 loss: 9.63955699e-07
Iter: 1816 loss: 9.62088393e-07
Iter: 1817 loss: 9.61899332e-07
Iter: 1818 loss: 9.65171466e-07
Iter: 1819 loss: 9.61880914e-07
Iter: 1820 loss: 9.61597607e-07
Iter: 1821 loss: 9.61446403e-07
Iter: 1822 loss: 9.61333171e-07
Iter: 1823 loss: 9.61036903e-07
Iter: 1824 loss: 9.62273475e-07
Iter: 1825 loss: 9.61027808e-07
Iter: 1826 loss: 9.60782e-07
Iter: 1827 loss: 9.60487114e-07
Iter: 1828 loss: 9.6052122e-07
Iter: 1829 loss: 9.60105581e-07
Iter: 1830 loss: 9.62334298e-07
Iter: 1831 loss: 9.60024408e-07
Iter: 1832 loss: 9.59688691e-07
Iter: 1833 loss: 9.59614226e-07
Iter: 1834 loss: 9.59452564e-07
Iter: 1835 loss: 9.58967121e-07
Iter: 1836 loss: 9.63491289e-07
Iter: 1837 loss: 9.5893256e-07
Iter: 1838 loss: 9.58687679e-07
Iter: 1839 loss: 9.58633791e-07
Iter: 1840 loss: 9.58440296e-07
Iter: 1841 loss: 9.58009537e-07
Iter: 1842 loss: 9.59481326e-07
Iter: 1843 loss: 9.57843667e-07
Iter: 1844 loss: 9.57443376e-07
Iter: 1845 loss: 9.57278417e-07
Iter: 1846 loss: 9.57028305e-07
Iter: 1847 loss: 9.56402914e-07
Iter: 1848 loss: 9.63963e-07
Iter: 1849 loss: 9.56441454e-07
Iter: 1850 loss: 9.56220333e-07
Iter: 1851 loss: 9.55910764e-07
Iter: 1852 loss: 9.55911e-07
Iter: 1853 loss: 9.56340159e-07
Iter: 1854 loss: 9.55767064e-07
Iter: 1855 loss: 9.55626092e-07
Iter: 1856 loss: 9.55678274e-07
Iter: 1857 loss: 9.55603127e-07
Iter: 1858 loss: 9.55445785e-07
Iter: 1859 loss: 9.55209771e-07
Iter: 1860 loss: 9.55184191e-07
Iter: 1861 loss: 9.54964321e-07
Iter: 1862 loss: 9.56610506e-07
Iter: 1863 loss: 9.54955453e-07
Iter: 1864 loss: 9.547025e-07
Iter: 1865 loss: 9.54443749e-07
Iter: 1866 loss: 9.5439475e-07
Iter: 1867 loss: 9.54023335e-07
Iter: 1868 loss: 9.60009743e-07
Iter: 1869 loss: 9.53992867e-07
Iter: 1870 loss: 9.53862354e-07
Iter: 1871 loss: 9.53365202e-07
Iter: 1872 loss: 9.59466092e-07
Iter: 1873 loss: 9.53354743e-07
Iter: 1874 loss: 9.52656706e-07
Iter: 1875 loss: 9.60219836e-07
Iter: 1876 loss: 9.52654318e-07
Iter: 1877 loss: 9.5236328e-07
Iter: 1878 loss: 9.52789151e-07
Iter: 1879 loss: 9.52271648e-07
Iter: 1880 loss: 9.52045752e-07
Iter: 1881 loss: 9.5190785e-07
Iter: 1882 loss: 9.51783591e-07
Iter: 1883 loss: 9.51564402e-07
Iter: 1884 loss: 9.51188667e-07
Iter: 1885 loss: 9.60661396e-07
Iter: 1886 loss: 9.51164566e-07
Iter: 1887 loss: 9.50839649e-07
Iter: 1888 loss: 9.50855e-07
Iter: 1889 loss: 9.50639048e-07
Iter: 1890 loss: 9.51272455e-07
Iter: 1891 loss: 9.50599883e-07
Iter: 1892 loss: 9.50324875e-07
Iter: 1893 loss: 9.50191918e-07
Iter: 1894 loss: 9.50099718e-07
Iter: 1895 loss: 9.49937373e-07
Iter: 1896 loss: 9.49940954e-07
Iter: 1897 loss: 9.49683908e-07
Iter: 1898 loss: 9.49389971e-07
Iter: 1899 loss: 9.51189577e-07
Iter: 1900 loss: 9.49295668e-07
Iter: 1901 loss: 9.4898121e-07
Iter: 1902 loss: 9.49249966e-07
Iter: 1903 loss: 9.48809884e-07
Iter: 1904 loss: 9.48378386e-07
Iter: 1905 loss: 9.49882917e-07
Iter: 1906 loss: 9.48242814e-07
Iter: 1907 loss: 9.48028458e-07
Iter: 1908 loss: 9.49537252e-07
Iter: 1909 loss: 9.48028799e-07
Iter: 1910 loss: 9.47696549e-07
Iter: 1911 loss: 9.4783752e-07
Iter: 1912 loss: 9.47481851e-07
Iter: 1913 loss: 9.47247372e-07
Iter: 1914 loss: 9.47203603e-07
Iter: 1915 loss: 9.47093895e-07
Iter: 1916 loss: 9.46793421e-07
Iter: 1917 loss: 9.46789896e-07
Iter: 1918 loss: 9.46530918e-07
Iter: 1919 loss: 9.48401748e-07
Iter: 1920 loss: 9.46398529e-07
Iter: 1921 loss: 9.46177693e-07
Iter: 1922 loss: 9.45727265e-07
Iter: 1923 loss: 9.56184067e-07
Iter: 1924 loss: 9.45712e-07
Iter: 1925 loss: 9.45336524e-07
Iter: 1926 loss: 9.45309182e-07
Iter: 1927 loss: 9.45052079e-07
Iter: 1928 loss: 9.47008516e-07
Iter: 1929 loss: 9.44974545e-07
Iter: 1930 loss: 9.44714543e-07
Iter: 1931 loss: 9.4466759e-07
Iter: 1932 loss: 9.44537874e-07
Iter: 1933 loss: 9.44376609e-07
Iter: 1934 loss: 9.44334147e-07
Iter: 1935 loss: 9.44179249e-07
Iter: 1936 loss: 9.43808459e-07
Iter: 1937 loss: 9.46383864e-07
Iter: 1938 loss: 9.43751729e-07
Iter: 1939 loss: 9.43607802e-07
Iter: 1940 loss: 9.44055046e-07
Iter: 1941 loss: 9.43596433e-07
Iter: 1942 loss: 9.43341433e-07
Iter: 1943 loss: 9.43071313e-07
Iter: 1944 loss: 9.42998952e-07
Iter: 1945 loss: 9.42822851e-07
Iter: 1946 loss: 9.42790564e-07
Iter: 1947 loss: 9.42571774e-07
Iter: 1948 loss: 9.42509871e-07
Iter: 1949 loss: 9.42380325e-07
Iter: 1950 loss: 9.41993562e-07
Iter: 1951 loss: 9.4194661e-07
Iter: 1952 loss: 9.41655912e-07
Iter: 1953 loss: 9.41307633e-07
Iter: 1954 loss: 9.4211174e-07
Iter: 1955 loss: 9.41170924e-07
Iter: 1956 loss: 9.40726181e-07
Iter: 1957 loss: 9.41874362e-07
Iter: 1958 loss: 9.40590269e-07
Iter: 1959 loss: 9.40218797e-07
Iter: 1960 loss: 9.41708265e-07
Iter: 1961 loss: 9.40175823e-07
Iter: 1962 loss: 9.39817483e-07
Iter: 1963 loss: 9.4441242e-07
Iter: 1964 loss: 9.39877509e-07
Iter: 1965 loss: 9.39707547e-07
Iter: 1966 loss: 9.39429128e-07
Iter: 1967 loss: 9.39431516e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3
+ date
Mon Oct 26 19:58:51 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 3 --phi 3 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f1_psi3_phi3_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8394e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f839a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f836bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8427048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8427950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f82d3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f82a78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f82f8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8279488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f823c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f81db9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f81fc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f81fc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8170400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f81b3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f81036a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f812b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f813a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f80f89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f80b6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f80b61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8052d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f80176a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29f8031620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e00b7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e00b7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e01227b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e009e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e009e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e009f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e0059268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f299478a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f299478a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29e00592f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29947649d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2994709048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.69660559e-05
Iter: 2 loss: 2.48865945e-05
Iter: 3 loss: 2.1330985e-05
Iter: 4 loss: 2.02314077e-05
Iter: 5 loss: 1.88995837e-05
Iter: 6 loss: 1.87718579e-05
Iter: 7 loss: 1.75113291e-05
Iter: 8 loss: 1.64590856e-05
Iter: 9 loss: 1.61009193e-05
Iter: 10 loss: 1.46503735e-05
Iter: 11 loss: 3.14025201e-05
Iter: 12 loss: 1.46268858e-05
Iter: 13 loss: 1.34514066e-05
Iter: 14 loss: 1.33151625e-05
Iter: 15 loss: 1.24680118e-05
Iter: 16 loss: 1.14982977e-05
Iter: 17 loss: 1.87300284e-05
Iter: 18 loss: 1.14210397e-05
Iter: 19 loss: 1.04238297e-05
Iter: 20 loss: 1.14217682e-05
Iter: 21 loss: 9.86196392e-06
Iter: 22 loss: 9.3587114e-06
Iter: 23 loss: 9.35741082e-06
Iter: 24 loss: 9.02220381e-06
Iter: 25 loss: 8.42739064e-06
Iter: 26 loss: 2.32135808e-05
Iter: 27 loss: 8.42744066e-06
Iter: 28 loss: 7.9321162e-06
Iter: 29 loss: 1.02670319e-05
Iter: 30 loss: 7.84167e-06
Iter: 31 loss: 7.59711838e-06
Iter: 32 loss: 7.34969626e-06
Iter: 33 loss: 7.3010051e-06
Iter: 34 loss: 6.95376548e-06
Iter: 35 loss: 6.94898154e-06
Iter: 36 loss: 6.79295044e-06
Iter: 37 loss: 6.68890107e-06
Iter: 38 loss: 6.63016635e-06
Iter: 39 loss: 6.36328559e-06
Iter: 40 loss: 6.18439663e-06
Iter: 41 loss: 6.08470145e-06
Iter: 42 loss: 5.80652659e-06
Iter: 43 loss: 8.82166387e-06
Iter: 44 loss: 5.79982907e-06
Iter: 45 loss: 5.56082705e-06
Iter: 46 loss: 5.72634281e-06
Iter: 47 loss: 5.41182862e-06
Iter: 48 loss: 5.2533569e-06
Iter: 49 loss: 7.42569409e-06
Iter: 50 loss: 5.2527339e-06
Iter: 51 loss: 5.11454073e-06
Iter: 52 loss: 4.92051367e-06
Iter: 53 loss: 4.91282117e-06
Iter: 54 loss: 4.78070069e-06
Iter: 55 loss: 4.77662388e-06
Iter: 56 loss: 4.65880748e-06
Iter: 57 loss: 4.54034307e-06
Iter: 58 loss: 4.516437e-06
Iter: 59 loss: 4.37076051e-06
Iter: 60 loss: 6.65220159e-06
Iter: 61 loss: 4.37081508e-06
Iter: 62 loss: 4.28671365e-06
Iter: 63 loss: 4.34850881e-06
Iter: 64 loss: 4.23502024e-06
Iter: 65 loss: 4.1364392e-06
Iter: 66 loss: 5.37798269e-06
Iter: 67 loss: 4.13557382e-06
Iter: 68 loss: 4.05652781e-06
Iter: 69 loss: 4.15510249e-06
Iter: 70 loss: 4.01531906e-06
Iter: 71 loss: 3.95507777e-06
Iter: 72 loss: 3.8570297e-06
Iter: 73 loss: 3.85644853e-06
Iter: 74 loss: 3.77526271e-06
Iter: 75 loss: 3.775388e-06
Iter: 76 loss: 3.7201105e-06
Iter: 77 loss: 3.63629988e-06
Iter: 78 loss: 3.63468234e-06
Iter: 79 loss: 3.55904967e-06
Iter: 80 loss: 3.55780321e-06
Iter: 81 loss: 3.50503251e-06
Iter: 82 loss: 3.44109799e-06
Iter: 83 loss: 3.43515399e-06
Iter: 84 loss: 3.35797495e-06
Iter: 85 loss: 4.58886689e-06
Iter: 86 loss: 3.35804089e-06
Iter: 87 loss: 3.31724959e-06
Iter: 88 loss: 3.25503925e-06
Iter: 89 loss: 3.25403971e-06
Iter: 90 loss: 3.16758724e-06
Iter: 91 loss: 4.08061533e-06
Iter: 92 loss: 3.16534715e-06
Iter: 93 loss: 3.12230941e-06
Iter: 94 loss: 3.21470702e-06
Iter: 95 loss: 3.10566e-06
Iter: 96 loss: 3.05666731e-06
Iter: 97 loss: 3.44452405e-06
Iter: 98 loss: 3.05339381e-06
Iter: 99 loss: 3.00909733e-06
Iter: 100 loss: 3.23239078e-06
Iter: 101 loss: 3.00167494e-06
Iter: 102 loss: 2.97912129e-06
Iter: 103 loss: 2.9477103e-06
Iter: 104 loss: 2.94638e-06
Iter: 105 loss: 2.90020057e-06
Iter: 106 loss: 2.98368832e-06
Iter: 107 loss: 2.88016599e-06
Iter: 108 loss: 2.83798545e-06
Iter: 109 loss: 2.81650136e-06
Iter: 110 loss: 2.79662618e-06
Iter: 111 loss: 2.7351482e-06
Iter: 112 loss: 3.5078217e-06
Iter: 113 loss: 2.73448086e-06
Iter: 114 loss: 2.70043392e-06
Iter: 115 loss: 2.70260671e-06
Iter: 116 loss: 2.67357291e-06
Iter: 117 loss: 2.62667322e-06
Iter: 118 loss: 3.08626318e-06
Iter: 119 loss: 2.62530375e-06
Iter: 120 loss: 2.60160755e-06
Iter: 121 loss: 2.5989209e-06
Iter: 122 loss: 2.58171417e-06
Iter: 123 loss: 2.53741769e-06
Iter: 124 loss: 2.63320362e-06
Iter: 125 loss: 2.51991378e-06
Iter: 126 loss: 2.49037453e-06
Iter: 127 loss: 2.64370715e-06
Iter: 128 loss: 2.48557558e-06
Iter: 129 loss: 2.45023443e-06
Iter: 130 loss: 2.46056243e-06
Iter: 131 loss: 2.42500118e-06
Iter: 132 loss: 2.42634405e-06
Iter: 133 loss: 2.41155203e-06
Iter: 134 loss: 2.39923611e-06
Iter: 135 loss: 2.3849957e-06
Iter: 136 loss: 2.38334974e-06
Iter: 137 loss: 2.36099504e-06
Iter: 138 loss: 2.35992457e-06
Iter: 139 loss: 2.34264098e-06
Iter: 140 loss: 2.32061689e-06
Iter: 141 loss: 2.33153014e-06
Iter: 142 loss: 2.30585192e-06
Iter: 143 loss: 2.27213e-06
Iter: 144 loss: 2.43366185e-06
Iter: 145 loss: 2.26642578e-06
Iter: 146 loss: 2.24277278e-06
Iter: 147 loss: 2.21666824e-06
Iter: 148 loss: 2.21306163e-06
Iter: 149 loss: 2.19349636e-06
Iter: 150 loss: 2.18944342e-06
Iter: 151 loss: 2.17391334e-06
Iter: 152 loss: 2.15264072e-06
Iter: 153 loss: 2.1516455e-06
Iter: 154 loss: 2.11985434e-06
Iter: 155 loss: 2.39935e-06
Iter: 156 loss: 2.11816905e-06
Iter: 157 loss: 2.10427561e-06
Iter: 158 loss: 2.09529117e-06
Iter: 159 loss: 2.08985421e-06
Iter: 160 loss: 2.06350546e-06
Iter: 161 loss: 2.22912013e-06
Iter: 162 loss: 2.06045115e-06
Iter: 163 loss: 2.04589492e-06
Iter: 164 loss: 2.06343066e-06
Iter: 165 loss: 2.03834293e-06
Iter: 166 loss: 2.01834018e-06
Iter: 167 loss: 2.1371543e-06
Iter: 168 loss: 2.01585954e-06
Iter: 169 loss: 2.00032605e-06
Iter: 170 loss: 2.21519e-06
Iter: 171 loss: 2.0002451e-06
Iter: 172 loss: 1.9933e-06
Iter: 173 loss: 1.97426152e-06
Iter: 174 loss: 2.09474274e-06
Iter: 175 loss: 1.96948713e-06
Iter: 176 loss: 1.95167058e-06
Iter: 177 loss: 2.20764309e-06
Iter: 178 loss: 1.95164466e-06
Iter: 179 loss: 1.94108748e-06
Iter: 180 loss: 1.92392963e-06
Iter: 181 loss: 1.92379753e-06
Iter: 182 loss: 1.90687251e-06
Iter: 183 loss: 1.90678861e-06
Iter: 184 loss: 1.89824107e-06
Iter: 185 loss: 1.88260685e-06
Iter: 186 loss: 2.2500617e-06
Iter: 187 loss: 1.88266256e-06
Iter: 188 loss: 1.86884552e-06
Iter: 189 loss: 1.86826696e-06
Iter: 190 loss: 1.8586129e-06
Iter: 191 loss: 1.8500325e-06
Iter: 192 loss: 1.84749604e-06
Iter: 193 loss: 1.82976532e-06
Iter: 194 loss: 1.95556458e-06
Iter: 195 loss: 1.82824078e-06
Iter: 196 loss: 1.81715359e-06
Iter: 197 loss: 1.81776568e-06
Iter: 198 loss: 1.80865322e-06
Iter: 199 loss: 1.79440588e-06
Iter: 200 loss: 1.92696552e-06
Iter: 201 loss: 1.79381891e-06
Iter: 202 loss: 1.79098606e-06
Iter: 203 loss: 1.7887495e-06
Iter: 204 loss: 1.78492292e-06
Iter: 205 loss: 1.77422964e-06
Iter: 206 loss: 1.82935128e-06
Iter: 207 loss: 1.77061702e-06
Iter: 208 loss: 1.75771947e-06
Iter: 209 loss: 1.80847314e-06
Iter: 210 loss: 1.75470916e-06
Iter: 211 loss: 1.74085085e-06
Iter: 212 loss: 1.73028752e-06
Iter: 213 loss: 1.72574e-06
Iter: 214 loss: 1.71562522e-06
Iter: 215 loss: 1.7144024e-06
Iter: 216 loss: 1.70633621e-06
Iter: 217 loss: 1.6879294e-06
Iter: 218 loss: 1.92423408e-06
Iter: 219 loss: 1.68665497e-06
Iter: 220 loss: 1.67689825e-06
Iter: 221 loss: 1.67563417e-06
Iter: 222 loss: 1.66618645e-06
Iter: 223 loss: 1.66118696e-06
Iter: 224 loss: 1.65701795e-06
Iter: 225 loss: 1.64538665e-06
Iter: 226 loss: 1.76189326e-06
Iter: 227 loss: 1.6450465e-06
Iter: 228 loss: 1.6367311e-06
Iter: 229 loss: 1.62694391e-06
Iter: 230 loss: 1.62590879e-06
Iter: 231 loss: 1.6153416e-06
Iter: 232 loss: 1.74028503e-06
Iter: 233 loss: 1.61520791e-06
Iter: 234 loss: 1.60663012e-06
Iter: 235 loss: 1.60574746e-06
Iter: 236 loss: 1.59943806e-06
Iter: 237 loss: 1.60086267e-06
Iter: 238 loss: 1.59397473e-06
Iter: 239 loss: 1.5918406e-06
Iter: 240 loss: 1.58530565e-06
Iter: 241 loss: 1.60418062e-06
Iter: 242 loss: 1.58200555e-06
Iter: 243 loss: 1.57134559e-06
Iter: 244 loss: 1.63931202e-06
Iter: 245 loss: 1.57004877e-06
Iter: 246 loss: 1.56333522e-06
Iter: 247 loss: 1.57876423e-06
Iter: 248 loss: 1.5607452e-06
Iter: 249 loss: 1.55234443e-06
Iter: 250 loss: 1.55987914e-06
Iter: 251 loss: 1.54740746e-06
Iter: 252 loss: 1.54072836e-06
Iter: 253 loss: 1.57981458e-06
Iter: 254 loss: 1.53968779e-06
Iter: 255 loss: 1.53224801e-06
Iter: 256 loss: 1.53527412e-06
Iter: 257 loss: 1.5269452e-06
Iter: 258 loss: 1.51989286e-06
Iter: 259 loss: 1.60213358e-06
Iter: 260 loss: 1.51993459e-06
Iter: 261 loss: 1.51409654e-06
Iter: 262 loss: 1.50922835e-06
Iter: 263 loss: 1.50757273e-06
Iter: 264 loss: 1.50063704e-06
Iter: 265 loss: 1.58658258e-06
Iter: 266 loss: 1.50053734e-06
Iter: 267 loss: 1.49509924e-06
Iter: 268 loss: 1.48984145e-06
Iter: 269 loss: 1.4886599e-06
Iter: 270 loss: 1.48908794e-06
Iter: 271 loss: 1.48493473e-06
Iter: 272 loss: 1.48183437e-06
Iter: 273 loss: 1.47652827e-06
Iter: 274 loss: 1.47660478e-06
Iter: 275 loss: 1.46984871e-06
Iter: 276 loss: 1.46844286e-06
Iter: 277 loss: 1.46397906e-06
Iter: 278 loss: 1.45690581e-06
Iter: 279 loss: 1.46163666e-06
Iter: 280 loss: 1.45238096e-06
Iter: 281 loss: 1.44247156e-06
Iter: 282 loss: 1.52473513e-06
Iter: 283 loss: 1.44186788e-06
Iter: 284 loss: 1.43660668e-06
Iter: 285 loss: 1.44291141e-06
Iter: 286 loss: 1.43384943e-06
Iter: 287 loss: 1.42546571e-06
Iter: 288 loss: 1.43432885e-06
Iter: 289 loss: 1.42088629e-06
Iter: 290 loss: 1.41490125e-06
Iter: 291 loss: 1.44217347e-06
Iter: 292 loss: 1.41378018e-06
Iter: 293 loss: 1.40672523e-06
Iter: 294 loss: 1.42015801e-06
Iter: 295 loss: 1.40388511e-06
Iter: 296 loss: 1.39824283e-06
Iter: 297 loss: 1.43925422e-06
Iter: 298 loss: 1.39769213e-06
Iter: 299 loss: 1.39253962e-06
Iter: 300 loss: 1.38866289e-06
Iter: 301 loss: 1.38688893e-06
Iter: 302 loss: 1.38623955e-06
Iter: 303 loss: 1.38413338e-06
Iter: 304 loss: 1.38100199e-06
Iter: 305 loss: 1.37688448e-06
Iter: 306 loss: 1.37671236e-06
Iter: 307 loss: 1.37090285e-06
Iter: 308 loss: 1.37446796e-06
Iter: 309 loss: 1.36735866e-06
Iter: 310 loss: 1.36250708e-06
Iter: 311 loss: 1.36232939e-06
Iter: 312 loss: 1.3585576e-06
Iter: 313 loss: 1.35291725e-06
Iter: 314 loss: 1.43606189e-06
Iter: 315 loss: 1.35296045e-06
Iter: 316 loss: 1.34926086e-06
Iter: 317 loss: 1.34582831e-06
Iter: 318 loss: 1.34499032e-06
Iter: 319 loss: 1.33844605e-06
Iter: 320 loss: 1.3890633e-06
Iter: 321 loss: 1.33808646e-06
Iter: 322 loss: 1.33451294e-06
Iter: 323 loss: 1.33069966e-06
Iter: 324 loss: 1.33007393e-06
Iter: 325 loss: 1.32255377e-06
Iter: 326 loss: 1.37626353e-06
Iter: 327 loss: 1.32185733e-06
Iter: 328 loss: 1.31771958e-06
Iter: 329 loss: 1.32601747e-06
Iter: 330 loss: 1.31595675e-06
Iter: 331 loss: 1.31048887e-06
Iter: 332 loss: 1.32407285e-06
Iter: 333 loss: 1.30855142e-06
Iter: 334 loss: 1.30462718e-06
Iter: 335 loss: 1.32239859e-06
Iter: 336 loss: 1.30392368e-06
Iter: 337 loss: 1.30020805e-06
Iter: 338 loss: 1.34298614e-06
Iter: 339 loss: 1.30019862e-06
Iter: 340 loss: 1.29692421e-06
Iter: 341 loss: 1.29409921e-06
Iter: 342 loss: 1.2933026e-06
Iter: 343 loss: 1.29053956e-06
Iter: 344 loss: 1.28425972e-06
Iter: 345 loss: 1.36839913e-06
Iter: 346 loss: 1.28382067e-06
Iter: 347 loss: 1.27970134e-06
Iter: 348 loss: 1.27929877e-06
Iter: 349 loss: 1.27556291e-06
Iter: 350 loss: 1.2722312e-06
Iter: 351 loss: 1.27130465e-06
Iter: 352 loss: 1.26566351e-06
Iter: 353 loss: 1.32524053e-06
Iter: 354 loss: 1.26548093e-06
Iter: 355 loss: 1.26200234e-06
Iter: 356 loss: 1.2586919e-06
Iter: 357 loss: 1.25792712e-06
Iter: 358 loss: 1.25290774e-06
Iter: 359 loss: 1.31134925e-06
Iter: 360 loss: 1.25269514e-06
Iter: 361 loss: 1.24932023e-06
Iter: 362 loss: 1.24578025e-06
Iter: 363 loss: 1.24512746e-06
Iter: 364 loss: 1.24092298e-06
Iter: 365 loss: 1.24081384e-06
Iter: 366 loss: 1.23766654e-06
Iter: 367 loss: 1.2478439e-06
Iter: 368 loss: 1.23670304e-06
Iter: 369 loss: 1.23403152e-06
Iter: 370 loss: 1.27162e-06
Iter: 371 loss: 1.23400298e-06
Iter: 372 loss: 1.23133304e-06
Iter: 373 loss: 1.23403629e-06
Iter: 374 loss: 1.22973938e-06
Iter: 375 loss: 1.22752317e-06
Iter: 376 loss: 1.22264237e-06
Iter: 377 loss: 1.30224726e-06
Iter: 378 loss: 1.22245319e-06
Iter: 379 loss: 1.21807329e-06
Iter: 380 loss: 1.27149769e-06
Iter: 381 loss: 1.21804658e-06
Iter: 382 loss: 1.21495532e-06
Iter: 383 loss: 1.21149503e-06
Iter: 384 loss: 1.21102244e-06
Iter: 385 loss: 1.20780339e-06
Iter: 386 loss: 1.20773143e-06
Iter: 387 loss: 1.20492473e-06
Iter: 388 loss: 1.20170773e-06
Iter: 389 loss: 1.20140862e-06
Iter: 390 loss: 1.19698211e-06
Iter: 391 loss: 1.23371683e-06
Iter: 392 loss: 1.19674053e-06
Iter: 393 loss: 1.19321055e-06
Iter: 394 loss: 1.19151264e-06
Iter: 395 loss: 1.1898137e-06
Iter: 396 loss: 1.18632761e-06
Iter: 397 loss: 1.22701158e-06
Iter: 398 loss: 1.1862428e-06
Iter: 399 loss: 1.18278524e-06
Iter: 400 loss: 1.18050411e-06
Iter: 401 loss: 1.17911691e-06
Iter: 402 loss: 1.17646937e-06
Iter: 403 loss: 1.17614468e-06
Iter: 404 loss: 1.17440322e-06
Iter: 405 loss: 1.19218953e-06
Iter: 406 loss: 1.17437207e-06
Iter: 407 loss: 1.17276932e-06
Iter: 408 loss: 1.16839533e-06
Iter: 409 loss: 1.18925459e-06
Iter: 410 loss: 1.16672686e-06
Iter: 411 loss: 1.16297849e-06
Iter: 412 loss: 1.21310063e-06
Iter: 413 loss: 1.1629445e-06
Iter: 414 loss: 1.16009915e-06
Iter: 415 loss: 1.15652313e-06
Iter: 416 loss: 1.15620287e-06
Iter: 417 loss: 1.15277658e-06
Iter: 418 loss: 1.20308925e-06
Iter: 419 loss: 1.15272383e-06
Iter: 420 loss: 1.1495199e-06
Iter: 421 loss: 1.15021044e-06
Iter: 422 loss: 1.14714862e-06
Iter: 423 loss: 1.14384807e-06
Iter: 424 loss: 1.16877175e-06
Iter: 425 loss: 1.14360171e-06
Iter: 426 loss: 1.14073032e-06
Iter: 427 loss: 1.14043905e-06
Iter: 428 loss: 1.13839087e-06
Iter: 429 loss: 1.13501778e-06
Iter: 430 loss: 1.16011017e-06
Iter: 431 loss: 1.13481519e-06
Iter: 432 loss: 1.13166618e-06
Iter: 433 loss: 1.13006649e-06
Iter: 434 loss: 1.12865973e-06
Iter: 435 loss: 1.12604835e-06
Iter: 436 loss: 1.1647428e-06
Iter: 437 loss: 1.12603061e-06
Iter: 438 loss: 1.12380189e-06
Iter: 439 loss: 1.1352779e-06
Iter: 440 loss: 1.12338944e-06
Iter: 441 loss: 1.12078885e-06
Iter: 442 loss: 1.12126668e-06
Iter: 443 loss: 1.118932e-06
Iter: 444 loss: 1.11714e-06
Iter: 445 loss: 1.11999179e-06
Iter: 446 loss: 1.11617942e-06
Iter: 447 loss: 1.11368036e-06
Iter: 448 loss: 1.11067459e-06
Iter: 449 loss: 1.11036616e-06
Iter: 450 loss: 1.10692713e-06
Iter: 451 loss: 1.11955478e-06
Iter: 452 loss: 1.10609255e-06
Iter: 453 loss: 1.10220731e-06
Iter: 454 loss: 1.12237501e-06
Iter: 455 loss: 1.10151882e-06
Iter: 456 loss: 1.09910695e-06
Iter: 457 loss: 1.10134056e-06
Iter: 458 loss: 1.09771008e-06
Iter: 459 loss: 1.09418318e-06
Iter: 460 loss: 1.11282168e-06
Iter: 461 loss: 1.09363191e-06
Iter: 462 loss: 1.09121765e-06
Iter: 463 loss: 1.09000166e-06
Iter: 464 loss: 1.08891231e-06
Iter: 465 loss: 1.08479549e-06
Iter: 466 loss: 1.1089893e-06
Iter: 467 loss: 1.08429776e-06
Iter: 468 loss: 1.08188192e-06
Iter: 469 loss: 1.0858414e-06
Iter: 470 loss: 1.08076233e-06
Iter: 471 loss: 1.07801225e-06
Iter: 472 loss: 1.11769566e-06
Iter: 473 loss: 1.07802816e-06
Iter: 474 loss: 1.07587039e-06
Iter: 475 loss: 1.08496658e-06
Iter: 476 loss: 1.07540609e-06
Iter: 477 loss: 1.07423182e-06
Iter: 478 loss: 1.0716069e-06
Iter: 479 loss: 1.11261033e-06
Iter: 480 loss: 1.07157621e-06
Iter: 481 loss: 1.06805874e-06
Iter: 482 loss: 1.08218546e-06
Iter: 483 loss: 1.06726202e-06
Iter: 484 loss: 1.06467724e-06
Iter: 485 loss: 1.06355594e-06
Iter: 486 loss: 1.06223797e-06
Iter: 487 loss: 1.05938273e-06
Iter: 488 loss: 1.05928007e-06
Iter: 489 loss: 1.05767754e-06
Iter: 490 loss: 1.05513845e-06
Iter: 491 loss: 1.05509139e-06
Iter: 492 loss: 1.05265292e-06
Iter: 493 loss: 1.05263382e-06
Iter: 494 loss: 1.05086315e-06
Iter: 495 loss: 1.04869696e-06
Iter: 496 loss: 1.04861442e-06
Iter: 497 loss: 1.04573132e-06
Iter: 498 loss: 1.07800611e-06
Iter: 499 loss: 1.04570336e-06
Iter: 500 loss: 1.0437841e-06
Iter: 501 loss: 1.04135756e-06
Iter: 502 loss: 1.0411884e-06
Iter: 503 loss: 1.03735965e-06
Iter: 504 loss: 1.05828701e-06
Iter: 505 loss: 1.0368567e-06
Iter: 506 loss: 1.03548223e-06
Iter: 507 loss: 1.03512082e-06
Iter: 508 loss: 1.03361015e-06
Iter: 509 loss: 1.03852472e-06
Iter: 510 loss: 1.03326238e-06
Iter: 511 loss: 1.03225943e-06
Iter: 512 loss: 1.03078014e-06
Iter: 513 loss: 1.030666e-06
Iter: 514 loss: 1.02865692e-06
Iter: 515 loss: 1.03228922e-06
Iter: 516 loss: 1.02770809e-06
Iter: 517 loss: 1.02597755e-06
Iter: 518 loss: 1.03843195e-06
Iter: 519 loss: 1.02580566e-06
Iter: 520 loss: 1.02401418e-06
Iter: 521 loss: 1.02229399e-06
Iter: 522 loss: 1.02196009e-06
Iter: 523 loss: 1.0200306e-06
Iter: 524 loss: 1.04871731e-06
Iter: 525 loss: 1.02009744e-06
Iter: 526 loss: 1.01837031e-06
Iter: 527 loss: 1.01568844e-06
Iter: 528 loss: 1.01566627e-06
Iter: 529 loss: 1.01349769e-06
Iter: 530 loss: 1.01351634e-06
Iter: 531 loss: 1.01154853e-06
Iter: 532 loss: 1.01174419e-06
Iter: 533 loss: 1.0099975e-06
Iter: 534 loss: 1.00809825e-06
Iter: 535 loss: 1.02621925e-06
Iter: 536 loss: 1.00808154e-06
Iter: 537 loss: 1.0060412e-06
Iter: 538 loss: 1.00356806e-06
Iter: 539 loss: 1.00338059e-06
Iter: 540 loss: 1.00142802e-06
Iter: 541 loss: 1.03014804e-06
Iter: 542 loss: 1.00145166e-06
Iter: 543 loss: 9.99890403e-07
Iter: 544 loss: 1.00861439e-06
Iter: 545 loss: 9.99667577e-07
Iter: 546 loss: 9.97601546e-07
Iter: 547 loss: 9.99547e-07
Iter: 548 loss: 9.96460585e-07
Iter: 549 loss: 9.95255732e-07
Iter: 550 loss: 9.93657068e-07
Iter: 551 loss: 9.93617277e-07
Iter: 552 loss: 9.9135525e-07
Iter: 553 loss: 1.0042553e-06
Iter: 554 loss: 9.9107433e-07
Iter: 555 loss: 9.89591626e-07
Iter: 556 loss: 9.88625175e-07
Iter: 557 loss: 9.88123475e-07
Iter: 558 loss: 9.86719442e-07
Iter: 559 loss: 9.86579153e-07
Iter: 560 loss: 9.85351335e-07
Iter: 561 loss: 9.82999609e-07
Iter: 562 loss: 1.03777234e-06
Iter: 563 loss: 9.83026212e-07
Iter: 564 loss: 9.80917889e-07
Iter: 565 loss: 1.01256853e-06
Iter: 566 loss: 9.80889808e-07
Iter: 567 loss: 9.79380729e-07
Iter: 568 loss: 9.76761839e-07
Iter: 569 loss: 1.03671186e-06
Iter: 570 loss: 9.7674274e-07
Iter: 571 loss: 9.74860313e-07
Iter: 572 loss: 9.9018871e-07
Iter: 573 loss: 9.74694785e-07
Iter: 574 loss: 9.73086912e-07
Iter: 575 loss: 9.75558e-07
Iter: 576 loss: 9.723326e-07
Iter: 577 loss: 9.71216195e-07
Iter: 578 loss: 9.71173677e-07
Iter: 579 loss: 9.70379915e-07
Iter: 580 loss: 9.71453801e-07
Iter: 581 loss: 9.69984285e-07
Iter: 582 loss: 9.68761924e-07
Iter: 583 loss: 9.66819925e-07
Iter: 584 loss: 9.6678707e-07
Iter: 585 loss: 9.64869741e-07
Iter: 586 loss: 9.71953796e-07
Iter: 587 loss: 9.64365768e-07
Iter: 588 loss: 9.62431841e-07
Iter: 589 loss: 9.71599775e-07
Iter: 590 loss: 9.62064746e-07
Iter: 591 loss: 9.60756665e-07
Iter: 592 loss: 9.61098294e-07
Iter: 593 loss: 9.59807494e-07
Iter: 594 loss: 9.57596626e-07
Iter: 595 loss: 9.69853772e-07
Iter: 596 loss: 9.57377438e-07
Iter: 597 loss: 9.55921678e-07
Iter: 598 loss: 9.56014446e-07
Iter: 599 loss: 9.54863e-07
Iter: 600 loss: 9.53001745e-07
Iter: 601 loss: 9.66731704e-07
Iter: 602 loss: 9.52843493e-07
Iter: 603 loss: 9.51516313e-07
Iter: 604 loss: 9.51874085e-07
Iter: 605 loss: 9.50566346e-07
Iter: 606 loss: 9.48601212e-07
Iter: 607 loss: 9.57065595e-07
Iter: 608 loss: 9.48149932e-07
Iter: 609 loss: 9.4677165e-07
Iter: 610 loss: 9.46092655e-07
Iter: 611 loss: 9.45393595e-07
Iter: 612 loss: 9.44743647e-07
Iter: 613 loss: 9.44207954e-07
Iter: 614 loss: 9.43527823e-07
Iter: 615 loss: 9.43287887e-07
Iter: 616 loss: 9.42927727e-07
Iter: 617 loss: 9.42068823e-07
Iter: 618 loss: 9.40375742e-07
Iter: 619 loss: 9.71538384e-07
Iter: 620 loss: 9.40286384e-07
Iter: 621 loss: 9.38825792e-07
Iter: 622 loss: 9.576205e-07
Iter: 623 loss: 9.38808057e-07
Iter: 624 loss: 9.37457116e-07
Iter: 625 loss: 9.36115043e-07
Iter: 626 loss: 9.35894718e-07
Iter: 627 loss: 9.33923388e-07
Iter: 628 loss: 9.45634895e-07
Iter: 629 loss: 9.33774118e-07
Iter: 630 loss: 9.31704903e-07
Iter: 631 loss: 9.34758816e-07
Iter: 632 loss: 9.30861859e-07
Iter: 633 loss: 9.2922221e-07
Iter: 634 loss: 9.35332309e-07
Iter: 635 loss: 9.28880638e-07
Iter: 636 loss: 9.26865368e-07
Iter: 637 loss: 9.32714443e-07
Iter: 638 loss: 9.26296e-07
Iter: 639 loss: 9.25174561e-07
Iter: 640 loss: 9.31140562e-07
Iter: 641 loss: 9.25030804e-07
Iter: 642 loss: 9.23771836e-07
Iter: 643 loss: 9.23687423e-07
Iter: 644 loss: 9.22750132e-07
Iter: 645 loss: 9.21383162e-07
Iter: 646 loss: 9.29485964e-07
Iter: 647 loss: 9.21238211e-07
Iter: 648 loss: 9.20250841e-07
Iter: 649 loss: 9.35389721e-07
Iter: 650 loss: 9.20217929e-07
Iter: 651 loss: 9.19348395e-07
Iter: 652 loss: 9.19449633e-07
Iter: 653 loss: 9.18616138e-07
Iter: 654 loss: 9.17954537e-07
Iter: 655 loss: 9.16784131e-07
Iter: 656 loss: 9.16771228e-07
Iter: 657 loss: 9.14896418e-07
Iter: 658 loss: 9.23716925e-07
Iter: 659 loss: 9.14561724e-07
Iter: 660 loss: 9.13555141e-07
Iter: 661 loss: 9.14197358e-07
Iter: 662 loss: 9.12844371e-07
Iter: 663 loss: 9.11219217e-07
Iter: 664 loss: 9.15511407e-07
Iter: 665 loss: 9.10607525e-07
Iter: 666 loss: 9.0904166e-07
Iter: 667 loss: 9.08573838e-07
Iter: 668 loss: 9.07720562e-07
Iter: 669 loss: 9.06048683e-07
Iter: 670 loss: 9.06071591e-07
Iter: 671 loss: 9.04811316e-07
Iter: 672 loss: 9.02934573e-07
Iter: 673 loss: 9.02888928e-07
Iter: 674 loss: 9.00897476e-07
Iter: 675 loss: 9.24185599e-07
Iter: 676 loss: 9.0090191e-07
Iter: 677 loss: 8.99084171e-07
Iter: 678 loss: 9.01437886e-07
Iter: 679 loss: 8.98186329e-07
Iter: 680 loss: 8.97273367e-07
Iter: 681 loss: 9.12480118e-07
Iter: 682 loss: 8.97242e-07
Iter: 683 loss: 8.96379902e-07
Iter: 684 loss: 8.99550059e-07
Iter: 685 loss: 8.96143e-07
Iter: 686 loss: 8.94836603e-07
Iter: 687 loss: 8.95093422e-07
Iter: 688 loss: 8.93981394e-07
Iter: 689 loss: 8.93254708e-07
Iter: 690 loss: 8.95413905e-07
Iter: 691 loss: 8.92910748e-07
Iter: 692 loss: 8.92063724e-07
Iter: 693 loss: 8.90178626e-07
Iter: 694 loss: 9.21293122e-07
Iter: 695 loss: 8.90148158e-07
Iter: 696 loss: 8.89217176e-07
Iter: 697 loss: 8.89029138e-07
Iter: 698 loss: 8.88261297e-07
Iter: 699 loss: 8.8709362e-07
Iter: 700 loss: 8.87043086e-07
Iter: 701 loss: 8.85504e-07
Iter: 702 loss: 8.99697113e-07
Iter: 703 loss: 8.85474833e-07
Iter: 704 loss: 8.84268161e-07
Iter: 705 loss: 8.83748498e-07
Iter: 706 loss: 8.83145105e-07
Iter: 707 loss: 8.81898e-07
Iter: 708 loss: 8.89644923e-07
Iter: 709 loss: 8.81771371e-07
Iter: 710 loss: 8.80487391e-07
Iter: 711 loss: 8.7981897e-07
Iter: 712 loss: 8.7919e-07
Iter: 713 loss: 8.78133619e-07
Iter: 714 loss: 8.78157721e-07
Iter: 715 loss: 8.7737817e-07
Iter: 716 loss: 8.7686692e-07
Iter: 717 loss: 8.76529668e-07
Iter: 718 loss: 8.75686396e-07
Iter: 719 loss: 8.75730848e-07
Iter: 720 loss: 8.75171907e-07
Iter: 721 loss: 8.75008936e-07
Iter: 722 loss: 8.74654575e-07
Iter: 723 loss: 8.73859108e-07
Iter: 724 loss: 8.72271642e-07
Iter: 725 loss: 9.07468916e-07
Iter: 726 loss: 8.723365e-07
Iter: 727 loss: 8.70806161e-07
Iter: 728 loss: 8.82203835e-07
Iter: 729 loss: 8.70706799e-07
Iter: 730 loss: 8.69186067e-07
Iter: 731 loss: 8.71418933e-07
Iter: 732 loss: 8.68509687e-07
Iter: 733 loss: 8.67313929e-07
Iter: 734 loss: 8.73339729e-07
Iter: 735 loss: 8.67045514e-07
Iter: 736 loss: 8.65720835e-07
Iter: 737 loss: 8.65449806e-07
Iter: 738 loss: 8.64512799e-07
Iter: 739 loss: 8.63400373e-07
Iter: 740 loss: 8.71705481e-07
Iter: 741 loss: 8.63289642e-07
Iter: 742 loss: 8.61941544e-07
Iter: 743 loss: 8.61700869e-07
Iter: 744 loss: 8.60762498e-07
Iter: 745 loss: 8.59761315e-07
Iter: 746 loss: 8.72374585e-07
Iter: 747 loss: 8.5979e-07
Iter: 748 loss: 8.58833914e-07
Iter: 749 loss: 8.58183057e-07
Iter: 750 loss: 8.57858083e-07
Iter: 751 loss: 8.57719954e-07
Iter: 752 loss: 8.57250825e-07
Iter: 753 loss: 8.56653628e-07
Iter: 754 loss: 8.56044721e-07
Iter: 755 loss: 8.55945075e-07
Iter: 756 loss: 8.54968e-07
Iter: 757 loss: 8.57184318e-07
Iter: 758 loss: 8.54670589e-07
Iter: 759 loss: 8.5396357e-07
Iter: 760 loss: 8.52889684e-07
Iter: 761 loss: 8.52818289e-07
Iter: 762 loss: 8.51411528e-07
Iter: 763 loss: 8.6535556e-07
Iter: 764 loss: 8.51300797e-07
Iter: 765 loss: 8.50682682e-07
Iter: 766 loss: 8.50923e-07
Iter: 767 loss: 8.50191441e-07
Iter: 768 loss: 8.49067192e-07
Iter: 769 loss: 8.51242135e-07
Iter: 770 loss: 8.48548154e-07
Iter: 771 loss: 8.47515082e-07
Iter: 772 loss: 8.48004561e-07
Iter: 773 loss: 8.46829892e-07
Iter: 774 loss: 8.45296768e-07
Iter: 775 loss: 8.55353449e-07
Iter: 776 loss: 8.45191266e-07
Iter: 777 loss: 8.43960436e-07
Iter: 778 loss: 8.43065266e-07
Iter: 779 loss: 8.42685722e-07
Iter: 780 loss: 8.41335179e-07
Iter: 781 loss: 8.4140936e-07
Iter: 782 loss: 8.40688585e-07
Iter: 783 loss: 8.41398446e-07
Iter: 784 loss: 8.40275675e-07
Iter: 785 loss: 8.39062182e-07
Iter: 786 loss: 8.46025841e-07
Iter: 787 loss: 8.38928599e-07
Iter: 788 loss: 8.38343e-07
Iter: 789 loss: 8.3868531e-07
Iter: 790 loss: 8.37906043e-07
Iter: 791 loss: 8.37265475e-07
Iter: 792 loss: 8.3642783e-07
Iter: 793 loss: 8.36269805e-07
Iter: 794 loss: 8.35264e-07
Iter: 795 loss: 8.46853084e-07
Iter: 796 loss: 8.35233209e-07
Iter: 797 loss: 8.34488e-07
Iter: 798 loss: 8.33438605e-07
Iter: 799 loss: 8.33463787e-07
Iter: 800 loss: 8.32338401e-07
Iter: 801 loss: 8.48161051e-07
Iter: 802 loss: 8.32352043e-07
Iter: 803 loss: 8.31558737e-07
Iter: 804 loss: 8.31522243e-07
Iter: 805 loss: 8.30912541e-07
Iter: 806 loss: 8.30038516e-07
Iter: 807 loss: 8.39488166e-07
Iter: 808 loss: 8.30002705e-07
Iter: 809 loss: 8.2937197e-07
Iter: 810 loss: 8.28335374e-07
Iter: 811 loss: 8.28337249e-07
Iter: 812 loss: 8.27613576e-07
Iter: 813 loss: 8.27542237e-07
Iter: 814 loss: 8.27067709e-07
Iter: 815 loss: 8.25995301e-07
Iter: 816 loss: 8.44642273e-07
Iter: 817 loss: 8.25959432e-07
Iter: 818 loss: 8.26232906e-07
Iter: 819 loss: 8.25376787e-07
Iter: 820 loss: 8.24843e-07
Iter: 821 loss: 8.2520279e-07
Iter: 822 loss: 8.24474455e-07
Iter: 823 loss: 8.23757205e-07
Iter: 824 loss: 8.23656421e-07
Iter: 825 loss: 8.23134656e-07
Iter: 826 loss: 8.22289621e-07
Iter: 827 loss: 8.27580322e-07
Iter: 828 loss: 8.22273819e-07
Iter: 829 loss: 8.21577316e-07
Iter: 830 loss: 8.20692e-07
Iter: 831 loss: 8.20599325e-07
Iter: 832 loss: 8.19858485e-07
Iter: 833 loss: 8.31490752e-07
Iter: 834 loss: 8.19890261e-07
Iter: 835 loss: 8.19138336e-07
Iter: 836 loss: 8.18861622e-07
Iter: 837 loss: 8.18443937e-07
Iter: 838 loss: 8.17584066e-07
Iter: 839 loss: 8.26181292e-07
Iter: 840 loss: 8.17580769e-07
Iter: 841 loss: 8.16885e-07
Iter: 842 loss: 8.16759496e-07
Iter: 843 loss: 8.16310774e-07
Iter: 844 loss: 8.15470571e-07
Iter: 845 loss: 8.20127639e-07
Iter: 846 loss: 8.15464e-07
Iter: 847 loss: 8.14591033e-07
Iter: 848 loss: 8.15203464e-07
Iter: 849 loss: 8.14106272e-07
Iter: 850 loss: 8.13456154e-07
Iter: 851 loss: 8.13454278e-07
Iter: 852 loss: 8.12987423e-07
Iter: 853 loss: 8.16354202e-07
Iter: 854 loss: 8.12946325e-07
Iter: 855 loss: 8.12475093e-07
Iter: 856 loss: 8.11488121e-07
Iter: 857 loss: 8.28417114e-07
Iter: 858 loss: 8.11499262e-07
Iter: 859 loss: 8.10906215e-07
Iter: 860 loss: 8.16016154e-07
Iter: 861 loss: 8.10776442e-07
Iter: 862 loss: 8.10140477e-07
Iter: 863 loss: 8.08951654e-07
Iter: 864 loss: 8.08964671e-07
Iter: 865 loss: 8.08177674e-07
Iter: 866 loss: 8.08180289e-07
Iter: 867 loss: 8.07410572e-07
Iter: 868 loss: 8.06366302e-07
Iter: 869 loss: 8.06299511e-07
Iter: 870 loss: 8.05457319e-07
Iter: 871 loss: 8.05450782e-07
Iter: 872 loss: 8.04873e-07
Iter: 873 loss: 8.04653496e-07
Iter: 874 loss: 8.04267756e-07
Iter: 875 loss: 8.03489058e-07
Iter: 876 loss: 8.07270908e-07
Iter: 877 loss: 8.03366902e-07
Iter: 878 loss: 8.02450927e-07
Iter: 879 loss: 8.04337674e-07
Iter: 880 loss: 8.02035174e-07
Iter: 881 loss: 8.01413194e-07
Iter: 882 loss: 8.02328032e-07
Iter: 883 loss: 8.01149e-07
Iter: 884 loss: 8.00514158e-07
Iter: 885 loss: 8.01544559e-07
Iter: 886 loss: 8.00243811e-07
Iter: 887 loss: 7.99528834e-07
Iter: 888 loss: 8.0684265e-07
Iter: 889 loss: 7.99506e-07
Iter: 890 loss: 7.99215286e-07
Iter: 891 loss: 7.98668793e-07
Iter: 892 loss: 8.11305199e-07
Iter: 893 loss: 7.98658789e-07
Iter: 894 loss: 7.97906864e-07
Iter: 895 loss: 8.01742317e-07
Iter: 896 loss: 7.97810799e-07
Iter: 897 loss: 7.97290568e-07
Iter: 898 loss: 7.97551138e-07
Iter: 899 loss: 7.97005782e-07
Iter: 900 loss: 7.96159384e-07
Iter: 901 loss: 7.97136067e-07
Iter: 902 loss: 7.95675419e-07
Iter: 903 loss: 7.94850621e-07
Iter: 904 loss: 7.96975314e-07
Iter: 905 loss: 7.94554921e-07
Iter: 906 loss: 7.93469951e-07
Iter: 907 loss: 7.95105848e-07
Iter: 908 loss: 7.92896685e-07
Iter: 909 loss: 7.92083199e-07
Iter: 910 loss: 7.92287494e-07
Iter: 911 loss: 7.91506125e-07
Iter: 912 loss: 7.90371928e-07
Iter: 913 loss: 8.0069276e-07
Iter: 914 loss: 7.90313038e-07
Iter: 915 loss: 7.89720048e-07
Iter: 916 loss: 7.89891942e-07
Iter: 917 loss: 7.89254841e-07
Iter: 918 loss: 7.88288276e-07
Iter: 919 loss: 7.91409548e-07
Iter: 920 loss: 7.87950398e-07
Iter: 921 loss: 7.87265208e-07
Iter: 922 loss: 7.88930095e-07
Iter: 923 loss: 7.8702783e-07
Iter: 924 loss: 7.86219857e-07
Iter: 925 loss: 7.97109919e-07
Iter: 926 loss: 7.86267719e-07
Iter: 927 loss: 7.8569451e-07
Iter: 928 loss: 7.85372777e-07
Iter: 929 loss: 7.85208158e-07
Iter: 930 loss: 7.84567419e-07
Iter: 931 loss: 7.84354938e-07
Iter: 932 loss: 7.8399853e-07
Iter: 933 loss: 7.8307869e-07
Iter: 934 loss: 7.90269382e-07
Iter: 935 loss: 7.83050211e-07
Iter: 936 loss: 7.82383495e-07
Iter: 937 loss: 7.81722406e-07
Iter: 938 loss: 7.81547158e-07
Iter: 939 loss: 7.80392099e-07
Iter: 940 loss: 7.89472153e-07
Iter: 941 loss: 7.80243283e-07
Iter: 942 loss: 7.79609536e-07
Iter: 943 loss: 7.78917e-07
Iter: 944 loss: 7.78844196e-07
Iter: 945 loss: 7.78021445e-07
Iter: 946 loss: 7.78065214e-07
Iter: 947 loss: 7.77501668e-07
Iter: 948 loss: 7.7699633e-07
Iter: 949 loss: 7.76807667e-07
Iter: 950 loss: 7.76147829e-07
Iter: 951 loss: 7.7746347e-07
Iter: 952 loss: 7.75840704e-07
Iter: 953 loss: 7.75078831e-07
Iter: 954 loss: 7.75242938e-07
Iter: 955 loss: 7.74457362e-07
Iter: 956 loss: 7.74139892e-07
Iter: 957 loss: 7.73964643e-07
Iter: 958 loss: 7.73480792e-07
Iter: 959 loss: 7.7365695e-07
Iter: 960 loss: 7.73212491e-07
Iter: 961 loss: 7.72544524e-07
Iter: 962 loss: 7.71570967e-07
Iter: 963 loss: 7.71481893e-07
Iter: 964 loss: 7.70803069e-07
Iter: 965 loss: 7.8066256e-07
Iter: 966 loss: 7.70818076e-07
Iter: 967 loss: 7.70151246e-07
Iter: 968 loss: 7.69495955e-07
Iter: 969 loss: 7.69386133e-07
Iter: 970 loss: 7.68409791e-07
Iter: 971 loss: 7.78836466e-07
Iter: 972 loss: 7.68388873e-07
Iter: 973 loss: 7.67652239e-07
Iter: 974 loss: 7.66965968e-07
Iter: 975 loss: 7.66929247e-07
Iter: 976 loss: 7.65921e-07
Iter: 977 loss: 7.71766736e-07
Iter: 978 loss: 7.6576282e-07
Iter: 979 loss: 7.64864694e-07
Iter: 980 loss: 7.66178e-07
Iter: 981 loss: 7.64291713e-07
Iter: 982 loss: 7.63566732e-07
Iter: 983 loss: 7.66681637e-07
Iter: 984 loss: 7.63415073e-07
Iter: 985 loss: 7.62452373e-07
Iter: 986 loss: 7.62670481e-07
Iter: 987 loss: 7.61694821e-07
Iter: 988 loss: 7.60995249e-07
Iter: 989 loss: 7.60995079e-07
Iter: 990 loss: 7.60413911e-07
Iter: 991 loss: 7.64740662e-07
Iter: 992 loss: 7.60408284e-07
Iter: 993 loss: 7.60014132e-07
Iter: 994 loss: 7.5933292e-07
Iter: 995 loss: 7.59320073e-07
Iter: 996 loss: 7.58713213e-07
Iter: 997 loss: 7.60333592e-07
Iter: 998 loss: 7.58467252e-07
Iter: 999 loss: 7.57785699e-07
Iter: 1000 loss: 7.59158297e-07
Iter: 1001 loss: 7.57482553e-07
Iter: 1002 loss: 7.56955671e-07
Iter: 1003 loss: 7.60370767e-07
Iter: 1004 loss: 7.569123e-07
Iter: 1005 loss: 7.56299528e-07
Iter: 1006 loss: 7.55759515e-07
Iter: 1007 loss: 7.55532483e-07
Iter: 1008 loss: 7.54920734e-07
Iter: 1009 loss: 7.61695674e-07
Iter: 1010 loss: 7.54910729e-07
Iter: 1011 loss: 7.54330813e-07
Iter: 1012 loss: 7.53293534e-07
Iter: 1013 loss: 7.53274321e-07
Iter: 1014 loss: 7.52439e-07
Iter: 1015 loss: 7.63504886e-07
Iter: 1016 loss: 7.52440656e-07
Iter: 1017 loss: 7.51640926e-07
Iter: 1018 loss: 7.53663528e-07
Iter: 1019 loss: 7.51389052e-07
Iter: 1020 loss: 7.50685103e-07
Iter: 1021 loss: 7.52261258e-07
Iter: 1022 loss: 7.50434083e-07
Iter: 1023 loss: 7.50010486e-07
Iter: 1024 loss: 7.49957849e-07
Iter: 1025 loss: 7.4950816e-07
Iter: 1026 loss: 7.50075742e-07
Iter: 1027 loss: 7.49288347e-07
Iter: 1028 loss: 7.4899458e-07
Iter: 1029 loss: 7.48430352e-07
Iter: 1030 loss: 7.570045e-07
Iter: 1031 loss: 7.48392665e-07
Iter: 1032 loss: 7.47572358e-07
Iter: 1033 loss: 7.5374669e-07
Iter: 1034 loss: 7.47559056e-07
Iter: 1035 loss: 7.46949638e-07
Iter: 1036 loss: 7.47124488e-07
Iter: 1037 loss: 7.46531668e-07
Iter: 1038 loss: 7.4581078e-07
Iter: 1039 loss: 7.51832033e-07
Iter: 1040 loss: 7.45785428e-07
Iter: 1041 loss: 7.45267243e-07
Iter: 1042 loss: 7.4539912e-07
Iter: 1043 loss: 7.44869681e-07
Iter: 1044 loss: 7.44056592e-07
Iter: 1045 loss: 7.46425314e-07
Iter: 1046 loss: 7.43774081e-07
Iter: 1047 loss: 7.43180408e-07
Iter: 1048 loss: 7.4351567e-07
Iter: 1049 loss: 7.42758061e-07
Iter: 1050 loss: 7.42134375e-07
Iter: 1051 loss: 7.48110665e-07
Iter: 1052 loss: 7.42080147e-07
Iter: 1053 loss: 7.41682243e-07
Iter: 1054 loss: 7.41664394e-07
Iter: 1055 loss: 7.41407121e-07
Iter: 1056 loss: 7.40587e-07
Iter: 1057 loss: 7.45278385e-07
Iter: 1058 loss: 7.40564303e-07
Iter: 1059 loss: 7.40207838e-07
Iter: 1060 loss: 7.40205337e-07
Iter: 1061 loss: 7.40023836e-07
Iter: 1062 loss: 7.39553286e-07
Iter: 1063 loss: 7.41219196e-07
Iter: 1064 loss: 7.39325685e-07
Iter: 1065 loss: 7.38722406e-07
Iter: 1066 loss: 7.44862234e-07
Iter: 1067 loss: 7.38653625e-07
Iter: 1068 loss: 7.38205131e-07
Iter: 1069 loss: 7.38109065e-07
Iter: 1070 loss: 7.37831e-07
Iter: 1071 loss: 7.37281425e-07
Iter: 1072 loss: 7.43086161e-07
Iter: 1073 loss: 7.37244136e-07
Iter: 1074 loss: 7.36867264e-07
Iter: 1075 loss: 7.36114771e-07
Iter: 1076 loss: 7.36153083e-07
Iter: 1077 loss: 7.35427705e-07
Iter: 1078 loss: 7.35412073e-07
Iter: 1079 loss: 7.35047252e-07
Iter: 1080 loss: 7.35625235e-07
Iter: 1081 loss: 7.34961e-07
Iter: 1082 loss: 7.34404694e-07
Iter: 1083 loss: 7.34494051e-07
Iter: 1084 loss: 7.34003e-07
Iter: 1085 loss: 7.33396064e-07
Iter: 1086 loss: 7.34211881e-07
Iter: 1087 loss: 7.32998728e-07
Iter: 1088 loss: 7.32425406e-07
Iter: 1089 loss: 7.41364431e-07
Iter: 1090 loss: 7.32410228e-07
Iter: 1091 loss: 7.32082754e-07
Iter: 1092 loss: 7.36547463e-07
Iter: 1093 loss: 7.32113676e-07
Iter: 1094 loss: 7.31758064e-07
Iter: 1095 loss: 7.31518639e-07
Iter: 1096 loss: 7.31375621e-07
Iter: 1097 loss: 7.31001364e-07
Iter: 1098 loss: 7.30811905e-07
Iter: 1099 loss: 7.30740283e-07
Iter: 1100 loss: 7.29978183e-07
Iter: 1101 loss: 7.30448392e-07
Iter: 1102 loss: 7.29507121e-07
Iter: 1103 loss: 7.28969667e-07
Iter: 1104 loss: 7.34894229e-07
Iter: 1105 loss: 7.28965574e-07
Iter: 1106 loss: 7.28424254e-07
Iter: 1107 loss: 7.27970416e-07
Iter: 1108 loss: 7.27850704e-07
Iter: 1109 loss: 7.2719331e-07
Iter: 1110 loss: 7.31334353e-07
Iter: 1111 loss: 7.27102e-07
Iter: 1112 loss: 7.26334861e-07
Iter: 1113 loss: 7.26990265e-07
Iter: 1114 loss: 7.25952418e-07
Iter: 1115 loss: 7.25298321e-07
Iter: 1116 loss: 7.29771557e-07
Iter: 1117 loss: 7.25281552e-07
Iter: 1118 loss: 7.24693223e-07
Iter: 1119 loss: 7.24845904e-07
Iter: 1120 loss: 7.2429151e-07
Iter: 1121 loss: 7.23709661e-07
Iter: 1122 loss: 7.25004895e-07
Iter: 1123 loss: 7.23414701e-07
Iter: 1124 loss: 7.22747757e-07
Iter: 1125 loss: 7.26618225e-07
Iter: 1126 loss: 7.22606273e-07
Iter: 1127 loss: 7.22278514e-07
Iter: 1128 loss: 7.2224816e-07
Iter: 1129 loss: 7.22075185e-07
Iter: 1130 loss: 7.21552283e-07
Iter: 1131 loss: 7.25102836e-07
Iter: 1132 loss: 7.21442575e-07
Iter: 1133 loss: 7.20626645e-07
Iter: 1134 loss: 7.21471054e-07
Iter: 1135 loss: 7.20306105e-07
Iter: 1136 loss: 7.19660534e-07
Iter: 1137 loss: 7.19967602e-07
Iter: 1138 loss: 7.19270474e-07
Iter: 1139 loss: 7.18419415e-07
Iter: 1140 loss: 7.25752159e-07
Iter: 1141 loss: 7.18401225e-07
Iter: 1142 loss: 7.17886678e-07
Iter: 1143 loss: 7.17668343e-07
Iter: 1144 loss: 7.17431533e-07
Iter: 1145 loss: 7.1688055e-07
Iter: 1146 loss: 7.21707e-07
Iter: 1147 loss: 7.16825468e-07
Iter: 1148 loss: 7.16323598e-07
Iter: 1149 loss: 7.16912723e-07
Iter: 1150 loss: 7.1597168e-07
Iter: 1151 loss: 7.15533247e-07
Iter: 1152 loss: 7.15526539e-07
Iter: 1153 loss: 7.15233966e-07
Iter: 1154 loss: 7.14581063e-07
Iter: 1155 loss: 7.2266937e-07
Iter: 1156 loss: 7.14494718e-07
Iter: 1157 loss: 7.13858583e-07
Iter: 1158 loss: 7.13835504e-07
Iter: 1159 loss: 7.13527925e-07
Iter: 1160 loss: 7.17326316e-07
Iter: 1161 loss: 7.13528323e-07
Iter: 1162 loss: 7.13203747e-07
Iter: 1163 loss: 7.12444944e-07
Iter: 1164 loss: 7.23103881e-07
Iter: 1165 loss: 7.12392591e-07
Iter: 1166 loss: 7.11801192e-07
Iter: 1167 loss: 7.16924262e-07
Iter: 1168 loss: 7.11736448e-07
Iter: 1169 loss: 7.11378902e-07
Iter: 1170 loss: 7.1083366e-07
Iter: 1171 loss: 7.10740892e-07
Iter: 1172 loss: 7.10050074e-07
Iter: 1173 loss: 7.16981276e-07
Iter: 1174 loss: 7.10003292e-07
Iter: 1175 loss: 7.09537801e-07
Iter: 1176 loss: 7.09078108e-07
Iter: 1177 loss: 7.08998755e-07
Iter: 1178 loss: 7.08346874e-07
Iter: 1179 loss: 7.14682187e-07
Iter: 1180 loss: 7.08370862e-07
Iter: 1181 loss: 7.07774916e-07
Iter: 1182 loss: 7.07578238e-07
Iter: 1183 loss: 7.07255595e-07
Iter: 1184 loss: 7.0670842e-07
Iter: 1185 loss: 7.10000563e-07
Iter: 1186 loss: 7.06544085e-07
Iter: 1187 loss: 7.05983e-07
Iter: 1188 loss: 7.0688759e-07
Iter: 1189 loss: 7.05635159e-07
Iter: 1190 loss: 7.05099751e-07
Iter: 1191 loss: 7.06702622e-07
Iter: 1192 loss: 7.04983563e-07
Iter: 1193 loss: 7.04398246e-07
Iter: 1194 loss: 7.05403352e-07
Iter: 1195 loss: 7.04098966e-07
Iter: 1196 loss: 7.03826686e-07
Iter: 1197 loss: 7.03866306e-07
Iter: 1198 loss: 7.03466128e-07
Iter: 1199 loss: 7.03211583e-07
Iter: 1200 loss: 7.03157411e-07
Iter: 1201 loss: 7.02719035e-07
Iter: 1202 loss: 7.02815043e-07
Iter: 1203 loss: 7.0233034e-07
Iter: 1204 loss: 7.01822614e-07
Iter: 1205 loss: 7.01649242e-07
Iter: 1206 loss: 7.01289878e-07
Iter: 1207 loss: 7.00498617e-07
Iter: 1208 loss: 7.08128425e-07
Iter: 1209 loss: 7.00371515e-07
Iter: 1210 loss: 6.99932912e-07
Iter: 1211 loss: 6.99294276e-07
Iter: 1212 loss: 6.99335715e-07
Iter: 1213 loss: 6.98522172e-07
Iter: 1214 loss: 6.98531323e-07
Iter: 1215 loss: 6.98108863e-07
Iter: 1216 loss: 6.97481539e-07
Iter: 1217 loss: 6.97411963e-07
Iter: 1218 loss: 6.96710572e-07
Iter: 1219 loss: 7.03125806e-07
Iter: 1220 loss: 6.96670043e-07
Iter: 1221 loss: 6.96009238e-07
Iter: 1222 loss: 6.98129895e-07
Iter: 1223 loss: 6.95894073e-07
Iter: 1224 loss: 6.9537731e-07
Iter: 1225 loss: 6.97539633e-07
Iter: 1226 loss: 6.95282779e-07
Iter: 1227 loss: 6.94695188e-07
Iter: 1228 loss: 6.94902e-07
Iter: 1229 loss: 6.94318089e-07
Iter: 1230 loss: 6.94254368e-07
Iter: 1231 loss: 6.94056155e-07
Iter: 1232 loss: 6.93875393e-07
Iter: 1233 loss: 6.93701963e-07
Iter: 1234 loss: 6.93604875e-07
Iter: 1235 loss: 6.93170364e-07
Iter: 1236 loss: 6.92383708e-07
Iter: 1237 loss: 7.1057093e-07
Iter: 1238 loss: 6.92414176e-07
Iter: 1239 loss: 6.91947662e-07
Iter: 1240 loss: 6.91887408e-07
Iter: 1241 loss: 6.91529635e-07
Iter: 1242 loss: 6.91114678e-07
Iter: 1243 loss: 6.91008552e-07
Iter: 1244 loss: 6.90400498e-07
Iter: 1245 loss: 6.90757304e-07
Iter: 1246 loss: 6.89956551e-07
Iter: 1247 loss: 6.89357e-07
Iter: 1248 loss: 6.89360661e-07
Iter: 1249 loss: 6.88884938e-07
Iter: 1250 loss: 6.87992e-07
Iter: 1251 loss: 7.07743311e-07
Iter: 1252 loss: 6.87966235e-07
Iter: 1253 loss: 6.86992053e-07
Iter: 1254 loss: 7.00763167e-07
Iter: 1255 loss: 6.87022464e-07
Iter: 1256 loss: 6.86565159e-07
Iter: 1257 loss: 6.85796294e-07
Iter: 1258 loss: 7.05122659e-07
Iter: 1259 loss: 6.85783505e-07
Iter: 1260 loss: 6.85127873e-07
Iter: 1261 loss: 6.90682e-07
Iter: 1262 loss: 6.85078e-07
Iter: 1263 loss: 6.846426e-07
Iter: 1264 loss: 6.85192617e-07
Iter: 1265 loss: 6.84334452e-07
Iter: 1266 loss: 6.84085592e-07
Iter: 1267 loss: 6.87400416e-07
Iter: 1268 loss: 6.84038696e-07
Iter: 1269 loss: 6.83660971e-07
Iter: 1270 loss: 6.85778446e-07
Iter: 1271 loss: 6.83531e-07
Iter: 1272 loss: 6.83221174e-07
Iter: 1273 loss: 6.82986524e-07
Iter: 1274 loss: 6.82875907e-07
Iter: 1275 loss: 6.82600216e-07
Iter: 1276 loss: 6.82364885e-07
Iter: 1277 loss: 6.82243e-07
Iter: 1278 loss: 6.81766664e-07
Iter: 1279 loss: 6.85192504e-07
Iter: 1280 loss: 6.81670258e-07
Iter: 1281 loss: 6.81332438e-07
Iter: 1282 loss: 6.81570896e-07
Iter: 1283 loss: 6.81072038e-07
Iter: 1284 loss: 6.80596713e-07
Iter: 1285 loss: 6.83948713e-07
Iter: 1286 loss: 6.80563232e-07
Iter: 1287 loss: 6.80224673e-07
Iter: 1288 loss: 6.7980551e-07
Iter: 1289 loss: 6.79803691e-07
Iter: 1290 loss: 6.79427899e-07
Iter: 1291 loss: 6.79403058e-07
Iter: 1292 loss: 6.79153e-07
Iter: 1293 loss: 6.7868325e-07
Iter: 1294 loss: 6.78626066e-07
Iter: 1295 loss: 6.78190759e-07
Iter: 1296 loss: 6.78196045e-07
Iter: 1297 loss: 6.77900516e-07
Iter: 1298 loss: 6.77404387e-07
Iter: 1299 loss: 6.77386424e-07
Iter: 1300 loss: 6.76668151e-07
Iter: 1301 loss: 6.84226e-07
Iter: 1302 loss: 6.76657635e-07
Iter: 1303 loss: 6.7639462e-07
Iter: 1304 loss: 6.76504499e-07
Iter: 1305 loss: 6.76187085e-07
Iter: 1306 loss: 6.7577389e-07
Iter: 1307 loss: 6.75999843e-07
Iter: 1308 loss: 6.75495812e-07
Iter: 1309 loss: 6.75225238e-07
Iter: 1310 loss: 6.79745199e-07
Iter: 1311 loss: 6.75210458e-07
Iter: 1312 loss: 6.7481767e-07
Iter: 1313 loss: 6.74595071e-07
Iter: 1314 loss: 6.7444671e-07
Iter: 1315 loss: 6.7391943e-07
Iter: 1316 loss: 6.76624495e-07
Iter: 1317 loss: 6.7383894e-07
Iter: 1318 loss: 6.7329438e-07
Iter: 1319 loss: 6.73239697e-07
Iter: 1320 loss: 6.72894885e-07
Iter: 1321 loss: 6.72331e-07
Iter: 1322 loss: 6.77261e-07
Iter: 1323 loss: 6.72315821e-07
Iter: 1324 loss: 6.71830662e-07
Iter: 1325 loss: 6.72306101e-07
Iter: 1326 loss: 6.71606699e-07
Iter: 1327 loss: 6.71034968e-07
Iter: 1328 loss: 6.72700764e-07
Iter: 1329 loss: 6.7080282e-07
Iter: 1330 loss: 6.70210909e-07
Iter: 1331 loss: 6.73391185e-07
Iter: 1332 loss: 6.70073518e-07
Iter: 1333 loss: 6.69715405e-07
Iter: 1334 loss: 6.71996418e-07
Iter: 1335 loss: 6.69673341e-07
Iter: 1336 loss: 6.69210351e-07
Iter: 1337 loss: 6.70951238e-07
Iter: 1338 loss: 6.69181304e-07
Iter: 1339 loss: 6.68899361e-07
Iter: 1340 loss: 6.68601444e-07
Iter: 1341 loss: 6.68582629e-07
Iter: 1342 loss: 6.68213204e-07
Iter: 1343 loss: 6.68533858e-07
Iter: 1344 loss: 6.680213e-07
Iter: 1345 loss: 6.67558197e-07
Iter: 1346 loss: 6.6990566e-07
Iter: 1347 loss: 6.67540689e-07
Iter: 1348 loss: 6.6709697e-07
Iter: 1349 loss: 6.67616234e-07
Iter: 1350 loss: 6.6693724e-07
Iter: 1351 loss: 6.6653638e-07
Iter: 1352 loss: 6.67893914e-07
Iter: 1353 loss: 6.66286724e-07
Iter: 1354 loss: 6.65945549e-07
Iter: 1355 loss: 6.66277401e-07
Iter: 1356 loss: 6.65656103e-07
Iter: 1357 loss: 6.65170205e-07
Iter: 1358 loss: 6.67124709e-07
Iter: 1359 loss: 6.65066352e-07
Iter: 1360 loss: 6.64676691e-07
Iter: 1361 loss: 6.65695552e-07
Iter: 1362 loss: 6.64503659e-07
Iter: 1363 loss: 6.64166635e-07
Iter: 1364 loss: 6.65896152e-07
Iter: 1365 loss: 6.64064e-07
Iter: 1366 loss: 6.63745595e-07
Iter: 1367 loss: 6.64880133e-07
Iter: 1368 loss: 6.63636058e-07
Iter: 1369 loss: 6.63408343e-07
Iter: 1370 loss: 6.63367757e-07
Iter: 1371 loss: 6.63249921e-07
Iter: 1372 loss: 6.62970535e-07
Iter: 1373 loss: 6.62976561e-07
Iter: 1374 loss: 6.62666537e-07
Iter: 1375 loss: 6.62360435e-07
Iter: 1376 loss: 6.62349237e-07
Iter: 1377 loss: 6.61833781e-07
Iter: 1378 loss: 6.65028153e-07
Iter: 1379 loss: 6.61846116e-07
Iter: 1380 loss: 6.6148948e-07
Iter: 1381 loss: 6.62301e-07
Iter: 1382 loss: 6.61383467e-07
Iter: 1383 loss: 6.60997102e-07
Iter: 1384 loss: 6.62381808e-07
Iter: 1385 loss: 6.60960609e-07
Iter: 1386 loss: 6.60574642e-07
Iter: 1387 loss: 6.60523085e-07
Iter: 1388 loss: 6.60286162e-07
Iter: 1389 loss: 6.59817943e-07
Iter: 1390 loss: 6.61941272e-07
Iter: 1391 loss: 6.59734155e-07
Iter: 1392 loss: 6.59311866e-07
Iter: 1393 loss: 6.5969266e-07
Iter: 1394 loss: 6.59075113e-07
Iter: 1395 loss: 6.5858967e-07
Iter: 1396 loss: 6.61594925e-07
Iter: 1397 loss: 6.58486783e-07
Iter: 1398 loss: 6.58126282e-07
Iter: 1399 loss: 6.5901969e-07
Iter: 1400 loss: 6.57992814e-07
Iter: 1401 loss: 6.57721728e-07
Iter: 1402 loss: 6.57650617e-07
Iter: 1403 loss: 6.57423357e-07
Iter: 1404 loss: 6.57153407e-07
Iter: 1405 loss: 6.57176e-07
Iter: 1406 loss: 6.56740156e-07
Iter: 1407 loss: 6.56610155e-07
Iter: 1408 loss: 6.56418194e-07
Iter: 1409 loss: 6.56042062e-07
Iter: 1410 loss: 6.58576255e-07
Iter: 1411 loss: 6.5595691e-07
Iter: 1412 loss: 6.55649274e-07
Iter: 1413 loss: 6.56178031e-07
Iter: 1414 loss: 6.55434405e-07
Iter: 1415 loss: 6.55058898e-07
Iter: 1416 loss: 6.56996917e-07
Iter: 1417 loss: 6.55032295e-07
Iter: 1418 loss: 6.5475524e-07
Iter: 1419 loss: 6.5487086e-07
Iter: 1420 loss: 6.54542191e-07
Iter: 1421 loss: 6.5408949e-07
Iter: 1422 loss: 6.55219e-07
Iter: 1423 loss: 6.53919926e-07
Iter: 1424 loss: 6.53451e-07
Iter: 1425 loss: 6.53838583e-07
Iter: 1426 loss: 6.53165671e-07
Iter: 1427 loss: 6.52690176e-07
Iter: 1428 loss: 6.55099882e-07
Iter: 1429 loss: 6.52596896e-07
Iter: 1430 loss: 6.52077915e-07
Iter: 1431 loss: 6.5293267e-07
Iter: 1432 loss: 6.51885728e-07
Iter: 1433 loss: 6.51649259e-07
Iter: 1434 loss: 6.51571497e-07
Iter: 1435 loss: 6.51343669e-07
Iter: 1436 loss: 6.51343896e-07
Iter: 1437 loss: 6.51186042e-07
Iter: 1438 loss: 6.50936556e-07
Iter: 1439 loss: 6.50913876e-07
Iter: 1440 loss: 6.50727259e-07
Iter: 1441 loss: 6.50361471e-07
Iter: 1442 loss: 6.51397613e-07
Iter: 1443 loss: 6.5030963e-07
Iter: 1444 loss: 6.499356e-07
Iter: 1445 loss: 6.50526886e-07
Iter: 1446 loss: 6.49836807e-07
Iter: 1447 loss: 6.49463686e-07
Iter: 1448 loss: 6.51779146e-07
Iter: 1449 loss: 6.49495348e-07
Iter: 1450 loss: 6.49193453e-07
Iter: 1451 loss: 6.49236e-07
Iter: 1452 loss: 6.49016e-07
Iter: 1453 loss: 6.4857619e-07
Iter: 1454 loss: 6.4968151e-07
Iter: 1455 loss: 6.48490584e-07
Iter: 1456 loss: 6.48111438e-07
Iter: 1457 loss: 6.48245702e-07
Iter: 1458 loss: 6.4787e-07
Iter: 1459 loss: 6.47434376e-07
Iter: 1460 loss: 6.49773824e-07
Iter: 1461 loss: 6.47298066e-07
Iter: 1462 loss: 6.46889816e-07
Iter: 1463 loss: 6.48144e-07
Iter: 1464 loss: 6.46726676e-07
Iter: 1465 loss: 6.46575131e-07
Iter: 1466 loss: 6.4650817e-07
Iter: 1467 loss: 6.46325248e-07
Iter: 1468 loss: 6.46321553e-07
Iter: 1469 loss: 6.46170065e-07
Iter: 1470 loss: 6.45979696e-07
Iter: 1471 loss: 6.45626415e-07
Iter: 1472 loss: 6.45621526e-07
Iter: 1473 loss: 6.45233456e-07
Iter: 1474 loss: 6.46624244e-07
Iter: 1475 loss: 6.45129319e-07
Iter: 1476 loss: 6.44758927e-07
Iter: 1477 loss: 6.45383807e-07
Iter: 1478 loss: 6.44524221e-07
Iter: 1479 loss: 6.44193051e-07
Iter: 1480 loss: 6.4631439e-07
Iter: 1481 loss: 6.4413382e-07
Iter: 1482 loss: 6.43807e-07
Iter: 1483 loss: 6.44110742e-07
Iter: 1484 loss: 6.43594262e-07
Iter: 1485 loss: 6.43153044e-07
Iter: 1486 loss: 6.44691909e-07
Iter: 1487 loss: 6.42993882e-07
Iter: 1488 loss: 6.42610701e-07
Iter: 1489 loss: 6.42852456e-07
Iter: 1490 loss: 6.42349335e-07
Iter: 1491 loss: 6.41917e-07
Iter: 1492 loss: 6.44145643e-07
Iter: 1493 loss: 6.4184178e-07
Iter: 1494 loss: 6.41462464e-07
Iter: 1495 loss: 6.42187274e-07
Iter: 1496 loss: 6.41301142e-07
Iter: 1497 loss: 6.41162501e-07
Iter: 1498 loss: 6.41131805e-07
Iter: 1499 loss: 6.40899032e-07
Iter: 1500 loss: 6.41142833e-07
Iter: 1501 loss: 6.40806e-07
Iter: 1502 loss: 6.40579e-07
Iter: 1503 loss: 6.40293877e-07
Iter: 1504 loss: 6.40295298e-07
Iter: 1505 loss: 6.39839527e-07
Iter: 1506 loss: 6.41587292e-07
Iter: 1507 loss: 6.39780296e-07
Iter: 1508 loss: 6.39408768e-07
Iter: 1509 loss: 6.39885684e-07
Iter: 1510 loss: 6.39220616e-07
Iter: 1511 loss: 6.38883535e-07
Iter: 1512 loss: 6.40103053e-07
Iter: 1513 loss: 6.38797587e-07
Iter: 1514 loss: 6.3837706e-07
Iter: 1515 loss: 6.39259838e-07
Iter: 1516 loss: 6.38315328e-07
Iter: 1517 loss: 6.37875587e-07
Iter: 1518 loss: 6.39641e-07
Iter: 1519 loss: 6.37791e-07
Iter: 1520 loss: 6.37476148e-07
Iter: 1521 loss: 6.37420214e-07
Iter: 1522 loss: 6.37198866e-07
Iter: 1523 loss: 6.36735251e-07
Iter: 1524 loss: 6.38571748e-07
Iter: 1525 loss: 6.366908e-07
Iter: 1526 loss: 6.3625555e-07
Iter: 1527 loss: 6.36646405e-07
Iter: 1528 loss: 6.36047957e-07
Iter: 1529 loss: 6.35739866e-07
Iter: 1530 loss: 6.35721619e-07
Iter: 1531 loss: 6.35413471e-07
Iter: 1532 loss: 6.36568643e-07
Iter: 1533 loss: 6.35305696e-07
Iter: 1534 loss: 6.35114873e-07
Iter: 1535 loss: 6.34845435e-07
Iter: 1536 loss: 6.34828268e-07
Iter: 1537 loss: 6.34489538e-07
Iter: 1538 loss: 6.35417564e-07
Iter: 1539 loss: 6.34331343e-07
Iter: 1540 loss: 6.33967943e-07
Iter: 1541 loss: 6.34825085e-07
Iter: 1542 loss: 6.33807758e-07
Iter: 1543 loss: 6.33435207e-07
Iter: 1544 loss: 6.34152798e-07
Iter: 1545 loss: 6.33332888e-07
Iter: 1546 loss: 6.32944875e-07
Iter: 1547 loss: 6.34571165e-07
Iter: 1548 loss: 6.32809e-07
Iter: 1549 loss: 6.32451645e-07
Iter: 1550 loss: 6.33850902e-07
Iter: 1551 loss: 6.32386786e-07
Iter: 1552 loss: 6.32051183e-07
Iter: 1553 loss: 6.32076478e-07
Iter: 1554 loss: 6.31811702e-07
Iter: 1555 loss: 6.31355192e-07
Iter: 1556 loss: 6.33202433e-07
Iter: 1557 loss: 6.31303351e-07
Iter: 1558 loss: 6.3092e-07
Iter: 1559 loss: 6.31278226e-07
Iter: 1560 loss: 6.30704051e-07
Iter: 1561 loss: 6.30400621e-07
Iter: 1562 loss: 6.34333674e-07
Iter: 1563 loss: 6.30412956e-07
Iter: 1564 loss: 6.3006064e-07
Iter: 1565 loss: 6.32641616e-07
Iter: 1566 loss: 6.30068826e-07
Iter: 1567 loss: 6.29916826e-07
Iter: 1568 loss: 6.2966069e-07
Iter: 1569 loss: 6.29670069e-07
Iter: 1570 loss: 6.29367548e-07
Iter: 1571 loss: 6.29980832e-07
Iter: 1572 loss: 6.29243345e-07
Iter: 1573 loss: 6.28908083e-07
Iter: 1574 loss: 6.29793419e-07
Iter: 1575 loss: 6.28804798e-07
Iter: 1576 loss: 6.28525186e-07
Iter: 1577 loss: 6.28764496e-07
Iter: 1578 loss: 6.28354826e-07
Iter: 1579 loss: 6.27944246e-07
Iter: 1580 loss: 6.30055354e-07
Iter: 1581 loss: 6.27879672e-07
Iter: 1582 loss: 6.27554869e-07
Iter: 1583 loss: 6.28602038e-07
Iter: 1584 loss: 6.27469035e-07
Iter: 1585 loss: 6.27162251e-07
Iter: 1586 loss: 6.27425038e-07
Iter: 1587 loss: 6.27031909e-07
Iter: 1588 loss: 6.26709266e-07
Iter: 1589 loss: 6.27823454e-07
Iter: 1590 loss: 6.26658107e-07
Iter: 1591 loss: 6.26292092e-07
Iter: 1592 loss: 6.26718e-07
Iter: 1593 loss: 6.26157316e-07
Iter: 1594 loss: 6.25795678e-07
Iter: 1595 loss: 6.27675774e-07
Iter: 1596 loss: 6.258295e-07
Iter: 1597 loss: 6.25604798e-07
Iter: 1598 loss: 6.25590133e-07
Iter: 1599 loss: 6.25449843e-07
Iter: 1600 loss: 6.2520553e-07
Iter: 1601 loss: 6.31383386e-07
Iter: 1602 loss: 6.25209395e-07
Iter: 1603 loss: 6.24910115e-07
Iter: 1604 loss: 6.25204507e-07
Iter: 1605 loss: 6.24791085e-07
Iter: 1606 loss: 6.24451673e-07
Iter: 1607 loss: 6.2617346e-07
Iter: 1608 loss: 6.24378345e-07
Iter: 1609 loss: 6.24073664e-07
Iter: 1610 loss: 6.24255904e-07
Iter: 1611 loss: 6.23946391e-07
Iter: 1612 loss: 6.23601e-07
Iter: 1613 loss: 6.24895506e-07
Iter: 1614 loss: 6.23500341e-07
Iter: 1615 loss: 6.23219648e-07
Iter: 1616 loss: 6.24323093e-07
Iter: 1617 loss: 6.23174174e-07
Iter: 1618 loss: 6.2294464e-07
Iter: 1619 loss: 6.23757728e-07
Iter: 1620 loss: 6.22816515e-07
Iter: 1621 loss: 6.22621258e-07
Iter: 1622 loss: 6.22894049e-07
Iter: 1623 loss: 6.22486766e-07
Iter: 1624 loss: 6.22201924e-07
Iter: 1625 loss: 6.22146445e-07
Iter: 1626 loss: 6.21903041e-07
Iter: 1627 loss: 6.21532195e-07
Iter: 1628 loss: 6.23647679e-07
Iter: 1629 loss: 6.21487857e-07
Iter: 1630 loss: 6.21367803e-07
Iter: 1631 loss: 6.2128322e-07
Iter: 1632 loss: 6.21149e-07
Iter: 1633 loss: 6.20934657e-07
Iter: 1634 loss: 6.2675e-07
Iter: 1635 loss: 6.20902654e-07
Iter: 1636 loss: 6.20651463e-07
Iter: 1637 loss: 6.20745709e-07
Iter: 1638 loss: 6.20510036e-07
Iter: 1639 loss: 6.20264302e-07
Iter: 1640 loss: 6.21894742e-07
Iter: 1641 loss: 6.20231276e-07
Iter: 1642 loss: 6.19989351e-07
Iter: 1643 loss: 6.20175967e-07
Iter: 1644 loss: 6.19853552e-07
Iter: 1645 loss: 6.19515163e-07
Iter: 1646 loss: 6.20785613e-07
Iter: 1647 loss: 6.19489583e-07
Iter: 1648 loss: 6.19233788e-07
Iter: 1649 loss: 6.19930177e-07
Iter: 1650 loss: 6.19141e-07
Iter: 1651 loss: 6.18951219e-07
Iter: 1652 loss: 6.19800176e-07
Iter: 1653 loss: 6.18898639e-07
Iter: 1654 loss: 6.18659612e-07
Iter: 1655 loss: 6.18807576e-07
Iter: 1656 loss: 6.1849255e-07
Iter: 1657 loss: 6.18223112e-07
Iter: 1658 loss: 6.18429169e-07
Iter: 1659 loss: 6.17975786e-07
Iter: 1660 loss: 6.17646492e-07
Iter: 1661 loss: 6.1900414e-07
Iter: 1662 loss: 6.17592491e-07
Iter: 1663 loss: 6.17532862e-07
Iter: 1664 loss: 6.174281e-07
Iter: 1665 loss: 6.17305432e-07
Iter: 1666 loss: 6.17126034e-07
Iter: 1667 loss: 6.17117621e-07
Iter: 1668 loss: 6.16890418e-07
Iter: 1669 loss: 6.16767238e-07
Iter: 1670 loss: 6.16650766e-07
Iter: 1671 loss: 6.16390594e-07
Iter: 1672 loss: 6.18393528e-07
Iter: 1673 loss: 6.16349155e-07
Iter: 1674 loss: 6.1608273e-07
Iter: 1675 loss: 6.16299644e-07
Iter: 1676 loss: 6.15854e-07
Iter: 1677 loss: 6.15552494e-07
Iter: 1678 loss: 6.17069645e-07
Iter: 1679 loss: 6.15524868e-07
Iter: 1680 loss: 6.15212798e-07
Iter: 1681 loss: 6.15824206e-07
Iter: 1682 loss: 6.15068643e-07
Iter: 1683 loss: 6.14791929e-07
Iter: 1684 loss: 6.16096429e-07
Iter: 1685 loss: 6.1466119e-07
Iter: 1686 loss: 6.14442797e-07
Iter: 1687 loss: 6.14670626e-07
Iter: 1688 loss: 6.14322232e-07
Iter: 1689 loss: 6.13915176e-07
Iter: 1690 loss: 6.15022259e-07
Iter: 1691 loss: 6.1388738e-07
Iter: 1692 loss: 6.1347248e-07
Iter: 1693 loss: 6.1410833e-07
Iter: 1694 loss: 6.13342422e-07
Iter: 1695 loss: 6.13216798e-07
Iter: 1696 loss: 6.13179168e-07
Iter: 1697 loss: 6.13012105e-07
Iter: 1698 loss: 6.12817644e-07
Iter: 1699 loss: 6.1278115e-07
Iter: 1700 loss: 6.12542237e-07
Iter: 1701 loss: 6.12192821e-07
Iter: 1702 loss: 6.12188956e-07
Iter: 1703 loss: 6.11899964e-07
Iter: 1704 loss: 6.13867257e-07
Iter: 1705 loss: 6.11805945e-07
Iter: 1706 loss: 6.11546113e-07
Iter: 1707 loss: 6.12036047e-07
Iter: 1708 loss: 6.1138195e-07
Iter: 1709 loss: 6.11039923e-07
Iter: 1710 loss: 6.11999781e-07
Iter: 1711 loss: 6.10946245e-07
Iter: 1712 loss: 6.10636619e-07
Iter: 1713 loss: 6.11442658e-07
Iter: 1714 loss: 6.10549762e-07
Iter: 1715 loss: 6.10269694e-07
Iter: 1716 loss: 6.1177218e-07
Iter: 1717 loss: 6.10228426e-07
Iter: 1718 loss: 6.09979793e-07
Iter: 1719 loss: 6.10170787e-07
Iter: 1720 loss: 6.09876e-07
Iter: 1721 loss: 6.0956836e-07
Iter: 1722 loss: 6.10416123e-07
Iter: 1723 loss: 6.09491565e-07
Iter: 1724 loss: 6.09205244e-07
Iter: 1725 loss: 6.09281415e-07
Iter: 1726 loss: 6.09008055e-07
Iter: 1727 loss: 6.08846335e-07
Iter: 1728 loss: 6.08799326e-07
Iter: 1729 loss: 6.08589062e-07
Iter: 1730 loss: 6.0871065e-07
Iter: 1731 loss: 6.08482765e-07
Iter: 1732 loss: 6.08335654e-07
Iter: 1733 loss: 6.08142784e-07
Iter: 1734 loss: 6.08141534e-07
Iter: 1735 loss: 6.07822813e-07
Iter: 1736 loss: 6.08388689e-07
Iter: 1737 loss: 6.07703953e-07
Iter: 1738 loss: 6.07344873e-07
Iter: 1739 loss: 6.08703658e-07
Iter: 1740 loss: 6.07284619e-07
Iter: 1741 loss: 6.06966296e-07
Iter: 1742 loss: 6.07719e-07
Iter: 1743 loss: 6.06910362e-07
Iter: 1744 loss: 6.06514561e-07
Iter: 1745 loss: 6.07224081e-07
Iter: 1746 loss: 6.06436515e-07
Iter: 1747 loss: 6.06175718e-07
Iter: 1748 loss: 6.07583502e-07
Iter: 1749 loss: 6.06129788e-07
Iter: 1750 loss: 6.05777871e-07
Iter: 1751 loss: 6.06094034e-07
Iter: 1752 loss: 6.05604441e-07
Iter: 1753 loss: 6.05290552e-07
Iter: 1754 loss: 6.06086587e-07
Iter: 1755 loss: 6.05194032e-07
Iter: 1756 loss: 6.04795e-07
Iter: 1757 loss: 6.05067157e-07
Iter: 1758 loss: 6.04552952e-07
Iter: 1759 loss: 6.04450918e-07
Iter: 1760 loss: 6.04370371e-07
Iter: 1761 loss: 6.04178126e-07
Iter: 1762 loss: 6.04277432e-07
Iter: 1763 loss: 6.04081947e-07
Iter: 1764 loss: 6.03899309e-07
Iter: 1765 loss: 6.03624358e-07
Iter: 1766 loss: 6.03612875e-07
Iter: 1767 loss: 6.03301089e-07
Iter: 1768 loss: 6.03962462e-07
Iter: 1769 loss: 6.03189733e-07
Iter: 1770 loss: 6.02849866e-07
Iter: 1771 loss: 6.04646971e-07
Iter: 1772 loss: 6.02815248e-07
Iter: 1773 loss: 6.02538421e-07
Iter: 1774 loss: 6.03299611e-07
Iter: 1775 loss: 6.0247794e-07
Iter: 1776 loss: 6.02195541e-07
Iter: 1777 loss: 6.02559624e-07
Iter: 1778 loss: 6.02054627e-07
Iter: 1779 loss: 6.01811735e-07
Iter: 1780 loss: 6.02905e-07
Iter: 1781 loss: 6.01727493e-07
Iter: 1782 loss: 6.01463114e-07
Iter: 1783 loss: 6.0196237e-07
Iter: 1784 loss: 6.01294289e-07
Iter: 1785 loss: 6.01013312e-07
Iter: 1786 loss: 6.01864144e-07
Iter: 1787 loss: 6.00936914e-07
Iter: 1788 loss: 6.00602903e-07
Iter: 1789 loss: 6.0064707e-07
Iter: 1790 loss: 6.00352e-07
Iter: 1791 loss: 6.00117914e-07
Iter: 1792 loss: 6.00104158e-07
Iter: 1793 loss: 5.99901909e-07
Iter: 1794 loss: 6.00357453e-07
Iter: 1795 loss: 5.99746784e-07
Iter: 1796 loss: 5.99546354e-07
Iter: 1797 loss: 5.99273221e-07
Iter: 1798 loss: 5.99233431e-07
Iter: 1799 loss: 5.98883048e-07
Iter: 1800 loss: 5.99560053e-07
Iter: 1801 loss: 5.9875822e-07
Iter: 1802 loss: 5.98383735e-07
Iter: 1803 loss: 6.00735575e-07
Iter: 1804 loss: 5.98310237e-07
Iter: 1805 loss: 5.98054157e-07
Iter: 1806 loss: 5.98360032e-07
Iter: 1807 loss: 5.9791148e-07
Iter: 1808 loss: 5.97579913e-07
Iter: 1809 loss: 5.98433246e-07
Iter: 1810 loss: 5.97418534e-07
Iter: 1811 loss: 5.9711067e-07
Iter: 1812 loss: 5.98192173e-07
Iter: 1813 loss: 5.97017902e-07
Iter: 1814 loss: 5.96685652e-07
Iter: 1815 loss: 5.97635449e-07
Iter: 1816 loss: 5.96599875e-07
Iter: 1817 loss: 5.96300083e-07
Iter: 1818 loss: 5.96869143e-07
Iter: 1819 loss: 5.96168547e-07
Iter: 1820 loss: 5.95841129e-07
Iter: 1821 loss: 5.96315601e-07
Iter: 1822 loss: 5.95685833e-07
Iter: 1823 loss: 5.95490292e-07
Iter: 1824 loss: 5.95499387e-07
Iter: 1825 loss: 5.95294637e-07
Iter: 1826 loss: 5.96339419e-07
Iter: 1827 loss: 5.9520994e-07
Iter: 1828 loss: 5.95084657e-07
Iter: 1829 loss: 5.94881e-07
Iter: 1830 loss: 5.94849553e-07
Iter: 1831 loss: 5.94601e-07
Iter: 1832 loss: 5.94826702e-07
Iter: 1833 loss: 5.94434482e-07
Iter: 1834 loss: 5.94175276e-07
Iter: 1835 loss: 5.9605469e-07
Iter: 1836 loss: 5.94110588e-07
Iter: 1837 loss: 5.93889183e-07
Iter: 1838 loss: 5.94018218e-07
Iter: 1839 loss: 5.93710411e-07
Iter: 1840 loss: 5.93371851e-07
Iter: 1841 loss: 5.94788162e-07
Iter: 1842 loss: 5.93317736e-07
Iter: 1843 loss: 5.93028744e-07
Iter: 1844 loss: 5.93682216e-07
Iter: 1845 loss: 5.92929155e-07
Iter: 1846 loss: 5.92626691e-07
Iter: 1847 loss: 5.93707568e-07
Iter: 1848 loss: 5.92548645e-07
Iter: 1849 loss: 5.92265337e-07
Iter: 1850 loss: 5.9285918e-07
Iter: 1851 loss: 5.92175127e-07
Iter: 1852 loss: 5.91870105e-07
Iter: 1853 loss: 5.92355889e-07
Iter: 1854 loss: 5.91752325e-07
Iter: 1855 loss: 5.91487151e-07
Iter: 1856 loss: 5.93191828e-07
Iter: 1857 loss: 5.9144935e-07
Iter: 1858 loss: 5.91258356e-07
Iter: 1859 loss: 5.91253183e-07
Iter: 1860 loss: 5.91099706e-07
Iter: 1861 loss: 5.90864261e-07
Iter: 1862 loss: 5.90882109e-07
Iter: 1863 loss: 5.9063791e-07
Iter: 1864 loss: 5.90658715e-07
Iter: 1865 loss: 5.90397804e-07
Iter: 1866 loss: 5.90142122e-07
Iter: 1867 loss: 5.91790354e-07
Iter: 1868 loss: 5.90099148e-07
Iter: 1869 loss: 5.89825675e-07
Iter: 1870 loss: 5.90115633e-07
Iter: 1871 loss: 5.89685555e-07
Iter: 1872 loss: 5.89414412e-07
Iter: 1873 loss: 5.91334356e-07
Iter: 1874 loss: 5.89418335e-07
Iter: 1875 loss: 5.89176125e-07
Iter: 1876 loss: 5.89396336e-07
Iter: 1877 loss: 5.8908671e-07
Iter: 1878 loss: 5.88800958e-07
Iter: 1879 loss: 5.90187369e-07
Iter: 1880 loss: 5.88795217e-07
Iter: 1881 loss: 5.88565968e-07
Iter: 1882 loss: 5.88857915e-07
Iter: 1883 loss: 5.88483886e-07
Iter: 1884 loss: 5.88202852e-07
Iter: 1885 loss: 5.88824378e-07
Iter: 1886 loss: 5.88111789e-07
Iter: 1887 loss: 5.87867362e-07
Iter: 1888 loss: 5.88169939e-07
Iter: 1889 loss: 5.87727243e-07
Iter: 1890 loss: 5.87688305e-07
Iter: 1891 loss: 5.87583941e-07
Iter: 1892 loss: 5.87453087e-07
Iter: 1893 loss: 5.87289946e-07
Iter: 1894 loss: 5.87263457e-07
Iter: 1895 loss: 5.87141813e-07
Iter: 1896 loss: 5.86959345e-07
Iter: 1897 loss: 5.86929957e-07
Iter: 1898 loss: 5.86617602e-07
Iter: 1899 loss: 5.87810064e-07
Iter: 1900 loss: 5.86557121e-07
Iter: 1901 loss: 5.86242436e-07
Iter: 1902 loss: 5.87118336e-07
Iter: 1903 loss: 5.86115505e-07
Iter: 1904 loss: 5.85821113e-07
Iter: 1905 loss: 5.87634418e-07
Iter: 1906 loss: 5.85830549e-07
Iter: 1907 loss: 5.85644557e-07
Iter: 1908 loss: 5.85594e-07
Iter: 1909 loss: 5.85470161e-07
Iter: 1910 loss: 5.8522329e-07
Iter: 1911 loss: 5.86800752e-07
Iter: 1912 loss: 5.85173723e-07
Iter: 1913 loss: 5.84905195e-07
Iter: 1914 loss: 5.85309181e-07
Iter: 1915 loss: 5.84849772e-07
Iter: 1916 loss: 5.84609722e-07
Iter: 1917 loss: 5.8503116e-07
Iter: 1918 loss: 5.84518432e-07
Iter: 1919 loss: 5.84225631e-07
Iter: 1920 loss: 5.84188911e-07
Iter: 1921 loss: 5.84044869e-07
Iter: 1922 loss: 5.83895599e-07
Iter: 1923 loss: 5.83817439e-07
Iter: 1924 loss: 5.83649637e-07
Iter: 1925 loss: 5.83696249e-07
Iter: 1926 loss: 5.83477174e-07
Iter: 1927 loss: 5.83314545e-07
Iter: 1928 loss: 5.83071937e-07
Iter: 1929 loss: 5.83087399e-07
Iter: 1930 loss: 5.82814152e-07
Iter: 1931 loss: 5.84701468e-07
Iter: 1932 loss: 5.82805114e-07
Iter: 1933 loss: 5.82528742e-07
Iter: 1934 loss: 5.82712858e-07
Iter: 1935 loss: 5.8241551e-07
Iter: 1936 loss: 5.82163921e-07
Iter: 1937 loss: 5.83363885e-07
Iter: 1938 loss: 5.82117764e-07
Iter: 1939 loss: 5.81779886e-07
Iter: 1940 loss: 5.82371968e-07
Iter: 1941 loss: 5.81646759e-07
Iter: 1942 loss: 5.81364588e-07
Iter: 1943 loss: 5.83258725e-07
Iter: 1944 loss: 5.81321729e-07
Iter: 1945 loss: 5.81081395e-07
Iter: 1946 loss: 5.81340373e-07
Iter: 1947 loss: 5.80970095e-07
Iter: 1948 loss: 5.80754545e-07
Iter: 1949 loss: 5.81614e-07
Iter: 1950 loss: 5.8062875e-07
Iter: 1951 loss: 5.80412e-07
Iter: 1952 loss: 5.80566052e-07
Iter: 1953 loss: 5.8027058e-07
Iter: 1954 loss: 5.79948335e-07
Iter: 1955 loss: 5.81360894e-07
Iter: 1956 loss: 5.79918492e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script69
+ '[' -r STOP.script69 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi3_phi3/500_500_500_500_1
