+ RUN=1
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ LAYERS=500_500_500_500_1
+ case $RUN in
+ PSI='-2 -1'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output61
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output69
+ for fn in f2
+ case $fn in
+ OPT=--alpha
+ for psi in $PSI
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0
+ date
Sat Nov  7 12:47:25 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ee9e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ee9e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eed7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ee29730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eed7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6edfc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6edfc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6edd06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eed7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ed7b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eed7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ed3ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ed3a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ed3ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ecef7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ecd4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ec79598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ec4f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ebf2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ebf2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ec0c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6ebd79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eb88950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eb6cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eb39488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eade950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eade840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eaee8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eab51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eaaeb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6eab5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb585cce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb585cc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb585a7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb585628c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb584f1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.5308144e-06
Iter: 2 loss: 6.07598395e-06
Iter: 3 loss: 6.04768047e-06
Iter: 4 loss: 5.45925604e-06
Iter: 5 loss: 6.39578411e-06
Iter: 6 loss: 5.18533761e-06
Iter: 7 loss: 4.92383151e-06
Iter: 8 loss: 4.74390345e-06
Iter: 9 loss: 4.64905588e-06
Iter: 10 loss: 4.55820737e-06
Iter: 11 loss: 4.47305729e-06
Iter: 12 loss: 4.37013387e-06
Iter: 13 loss: 4.34230969e-06
Iter: 14 loss: 4.27882651e-06
Iter: 15 loss: 4.18473564e-06
Iter: 16 loss: 4.04499042e-06
Iter: 17 loss: 4.0417226e-06
Iter: 18 loss: 4.07989683e-06
Iter: 19 loss: 3.96610858e-06
Iter: 20 loss: 3.92020684e-06
Iter: 21 loss: 3.77624656e-06
Iter: 22 loss: 4.0028317e-06
Iter: 23 loss: 3.67620078e-06
Iter: 24 loss: 3.50537312e-06
Iter: 25 loss: 6.05323157e-06
Iter: 26 loss: 3.5052542e-06
Iter: 27 loss: 3.37342362e-06
Iter: 28 loss: 3.86214606e-06
Iter: 29 loss: 3.34106517e-06
Iter: 30 loss: 3.2825576e-06
Iter: 31 loss: 3.32286709e-06
Iter: 32 loss: 3.24598068e-06
Iter: 33 loss: 3.20029881e-06
Iter: 34 loss: 3.11003691e-06
Iter: 35 loss: 4.87798388e-06
Iter: 36 loss: 3.10908399e-06
Iter: 37 loss: 3.04274067e-06
Iter: 38 loss: 3.62001015e-06
Iter: 39 loss: 3.03922843e-06
Iter: 40 loss: 2.98251666e-06
Iter: 41 loss: 3.0076003e-06
Iter: 42 loss: 2.9439741e-06
Iter: 43 loss: 2.90512298e-06
Iter: 44 loss: 2.90427579e-06
Iter: 45 loss: 2.85702231e-06
Iter: 46 loss: 2.85737838e-06
Iter: 47 loss: 2.81933944e-06
Iter: 48 loss: 2.75992193e-06
Iter: 49 loss: 2.74827107e-06
Iter: 50 loss: 2.70863552e-06
Iter: 51 loss: 2.66619372e-06
Iter: 52 loss: 3.2128014e-06
Iter: 53 loss: 2.6659086e-06
Iter: 54 loss: 2.60750767e-06
Iter: 55 loss: 2.52948257e-06
Iter: 56 loss: 2.52516475e-06
Iter: 57 loss: 2.46482909e-06
Iter: 58 loss: 2.93123503e-06
Iter: 59 loss: 2.46042464e-06
Iter: 60 loss: 2.39691281e-06
Iter: 61 loss: 2.59255285e-06
Iter: 62 loss: 2.3782668e-06
Iter: 63 loss: 2.33814194e-06
Iter: 64 loss: 2.64965684e-06
Iter: 65 loss: 2.33523133e-06
Iter: 66 loss: 2.30432215e-06
Iter: 67 loss: 2.33000651e-06
Iter: 68 loss: 2.28591216e-06
Iter: 69 loss: 2.26730936e-06
Iter: 70 loss: 2.23786401e-06
Iter: 71 loss: 2.23754228e-06
Iter: 72 loss: 2.20189486e-06
Iter: 73 loss: 2.47681328e-06
Iter: 74 loss: 2.1993385e-06
Iter: 75 loss: 2.17764818e-06
Iter: 76 loss: 2.1816868e-06
Iter: 77 loss: 2.16144872e-06
Iter: 78 loss: 2.12516034e-06
Iter: 79 loss: 2.45529372e-06
Iter: 80 loss: 2.12350869e-06
Iter: 81 loss: 2.08750521e-06
Iter: 82 loss: 2.07696212e-06
Iter: 83 loss: 2.05530523e-06
Iter: 84 loss: 2.02173942e-06
Iter: 85 loss: 2.01209536e-06
Iter: 86 loss: 1.99179203e-06
Iter: 87 loss: 1.98826069e-06
Iter: 88 loss: 1.97197051e-06
Iter: 89 loss: 1.95640223e-06
Iter: 90 loss: 1.94448421e-06
Iter: 91 loss: 1.93949745e-06
Iter: 92 loss: 1.92259563e-06
Iter: 93 loss: 1.94773747e-06
Iter: 94 loss: 1.91454592e-06
Iter: 95 loss: 1.88684771e-06
Iter: 96 loss: 1.98775979e-06
Iter: 97 loss: 1.87990372e-06
Iter: 98 loss: 1.8737062e-06
Iter: 99 loss: 1.91593176e-06
Iter: 100 loss: 1.87303226e-06
Iter: 101 loss: 1.86437433e-06
Iter: 102 loss: 1.84396174e-06
Iter: 103 loss: 2.07850985e-06
Iter: 104 loss: 1.84204725e-06
Iter: 105 loss: 1.82140957e-06
Iter: 106 loss: 1.889842e-06
Iter: 107 loss: 1.81570431e-06
Iter: 108 loss: 1.79819517e-06
Iter: 109 loss: 1.7860724e-06
Iter: 110 loss: 1.77975221e-06
Iter: 111 loss: 1.75575894e-06
Iter: 112 loss: 2.09410246e-06
Iter: 113 loss: 1.75574087e-06
Iter: 114 loss: 1.73952571e-06
Iter: 115 loss: 1.95262555e-06
Iter: 116 loss: 1.73941044e-06
Iter: 117 loss: 1.72697969e-06
Iter: 118 loss: 1.70727162e-06
Iter: 119 loss: 1.70708563e-06
Iter: 120 loss: 1.69667942e-06
Iter: 121 loss: 1.82037343e-06
Iter: 122 loss: 1.69653526e-06
Iter: 123 loss: 1.69126338e-06
Iter: 124 loss: 1.69124849e-06
Iter: 125 loss: 1.68621295e-06
Iter: 126 loss: 1.67390181e-06
Iter: 127 loss: 1.80190182e-06
Iter: 128 loss: 1.67247276e-06
Iter: 129 loss: 1.66385155e-06
Iter: 130 loss: 1.66557584e-06
Iter: 131 loss: 1.65742608e-06
Iter: 132 loss: 1.64765675e-06
Iter: 133 loss: 1.64732614e-06
Iter: 134 loss: 1.63696279e-06
Iter: 135 loss: 1.6286308e-06
Iter: 136 loss: 1.62544916e-06
Iter: 137 loss: 1.61549303e-06
Iter: 138 loss: 1.61001162e-06
Iter: 139 loss: 1.6055684e-06
Iter: 140 loss: 1.59860122e-06
Iter: 141 loss: 1.59564206e-06
Iter: 142 loss: 1.5913555e-06
Iter: 143 loss: 1.58171247e-06
Iter: 144 loss: 1.71253532e-06
Iter: 145 loss: 1.58112834e-06
Iter: 146 loss: 1.56785791e-06
Iter: 147 loss: 1.55954604e-06
Iter: 148 loss: 1.55428427e-06
Iter: 149 loss: 1.5448577e-06
Iter: 150 loss: 1.544724e-06
Iter: 151 loss: 1.53644737e-06
Iter: 152 loss: 1.53520796e-06
Iter: 153 loss: 1.5293972e-06
Iter: 154 loss: 1.52772736e-06
Iter: 155 loss: 1.52365874e-06
Iter: 156 loss: 1.52068912e-06
Iter: 157 loss: 1.51648192e-06
Iter: 158 loss: 1.51627114e-06
Iter: 159 loss: 1.51049926e-06
Iter: 160 loss: 1.49956793e-06
Iter: 161 loss: 1.73922444e-06
Iter: 162 loss: 1.49952029e-06
Iter: 163 loss: 1.50118865e-06
Iter: 164 loss: 1.49334869e-06
Iter: 165 loss: 1.48961647e-06
Iter: 166 loss: 1.47835965e-06
Iter: 167 loss: 1.51196502e-06
Iter: 168 loss: 1.47272067e-06
Iter: 169 loss: 1.4769679e-06
Iter: 170 loss: 1.46758907e-06
Iter: 171 loss: 1.46365323e-06
Iter: 172 loss: 1.46210925e-06
Iter: 173 loss: 1.45995591e-06
Iter: 174 loss: 1.45606805e-06
Iter: 175 loss: 1.47885066e-06
Iter: 176 loss: 1.45558215e-06
Iter: 177 loss: 1.45039076e-06
Iter: 178 loss: 1.44876685e-06
Iter: 179 loss: 1.44573937e-06
Iter: 180 loss: 1.44272201e-06
Iter: 181 loss: 1.43734178e-06
Iter: 182 loss: 1.56889723e-06
Iter: 183 loss: 1.43733962e-06
Iter: 184 loss: 1.43116824e-06
Iter: 185 loss: 1.43778527e-06
Iter: 186 loss: 1.4277972e-06
Iter: 187 loss: 1.42157228e-06
Iter: 188 loss: 1.41794862e-06
Iter: 189 loss: 1.41533792e-06
Iter: 190 loss: 1.41425767e-06
Iter: 191 loss: 1.41054124e-06
Iter: 192 loss: 1.40807936e-06
Iter: 193 loss: 1.40268526e-06
Iter: 194 loss: 1.48173149e-06
Iter: 195 loss: 1.40243571e-06
Iter: 196 loss: 1.39498798e-06
Iter: 197 loss: 1.40299699e-06
Iter: 198 loss: 1.39094391e-06
Iter: 199 loss: 1.38945074e-06
Iter: 200 loss: 1.38650398e-06
Iter: 201 loss: 1.38511166e-06
Iter: 202 loss: 1.38089331e-06
Iter: 203 loss: 1.39768292e-06
Iter: 204 loss: 1.37918687e-06
Iter: 205 loss: 1.37724373e-06
Iter: 206 loss: 1.3761537e-06
Iter: 207 loss: 1.37385837e-06
Iter: 208 loss: 1.37859911e-06
Iter: 209 loss: 1.37290738e-06
Iter: 210 loss: 1.37111147e-06
Iter: 211 loss: 1.36907772e-06
Iter: 212 loss: 1.36882363e-06
Iter: 213 loss: 1.3646345e-06
Iter: 214 loss: 1.39440886e-06
Iter: 215 loss: 1.36426e-06
Iter: 216 loss: 1.36170843e-06
Iter: 217 loss: 1.35845085e-06
Iter: 218 loss: 1.35821574e-06
Iter: 219 loss: 1.352754e-06
Iter: 220 loss: 1.34209131e-06
Iter: 221 loss: 1.55662121e-06
Iter: 222 loss: 1.34203719e-06
Iter: 223 loss: 1.3481997e-06
Iter: 224 loss: 1.33824369e-06
Iter: 225 loss: 1.33500248e-06
Iter: 226 loss: 1.34028255e-06
Iter: 227 loss: 1.33354388e-06
Iter: 228 loss: 1.33110245e-06
Iter: 229 loss: 1.32652349e-06
Iter: 230 loss: 1.43260104e-06
Iter: 231 loss: 1.32653281e-06
Iter: 232 loss: 1.32540208e-06
Iter: 233 loss: 1.32456569e-06
Iter: 234 loss: 1.32229536e-06
Iter: 235 loss: 1.3198844e-06
Iter: 236 loss: 1.31945148e-06
Iter: 237 loss: 1.31680542e-06
Iter: 238 loss: 1.3202623e-06
Iter: 239 loss: 1.31547063e-06
Iter: 240 loss: 1.31350407e-06
Iter: 241 loss: 1.31350157e-06
Iter: 242 loss: 1.31107163e-06
Iter: 243 loss: 1.3046922e-06
Iter: 244 loss: 1.35376604e-06
Iter: 245 loss: 1.30347098e-06
Iter: 246 loss: 1.30354658e-06
Iter: 247 loss: 1.30146827e-06
Iter: 248 loss: 1.29953264e-06
Iter: 249 loss: 1.2979126e-06
Iter: 250 loss: 1.29735349e-06
Iter: 251 loss: 1.29381124e-06
Iter: 252 loss: 1.28732631e-06
Iter: 253 loss: 1.44410319e-06
Iter: 254 loss: 1.28736747e-06
Iter: 255 loss: 1.28360716e-06
Iter: 256 loss: 1.28350439e-06
Iter: 257 loss: 1.28208728e-06
Iter: 258 loss: 1.28199167e-06
Iter: 259 loss: 1.28073395e-06
Iter: 260 loss: 1.27843316e-06
Iter: 261 loss: 1.33254889e-06
Iter: 262 loss: 1.27844874e-06
Iter: 263 loss: 1.27659212e-06
Iter: 264 loss: 1.27274711e-06
Iter: 265 loss: 1.34001846e-06
Iter: 266 loss: 1.27265389e-06
Iter: 267 loss: 1.26787199e-06
Iter: 268 loss: 1.31695049e-06
Iter: 269 loss: 1.26770715e-06
Iter: 270 loss: 1.26456473e-06
Iter: 271 loss: 1.27542546e-06
Iter: 272 loss: 1.26375926e-06
Iter: 273 loss: 1.25826602e-06
Iter: 274 loss: 1.26220971e-06
Iter: 275 loss: 1.25482325e-06
Iter: 276 loss: 1.25335418e-06
Iter: 277 loss: 1.27605767e-06
Iter: 278 loss: 1.25335214e-06
Iter: 279 loss: 1.25199119e-06
Iter: 280 loss: 1.25259805e-06
Iter: 281 loss: 1.25105862e-06
Iter: 282 loss: 1.24978817e-06
Iter: 283 loss: 1.24932171e-06
Iter: 284 loss: 1.24857934e-06
Iter: 285 loss: 1.24778569e-06
Iter: 286 loss: 1.24752387e-06
Iter: 287 loss: 1.24680491e-06
Iter: 288 loss: 1.24436747e-06
Iter: 289 loss: 1.24524604e-06
Iter: 290 loss: 1.24210601e-06
Iter: 291 loss: 1.23893642e-06
Iter: 292 loss: 1.23892971e-06
Iter: 293 loss: 1.23678581e-06
Iter: 294 loss: 1.25864551e-06
Iter: 295 loss: 1.23671907e-06
Iter: 296 loss: 1.23422853e-06
Iter: 297 loss: 1.22885808e-06
Iter: 298 loss: 1.3116944e-06
Iter: 299 loss: 1.22865231e-06
Iter: 300 loss: 1.22586778e-06
Iter: 301 loss: 1.25755855e-06
Iter: 302 loss: 1.22582799e-06
Iter: 303 loss: 1.22390543e-06
Iter: 304 loss: 1.21996732e-06
Iter: 305 loss: 1.28743204e-06
Iter: 306 loss: 1.21985818e-06
Iter: 307 loss: 1.21743233e-06
Iter: 308 loss: 1.2172502e-06
Iter: 309 loss: 1.21608878e-06
Iter: 310 loss: 1.21598009e-06
Iter: 311 loss: 1.21489779e-06
Iter: 312 loss: 1.21256971e-06
Iter: 313 loss: 1.24868347e-06
Iter: 314 loss: 1.21247228e-06
Iter: 315 loss: 1.21179278e-06
Iter: 316 loss: 1.21165488e-06
Iter: 317 loss: 1.21064318e-06
Iter: 318 loss: 1.20809466e-06
Iter: 319 loss: 1.23259645e-06
Iter: 320 loss: 1.20776735e-06
Iter: 321 loss: 1.20713048e-06
Iter: 322 loss: 1.20665413e-06
Iter: 323 loss: 1.20565369e-06
Iter: 324 loss: 1.20432674e-06
Iter: 325 loss: 1.20423033e-06
Iter: 326 loss: 1.20210302e-06
Iter: 327 loss: 1.20290554e-06
Iter: 328 loss: 1.20061713e-06
Iter: 329 loss: 1.19623019e-06
Iter: 330 loss: 1.20847062e-06
Iter: 331 loss: 1.19483877e-06
Iter: 332 loss: 1.19317178e-06
Iter: 333 loss: 1.19439721e-06
Iter: 334 loss: 1.19213303e-06
Iter: 335 loss: 1.18980472e-06
Iter: 336 loss: 1.18995149e-06
Iter: 337 loss: 1.18799733e-06
Iter: 338 loss: 1.18653759e-06
Iter: 339 loss: 1.19171511e-06
Iter: 340 loss: 1.18613093e-06
Iter: 341 loss: 1.18489379e-06
Iter: 342 loss: 1.18489788e-06
Iter: 343 loss: 1.18352284e-06
Iter: 344 loss: 1.18489311e-06
Iter: 345 loss: 1.18276398e-06
Iter: 346 loss: 1.18169021e-06
Iter: 347 loss: 1.17944182e-06
Iter: 348 loss: 1.22112942e-06
Iter: 349 loss: 1.17942682e-06
Iter: 350 loss: 1.17609841e-06
Iter: 351 loss: 1.21258449e-06
Iter: 352 loss: 1.17605134e-06
Iter: 353 loss: 1.17506511e-06
Iter: 354 loss: 1.17475201e-06
Iter: 355 loss: 1.17418926e-06
Iter: 356 loss: 1.17251579e-06
Iter: 357 loss: 1.18431069e-06
Iter: 358 loss: 1.17233117e-06
Iter: 359 loss: 1.17108857e-06
Iter: 360 loss: 1.16866022e-06
Iter: 361 loss: 1.2209058e-06
Iter: 362 loss: 1.16867295e-06
Iter: 363 loss: 1.16902982e-06
Iter: 364 loss: 1.16774731e-06
Iter: 365 loss: 1.16734213e-06
Iter: 366 loss: 1.16614342e-06
Iter: 367 loss: 1.16702495e-06
Iter: 368 loss: 1.16503679e-06
Iter: 369 loss: 1.16291744e-06
Iter: 370 loss: 1.1820639e-06
Iter: 371 loss: 1.16281262e-06
Iter: 372 loss: 1.16115859e-06
Iter: 373 loss: 1.16809736e-06
Iter: 374 loss: 1.16080264e-06
Iter: 375 loss: 1.15922307e-06
Iter: 376 loss: 1.16047499e-06
Iter: 377 loss: 1.15830539e-06
Iter: 378 loss: 1.15601881e-06
Iter: 379 loss: 1.166846e-06
Iter: 380 loss: 1.15564342e-06
Iter: 381 loss: 1.15350304e-06
Iter: 382 loss: 1.18029573e-06
Iter: 383 loss: 1.153516e-06
Iter: 384 loss: 1.15246735e-06
Iter: 385 loss: 1.15040393e-06
Iter: 386 loss: 1.18968705e-06
Iter: 387 loss: 1.15041121e-06
Iter: 388 loss: 1.14979366e-06
Iter: 389 loss: 1.14932868e-06
Iter: 390 loss: 1.14840748e-06
Iter: 391 loss: 1.14643956e-06
Iter: 392 loss: 1.17807667e-06
Iter: 393 loss: 1.14634634e-06
Iter: 394 loss: 1.14516115e-06
Iter: 395 loss: 1.15229693e-06
Iter: 396 loss: 1.14503723e-06
Iter: 397 loss: 1.14413501e-06
Iter: 398 loss: 1.14413979e-06
Iter: 399 loss: 1.1436e-06
Iter: 400 loss: 1.1424579e-06
Iter: 401 loss: 1.15902617e-06
Iter: 402 loss: 1.1423881e-06
Iter: 403 loss: 1.14103273e-06
Iter: 404 loss: 1.13856197e-06
Iter: 405 loss: 1.19518927e-06
Iter: 406 loss: 1.13857652e-06
Iter: 407 loss: 1.14047566e-06
Iter: 408 loss: 1.13755618e-06
Iter: 409 loss: 1.13660633e-06
Iter: 410 loss: 1.13567296e-06
Iter: 411 loss: 1.13553017e-06
Iter: 412 loss: 1.13407714e-06
Iter: 413 loss: 1.13316355e-06
Iter: 414 loss: 1.13258591e-06
Iter: 415 loss: 1.13034957e-06
Iter: 416 loss: 1.13835154e-06
Iter: 417 loss: 1.12978944e-06
Iter: 418 loss: 1.12892019e-06
Iter: 419 loss: 1.12860323e-06
Iter: 420 loss: 1.12783505e-06
Iter: 421 loss: 1.12656437e-06
Iter: 422 loss: 1.12655812e-06
Iter: 423 loss: 1.12565385e-06
Iter: 424 loss: 1.1322677e-06
Iter: 425 loss: 1.12556768e-06
Iter: 426 loss: 1.12447719e-06
Iter: 427 loss: 1.12687667e-06
Iter: 428 loss: 1.12401688e-06
Iter: 429 loss: 1.12326632e-06
Iter: 430 loss: 1.12247403e-06
Iter: 431 loss: 1.12234784e-06
Iter: 432 loss: 1.12210705e-06
Iter: 433 loss: 1.1217852e-06
Iter: 434 loss: 1.12124758e-06
Iter: 435 loss: 1.1194561e-06
Iter: 436 loss: 1.12180828e-06
Iter: 437 loss: 1.11821259e-06
Iter: 438 loss: 1.11535701e-06
Iter: 439 loss: 1.12085365e-06
Iter: 440 loss: 1.11414033e-06
Iter: 441 loss: 1.11122267e-06
Iter: 442 loss: 1.13598026e-06
Iter: 443 loss: 1.1110551e-06
Iter: 444 loss: 1.11037946e-06
Iter: 445 loss: 1.11034922e-06
Iter: 446 loss: 1.10949975e-06
Iter: 447 loss: 1.10983422e-06
Iter: 448 loss: 1.10887595e-06
Iter: 449 loss: 1.10828705e-06
Iter: 450 loss: 1.10830069e-06
Iter: 451 loss: 1.10778433e-06
Iter: 452 loss: 1.10684402e-06
Iter: 453 loss: 1.10718793e-06
Iter: 454 loss: 1.10620454e-06
Iter: 455 loss: 1.10529891e-06
Iter: 456 loss: 1.1053105e-06
Iter: 457 loss: 1.10434235e-06
Iter: 458 loss: 1.10544579e-06
Iter: 459 loss: 1.10382393e-06
Iter: 460 loss: 1.10290046e-06
Iter: 461 loss: 1.1014431e-06
Iter: 462 loss: 1.10143799e-06
Iter: 463 loss: 1.10148881e-06
Iter: 464 loss: 1.10074802e-06
Iter: 465 loss: 1.10024939e-06
Iter: 466 loss: 1.09897167e-06
Iter: 467 loss: 1.11059558e-06
Iter: 468 loss: 1.09878636e-06
Iter: 469 loss: 1.09717621e-06
Iter: 470 loss: 1.09800794e-06
Iter: 471 loss: 1.09614916e-06
Iter: 472 loss: 1.09540838e-06
Iter: 473 loss: 1.09529333e-06
Iter: 474 loss: 1.09432722e-06
Iter: 475 loss: 1.096083e-06
Iter: 476 loss: 1.09387929e-06
Iter: 477 loss: 1.09342272e-06
Iter: 478 loss: 1.09282337e-06
Iter: 479 loss: 1.09278221e-06
Iter: 480 loss: 1.09175437e-06
Iter: 481 loss: 1.09252642e-06
Iter: 482 loss: 1.09111784e-06
Iter: 483 loss: 1.09029929e-06
Iter: 484 loss: 1.09015934e-06
Iter: 485 loss: 1.08976712e-06
Iter: 486 loss: 1.08849201e-06
Iter: 487 loss: 1.08877157e-06
Iter: 488 loss: 1.08722907e-06
Iter: 489 loss: 1.08459085e-06
Iter: 490 loss: 1.10579299e-06
Iter: 491 loss: 1.08443669e-06
Iter: 492 loss: 1.08416612e-06
Iter: 493 loss: 1.08366817e-06
Iter: 494 loss: 1.08304914e-06
Iter: 495 loss: 1.08253846e-06
Iter: 496 loss: 1.08233917e-06
Iter: 497 loss: 1.08178574e-06
Iter: 498 loss: 1.0854e-06
Iter: 499 loss: 1.08175561e-06
Iter: 500 loss: 1.08121765e-06
Iter: 501 loss: 1.08340691e-06
Iter: 502 loss: 1.08110532e-06
Iter: 503 loss: 1.08066524e-06
Iter: 504 loss: 1.07966343e-06
Iter: 505 loss: 1.09367295e-06
Iter: 506 loss: 1.07958408e-06
Iter: 507 loss: 1.0785908e-06
Iter: 508 loss: 1.08208587e-06
Iter: 509 loss: 1.0783134e-06
Iter: 510 loss: 1.07765447e-06
Iter: 511 loss: 1.07763458e-06
Iter: 512 loss: 1.07681933e-06
Iter: 513 loss: 1.07602477e-06
Iter: 514 loss: 1.07584867e-06
Iter: 515 loss: 1.07499488e-06
Iter: 516 loss: 1.07347273e-06
Iter: 517 loss: 1.07347535e-06
Iter: 518 loss: 1.07237713e-06
Iter: 519 loss: 1.07235542e-06
Iter: 520 loss: 1.07165647e-06
Iter: 521 loss: 1.07165954e-06
Iter: 522 loss: 1.07106939e-06
Iter: 523 loss: 1.06946254e-06
Iter: 524 loss: 1.08145787e-06
Iter: 525 loss: 1.06912557e-06
Iter: 526 loss: 1.06878144e-06
Iter: 527 loss: 1.0686407e-06
Iter: 528 loss: 1.06802122e-06
Iter: 529 loss: 1.06835387e-06
Iter: 530 loss: 1.06763287e-06
Iter: 531 loss: 1.06703646e-06
Iter: 532 loss: 1.06689049e-06
Iter: 533 loss: 1.06655023e-06
Iter: 534 loss: 1.0656986e-06
Iter: 535 loss: 1.07621736e-06
Iter: 536 loss: 1.0657235e-06
Iter: 537 loss: 1.06521566e-06
Iter: 538 loss: 1.06385687e-06
Iter: 539 loss: 1.07478036e-06
Iter: 540 loss: 1.06363734e-06
Iter: 541 loss: 1.06230095e-06
Iter: 542 loss: 1.07437018e-06
Iter: 543 loss: 1.06225934e-06
Iter: 544 loss: 1.06127163e-06
Iter: 545 loss: 1.07226651e-06
Iter: 546 loss: 1.06124639e-06
Iter: 547 loss: 1.06031575e-06
Iter: 548 loss: 1.05862819e-06
Iter: 549 loss: 1.05864092e-06
Iter: 550 loss: 1.05766435e-06
Iter: 551 loss: 1.0617099e-06
Iter: 552 loss: 1.05749166e-06
Iter: 553 loss: 1.05663094e-06
Iter: 554 loss: 1.05782021e-06
Iter: 555 loss: 1.05624486e-06
Iter: 556 loss: 1.05600088e-06
Iter: 557 loss: 1.05578602e-06
Iter: 558 loss: 1.0553556e-06
Iter: 559 loss: 1.05414063e-06
Iter: 560 loss: 1.05918127e-06
Iter: 561 loss: 1.05365746e-06
Iter: 562 loss: 1.05214303e-06
Iter: 563 loss: 1.06065647e-06
Iter: 564 loss: 1.05193658e-06
Iter: 565 loss: 1.05089589e-06
Iter: 566 loss: 1.05106631e-06
Iter: 567 loss: 1.05008905e-06
Iter: 568 loss: 1.04903893e-06
Iter: 569 loss: 1.04891774e-06
Iter: 570 loss: 1.0483908e-06
Iter: 571 loss: 1.04742185e-06
Iter: 572 loss: 1.07080052e-06
Iter: 573 loss: 1.04741457e-06
Iter: 574 loss: 1.04635319e-06
Iter: 575 loss: 1.04556932e-06
Iter: 576 loss: 1.04520848e-06
Iter: 577 loss: 1.04625519e-06
Iter: 578 loss: 1.04468768e-06
Iter: 579 loss: 1.0443066e-06
Iter: 580 loss: 1.0436147e-06
Iter: 581 loss: 1.04358355e-06
Iter: 582 loss: 1.04291689e-06
Iter: 583 loss: 1.04564435e-06
Iter: 584 loss: 1.04273192e-06
Iter: 585 loss: 1.04252763e-06
Iter: 586 loss: 1.04245919e-06
Iter: 587 loss: 1.04220567e-06
Iter: 588 loss: 1.04144578e-06
Iter: 589 loss: 1.04213359e-06
Iter: 590 loss: 1.04079515e-06
Iter: 591 loss: 1.03933303e-06
Iter: 592 loss: 1.04475464e-06
Iter: 593 loss: 1.03894899e-06
Iter: 594 loss: 1.03824618e-06
Iter: 595 loss: 1.03815717e-06
Iter: 596 loss: 1.03727893e-06
Iter: 597 loss: 1.03600087e-06
Iter: 598 loss: 1.03595039e-06
Iter: 599 loss: 1.03507614e-06
Iter: 600 loss: 1.03522189e-06
Iter: 601 loss: 1.03441391e-06
Iter: 602 loss: 1.0344811e-06
Iter: 603 loss: 1.03392972e-06
Iter: 604 loss: 1.03356206e-06
Iter: 605 loss: 1.03311913e-06
Iter: 606 loss: 1.0330964e-06
Iter: 607 loss: 1.03259788e-06
Iter: 608 loss: 1.03131811e-06
Iter: 609 loss: 1.0408769e-06
Iter: 610 loss: 1.03106186e-06
Iter: 611 loss: 1.03024854e-06
Iter: 612 loss: 1.03011598e-06
Iter: 613 loss: 1.02953504e-06
Iter: 614 loss: 1.02953163e-06
Iter: 615 loss: 1.02909985e-06
Iter: 616 loss: 1.0280296e-06
Iter: 617 loss: 1.03897787e-06
Iter: 618 loss: 1.02788692e-06
Iter: 619 loss: 1.02693116e-06
Iter: 620 loss: 1.03325397e-06
Iter: 621 loss: 1.02682463e-06
Iter: 622 loss: 1.0253998e-06
Iter: 623 loss: 1.02705906e-06
Iter: 624 loss: 1.02462093e-06
Iter: 625 loss: 1.02379647e-06
Iter: 626 loss: 1.02475042e-06
Iter: 627 loss: 1.02334525e-06
Iter: 628 loss: 1.02244519e-06
Iter: 629 loss: 1.02249476e-06
Iter: 630 loss: 1.02179115e-06
Iter: 631 loss: 1.02110869e-06
Iter: 632 loss: 1.02097681e-06
Iter: 633 loss: 1.02057891e-06
Iter: 634 loss: 1.02026831e-06
Iter: 635 loss: 1.02016975e-06
Iter: 636 loss: 1.01974592e-06
Iter: 637 loss: 1.02022614e-06
Iter: 638 loss: 1.01952787e-06
Iter: 639 loss: 1.01884905e-06
Iter: 640 loss: 1.02293848e-06
Iter: 641 loss: 1.01877777e-06
Iter: 642 loss: 1.01841715e-06
Iter: 643 loss: 1.01740784e-06
Iter: 644 loss: 1.02120634e-06
Iter: 645 loss: 1.0169955e-06
Iter: 646 loss: 1.01554224e-06
Iter: 647 loss: 1.0289782e-06
Iter: 648 loss: 1.01549585e-06
Iter: 649 loss: 1.01486921e-06
Iter: 650 loss: 1.01477872e-06
Iter: 651 loss: 1.01442492e-06
Iter: 652 loss: 1.01337946e-06
Iter: 653 loss: 1.01781984e-06
Iter: 654 loss: 1.01297371e-06
Iter: 655 loss: 1.01382238e-06
Iter: 656 loss: 1.01259343e-06
Iter: 657 loss: 1.01228807e-06
Iter: 658 loss: 1.01155297e-06
Iter: 659 loss: 1.01726016e-06
Iter: 660 loss: 1.011422e-06
Iter: 661 loss: 1.01079081e-06
Iter: 662 loss: 1.01688534e-06
Iter: 663 loss: 1.01074284e-06
Iter: 664 loss: 1.01041633e-06
Iter: 665 loss: 1.01043167e-06
Iter: 666 loss: 1.009985e-06
Iter: 667 loss: 1.00926911e-06
Iter: 668 loss: 1.00926559e-06
Iter: 669 loss: 1.00855027e-06
Iter: 670 loss: 1.0108887e-06
Iter: 671 loss: 1.00833131e-06
Iter: 672 loss: 1.00799207e-06
Iter: 673 loss: 1.01273781e-06
Iter: 674 loss: 1.00799048e-06
Iter: 675 loss: 1.00752459e-06
Iter: 676 loss: 1.00626335e-06
Iter: 677 loss: 1.01539513e-06
Iter: 678 loss: 1.00599357e-06
Iter: 679 loss: 1.0049788e-06
Iter: 680 loss: 1.00674129e-06
Iter: 681 loss: 1.00450654e-06
Iter: 682 loss: 1.00340253e-06
Iter: 683 loss: 1.01221133e-06
Iter: 684 loss: 1.00332875e-06
Iter: 685 loss: 1.00242517e-06
Iter: 686 loss: 1.01532919e-06
Iter: 687 loss: 1.00240663e-06
Iter: 688 loss: 1.0021306e-06
Iter: 689 loss: 1.00154739e-06
Iter: 690 loss: 1.01152477e-06
Iter: 691 loss: 1.0015126e-06
Iter: 692 loss: 1.00156831e-06
Iter: 693 loss: 1.00123361e-06
Iter: 694 loss: 1.00113596e-06
Iter: 695 loss: 1.00085208e-06
Iter: 696 loss: 1.00165062e-06
Iter: 697 loss: 1.00071327e-06
Iter: 698 loss: 1.00023624e-06
Iter: 699 loss: 1.00337888e-06
Iter: 700 loss: 1.00017178e-06
Iter: 701 loss: 9.99758868e-07
Iter: 702 loss: 9.99362555e-07
Iter: 703 loss: 9.99236363e-07
Iter: 704 loss: 9.98587893e-07
Iter: 705 loss: 9.9757483e-07
Iter: 706 loss: 9.97543339e-07
Iter: 707 loss: 9.96883614e-07
Iter: 708 loss: 1.00585714e-06
Iter: 709 loss: 9.96879294e-07
Iter: 710 loss: 9.96387371e-07
Iter: 711 loss: 9.97158622e-07
Iter: 712 loss: 9.96177732e-07
Iter: 713 loss: 9.95640221e-07
Iter: 714 loss: 9.94720494e-07
Iter: 715 loss: 9.94755e-07
Iter: 716 loss: 9.94209586e-07
Iter: 717 loss: 9.97087568e-07
Iter: 718 loss: 9.94148e-07
Iter: 719 loss: 9.93770527e-07
Iter: 720 loss: 9.93100912e-07
Iter: 721 loss: 1.00870022e-06
Iter: 722 loss: 9.93074082e-07
Iter: 723 loss: 9.92407877e-07
Iter: 724 loss: 9.92398782e-07
Iter: 725 loss: 9.92128321e-07
Iter: 726 loss: 9.93827143e-07
Iter: 727 loss: 9.92071818e-07
Iter: 728 loss: 9.91790102e-07
Iter: 729 loss: 9.91612296e-07
Iter: 730 loss: 9.91476e-07
Iter: 731 loss: 9.90990202e-07
Iter: 732 loss: 9.90026706e-07
Iter: 733 loss: 1.00929719e-06
Iter: 734 loss: 9.90006129e-07
Iter: 735 loss: 9.89250907e-07
Iter: 736 loss: 9.96980134e-07
Iter: 737 loss: 9.89224418e-07
Iter: 738 loss: 9.88496822e-07
Iter: 739 loss: 9.95671485e-07
Iter: 740 loss: 9.88474767e-07
Iter: 741 loss: 9.88115744e-07
Iter: 742 loss: 9.87745e-07
Iter: 743 loss: 9.87665e-07
Iter: 744 loss: 9.87273552e-07
Iter: 745 loss: 9.87291514e-07
Iter: 746 loss: 9.86919758e-07
Iter: 747 loss: 9.86239684e-07
Iter: 748 loss: 1.00061789e-06
Iter: 749 loss: 9.86253895e-07
Iter: 750 loss: 9.85856559e-07
Iter: 751 loss: 9.91094907e-07
Iter: 752 loss: 9.85850761e-07
Iter: 753 loss: 9.85552333e-07
Iter: 754 loss: 9.86523673e-07
Iter: 755 loss: 9.85485e-07
Iter: 756 loss: 9.8513965e-07
Iter: 757 loss: 9.84798362e-07
Iter: 758 loss: 9.84705821e-07
Iter: 759 loss: 9.84019266e-07
Iter: 760 loss: 9.86891337e-07
Iter: 761 loss: 9.83882387e-07
Iter: 762 loss: 9.83482778e-07
Iter: 763 loss: 9.85674205e-07
Iter: 764 loss: 9.83422524e-07
Iter: 765 loss: 9.82816573e-07
Iter: 766 loss: 9.82146503e-07
Iter: 767 loss: 9.82068286e-07
Iter: 768 loss: 9.81617291e-07
Iter: 769 loss: 9.81689482e-07
Iter: 770 loss: 9.81286803e-07
Iter: 771 loss: 9.80660161e-07
Iter: 772 loss: 9.84698318e-07
Iter: 773 loss: 9.80574214e-07
Iter: 774 loss: 9.79867309e-07
Iter: 775 loss: 9.8388432e-07
Iter: 776 loss: 9.7974953e-07
Iter: 777 loss: 9.7950533e-07
Iter: 778 loss: 9.7921486e-07
Iter: 779 loss: 9.79174274e-07
Iter: 780 loss: 9.78575713e-07
Iter: 781 loss: 9.82779284e-07
Iter: 782 loss: 9.7848465e-07
Iter: 783 loss: 9.78276375e-07
Iter: 784 loss: 9.78034222e-07
Iter: 785 loss: 9.77983e-07
Iter: 786 loss: 9.77660648e-07
Iter: 787 loss: 9.79947117e-07
Iter: 788 loss: 9.77622221e-07
Iter: 789 loss: 9.77231593e-07
Iter: 790 loss: 9.77146101e-07
Iter: 791 loss: 9.76886895e-07
Iter: 792 loss: 9.76399e-07
Iter: 793 loss: 9.78447815e-07
Iter: 794 loss: 9.76328238e-07
Iter: 795 loss: 9.75823582e-07
Iter: 796 loss: 9.75156354e-07
Iter: 797 loss: 9.75104513e-07
Iter: 798 loss: 9.74215254e-07
Iter: 799 loss: 9.74189902e-07
Iter: 800 loss: 9.73781539e-07
Iter: 801 loss: 9.73271426e-07
Iter: 802 loss: 9.7322e-07
Iter: 803 loss: 9.72630232e-07
Iter: 804 loss: 9.72954126e-07
Iter: 805 loss: 9.72213456e-07
Iter: 806 loss: 9.72155703e-07
Iter: 807 loss: 9.71847385e-07
Iter: 808 loss: 9.71683335e-07
Iter: 809 loss: 9.71309305e-07
Iter: 810 loss: 9.75906e-07
Iter: 811 loss: 9.71325107e-07
Iter: 812 loss: 9.70965857e-07
Iter: 813 loss: 9.70958808e-07
Iter: 814 loss: 9.70711767e-07
Iter: 815 loss: 9.70214e-07
Iter: 816 loss: 9.8127839e-07
Iter: 817 loss: 9.70211431e-07
Iter: 818 loss: 9.69779194e-07
Iter: 819 loss: 9.69657322e-07
Iter: 820 loss: 9.69373104e-07
Iter: 821 loss: 9.68592758e-07
Iter: 822 loss: 9.7076088e-07
Iter: 823 loss: 9.68339918e-07
Iter: 824 loss: 9.67937467e-07
Iter: 825 loss: 9.67131427e-07
Iter: 826 loss: 9.82404117e-07
Iter: 827 loss: 9.67108235e-07
Iter: 828 loss: 9.65867798e-07
Iter: 829 loss: 9.67866754e-07
Iter: 830 loss: 9.65297659e-07
Iter: 831 loss: 9.66356083e-07
Iter: 832 loss: 9.6502788e-07
Iter: 833 loss: 9.64782203e-07
Iter: 834 loss: 9.6411e-07
Iter: 835 loss: 9.69585699e-07
Iter: 836 loss: 9.64020501e-07
Iter: 837 loss: 9.63459911e-07
Iter: 838 loss: 9.67797405e-07
Iter: 839 loss: 9.63408638e-07
Iter: 840 loss: 9.6305439e-07
Iter: 841 loss: 9.63122488e-07
Iter: 842 loss: 9.62743115e-07
Iter: 843 loss: 9.62323384e-07
Iter: 844 loss: 9.62326112e-07
Iter: 845 loss: 9.62029844e-07
Iter: 846 loss: 9.61402634e-07
Iter: 847 loss: 9.72431e-07
Iter: 848 loss: 9.61404e-07
Iter: 849 loss: 9.60657417e-07
Iter: 850 loss: 9.59782938e-07
Iter: 851 loss: 9.59663112e-07
Iter: 852 loss: 9.60804414e-07
Iter: 853 loss: 9.59282147e-07
Iter: 854 loss: 9.58993269e-07
Iter: 855 loss: 9.58221221e-07
Iter: 856 loss: 9.609264e-07
Iter: 857 loss: 9.57865e-07
Iter: 858 loss: 9.57976795e-07
Iter: 859 loss: 9.57421662e-07
Iter: 860 loss: 9.57097e-07
Iter: 861 loss: 9.57492148e-07
Iter: 862 loss: 9.56915073e-07
Iter: 863 loss: 9.56661324e-07
Iter: 864 loss: 9.56444183e-07
Iter: 865 loss: 9.56377562e-07
Iter: 866 loss: 9.56003078e-07
Iter: 867 loss: 9.55987161e-07
Iter: 868 loss: 9.5587643e-07
Iter: 869 loss: 9.55575842e-07
Iter: 870 loss: 9.59754402e-07
Iter: 871 loss: 9.55549353e-07
Iter: 872 loss: 9.55e-07
Iter: 873 loss: 9.54210236e-07
Iter: 874 loss: 9.54176812e-07
Iter: 875 loss: 9.53551478e-07
Iter: 876 loss: 9.62162858e-07
Iter: 877 loss: 9.53553354e-07
Iter: 878 loss: 9.53093377e-07
Iter: 879 loss: 9.55404857e-07
Iter: 880 loss: 9.53004815e-07
Iter: 881 loss: 9.52519031e-07
Iter: 882 loss: 9.51629715e-07
Iter: 883 loss: 9.72268708e-07
Iter: 884 loss: 9.51634e-07
Iter: 885 loss: 9.50830326e-07
Iter: 886 loss: 9.54873485e-07
Iter: 887 loss: 9.506835e-07
Iter: 888 loss: 9.49982791e-07
Iter: 889 loss: 9.51922345e-07
Iter: 890 loss: 9.49778723e-07
Iter: 891 loss: 9.4950758e-07
Iter: 892 loss: 9.49362402e-07
Iter: 893 loss: 9.49229275e-07
Iter: 894 loss: 9.4874224e-07
Iter: 895 loss: 9.4904351e-07
Iter: 896 loss: 9.48283514e-07
Iter: 897 loss: 9.4841954e-07
Iter: 898 loss: 9.47985143e-07
Iter: 899 loss: 9.47682622e-07
Iter: 900 loss: 9.4760469e-07
Iter: 901 loss: 9.47448711e-07
Iter: 902 loss: 9.47118338e-07
Iter: 903 loss: 9.47640387e-07
Iter: 904 loss: 9.4698089e-07
Iter: 905 loss: 9.46445653e-07
Iter: 906 loss: 9.47924832e-07
Iter: 907 loss: 9.46270063e-07
Iter: 908 loss: 9.46003809e-07
Iter: 909 loss: 9.4634612e-07
Iter: 910 loss: 9.45864144e-07
Iter: 911 loss: 9.45432589e-07
Iter: 912 loss: 9.44950727e-07
Iter: 913 loss: 9.44876888e-07
Iter: 914 loss: 9.44320277e-07
Iter: 915 loss: 9.49073524e-07
Iter: 916 loss: 9.44289411e-07
Iter: 917 loss: 9.43881787e-07
Iter: 918 loss: 9.43409873e-07
Iter: 919 loss: 9.43397e-07
Iter: 920 loss: 9.4292659e-07
Iter: 921 loss: 9.48337401e-07
Iter: 922 loss: 9.42907207e-07
Iter: 923 loss: 9.42691429e-07
Iter: 924 loss: 9.45596526e-07
Iter: 925 loss: 9.42716611e-07
Iter: 926 loss: 9.42453312e-07
Iter: 927 loss: 9.4174959e-07
Iter: 928 loss: 9.47235435e-07
Iter: 929 loss: 9.41633743e-07
Iter: 930 loss: 9.4110203e-07
Iter: 931 loss: 9.44228304e-07
Iter: 932 loss: 9.41021142e-07
Iter: 933 loss: 9.40579298e-07
Iter: 934 loss: 9.47543413e-07
Iter: 935 loss: 9.4059061e-07
Iter: 936 loss: 9.4029906e-07
Iter: 937 loss: 9.39789516e-07
Iter: 938 loss: 9.39791676e-07
Iter: 939 loss: 9.39628308e-07
Iter: 940 loss: 9.39531276e-07
Iter: 941 loss: 9.39340396e-07
Iter: 942 loss: 9.38800781e-07
Iter: 943 loss: 9.42936708e-07
Iter: 944 loss: 9.38685503e-07
Iter: 945 loss: 9.38289645e-07
Iter: 946 loss: 9.3825048e-07
Iter: 947 loss: 9.38104904e-07
Iter: 948 loss: 9.37754692e-07
Iter: 949 loss: 9.43203815e-07
Iter: 950 loss: 9.37728373e-07
Iter: 951 loss: 9.37272318e-07
Iter: 952 loss: 9.37884352e-07
Iter: 953 loss: 9.37035907e-07
Iter: 954 loss: 9.36513288e-07
Iter: 955 loss: 9.39275196e-07
Iter: 956 loss: 9.36431093e-07
Iter: 957 loss: 9.36118909e-07
Iter: 958 loss: 9.38875701e-07
Iter: 959 loss: 9.36098331e-07
Iter: 960 loss: 9.35775688e-07
Iter: 961 loss: 9.362426e-07
Iter: 962 loss: 9.35597086e-07
Iter: 963 loss: 9.3533788e-07
Iter: 964 loss: 9.34810316e-07
Iter: 965 loss: 9.41985832e-07
Iter: 966 loss: 9.34771833e-07
Iter: 967 loss: 9.34589139e-07
Iter: 968 loss: 9.34423497e-07
Iter: 969 loss: 9.34054697e-07
Iter: 970 loss: 9.3394425e-07
Iter: 971 loss: 9.33753142e-07
Iter: 972 loss: 9.33458296e-07
Iter: 973 loss: 9.33536398e-07
Iter: 974 loss: 9.33237857e-07
Iter: 975 loss: 9.32654928e-07
Iter: 976 loss: 9.35268076e-07
Iter: 977 loss: 9.32502644e-07
Iter: 978 loss: 9.32326543e-07
Iter: 979 loss: 9.34058107e-07
Iter: 980 loss: 9.32301816e-07
Iter: 981 loss: 9.32109174e-07
Iter: 982 loss: 9.31901695e-07
Iter: 983 loss: 9.31839622e-07
Iter: 984 loss: 9.31465934e-07
Iter: 985 loss: 9.31777492e-07
Iter: 986 loss: 9.31306431e-07
Iter: 987 loss: 9.30848159e-07
Iter: 988 loss: 9.31490888e-07
Iter: 989 loss: 9.30669216e-07
Iter: 990 loss: 9.30135684e-07
Iter: 991 loss: 9.31302793e-07
Iter: 992 loss: 9.2993e-07
Iter: 993 loss: 9.29552e-07
Iter: 994 loss: 9.29530756e-07
Iter: 995 loss: 9.29372334e-07
Iter: 996 loss: 9.28811801e-07
Iter: 997 loss: 9.30444628e-07
Iter: 998 loss: 9.28548161e-07
Iter: 999 loss: 9.28017869e-07
Iter: 1000 loss: 9.36650849e-07
Iter: 1001 loss: 9.28007296e-07
Iter: 1002 loss: 9.27662654e-07
Iter: 1003 loss: 9.27650262e-07
Iter: 1004 loss: 9.27465e-07
Iter: 1005 loss: 9.26940288e-07
Iter: 1006 loss: 9.30260796e-07
Iter: 1007 loss: 9.26849452e-07
Iter: 1008 loss: 9.27021063e-07
Iter: 1009 loss: 9.2665033e-07
Iter: 1010 loss: 9.2646053e-07
Iter: 1011 loss: 9.2603716e-07
Iter: 1012 loss: 9.30071167e-07
Iter: 1013 loss: 9.25982533e-07
Iter: 1014 loss: 9.25610721e-07
Iter: 1015 loss: 9.25567235e-07
Iter: 1016 loss: 9.25295353e-07
Iter: 1017 loss: 9.25109589e-07
Iter: 1018 loss: 9.24984192e-07
Iter: 1019 loss: 9.24628807e-07
Iter: 1020 loss: 9.24961114e-07
Iter: 1021 loss: 9.24423944e-07
Iter: 1022 loss: 9.23865e-07
Iter: 1023 loss: 9.23551056e-07
Iter: 1024 loss: 9.2331112e-07
Iter: 1025 loss: 9.22784125e-07
Iter: 1026 loss: 9.2568547e-07
Iter: 1027 loss: 9.22687491e-07
Iter: 1028 loss: 9.22224217e-07
Iter: 1029 loss: 9.22240815e-07
Iter: 1030 loss: 9.22038396e-07
Iter: 1031 loss: 9.21728656e-07
Iter: 1032 loss: 9.21718879e-07
Iter: 1033 loss: 9.21464789e-07
Iter: 1034 loss: 9.23364e-07
Iter: 1035 loss: 9.21412322e-07
Iter: 1036 loss: 9.21088713e-07
Iter: 1037 loss: 9.21786523e-07
Iter: 1038 loss: 9.20958485e-07
Iter: 1039 loss: 9.20797106e-07
Iter: 1040 loss: 9.20791877e-07
Iter: 1041 loss: 9.20637717e-07
Iter: 1042 loss: 9.20429443e-07
Iter: 1043 loss: 9.23646724e-07
Iter: 1044 loss: 9.20427055e-07
Iter: 1045 loss: 9.20203775e-07
Iter: 1046 loss: 9.19836168e-07
Iter: 1047 loss: 9.19840033e-07
Iter: 1048 loss: 9.19729814e-07
Iter: 1049 loss: 9.1963841e-07
Iter: 1050 loss: 9.19510057e-07
Iter: 1051 loss: 9.19338333e-07
Iter: 1052 loss: 9.23221251e-07
Iter: 1053 loss: 9.19308548e-07
Iter: 1054 loss: 9.18973399e-07
Iter: 1055 loss: 9.19016e-07
Iter: 1056 loss: 9.18703108e-07
Iter: 1057 loss: 9.18377509e-07
Iter: 1058 loss: 9.19667912e-07
Iter: 1059 loss: 9.18285536e-07
Iter: 1060 loss: 9.17995408e-07
Iter: 1061 loss: 9.19946956e-07
Iter: 1062 loss: 9.17961358e-07
Iter: 1063 loss: 9.1770562e-07
Iter: 1064 loss: 9.20318826e-07
Iter: 1065 loss: 9.17680325e-07
Iter: 1066 loss: 9.17584487e-07
Iter: 1067 loss: 9.17348871e-07
Iter: 1068 loss: 9.18121486e-07
Iter: 1069 loss: 9.17212219e-07
Iter: 1070 loss: 9.17504394e-07
Iter: 1071 loss: 9.17101943e-07
Iter: 1072 loss: 9.17016507e-07
Iter: 1073 loss: 9.16867066e-07
Iter: 1074 loss: 9.20401249e-07
Iter: 1075 loss: 9.1683637e-07
Iter: 1076 loss: 9.16666863e-07
Iter: 1077 loss: 9.17601199e-07
Iter: 1078 loss: 9.16640261e-07
Iter: 1079 loss: 9.16398e-07
Iter: 1080 loss: 9.16672093e-07
Iter: 1081 loss: 9.16248553e-07
Iter: 1082 loss: 9.16086378e-07
Iter: 1083 loss: 9.16057104e-07
Iter: 1084 loss: 9.15984685e-07
Iter: 1085 loss: 9.15707858e-07
Iter: 1086 loss: 9.18657349e-07
Iter: 1087 loss: 9.15686485e-07
Iter: 1088 loss: 9.15577061e-07
Iter: 1089 loss: 9.15406645e-07
Iter: 1090 loss: 9.15379871e-07
Iter: 1091 loss: 9.15173075e-07
Iter: 1092 loss: 9.15450926e-07
Iter: 1093 loss: 9.15087298e-07
Iter: 1094 loss: 9.14917905e-07
Iter: 1095 loss: 9.14912675e-07
Iter: 1096 loss: 9.14846169e-07
Iter: 1097 loss: 9.1483588e-07
Iter: 1098 loss: 9.14794157e-07
Iter: 1099 loss: 9.14614361e-07
Iter: 1100 loss: 9.14679958e-07
Iter: 1101 loss: 9.14473276e-07
Iter: 1102 loss: 9.14294333e-07
Iter: 1103 loss: 9.14282055e-07
Iter: 1104 loss: 9.14118402e-07
Iter: 1105 loss: 9.14291718e-07
Iter: 1106 loss: 9.13994199e-07
Iter: 1107 loss: 9.13836e-07
Iter: 1108 loss: 9.13807867e-07
Iter: 1109 loss: 9.13669965e-07
Iter: 1110 loss: 9.13412407e-07
Iter: 1111 loss: 9.15362648e-07
Iter: 1112 loss: 9.1338859e-07
Iter: 1113 loss: 9.13259896e-07
Iter: 1114 loss: 9.12966129e-07
Iter: 1115 loss: 9.1864797e-07
Iter: 1116 loss: 9.12968915e-07
Iter: 1117 loss: 9.12627684e-07
Iter: 1118 loss: 9.12956523e-07
Iter: 1119 loss: 9.12448058e-07
Iter: 1120 loss: 9.12441408e-07
Iter: 1121 loss: 9.12263431e-07
Iter: 1122 loss: 9.12170492e-07
Iter: 1123 loss: 9.11891e-07
Iter: 1124 loss: 9.12361429e-07
Iter: 1125 loss: 9.11706366e-07
Iter: 1126 loss: 9.11484904e-07
Iter: 1127 loss: 9.11495135e-07
Iter: 1128 loss: 9.11295388e-07
Iter: 1129 loss: 9.1112571e-07
Iter: 1130 loss: 9.11066195e-07
Iter: 1131 loss: 9.1082245e-07
Iter: 1132 loss: 9.14742145e-07
Iter: 1133 loss: 9.10816539e-07
Iter: 1134 loss: 9.10540734e-07
Iter: 1135 loss: 9.10611618e-07
Iter: 1136 loss: 9.10354061e-07
Iter: 1137 loss: 9.10052563e-07
Iter: 1138 loss: 9.09531593e-07
Iter: 1139 loss: 9.19257047e-07
Iter: 1140 loss: 9.09543644e-07
Iter: 1141 loss: 9.09533355e-07
Iter: 1142 loss: 9.09362541e-07
Iter: 1143 loss: 9.0925937e-07
Iter: 1144 loss: 9.09230948e-07
Iter: 1145 loss: 9.0917905e-07
Iter: 1146 loss: 9.08928826e-07
Iter: 1147 loss: 9.08952e-07
Iter: 1148 loss: 9.08779384e-07
Iter: 1149 loss: 9.08526033e-07
Iter: 1150 loss: 9.09202129e-07
Iter: 1151 loss: 9.0847459e-07
Iter: 1152 loss: 9.08310369e-07
Iter: 1153 loss: 9.08183324e-07
Iter: 1154 loss: 9.08142283e-07
Iter: 1155 loss: 9.08011e-07
Iter: 1156 loss: 9.08012453e-07
Iter: 1157 loss: 9.07859544e-07
Iter: 1158 loss: 9.07904223e-07
Iter: 1159 loss: 9.07762455e-07
Iter: 1160 loss: 9.07557876e-07
Iter: 1161 loss: 9.07023377e-07
Iter: 1162 loss: 9.10615768e-07
Iter: 1163 loss: 9.06913442e-07
Iter: 1164 loss: 9.06642413e-07
Iter: 1165 loss: 9.06645937e-07
Iter: 1166 loss: 9.0631147e-07
Iter: 1167 loss: 9.07733238e-07
Iter: 1168 loss: 9.06261164e-07
Iter: 1169 loss: 9.05961485e-07
Iter: 1170 loss: 9.06017306e-07
Iter: 1171 loss: 9.05733373e-07
Iter: 1172 loss: 9.05557499e-07
Iter: 1173 loss: 9.05648676e-07
Iter: 1174 loss: 9.05479169e-07
Iter: 1175 loss: 9.05250204e-07
Iter: 1176 loss: 9.05874856e-07
Iter: 1177 loss: 9.05185971e-07
Iter: 1178 loss: 9.05082288e-07
Iter: 1179 loss: 9.05080583e-07
Iter: 1180 loss: 9.04996909e-07
Iter: 1181 loss: 9.04704393e-07
Iter: 1182 loss: 9.04309331e-07
Iter: 1183 loss: 9.04250328e-07
Iter: 1184 loss: 9.04030571e-07
Iter: 1185 loss: 9.03903924e-07
Iter: 1186 loss: 9.03556668e-07
Iter: 1187 loss: 9.04882e-07
Iter: 1188 loss: 9.03466571e-07
Iter: 1189 loss: 9.03179341e-07
Iter: 1190 loss: 9.02686622e-07
Iter: 1191 loss: 9.14046609e-07
Iter: 1192 loss: 9.02674742e-07
Iter: 1193 loss: 9.02526835e-07
Iter: 1194 loss: 9.02526835e-07
Iter: 1195 loss: 9.02333284e-07
Iter: 1196 loss: 9.02572e-07
Iter: 1197 loss: 9.02264048e-07
Iter: 1198 loss: 9.02110173e-07
Iter: 1199 loss: 9.02021e-07
Iter: 1200 loss: 9.01941e-07
Iter: 1201 loss: 9.01804e-07
Iter: 1202 loss: 9.01791225e-07
Iter: 1203 loss: 9.01623253e-07
Iter: 1204 loss: 9.01156454e-07
Iter: 1205 loss: 9.02920817e-07
Iter: 1206 loss: 9.00946134e-07
Iter: 1207 loss: 9.00570058e-07
Iter: 1208 loss: 9.0056443e-07
Iter: 1209 loss: 9.00296186e-07
Iter: 1210 loss: 9.03649379e-07
Iter: 1211 loss: 9.00295618e-07
Iter: 1212 loss: 8.9998548e-07
Iter: 1213 loss: 8.99696147e-07
Iter: 1214 loss: 8.99652832e-07
Iter: 1215 loss: 8.99356678e-07
Iter: 1216 loss: 8.99969336e-07
Iter: 1217 loss: 8.99241229e-07
Iter: 1218 loss: 8.99027384e-07
Iter: 1219 loss: 8.99025849e-07
Iter: 1220 loss: 8.98852591e-07
Iter: 1221 loss: 8.98586109e-07
Iter: 1222 loss: 8.98580765e-07
Iter: 1223 loss: 8.98353562e-07
Iter: 1224 loss: 8.98183202e-07
Iter: 1225 loss: 8.98122948e-07
Iter: 1226 loss: 8.98291887e-07
Iter: 1227 loss: 8.97985501e-07
Iter: 1228 loss: 8.9789205e-07
Iter: 1229 loss: 8.97687812e-07
Iter: 1230 loss: 8.97695656e-07
Iter: 1231 loss: 8.97499035e-07
Iter: 1232 loss: 8.98042913e-07
Iter: 1233 loss: 8.97411e-07
Iter: 1234 loss: 8.97123471e-07
Iter: 1235 loss: 8.97546e-07
Iter: 1236 loss: 8.96958454e-07
Iter: 1237 loss: 8.96739891e-07
Iter: 1238 loss: 8.96143661e-07
Iter: 1239 loss: 8.98309622e-07
Iter: 1240 loss: 8.9585393e-07
Iter: 1241 loss: 8.95155495e-07
Iter: 1242 loss: 8.95135258e-07
Iter: 1243 loss: 8.94546361e-07
Iter: 1244 loss: 8.98107601e-07
Iter: 1245 loss: 8.94491677e-07
Iter: 1246 loss: 8.9426203e-07
Iter: 1247 loss: 8.93894594e-07
Iter: 1248 loss: 8.93883907e-07
Iter: 1249 loss: 8.93437402e-07
Iter: 1250 loss: 8.98114649e-07
Iter: 1251 loss: 8.93443712e-07
Iter: 1252 loss: 8.93090601e-07
Iter: 1253 loss: 8.9639758e-07
Iter: 1254 loss: 8.93098104e-07
Iter: 1255 loss: 8.92962817e-07
Iter: 1256 loss: 8.92561047e-07
Iter: 1257 loss: 8.93290576e-07
Iter: 1258 loss: 8.92298772e-07
Iter: 1259 loss: 8.92109369e-07
Iter: 1260 loss: 8.92036212e-07
Iter: 1261 loss: 8.91695322e-07
Iter: 1262 loss: 8.91846298e-07
Iter: 1263 loss: 8.91446746e-07
Iter: 1264 loss: 8.91040372e-07
Iter: 1265 loss: 8.90855119e-07
Iter: 1266 loss: 8.90646049e-07
Iter: 1267 loss: 8.90394517e-07
Iter: 1268 loss: 8.9029254e-07
Iter: 1269 loss: 8.90139631e-07
Iter: 1270 loss: 8.89630257e-07
Iter: 1271 loss: 8.89376849e-07
Iter: 1272 loss: 8.8902641e-07
Iter: 1273 loss: 8.8822037e-07
Iter: 1274 loss: 8.95360472e-07
Iter: 1275 loss: 8.88145053e-07
Iter: 1276 loss: 8.87736292e-07
Iter: 1277 loss: 8.87720262e-07
Iter: 1278 loss: 8.87348847e-07
Iter: 1279 loss: 8.89102125e-07
Iter: 1280 loss: 8.87257215e-07
Iter: 1281 loss: 8.87085e-07
Iter: 1282 loss: 8.86718226e-07
Iter: 1283 loss: 8.9389232e-07
Iter: 1284 loss: 8.86727719e-07
Iter: 1285 loss: 8.86314297e-07
Iter: 1286 loss: 8.88646696e-07
Iter: 1287 loss: 8.86263308e-07
Iter: 1288 loss: 8.8607726e-07
Iter: 1289 loss: 8.86053044e-07
Iter: 1290 loss: 8.85877341e-07
Iter: 1291 loss: 8.8560671e-07
Iter: 1292 loss: 8.85600912e-07
Iter: 1293 loss: 8.85184477e-07
Iter: 1294 loss: 8.84681413e-07
Iter: 1295 loss: 8.84652422e-07
Iter: 1296 loss: 8.849496e-07
Iter: 1297 loss: 8.84409417e-07
Iter: 1298 loss: 8.84219276e-07
Iter: 1299 loss: 8.83701e-07
Iter: 1300 loss: 8.86223802e-07
Iter: 1301 loss: 8.83522887e-07
Iter: 1302 loss: 8.82915913e-07
Iter: 1303 loss: 8.85730856e-07
Iter: 1304 loss: 8.82798702e-07
Iter: 1305 loss: 8.82331676e-07
Iter: 1306 loss: 8.82123345e-07
Iter: 1307 loss: 8.81857773e-07
Iter: 1308 loss: 8.8172493e-07
Iter: 1309 loss: 8.81621872e-07
Iter: 1310 loss: 8.81362723e-07
Iter: 1311 loss: 8.82415804e-07
Iter: 1312 loss: 8.81280187e-07
Iter: 1313 loss: 8.81070662e-07
Iter: 1314 loss: 8.80740345e-07
Iter: 1315 loss: 8.80736252e-07
Iter: 1316 loss: 8.80474715e-07
Iter: 1317 loss: 8.81070264e-07
Iter: 1318 loss: 8.80374898e-07
Iter: 1319 loss: 8.79889399e-07
Iter: 1320 loss: 8.8078e-07
Iter: 1321 loss: 8.79671063e-07
Iter: 1322 loss: 8.79364677e-07
Iter: 1323 loss: 8.79652475e-07
Iter: 1324 loss: 8.79209949e-07
Iter: 1325 loss: 8.78783624e-07
Iter: 1326 loss: 8.82603445e-07
Iter: 1327 loss: 8.78771971e-07
Iter: 1328 loss: 8.78526123e-07
Iter: 1329 loss: 8.77961497e-07
Iter: 1330 loss: 8.85888e-07
Iter: 1331 loss: 8.77933417e-07
Iter: 1332 loss: 8.78042385e-07
Iter: 1333 loss: 8.77797333e-07
Iter: 1334 loss: 8.77686603e-07
Iter: 1335 loss: 8.77524087e-07
Iter: 1336 loss: 8.77493676e-07
Iter: 1337 loss: 8.77324226e-07
Iter: 1338 loss: 8.77616458e-07
Iter: 1339 loss: 8.77240609e-07
Iter: 1340 loss: 8.77136927e-07
Iter: 1341 loss: 8.76787055e-07
Iter: 1342 loss: 8.79620245e-07
Iter: 1343 loss: 8.76752665e-07
Iter: 1344 loss: 8.76412457e-07
Iter: 1345 loss: 8.76404e-07
Iter: 1346 loss: 8.76095214e-07
Iter: 1347 loss: 8.77862306e-07
Iter: 1348 loss: 8.76041e-07
Iter: 1349 loss: 8.75805e-07
Iter: 1350 loss: 8.752491e-07
Iter: 1351 loss: 8.80556627e-07
Iter: 1352 loss: 8.75157525e-07
Iter: 1353 loss: 8.75722208e-07
Iter: 1354 loss: 8.75018372e-07
Iter: 1355 loss: 8.74919124e-07
Iter: 1356 loss: 8.74713294e-07
Iter: 1357 loss: 8.79300273e-07
Iter: 1358 loss: 8.74727732e-07
Iter: 1359 loss: 8.74511272e-07
Iter: 1360 loss: 8.76621129e-07
Iter: 1361 loss: 8.74494276e-07
Iter: 1362 loss: 8.74394857e-07
Iter: 1363 loss: 8.74272075e-07
Iter: 1364 loss: 8.74234217e-07
Iter: 1365 loss: 8.74096e-07
Iter: 1366 loss: 8.74038733e-07
Iter: 1367 loss: 8.73967e-07
Iter: 1368 loss: 8.7374292e-07
Iter: 1369 loss: 8.75953e-07
Iter: 1370 loss: 8.73744511e-07
Iter: 1371 loss: 8.73593706e-07
Iter: 1372 loss: 8.73506337e-07
Iter: 1373 loss: 8.734728e-07
Iter: 1374 loss: 8.73231954e-07
Iter: 1375 loss: 8.73186252e-07
Iter: 1376 loss: 8.73049e-07
Iter: 1377 loss: 8.72618159e-07
Iter: 1378 loss: 8.75027126e-07
Iter: 1379 loss: 8.7257888e-07
Iter: 1380 loss: 8.72369299e-07
Iter: 1381 loss: 8.7421256e-07
Iter: 1382 loss: 8.72383055e-07
Iter: 1383 loss: 8.72160399e-07
Iter: 1384 loss: 8.71809561e-07
Iter: 1385 loss: 8.80143205e-07
Iter: 1386 loss: 8.71796601e-07
Iter: 1387 loss: 8.71528414e-07
Iter: 1388 loss: 8.72861733e-07
Iter: 1389 loss: 8.71470263e-07
Iter: 1390 loss: 8.71215832e-07
Iter: 1391 loss: 8.71176269e-07
Iter: 1392 loss: 8.70976237e-07
Iter: 1393 loss: 8.70851864e-07
Iter: 1394 loss: 8.70761e-07
Iter: 1395 loss: 8.70677695e-07
Iter: 1396 loss: 8.7052149e-07
Iter: 1397 loss: 8.72088776e-07
Iter: 1398 loss: 8.70495512e-07
Iter: 1399 loss: 8.70318729e-07
Iter: 1400 loss: 8.70310942e-07
Iter: 1401 loss: 8.7021516e-07
Iter: 1402 loss: 8.70128247e-07
Iter: 1403 loss: 8.70121369e-07
Iter: 1404 loss: 8.69915652e-07
Iter: 1405 loss: 8.70996132e-07
Iter: 1406 loss: 8.69891e-07
Iter: 1407 loss: 8.69755866e-07
Iter: 1408 loss: 8.69438679e-07
Iter: 1409 loss: 8.74871716e-07
Iter: 1410 loss: 8.69449195e-07
Iter: 1411 loss: 8.69140877e-07
Iter: 1412 loss: 8.69525138e-07
Iter: 1413 loss: 8.68979498e-07
Iter: 1414 loss: 8.68747e-07
Iter: 1415 loss: 8.6839259e-07
Iter: 1416 loss: 8.6838952e-07
Iter: 1417 loss: 8.68198526e-07
Iter: 1418 loss: 8.68149527e-07
Iter: 1419 loss: 8.68036238e-07
Iter: 1420 loss: 8.67836e-07
Iter: 1421 loss: 8.71699967e-07
Iter: 1422 loss: 8.67836434e-07
Iter: 1423 loss: 8.67627591e-07
Iter: 1424 loss: 8.68991947e-07
Iter: 1425 loss: 8.67604172e-07
Iter: 1426 loss: 8.67501399e-07
Iter: 1427 loss: 8.68319262e-07
Iter: 1428 loss: 8.67492361e-07
Iter: 1429 loss: 8.67311599e-07
Iter: 1430 loss: 8.672028e-07
Iter: 1431 loss: 8.671297e-07
Iter: 1432 loss: 8.66978098e-07
Iter: 1433 loss: 8.67630888e-07
Iter: 1434 loss: 8.66936034e-07
Iter: 1435 loss: 8.66758114e-07
Iter: 1436 loss: 8.67772542e-07
Iter: 1437 loss: 8.66733956e-07
Iter: 1438 loss: 8.66607138e-07
Iter: 1439 loss: 8.66532616e-07
Iter: 1440 loss: 8.66480377e-07
Iter: 1441 loss: 8.66183427e-07
Iter: 1442 loss: 8.67183871e-07
Iter: 1443 loss: 8.66092648e-07
Iter: 1444 loss: 8.65946276e-07
Iter: 1445 loss: 8.65683944e-07
Iter: 1446 loss: 8.72297619e-07
Iter: 1447 loss: 8.65673712e-07
Iter: 1448 loss: 8.65454467e-07
Iter: 1449 loss: 8.65425477e-07
Iter: 1450 loss: 8.65270295e-07
Iter: 1451 loss: 8.65176389e-07
Iter: 1452 loss: 8.65140919e-07
Iter: 1453 loss: 8.64834817e-07
Iter: 1454 loss: 8.65442e-07
Iter: 1455 loss: 8.64701803e-07
Iter: 1456 loss: 8.64517915e-07
Iter: 1457 loss: 8.65321908e-07
Iter: 1458 loss: 8.64441176e-07
Iter: 1459 loss: 8.64341359e-07
Iter: 1460 loss: 8.64808612e-07
Iter: 1461 loss: 8.64303615e-07
Iter: 1462 loss: 8.64176627e-07
Iter: 1463 loss: 8.64733579e-07
Iter: 1464 loss: 8.64101253e-07
Iter: 1465 loss: 8.63980745e-07
Iter: 1466 loss: 8.63945e-07
Iter: 1467 loss: 8.63862624e-07
Iter: 1468 loss: 8.63746664e-07
Iter: 1469 loss: 8.63753e-07
Iter: 1470 loss: 8.63643663e-07
Iter: 1471 loss: 8.63416631e-07
Iter: 1472 loss: 8.66752828e-07
Iter: 1473 loss: 8.63421519e-07
Iter: 1474 loss: 8.63174478e-07
Iter: 1475 loss: 8.63174648e-07
Iter: 1476 loss: 8.63052719e-07
Iter: 1477 loss: 8.62753495e-07
Iter: 1478 loss: 8.63913669e-07
Iter: 1479 loss: 8.62620766e-07
Iter: 1480 loss: 8.62256286e-07
Iter: 1481 loss: 8.65478853e-07
Iter: 1482 loss: 8.62234288e-07
Iter: 1483 loss: 8.62101956e-07
Iter: 1484 loss: 8.62100705e-07
Iter: 1485 loss: 8.61971898e-07
Iter: 1486 loss: 8.61931e-07
Iter: 1487 loss: 8.61843375e-07
Iter: 1488 loss: 8.61655394e-07
Iter: 1489 loss: 8.61731905e-07
Iter: 1490 loss: 8.61512603e-07
Iter: 1491 loss: 8.61328772e-07
Iter: 1492 loss: 8.61599574e-07
Iter: 1493 loss: 8.61272497e-07
Iter: 1494 loss: 8.61135618e-07
Iter: 1495 loss: 8.61149147e-07
Iter: 1496 loss: 8.6103222e-07
Iter: 1497 loss: 8.60829346e-07
Iter: 1498 loss: 8.64336926e-07
Iter: 1499 loss: 8.60830767e-07
Iter: 1500 loss: 8.60614932e-07
Iter: 1501 loss: 8.62964043e-07
Iter: 1502 loss: 8.60601745e-07
Iter: 1503 loss: 8.60364935e-07
Iter: 1504 loss: 8.60048431e-07
Iter: 1505 loss: 8.6003007e-07
Iter: 1506 loss: 8.59878924e-07
Iter: 1507 loss: 8.59840043e-07
Iter: 1508 loss: 8.59669171e-07
Iter: 1509 loss: 8.59255465e-07
Iter: 1510 loss: 8.624055e-07
Iter: 1511 loss: 8.59158376e-07
Iter: 1512 loss: 8.58744784e-07
Iter: 1513 loss: 8.59749775e-07
Iter: 1514 loss: 8.58579597e-07
Iter: 1515 loss: 8.58403155e-07
Iter: 1516 loss: 8.58396277e-07
Iter: 1517 loss: 8.58192777e-07
Iter: 1518 loss: 8.58477449e-07
Iter: 1519 loss: 8.58092733e-07
Iter: 1520 loss: 8.57929251e-07
Iter: 1521 loss: 8.57982343e-07
Iter: 1522 loss: 8.57821078e-07
Iter: 1523 loss: 8.57549367e-07
Iter: 1524 loss: 8.57172836e-07
Iter: 1525 loss: 8.57174541e-07
Iter: 1526 loss: 8.57254577e-07
Iter: 1527 loss: 8.56933411e-07
Iter: 1528 loss: 8.56789541e-07
Iter: 1529 loss: 8.56516749e-07
Iter: 1530 loss: 8.63110472e-07
Iter: 1531 loss: 8.56526299e-07
Iter: 1532 loss: 8.56253791e-07
Iter: 1533 loss: 8.59077772e-07
Iter: 1534 loss: 8.56245549e-07
Iter: 1535 loss: 8.55970711e-07
Iter: 1536 loss: 8.55804842e-07
Iter: 1537 loss: 8.5570241e-07
Iter: 1538 loss: 8.5544e-07
Iter: 1539 loss: 8.58897636e-07
Iter: 1540 loss: 8.5543445e-07
Iter: 1541 loss: 8.55183544e-07
Iter: 1542 loss: 8.54887503e-07
Iter: 1543 loss: 8.54877783e-07
Iter: 1544 loss: 8.54602831e-07
Iter: 1545 loss: 8.55340886e-07
Iter: 1546 loss: 8.54522966e-07
Iter: 1547 loss: 8.54191e-07
Iter: 1548 loss: 8.53509675e-07
Iter: 1549 loss: 8.64815547e-07
Iter: 1550 loss: 8.53479662e-07
Iter: 1551 loss: 8.53222332e-07
Iter: 1552 loss: 8.53183e-07
Iter: 1553 loss: 8.52933795e-07
Iter: 1554 loss: 8.56770725e-07
Iter: 1555 loss: 8.52928906e-07
Iter: 1556 loss: 8.52772587e-07
Iter: 1557 loss: 8.52348e-07
Iter: 1558 loss: 8.56315296e-07
Iter: 1559 loss: 8.52286348e-07
Iter: 1560 loss: 8.51970412e-07
Iter: 1561 loss: 8.54558436e-07
Iter: 1562 loss: 8.51956429e-07
Iter: 1563 loss: 8.5163208e-07
Iter: 1564 loss: 8.54150358e-07
Iter: 1565 loss: 8.51614573e-07
Iter: 1566 loss: 8.51487357e-07
Iter: 1567 loss: 8.51298353e-07
Iter: 1568 loss: 8.51269874e-07
Iter: 1569 loss: 8.50987647e-07
Iter: 1570 loss: 8.53220627e-07
Iter: 1571 loss: 8.50949505e-07
Iter: 1572 loss: 8.5067245e-07
Iter: 1573 loss: 8.50489755e-07
Iter: 1574 loss: 8.50398919e-07
Iter: 1575 loss: 8.50217646e-07
Iter: 1576 loss: 8.50192805e-07
Iter: 1577 loss: 8.50077697e-07
Iter: 1578 loss: 8.49870901e-07
Iter: 1579 loss: 8.53236429e-07
Iter: 1580 loss: 8.49853677e-07
Iter: 1581 loss: 8.49556272e-07
Iter: 1582 loss: 8.49694402e-07
Iter: 1583 loss: 8.49354592e-07
Iter: 1584 loss: 8.49090952e-07
Iter: 1585 loss: 8.4985885e-07
Iter: 1586 loss: 8.49018079e-07
Iter: 1587 loss: 8.48674404e-07
Iter: 1588 loss: 8.50198035e-07
Iter: 1589 loss: 8.48631885e-07
Iter: 1590 loss: 8.48227899e-07
Iter: 1591 loss: 8.50970878e-07
Iter: 1592 loss: 8.48216814e-07
Iter: 1593 loss: 8.48000354e-07
Iter: 1594 loss: 8.4739213e-07
Iter: 1595 loss: 8.49354308e-07
Iter: 1596 loss: 8.47087279e-07
Iter: 1597 loss: 8.47105298e-07
Iter: 1598 loss: 8.4679175e-07
Iter: 1599 loss: 8.46572391e-07
Iter: 1600 loss: 8.47782474e-07
Iter: 1601 loss: 8.46528394e-07
Iter: 1602 loss: 8.46346552e-07
Iter: 1603 loss: 8.46025046e-07
Iter: 1604 loss: 8.52210121e-07
Iter: 1605 loss: 8.45998102e-07
Iter: 1606 loss: 8.45842123e-07
Iter: 1607 loss: 8.45770501e-07
Iter: 1608 loss: 8.45658462e-07
Iter: 1609 loss: 8.45436489e-07
Iter: 1610 loss: 8.48555203e-07
Iter: 1611 loss: 8.45392094e-07
Iter: 1612 loss: 8.45100317e-07
Iter: 1613 loss: 8.45101567e-07
Iter: 1614 loss: 8.44952297e-07
Iter: 1615 loss: 8.44718841e-07
Iter: 1616 loss: 8.44733393e-07
Iter: 1617 loss: 8.44376245e-07
Iter: 1618 loss: 8.43652742e-07
Iter: 1619 loss: 8.56592123e-07
Iter: 1620 loss: 8.43656153e-07
Iter: 1621 loss: 8.43249609e-07
Iter: 1622 loss: 8.43252678e-07
Iter: 1623 loss: 8.42955671e-07
Iter: 1624 loss: 8.46228e-07
Iter: 1625 loss: 8.42942768e-07
Iter: 1626 loss: 8.42600741e-07
Iter: 1627 loss: 8.42108534e-07
Iter: 1628 loss: 8.42112399e-07
Iter: 1629 loss: 8.41713131e-07
Iter: 1630 loss: 8.43222097e-07
Iter: 1631 loss: 8.41609904e-07
Iter: 1632 loss: 8.41331371e-07
Iter: 1633 loss: 8.42933e-07
Iter: 1634 loss: 8.41288283e-07
Iter: 1635 loss: 8.41060739e-07
Iter: 1636 loss: 8.40799089e-07
Iter: 1637 loss: 8.40785162e-07
Iter: 1638 loss: 8.40654479e-07
Iter: 1639 loss: 8.40618327e-07
Iter: 1640 loss: 8.40479743e-07
Iter: 1641 loss: 8.40239409e-07
Iter: 1642 loss: 8.40240261e-07
Iter: 1643 loss: 8.40054213e-07
Iter: 1644 loss: 8.42640816e-07
Iter: 1645 loss: 8.40047278e-07
Iter: 1646 loss: 8.39854e-07
Iter: 1647 loss: 8.39723725e-07
Iter: 1648 loss: 8.39638801e-07
Iter: 1649 loss: 8.39302629e-07
Iter: 1650 loss: 8.38390633e-07
Iter: 1651 loss: 8.4423732e-07
Iter: 1652 loss: 8.38159281e-07
Iter: 1653 loss: 8.37789912e-07
Iter: 1654 loss: 8.37671109e-07
Iter: 1655 loss: 8.37331697e-07
Iter: 1656 loss: 8.39344693e-07
Iter: 1657 loss: 8.37285256e-07
Iter: 1658 loss: 8.36887921e-07
Iter: 1659 loss: 8.37699702e-07
Iter: 1660 loss: 8.36726599e-07
Iter: 1661 loss: 8.36511219e-07
Iter: 1662 loss: 8.36741492e-07
Iter: 1663 loss: 8.36372692e-07
Iter: 1664 loss: 8.36190452e-07
Iter: 1665 loss: 8.37506889e-07
Iter: 1666 loss: 8.36184e-07
Iter: 1667 loss: 8.35960918e-07
Iter: 1668 loss: 8.35794e-07
Iter: 1669 loss: 8.35714104e-07
Iter: 1670 loss: 8.35435856e-07
Iter: 1671 loss: 8.35720812e-07
Iter: 1672 loss: 8.35300398e-07
Iter: 1673 loss: 8.34908917e-07
Iter: 1674 loss: 8.3650184e-07
Iter: 1675 loss: 8.34793468e-07
Iter: 1676 loss: 8.34485661e-07
Iter: 1677 loss: 8.34354864e-07
Iter: 1678 loss: 8.34170351e-07
Iter: 1679 loss: 8.33950935e-07
Iter: 1680 loss: 8.3392257e-07
Iter: 1681 loss: 8.33784895e-07
Iter: 1682 loss: 8.33339527e-07
Iter: 1683 loss: 8.34719515e-07
Iter: 1684 loss: 8.33097374e-07
Iter: 1685 loss: 8.32540536e-07
Iter: 1686 loss: 8.36997572e-07
Iter: 1687 loss: 8.32483579e-07
Iter: 1688 loss: 8.32158094e-07
Iter: 1689 loss: 8.32366709e-07
Iter: 1690 loss: 8.31933789e-07
Iter: 1691 loss: 8.32152409e-07
Iter: 1692 loss: 8.31809416e-07
Iter: 1693 loss: 8.3171085e-07
Iter: 1694 loss: 8.31519912e-07
Iter: 1695 loss: 8.34952743e-07
Iter: 1696 loss: 8.31523153e-07
Iter: 1697 loss: 8.31239674e-07
Iter: 1698 loss: 8.3259755e-07
Iter: 1699 loss: 8.3118266e-07
Iter: 1700 loss: 8.30910437e-07
Iter: 1701 loss: 8.31636214e-07
Iter: 1702 loss: 8.30830459e-07
Iter: 1703 loss: 8.3063054e-07
Iter: 1704 loss: 8.30365252e-07
Iter: 1705 loss: 8.30358033e-07
Iter: 1706 loss: 8.29912778e-07
Iter: 1707 loss: 8.32354544e-07
Iter: 1708 loss: 8.298382e-07
Iter: 1709 loss: 8.29370151e-07
Iter: 1710 loss: 8.32270246e-07
Iter: 1711 loss: 8.29301882e-07
Iter: 1712 loss: 8.29144597e-07
Iter: 1713 loss: 8.2937396e-07
Iter: 1714 loss: 8.29088549e-07
Iter: 1715 loss: 8.28813256e-07
Iter: 1716 loss: 8.29440296e-07
Iter: 1717 loss: 8.28744362e-07
Iter: 1718 loss: 8.28531654e-07
Iter: 1719 loss: 8.28367604e-07
Iter: 1720 loss: 8.28305303e-07
Iter: 1721 loss: 8.27998804e-07
Iter: 1722 loss: 8.27549457e-07
Iter: 1723 loss: 8.27545534e-07
Iter: 1724 loss: 8.27144959e-07
Iter: 1725 loss: 8.27152462e-07
Iter: 1726 loss: 8.26894507e-07
Iter: 1727 loss: 8.27641884e-07
Iter: 1728 loss: 8.26828398e-07
Iter: 1729 loss: 8.26423332e-07
Iter: 1730 loss: 8.27446e-07
Iter: 1731 loss: 8.26272299e-07
Iter: 1732 loss: 8.26144458e-07
Iter: 1733 loss: 8.25832331e-07
Iter: 1734 loss: 8.31282e-07
Iter: 1735 loss: 8.25808e-07
Iter: 1736 loss: 8.25377924e-07
Iter: 1737 loss: 8.27986128e-07
Iter: 1738 loss: 8.25351549e-07
Iter: 1739 loss: 8.24934148e-07
Iter: 1740 loss: 8.28749648e-07
Iter: 1741 loss: 8.24914594e-07
Iter: 1742 loss: 8.24712629e-07
Iter: 1743 loss: 8.24181143e-07
Iter: 1744 loss: 8.28149041e-07
Iter: 1745 loss: 8.24092751e-07
Iter: 1746 loss: 8.24092695e-07
Iter: 1747 loss: 8.23853384e-07
Iter: 1748 loss: 8.23661708e-07
Iter: 1749 loss: 8.2399788e-07
Iter: 1750 loss: 8.23593155e-07
Iter: 1751 loss: 8.23433936e-07
Iter: 1752 loss: 8.23122264e-07
Iter: 1753 loss: 8.27652059e-07
Iter: 1754 loss: 8.23096343e-07
Iter: 1755 loss: 8.23095434e-07
Iter: 1756 loss: 8.22928541e-07
Iter: 1757 loss: 8.2280178e-07
Iter: 1758 loss: 8.22749e-07
Iter: 1759 loss: 8.2269753e-07
Iter: 1760 loss: 8.22493462e-07
Iter: 1761 loss: 8.21989829e-07
Iter: 1762 loss: 8.24885e-07
Iter: 1763 loss: 8.21835215e-07
Iter: 1764 loss: 8.21662582e-07
Iter: 1765 loss: 8.21477784e-07
Iter: 1766 loss: 8.21320441e-07
Iter: 1767 loss: 8.21077947e-07
Iter: 1768 loss: 8.21076299e-07
Iter: 1769 loss: 8.20798164e-07
Iter: 1770 loss: 8.21358753e-07
Iter: 1771 loss: 8.20711762e-07
Iter: 1772 loss: 8.21304127e-07
Iter: 1773 loss: 8.20606886e-07
Iter: 1774 loss: 8.20552827e-07
Iter: 1775 loss: 8.20328808e-07
Iter: 1776 loss: 8.20573689e-07
Iter: 1777 loss: 8.20149182e-07
Iter: 1778 loss: 8.19836828e-07
Iter: 1779 loss: 8.1984092e-07
Iter: 1780 loss: 8.19604566e-07
Iter: 1781 loss: 8.2157112e-07
Iter: 1782 loss: 8.19578872e-07
Iter: 1783 loss: 8.19466663e-07
Iter: 1784 loss: 8.19048e-07
Iter: 1785 loss: 8.22110223e-07
Iter: 1786 loss: 8.18984176e-07
Iter: 1787 loss: 8.1859821e-07
Iter: 1788 loss: 8.18597584e-07
Iter: 1789 loss: 8.1830342e-07
Iter: 1790 loss: 8.20345576e-07
Iter: 1791 loss: 8.18272383e-07
Iter: 1792 loss: 8.18075534e-07
Iter: 1793 loss: 8.17506759e-07
Iter: 1794 loss: 8.21883305e-07
Iter: 1795 loss: 8.17403816e-07
Iter: 1796 loss: 8.17698435e-07
Iter: 1797 loss: 8.17148646e-07
Iter: 1798 loss: 8.17004661e-07
Iter: 1799 loss: 8.1661841e-07
Iter: 1800 loss: 8.20563514e-07
Iter: 1801 loss: 8.16579927e-07
Iter: 1802 loss: 8.16076806e-07
Iter: 1803 loss: 8.16834927e-07
Iter: 1804 loss: 8.15835165e-07
Iter: 1805 loss: 8.1553992e-07
Iter: 1806 loss: 8.16850729e-07
Iter: 1807 loss: 8.15450448e-07
Iter: 1808 loss: 8.15104841e-07
Iter: 1809 loss: 8.18711e-07
Iter: 1810 loss: 8.15110411e-07
Iter: 1811 loss: 8.14935902e-07
Iter: 1812 loss: 8.14821419e-07
Iter: 1813 loss: 8.14756504e-07
Iter: 1814 loss: 8.14636e-07
Iter: 1815 loss: 8.14657312e-07
Iter: 1816 loss: 8.14510031e-07
Iter: 1817 loss: 8.14075634e-07
Iter: 1818 loss: 8.14969098e-07
Iter: 1819 loss: 8.13838199e-07
Iter: 1820 loss: 8.13298243e-07
Iter: 1821 loss: 8.20344667e-07
Iter: 1822 loss: 8.13276245e-07
Iter: 1823 loss: 8.13120948e-07
Iter: 1824 loss: 8.13018346e-07
Iter: 1825 loss: 8.12860662e-07
Iter: 1826 loss: 8.12524263e-07
Iter: 1827 loss: 8.15419867e-07
Iter: 1828 loss: 8.12482767e-07
Iter: 1829 loss: 8.12218104e-07
Iter: 1830 loss: 8.12224869e-07
Iter: 1831 loss: 8.12019266e-07
Iter: 1832 loss: 8.13078486e-07
Iter: 1833 loss: 8.11983909e-07
Iter: 1834 loss: 8.11828102e-07
Iter: 1835 loss: 8.11460723e-07
Iter: 1836 loss: 8.17257501e-07
Iter: 1837 loss: 8.11478458e-07
Iter: 1838 loss: 8.11207883e-07
Iter: 1839 loss: 8.1199687e-07
Iter: 1840 loss: 8.11123414e-07
Iter: 1841 loss: 8.10876713e-07
Iter: 1842 loss: 8.10865117e-07
Iter: 1843 loss: 8.10691745e-07
Iter: 1844 loss: 8.10457e-07
Iter: 1845 loss: 8.10435267e-07
Iter: 1846 loss: 8.10268716e-07
Iter: 1847 loss: 8.12078497e-07
Iter: 1848 loss: 8.10238362e-07
Iter: 1849 loss: 8.10015194e-07
Iter: 1850 loss: 8.09638891e-07
Iter: 1851 loss: 8.09613766e-07
Iter: 1852 loss: 8.09250537e-07
Iter: 1853 loss: 8.09309029e-07
Iter: 1854 loss: 8.08945629e-07
Iter: 1855 loss: 8.08597576e-07
Iter: 1856 loss: 8.08566142e-07
Iter: 1857 loss: 8.08252423e-07
Iter: 1858 loss: 8.08439211e-07
Iter: 1859 loss: 8.08047e-07
Iter: 1860 loss: 8.07850085e-07
Iter: 1861 loss: 8.07842412e-07
Iter: 1862 loss: 8.07708e-07
Iter: 1863 loss: 8.07496e-07
Iter: 1864 loss: 8.07474407e-07
Iter: 1865 loss: 8.07273352e-07
Iter: 1866 loss: 8.0710015e-07
Iter: 1867 loss: 8.07040919e-07
Iter: 1868 loss: 8.06870219e-07
Iter: 1869 loss: 8.06664104e-07
Iter: 1870 loss: 8.0664131e-07
Iter: 1871 loss: 8.06344758e-07
Iter: 1872 loss: 8.06356582e-07
Iter: 1873 loss: 8.06059234e-07
Iter: 1874 loss: 8.06275295e-07
Iter: 1875 loss: 8.05831633e-07
Iter: 1876 loss: 8.05541617e-07
Iter: 1877 loss: 8.04994102e-07
Iter: 1878 loss: 8.05000582e-07
Iter: 1879 loss: 8.04687772e-07
Iter: 1880 loss: 8.04562e-07
Iter: 1881 loss: 8.04429078e-07
Iter: 1882 loss: 8.04191416e-07
Iter: 1883 loss: 8.04195338e-07
Iter: 1884 loss: 8.03943522e-07
Iter: 1885 loss: 8.04542424e-07
Iter: 1886 loss: 8.03828357e-07
Iter: 1887 loss: 8.03466946e-07
Iter: 1888 loss: 8.05654395e-07
Iter: 1889 loss: 8.03419425e-07
Iter: 1890 loss: 8.03246053e-07
Iter: 1891 loss: 8.03055798e-07
Iter: 1892 loss: 8.03018054e-07
Iter: 1893 loss: 8.02713885e-07
Iter: 1894 loss: 8.03972398e-07
Iter: 1895 loss: 8.02648515e-07
Iter: 1896 loss: 8.02326781e-07
Iter: 1897 loss: 8.04784349e-07
Iter: 1898 loss: 8.0229961e-07
Iter: 1899 loss: 8.02175805e-07
Iter: 1900 loss: 8.01943088e-07
Iter: 1901 loss: 8.0693718e-07
Iter: 1902 loss: 8.01946726e-07
Iter: 1903 loss: 8.0165313e-07
Iter: 1904 loss: 8.02760155e-07
Iter: 1905 loss: 8.01609644e-07
Iter: 1906 loss: 8.01464e-07
Iter: 1907 loss: 8.01434282e-07
Iter: 1908 loss: 8.0134339e-07
Iter: 1909 loss: 8.01018359e-07
Iter: 1910 loss: 8.02053705e-07
Iter: 1911 loss: 8.00880855e-07
Iter: 1912 loss: 8.00847488e-07
Iter: 1913 loss: 8.00683097e-07
Iter: 1914 loss: 8.00563498e-07
Iter: 1915 loss: 8.0067025e-07
Iter: 1916 loss: 8.00464647e-07
Iter: 1917 loss: 8.00360681e-07
Iter: 1918 loss: 8.00243868e-07
Iter: 1919 loss: 8.0024472e-07
Iter: 1920 loss: 8.00080841e-07
Iter: 1921 loss: 8.00088969e-07
Iter: 1922 loss: 8.00004386e-07
Iter: 1923 loss: 7.99910197e-07
Iter: 1924 loss: 7.99890699e-07
Iter: 1925 loss: 7.99756322e-07
Iter: 1926 loss: 8.00050202e-07
Iter: 1927 loss: 7.99702434e-07
Iter: 1928 loss: 7.9955953e-07
Iter: 1929 loss: 8.00297585e-07
Iter: 1930 loss: 7.99525651e-07
Iter: 1931 loss: 7.99400254e-07
Iter: 1932 loss: 7.99309305e-07
Iter: 1933 loss: 7.99263603e-07
Iter: 1934 loss: 7.99001839e-07
Iter: 1935 loss: 7.98570227e-07
Iter: 1936 loss: 7.98577048e-07
Iter: 1937 loss: 7.99426289e-07
Iter: 1938 loss: 7.98436645e-07
Iter: 1939 loss: 7.98350925e-07
Iter: 1940 loss: 7.98143162e-07
Iter: 1941 loss: 8.01481292e-07
Iter: 1942 loss: 7.98112296e-07
Iter: 1943 loss: 7.97960922e-07
Iter: 1944 loss: 7.99517636e-07
Iter: 1945 loss: 7.97959615e-07
Iter: 1946 loss: 7.97810685e-07
Iter: 1947 loss: 7.98542942e-07
Iter: 1948 loss: 7.97780103e-07
Iter: 1949 loss: 7.97705411e-07
Iter: 1950 loss: 7.97548296e-07
Iter: 1951 loss: 7.97561029e-07
Iter: 1952 loss: 7.9745854e-07
Iter: 1953 loss: 7.97452799e-07
Iter: 1954 loss: 7.97361452e-07
Iter: 1955 loss: 7.97378846e-07
Iter: 1956 loss: 7.9730745e-07
Iter: 1957 loss: 7.97227472e-07
Iter: 1958 loss: 7.97314954e-07
Iter: 1959 loss: 7.97213033e-07
Iter: 1960 loss: 7.97101848e-07
Iter: 1961 loss: 7.97190637e-07
Iter: 1962 loss: 7.9704e-07
Iter: 1963 loss: 7.96924439e-07
Iter: 1964 loss: 7.97228722e-07
Iter: 1965 loss: 7.96839856e-07
Iter: 1966 loss: 7.96734184e-07
Iter: 1967 loss: 7.96500899e-07
Iter: 1968 loss: 8.01855094e-07
Iter: 1969 loss: 7.96493396e-07
Iter: 1970 loss: 7.96279721e-07
Iter: 1971 loss: 7.96265624e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.4
+ date
Sat Nov  7 13:22:10 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d392158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d418598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d2ec6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d2ec8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d2ec2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d418d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d2732f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d273d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d24f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d1fc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d1fcae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d1fc598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d21e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d1d7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d1a89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d10b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d0fa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d14dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d0ae620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d1610d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d0b0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd2d0b0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23ecbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23ecbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23e972f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23ecbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23e97488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23e97510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23de17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23de12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23dec400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23d99158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23d3ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23d3e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23d3e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd23e8fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.48599293e-05
Iter: 2 loss: 1.17097934e-05
Iter: 3 loss: 5.73308389e-05
Iter: 4 loss: 1.1705175e-05
Iter: 5 loss: 1.05235595e-05
Iter: 6 loss: 1.23432819e-05
Iter: 7 loss: 9.96743529e-06
Iter: 8 loss: 9.31466275e-06
Iter: 9 loss: 8.65340553e-06
Iter: 10 loss: 8.52338871e-06
Iter: 11 loss: 8.12501821e-06
Iter: 12 loss: 7.95598316e-06
Iter: 13 loss: 7.62261379e-06
Iter: 14 loss: 7.73797183e-06
Iter: 15 loss: 7.38796052e-06
Iter: 16 loss: 7.12673864e-06
Iter: 17 loss: 7.42146221e-06
Iter: 18 loss: 6.98589429e-06
Iter: 19 loss: 6.4961946e-06
Iter: 20 loss: 7.15957958e-06
Iter: 21 loss: 6.2507761e-06
Iter: 22 loss: 5.89317369e-06
Iter: 23 loss: 6.03260105e-06
Iter: 24 loss: 5.64498623e-06
Iter: 25 loss: 5.4960733e-06
Iter: 26 loss: 5.45483636e-06
Iter: 27 loss: 5.2855421e-06
Iter: 28 loss: 5.13552504e-06
Iter: 29 loss: 5.09182337e-06
Iter: 30 loss: 4.93807511e-06
Iter: 31 loss: 4.86583394e-06
Iter: 32 loss: 4.79047912e-06
Iter: 33 loss: 4.62090884e-06
Iter: 34 loss: 5.50683853e-06
Iter: 35 loss: 4.59420789e-06
Iter: 36 loss: 4.4225103e-06
Iter: 37 loss: 4.91137052e-06
Iter: 38 loss: 4.36825485e-06
Iter: 39 loss: 4.22429184e-06
Iter: 40 loss: 4.2094257e-06
Iter: 41 loss: 4.10442772e-06
Iter: 42 loss: 3.90090463e-06
Iter: 43 loss: 4.77795675e-06
Iter: 44 loss: 3.85903786e-06
Iter: 45 loss: 3.72549084e-06
Iter: 46 loss: 3.72411614e-06
Iter: 47 loss: 3.66945051e-06
Iter: 48 loss: 3.61186085e-06
Iter: 49 loss: 3.60202239e-06
Iter: 50 loss: 3.52904317e-06
Iter: 51 loss: 4.31091257e-06
Iter: 52 loss: 3.52732104e-06
Iter: 53 loss: 3.44976024e-06
Iter: 54 loss: 3.37666688e-06
Iter: 55 loss: 3.3586989e-06
Iter: 56 loss: 3.27294e-06
Iter: 57 loss: 3.38929567e-06
Iter: 58 loss: 3.23004383e-06
Iter: 59 loss: 3.13692976e-06
Iter: 60 loss: 3.13691135e-06
Iter: 61 loss: 3.08271524e-06
Iter: 62 loss: 3.01679074e-06
Iter: 63 loss: 3.010603e-06
Iter: 64 loss: 2.9528826e-06
Iter: 65 loss: 3.43696092e-06
Iter: 66 loss: 2.94949905e-06
Iter: 67 loss: 2.89814443e-06
Iter: 68 loss: 3.20211529e-06
Iter: 69 loss: 2.89150375e-06
Iter: 70 loss: 2.85332135e-06
Iter: 71 loss: 2.8343145e-06
Iter: 72 loss: 2.81614803e-06
Iter: 73 loss: 2.77319873e-06
Iter: 74 loss: 2.9091766e-06
Iter: 75 loss: 2.76080596e-06
Iter: 76 loss: 2.71419435e-06
Iter: 77 loss: 3.06296761e-06
Iter: 78 loss: 2.7104893e-06
Iter: 79 loss: 2.66017696e-06
Iter: 80 loss: 2.61896616e-06
Iter: 81 loss: 2.60423349e-06
Iter: 82 loss: 2.56359772e-06
Iter: 83 loss: 3.01988302e-06
Iter: 84 loss: 2.5628874e-06
Iter: 85 loss: 2.53116764e-06
Iter: 86 loss: 2.70349983e-06
Iter: 87 loss: 2.52652171e-06
Iter: 88 loss: 2.50486187e-06
Iter: 89 loss: 2.46447962e-06
Iter: 90 loss: 3.36582957e-06
Iter: 91 loss: 2.46443255e-06
Iter: 92 loss: 2.45262345e-06
Iter: 93 loss: 2.4447022e-06
Iter: 94 loss: 2.42474971e-06
Iter: 95 loss: 2.38975372e-06
Iter: 96 loss: 2.38971234e-06
Iter: 97 loss: 2.35167045e-06
Iter: 98 loss: 2.41345742e-06
Iter: 99 loss: 2.33424316e-06
Iter: 100 loss: 2.30619798e-06
Iter: 101 loss: 2.30564956e-06
Iter: 102 loss: 2.28196382e-06
Iter: 103 loss: 2.24967494e-06
Iter: 104 loss: 2.24813652e-06
Iter: 105 loss: 2.21281607e-06
Iter: 106 loss: 2.34495656e-06
Iter: 107 loss: 2.2043107e-06
Iter: 108 loss: 2.19076219e-06
Iter: 109 loss: 2.19003573e-06
Iter: 110 loss: 2.17641218e-06
Iter: 111 loss: 2.17342063e-06
Iter: 112 loss: 2.1646274e-06
Iter: 113 loss: 2.14451484e-06
Iter: 114 loss: 2.14162083e-06
Iter: 115 loss: 2.12751161e-06
Iter: 116 loss: 2.1137414e-06
Iter: 117 loss: 2.11171891e-06
Iter: 118 loss: 2.10053076e-06
Iter: 119 loss: 2.07592348e-06
Iter: 120 loss: 2.44066518e-06
Iter: 121 loss: 2.07483163e-06
Iter: 122 loss: 2.05057222e-06
Iter: 123 loss: 2.21553046e-06
Iter: 124 loss: 2.04818866e-06
Iter: 125 loss: 2.02913498e-06
Iter: 126 loss: 2.27798682e-06
Iter: 127 loss: 2.02907358e-06
Iter: 128 loss: 2.02126375e-06
Iter: 129 loss: 2.00405248e-06
Iter: 130 loss: 2.25469967e-06
Iter: 131 loss: 2.00329259e-06
Iter: 132 loss: 1.99169745e-06
Iter: 133 loss: 1.99129045e-06
Iter: 134 loss: 1.97985332e-06
Iter: 135 loss: 1.98892167e-06
Iter: 136 loss: 1.97295367e-06
Iter: 137 loss: 1.95991288e-06
Iter: 138 loss: 1.93926667e-06
Iter: 139 loss: 1.93907226e-06
Iter: 140 loss: 1.91733352e-06
Iter: 141 loss: 2.17396473e-06
Iter: 142 loss: 1.91701224e-06
Iter: 143 loss: 1.90170567e-06
Iter: 144 loss: 2.07997755e-06
Iter: 145 loss: 1.90147796e-06
Iter: 146 loss: 1.89230616e-06
Iter: 147 loss: 1.87760259e-06
Iter: 148 loss: 1.87748492e-06
Iter: 149 loss: 1.86571265e-06
Iter: 150 loss: 1.86557054e-06
Iter: 151 loss: 1.85668739e-06
Iter: 152 loss: 1.88202898e-06
Iter: 153 loss: 1.85385045e-06
Iter: 154 loss: 1.8476585e-06
Iter: 155 loss: 1.83414045e-06
Iter: 156 loss: 2.03479863e-06
Iter: 157 loss: 1.83353507e-06
Iter: 158 loss: 1.82369934e-06
Iter: 159 loss: 1.82222652e-06
Iter: 160 loss: 1.81372195e-06
Iter: 161 loss: 1.80081781e-06
Iter: 162 loss: 1.80059521e-06
Iter: 163 loss: 1.7890992e-06
Iter: 164 loss: 1.81551559e-06
Iter: 165 loss: 1.78480536e-06
Iter: 166 loss: 1.77292668e-06
Iter: 167 loss: 1.93809637e-06
Iter: 168 loss: 1.77289144e-06
Iter: 169 loss: 1.76709e-06
Iter: 170 loss: 1.76098774e-06
Iter: 171 loss: 1.75995058e-06
Iter: 172 loss: 1.75118862e-06
Iter: 173 loss: 1.75829257e-06
Iter: 174 loss: 1.74603679e-06
Iter: 175 loss: 1.7394068e-06
Iter: 176 loss: 1.73870239e-06
Iter: 177 loss: 1.73311128e-06
Iter: 178 loss: 1.72577506e-06
Iter: 179 loss: 1.72527257e-06
Iter: 180 loss: 1.71522402e-06
Iter: 181 loss: 1.73305614e-06
Iter: 182 loss: 1.71084071e-06
Iter: 183 loss: 1.69874306e-06
Iter: 184 loss: 1.81058e-06
Iter: 185 loss: 1.69827058e-06
Iter: 186 loss: 1.69219038e-06
Iter: 187 loss: 1.6918633e-06
Iter: 188 loss: 1.68726103e-06
Iter: 189 loss: 1.6819597e-06
Iter: 190 loss: 1.719897e-06
Iter: 191 loss: 1.68153224e-06
Iter: 192 loss: 1.67475685e-06
Iter: 193 loss: 1.67519011e-06
Iter: 194 loss: 1.66947734e-06
Iter: 195 loss: 1.66380369e-06
Iter: 196 loss: 1.6654368e-06
Iter: 197 loss: 1.65973984e-06
Iter: 198 loss: 1.65412359e-06
Iter: 199 loss: 1.65413019e-06
Iter: 200 loss: 1.64811445e-06
Iter: 201 loss: 1.635285e-06
Iter: 202 loss: 1.83651696e-06
Iter: 203 loss: 1.63486277e-06
Iter: 204 loss: 1.62299261e-06
Iter: 205 loss: 1.68419103e-06
Iter: 206 loss: 1.62110291e-06
Iter: 207 loss: 1.61639832e-06
Iter: 208 loss: 1.61623529e-06
Iter: 209 loss: 1.6114567e-06
Iter: 210 loss: 1.6131e-06
Iter: 211 loss: 1.6080653e-06
Iter: 212 loss: 1.60362515e-06
Iter: 213 loss: 1.60847594e-06
Iter: 214 loss: 1.60118975e-06
Iter: 215 loss: 1.59664569e-06
Iter: 216 loss: 1.65038045e-06
Iter: 217 loss: 1.59660431e-06
Iter: 218 loss: 1.59240267e-06
Iter: 219 loss: 1.58586658e-06
Iter: 220 loss: 1.5857828e-06
Iter: 221 loss: 1.57908289e-06
Iter: 222 loss: 1.60775051e-06
Iter: 223 loss: 1.57767442e-06
Iter: 224 loss: 1.57147485e-06
Iter: 225 loss: 1.6400661e-06
Iter: 226 loss: 1.57132467e-06
Iter: 227 loss: 1.56697524e-06
Iter: 228 loss: 1.55745215e-06
Iter: 229 loss: 1.70033411e-06
Iter: 230 loss: 1.5569758e-06
Iter: 231 loss: 1.55439511e-06
Iter: 232 loss: 1.55340058e-06
Iter: 233 loss: 1.54985514e-06
Iter: 234 loss: 1.5512453e-06
Iter: 235 loss: 1.54742008e-06
Iter: 236 loss: 1.54339e-06
Iter: 237 loss: 1.53852625e-06
Iter: 238 loss: 1.53804672e-06
Iter: 239 loss: 1.53288624e-06
Iter: 240 loss: 1.58674766e-06
Iter: 241 loss: 1.53275425e-06
Iter: 242 loss: 1.52749112e-06
Iter: 243 loss: 1.55379985e-06
Iter: 244 loss: 1.52660482e-06
Iter: 245 loss: 1.52235282e-06
Iter: 246 loss: 1.51628592e-06
Iter: 247 loss: 1.5161246e-06
Iter: 248 loss: 1.51228801e-06
Iter: 249 loss: 1.51197742e-06
Iter: 250 loss: 1.50856795e-06
Iter: 251 loss: 1.51082259e-06
Iter: 252 loss: 1.50644269e-06
Iter: 253 loss: 1.50310814e-06
Iter: 254 loss: 1.503249e-06
Iter: 255 loss: 1.50049675e-06
Iter: 256 loss: 1.4987445e-06
Iter: 257 loss: 1.49832738e-06
Iter: 258 loss: 1.49642278e-06
Iter: 259 loss: 1.49237201e-06
Iter: 260 loss: 1.55688122e-06
Iter: 261 loss: 1.49219511e-06
Iter: 262 loss: 1.48724189e-06
Iter: 263 loss: 1.49181551e-06
Iter: 264 loss: 1.48441825e-06
Iter: 265 loss: 1.48119511e-06
Iter: 266 loss: 1.48058768e-06
Iter: 267 loss: 1.47869571e-06
Iter: 268 loss: 1.47408116e-06
Iter: 269 loss: 1.51663994e-06
Iter: 270 loss: 1.47337232e-06
Iter: 271 loss: 1.46790683e-06
Iter: 272 loss: 1.49909647e-06
Iter: 273 loss: 1.4672537e-06
Iter: 274 loss: 1.46629964e-06
Iter: 275 loss: 1.46529885e-06
Iter: 276 loss: 1.4640151e-06
Iter: 277 loss: 1.46100945e-06
Iter: 278 loss: 1.4951089e-06
Iter: 279 loss: 1.46067009e-06
Iter: 280 loss: 1.4571151e-06
Iter: 281 loss: 1.47730157e-06
Iter: 282 loss: 1.45661761e-06
Iter: 283 loss: 1.45283786e-06
Iter: 284 loss: 1.47217202e-06
Iter: 285 loss: 1.45220554e-06
Iter: 286 loss: 1.44934165e-06
Iter: 287 loss: 1.44537728e-06
Iter: 288 loss: 1.44522801e-06
Iter: 289 loss: 1.44149885e-06
Iter: 290 loss: 1.44150567e-06
Iter: 291 loss: 1.43818397e-06
Iter: 292 loss: 1.44692922e-06
Iter: 293 loss: 1.43705051e-06
Iter: 294 loss: 1.43503109e-06
Iter: 295 loss: 1.43187958e-06
Iter: 296 loss: 1.43186764e-06
Iter: 297 loss: 1.42976364e-06
Iter: 298 loss: 1.42940826e-06
Iter: 299 loss: 1.42735803e-06
Iter: 300 loss: 1.42500835e-06
Iter: 301 loss: 1.42471117e-06
Iter: 302 loss: 1.42177419e-06
Iter: 303 loss: 1.41764144e-06
Iter: 304 loss: 1.41751502e-06
Iter: 305 loss: 1.41497299e-06
Iter: 306 loss: 1.41411681e-06
Iter: 307 loss: 1.41131727e-06
Iter: 308 loss: 1.4139265e-06
Iter: 309 loss: 1.40969541e-06
Iter: 310 loss: 1.4077973e-06
Iter: 311 loss: 1.40823431e-06
Iter: 312 loss: 1.40641828e-06
Iter: 313 loss: 1.40402426e-06
Iter: 314 loss: 1.43806346e-06
Iter: 315 loss: 1.40404154e-06
Iter: 316 loss: 1.40243174e-06
Iter: 317 loss: 1.40105362e-06
Iter: 318 loss: 1.40062912e-06
Iter: 319 loss: 1.39839312e-06
Iter: 320 loss: 1.40400448e-06
Iter: 321 loss: 1.39760664e-06
Iter: 322 loss: 1.39468511e-06
Iter: 323 loss: 1.41247529e-06
Iter: 324 loss: 1.39432746e-06
Iter: 325 loss: 1.39222948e-06
Iter: 326 loss: 1.38946132e-06
Iter: 327 loss: 1.38928431e-06
Iter: 328 loss: 1.38664791e-06
Iter: 329 loss: 1.41432224e-06
Iter: 330 loss: 1.38657094e-06
Iter: 331 loss: 1.38364146e-06
Iter: 332 loss: 1.38645487e-06
Iter: 333 loss: 1.38194605e-06
Iter: 334 loss: 1.37985444e-06
Iter: 335 loss: 1.37912662e-06
Iter: 336 loss: 1.37788993e-06
Iter: 337 loss: 1.37523534e-06
Iter: 338 loss: 1.39449924e-06
Iter: 339 loss: 1.37503662e-06
Iter: 340 loss: 1.37205325e-06
Iter: 341 loss: 1.38566588e-06
Iter: 342 loss: 1.37150664e-06
Iter: 343 loss: 1.36985227e-06
Iter: 344 loss: 1.36802771e-06
Iter: 345 loss: 1.36777635e-06
Iter: 346 loss: 1.36519543e-06
Iter: 347 loss: 1.39508859e-06
Iter: 348 loss: 1.36513688e-06
Iter: 349 loss: 1.36246706e-06
Iter: 350 loss: 1.36025551e-06
Iter: 351 loss: 1.3594647e-06
Iter: 352 loss: 1.35670598e-06
Iter: 353 loss: 1.37294376e-06
Iter: 354 loss: 1.3563573e-06
Iter: 355 loss: 1.35490791e-06
Iter: 356 loss: 1.35487812e-06
Iter: 357 loss: 1.3537225e-06
Iter: 358 loss: 1.3514391e-06
Iter: 359 loss: 1.39553322e-06
Iter: 360 loss: 1.35142113e-06
Iter: 361 loss: 1.34924608e-06
Iter: 362 loss: 1.36107178e-06
Iter: 363 loss: 1.34895095e-06
Iter: 364 loss: 1.34682261e-06
Iter: 365 loss: 1.36218682e-06
Iter: 366 loss: 1.34662093e-06
Iter: 367 loss: 1.34502284e-06
Iter: 368 loss: 1.34114885e-06
Iter: 369 loss: 1.38124255e-06
Iter: 370 loss: 1.34067386e-06
Iter: 371 loss: 1.33758681e-06
Iter: 372 loss: 1.37674033e-06
Iter: 373 loss: 1.33755111e-06
Iter: 374 loss: 1.33537162e-06
Iter: 375 loss: 1.36738038e-06
Iter: 376 loss: 1.33540721e-06
Iter: 377 loss: 1.33396986e-06
Iter: 378 loss: 1.33126753e-06
Iter: 379 loss: 1.39153963e-06
Iter: 380 loss: 1.3312997e-06
Iter: 381 loss: 1.32998684e-06
Iter: 382 loss: 1.32991295e-06
Iter: 383 loss: 1.32852392e-06
Iter: 384 loss: 1.32866319e-06
Iter: 385 loss: 1.32750608e-06
Iter: 386 loss: 1.32565663e-06
Iter: 387 loss: 1.32447849e-06
Iter: 388 loss: 1.32377545e-06
Iter: 389 loss: 1.32218372e-06
Iter: 390 loss: 1.322049e-06
Iter: 391 loss: 1.32059677e-06
Iter: 392 loss: 1.3193486e-06
Iter: 393 loss: 1.31894751e-06
Iter: 394 loss: 1.31677439e-06
Iter: 395 loss: 1.3179814e-06
Iter: 396 loss: 1.31543993e-06
Iter: 397 loss: 1.31408035e-06
Iter: 398 loss: 1.31386287e-06
Iter: 399 loss: 1.31296167e-06
Iter: 400 loss: 1.31133788e-06
Iter: 401 loss: 1.31132617e-06
Iter: 402 loss: 1.30958233e-06
Iter: 403 loss: 1.31057607e-06
Iter: 404 loss: 1.30851458e-06
Iter: 405 loss: 1.30757758e-06
Iter: 406 loss: 1.30726858e-06
Iter: 407 loss: 1.30616684e-06
Iter: 408 loss: 1.30378203e-06
Iter: 409 loss: 1.33853928e-06
Iter: 410 loss: 1.30365856e-06
Iter: 411 loss: 1.30124749e-06
Iter: 412 loss: 1.31476259e-06
Iter: 413 loss: 1.30088222e-06
Iter: 414 loss: 1.29888849e-06
Iter: 415 loss: 1.32266109e-06
Iter: 416 loss: 1.29883108e-06
Iter: 417 loss: 1.29790055e-06
Iter: 418 loss: 1.29637897e-06
Iter: 419 loss: 1.29638454e-06
Iter: 420 loss: 1.29463774e-06
Iter: 421 loss: 1.31166757e-06
Iter: 422 loss: 1.29459136e-06
Iter: 423 loss: 1.29305022e-06
Iter: 424 loss: 1.2989608e-06
Iter: 425 loss: 1.29265754e-06
Iter: 426 loss: 1.29177238e-06
Iter: 427 loss: 1.29037244e-06
Iter: 428 loss: 1.29030673e-06
Iter: 429 loss: 1.28844295e-06
Iter: 430 loss: 1.30616138e-06
Iter: 431 loss: 1.28837132e-06
Iter: 432 loss: 1.2864059e-06
Iter: 433 loss: 1.28500983e-06
Iter: 434 loss: 1.28436113e-06
Iter: 435 loss: 1.28241766e-06
Iter: 436 loss: 1.28325451e-06
Iter: 437 loss: 1.28110764e-06
Iter: 438 loss: 1.27972885e-06
Iter: 439 loss: 1.27961869e-06
Iter: 440 loss: 1.27820658e-06
Iter: 441 loss: 1.27821522e-06
Iter: 442 loss: 1.27707335e-06
Iter: 443 loss: 1.27591e-06
Iter: 444 loss: 1.27659109e-06
Iter: 445 loss: 1.27515159e-06
Iter: 446 loss: 1.27388694e-06
Iter: 447 loss: 1.2738966e-06
Iter: 448 loss: 1.27297324e-06
Iter: 449 loss: 1.27135593e-06
Iter: 450 loss: 1.27137571e-06
Iter: 451 loss: 1.26963209e-06
Iter: 452 loss: 1.27864e-06
Iter: 453 loss: 1.26932548e-06
Iter: 454 loss: 1.26728071e-06
Iter: 455 loss: 1.27785461e-06
Iter: 456 loss: 1.2669766e-06
Iter: 457 loss: 1.26549446e-06
Iter: 458 loss: 1.26430598e-06
Iter: 459 loss: 1.2638867e-06
Iter: 460 loss: 1.262654e-06
Iter: 461 loss: 1.26266286e-06
Iter: 462 loss: 1.26152645e-06
Iter: 463 loss: 1.26158523e-06
Iter: 464 loss: 1.26058399e-06
Iter: 465 loss: 1.25932524e-06
Iter: 466 loss: 1.25861789e-06
Iter: 467 loss: 1.25802626e-06
Iter: 468 loss: 1.25675774e-06
Iter: 469 loss: 1.27271983e-06
Iter: 470 loss: 1.25675945e-06
Iter: 471 loss: 1.25518045e-06
Iter: 472 loss: 1.25594602e-06
Iter: 473 loss: 1.25415852e-06
Iter: 474 loss: 1.25253291e-06
Iter: 475 loss: 1.25258953e-06
Iter: 476 loss: 1.25127315e-06
Iter: 477 loss: 1.25063616e-06
Iter: 478 loss: 1.25035331e-06
Iter: 479 loss: 1.24955477e-06
Iter: 480 loss: 1.24786311e-06
Iter: 481 loss: 1.27488386e-06
Iter: 482 loss: 1.24780195e-06
Iter: 483 loss: 1.24604389e-06
Iter: 484 loss: 1.25580141e-06
Iter: 485 loss: 1.24574512e-06
Iter: 486 loss: 1.24459552e-06
Iter: 487 loss: 1.24461735e-06
Iter: 488 loss: 1.24378892e-06
Iter: 489 loss: 1.2421616e-06
Iter: 490 loss: 1.27251883e-06
Iter: 491 loss: 1.24216308e-06
Iter: 492 loss: 1.24043072e-06
Iter: 493 loss: 1.25247391e-06
Iter: 494 loss: 1.24023722e-06
Iter: 495 loss: 1.23853977e-06
Iter: 496 loss: 1.24590281e-06
Iter: 497 loss: 1.23820882e-06
Iter: 498 loss: 1.23697407e-06
Iter: 499 loss: 1.23484961e-06
Iter: 500 loss: 1.2348371e-06
Iter: 501 loss: 1.23304289e-06
Iter: 502 loss: 1.25364318e-06
Iter: 503 loss: 1.2330006e-06
Iter: 504 loss: 1.23196787e-06
Iter: 505 loss: 1.23196617e-06
Iter: 506 loss: 1.23135669e-06
Iter: 507 loss: 1.22986421e-06
Iter: 508 loss: 1.2414589e-06
Iter: 509 loss: 1.22953361e-06
Iter: 510 loss: 1.22867175e-06
Iter: 511 loss: 1.22849985e-06
Iter: 512 loss: 1.22753113e-06
Iter: 513 loss: 1.22730034e-06
Iter: 514 loss: 1.22664483e-06
Iter: 515 loss: 1.22541883e-06
Iter: 516 loss: 1.22405504e-06
Iter: 517 loss: 1.22381743e-06
Iter: 518 loss: 1.22259212e-06
Iter: 519 loss: 1.22236429e-06
Iter: 520 loss: 1.22137669e-06
Iter: 521 loss: 1.22106007e-06
Iter: 522 loss: 1.22047391e-06
Iter: 523 loss: 1.21932226e-06
Iter: 524 loss: 1.22070446e-06
Iter: 525 loss: 1.21875576e-06
Iter: 526 loss: 1.21740618e-06
Iter: 527 loss: 1.23040877e-06
Iter: 528 loss: 1.21735115e-06
Iter: 529 loss: 1.21647395e-06
Iter: 530 loss: 1.2154544e-06
Iter: 531 loss: 1.21536232e-06
Iter: 532 loss: 1.21401945e-06
Iter: 533 loss: 1.2143164e-06
Iter: 534 loss: 1.21302401e-06
Iter: 535 loss: 1.21200594e-06
Iter: 536 loss: 1.21180813e-06
Iter: 537 loss: 1.21092035e-06
Iter: 538 loss: 1.20923869e-06
Iter: 539 loss: 1.24227722e-06
Iter: 540 loss: 1.20919e-06
Iter: 541 loss: 1.20761854e-06
Iter: 542 loss: 1.21609082e-06
Iter: 543 loss: 1.20736945e-06
Iter: 544 loss: 1.20568018e-06
Iter: 545 loss: 1.21595576e-06
Iter: 546 loss: 1.20543359e-06
Iter: 547 loss: 1.20462391e-06
Iter: 548 loss: 1.20382037e-06
Iter: 549 loss: 1.20365905e-06
Iter: 550 loss: 1.20254754e-06
Iter: 551 loss: 1.21602852e-06
Iter: 552 loss: 1.20252309e-06
Iter: 553 loss: 1.2013611e-06
Iter: 554 loss: 1.20145285e-06
Iter: 555 loss: 1.2004266e-06
Iter: 556 loss: 1.19928859e-06
Iter: 557 loss: 1.20121217e-06
Iter: 558 loss: 1.19873744e-06
Iter: 559 loss: 1.19761876e-06
Iter: 560 loss: 1.20773859e-06
Iter: 561 loss: 1.19749825e-06
Iter: 562 loss: 1.19633046e-06
Iter: 563 loss: 1.19448339e-06
Iter: 564 loss: 1.19448453e-06
Iter: 565 loss: 1.19295623e-06
Iter: 566 loss: 1.20015966e-06
Iter: 567 loss: 1.19265587e-06
Iter: 568 loss: 1.19186166e-06
Iter: 569 loss: 1.19184983e-06
Iter: 570 loss: 1.19104311e-06
Iter: 571 loss: 1.1899391e-06
Iter: 572 loss: 1.1898768e-06
Iter: 573 loss: 1.18881371e-06
Iter: 574 loss: 1.19050787e-06
Iter: 575 loss: 1.18837181e-06
Iter: 576 loss: 1.18713899e-06
Iter: 577 loss: 1.20136929e-06
Iter: 578 loss: 1.1871482e-06
Iter: 579 loss: 1.18625246e-06
Iter: 580 loss: 1.18465675e-06
Iter: 581 loss: 1.22227993e-06
Iter: 582 loss: 1.18465107e-06
Iter: 583 loss: 1.1835333e-06
Iter: 584 loss: 1.19943809e-06
Iter: 585 loss: 1.18353057e-06
Iter: 586 loss: 1.18233743e-06
Iter: 587 loss: 1.18506296e-06
Iter: 588 loss: 1.18192952e-06
Iter: 589 loss: 1.18093317e-06
Iter: 590 loss: 1.18155265e-06
Iter: 591 loss: 1.18032949e-06
Iter: 592 loss: 1.17962782e-06
Iter: 593 loss: 1.17962463e-06
Iter: 594 loss: 1.17900481e-06
Iter: 595 loss: 1.17843183e-06
Iter: 596 loss: 1.17831416e-06
Iter: 597 loss: 1.17728678e-06
Iter: 598 loss: 1.17625132e-06
Iter: 599 loss: 1.17602281e-06
Iter: 600 loss: 1.17494324e-06
Iter: 601 loss: 1.17494221e-06
Iter: 602 loss: 1.17370769e-06
Iter: 603 loss: 1.17451305e-06
Iter: 604 loss: 1.17296031e-06
Iter: 605 loss: 1.17170362e-06
Iter: 606 loss: 1.17061666e-06
Iter: 607 loss: 1.17029424e-06
Iter: 608 loss: 1.17026832e-06
Iter: 609 loss: 1.1695513e-06
Iter: 610 loss: 1.16901072e-06
Iter: 611 loss: 1.16777642e-06
Iter: 612 loss: 1.18636308e-06
Iter: 613 loss: 1.16776152e-06
Iter: 614 loss: 1.16662341e-06
Iter: 615 loss: 1.17325806e-06
Iter: 616 loss: 1.16644674e-06
Iter: 617 loss: 1.1655568e-06
Iter: 618 loss: 1.17918682e-06
Iter: 619 loss: 1.16555725e-06
Iter: 620 loss: 1.16504725e-06
Iter: 621 loss: 1.16402771e-06
Iter: 622 loss: 1.18472099e-06
Iter: 623 loss: 1.16401759e-06
Iter: 624 loss: 1.162898e-06
Iter: 625 loss: 1.17460297e-06
Iter: 626 loss: 1.16287947e-06
Iter: 627 loss: 1.16188119e-06
Iter: 628 loss: 1.16386536e-06
Iter: 629 loss: 1.16150522e-06
Iter: 630 loss: 1.16067918e-06
Iter: 631 loss: 1.15963962e-06
Iter: 632 loss: 1.15957266e-06
Iter: 633 loss: 1.15841453e-06
Iter: 634 loss: 1.17122192e-06
Iter: 635 loss: 1.15842442e-06
Iter: 636 loss: 1.15762634e-06
Iter: 637 loss: 1.16703563e-06
Iter: 638 loss: 1.15760145e-06
Iter: 639 loss: 1.15716693e-06
Iter: 640 loss: 1.15606929e-06
Iter: 641 loss: 1.16542697e-06
Iter: 642 loss: 1.1559099e-06
Iter: 643 loss: 1.15491548e-06
Iter: 644 loss: 1.15493572e-06
Iter: 645 loss: 1.15386922e-06
Iter: 646 loss: 1.15377168e-06
Iter: 647 loss: 1.15297087e-06
Iter: 648 loss: 1.15197884e-06
Iter: 649 loss: 1.15160276e-06
Iter: 650 loss: 1.15103558e-06
Iter: 651 loss: 1.14988154e-06
Iter: 652 loss: 1.14986165e-06
Iter: 653 loss: 1.14908653e-06
Iter: 654 loss: 1.14854447e-06
Iter: 655 loss: 1.14827503e-06
Iter: 656 loss: 1.14746922e-06
Iter: 657 loss: 1.15255875e-06
Iter: 658 loss: 1.14739646e-06
Iter: 659 loss: 1.14650413e-06
Iter: 660 loss: 1.14873933e-06
Iter: 661 loss: 1.14621503e-06
Iter: 662 loss: 1.1453908e-06
Iter: 663 loss: 1.14472573e-06
Iter: 664 loss: 1.14448289e-06
Iter: 665 loss: 1.14334364e-06
Iter: 666 loss: 1.14634804e-06
Iter: 667 loss: 1.14295221e-06
Iter: 668 loss: 1.14175327e-06
Iter: 669 loss: 1.15825742e-06
Iter: 670 loss: 1.14176396e-06
Iter: 671 loss: 1.14098771e-06
Iter: 672 loss: 1.13970486e-06
Iter: 673 loss: 1.13968508e-06
Iter: 674 loss: 1.13860779e-06
Iter: 675 loss: 1.14782017e-06
Iter: 676 loss: 1.13857868e-06
Iter: 677 loss: 1.13738713e-06
Iter: 678 loss: 1.14085583e-06
Iter: 679 loss: 1.13705346e-06
Iter: 680 loss: 1.13640965e-06
Iter: 681 loss: 1.13605461e-06
Iter: 682 loss: 1.13576289e-06
Iter: 683 loss: 1.13508963e-06
Iter: 684 loss: 1.13508918e-06
Iter: 685 loss: 1.13439023e-06
Iter: 686 loss: 1.1332429e-06
Iter: 687 loss: 1.13320698e-06
Iter: 688 loss: 1.13209376e-06
Iter: 689 loss: 1.13955662e-06
Iter: 690 loss: 1.13198757e-06
Iter: 691 loss: 1.1311181e-06
Iter: 692 loss: 1.13928e-06
Iter: 693 loss: 1.13106148e-06
Iter: 694 loss: 1.13042142e-06
Iter: 695 loss: 1.12931298e-06
Iter: 696 loss: 1.12929752e-06
Iter: 697 loss: 1.12812745e-06
Iter: 698 loss: 1.13330782e-06
Iter: 699 loss: 1.12791554e-06
Iter: 700 loss: 1.12737939e-06
Iter: 701 loss: 1.12727719e-06
Iter: 702 loss: 1.12687042e-06
Iter: 703 loss: 1.12583609e-06
Iter: 704 loss: 1.13998806e-06
Iter: 705 loss: 1.12578391e-06
Iter: 706 loss: 1.12474072e-06
Iter: 707 loss: 1.13036822e-06
Iter: 708 loss: 1.12457121e-06
Iter: 709 loss: 1.12357964e-06
Iter: 710 loss: 1.13289411e-06
Iter: 711 loss: 1.12355906e-06
Iter: 712 loss: 1.1229539e-06
Iter: 713 loss: 1.12157932e-06
Iter: 714 loss: 1.1379982e-06
Iter: 715 loss: 1.12146677e-06
Iter: 716 loss: 1.12093494e-06
Iter: 717 loss: 1.12070529e-06
Iter: 718 loss: 1.11993904e-06
Iter: 719 loss: 1.12034354e-06
Iter: 720 loss: 1.1195209e-06
Iter: 721 loss: 1.11880115e-06
Iter: 722 loss: 1.11875784e-06
Iter: 723 loss: 1.11822226e-06
Iter: 724 loss: 1.11739735e-06
Iter: 725 loss: 1.11740724e-06
Iter: 726 loss: 1.11689337e-06
Iter: 727 loss: 1.11630879e-06
Iter: 728 loss: 1.11622558e-06
Iter: 729 loss: 1.11530767e-06
Iter: 730 loss: 1.1149308e-06
Iter: 731 loss: 1.11444672e-06
Iter: 732 loss: 1.11378074e-06
Iter: 733 loss: 1.11359918e-06
Iter: 734 loss: 1.11283248e-06
Iter: 735 loss: 1.1120693e-06
Iter: 736 loss: 1.11195209e-06
Iter: 737 loss: 1.11104009e-06
Iter: 738 loss: 1.11222516e-06
Iter: 739 loss: 1.11057261e-06
Iter: 740 loss: 1.10978135e-06
Iter: 741 loss: 1.1097743e-06
Iter: 742 loss: 1.10931637e-06
Iter: 743 loss: 1.10836936e-06
Iter: 744 loss: 1.12868793e-06
Iter: 745 loss: 1.10839619e-06
Iter: 746 loss: 1.10765905e-06
Iter: 747 loss: 1.1126042e-06
Iter: 748 loss: 1.10758072e-06
Iter: 749 loss: 1.10661108e-06
Iter: 750 loss: 1.10962105e-06
Iter: 751 loss: 1.10633482e-06
Iter: 752 loss: 1.10570875e-06
Iter: 753 loss: 1.10530277e-06
Iter: 754 loss: 1.10505e-06
Iter: 755 loss: 1.10423798e-06
Iter: 756 loss: 1.11638565e-06
Iter: 757 loss: 1.10423548e-06
Iter: 758 loss: 1.10342887e-06
Iter: 759 loss: 1.10229564e-06
Iter: 760 loss: 1.10227711e-06
Iter: 761 loss: 1.10107885e-06
Iter: 762 loss: 1.10441283e-06
Iter: 763 loss: 1.100703e-06
Iter: 764 loss: 1.09995631e-06
Iter: 765 loss: 1.10950964e-06
Iter: 766 loss: 1.09994949e-06
Iter: 767 loss: 1.09912207e-06
Iter: 768 loss: 1.09911275e-06
Iter: 769 loss: 1.09841926e-06
Iter: 770 loss: 1.09761288e-06
Iter: 771 loss: 1.09783127e-06
Iter: 772 loss: 1.09707844e-06
Iter: 773 loss: 1.09634539e-06
Iter: 774 loss: 1.09634857e-06
Iter: 775 loss: 1.09561051e-06
Iter: 776 loss: 1.09414543e-06
Iter: 777 loss: 1.11942768e-06
Iter: 778 loss: 1.09411496e-06
Iter: 779 loss: 1.09292421e-06
Iter: 780 loss: 1.09998109e-06
Iter: 781 loss: 1.09281439e-06
Iter: 782 loss: 1.09195832e-06
Iter: 783 loss: 1.09194343e-06
Iter: 784 loss: 1.09147243e-06
Iter: 785 loss: 1.09037774e-06
Iter: 786 loss: 1.10706776e-06
Iter: 787 loss: 1.09033908e-06
Iter: 788 loss: 1.08984295e-06
Iter: 789 loss: 1.08975405e-06
Iter: 790 loss: 1.08923064e-06
Iter: 791 loss: 1.0892345e-06
Iter: 792 loss: 1.08878567e-06
Iter: 793 loss: 1.08812378e-06
Iter: 794 loss: 1.08726556e-06
Iter: 795 loss: 1.08718e-06
Iter: 796 loss: 1.0861155e-06
Iter: 797 loss: 1.09640087e-06
Iter: 798 loss: 1.08600841e-06
Iter: 799 loss: 1.08499489e-06
Iter: 800 loss: 1.09125767e-06
Iter: 801 loss: 1.08482936e-06
Iter: 802 loss: 1.08408722e-06
Iter: 803 loss: 1.08268011e-06
Iter: 804 loss: 1.11519125e-06
Iter: 805 loss: 1.08266977e-06
Iter: 806 loss: 1.08251231e-06
Iter: 807 loss: 1.08217296e-06
Iter: 808 loss: 1.08169684e-06
Iter: 809 loss: 1.08105201e-06
Iter: 810 loss: 1.08100699e-06
Iter: 811 loss: 1.080169e-06
Iter: 812 loss: 1.08033544e-06
Iter: 813 loss: 1.0795701e-06
Iter: 814 loss: 1.07960375e-06
Iter: 815 loss: 1.07919709e-06
Iter: 816 loss: 1.07887058e-06
Iter: 817 loss: 1.07792607e-06
Iter: 818 loss: 1.0821725e-06
Iter: 819 loss: 1.07761321e-06
Iter: 820 loss: 1.07661185e-06
Iter: 821 loss: 1.0766156e-06
Iter: 822 loss: 1.07576375e-06
Iter: 823 loss: 1.07854953e-06
Iter: 824 loss: 1.07552432e-06
Iter: 825 loss: 1.07484345e-06
Iter: 826 loss: 1.07375217e-06
Iter: 827 loss: 1.07374194e-06
Iter: 828 loss: 1.07257688e-06
Iter: 829 loss: 1.08080758e-06
Iter: 830 loss: 1.07245364e-06
Iter: 831 loss: 1.07194455e-06
Iter: 832 loss: 1.07188703e-06
Iter: 833 loss: 1.07151573e-06
Iter: 834 loss: 1.07064307e-06
Iter: 835 loss: 1.07889048e-06
Iter: 836 loss: 1.07049163e-06
Iter: 837 loss: 1.06943662e-06
Iter: 838 loss: 1.07461437e-06
Iter: 839 loss: 1.06928803e-06
Iter: 840 loss: 1.06824041e-06
Iter: 841 loss: 1.07991025e-06
Iter: 842 loss: 1.06822245e-06
Iter: 843 loss: 1.06768e-06
Iter: 844 loss: 1.06648167e-06
Iter: 845 loss: 1.08341123e-06
Iter: 846 loss: 1.06642983e-06
Iter: 847 loss: 1.0662875e-06
Iter: 848 loss: 1.06598088e-06
Iter: 849 loss: 1.06551681e-06
Iter: 850 loss: 1.06524851e-06
Iter: 851 loss: 1.06508958e-06
Iter: 852 loss: 1.06442292e-06
Iter: 853 loss: 1.06418565e-06
Iter: 854 loss: 1.06384596e-06
Iter: 855 loss: 1.06314815e-06
Iter: 856 loss: 1.06311654e-06
Iter: 857 loss: 1.06273353e-06
Iter: 858 loss: 1.06207472e-06
Iter: 859 loss: 1.06209177e-06
Iter: 860 loss: 1.0610936e-06
Iter: 861 loss: 1.06062885e-06
Iter: 862 loss: 1.06012442e-06
Iter: 863 loss: 1.0598468e-06
Iter: 864 loss: 1.05944491e-06
Iter: 865 loss: 1.05890899e-06
Iter: 866 loss: 1.05843037e-06
Iter: 867 loss: 1.05830816e-06
Iter: 868 loss: 1.05763593e-06
Iter: 869 loss: 1.05716833e-06
Iter: 870 loss: 1.05694301e-06
Iter: 871 loss: 1.05683807e-06
Iter: 872 loss: 1.05645972e-06
Iter: 873 loss: 1.05613913e-06
Iter: 874 loss: 1.05533866e-06
Iter: 875 loss: 1.06368384e-06
Iter: 876 loss: 1.05526101e-06
Iter: 877 loss: 1.0543514e-06
Iter: 878 loss: 1.05815445e-06
Iter: 879 loss: 1.05415688e-06
Iter: 880 loss: 1.05318804e-06
Iter: 881 loss: 1.06305765e-06
Iter: 882 loss: 1.0531744e-06
Iter: 883 loss: 1.05267623e-06
Iter: 884 loss: 1.05164463e-06
Iter: 885 loss: 1.06768607e-06
Iter: 886 loss: 1.05160427e-06
Iter: 887 loss: 1.0510056e-06
Iter: 888 loss: 1.05088986e-06
Iter: 889 loss: 1.05043955e-06
Iter: 890 loss: 1.04997196e-06
Iter: 891 loss: 1.04989454e-06
Iter: 892 loss: 1.0492447e-06
Iter: 893 loss: 1.04979779e-06
Iter: 894 loss: 1.04885203e-06
Iter: 895 loss: 1.04810977e-06
Iter: 896 loss: 1.0529335e-06
Iter: 897 loss: 1.04804417e-06
Iter: 898 loss: 1.04732771e-06
Iter: 899 loss: 1.05155505e-06
Iter: 900 loss: 1.04720164e-06
Iter: 901 loss: 1.04675337e-06
Iter: 902 loss: 1.04564083e-06
Iter: 903 loss: 1.055143e-06
Iter: 904 loss: 1.04546405e-06
Iter: 905 loss: 1.04457752e-06
Iter: 906 loss: 1.0445101e-06
Iter: 907 loss: 1.04365256e-06
Iter: 908 loss: 1.0459778e-06
Iter: 909 loss: 1.04334958e-06
Iter: 910 loss: 1.04294315e-06
Iter: 911 loss: 1.0421345e-06
Iter: 912 loss: 1.06025823e-06
Iter: 913 loss: 1.04213e-06
Iter: 914 loss: 1.04205469e-06
Iter: 915 loss: 1.04165679e-06
Iter: 916 loss: 1.04137087e-06
Iter: 917 loss: 1.04085484e-06
Iter: 918 loss: 1.05108234e-06
Iter: 919 loss: 1.04084847e-06
Iter: 920 loss: 1.04035416e-06
Iter: 921 loss: 1.04374146e-06
Iter: 922 loss: 1.0403005e-06
Iter: 923 loss: 1.0396451e-06
Iter: 924 loss: 1.04017045e-06
Iter: 925 loss: 1.03925527e-06
Iter: 926 loss: 1.03867114e-06
Iter: 927 loss: 1.03844968e-06
Iter: 928 loss: 1.03808861e-06
Iter: 929 loss: 1.03727859e-06
Iter: 930 loss: 1.04113133e-06
Iter: 931 loss: 1.0371491e-06
Iter: 932 loss: 1.03656259e-06
Iter: 933 loss: 1.03659409e-06
Iter: 934 loss: 1.03620869e-06
Iter: 935 loss: 1.03572711e-06
Iter: 936 loss: 1.03574848e-06
Iter: 937 loss: 1.03512207e-06
Iter: 938 loss: 1.03548075e-06
Iter: 939 loss: 1.03479306e-06
Iter: 940 loss: 1.03404773e-06
Iter: 941 loss: 1.03405466e-06
Iter: 942 loss: 1.03367381e-06
Iter: 943 loss: 1.03297327e-06
Iter: 944 loss: 1.04622018e-06
Iter: 945 loss: 1.03295508e-06
Iter: 946 loss: 1.03228263e-06
Iter: 947 loss: 1.03882735e-06
Iter: 948 loss: 1.03226535e-06
Iter: 949 loss: 1.03144623e-06
Iter: 950 loss: 1.03246703e-06
Iter: 951 loss: 1.03103889e-06
Iter: 952 loss: 1.03062007e-06
Iter: 953 loss: 1.03051241e-06
Iter: 954 loss: 1.03028697e-06
Iter: 955 loss: 1.02974741e-06
Iter: 956 loss: 1.0297332e-06
Iter: 957 loss: 1.02941021e-06
Iter: 958 loss: 1.0289981e-06
Iter: 959 loss: 1.02895956e-06
Iter: 960 loss: 1.02842091e-06
Iter: 961 loss: 1.02877198e-06
Iter: 962 loss: 1.02805052e-06
Iter: 963 loss: 1.02736226e-06
Iter: 964 loss: 1.03689604e-06
Iter: 965 loss: 1.02736237e-06
Iter: 966 loss: 1.02682179e-06
Iter: 967 loss: 1.02678e-06
Iter: 968 loss: 1.02634544e-06
Iter: 969 loss: 1.02574859e-06
Iter: 970 loss: 1.02509171e-06
Iter: 971 loss: 1.02498973e-06
Iter: 972 loss: 1.02483546e-06
Iter: 973 loss: 1.02446847e-06
Iter: 974 loss: 1.02409797e-06
Iter: 975 loss: 1.02366243e-06
Iter: 976 loss: 1.02363072e-06
Iter: 977 loss: 1.02313084e-06
Iter: 978 loss: 1.0230998e-06
Iter: 979 loss: 1.02272884e-06
Iter: 980 loss: 1.02201147e-06
Iter: 981 loss: 1.02199601e-06
Iter: 982 loss: 1.02168019e-06
Iter: 983 loss: 1.02093611e-06
Iter: 984 loss: 1.03149932e-06
Iter: 985 loss: 1.02092315e-06
Iter: 986 loss: 1.02038598e-06
Iter: 987 loss: 1.02033664e-06
Iter: 988 loss: 1.01975343e-06
Iter: 989 loss: 1.01916339e-06
Iter: 990 loss: 1.01905016e-06
Iter: 991 loss: 1.01841727e-06
Iter: 992 loss: 1.01963917e-06
Iter: 993 loss: 1.01814237e-06
Iter: 994 loss: 1.01761941e-06
Iter: 995 loss: 1.01760338e-06
Iter: 996 loss: 1.01716864e-06
Iter: 997 loss: 1.01763703e-06
Iter: 998 loss: 1.01692217e-06
Iter: 999 loss: 1.01647743e-06
Iter: 1000 loss: 1.01613432e-06
Iter: 1001 loss: 1.0160071e-06
Iter: 1002 loss: 1.01537398e-06
Iter: 1003 loss: 1.01972637e-06
Iter: 1004 loss: 1.015316e-06
Iter: 1005 loss: 1.0144712e-06
Iter: 1006 loss: 1.01527564e-06
Iter: 1007 loss: 1.01402247e-06
Iter: 1008 loss: 1.01353544e-06
Iter: 1009 loss: 1.01317391e-06
Iter: 1010 loss: 1.01296757e-06
Iter: 1011 loss: 1.01256785e-06
Iter: 1012 loss: 1.01246246e-06
Iter: 1013 loss: 1.01203648e-06
Iter: 1014 loss: 1.01153341e-06
Iter: 1015 loss: 1.01146884e-06
Iter: 1016 loss: 1.0110989e-06
Iter: 1017 loss: 1.01299531e-06
Iter: 1018 loss: 1.01101773e-06
Iter: 1019 loss: 1.01050455e-06
Iter: 1020 loss: 1.01119713e-06
Iter: 1021 loss: 1.01025375e-06
Iter: 1022 loss: 1.00971647e-06
Iter: 1023 loss: 1.00904435e-06
Iter: 1024 loss: 1.00896807e-06
Iter: 1025 loss: 1.00830766e-06
Iter: 1026 loss: 1.01765579e-06
Iter: 1027 loss: 1.00829288e-06
Iter: 1028 loss: 1.00768989e-06
Iter: 1029 loss: 1.00956277e-06
Iter: 1030 loss: 1.00746297e-06
Iter: 1031 loss: 1.00695456e-06
Iter: 1032 loss: 1.00706734e-06
Iter: 1033 loss: 1.0065985e-06
Iter: 1034 loss: 1.00612692e-06
Iter: 1035 loss: 1.00755165e-06
Iter: 1036 loss: 1.00595503e-06
Iter: 1037 loss: 1.00539887e-06
Iter: 1038 loss: 1.01023011e-06
Iter: 1039 loss: 1.00535669e-06
Iter: 1040 loss: 1.00502973e-06
Iter: 1041 loss: 1.00443685e-06
Iter: 1042 loss: 1.00445027e-06
Iter: 1043 loss: 1.00388468e-06
Iter: 1044 loss: 1.0077888e-06
Iter: 1045 loss: 1.00382249e-06
Iter: 1046 loss: 1.00306283e-06
Iter: 1047 loss: 1.00341367e-06
Iter: 1048 loss: 1.00254067e-06
Iter: 1049 loss: 1.00199054e-06
Iter: 1050 loss: 1.00241482e-06
Iter: 1051 loss: 1.00167165e-06
Iter: 1052 loss: 1.0012584e-06
Iter: 1053 loss: 1.00122043e-06
Iter: 1054 loss: 1.00088505e-06
Iter: 1055 loss: 1.00006798e-06
Iter: 1056 loss: 1.0098106e-06
Iter: 1057 loss: 9.99974645e-07
Iter: 1058 loss: 9.99536496e-07
Iter: 1059 loss: 9.99541e-07
Iter: 1060 loss: 9.99114491e-07
Iter: 1061 loss: 1.00055058e-06
Iter: 1062 loss: 9.99037e-07
Iter: 1063 loss: 9.98571068e-07
Iter: 1064 loss: 9.97969437e-07
Iter: 1065 loss: 9.97944426e-07
Iter: 1066 loss: 9.97202733e-07
Iter: 1067 loss: 9.99250574e-07
Iter: 1068 loss: 9.96967e-07
Iter: 1069 loss: 9.96405e-07
Iter: 1070 loss: 9.96424e-07
Iter: 1071 loss: 9.95959e-07
Iter: 1072 loss: 9.95391702e-07
Iter: 1073 loss: 9.95358278e-07
Iter: 1074 loss: 9.94889319e-07
Iter: 1075 loss: 9.9574163e-07
Iter: 1076 loss: 9.94668312e-07
Iter: 1077 loss: 9.94227e-07
Iter: 1078 loss: 9.94232664e-07
Iter: 1079 loss: 9.93977e-07
Iter: 1080 loss: 9.93362391e-07
Iter: 1081 loss: 1.00171974e-06
Iter: 1082 loss: 9.93361596e-07
Iter: 1083 loss: 9.92922764e-07
Iter: 1084 loss: 9.92932e-07
Iter: 1085 loss: 9.92401851e-07
Iter: 1086 loss: 9.91740535e-07
Iter: 1087 loss: 9.91685624e-07
Iter: 1088 loss: 9.90914486e-07
Iter: 1089 loss: 9.9367935e-07
Iter: 1090 loss: 9.90721901e-07
Iter: 1091 loss: 9.90268177e-07
Iter: 1092 loss: 9.90269427e-07
Iter: 1093 loss: 9.89935756e-07
Iter: 1094 loss: 9.89744763e-07
Iter: 1095 loss: 9.89631872e-07
Iter: 1096 loss: 9.89145519e-07
Iter: 1097 loss: 9.89315e-07
Iter: 1098 loss: 9.88797e-07
Iter: 1099 loss: 9.88467264e-07
Iter: 1100 loss: 9.88477e-07
Iter: 1101 loss: 9.88122792e-07
Iter: 1102 loss: 9.87803105e-07
Iter: 1103 loss: 9.87709882e-07
Iter: 1104 loss: 9.8712178e-07
Iter: 1105 loss: 9.8642e-07
Iter: 1106 loss: 9.86335522e-07
Iter: 1107 loss: 9.86479563e-07
Iter: 1108 loss: 9.85979113e-07
Iter: 1109 loss: 9.85657834e-07
Iter: 1110 loss: 9.84875442e-07
Iter: 1111 loss: 9.93417871e-07
Iter: 1112 loss: 9.84848384e-07
Iter: 1113 loss: 9.84294729e-07
Iter: 1114 loss: 9.89755563e-07
Iter: 1115 loss: 9.84265398e-07
Iter: 1116 loss: 9.83848167e-07
Iter: 1117 loss: 9.88402576e-07
Iter: 1118 loss: 9.83824748e-07
Iter: 1119 loss: 9.83585323e-07
Iter: 1120 loss: 9.83007567e-07
Iter: 1121 loss: 9.89154e-07
Iter: 1122 loss: 9.82940264e-07
Iter: 1123 loss: 9.82418896e-07
Iter: 1124 loss: 9.82429128e-07
Iter: 1125 loss: 9.82003712e-07
Iter: 1126 loss: 9.82074766e-07
Iter: 1127 loss: 9.81695848e-07
Iter: 1128 loss: 9.81192898e-07
Iter: 1129 loss: 9.81087396e-07
Iter: 1130 loss: 9.80753157e-07
Iter: 1131 loss: 9.801646e-07
Iter: 1132 loss: 9.84690587e-07
Iter: 1133 loss: 9.80120831e-07
Iter: 1134 loss: 9.79526703e-07
Iter: 1135 loss: 9.82163e-07
Iter: 1136 loss: 9.79459855e-07
Iter: 1137 loss: 9.79126185e-07
Iter: 1138 loss: 9.78694743e-07
Iter: 1139 loss: 9.78646426e-07
Iter: 1140 loss: 9.78249318e-07
Iter: 1141 loss: 9.84132612e-07
Iter: 1142 loss: 9.7822e-07
Iter: 1143 loss: 9.77784453e-07
Iter: 1144 loss: 9.78161438e-07
Iter: 1145 loss: 9.77500463e-07
Iter: 1146 loss: 9.77075615e-07
Iter: 1147 loss: 9.76308229e-07
Iter: 1148 loss: 9.94178663e-07
Iter: 1149 loss: 9.76289357e-07
Iter: 1150 loss: 9.76017e-07
Iter: 1151 loss: 9.75820853e-07
Iter: 1152 loss: 9.75433068e-07
Iter: 1153 loss: 9.74918748e-07
Iter: 1154 loss: 9.7488612e-07
Iter: 1155 loss: 9.74396698e-07
Iter: 1156 loss: 9.79243509e-07
Iter: 1157 loss: 9.7437669e-07
Iter: 1158 loss: 9.73925353e-07
Iter: 1159 loss: 9.74597469e-07
Iter: 1160 loss: 9.73672286e-07
Iter: 1161 loss: 9.73274382e-07
Iter: 1162 loss: 9.74116801e-07
Iter: 1163 loss: 9.73082365e-07
Iter: 1164 loss: 9.72741873e-07
Iter: 1165 loss: 9.73029614e-07
Iter: 1166 loss: 9.72548264e-07
Iter: 1167 loss: 9.71997679e-07
Iter: 1168 loss: 9.74692512e-07
Iter: 1169 loss: 9.7185e-07
Iter: 1170 loss: 9.71377062e-07
Iter: 1171 loss: 9.71105578e-07
Iter: 1172 loss: 9.70893552e-07
Iter: 1173 loss: 9.70321935e-07
Iter: 1174 loss: 9.72546104e-07
Iter: 1175 loss: 9.70209271e-07
Iter: 1176 loss: 9.69572397e-07
Iter: 1177 loss: 9.73767783e-07
Iter: 1178 loss: 9.6948952e-07
Iter: 1179 loss: 9.69129132e-07
Iter: 1180 loss: 9.68648465e-07
Iter: 1181 loss: 9.68611e-07
Iter: 1182 loss: 9.68350264e-07
Iter: 1183 loss: 9.6834242e-07
Iter: 1184 loss: 9.68008635e-07
Iter: 1185 loss: 9.67515462e-07
Iter: 1186 loss: 9.67513643e-07
Iter: 1187 loss: 9.67044e-07
Iter: 1188 loss: 9.70176529e-07
Iter: 1189 loss: 9.6697363e-07
Iter: 1190 loss: 9.6643339e-07
Iter: 1191 loss: 9.68211225e-07
Iter: 1192 loss: 9.66291736e-07
Iter: 1193 loss: 9.65739e-07
Iter: 1194 loss: 9.65567779e-07
Iter: 1195 loss: 9.65273557e-07
Iter: 1196 loss: 9.64595301e-07
Iter: 1197 loss: 9.68029894e-07
Iter: 1198 loss: 9.64464107e-07
Iter: 1199 loss: 9.63966386e-07
Iter: 1200 loss: 9.70145493e-07
Iter: 1201 loss: 9.63973434e-07
Iter: 1202 loss: 9.6364613e-07
Iter: 1203 loss: 9.6313056e-07
Iter: 1204 loss: 9.63085199e-07
Iter: 1205 loss: 9.62488e-07
Iter: 1206 loss: 9.64443643e-07
Iter: 1207 loss: 9.62297463e-07
Iter: 1208 loss: 9.62018817e-07
Iter: 1209 loss: 9.61971864e-07
Iter: 1210 loss: 9.6173892e-07
Iter: 1211 loss: 9.61103865e-07
Iter: 1212 loss: 9.64580067e-07
Iter: 1213 loss: 9.60917077e-07
Iter: 1214 loss: 9.60303169e-07
Iter: 1215 loss: 9.6028657e-07
Iter: 1216 loss: 9.59738259e-07
Iter: 1217 loss: 9.62092145e-07
Iter: 1218 loss: 9.59609451e-07
Iter: 1219 loss: 9.59269187e-07
Iter: 1220 loss: 9.58974169e-07
Iter: 1221 loss: 9.58903797e-07
Iter: 1222 loss: 9.58386067e-07
Iter: 1223 loss: 9.65252752e-07
Iter: 1224 loss: 9.58383225e-07
Iter: 1225 loss: 9.58075248e-07
Iter: 1226 loss: 9.57836619e-07
Iter: 1227 loss: 9.57713382e-07
Iter: 1228 loss: 9.57203611e-07
Iter: 1229 loss: 9.5808582e-07
Iter: 1230 loss: 9.5701e-07
Iter: 1231 loss: 9.56478402e-07
Iter: 1232 loss: 9.60911393e-07
Iter: 1233 loss: 9.56453e-07
Iter: 1234 loss: 9.55995347e-07
Iter: 1235 loss: 9.55680548e-07
Iter: 1236 loss: 9.55502856e-07
Iter: 1237 loss: 9.54873713e-07
Iter: 1238 loss: 9.54947836e-07
Iter: 1239 loss: 9.54392362e-07
Iter: 1240 loss: 9.54099e-07
Iter: 1241 loss: 9.53902372e-07
Iter: 1242 loss: 9.53571487e-07
Iter: 1243 loss: 9.53048811e-07
Iter: 1244 loss: 9.53026188e-07
Iter: 1245 loss: 9.52558594e-07
Iter: 1246 loss: 9.53282665e-07
Iter: 1247 loss: 9.52342646e-07
Iter: 1248 loss: 9.51769607e-07
Iter: 1249 loss: 9.58653118e-07
Iter: 1250 loss: 9.5175983e-07
Iter: 1251 loss: 9.51452137e-07
Iter: 1252 loss: 9.51071797e-07
Iter: 1253 loss: 9.51036668e-07
Iter: 1254 loss: 9.50592039e-07
Iter: 1255 loss: 9.57122666e-07
Iter: 1256 loss: 9.50605397e-07
Iter: 1257 loss: 9.50255071e-07
Iter: 1258 loss: 9.49667424e-07
Iter: 1259 loss: 9.4962445e-07
Iter: 1260 loss: 9.48969102e-07
Iter: 1261 loss: 9.52057405e-07
Iter: 1262 loss: 9.48842171e-07
Iter: 1263 loss: 9.48403624e-07
Iter: 1264 loss: 9.50452886e-07
Iter: 1265 loss: 9.48329102e-07
Iter: 1266 loss: 9.47831495e-07
Iter: 1267 loss: 9.48345757e-07
Iter: 1268 loss: 9.47569788e-07
Iter: 1269 loss: 9.47098783e-07
Iter: 1270 loss: 9.47054389e-07
Iter: 1271 loss: 9.46715375e-07
Iter: 1272 loss: 9.46436728e-07
Iter: 1273 loss: 9.46388354e-07
Iter: 1274 loss: 9.46061e-07
Iter: 1275 loss: 9.45591637e-07
Iter: 1276 loss: 9.45579814e-07
Iter: 1277 loss: 9.45043e-07
Iter: 1278 loss: 9.45262173e-07
Iter: 1279 loss: 9.44662759e-07
Iter: 1280 loss: 9.44424e-07
Iter: 1281 loss: 9.44270823e-07
Iter: 1282 loss: 9.44020144e-07
Iter: 1283 loss: 9.434e-07
Iter: 1284 loss: 9.50837148e-07
Iter: 1285 loss: 9.433478e-07
Iter: 1286 loss: 9.42917097e-07
Iter: 1287 loss: 9.42898907e-07
Iter: 1288 loss: 9.4259849e-07
Iter: 1289 loss: 9.42476674e-07
Iter: 1290 loss: 9.42280735e-07
Iter: 1291 loss: 9.41925748e-07
Iter: 1292 loss: 9.43105817e-07
Iter: 1293 loss: 9.41839858e-07
Iter: 1294 loss: 9.41405688e-07
Iter: 1295 loss: 9.4252988e-07
Iter: 1296 loss: 9.41233054e-07
Iter: 1297 loss: 9.4072891e-07
Iter: 1298 loss: 9.41486405e-07
Iter: 1299 loss: 9.40491873e-07
Iter: 1300 loss: 9.3999779e-07
Iter: 1301 loss: 9.39448114e-07
Iter: 1302 loss: 9.39355118e-07
Iter: 1303 loss: 9.38734843e-07
Iter: 1304 loss: 9.38737742e-07
Iter: 1305 loss: 9.38084327e-07
Iter: 1306 loss: 9.39194649e-07
Iter: 1307 loss: 9.37811876e-07
Iter: 1308 loss: 9.3742824e-07
Iter: 1309 loss: 9.37139305e-07
Iter: 1310 loss: 9.36996742e-07
Iter: 1311 loss: 9.36703259e-07
Iter: 1312 loss: 9.36678e-07
Iter: 1313 loss: 9.36352762e-07
Iter: 1314 loss: 9.35885225e-07
Iter: 1315 loss: 9.35844469e-07
Iter: 1316 loss: 9.35495791e-07
Iter: 1317 loss: 9.4040422e-07
Iter: 1318 loss: 9.3549977e-07
Iter: 1319 loss: 9.35137336e-07
Iter: 1320 loss: 9.34943216e-07
Iter: 1321 loss: 9.34785362e-07
Iter: 1322 loss: 9.34321747e-07
Iter: 1323 loss: 9.35304797e-07
Iter: 1324 loss: 9.34123591e-07
Iter: 1325 loss: 9.33668161e-07
Iter: 1326 loss: 9.36422452e-07
Iter: 1327 loss: 9.33579031e-07
Iter: 1328 loss: 9.3316163e-07
Iter: 1329 loss: 9.34055947e-07
Iter: 1330 loss: 9.33017645e-07
Iter: 1331 loss: 9.32562671e-07
Iter: 1332 loss: 9.32269927e-07
Iter: 1333 loss: 9.32148623e-07
Iter: 1334 loss: 9.31739805e-07
Iter: 1335 loss: 9.37334846e-07
Iter: 1336 loss: 9.31757143e-07
Iter: 1337 loss: 9.31350542e-07
Iter: 1338 loss: 9.32349849e-07
Iter: 1339 loss: 9.31194108e-07
Iter: 1340 loss: 9.3086777e-07
Iter: 1341 loss: 9.30307294e-07
Iter: 1342 loss: 9.3030684e-07
Iter: 1343 loss: 9.29916837e-07
Iter: 1344 loss: 9.29898192e-07
Iter: 1345 loss: 9.29476073e-07
Iter: 1346 loss: 9.29298e-07
Iter: 1347 loss: 9.29032637e-07
Iter: 1348 loss: 9.28569648e-07
Iter: 1349 loss: 9.30940473e-07
Iter: 1350 loss: 9.28498139e-07
Iter: 1351 loss: 9.27996211e-07
Iter: 1352 loss: 9.29620228e-07
Iter: 1353 loss: 9.27871042e-07
Iter: 1354 loss: 9.27583073e-07
Iter: 1355 loss: 9.27657766e-07
Iter: 1356 loss: 9.27382075e-07
Iter: 1357 loss: 9.26964276e-07
Iter: 1358 loss: 9.29106818e-07
Iter: 1359 loss: 9.26878329e-07
Iter: 1360 loss: 9.26504526e-07
Iter: 1361 loss: 9.27312556e-07
Iter: 1362 loss: 9.26360769e-07
Iter: 1363 loss: 9.25922564e-07
Iter: 1364 loss: 9.25550125e-07
Iter: 1365 loss: 9.25429333e-07
Iter: 1366 loss: 9.24809569e-07
Iter: 1367 loss: 9.27102292e-07
Iter: 1368 loss: 9.24644837e-07
Iter: 1369 loss: 9.24053438e-07
Iter: 1370 loss: 9.31848206e-07
Iter: 1371 loss: 9.24035305e-07
Iter: 1372 loss: 9.23708626e-07
Iter: 1373 loss: 9.23119615e-07
Iter: 1374 loss: 9.23109383e-07
Iter: 1375 loss: 9.22577271e-07
Iter: 1376 loss: 9.25497261e-07
Iter: 1377 loss: 9.22480694e-07
Iter: 1378 loss: 9.21929711e-07
Iter: 1379 loss: 9.27238375e-07
Iter: 1380 loss: 9.21895605e-07
Iter: 1381 loss: 9.21660785e-07
Iter: 1382 loss: 9.21539254e-07
Iter: 1383 loss: 9.21432843e-07
Iter: 1384 loss: 9.20975481e-07
Iter: 1385 loss: 9.23533094e-07
Iter: 1386 loss: 9.20905791e-07
Iter: 1387 loss: 9.20562627e-07
Iter: 1388 loss: 9.20139e-07
Iter: 1389 loss: 9.20111233e-07
Iter: 1390 loss: 9.19619879e-07
Iter: 1391 loss: 9.26348434e-07
Iter: 1392 loss: 9.19604133e-07
Iter: 1393 loss: 9.19237777e-07
Iter: 1394 loss: 9.19794161e-07
Iter: 1395 loss: 9.19080378e-07
Iter: 1396 loss: 9.18575552e-07
Iter: 1397 loss: 9.18177079e-07
Iter: 1398 loss: 9.18043042e-07
Iter: 1399 loss: 9.17474949e-07
Iter: 1400 loss: 9.20891466e-07
Iter: 1401 loss: 9.17406965e-07
Iter: 1402 loss: 9.17105353e-07
Iter: 1403 loss: 9.17068292e-07
Iter: 1404 loss: 9.16847398e-07
Iter: 1405 loss: 9.16253498e-07
Iter: 1406 loss: 9.2144569e-07
Iter: 1407 loss: 9.16153567e-07
Iter: 1408 loss: 9.15511521e-07
Iter: 1409 loss: 9.19417175e-07
Iter: 1410 loss: 9.15452915e-07
Iter: 1411 loss: 9.15039209e-07
Iter: 1412 loss: 9.15035059e-07
Iter: 1413 loss: 9.14729299e-07
Iter: 1414 loss: 9.14176098e-07
Iter: 1415 loss: 9.26430175e-07
Iter: 1416 loss: 9.14184795e-07
Iter: 1417 loss: 9.13825602e-07
Iter: 1418 loss: 9.13779218e-07
Iter: 1419 loss: 9.13533e-07
Iter: 1420 loss: 9.13113695e-07
Iter: 1421 loss: 9.22001277e-07
Iter: 1422 loss: 9.13110341e-07
Iter: 1423 loss: 9.12680662e-07
Iter: 1424 loss: 9.17349382e-07
Iter: 1425 loss: 9.12677081e-07
Iter: 1426 loss: 9.12279802e-07
Iter: 1427 loss: 9.13303552e-07
Iter: 1428 loss: 9.12145651e-07
Iter: 1429 loss: 9.11766278e-07
Iter: 1430 loss: 9.11535039e-07
Iter: 1431 loss: 9.11355e-07
Iter: 1432 loss: 9.10788458e-07
Iter: 1433 loss: 9.10891799e-07
Iter: 1434 loss: 9.10342692e-07
Iter: 1435 loss: 9.10011579e-07
Iter: 1436 loss: 9.09926086e-07
Iter: 1437 loss: 9.09559787e-07
Iter: 1438 loss: 9.09018297e-07
Iter: 1439 loss: 9.09008804e-07
Iter: 1440 loss: 9.08456343e-07
Iter: 1441 loss: 9.08707591e-07
Iter: 1442 loss: 9.08074753e-07
Iter: 1443 loss: 9.07925823e-07
Iter: 1444 loss: 9.07703395e-07
Iter: 1445 loss: 9.07504614e-07
Iter: 1446 loss: 9.07152298e-07
Iter: 1447 loss: 9.07150195e-07
Iter: 1448 loss: 9.0682056e-07
Iter: 1449 loss: 9.11152938e-07
Iter: 1450 loss: 9.06819764e-07
Iter: 1451 loss: 9.06494449e-07
Iter: 1452 loss: 9.05916409e-07
Iter: 1453 loss: 9.20363505e-07
Iter: 1454 loss: 9.05913851e-07
Iter: 1455 loss: 9.05379807e-07
Iter: 1456 loss: 9.06125e-07
Iter: 1457 loss: 9.05131969e-07
Iter: 1458 loss: 9.04344631e-07
Iter: 1459 loss: 9.1150855e-07
Iter: 1460 loss: 9.04326726e-07
Iter: 1461 loss: 9.03789555e-07
Iter: 1462 loss: 9.03745786e-07
Iter: 1463 loss: 9.03321393e-07
Iter: 1464 loss: 9.02803549e-07
Iter: 1465 loss: 9.03540297e-07
Iter: 1466 loss: 9.02516547e-07
Iter: 1467 loss: 9.02130864e-07
Iter: 1468 loss: 9.07240405e-07
Iter: 1469 loss: 9.02130068e-07
Iter: 1470 loss: 9.01728072e-07
Iter: 1471 loss: 9.01954934e-07
Iter: 1472 loss: 9.01465114e-07
Iter: 1473 loss: 9.01112401e-07
Iter: 1474 loss: 9.00770658e-07
Iter: 1475 loss: 9.00724956e-07
Iter: 1476 loss: 9.00298e-07
Iter: 1477 loss: 9.00295e-07
Iter: 1478 loss: 8.99810743e-07
Iter: 1479 loss: 8.99717406e-07
Iter: 1480 loss: 8.9941193e-07
Iter: 1481 loss: 8.99026929e-07
Iter: 1482 loss: 9.01592671e-07
Iter: 1483 loss: 8.9900891e-07
Iter: 1484 loss: 8.98600376e-07
Iter: 1485 loss: 8.98914664e-07
Iter: 1486 loss: 8.98340716e-07
Iter: 1487 loss: 8.97953328e-07
Iter: 1488 loss: 8.9770424e-07
Iter: 1489 loss: 8.97542066e-07
Iter: 1490 loss: 8.97389668e-07
Iter: 1491 loss: 8.9728286e-07
Iter: 1492 loss: 8.97093344e-07
Iter: 1493 loss: 8.96787697e-07
Iter: 1494 loss: 8.96774736e-07
Iter: 1495 loss: 8.96230574e-07
Iter: 1496 loss: 8.96197434e-07
Iter: 1497 loss: 8.95829658e-07
Iter: 1498 loss: 8.9527714e-07
Iter: 1499 loss: 9.01194198e-07
Iter: 1500 loss: 8.9526543e-07
Iter: 1501 loss: 8.94781579e-07
Iter: 1502 loss: 8.96793779e-07
Iter: 1503 loss: 8.94659252e-07
Iter: 1504 loss: 8.94279196e-07
Iter: 1505 loss: 8.93565527e-07
Iter: 1506 loss: 9.10009e-07
Iter: 1507 loss: 8.93576043e-07
Iter: 1508 loss: 8.93154379e-07
Iter: 1509 loss: 8.93152105e-07
Iter: 1510 loss: 8.92793821e-07
Iter: 1511 loss: 8.95194887e-07
Iter: 1512 loss: 8.92779326e-07
Iter: 1513 loss: 8.92546723e-07
Iter: 1514 loss: 8.92157345e-07
Iter: 1515 loss: 9.00858822e-07
Iter: 1516 loss: 8.92156606e-07
Iter: 1517 loss: 8.91678269e-07
Iter: 1518 loss: 8.91684465e-07
Iter: 1519 loss: 8.91423e-07
Iter: 1520 loss: 8.90705e-07
Iter: 1521 loss: 8.95896278e-07
Iter: 1522 loss: 8.90543902e-07
Iter: 1523 loss: 8.89936359e-07
Iter: 1524 loss: 8.89936473e-07
Iter: 1525 loss: 8.89438411e-07
Iter: 1526 loss: 8.92271487e-07
Iter: 1527 loss: 8.89380544e-07
Iter: 1528 loss: 8.89106445e-07
Iter: 1529 loss: 8.88975933e-07
Iter: 1530 loss: 8.88866566e-07
Iter: 1531 loss: 8.88402383e-07
Iter: 1532 loss: 8.89661351e-07
Iter: 1533 loss: 8.88240891e-07
Iter: 1534 loss: 8.87870044e-07
Iter: 1535 loss: 8.87872375e-07
Iter: 1536 loss: 8.87619137e-07
Iter: 1537 loss: 8.87078954e-07
Iter: 1538 loss: 8.94096843e-07
Iter: 1539 loss: 8.87031092e-07
Iter: 1540 loss: 8.86330326e-07
Iter: 1541 loss: 8.87876752e-07
Iter: 1542 loss: 8.86038094e-07
Iter: 1543 loss: 8.85591135e-07
Iter: 1544 loss: 8.85525367e-07
Iter: 1545 loss: 8.8524007e-07
Iter: 1546 loss: 8.84823464e-07
Iter: 1547 loss: 8.84795554e-07
Iter: 1548 loss: 8.84489168e-07
Iter: 1549 loss: 8.84476265e-07
Iter: 1550 loss: 8.84212795e-07
Iter: 1551 loss: 8.83677217e-07
Iter: 1552 loss: 8.9461588e-07
Iter: 1553 loss: 8.83677103e-07
Iter: 1554 loss: 8.83302164e-07
Iter: 1555 loss: 8.84595295e-07
Iter: 1556 loss: 8.83232e-07
Iter: 1557 loss: 8.82802169e-07
Iter: 1558 loss: 8.85998645e-07
Iter: 1559 loss: 8.8277443e-07
Iter: 1560 loss: 8.82413133e-07
Iter: 1561 loss: 8.81786491e-07
Iter: 1562 loss: 8.9735579e-07
Iter: 1563 loss: 8.81795586e-07
Iter: 1564 loss: 8.81153937e-07
Iter: 1565 loss: 8.86954922e-07
Iter: 1566 loss: 8.81108576e-07
Iter: 1567 loss: 8.80761263e-07
Iter: 1568 loss: 8.86440489e-07
Iter: 1569 loss: 8.80768198e-07
Iter: 1570 loss: 8.80449079e-07
Iter: 1571 loss: 8.80036282e-07
Iter: 1572 loss: 8.80006667e-07
Iter: 1573 loss: 8.79554932e-07
Iter: 1574 loss: 8.80573793e-07
Iter: 1575 loss: 8.79352797e-07
Iter: 1576 loss: 8.79104903e-07
Iter: 1577 loss: 8.79078584e-07
Iter: 1578 loss: 8.78844389e-07
Iter: 1579 loss: 8.78229741e-07
Iter: 1580 loss: 8.84848419e-07
Iter: 1581 loss: 8.78198819e-07
Iter: 1582 loss: 8.77677166e-07
Iter: 1583 loss: 8.8528742e-07
Iter: 1584 loss: 8.77691036e-07
Iter: 1585 loss: 8.77135278e-07
Iter: 1586 loss: 8.76887043e-07
Iter: 1587 loss: 8.76581e-07
Iter: 1588 loss: 8.76022739e-07
Iter: 1589 loss: 8.75544e-07
Iter: 1590 loss: 8.75402293e-07
Iter: 1591 loss: 8.75423837e-07
Iter: 1592 loss: 8.75044634e-07
Iter: 1593 loss: 8.7477008e-07
Iter: 1594 loss: 8.74427201e-07
Iter: 1595 loss: 8.74422085e-07
Iter: 1596 loss: 8.74030036e-07
Iter: 1597 loss: 8.74479952e-07
Iter: 1598 loss: 8.73799934e-07
Iter: 1599 loss: 8.7339339e-07
Iter: 1600 loss: 8.77823481e-07
Iter: 1601 loss: 8.73354224e-07
Iter: 1602 loss: 8.72999351e-07
Iter: 1603 loss: 8.73363604e-07
Iter: 1604 loss: 8.72789428e-07
Iter: 1605 loss: 8.72376404e-07
Iter: 1606 loss: 8.71750785e-07
Iter: 1607 loss: 8.71747091e-07
Iter: 1608 loss: 8.71296947e-07
Iter: 1609 loss: 8.71281713e-07
Iter: 1610 loss: 8.70859537e-07
Iter: 1611 loss: 8.71903183e-07
Iter: 1612 loss: 8.7070805e-07
Iter: 1613 loss: 8.70489885e-07
Iter: 1614 loss: 8.70555823e-07
Iter: 1615 loss: 8.7028377e-07
Iter: 1616 loss: 8.69875123e-07
Iter: 1617 loss: 8.72734404e-07
Iter: 1618 loss: 8.69863925e-07
Iter: 1619 loss: 8.69651217e-07
Iter: 1620 loss: 8.69208407e-07
Iter: 1621 loss: 8.76107549e-07
Iter: 1622 loss: 8.69166513e-07
Iter: 1623 loss: 8.68642871e-07
Iter: 1624 loss: 8.71364819e-07
Iter: 1625 loss: 8.68566588e-07
Iter: 1626 loss: 8.67915105e-07
Iter: 1627 loss: 8.70230735e-07
Iter: 1628 loss: 8.67731615e-07
Iter: 1629 loss: 8.67342465e-07
Iter: 1630 loss: 8.6710304e-07
Iter: 1631 loss: 8.6690585e-07
Iter: 1632 loss: 8.66476967e-07
Iter: 1633 loss: 8.72799376e-07
Iter: 1634 loss: 8.66497714e-07
Iter: 1635 loss: 8.66200537e-07
Iter: 1636 loss: 8.67401468e-07
Iter: 1637 loss: 8.66094638e-07
Iter: 1638 loss: 8.65866e-07
Iter: 1639 loss: 8.65580546e-07
Iter: 1640 loss: 8.65521031e-07
Iter: 1641 loss: 8.65097036e-07
Iter: 1642 loss: 8.65854076e-07
Iter: 1643 loss: 8.649e-07
Iter: 1644 loss: 8.64383367e-07
Iter: 1645 loss: 8.7078746e-07
Iter: 1646 loss: 8.6439627e-07
Iter: 1647 loss: 8.64116373e-07
Iter: 1648 loss: 8.63699313e-07
Iter: 1649 loss: 8.63679134e-07
Iter: 1650 loss: 8.63324317e-07
Iter: 1651 loss: 8.63312835e-07
Iter: 1652 loss: 8.63020603e-07
Iter: 1653 loss: 8.62375828e-07
Iter: 1654 loss: 8.71779548e-07
Iter: 1655 loss: 8.62365596e-07
Iter: 1656 loss: 8.61905733e-07
Iter: 1657 loss: 8.64468575e-07
Iter: 1658 loss: 8.61876856e-07
Iter: 1659 loss: 8.61655622e-07
Iter: 1660 loss: 8.61619e-07
Iter: 1661 loss: 8.61446949e-07
Iter: 1662 loss: 8.61045464e-07
Iter: 1663 loss: 8.67417839e-07
Iter: 1664 loss: 8.6100755e-07
Iter: 1665 loss: 8.60643e-07
Iter: 1666 loss: 8.63284924e-07
Iter: 1667 loss: 8.60625732e-07
Iter: 1668 loss: 8.60293483e-07
Iter: 1669 loss: 8.61427225e-07
Iter: 1670 loss: 8.60178545e-07
Iter: 1671 loss: 8.5979093e-07
Iter: 1672 loss: 8.59670422e-07
Iter: 1673 loss: 8.59444242e-07
Iter: 1674 loss: 8.58990461e-07
Iter: 1675 loss: 8.60061391e-07
Iter: 1676 loss: 8.58813564e-07
Iter: 1677 loss: 8.58539806e-07
Iter: 1678 loss: 8.58561918e-07
Iter: 1679 loss: 8.58296289e-07
Iter: 1680 loss: 8.57974e-07
Iter: 1681 loss: 8.57937493e-07
Iter: 1682 loss: 8.5767681e-07
Iter: 1683 loss: 8.60551438e-07
Iter: 1684 loss: 8.57673115e-07
Iter: 1685 loss: 8.57405666e-07
Iter: 1686 loss: 8.57167549e-07
Iter: 1687 loss: 8.57067789e-07
Iter: 1688 loss: 8.56613156e-07
Iter: 1689 loss: 8.56208146e-07
Iter: 1690 loss: 8.56086444e-07
Iter: 1691 loss: 8.55891585e-07
Iter: 1692 loss: 8.55773123e-07
Iter: 1693 loss: 8.5546003e-07
Iter: 1694 loss: 8.5553927e-07
Iter: 1695 loss: 8.55258861e-07
Iter: 1696 loss: 8.54934342e-07
Iter: 1697 loss: 8.54973564e-07
Iter: 1698 loss: 8.54681e-07
Iter: 1699 loss: 8.54422638e-07
Iter: 1700 loss: 8.54395125e-07
Iter: 1701 loss: 8.54209e-07
Iter: 1702 loss: 8.54096697e-07
Iter: 1703 loss: 8.5400535e-07
Iter: 1704 loss: 8.53701692e-07
Iter: 1705 loss: 8.53314134e-07
Iter: 1706 loss: 8.5329134e-07
Iter: 1707 loss: 8.52749395e-07
Iter: 1708 loss: 8.58506155e-07
Iter: 1709 loss: 8.52734615e-07
Iter: 1710 loss: 8.5224417e-07
Iter: 1711 loss: 8.54526832e-07
Iter: 1712 loss: 8.52160383e-07
Iter: 1713 loss: 8.51914535e-07
Iter: 1714 loss: 8.51850245e-07
Iter: 1715 loss: 8.51707057e-07
Iter: 1716 loss: 8.51294431e-07
Iter: 1717 loss: 8.54142684e-07
Iter: 1718 loss: 8.51249297e-07
Iter: 1719 loss: 8.51045968e-07
Iter: 1720 loss: 8.50763797e-07
Iter: 1721 loss: 8.50727304e-07
Iter: 1722 loss: 8.50478841e-07
Iter: 1723 loss: 8.52986091e-07
Iter: 1724 loss: 8.50465767e-07
Iter: 1725 loss: 8.50110837e-07
Iter: 1726 loss: 8.50947686e-07
Iter: 1727 loss: 8.49990442e-07
Iter: 1728 loss: 8.49714638e-07
Iter: 1729 loss: 8.49517846e-07
Iter: 1730 loss: 8.49443325e-07
Iter: 1731 loss: 8.49039736e-07
Iter: 1732 loss: 8.53625352e-07
Iter: 1733 loss: 8.49042408e-07
Iter: 1734 loss: 8.48733748e-07
Iter: 1735 loss: 8.48657066e-07
Iter: 1736 loss: 8.48418381e-07
Iter: 1737 loss: 8.47982506e-07
Iter: 1738 loss: 8.48589252e-07
Iter: 1739 loss: 8.47769684e-07
Iter: 1740 loss: 8.47450565e-07
Iter: 1741 loss: 8.49395747e-07
Iter: 1742 loss: 8.47401736e-07
Iter: 1743 loss: 8.47114507e-07
Iter: 1744 loss: 8.49845833e-07
Iter: 1745 loss: 8.47107344e-07
Iter: 1746 loss: 8.46903845e-07
Iter: 1747 loss: 8.46633611e-07
Iter: 1748 loss: 8.46635544e-07
Iter: 1749 loss: 8.46381909e-07
Iter: 1750 loss: 8.46356215e-07
Iter: 1751 loss: 8.46194439e-07
Iter: 1752 loss: 8.45682905e-07
Iter: 1753 loss: 8.4987812e-07
Iter: 1754 loss: 8.45609861e-07
Iter: 1755 loss: 8.4500914e-07
Iter: 1756 loss: 8.46225191e-07
Iter: 1757 loss: 8.44766646e-07
Iter: 1758 loss: 8.44717761e-07
Iter: 1759 loss: 8.44462875e-07
Iter: 1760 loss: 8.44318947e-07
Iter: 1761 loss: 8.43959583e-07
Iter: 1762 loss: 8.49985724e-07
Iter: 1763 loss: 8.4397783e-07
Iter: 1764 loss: 8.43723569e-07
Iter: 1765 loss: 8.47197271e-07
Iter: 1766 loss: 8.43726e-07
Iter: 1767 loss: 8.43496423e-07
Iter: 1768 loss: 8.44246358e-07
Iter: 1769 loss: 8.43424687e-07
Iter: 1770 loss: 8.43234488e-07
Iter: 1771 loss: 8.42939698e-07
Iter: 1772 loss: 8.42920258e-07
Iter: 1773 loss: 8.42467443e-07
Iter: 1774 loss: 8.43389444e-07
Iter: 1775 loss: 8.42297482e-07
Iter: 1776 loss: 8.42010252e-07
Iter: 1777 loss: 8.41978078e-07
Iter: 1778 loss: 8.41720521e-07
Iter: 1779 loss: 8.41286294e-07
Iter: 1780 loss: 8.41304086e-07
Iter: 1781 loss: 8.41059943e-07
Iter: 1782 loss: 8.41041924e-07
Iter: 1783 loss: 8.40834e-07
Iter: 1784 loss: 8.40603775e-07
Iter: 1785 loss: 8.40557959e-07
Iter: 1786 loss: 8.40291818e-07
Iter: 1787 loss: 8.40131293e-07
Iter: 1788 loss: 8.40016924e-07
Iter: 1789 loss: 8.39776703e-07
Iter: 1790 loss: 8.39728727e-07
Iter: 1791 loss: 8.39463951e-07
Iter: 1792 loss: 8.39357767e-07
Iter: 1793 loss: 8.39217137e-07
Iter: 1794 loss: 8.38903873e-07
Iter: 1795 loss: 8.38867891e-07
Iter: 1796 loss: 8.38611641e-07
Iter: 1797 loss: 8.38193898e-07
Iter: 1798 loss: 8.38195092e-07
Iter: 1799 loss: 8.37918037e-07
Iter: 1800 loss: 8.37782068e-07
Iter: 1801 loss: 8.37688503e-07
Iter: 1802 loss: 8.37401331e-07
Iter: 1803 loss: 8.38173946e-07
Iter: 1804 loss: 8.37327093e-07
Iter: 1805 loss: 8.37079654e-07
Iter: 1806 loss: 8.39108793e-07
Iter: 1807 loss: 8.37053676e-07
Iter: 1808 loss: 8.36773211e-07
Iter: 1809 loss: 8.36921799e-07
Iter: 1810 loss: 8.3658847e-07
Iter: 1811 loss: 8.3638048e-07
Iter: 1812 loss: 8.37065159e-07
Iter: 1813 loss: 8.36313916e-07
Iter: 1814 loss: 8.35990591e-07
Iter: 1815 loss: 8.36238542e-07
Iter: 1816 loss: 8.35790047e-07
Iter: 1817 loss: 8.35466949e-07
Iter: 1818 loss: 8.35171591e-07
Iter: 1819 loss: 8.35091328e-07
Iter: 1820 loss: 8.3475e-07
Iter: 1821 loss: 8.37148377e-07
Iter: 1822 loss: 8.34703201e-07
Iter: 1823 loss: 8.34405853e-07
Iter: 1824 loss: 8.39158588e-07
Iter: 1825 loss: 8.34388516e-07
Iter: 1826 loss: 8.34276193e-07
Iter: 1827 loss: 8.33974809e-07
Iter: 1828 loss: 8.39908125e-07
Iter: 1829 loss: 8.33972479e-07
Iter: 1830 loss: 8.33685192e-07
Iter: 1831 loss: 8.3696e-07
Iter: 1832 loss: 8.33711965e-07
Iter: 1833 loss: 8.33398531e-07
Iter: 1834 loss: 8.33146203e-07
Iter: 1835 loss: 8.33041781e-07
Iter: 1836 loss: 8.32689238e-07
Iter: 1837 loss: 8.33328954e-07
Iter: 1838 loss: 8.32524279e-07
Iter: 1839 loss: 8.32164915e-07
Iter: 1840 loss: 8.34983439e-07
Iter: 1841 loss: 8.32170599e-07
Iter: 1842 loss: 8.31858756e-07
Iter: 1843 loss: 8.33493345e-07
Iter: 1844 loss: 8.31843295e-07
Iter: 1845 loss: 8.31642069e-07
Iter: 1846 loss: 8.31548903e-07
Iter: 1847 loss: 8.3145153e-07
Iter: 1848 loss: 8.31241209e-07
Iter: 1849 loss: 8.31245927e-07
Iter: 1850 loss: 8.31143495e-07
Iter: 1851 loss: 8.30769181e-07
Iter: 1852 loss: 8.32362389e-07
Iter: 1853 loss: 8.30639749e-07
Iter: 1854 loss: 8.30106842e-07
Iter: 1855 loss: 8.31789066e-07
Iter: 1856 loss: 8.29958481e-07
Iter: 1857 loss: 8.29844168e-07
Iter: 1858 loss: 8.29767487e-07
Iter: 1859 loss: 8.29552107e-07
Iter: 1860 loss: 8.29175633e-07
Iter: 1861 loss: 8.36271283e-07
Iter: 1862 loss: 8.29160626e-07
Iter: 1863 loss: 8.28910061e-07
Iter: 1864 loss: 8.31748366e-07
Iter: 1865 loss: 8.28896418e-07
Iter: 1866 loss: 8.28722136e-07
Iter: 1867 loss: 8.30557042e-07
Iter: 1868 loss: 8.2870838e-07
Iter: 1869 loss: 8.28586394e-07
Iter: 1870 loss: 8.28337647e-07
Iter: 1871 loss: 8.32217097e-07
Iter: 1872 loss: 8.28329121e-07
Iter: 1873 loss: 8.28011196e-07
Iter: 1874 loss: 8.29817225e-07
Iter: 1875 loss: 8.27980671e-07
Iter: 1876 loss: 8.27719816e-07
Iter: 1877 loss: 8.30121394e-07
Iter: 1878 loss: 8.2769435e-07
Iter: 1879 loss: 8.27470785e-07
Iter: 1880 loss: 8.27131316e-07
Iter: 1881 loss: 8.27088343e-07
Iter: 1882 loss: 8.26839596e-07
Iter: 1883 loss: 8.26841926e-07
Iter: 1884 loss: 8.26597898e-07
Iter: 1885 loss: 8.26474832e-07
Iter: 1886 loss: 8.26391897e-07
Iter: 1887 loss: 8.26170094e-07
Iter: 1888 loss: 8.25954146e-07
Iter: 1889 loss: 8.25906909e-07
Iter: 1890 loss: 8.2565208e-07
Iter: 1891 loss: 8.25654638e-07
Iter: 1892 loss: 8.25382358e-07
Iter: 1893 loss: 8.25866096e-07
Iter: 1894 loss: 8.25259463e-07
Iter: 1895 loss: 8.25067502e-07
Iter: 1896 loss: 8.24731728e-07
Iter: 1897 loss: 8.24721383e-07
Iter: 1898 loss: 8.24466099e-07
Iter: 1899 loss: 8.24444896e-07
Iter: 1900 loss: 8.24248e-07
Iter: 1901 loss: 8.24055519e-07
Iter: 1902 loss: 8.24013853e-07
Iter: 1903 loss: 8.23811661e-07
Iter: 1904 loss: 8.24413803e-07
Iter: 1905 loss: 8.23727817e-07
Iter: 1906 loss: 8.23552398e-07
Iter: 1907 loss: 8.25758207e-07
Iter: 1908 loss: 8.23541143e-07
Iter: 1909 loss: 8.23373512e-07
Iter: 1910 loss: 8.23437347e-07
Iter: 1911 loss: 8.23264827e-07
Iter: 1912 loss: 8.23047912e-07
Iter: 1913 loss: 8.23301434e-07
Iter: 1914 loss: 8.22929223e-07
Iter: 1915 loss: 8.22647735e-07
Iter: 1916 loss: 8.23419896e-07
Iter: 1917 loss: 8.22517848e-07
Iter: 1918 loss: 8.22265747e-07
Iter: 1919 loss: 8.21815206e-07
Iter: 1920 loss: 8.21826291e-07
Iter: 1921 loss: 8.21390813e-07
Iter: 1922 loss: 8.24022777e-07
Iter: 1923 loss: 8.21330332e-07
Iter: 1924 loss: 8.21115236e-07
Iter: 1925 loss: 8.21092954e-07
Iter: 1926 loss: 8.2095363e-07
Iter: 1927 loss: 8.20711364e-07
Iter: 1928 loss: 8.25141342e-07
Iter: 1929 loss: 8.20704145e-07
Iter: 1930 loss: 8.2047444e-07
Iter: 1931 loss: 8.23786195e-07
Iter: 1932 loss: 8.20485e-07
Iter: 1933 loss: 8.20275602e-07
Iter: 1934 loss: 8.20012247e-07
Iter: 1935 loss: 8.19973479e-07
Iter: 1936 loss: 8.1961764e-07
Iter: 1937 loss: 8.20118089e-07
Iter: 1938 loss: 8.19480761e-07
Iter: 1939 loss: 8.1914294e-07
Iter: 1940 loss: 8.21774961e-07
Iter: 1941 loss: 8.19122079e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.8
+ date
Sat Nov  7 13:55:16 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.8/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi0.8_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c3a72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c3a7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c3b3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c3b3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c364620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c364840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c2e0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c3b3048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c2bc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c2669d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c2668c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c289400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c230400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c230598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c1efae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c196048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c1ba8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c177378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c123400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c1820d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c0ed0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c0ed598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c0be9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c0ce840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c0999d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c0ce7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c04c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e3c099048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36fc5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36f8a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36fcef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36f5e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36f5e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36f5f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36f5fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e36f281e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.94857073e-05
Iter: 2 loss: 2.3802475e-05
Iter: 3 loss: 4.50869302e-05
Iter: 4 loss: 2.24703836e-05
Iter: 5 loss: 1.9359446e-05
Iter: 6 loss: 3.98746415e-05
Iter: 7 loss: 1.90386672e-05
Iter: 8 loss: 1.71866086e-05
Iter: 9 loss: 1.74035376e-05
Iter: 10 loss: 1.57659852e-05
Iter: 11 loss: 1.40626453e-05
Iter: 12 loss: 2.78395091e-05
Iter: 13 loss: 1.39535923e-05
Iter: 14 loss: 1.29263426e-05
Iter: 15 loss: 1.88153153e-05
Iter: 16 loss: 1.27887215e-05
Iter: 17 loss: 1.213826e-05
Iter: 18 loss: 1.15932726e-05
Iter: 19 loss: 1.14090963e-05
Iter: 20 loss: 1.05800436e-05
Iter: 21 loss: 1.05740055e-05
Iter: 22 loss: 1.01433134e-05
Iter: 23 loss: 9.65168601e-06
Iter: 24 loss: 9.58979763e-06
Iter: 25 loss: 9.00859686e-06
Iter: 26 loss: 9.81194e-06
Iter: 27 loss: 8.72036435e-06
Iter: 28 loss: 8.38044161e-06
Iter: 29 loss: 8.31289071e-06
Iter: 30 loss: 8.04927458e-06
Iter: 31 loss: 7.53274071e-06
Iter: 32 loss: 1.78813443e-05
Iter: 33 loss: 7.52848882e-06
Iter: 34 loss: 7.085996e-06
Iter: 35 loss: 1.03710972e-05
Iter: 36 loss: 7.05057255e-06
Iter: 37 loss: 6.8087129e-06
Iter: 38 loss: 6.79600907e-06
Iter: 39 loss: 6.5932154e-06
Iter: 40 loss: 6.56404927e-06
Iter: 41 loss: 6.42198074e-06
Iter: 42 loss: 6.18696777e-06
Iter: 43 loss: 6.67895529e-06
Iter: 44 loss: 6.09381959e-06
Iter: 45 loss: 5.86926035e-06
Iter: 46 loss: 7.6055735e-06
Iter: 47 loss: 5.85297585e-06
Iter: 48 loss: 5.68529322e-06
Iter: 49 loss: 5.99122268e-06
Iter: 50 loss: 5.61288653e-06
Iter: 51 loss: 5.47458376e-06
Iter: 52 loss: 5.8971832e-06
Iter: 53 loss: 5.43364058e-06
Iter: 54 loss: 5.25696851e-06
Iter: 55 loss: 5.68000632e-06
Iter: 56 loss: 5.19318473e-06
Iter: 57 loss: 5.06883862e-06
Iter: 58 loss: 4.95789754e-06
Iter: 59 loss: 4.92601794e-06
Iter: 60 loss: 4.78189759e-06
Iter: 61 loss: 6.19717048e-06
Iter: 62 loss: 4.77690355e-06
Iter: 63 loss: 4.66146548e-06
Iter: 64 loss: 5.73506e-06
Iter: 65 loss: 4.65650191e-06
Iter: 66 loss: 4.59208286e-06
Iter: 67 loss: 4.46570357e-06
Iter: 68 loss: 6.99396332e-06
Iter: 69 loss: 4.46469858e-06
Iter: 70 loss: 4.33323976e-06
Iter: 71 loss: 5.15540478e-06
Iter: 72 loss: 4.31800345e-06
Iter: 73 loss: 4.25830831e-06
Iter: 74 loss: 4.25150665e-06
Iter: 75 loss: 4.2054362e-06
Iter: 76 loss: 4.13023554e-06
Iter: 77 loss: 4.12982899e-06
Iter: 78 loss: 4.05039191e-06
Iter: 79 loss: 4.57580563e-06
Iter: 80 loss: 4.04208458e-06
Iter: 81 loss: 3.97479789e-06
Iter: 82 loss: 4.26533188e-06
Iter: 83 loss: 3.96095129e-06
Iter: 84 loss: 3.90752166e-06
Iter: 85 loss: 3.99707e-06
Iter: 86 loss: 3.88337867e-06
Iter: 87 loss: 3.83190672e-06
Iter: 88 loss: 4.10023313e-06
Iter: 89 loss: 3.82372218e-06
Iter: 90 loss: 3.76767298e-06
Iter: 91 loss: 3.7896059e-06
Iter: 92 loss: 3.72870454e-06
Iter: 93 loss: 3.67077018e-06
Iter: 94 loss: 3.66726181e-06
Iter: 95 loss: 3.62329615e-06
Iter: 96 loss: 3.56720352e-06
Iter: 97 loss: 4.13462385e-06
Iter: 98 loss: 3.56548048e-06
Iter: 99 loss: 3.50987216e-06
Iter: 100 loss: 3.74657748e-06
Iter: 101 loss: 3.49825973e-06
Iter: 102 loss: 3.46403476e-06
Iter: 103 loss: 3.42792532e-06
Iter: 104 loss: 3.42175713e-06
Iter: 105 loss: 3.37225288e-06
Iter: 106 loss: 3.52145139e-06
Iter: 107 loss: 3.35737059e-06
Iter: 108 loss: 3.30937337e-06
Iter: 109 loss: 3.30939019e-06
Iter: 110 loss: 3.28542296e-06
Iter: 111 loss: 3.24964708e-06
Iter: 112 loss: 3.24891585e-06
Iter: 113 loss: 3.21019934e-06
Iter: 114 loss: 3.62087985e-06
Iter: 115 loss: 3.20928848e-06
Iter: 116 loss: 3.1768534e-06
Iter: 117 loss: 3.22017149e-06
Iter: 118 loss: 3.16054661e-06
Iter: 119 loss: 3.12754401e-06
Iter: 120 loss: 3.22352253e-06
Iter: 121 loss: 3.11728445e-06
Iter: 122 loss: 3.09068946e-06
Iter: 123 loss: 3.32787522e-06
Iter: 124 loss: 3.08942754e-06
Iter: 125 loss: 3.0697588e-06
Iter: 126 loss: 3.06091488e-06
Iter: 127 loss: 3.05090566e-06
Iter: 128 loss: 3.02130616e-06
Iter: 129 loss: 3.01457317e-06
Iter: 130 loss: 2.9955354e-06
Iter: 131 loss: 2.97067663e-06
Iter: 132 loss: 2.9706157e-06
Iter: 133 loss: 2.94294387e-06
Iter: 134 loss: 2.9488765e-06
Iter: 135 loss: 2.92253503e-06
Iter: 136 loss: 2.89651234e-06
Iter: 137 loss: 2.90579374e-06
Iter: 138 loss: 2.87827925e-06
Iter: 139 loss: 2.85347687e-06
Iter: 140 loss: 3.02712647e-06
Iter: 141 loss: 2.85119631e-06
Iter: 142 loss: 2.82925885e-06
Iter: 143 loss: 3.06898391e-06
Iter: 144 loss: 2.82882e-06
Iter: 145 loss: 2.81821781e-06
Iter: 146 loss: 2.7993874e-06
Iter: 147 loss: 2.79936489e-06
Iter: 148 loss: 2.77935442e-06
Iter: 149 loss: 3.0125716e-06
Iter: 150 loss: 2.77908271e-06
Iter: 151 loss: 2.76031278e-06
Iter: 152 loss: 2.76024275e-06
Iter: 153 loss: 2.74522131e-06
Iter: 154 loss: 2.7244721e-06
Iter: 155 loss: 2.84534462e-06
Iter: 156 loss: 2.72174475e-06
Iter: 157 loss: 2.70322835e-06
Iter: 158 loss: 2.77656682e-06
Iter: 159 loss: 2.69909447e-06
Iter: 160 loss: 2.68377403e-06
Iter: 161 loss: 2.68415033e-06
Iter: 162 loss: 2.67174119e-06
Iter: 163 loss: 2.65185599e-06
Iter: 164 loss: 2.68382792e-06
Iter: 165 loss: 2.64271102e-06
Iter: 166 loss: 2.62851063e-06
Iter: 167 loss: 2.77426352e-06
Iter: 168 loss: 2.62802496e-06
Iter: 169 loss: 2.61186915e-06
Iter: 170 loss: 2.62071694e-06
Iter: 171 loss: 2.60111892e-06
Iter: 172 loss: 2.58423916e-06
Iter: 173 loss: 2.5742695e-06
Iter: 174 loss: 2.56713656e-06
Iter: 175 loss: 2.55012833e-06
Iter: 176 loss: 2.72801617e-06
Iter: 177 loss: 2.54967108e-06
Iter: 178 loss: 2.53205076e-06
Iter: 179 loss: 2.62007825e-06
Iter: 180 loss: 2.52918335e-06
Iter: 181 loss: 2.51792972e-06
Iter: 182 loss: 2.50656876e-06
Iter: 183 loss: 2.50434596e-06
Iter: 184 loss: 2.49374511e-06
Iter: 185 loss: 2.49364302e-06
Iter: 186 loss: 2.48331389e-06
Iter: 187 loss: 2.47432945e-06
Iter: 188 loss: 2.47155913e-06
Iter: 189 loss: 2.45899946e-06
Iter: 190 loss: 2.56288195e-06
Iter: 191 loss: 2.45819842e-06
Iter: 192 loss: 2.44592889e-06
Iter: 193 loss: 2.46415561e-06
Iter: 194 loss: 2.44009743e-06
Iter: 195 loss: 2.42777014e-06
Iter: 196 loss: 2.43186423e-06
Iter: 197 loss: 2.419157e-06
Iter: 198 loss: 2.40448958e-06
Iter: 199 loss: 2.45494357e-06
Iter: 200 loss: 2.40069198e-06
Iter: 201 loss: 2.38972052e-06
Iter: 202 loss: 2.4619485e-06
Iter: 203 loss: 2.38853477e-06
Iter: 204 loss: 2.37748645e-06
Iter: 205 loss: 2.41760563e-06
Iter: 206 loss: 2.37475751e-06
Iter: 207 loss: 2.36689903e-06
Iter: 208 loss: 2.3572552e-06
Iter: 209 loss: 2.3564462e-06
Iter: 210 loss: 2.34555682e-06
Iter: 211 loss: 2.42311057e-06
Iter: 212 loss: 2.34459367e-06
Iter: 213 loss: 2.33373066e-06
Iter: 214 loss: 2.41641942e-06
Iter: 215 loss: 2.33288029e-06
Iter: 216 loss: 2.32577077e-06
Iter: 217 loss: 2.31249487e-06
Iter: 218 loss: 2.61136552e-06
Iter: 219 loss: 2.31247077e-06
Iter: 220 loss: 2.30347109e-06
Iter: 221 loss: 2.30339583e-06
Iter: 222 loss: 2.29402599e-06
Iter: 223 loss: 2.29339344e-06
Iter: 224 loss: 2.28632871e-06
Iter: 225 loss: 2.27690589e-06
Iter: 226 loss: 2.32098864e-06
Iter: 227 loss: 2.27519899e-06
Iter: 228 loss: 2.26482e-06
Iter: 229 loss: 2.29740408e-06
Iter: 230 loss: 2.26180919e-06
Iter: 231 loss: 2.2544059e-06
Iter: 232 loss: 2.24920655e-06
Iter: 233 loss: 2.24662631e-06
Iter: 234 loss: 2.23590314e-06
Iter: 235 loss: 2.30153364e-06
Iter: 236 loss: 2.2346394e-06
Iter: 237 loss: 2.22616109e-06
Iter: 238 loss: 2.2603881e-06
Iter: 239 loss: 2.2242416e-06
Iter: 240 loss: 2.21530854e-06
Iter: 241 loss: 2.25829399e-06
Iter: 242 loss: 2.2137549e-06
Iter: 243 loss: 2.20857373e-06
Iter: 244 loss: 2.20182028e-06
Iter: 245 loss: 2.20139236e-06
Iter: 246 loss: 2.19172489e-06
Iter: 247 loss: 2.23754864e-06
Iter: 248 loss: 2.18992773e-06
Iter: 249 loss: 2.18281866e-06
Iter: 250 loss: 2.18278547e-06
Iter: 251 loss: 2.17895581e-06
Iter: 252 loss: 2.16966782e-06
Iter: 253 loss: 2.26706197e-06
Iter: 254 loss: 2.16854642e-06
Iter: 255 loss: 2.1610274e-06
Iter: 256 loss: 2.16105059e-06
Iter: 257 loss: 2.15391265e-06
Iter: 258 loss: 2.16768967e-06
Iter: 259 loss: 2.15081e-06
Iter: 260 loss: 2.1447795e-06
Iter: 261 loss: 2.14922284e-06
Iter: 262 loss: 2.14110696e-06
Iter: 263 loss: 2.13249905e-06
Iter: 264 loss: 2.18812079e-06
Iter: 265 loss: 2.13153635e-06
Iter: 266 loss: 2.1266892e-06
Iter: 267 loss: 2.12023861e-06
Iter: 268 loss: 2.11983775e-06
Iter: 269 loss: 2.11066777e-06
Iter: 270 loss: 2.14101874e-06
Iter: 271 loss: 2.10816165e-06
Iter: 272 loss: 2.10164853e-06
Iter: 273 loss: 2.10164353e-06
Iter: 274 loss: 2.09692348e-06
Iter: 275 loss: 2.10399367e-06
Iter: 276 loss: 2.09465566e-06
Iter: 277 loss: 2.08920574e-06
Iter: 278 loss: 2.08499682e-06
Iter: 279 loss: 2.08333427e-06
Iter: 280 loss: 2.07583753e-06
Iter: 281 loss: 2.11811971e-06
Iter: 282 loss: 2.07477979e-06
Iter: 283 loss: 2.06959248e-06
Iter: 284 loss: 2.06961613e-06
Iter: 285 loss: 2.06616414e-06
Iter: 286 loss: 2.0574671e-06
Iter: 287 loss: 2.13586463e-06
Iter: 288 loss: 2.0561713e-06
Iter: 289 loss: 2.0490811e-06
Iter: 290 loss: 2.148146e-06
Iter: 291 loss: 2.0490636e-06
Iter: 292 loss: 2.04281355e-06
Iter: 293 loss: 2.07710582e-06
Iter: 294 loss: 2.04187e-06
Iter: 295 loss: 2.03817012e-06
Iter: 296 loss: 2.03668287e-06
Iter: 297 loss: 2.03480113e-06
Iter: 298 loss: 2.02851197e-06
Iter: 299 loss: 2.07318294e-06
Iter: 300 loss: 2.02792262e-06
Iter: 301 loss: 2.0239595e-06
Iter: 302 loss: 2.01922e-06
Iter: 303 loss: 2.01872331e-06
Iter: 304 loss: 2.01273542e-06
Iter: 305 loss: 2.02865408e-06
Iter: 306 loss: 2.01068065e-06
Iter: 307 loss: 2.00551926e-06
Iter: 308 loss: 2.00550812e-06
Iter: 309 loss: 2.00163049e-06
Iter: 310 loss: 2.00257455e-06
Iter: 311 loss: 1.99886563e-06
Iter: 312 loss: 1.99385886e-06
Iter: 313 loss: 1.99769829e-06
Iter: 314 loss: 1.99083524e-06
Iter: 315 loss: 1.98495763e-06
Iter: 316 loss: 2.0020957e-06
Iter: 317 loss: 1.98313683e-06
Iter: 318 loss: 1.97699387e-06
Iter: 319 loss: 2.04479875e-06
Iter: 320 loss: 1.97691202e-06
Iter: 321 loss: 1.97348027e-06
Iter: 322 loss: 1.96778342e-06
Iter: 323 loss: 1.96775e-06
Iter: 324 loss: 1.96206292e-06
Iter: 325 loss: 1.99531542e-06
Iter: 326 loss: 1.96128894e-06
Iter: 327 loss: 1.95608595e-06
Iter: 328 loss: 1.99958254e-06
Iter: 329 loss: 1.95579332e-06
Iter: 330 loss: 1.9523568e-06
Iter: 331 loss: 1.94873678e-06
Iter: 332 loss: 1.94818017e-06
Iter: 333 loss: 1.94426161e-06
Iter: 334 loss: 1.94417839e-06
Iter: 335 loss: 1.94143399e-06
Iter: 336 loss: 1.93523192e-06
Iter: 337 loss: 2.01327043e-06
Iter: 338 loss: 1.93477513e-06
Iter: 339 loss: 1.92792299e-06
Iter: 340 loss: 1.9532506e-06
Iter: 341 loss: 1.92633024e-06
Iter: 342 loss: 1.92229936e-06
Iter: 343 loss: 1.92204311e-06
Iter: 344 loss: 1.91890922e-06
Iter: 345 loss: 1.9163831e-06
Iter: 346 loss: 1.91540312e-06
Iter: 347 loss: 1.9109159e-06
Iter: 348 loss: 1.92112407e-06
Iter: 349 loss: 1.90932747e-06
Iter: 350 loss: 1.90487947e-06
Iter: 351 loss: 1.92897505e-06
Iter: 352 loss: 1.90420974e-06
Iter: 353 loss: 1.89997161e-06
Iter: 354 loss: 1.92497737e-06
Iter: 355 loss: 1.89935804e-06
Iter: 356 loss: 1.89643515e-06
Iter: 357 loss: 1.89222283e-06
Iter: 358 loss: 1.8920764e-06
Iter: 359 loss: 1.88711306e-06
Iter: 360 loss: 1.90662809e-06
Iter: 361 loss: 1.88603713e-06
Iter: 362 loss: 1.88126421e-06
Iter: 363 loss: 1.93322194e-06
Iter: 364 loss: 1.8811528e-06
Iter: 365 loss: 1.87853493e-06
Iter: 366 loss: 1.87554917e-06
Iter: 367 loss: 1.87524074e-06
Iter: 368 loss: 1.87139472e-06
Iter: 369 loss: 1.92879543e-06
Iter: 370 loss: 1.87141052e-06
Iter: 371 loss: 1.86876207e-06
Iter: 372 loss: 1.86486864e-06
Iter: 373 loss: 1.86466093e-06
Iter: 374 loss: 1.86067507e-06
Iter: 375 loss: 1.8623399e-06
Iter: 376 loss: 1.85797091e-06
Iter: 377 loss: 1.85472584e-06
Iter: 378 loss: 1.85440285e-06
Iter: 379 loss: 1.85168528e-06
Iter: 380 loss: 1.85143585e-06
Iter: 381 loss: 1.84947748e-06
Iter: 382 loss: 1.84593307e-06
Iter: 383 loss: 1.84137104e-06
Iter: 384 loss: 1.84106921e-06
Iter: 385 loss: 1.83769873e-06
Iter: 386 loss: 1.83718e-06
Iter: 387 loss: 1.83429415e-06
Iter: 388 loss: 1.84276291e-06
Iter: 389 loss: 1.83344889e-06
Iter: 390 loss: 1.83068391e-06
Iter: 391 loss: 1.82700876e-06
Iter: 392 loss: 1.82677604e-06
Iter: 393 loss: 1.82233089e-06
Iter: 394 loss: 1.84218584e-06
Iter: 395 loss: 1.82140832e-06
Iter: 396 loss: 1.81823e-06
Iter: 397 loss: 1.81818496e-06
Iter: 398 loss: 1.8163496e-06
Iter: 399 loss: 1.8131675e-06
Iter: 400 loss: 1.8131426e-06
Iter: 401 loss: 1.8094579e-06
Iter: 402 loss: 1.84893111e-06
Iter: 403 loss: 1.80932602e-06
Iter: 404 loss: 1.80604661e-06
Iter: 405 loss: 1.80503957e-06
Iter: 406 loss: 1.80315112e-06
Iter: 407 loss: 1.79971437e-06
Iter: 408 loss: 1.79794313e-06
Iter: 409 loss: 1.79642223e-06
Iter: 410 loss: 1.79288838e-06
Iter: 411 loss: 1.79279277e-06
Iter: 412 loss: 1.78929633e-06
Iter: 413 loss: 1.79324036e-06
Iter: 414 loss: 1.7874213e-06
Iter: 415 loss: 1.7844028e-06
Iter: 416 loss: 1.78025562e-06
Iter: 417 loss: 1.78009066e-06
Iter: 418 loss: 1.77752236e-06
Iter: 419 loss: 1.77697211e-06
Iter: 420 loss: 1.77423976e-06
Iter: 421 loss: 1.77750485e-06
Iter: 422 loss: 1.77288166e-06
Iter: 423 loss: 1.77007337e-06
Iter: 424 loss: 1.77009406e-06
Iter: 425 loss: 1.76785704e-06
Iter: 426 loss: 1.76430331e-06
Iter: 427 loss: 1.77458276e-06
Iter: 428 loss: 1.76319395e-06
Iter: 429 loss: 1.76005369e-06
Iter: 430 loss: 1.79955134e-06
Iter: 431 loss: 1.75999094e-06
Iter: 432 loss: 1.7578393e-06
Iter: 433 loss: 1.75571722e-06
Iter: 434 loss: 1.75524838e-06
Iter: 435 loss: 1.75230321e-06
Iter: 436 loss: 1.77753077e-06
Iter: 437 loss: 1.75219589e-06
Iter: 438 loss: 1.74944739e-06
Iter: 439 loss: 1.75120385e-06
Iter: 440 loss: 1.74761567e-06
Iter: 441 loss: 1.74499041e-06
Iter: 442 loss: 1.74230763e-06
Iter: 443 loss: 1.74170805e-06
Iter: 444 loss: 1.73845478e-06
Iter: 445 loss: 1.78829293e-06
Iter: 446 loss: 1.7383968e-06
Iter: 447 loss: 1.7353052e-06
Iter: 448 loss: 1.7466823e-06
Iter: 449 loss: 1.7344953e-06
Iter: 450 loss: 1.73224919e-06
Iter: 451 loss: 1.72702175e-06
Iter: 452 loss: 1.79443236e-06
Iter: 453 loss: 1.72677096e-06
Iter: 454 loss: 1.72646253e-06
Iter: 455 loss: 1.72436489e-06
Iter: 456 loss: 1.72226203e-06
Iter: 457 loss: 1.72285206e-06
Iter: 458 loss: 1.72072714e-06
Iter: 459 loss: 1.71821421e-06
Iter: 460 loss: 1.71712577e-06
Iter: 461 loss: 1.71587681e-06
Iter: 462 loss: 1.71241891e-06
Iter: 463 loss: 1.73573358e-06
Iter: 464 loss: 1.71211047e-06
Iter: 465 loss: 1.70974238e-06
Iter: 466 loss: 1.73135152e-06
Iter: 467 loss: 1.70967246e-06
Iter: 468 loss: 1.70761211e-06
Iter: 469 loss: 1.70497538e-06
Iter: 470 loss: 1.70480985e-06
Iter: 471 loss: 1.70172677e-06
Iter: 472 loss: 1.72546174e-06
Iter: 473 loss: 1.70148746e-06
Iter: 474 loss: 1.69867917e-06
Iter: 475 loss: 1.70655676e-06
Iter: 476 loss: 1.69770692e-06
Iter: 477 loss: 1.69549571e-06
Iter: 478 loss: 1.69173325e-06
Iter: 479 loss: 1.69176417e-06
Iter: 480 loss: 1.68820623e-06
Iter: 481 loss: 1.73811065e-06
Iter: 482 loss: 1.68815905e-06
Iter: 483 loss: 1.68514191e-06
Iter: 484 loss: 1.70388125e-06
Iter: 485 loss: 1.68475458e-06
Iter: 486 loss: 1.68289671e-06
Iter: 487 loss: 1.67969824e-06
Iter: 488 loss: 1.67969313e-06
Iter: 489 loss: 1.67661881e-06
Iter: 490 loss: 1.71560669e-06
Iter: 491 loss: 1.67657413e-06
Iter: 492 loss: 1.67369637e-06
Iter: 493 loss: 1.68598513e-06
Iter: 494 loss: 1.67300846e-06
Iter: 495 loss: 1.67135534e-06
Iter: 496 loss: 1.6685492e-06
Iter: 497 loss: 1.66853374e-06
Iter: 498 loss: 1.66514042e-06
Iter: 499 loss: 1.6942704e-06
Iter: 500 loss: 1.66495522e-06
Iter: 501 loss: 1.66238567e-06
Iter: 502 loss: 1.68181009e-06
Iter: 503 loss: 1.66226732e-06
Iter: 504 loss: 1.66023597e-06
Iter: 505 loss: 1.65988172e-06
Iter: 506 loss: 1.65864344e-06
Iter: 507 loss: 1.65595736e-06
Iter: 508 loss: 1.66421182e-06
Iter: 509 loss: 1.65515667e-06
Iter: 510 loss: 1.65235156e-06
Iter: 511 loss: 1.66630309e-06
Iter: 512 loss: 1.65186691e-06
Iter: 513 loss: 1.64971243e-06
Iter: 514 loss: 1.64689391e-06
Iter: 515 loss: 1.64668563e-06
Iter: 516 loss: 1.64372864e-06
Iter: 517 loss: 1.66567781e-06
Iter: 518 loss: 1.6434484e-06
Iter: 519 loss: 1.64061407e-06
Iter: 520 loss: 1.66117582e-06
Iter: 521 loss: 1.64036715e-06
Iter: 522 loss: 1.63851962e-06
Iter: 523 loss: 1.63603772e-06
Iter: 524 loss: 1.63586651e-06
Iter: 525 loss: 1.6333687e-06
Iter: 526 loss: 1.64984e-06
Iter: 527 loss: 1.6330855e-06
Iter: 528 loss: 1.62997344e-06
Iter: 529 loss: 1.64142318e-06
Iter: 530 loss: 1.6291981e-06
Iter: 531 loss: 1.62746665e-06
Iter: 532 loss: 1.62514175e-06
Iter: 533 loss: 1.62497042e-06
Iter: 534 loss: 1.62214701e-06
Iter: 535 loss: 1.64307448e-06
Iter: 536 loss: 1.62197307e-06
Iter: 537 loss: 1.61899789e-06
Iter: 538 loss: 1.6298867e-06
Iter: 539 loss: 1.61829246e-06
Iter: 540 loss: 1.61601247e-06
Iter: 541 loss: 1.62005358e-06
Iter: 542 loss: 1.61501055e-06
Iter: 543 loss: 1.6128788e-06
Iter: 544 loss: 1.61880712e-06
Iter: 545 loss: 1.61214871e-06
Iter: 546 loss: 1.6095554e-06
Iter: 547 loss: 1.61702837e-06
Iter: 548 loss: 1.60878699e-06
Iter: 549 loss: 1.6064505e-06
Iter: 550 loss: 1.6057827e-06
Iter: 551 loss: 1.60432944e-06
Iter: 552 loss: 1.60186175e-06
Iter: 553 loss: 1.61597552e-06
Iter: 554 loss: 1.60156083e-06
Iter: 555 loss: 1.59917192e-06
Iter: 556 loss: 1.61582057e-06
Iter: 557 loss: 1.59894216e-06
Iter: 558 loss: 1.59711e-06
Iter: 559 loss: 1.59402282e-06
Iter: 560 loss: 1.59402339e-06
Iter: 561 loss: 1.59156536e-06
Iter: 562 loss: 1.62187166e-06
Iter: 563 loss: 1.59153274e-06
Iter: 564 loss: 1.58920511e-06
Iter: 565 loss: 1.60113632e-06
Iter: 566 loss: 1.58883006e-06
Iter: 567 loss: 1.58727846e-06
Iter: 568 loss: 1.58457567e-06
Iter: 569 loss: 1.58456169e-06
Iter: 570 loss: 1.58210287e-06
Iter: 571 loss: 1.59784906e-06
Iter: 572 loss: 1.58182922e-06
Iter: 573 loss: 1.57902343e-06
Iter: 574 loss: 1.59305023e-06
Iter: 575 loss: 1.57854095e-06
Iter: 576 loss: 1.57661964e-06
Iter: 577 loss: 1.57675925e-06
Iter: 578 loss: 1.57509044e-06
Iter: 579 loss: 1.57276349e-06
Iter: 580 loss: 1.58924468e-06
Iter: 581 loss: 1.5725866e-06
Iter: 582 loss: 1.57053478e-06
Iter: 583 loss: 1.57282818e-06
Iter: 584 loss: 1.56943679e-06
Iter: 585 loss: 1.56688236e-06
Iter: 586 loss: 1.56812246e-06
Iter: 587 loss: 1.5651525e-06
Iter: 588 loss: 1.56265764e-06
Iter: 589 loss: 1.57180523e-06
Iter: 590 loss: 1.56203635e-06
Iter: 591 loss: 1.55982593e-06
Iter: 592 loss: 1.58883631e-06
Iter: 593 loss: 1.55978387e-06
Iter: 594 loss: 1.55840701e-06
Iter: 595 loss: 1.55582643e-06
Iter: 596 loss: 1.61048968e-06
Iter: 597 loss: 1.55581347e-06
Iter: 598 loss: 1.55337557e-06
Iter: 599 loss: 1.57813088e-06
Iter: 600 loss: 1.5532911e-06
Iter: 601 loss: 1.55084331e-06
Iter: 602 loss: 1.56235819e-06
Iter: 603 loss: 1.55044984e-06
Iter: 604 loss: 1.54915824e-06
Iter: 605 loss: 1.54660461e-06
Iter: 606 loss: 1.59714477e-06
Iter: 607 loss: 1.54659597e-06
Iter: 608 loss: 1.54367331e-06
Iter: 609 loss: 1.564939e-06
Iter: 610 loss: 1.54346321e-06
Iter: 611 loss: 1.54125382e-06
Iter: 612 loss: 1.56922852e-06
Iter: 613 loss: 1.54119493e-06
Iter: 614 loss: 1.54002862e-06
Iter: 615 loss: 1.53813187e-06
Iter: 616 loss: 1.53808764e-06
Iter: 617 loss: 1.53625092e-06
Iter: 618 loss: 1.56301144e-06
Iter: 619 loss: 1.53626684e-06
Iter: 620 loss: 1.53465703e-06
Iter: 621 loss: 1.53392602e-06
Iter: 622 loss: 1.53313317e-06
Iter: 623 loss: 1.53072415e-06
Iter: 624 loss: 1.53768542e-06
Iter: 625 loss: 1.52994244e-06
Iter: 626 loss: 1.52805239e-06
Iter: 627 loss: 1.5331201e-06
Iter: 628 loss: 1.52739972e-06
Iter: 629 loss: 1.52547318e-06
Iter: 630 loss: 1.54487668e-06
Iter: 631 loss: 1.52541065e-06
Iter: 632 loss: 1.52409393e-06
Iter: 633 loss: 1.52178609e-06
Iter: 634 loss: 1.52180314e-06
Iter: 635 loss: 1.52003918e-06
Iter: 636 loss: 1.5438718e-06
Iter: 637 loss: 1.51999484e-06
Iter: 638 loss: 1.51809627e-06
Iter: 639 loss: 1.52229313e-06
Iter: 640 loss: 1.5173656e-06
Iter: 641 loss: 1.5158264e-06
Iter: 642 loss: 1.51381312e-06
Iter: 643 loss: 1.51368022e-06
Iter: 644 loss: 1.51143172e-06
Iter: 645 loss: 1.52529469e-06
Iter: 646 loss: 1.51117843e-06
Iter: 647 loss: 1.50923654e-06
Iter: 648 loss: 1.53195174e-06
Iter: 649 loss: 1.50924643e-06
Iter: 650 loss: 1.50799383e-06
Iter: 651 loss: 1.50588357e-06
Iter: 652 loss: 1.50589472e-06
Iter: 653 loss: 1.50433777e-06
Iter: 654 loss: 1.50428968e-06
Iter: 655 loss: 1.50279288e-06
Iter: 656 loss: 1.50098288e-06
Iter: 657 loss: 1.50079222e-06
Iter: 658 loss: 1.49822495e-06
Iter: 659 loss: 1.50880715e-06
Iter: 660 loss: 1.497732e-06
Iter: 661 loss: 1.49567086e-06
Iter: 662 loss: 1.50389133e-06
Iter: 663 loss: 1.49520724e-06
Iter: 664 loss: 1.49344123e-06
Iter: 665 loss: 1.50912535e-06
Iter: 666 loss: 1.49340303e-06
Iter: 667 loss: 1.49210985e-06
Iter: 668 loss: 1.49003131e-06
Iter: 669 loss: 1.48997219e-06
Iter: 670 loss: 1.48876779e-06
Iter: 671 loss: 1.48873085e-06
Iter: 672 loss: 1.48736274e-06
Iter: 673 loss: 1.48677759e-06
Iter: 674 loss: 1.48607319e-06
Iter: 675 loss: 1.48419485e-06
Iter: 676 loss: 1.48238973e-06
Iter: 677 loss: 1.48200638e-06
Iter: 678 loss: 1.47987305e-06
Iter: 679 loss: 1.50680148e-06
Iter: 680 loss: 1.47986827e-06
Iter: 681 loss: 1.47801586e-06
Iter: 682 loss: 1.48939057e-06
Iter: 683 loss: 1.47784215e-06
Iter: 684 loss: 1.47659716e-06
Iter: 685 loss: 1.47449191e-06
Iter: 686 loss: 1.47451078e-06
Iter: 687 loss: 1.47336573e-06
Iter: 688 loss: 1.47317792e-06
Iter: 689 loss: 1.47207652e-06
Iter: 690 loss: 1.4704716e-06
Iter: 691 loss: 1.47041715e-06
Iter: 692 loss: 1.4683078e-06
Iter: 693 loss: 1.47434253e-06
Iter: 694 loss: 1.46764148e-06
Iter: 695 loss: 1.46591742e-06
Iter: 696 loss: 1.48471941e-06
Iter: 697 loss: 1.46589139e-06
Iter: 698 loss: 1.46444108e-06
Iter: 699 loss: 1.4678219e-06
Iter: 700 loss: 1.4640118e-06
Iter: 701 loss: 1.46255081e-06
Iter: 702 loss: 1.46097659e-06
Iter: 703 loss: 1.46077662e-06
Iter: 704 loss: 1.45952959e-06
Iter: 705 loss: 1.45939316e-06
Iter: 706 loss: 1.45817819e-06
Iter: 707 loss: 1.45801505e-06
Iter: 708 loss: 1.4571508e-06
Iter: 709 loss: 1.45578952e-06
Iter: 710 loss: 1.45370677e-06
Iter: 711 loss: 1.45368483e-06
Iter: 712 loss: 1.45208992e-06
Iter: 713 loss: 1.45207969e-06
Iter: 714 loss: 1.450431e-06
Iter: 715 loss: 1.45318847e-06
Iter: 716 loss: 1.44967021e-06
Iter: 717 loss: 1.44818841e-06
Iter: 718 loss: 1.44738078e-06
Iter: 719 loss: 1.44672595e-06
Iter: 720 loss: 1.44552314e-06
Iter: 721 loss: 1.44546902e-06
Iter: 722 loss: 1.44434625e-06
Iter: 723 loss: 1.44258183e-06
Iter: 724 loss: 1.44261207e-06
Iter: 725 loss: 1.44066553e-06
Iter: 726 loss: 1.44943533e-06
Iter: 727 loss: 1.44034061e-06
Iter: 728 loss: 1.43884779e-06
Iter: 729 loss: 1.45530669e-06
Iter: 730 loss: 1.43883358e-06
Iter: 731 loss: 1.43764578e-06
Iter: 732 loss: 1.43761827e-06
Iter: 733 loss: 1.43668035e-06
Iter: 734 loss: 1.43504985e-06
Iter: 735 loss: 1.43706472e-06
Iter: 736 loss: 1.43415991e-06
Iter: 737 loss: 1.43293437e-06
Iter: 738 loss: 1.43292095e-06
Iter: 739 loss: 1.43184093e-06
Iter: 740 loss: 1.43141597e-06
Iter: 741 loss: 1.43080206e-06
Iter: 742 loss: 1.42948306e-06
Iter: 743 loss: 1.42701447e-06
Iter: 744 loss: 1.48741e-06
Iter: 745 loss: 1.42702356e-06
Iter: 746 loss: 1.42642716e-06
Iter: 747 loss: 1.42577915e-06
Iter: 748 loss: 1.42458168e-06
Iter: 749 loss: 1.42495492e-06
Iter: 750 loss: 1.42374802e-06
Iter: 751 loss: 1.42237752e-06
Iter: 752 loss: 1.42098793e-06
Iter: 753 loss: 1.42071235e-06
Iter: 754 loss: 1.41941644e-06
Iter: 755 loss: 1.41927285e-06
Iter: 756 loss: 1.4181885e-06
Iter: 757 loss: 1.41721489e-06
Iter: 758 loss: 1.41691953e-06
Iter: 759 loss: 1.41530836e-06
Iter: 760 loss: 1.41607859e-06
Iter: 761 loss: 1.41417081e-06
Iter: 762 loss: 1.41295936e-06
Iter: 763 loss: 1.41284318e-06
Iter: 764 loss: 1.41190731e-06
Iter: 765 loss: 1.41107398e-06
Iter: 766 loss: 1.4108532e-06
Iter: 767 loss: 1.40922634e-06
Iter: 768 loss: 1.41283931e-06
Iter: 769 loss: 1.40859265e-06
Iter: 770 loss: 1.40720658e-06
Iter: 771 loss: 1.42635781e-06
Iter: 772 loss: 1.40720488e-06
Iter: 773 loss: 1.40614225e-06
Iter: 774 loss: 1.40594216e-06
Iter: 775 loss: 1.40525378e-06
Iter: 776 loss: 1.40388943e-06
Iter: 777 loss: 1.40230179e-06
Iter: 778 loss: 1.40214638e-06
Iter: 779 loss: 1.40071427e-06
Iter: 780 loss: 1.40069756e-06
Iter: 781 loss: 1.39924293e-06
Iter: 782 loss: 1.40204429e-06
Iter: 783 loss: 1.39862925e-06
Iter: 784 loss: 1.3972849e-06
Iter: 785 loss: 1.3955721e-06
Iter: 786 loss: 1.39547046e-06
Iter: 787 loss: 1.39447093e-06
Iter: 788 loss: 1.39434223e-06
Iter: 789 loss: 1.39319536e-06
Iter: 790 loss: 1.39167173e-06
Iter: 791 loss: 1.39158101e-06
Iter: 792 loss: 1.38973519e-06
Iter: 793 loss: 1.39443307e-06
Iter: 794 loss: 1.38909706e-06
Iter: 795 loss: 1.38799794e-06
Iter: 796 loss: 1.38796111e-06
Iter: 797 loss: 1.38693167e-06
Iter: 798 loss: 1.38568373e-06
Iter: 799 loss: 1.38557164e-06
Iter: 800 loss: 1.38400912e-06
Iter: 801 loss: 1.3903865e-06
Iter: 802 loss: 1.38370228e-06
Iter: 803 loss: 1.38234543e-06
Iter: 804 loss: 1.39642566e-06
Iter: 805 loss: 1.38234782e-06
Iter: 806 loss: 1.38131827e-06
Iter: 807 loss: 1.38109681e-06
Iter: 808 loss: 1.38046198e-06
Iter: 809 loss: 1.37914651e-06
Iter: 810 loss: 1.37941049e-06
Iter: 811 loss: 1.37813333e-06
Iter: 812 loss: 1.37663744e-06
Iter: 813 loss: 1.38514315e-06
Iter: 814 loss: 1.37640336e-06
Iter: 815 loss: 1.37490565e-06
Iter: 816 loss: 1.38495307e-06
Iter: 817 loss: 1.37477127e-06
Iter: 818 loss: 1.37374286e-06
Iter: 819 loss: 1.37149209e-06
Iter: 820 loss: 1.40656209e-06
Iter: 821 loss: 1.37145162e-06
Iter: 822 loss: 1.37030588e-06
Iter: 823 loss: 1.37016809e-06
Iter: 824 loss: 1.36890128e-06
Iter: 825 loss: 1.36843096e-06
Iter: 826 loss: 1.36770109e-06
Iter: 827 loss: 1.36616086e-06
Iter: 828 loss: 1.36809945e-06
Iter: 829 loss: 1.36543315e-06
Iter: 830 loss: 1.36427298e-06
Iter: 831 loss: 1.36424273e-06
Iter: 832 loss: 1.36325502e-06
Iter: 833 loss: 1.36210838e-06
Iter: 834 loss: 1.36200288e-06
Iter: 835 loss: 1.36055655e-06
Iter: 836 loss: 1.36650681e-06
Iter: 837 loss: 1.3602463e-06
Iter: 838 loss: 1.35886137e-06
Iter: 839 loss: 1.37001211e-06
Iter: 840 loss: 1.35875848e-06
Iter: 841 loss: 1.35785103e-06
Iter: 842 loss: 1.3573873e-06
Iter: 843 loss: 1.35695927e-06
Iter: 844 loss: 1.35563562e-06
Iter: 845 loss: 1.35749542e-06
Iter: 846 loss: 1.35498067e-06
Iter: 847 loss: 1.35349137e-06
Iter: 848 loss: 1.3597446e-06
Iter: 849 loss: 1.35315713e-06
Iter: 850 loss: 1.35152811e-06
Iter: 851 loss: 1.36086555e-06
Iter: 852 loss: 1.35128198e-06
Iter: 853 loss: 1.35035748e-06
Iter: 854 loss: 1.34875654e-06
Iter: 855 loss: 1.34874813e-06
Iter: 856 loss: 1.3473815e-06
Iter: 857 loss: 1.34737934e-06
Iter: 858 loss: 1.34611741e-06
Iter: 859 loss: 1.34885772e-06
Iter: 860 loss: 1.34567176e-06
Iter: 861 loss: 1.34458583e-06
Iter: 862 loss: 1.34323727e-06
Iter: 863 loss: 1.3431827e-06
Iter: 864 loss: 1.34216589e-06
Iter: 865 loss: 1.34201218e-06
Iter: 866 loss: 1.34105858e-06
Iter: 867 loss: 1.34009156e-06
Iter: 868 loss: 1.33990682e-06
Iter: 869 loss: 1.33856838e-06
Iter: 870 loss: 1.34339427e-06
Iter: 871 loss: 1.33828962e-06
Iter: 872 loss: 1.33691356e-06
Iter: 873 loss: 1.34899369e-06
Iter: 874 loss: 1.33685433e-06
Iter: 875 loss: 1.33597973e-06
Iter: 876 loss: 1.33445246e-06
Iter: 877 loss: 1.37124357e-06
Iter: 878 loss: 1.33446338e-06
Iter: 879 loss: 1.33275591e-06
Iter: 880 loss: 1.34497895e-06
Iter: 881 loss: 1.33264689e-06
Iter: 882 loss: 1.33149706e-06
Iter: 883 loss: 1.33797016e-06
Iter: 884 loss: 1.33133324e-06
Iter: 885 loss: 1.33010792e-06
Iter: 886 loss: 1.33282617e-06
Iter: 887 loss: 1.32962487e-06
Iter: 888 loss: 1.32862147e-06
Iter: 889 loss: 1.3275469e-06
Iter: 890 loss: 1.32735352e-06
Iter: 891 loss: 1.32647688e-06
Iter: 892 loss: 1.32643231e-06
Iter: 893 loss: 1.32547962e-06
Iter: 894 loss: 1.32702655e-06
Iter: 895 loss: 1.3250974e-06
Iter: 896 loss: 1.32403056e-06
Iter: 897 loss: 1.32233845e-06
Iter: 898 loss: 1.3223455e-06
Iter: 899 loss: 1.32167611e-06
Iter: 900 loss: 1.32123796e-06
Iter: 901 loss: 1.32042567e-06
Iter: 902 loss: 1.31915624e-06
Iter: 903 loss: 1.31919455e-06
Iter: 904 loss: 1.31783429e-06
Iter: 905 loss: 1.32434e-06
Iter: 906 loss: 1.31757088e-06
Iter: 907 loss: 1.31602269e-06
Iter: 908 loss: 1.32441073e-06
Iter: 909 loss: 1.31576417e-06
Iter: 910 loss: 1.31505806e-06
Iter: 911 loss: 1.31451691e-06
Iter: 912 loss: 1.314261e-06
Iter: 913 loss: 1.31309662e-06
Iter: 914 loss: 1.31677916e-06
Iter: 915 loss: 1.31276909e-06
Iter: 916 loss: 1.31151353e-06
Iter: 917 loss: 1.32001753e-06
Iter: 918 loss: 1.31141746e-06
Iter: 919 loss: 1.31033607e-06
Iter: 920 loss: 1.31159538e-06
Iter: 921 loss: 1.30978492e-06
Iter: 922 loss: 1.30875333e-06
Iter: 923 loss: 1.30813146e-06
Iter: 924 loss: 1.30768285e-06
Iter: 925 loss: 1.30642502e-06
Iter: 926 loss: 1.31858553e-06
Iter: 927 loss: 1.30634817e-06
Iter: 928 loss: 1.30525507e-06
Iter: 929 loss: 1.31016418e-06
Iter: 930 loss: 1.30503713e-06
Iter: 931 loss: 1.30415947e-06
Iter: 932 loss: 1.30292597e-06
Iter: 933 loss: 1.30288504e-06
Iter: 934 loss: 1.30195917e-06
Iter: 935 loss: 1.30185799e-06
Iter: 936 loss: 1.30098545e-06
Iter: 937 loss: 1.29985244e-06
Iter: 938 loss: 1.29977525e-06
Iter: 939 loss: 1.29864702e-06
Iter: 940 loss: 1.30742683e-06
Iter: 941 loss: 1.2986e-06
Iter: 942 loss: 1.29732564e-06
Iter: 943 loss: 1.29957573e-06
Iter: 944 loss: 1.29677574e-06
Iter: 945 loss: 1.29604223e-06
Iter: 946 loss: 1.29556054e-06
Iter: 947 loss: 1.29526177e-06
Iter: 948 loss: 1.29417231e-06
Iter: 949 loss: 1.30493231e-06
Iter: 950 loss: 1.29413229e-06
Iter: 951 loss: 1.2932644e-06
Iter: 952 loss: 1.29659816e-06
Iter: 953 loss: 1.29303612e-06
Iter: 954 loss: 1.29217165e-06
Iter: 955 loss: 1.2915275e-06
Iter: 956 loss: 1.29121418e-06
Iter: 957 loss: 1.28993361e-06
Iter: 958 loss: 1.29294631e-06
Iter: 959 loss: 1.28951183e-06
Iter: 960 loss: 1.28847432e-06
Iter: 961 loss: 1.29621105e-06
Iter: 962 loss: 1.28840247e-06
Iter: 963 loss: 1.2871451e-06
Iter: 964 loss: 1.28762349e-06
Iter: 965 loss: 1.28632689e-06
Iter: 966 loss: 1.28528347e-06
Iter: 967 loss: 1.2878736e-06
Iter: 968 loss: 1.28491672e-06
Iter: 969 loss: 1.28396641e-06
Iter: 970 loss: 1.29599198e-06
Iter: 971 loss: 1.28396096e-06
Iter: 972 loss: 1.28322506e-06
Iter: 973 loss: 1.28187639e-06
Iter: 974 loss: 1.30919e-06
Iter: 975 loss: 1.28185695e-06
Iter: 976 loss: 1.28118563e-06
Iter: 977 loss: 1.28102965e-06
Iter: 978 loss: 1.2802185e-06
Iter: 979 loss: 1.27931321e-06
Iter: 980 loss: 1.27922033e-06
Iter: 981 loss: 1.27812586e-06
Iter: 982 loss: 1.27824546e-06
Iter: 983 loss: 1.27724888e-06
Iter: 984 loss: 1.27636508e-06
Iter: 985 loss: 1.27625879e-06
Iter: 986 loss: 1.27550436e-06
Iter: 987 loss: 1.27587157e-06
Iter: 988 loss: 1.27495298e-06
Iter: 989 loss: 1.274037e-06
Iter: 990 loss: 1.27418707e-06
Iter: 991 loss: 1.27336102e-06
Iter: 992 loss: 1.27203316e-06
Iter: 993 loss: 1.27527619e-06
Iter: 994 loss: 1.27160797e-06
Iter: 995 loss: 1.27065994e-06
Iter: 996 loss: 1.28192278e-06
Iter: 997 loss: 1.27063265e-06
Iter: 998 loss: 1.26970463e-06
Iter: 999 loss: 1.26961584e-06
Iter: 1000 loss: 1.2689793e-06
Iter: 1001 loss: 1.26799023e-06
Iter: 1002 loss: 1.27070587e-06
Iter: 1003 loss: 1.26769646e-06
Iter: 1004 loss: 1.26668021e-06
Iter: 1005 loss: 1.27553949e-06
Iter: 1006 loss: 1.26666805e-06
Iter: 1007 loss: 1.26595853e-06
Iter: 1008 loss: 1.26483769e-06
Iter: 1009 loss: 1.26480006e-06
Iter: 1010 loss: 1.26414693e-06
Iter: 1011 loss: 1.26402642e-06
Iter: 1012 loss: 1.26342604e-06
Iter: 1013 loss: 1.26212717e-06
Iter: 1014 loss: 1.28344129e-06
Iter: 1015 loss: 1.26210273e-06
Iter: 1016 loss: 1.26081363e-06
Iter: 1017 loss: 1.26298028e-06
Iter: 1018 loss: 1.26025373e-06
Iter: 1019 loss: 1.25959718e-06
Iter: 1020 loss: 1.25942256e-06
Iter: 1021 loss: 1.25880115e-06
Iter: 1022 loss: 1.25780252e-06
Iter: 1023 loss: 1.25779388e-06
Iter: 1024 loss: 1.25658221e-06
Iter: 1025 loss: 1.2599769e-06
Iter: 1026 loss: 1.25620977e-06
Iter: 1027 loss: 1.25500753e-06
Iter: 1028 loss: 1.25880194e-06
Iter: 1029 loss: 1.25461565e-06
Iter: 1030 loss: 1.25375163e-06
Iter: 1031 loss: 1.26471377e-06
Iter: 1032 loss: 1.25375595e-06
Iter: 1033 loss: 1.25294196e-06
Iter: 1034 loss: 1.25178417e-06
Iter: 1035 loss: 1.2517346e-06
Iter: 1036 loss: 1.2507063e-06
Iter: 1037 loss: 1.26506404e-06
Iter: 1038 loss: 1.25068038e-06
Iter: 1039 loss: 1.24975509e-06
Iter: 1040 loss: 1.25118015e-06
Iter: 1041 loss: 1.24933661e-06
Iter: 1042 loss: 1.24845758e-06
Iter: 1043 loss: 1.24889152e-06
Iter: 1044 loss: 1.2478821e-06
Iter: 1045 loss: 1.24680582e-06
Iter: 1046 loss: 1.26063674e-06
Iter: 1047 loss: 1.24680287e-06
Iter: 1048 loss: 1.24627161e-06
Iter: 1049 loss: 1.24539781e-06
Iter: 1050 loss: 1.24538724e-06
Iter: 1051 loss: 1.24441146e-06
Iter: 1052 loss: 1.24654071e-06
Iter: 1053 loss: 1.24405938e-06
Iter: 1054 loss: 1.24295366e-06
Iter: 1055 loss: 1.2565846e-06
Iter: 1056 loss: 1.24293592e-06
Iter: 1057 loss: 1.2423202e-06
Iter: 1058 loss: 1.24139e-06
Iter: 1059 loss: 1.24139933e-06
Iter: 1060 loss: 1.2402196e-06
Iter: 1061 loss: 1.24458961e-06
Iter: 1062 loss: 1.23989571e-06
Iter: 1063 loss: 1.23881671e-06
Iter: 1064 loss: 1.24413202e-06
Iter: 1065 loss: 1.23859968e-06
Iter: 1066 loss: 1.23766085e-06
Iter: 1067 loss: 1.24308553e-06
Iter: 1068 loss: 1.23749703e-06
Iter: 1069 loss: 1.23681741e-06
Iter: 1070 loss: 1.23675397e-06
Iter: 1071 loss: 1.23618543e-06
Iter: 1072 loss: 1.23541554e-06
Iter: 1073 loss: 1.24468113e-06
Iter: 1074 loss: 1.235421e-06
Iter: 1075 loss: 1.234622e-06
Iter: 1076 loss: 1.23386349e-06
Iter: 1077 loss: 1.23369341e-06
Iter: 1078 loss: 1.23283053e-06
Iter: 1079 loss: 1.2410917e-06
Iter: 1080 loss: 1.23279415e-06
Iter: 1081 loss: 1.23189534e-06
Iter: 1082 loss: 1.23347741e-06
Iter: 1083 loss: 1.2314938e-06
Iter: 1084 loss: 1.23074983e-06
Iter: 1085 loss: 1.22932283e-06
Iter: 1086 loss: 1.26186546e-06
Iter: 1087 loss: 1.22932568e-06
Iter: 1088 loss: 1.22848041e-06
Iter: 1089 loss: 1.22843699e-06
Iter: 1090 loss: 1.22743938e-06
Iter: 1091 loss: 1.22785855e-06
Iter: 1092 loss: 1.22674783e-06
Iter: 1093 loss: 1.22584629e-06
Iter: 1094 loss: 1.22626204e-06
Iter: 1095 loss: 1.22522488e-06
Iter: 1096 loss: 1.22416589e-06
Iter: 1097 loss: 1.23008203e-06
Iter: 1098 loss: 1.22406891e-06
Iter: 1099 loss: 1.22314191e-06
Iter: 1100 loss: 1.22733411e-06
Iter: 1101 loss: 1.22296012e-06
Iter: 1102 loss: 1.22197616e-06
Iter: 1103 loss: 1.22318329e-06
Iter: 1104 loss: 1.22150141e-06
Iter: 1105 loss: 1.2205353e-06
Iter: 1106 loss: 1.22258143e-06
Iter: 1107 loss: 1.22018469e-06
Iter: 1108 loss: 1.21923813e-06
Iter: 1109 loss: 1.22867016e-06
Iter: 1110 loss: 1.21920243e-06
Iter: 1111 loss: 1.21855612e-06
Iter: 1112 loss: 1.21737264e-06
Iter: 1113 loss: 1.21735047e-06
Iter: 1114 loss: 1.21658172e-06
Iter: 1115 loss: 1.21649373e-06
Iter: 1116 loss: 1.21579797e-06
Iter: 1117 loss: 1.21507969e-06
Iter: 1118 loss: 1.21498135e-06
Iter: 1119 loss: 1.21405697e-06
Iter: 1120 loss: 1.213769e-06
Iter: 1121 loss: 1.21323103e-06
Iter: 1122 loss: 1.2120438e-06
Iter: 1123 loss: 1.21989024e-06
Iter: 1124 loss: 1.21194512e-06
Iter: 1125 loss: 1.21106541e-06
Iter: 1126 loss: 1.21105484e-06
Iter: 1127 loss: 1.21054279e-06
Iter: 1128 loss: 1.20946663e-06
Iter: 1129 loss: 1.2300336e-06
Iter: 1130 loss: 1.20943901e-06
Iter: 1131 loss: 1.20829122e-06
Iter: 1132 loss: 1.20982452e-06
Iter: 1133 loss: 1.20768891e-06
Iter: 1134 loss: 1.20657e-06
Iter: 1135 loss: 1.21611197e-06
Iter: 1136 loss: 1.20652317e-06
Iter: 1137 loss: 1.20572804e-06
Iter: 1138 loss: 1.21523192e-06
Iter: 1139 loss: 1.20573554e-06
Iter: 1140 loss: 1.20508685e-06
Iter: 1141 loss: 1.20428649e-06
Iter: 1142 loss: 1.20424966e-06
Iter: 1143 loss: 1.20318657e-06
Iter: 1144 loss: 1.21133928e-06
Iter: 1145 loss: 1.20308414e-06
Iter: 1146 loss: 1.20228071e-06
Iter: 1147 loss: 1.20629579e-06
Iter: 1148 loss: 1.20215418e-06
Iter: 1149 loss: 1.20138156e-06
Iter: 1150 loss: 1.20084201e-06
Iter: 1151 loss: 1.20055847e-06
Iter: 1152 loss: 1.1996251e-06
Iter: 1153 loss: 1.21107178e-06
Iter: 1154 loss: 1.1996392e-06
Iter: 1155 loss: 1.19881054e-06
Iter: 1156 loss: 1.19889364e-06
Iter: 1157 loss: 1.19816832e-06
Iter: 1158 loss: 1.19738775e-06
Iter: 1159 loss: 1.19672882e-06
Iter: 1160 loss: 1.19652759e-06
Iter: 1161 loss: 1.19531921e-06
Iter: 1162 loss: 1.20067261e-06
Iter: 1163 loss: 1.19506069e-06
Iter: 1164 loss: 1.19444508e-06
Iter: 1165 loss: 1.19439483e-06
Iter: 1166 loss: 1.19383162e-06
Iter: 1167 loss: 1.19271658e-06
Iter: 1168 loss: 1.21589846e-06
Iter: 1169 loss: 1.19273284e-06
Iter: 1170 loss: 1.19166566e-06
Iter: 1171 loss: 1.19311517e-06
Iter: 1172 loss: 1.19114361e-06
Iter: 1173 loss: 1.18997434e-06
Iter: 1174 loss: 1.19234983e-06
Iter: 1175 loss: 1.1895338e-06
Iter: 1176 loss: 1.18825687e-06
Iter: 1177 loss: 1.19376341e-06
Iter: 1178 loss: 1.1880453e-06
Iter: 1179 loss: 1.18730873e-06
Iter: 1180 loss: 1.18732078e-06
Iter: 1181 loss: 1.18658591e-06
Iter: 1182 loss: 1.18656908e-06
Iter: 1183 loss: 1.18607545e-06
Iter: 1184 loss: 1.18526896e-06
Iter: 1185 loss: 1.18665457e-06
Iter: 1186 loss: 1.18492017e-06
Iter: 1187 loss: 1.18378284e-06
Iter: 1188 loss: 1.18875573e-06
Iter: 1189 loss: 1.18353569e-06
Iter: 1190 loss: 1.18282458e-06
Iter: 1191 loss: 1.18351386e-06
Iter: 1192 loss: 1.18241428e-06
Iter: 1193 loss: 1.18157755e-06
Iter: 1194 loss: 1.18811863e-06
Iter: 1195 loss: 1.18151388e-06
Iter: 1196 loss: 1.18095693e-06
Iter: 1197 loss: 1.1796302e-06
Iter: 1198 loss: 1.1950093e-06
Iter: 1199 loss: 1.17953186e-06
Iter: 1200 loss: 1.1784789e-06
Iter: 1201 loss: 1.19411607e-06
Iter: 1202 loss: 1.17845138e-06
Iter: 1203 loss: 1.17765126e-06
Iter: 1204 loss: 1.17957029e-06
Iter: 1205 loss: 1.17738955e-06
Iter: 1206 loss: 1.17646505e-06
Iter: 1207 loss: 1.18285141e-06
Iter: 1208 loss: 1.17633363e-06
Iter: 1209 loss: 1.17554623e-06
Iter: 1210 loss: 1.17498666e-06
Iter: 1211 loss: 1.17469938e-06
Iter: 1212 loss: 1.17378704e-06
Iter: 1213 loss: 1.17529135e-06
Iter: 1214 loss: 1.17338732e-06
Iter: 1215 loss: 1.17225147e-06
Iter: 1216 loss: 1.17273146e-06
Iter: 1217 loss: 1.17146442e-06
Iter: 1218 loss: 1.17060586e-06
Iter: 1219 loss: 1.17062314e-06
Iter: 1220 loss: 1.16978822e-06
Iter: 1221 loss: 1.17280752e-06
Iter: 1222 loss: 1.16959518e-06
Iter: 1223 loss: 1.16900628e-06
Iter: 1224 loss: 1.16872275e-06
Iter: 1225 loss: 1.16845536e-06
Iter: 1226 loss: 1.16757815e-06
Iter: 1227 loss: 1.17833827e-06
Iter: 1228 loss: 1.16759884e-06
Iter: 1229 loss: 1.16708713e-06
Iter: 1230 loss: 1.16606191e-06
Iter: 1231 loss: 1.18317678e-06
Iter: 1232 loss: 1.16602541e-06
Iter: 1233 loss: 1.16523654e-06
Iter: 1234 loss: 1.16519959e-06
Iter: 1235 loss: 1.1645443e-06
Iter: 1236 loss: 1.16385525e-06
Iter: 1237 loss: 1.1637776e-06
Iter: 1238 loss: 1.16273043e-06
Iter: 1239 loss: 1.16290232e-06
Iter: 1240 loss: 1.1620034e-06
Iter: 1241 loss: 1.16136994e-06
Iter: 1242 loss: 1.16121896e-06
Iter: 1243 loss: 1.1605523e-06
Iter: 1244 loss: 1.16004412e-06
Iter: 1245 loss: 1.15983244e-06
Iter: 1246 loss: 1.15898433e-06
Iter: 1247 loss: 1.16031947e-06
Iter: 1248 loss: 1.15858597e-06
Iter: 1249 loss: 1.15764749e-06
Iter: 1250 loss: 1.16074307e-06
Iter: 1251 loss: 1.15736657e-06
Iter: 1252 loss: 1.15650278e-06
Iter: 1253 loss: 1.15790954e-06
Iter: 1254 loss: 1.15612136e-06
Iter: 1255 loss: 1.15551802e-06
Iter: 1256 loss: 1.15547243e-06
Iter: 1257 loss: 1.15501098e-06
Iter: 1258 loss: 1.15410012e-06
Iter: 1259 loss: 1.15412115e-06
Iter: 1260 loss: 1.15353873e-06
Iter: 1261 loss: 1.15355374e-06
Iter: 1262 loss: 1.15297814e-06
Iter: 1263 loss: 1.15194564e-06
Iter: 1264 loss: 1.17419063e-06
Iter: 1265 loss: 1.15194837e-06
Iter: 1266 loss: 1.15078228e-06
Iter: 1267 loss: 1.15299895e-06
Iter: 1268 loss: 1.15022681e-06
Iter: 1269 loss: 1.14960869e-06
Iter: 1270 loss: 1.1495473e-06
Iter: 1271 loss: 1.14905276e-06
Iter: 1272 loss: 1.14816203e-06
Iter: 1273 loss: 1.16961121e-06
Iter: 1274 loss: 1.14816089e-06
Iter: 1275 loss: 1.14714555e-06
Iter: 1276 loss: 1.14862553e-06
Iter: 1277 loss: 1.14666e-06
Iter: 1278 loss: 1.14619479e-06
Iter: 1279 loss: 1.14605155e-06
Iter: 1280 loss: 1.14555633e-06
Iter: 1281 loss: 1.14499903e-06
Iter: 1282 loss: 1.14488989e-06
Iter: 1283 loss: 1.14409841e-06
Iter: 1284 loss: 1.14322256e-06
Iter: 1285 loss: 1.14308045e-06
Iter: 1286 loss: 1.14191789e-06
Iter: 1287 loss: 1.15046794e-06
Iter: 1288 loss: 1.14178783e-06
Iter: 1289 loss: 1.14124043e-06
Iter: 1290 loss: 1.14123714e-06
Iter: 1291 loss: 1.14069928e-06
Iter: 1292 loss: 1.14073009e-06
Iter: 1293 loss: 1.14029035e-06
Iter: 1294 loss: 1.13959663e-06
Iter: 1295 loss: 1.14137526e-06
Iter: 1296 loss: 1.13938904e-06
Iter: 1297 loss: 1.13868805e-06
Iter: 1298 loss: 1.14230158e-06
Iter: 1299 loss: 1.13856345e-06
Iter: 1300 loss: 1.13794124e-06
Iter: 1301 loss: 1.13748638e-06
Iter: 1302 loss: 1.1372457e-06
Iter: 1303 loss: 1.13650981e-06
Iter: 1304 loss: 1.13972692e-06
Iter: 1305 loss: 1.13632098e-06
Iter: 1306 loss: 1.13555325e-06
Iter: 1307 loss: 1.14035345e-06
Iter: 1308 loss: 1.13547458e-06
Iter: 1309 loss: 1.13481269e-06
Iter: 1310 loss: 1.1338941e-06
Iter: 1311 loss: 1.13386932e-06
Iter: 1312 loss: 1.13287831e-06
Iter: 1313 loss: 1.13916622e-06
Iter: 1314 loss: 1.13277576e-06
Iter: 1315 loss: 1.13205715e-06
Iter: 1316 loss: 1.14303361e-06
Iter: 1317 loss: 1.13206534e-06
Iter: 1318 loss: 1.13161741e-06
Iter: 1319 loss: 1.13057922e-06
Iter: 1320 loss: 1.14230488e-06
Iter: 1321 loss: 1.13046588e-06
Iter: 1322 loss: 1.12936243e-06
Iter: 1323 loss: 1.13461795e-06
Iter: 1324 loss: 1.12912335e-06
Iter: 1325 loss: 1.12821397e-06
Iter: 1326 loss: 1.12867212e-06
Iter: 1327 loss: 1.12760722e-06
Iter: 1328 loss: 1.12661712e-06
Iter: 1329 loss: 1.13950728e-06
Iter: 1330 loss: 1.12660655e-06
Iter: 1331 loss: 1.12600901e-06
Iter: 1332 loss: 1.13431224e-06
Iter: 1333 loss: 1.12600378e-06
Iter: 1334 loss: 1.12556859e-06
Iter: 1335 loss: 1.12480063e-06
Iter: 1336 loss: 1.1247821e-06
Iter: 1337 loss: 1.12417945e-06
Iter: 1338 loss: 1.12414546e-06
Iter: 1339 loss: 1.1237446e-06
Iter: 1340 loss: 1.12354223e-06
Iter: 1341 loss: 1.12334465e-06
Iter: 1342 loss: 1.12264104e-06
Iter: 1343 loss: 1.12289035e-06
Iter: 1344 loss: 1.12213957e-06
Iter: 1345 loss: 1.12147291e-06
Iter: 1346 loss: 1.13008014e-06
Iter: 1347 loss: 1.12144858e-06
Iter: 1348 loss: 1.12087719e-06
Iter: 1349 loss: 1.12076305e-06
Iter: 1350 loss: 1.12035627e-06
Iter: 1351 loss: 1.11956206e-06
Iter: 1352 loss: 1.11976351e-06
Iter: 1353 loss: 1.11902318e-06
Iter: 1354 loss: 1.11862914e-06
Iter: 1355 loss: 1.11849454e-06
Iter: 1356 loss: 1.11807617e-06
Iter: 1357 loss: 1.11719464e-06
Iter: 1358 loss: 1.13137241e-06
Iter: 1359 loss: 1.11714962e-06
Iter: 1360 loss: 1.11606983e-06
Iter: 1361 loss: 1.11743429e-06
Iter: 1362 loss: 1.11550708e-06
Iter: 1363 loss: 1.11450368e-06
Iter: 1364 loss: 1.11778309e-06
Iter: 1365 loss: 1.1142115e-06
Iter: 1366 loss: 1.11359645e-06
Iter: 1367 loss: 1.1135711e-06
Iter: 1368 loss: 1.11300255e-06
Iter: 1369 loss: 1.11306861e-06
Iter: 1370 loss: 1.11261045e-06
Iter: 1371 loss: 1.11203872e-06
Iter: 1372 loss: 1.11327336e-06
Iter: 1373 loss: 1.11180259e-06
Iter: 1374 loss: 1.1111116e-06
Iter: 1375 loss: 1.11368718e-06
Iter: 1376 loss: 1.11090139e-06
Iter: 1377 loss: 1.11039071e-06
Iter: 1378 loss: 1.10986753e-06
Iter: 1379 loss: 1.10983717e-06
Iter: 1380 loss: 1.10894257e-06
Iter: 1381 loss: 1.11577799e-06
Iter: 1382 loss: 1.10885048e-06
Iter: 1383 loss: 1.10821316e-06
Iter: 1384 loss: 1.11048e-06
Iter: 1385 loss: 1.10799692e-06
Iter: 1386 loss: 1.10729593e-06
Iter: 1387 loss: 1.10745691e-06
Iter: 1388 loss: 1.10679036e-06
Iter: 1389 loss: 1.10597796e-06
Iter: 1390 loss: 1.1087983e-06
Iter: 1391 loss: 1.10575343e-06
Iter: 1392 loss: 1.10482017e-06
Iter: 1393 loss: 1.11019426e-06
Iter: 1394 loss: 1.10470228e-06
Iter: 1395 loss: 1.10416272e-06
Iter: 1396 loss: 1.10346e-06
Iter: 1397 loss: 1.10340466e-06
Iter: 1398 loss: 1.10255041e-06
Iter: 1399 loss: 1.10496114e-06
Iter: 1400 loss: 1.1022538e-06
Iter: 1401 loss: 1.10155725e-06
Iter: 1402 loss: 1.10879284e-06
Iter: 1403 loss: 1.1014979e-06
Iter: 1404 loss: 1.10078918e-06
Iter: 1405 loss: 1.10349379e-06
Iter: 1406 loss: 1.10059409e-06
Iter: 1407 loss: 1.10010046e-06
Iter: 1408 loss: 1.10010046e-06
Iter: 1409 loss: 1.09971302e-06
Iter: 1410 loss: 1.09906523e-06
Iter: 1411 loss: 1.10567953e-06
Iter: 1412 loss: 1.09903885e-06
Iter: 1413 loss: 1.0985259e-06
Iter: 1414 loss: 1.09759685e-06
Iter: 1415 loss: 1.12062457e-06
Iter: 1416 loss: 1.09759503e-06
Iter: 1417 loss: 1.09671373e-06
Iter: 1418 loss: 1.10353267e-06
Iter: 1419 loss: 1.09672067e-06
Iter: 1420 loss: 1.09596635e-06
Iter: 1421 loss: 1.09969369e-06
Iter: 1422 loss: 1.09578866e-06
Iter: 1423 loss: 1.09524592e-06
Iter: 1424 loss: 1.09561665e-06
Iter: 1425 loss: 1.09487178e-06
Iter: 1426 loss: 1.09411008e-06
Iter: 1427 loss: 1.09601683e-06
Iter: 1428 loss: 1.09383234e-06
Iter: 1429 loss: 1.09309462e-06
Iter: 1430 loss: 1.0995534e-06
Iter: 1431 loss: 1.09307632e-06
Iter: 1432 loss: 1.09247731e-06
Iter: 1433 loss: 1.09166581e-06
Iter: 1434 loss: 1.09165057e-06
Iter: 1435 loss: 1.09073324e-06
Iter: 1436 loss: 1.09360417e-06
Iter: 1437 loss: 1.09051143e-06
Iter: 1438 loss: 1.08982226e-06
Iter: 1439 loss: 1.09254438e-06
Iter: 1440 loss: 1.08963673e-06
Iter: 1441 loss: 1.08894233e-06
Iter: 1442 loss: 1.09637654e-06
Iter: 1443 loss: 1.0889222e-06
Iter: 1444 loss: 1.08846143e-06
Iter: 1445 loss: 1.08802919e-06
Iter: 1446 loss: 1.08794029e-06
Iter: 1447 loss: 1.08742074e-06
Iter: 1448 loss: 1.0874287e-06
Iter: 1449 loss: 1.08704921e-06
Iter: 1450 loss: 1.08597283e-06
Iter: 1451 loss: 1.09748703e-06
Iter: 1452 loss: 1.08587676e-06
Iter: 1453 loss: 1.084818e-06
Iter: 1454 loss: 1.09217876e-06
Iter: 1455 loss: 1.08472568e-06
Iter: 1456 loss: 1.08401719e-06
Iter: 1457 loss: 1.09341011e-06
Iter: 1458 loss: 1.08404242e-06
Iter: 1459 loss: 1.08346012e-06
Iter: 1460 loss: 1.08286804e-06
Iter: 1461 loss: 1.08273775e-06
Iter: 1462 loss: 1.08216568e-06
Iter: 1463 loss: 1.08930431e-06
Iter: 1464 loss: 1.08211543e-06
Iter: 1465 loss: 1.08161032e-06
Iter: 1466 loss: 1.08313179e-06
Iter: 1467 loss: 1.08148186e-06
Iter: 1468 loss: 1.0809365e-06
Iter: 1469 loss: 1.0805818e-06
Iter: 1470 loss: 1.0803376e-06
Iter: 1471 loss: 1.07953292e-06
Iter: 1472 loss: 1.08122708e-06
Iter: 1473 loss: 1.07923347e-06
Iter: 1474 loss: 1.0784928e-06
Iter: 1475 loss: 1.07969822e-06
Iter: 1476 loss: 1.07814878e-06
Iter: 1477 loss: 1.07756421e-06
Iter: 1478 loss: 1.07753749e-06
Iter: 1479 loss: 1.07697144e-06
Iter: 1480 loss: 1.07617279e-06
Iter: 1481 loss: 1.0761579e-06
Iter: 1482 loss: 1.07564961e-06
Iter: 1483 loss: 1.08379402e-06
Iter: 1484 loss: 1.07564165e-06
Iter: 1485 loss: 1.07510016e-06
Iter: 1486 loss: 1.07484902e-06
Iter: 1487 loss: 1.07459573e-06
Iter: 1488 loss: 1.07386245e-06
Iter: 1489 loss: 1.07389008e-06
Iter: 1490 loss: 1.07331948e-06
Iter: 1491 loss: 1.07283745e-06
Iter: 1492 loss: 1.07275548e-06
Iter: 1493 loss: 1.07232404e-06
Iter: 1494 loss: 1.07194114e-06
Iter: 1495 loss: 1.07184042e-06
Iter: 1496 loss: 1.07119786e-06
Iter: 1497 loss: 1.07497112e-06
Iter: 1498 loss: 1.07114477e-06
Iter: 1499 loss: 1.07051096e-06
Iter: 1500 loss: 1.0723536e-06
Iter: 1501 loss: 1.07029086e-06
Iter: 1502 loss: 1.06972129e-06
Iter: 1503 loss: 1.06969821e-06
Iter: 1504 loss: 1.06922596e-06
Iter: 1505 loss: 1.06855975e-06
Iter: 1506 loss: 1.07023379e-06
Iter: 1507 loss: 1.06832681e-06
Iter: 1508 loss: 1.06757182e-06
Iter: 1509 loss: 1.06908635e-06
Iter: 1510 loss: 1.06727498e-06
Iter: 1511 loss: 1.06676634e-06
Iter: 1512 loss: 1.0667477e-06
Iter: 1513 loss: 1.06643051e-06
Iter: 1514 loss: 1.06572804e-06
Iter: 1515 loss: 1.07668916e-06
Iter: 1516 loss: 1.0657169e-06
Iter: 1517 loss: 1.06516279e-06
Iter: 1518 loss: 1.0651861e-06
Iter: 1519 loss: 1.06467155e-06
Iter: 1520 loss: 1.06442246e-06
Iter: 1521 loss: 1.06413768e-06
Iter: 1522 loss: 1.06350626e-06
Iter: 1523 loss: 1.06374159e-06
Iter: 1524 loss: 1.06309449e-06
Iter: 1525 loss: 1.0624168e-06
Iter: 1526 loss: 1.0711999e-06
Iter: 1527 loss: 1.06242032e-06
Iter: 1528 loss: 1.06175912e-06
Iter: 1529 loss: 1.06190259e-06
Iter: 1530 loss: 1.06129573e-06
Iter: 1531 loss: 1.06064533e-06
Iter: 1532 loss: 1.06231209e-06
Iter: 1533 loss: 1.06044126e-06
Iter: 1534 loss: 1.05969229e-06
Iter: 1535 loss: 1.06470384e-06
Iter: 1536 loss: 1.05962067e-06
Iter: 1537 loss: 1.05914569e-06
Iter: 1538 loss: 1.05844697e-06
Iter: 1539 loss: 1.05841457e-06
Iter: 1540 loss: 1.057546e-06
Iter: 1541 loss: 1.0613885e-06
Iter: 1542 loss: 1.05736e-06
Iter: 1543 loss: 1.05655977e-06
Iter: 1544 loss: 1.05857794e-06
Iter: 1545 loss: 1.05634217e-06
Iter: 1546 loss: 1.05581103e-06
Iter: 1547 loss: 1.05578772e-06
Iter: 1548 loss: 1.05533297e-06
Iter: 1549 loss: 1.05479535e-06
Iter: 1550 loss: 1.05473896e-06
Iter: 1551 loss: 1.05406798e-06
Iter: 1552 loss: 1.05606864e-06
Iter: 1553 loss: 1.05385834e-06
Iter: 1554 loss: 1.0530897e-06
Iter: 1555 loss: 1.05814024e-06
Iter: 1556 loss: 1.05301592e-06
Iter: 1557 loss: 1.05263348e-06
Iter: 1558 loss: 1.05205947e-06
Iter: 1559 loss: 1.05208437e-06
Iter: 1560 loss: 1.05135507e-06
Iter: 1561 loss: 1.05653555e-06
Iter: 1562 loss: 1.05128879e-06
Iter: 1563 loss: 1.05052482e-06
Iter: 1564 loss: 1.0524102e-06
Iter: 1565 loss: 1.0502373e-06
Iter: 1566 loss: 1.04967626e-06
Iter: 1567 loss: 1.04995092e-06
Iter: 1568 loss: 1.0492837e-06
Iter: 1569 loss: 1.04866763e-06
Iter: 1570 loss: 1.05776553e-06
Iter: 1571 loss: 1.04865421e-06
Iter: 1572 loss: 1.04818787e-06
Iter: 1573 loss: 1.04750961e-06
Iter: 1574 loss: 1.04750256e-06
Iter: 1575 loss: 1.04675223e-06
Iter: 1576 loss: 1.04831349e-06
Iter: 1577 loss: 1.04644892e-06
Iter: 1578 loss: 1.04565925e-06
Iter: 1579 loss: 1.05021638e-06
Iter: 1580 loss: 1.04557944e-06
Iter: 1581 loss: 1.04507046e-06
Iter: 1582 loss: 1.05136053e-06
Iter: 1583 loss: 1.04504829e-06
Iter: 1584 loss: 1.04461833e-06
Iter: 1585 loss: 1.04498599e-06
Iter: 1586 loss: 1.04435776e-06
Iter: 1587 loss: 1.04385799e-06
Iter: 1588 loss: 1.04333253e-06
Iter: 1589 loss: 1.04323385e-06
Iter: 1590 loss: 1.04260653e-06
Iter: 1591 loss: 1.04259891e-06
Iter: 1592 loss: 1.04218589e-06
Iter: 1593 loss: 1.04168555e-06
Iter: 1594 loss: 1.04160063e-06
Iter: 1595 loss: 1.04095511e-06
Iter: 1596 loss: 1.04169146e-06
Iter: 1597 loss: 1.04054118e-06
Iter: 1598 loss: 1.03971161e-06
Iter: 1599 loss: 1.04963078e-06
Iter: 1600 loss: 1.03969523e-06
Iter: 1601 loss: 1.03919797e-06
Iter: 1602 loss: 1.03903608e-06
Iter: 1603 loss: 1.03874436e-06
Iter: 1604 loss: 1.03832031e-06
Iter: 1605 loss: 1.03831485e-06
Iter: 1606 loss: 1.0378584e-06
Iter: 1607 loss: 1.03709976e-06
Iter: 1608 loss: 1.03710397e-06
Iter: 1609 loss: 1.03640241e-06
Iter: 1610 loss: 1.03781827e-06
Iter: 1611 loss: 1.03614457e-06
Iter: 1612 loss: 1.0354114e-06
Iter: 1613 loss: 1.03820162e-06
Iter: 1614 loss: 1.03526099e-06
Iter: 1615 loss: 1.03473167e-06
Iter: 1616 loss: 1.04140565e-06
Iter: 1617 loss: 1.03471746e-06
Iter: 1618 loss: 1.03414777e-06
Iter: 1619 loss: 1.03497655e-06
Iter: 1620 loss: 1.03393279e-06
Iter: 1621 loss: 1.03340369e-06
Iter: 1622 loss: 1.0340018e-06
Iter: 1623 loss: 1.03316336e-06
Iter: 1624 loss: 1.03263835e-06
Iter: 1625 loss: 1.03540765e-06
Iter: 1626 loss: 1.03258799e-06
Iter: 1627 loss: 1.03200045e-06
Iter: 1628 loss: 1.03220987e-06
Iter: 1629 loss: 1.03160096e-06
Iter: 1630 loss: 1.03099831e-06
Iter: 1631 loss: 1.03124717e-06
Iter: 1632 loss: 1.03057209e-06
Iter: 1633 loss: 1.030048e-06
Iter: 1634 loss: 1.03005721e-06
Iter: 1635 loss: 1.02952731e-06
Iter: 1636 loss: 1.02928186e-06
Iter: 1637 loss: 1.02905153e-06
Iter: 1638 loss: 1.02857211e-06
Iter: 1639 loss: 1.03266416e-06
Iter: 1640 loss: 1.02856166e-06
Iter: 1641 loss: 1.02803745e-06
Iter: 1642 loss: 1.02827596e-06
Iter: 1643 loss: 1.02764488e-06
Iter: 1644 loss: 1.02711454e-06
Iter: 1645 loss: 1.02666604e-06
Iter: 1646 loss: 1.0265187e-06
Iter: 1647 loss: 1.02570561e-06
Iter: 1648 loss: 1.02730871e-06
Iter: 1649 loss: 1.02535682e-06
Iter: 1650 loss: 1.02444437e-06
Iter: 1651 loss: 1.02948411e-06
Iter: 1652 loss: 1.0242818e-06
Iter: 1653 loss: 1.02397735e-06
Iter: 1654 loss: 1.02388276e-06
Iter: 1655 loss: 1.02362014e-06
Iter: 1656 loss: 1.02325112e-06
Iter: 1657 loss: 1.0232111e-06
Iter: 1658 loss: 1.02265835e-06
Iter: 1659 loss: 1.02349168e-06
Iter: 1660 loss: 1.02238948e-06
Iter: 1661 loss: 1.02176591e-06
Iter: 1662 loss: 1.02790352e-06
Iter: 1663 loss: 1.02178524e-06
Iter: 1664 loss: 1.02134e-06
Iter: 1665 loss: 1.02130468e-06
Iter: 1666 loss: 1.02098193e-06
Iter: 1667 loss: 1.02043919e-06
Iter: 1668 loss: 1.02031231e-06
Iter: 1669 loss: 1.01995249e-06
Iter: 1670 loss: 1.01950241e-06
Iter: 1671 loss: 1.01947069e-06
Iter: 1672 loss: 1.01907096e-06
Iter: 1673 loss: 1.01865589e-06
Iter: 1674 loss: 1.018587e-06
Iter: 1675 loss: 1.01805108e-06
Iter: 1676 loss: 1.02207878e-06
Iter: 1677 loss: 1.01804312e-06
Iter: 1678 loss: 1.01748685e-06
Iter: 1679 loss: 1.01870046e-06
Iter: 1680 loss: 1.01726835e-06
Iter: 1681 loss: 1.01686055e-06
Iter: 1682 loss: 1.0160893e-06
Iter: 1683 loss: 1.03182435e-06
Iter: 1684 loss: 1.01607759e-06
Iter: 1685 loss: 1.015208e-06
Iter: 1686 loss: 1.02139177e-06
Iter: 1687 loss: 1.01519299e-06
Iter: 1688 loss: 1.01459227e-06
Iter: 1689 loss: 1.01738965e-06
Iter: 1690 loss: 1.01450519e-06
Iter: 1691 loss: 1.01385683e-06
Iter: 1692 loss: 1.01893283e-06
Iter: 1693 loss: 1.01383489e-06
Iter: 1694 loss: 1.01351861e-06
Iter: 1695 loss: 1.01290948e-06
Iter: 1696 loss: 1.02594242e-06
Iter: 1697 loss: 1.01292881e-06
Iter: 1698 loss: 1.01236265e-06
Iter: 1699 loss: 1.01238788e-06
Iter: 1700 loss: 1.011893e-06
Iter: 1701 loss: 1.012148e-06
Iter: 1702 loss: 1.01158071e-06
Iter: 1703 loss: 1.01110891e-06
Iter: 1704 loss: 1.0114893e-06
Iter: 1705 loss: 1.01082367e-06
Iter: 1706 loss: 1.010235e-06
Iter: 1707 loss: 1.01342039e-06
Iter: 1708 loss: 1.01013904e-06
Iter: 1709 loss: 1.009632e-06
Iter: 1710 loss: 1.01223e-06
Iter: 1711 loss: 1.00958061e-06
Iter: 1712 loss: 1.00920465e-06
Iter: 1713 loss: 1.00922762e-06
Iter: 1714 loss: 1.00892498e-06
Iter: 1715 loss: 1.0083935e-06
Iter: 1716 loss: 1.01207559e-06
Iter: 1717 loss: 1.00833552e-06
Iter: 1718 loss: 1.00792465e-06
Iter: 1719 loss: 1.00769194e-06
Iter: 1720 loss: 1.00748764e-06
Iter: 1721 loss: 1.00690681e-06
Iter: 1722 loss: 1.00655507e-06
Iter: 1723 loss: 1.00634725e-06
Iter: 1724 loss: 1.00537204e-06
Iter: 1725 loss: 1.00940906e-06
Iter: 1726 loss: 1.00516195e-06
Iter: 1727 loss: 1.00463649e-06
Iter: 1728 loss: 1.01232376e-06
Iter: 1729 loss: 1.00465104e-06
Iter: 1730 loss: 1.00417265e-06
Iter: 1731 loss: 1.00605303e-06
Iter: 1732 loss: 1.00404168e-06
Iter: 1733 loss: 1.00368197e-06
Iter: 1734 loss: 1.00317379e-06
Iter: 1735 loss: 1.0031531e-06
Iter: 1736 loss: 1.00263173e-06
Iter: 1737 loss: 1.00815419e-06
Iter: 1738 loss: 1.00261536e-06
Iter: 1739 loss: 1.00209718e-06
Iter: 1740 loss: 1.00296415e-06
Iter: 1741 loss: 1.00186276e-06
Iter: 1742 loss: 1.00137686e-06
Iter: 1743 loss: 1.00142438e-06
Iter: 1744 loss: 1.0010308e-06
Iter: 1745 loss: 1.00038505e-06
Iter: 1746 loss: 1.00498119e-06
Iter: 1747 loss: 1.00032264e-06
Iter: 1748 loss: 9.99856638e-07
Iter: 1749 loss: 1.00181035e-06
Iter: 1750 loss: 9.99769668e-07
Iter: 1751 loss: 9.9935346e-07
Iter: 1752 loss: 9.99308895e-07
Iter: 1753 loss: 9.9898034e-07
Iter: 1754 loss: 9.98483756e-07
Iter: 1755 loss: 1.00433272e-06
Iter: 1756 loss: 9.98426344e-07
Iter: 1757 loss: 9.98055611e-07
Iter: 1758 loss: 9.97461e-07
Iter: 1759 loss: 9.9745057e-07
Iter: 1760 loss: 9.96745371e-07
Iter: 1761 loss: 9.98267183e-07
Iter: 1762 loss: 9.9651561e-07
Iter: 1763 loss: 9.95821893e-07
Iter: 1764 loss: 9.96037e-07
Iter: 1765 loss: 9.95379537e-07
Iter: 1766 loss: 9.95067e-07
Iter: 1767 loss: 9.94932861e-07
Iter: 1768 loss: 9.94523475e-07
Iter: 1769 loss: 9.95116352e-07
Iter: 1770 loss: 9.94361471e-07
Iter: 1771 loss: 9.93932645e-07
Iter: 1772 loss: 9.9329668e-07
Iter: 1773 loss: 9.93303502e-07
Iter: 1774 loss: 9.92463924e-07
Iter: 1775 loss: 9.96331892e-07
Iter: 1776 loss: 9.92322839e-07
Iter: 1777 loss: 9.91778506e-07
Iter: 1778 loss: 9.98085852e-07
Iter: 1779 loss: 9.91804313e-07
Iter: 1780 loss: 9.91307729e-07
Iter: 1781 loss: 9.92672312e-07
Iter: 1782 loss: 9.91162551e-07
Iter: 1783 loss: 9.9069814e-07
Iter: 1784 loss: 9.90938474e-07
Iter: 1785 loss: 9.90425178e-07
Iter: 1786 loss: 9.89888122e-07
Iter: 1787 loss: 9.92399464e-07
Iter: 1788 loss: 9.89793079e-07
Iter: 1789 loss: 9.89317414e-07
Iter: 1790 loss: 9.90393801e-07
Iter: 1791 loss: 9.89105502e-07
Iter: 1792 loss: 9.88670081e-07
Iter: 1793 loss: 9.89118348e-07
Iter: 1794 loss: 9.884e-07
Iter: 1795 loss: 9.87852786e-07
Iter: 1796 loss: 9.91842171e-07
Iter: 1797 loss: 9.87792532e-07
Iter: 1798 loss: 9.87383942e-07
Iter: 1799 loss: 9.86927262e-07
Iter: 1800 loss: 9.86868827e-07
Iter: 1801 loss: 9.86291411e-07
Iter: 1802 loss: 9.86477176e-07
Iter: 1803 loss: 9.85877136e-07
Iter: 1804 loss: 9.85224915e-07
Iter: 1805 loss: 9.90265448e-07
Iter: 1806 loss: 9.85158e-07
Iter: 1807 loss: 9.8485657e-07
Iter: 1808 loss: 9.84798817e-07
Iter: 1809 loss: 9.84524604e-07
Iter: 1810 loss: 9.83961399e-07
Iter: 1811 loss: 9.90499075e-07
Iter: 1812 loss: 9.83905466e-07
Iter: 1813 loss: 9.83156497e-07
Iter: 1814 loss: 9.85698648e-07
Iter: 1815 loss: 9.82961e-07
Iter: 1816 loss: 9.82358301e-07
Iter: 1817 loss: 9.85150564e-07
Iter: 1818 loss: 9.82278607e-07
Iter: 1819 loss: 9.81719495e-07
Iter: 1820 loss: 9.85959105e-07
Iter: 1821 loss: 9.81674475e-07
Iter: 1822 loss: 9.81198582e-07
Iter: 1823 loss: 9.81357857e-07
Iter: 1824 loss: 9.80856385e-07
Iter: 1825 loss: 9.80321602e-07
Iter: 1826 loss: 9.81374342e-07
Iter: 1827 loss: 9.80138452e-07
Iter: 1828 loss: 9.79652555e-07
Iter: 1829 loss: 9.85348834e-07
Iter: 1830 loss: 9.79662673e-07
Iter: 1831 loss: 9.79293759e-07
Iter: 1832 loss: 9.78728281e-07
Iter: 1833 loss: 9.78710659e-07
Iter: 1834 loss: 9.78128924e-07
Iter: 1835 loss: 9.82604206e-07
Iter: 1836 loss: 9.78074468e-07
Iter: 1837 loss: 9.77530249e-07
Iter: 1838 loss: 9.79295919e-07
Iter: 1839 loss: 9.77426907e-07
Iter: 1840 loss: 9.76975116e-07
Iter: 1841 loss: 9.76693514e-07
Iter: 1842 loss: 9.76507067e-07
Iter: 1843 loss: 9.75998319e-07
Iter: 1844 loss: 9.78071057e-07
Iter: 1845 loss: 9.75894636e-07
Iter: 1846 loss: 9.75386e-07
Iter: 1847 loss: 9.75411922e-07
Iter: 1848 loss: 9.75105877e-07
Iter: 1849 loss: 9.74559612e-07
Iter: 1850 loss: 9.8763735e-07
Iter: 1851 loss: 9.74573254e-07
Iter: 1852 loss: 9.73941269e-07
Iter: 1853 loss: 9.74194904e-07
Iter: 1854 loss: 9.73497436e-07
Iter: 1855 loss: 9.72641601e-07
Iter: 1856 loss: 9.77970103e-07
Iter: 1857 loss: 9.72557473e-07
Iter: 1858 loss: 9.71962e-07
Iter: 1859 loss: 9.73881356e-07
Iter: 1860 loss: 9.71771897e-07
Iter: 1861 loss: 9.71263717e-07
Iter: 1862 loss: 9.76486604e-07
Iter: 1863 loss: 9.71238251e-07
Iter: 1864 loss: 9.70765541e-07
Iter: 1865 loss: 9.71371719e-07
Iter: 1866 loss: 9.70536576e-07
Iter: 1867 loss: 9.70130827e-07
Iter: 1868 loss: 9.70109681e-07
Iter: 1869 loss: 9.69752136e-07
Iter: 1870 loss: 9.69345e-07
Iter: 1871 loss: 9.76036517e-07
Iter: 1872 loss: 9.69343546e-07
Iter: 1873 loss: 9.6892154e-07
Iter: 1874 loss: 9.68410063e-07
Iter: 1875 loss: 9.68381755e-07
Iter: 1876 loss: 9.67789e-07
Iter: 1877 loss: 9.70274641e-07
Iter: 1878 loss: 9.67662572e-07
Iter: 1879 loss: 9.67298888e-07
Iter: 1880 loss: 9.67270921e-07
Iter: 1881 loss: 9.66995799e-07
Iter: 1882 loss: 9.66504786e-07
Iter: 1883 loss: 9.66502284e-07
Iter: 1884 loss: 9.66128709e-07
Iter: 1885 loss: 9.66143716e-07
Iter: 1886 loss: 9.6576764e-07
Iter: 1887 loss: 9.65554477e-07
Iter: 1888 loss: 9.65352569e-07
Iter: 1889 loss: 9.64924084e-07
Iter: 1890 loss: 9.6475469e-07
Iter: 1891 loss: 9.64513674e-07
Iter: 1892 loss: 9.63783123e-07
Iter: 1893 loss: 9.66335e-07
Iter: 1894 loss: 9.6360418e-07
Iter: 1895 loss: 9.62990498e-07
Iter: 1896 loss: 9.66157e-07
Iter: 1897 loss: 9.62893864e-07
Iter: 1898 loss: 9.62454351e-07
Iter: 1899 loss: 9.64561536e-07
Iter: 1900 loss: 9.62362e-07
Iter: 1901 loss: 9.61946171e-07
Iter: 1902 loss: 9.64203e-07
Iter: 1903 loss: 9.61849764e-07
Iter: 1904 loss: 9.61472097e-07
Iter: 1905 loss: 9.61065e-07
Iter: 1906 loss: 9.61011551e-07
Iter: 1907 loss: 9.60592843e-07
Iter: 1908 loss: 9.60594548e-07
Iter: 1909 loss: 9.60237458e-07
Iter: 1910 loss: 9.59740191e-07
Iter: 1911 loss: 9.59730642e-07
Iter: 1912 loss: 9.59154931e-07
Iter: 1913 loss: 9.61380238e-07
Iter: 1914 loss: 9.58998e-07
Iter: 1915 loss: 9.58658575e-07
Iter: 1916 loss: 9.58637429e-07
Iter: 1917 loss: 9.58342071e-07
Iter: 1918 loss: 9.57774091e-07
Iter: 1919 loss: 9.57764769e-07
Iter: 1920 loss: 9.57401767e-07
Iter: 1921 loss: 9.57392331e-07
Iter: 1922 loss: 9.57050361e-07
Iter: 1923 loss: 9.56749545e-07
Iter: 1924 loss: 9.56640861e-07
Iter: 1925 loss: 9.56133e-07
Iter: 1926 loss: 9.55982614e-07
Iter: 1927 loss: 9.55708174e-07
Iter: 1928 loss: 9.55073119e-07
Iter: 1929 loss: 9.60023726e-07
Iter: 1930 loss: 9.55009e-07
Iter: 1931 loss: 9.54502866e-07
Iter: 1932 loss: 9.55278324e-07
Iter: 1933 loss: 9.5429175e-07
Iter: 1934 loss: 9.53830749e-07
Iter: 1935 loss: 9.60006901e-07
Iter: 1936 loss: 9.53844278e-07
Iter: 1937 loss: 9.53430344e-07
Iter: 1938 loss: 9.53731842e-07
Iter: 1939 loss: 9.53168069e-07
Iter: 1940 loss: 9.52783751e-07
Iter: 1941 loss: 9.53416475e-07
Iter: 1942 loss: 9.52627602e-07
Iter: 1943 loss: 9.52069513e-07
Iter: 1944 loss: 9.54296411e-07
Iter: 1945 loss: 9.51981633e-07
Iter: 1946 loss: 9.51590209e-07
Iter: 1947 loss: 9.51064294e-07
Iter: 1948 loss: 9.51031552e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.2
+ date
Sat Nov  7 14:28:04 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f534b11d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f534b11dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53153766a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5315382c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5315382048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53153596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53153140d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53153129d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53152db1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53152c80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f53152859d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f531526abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f531526a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f0360a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f0300730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f0279620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f027a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f02c9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f025d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f02cec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f02ce620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f0253d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f01ad400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f01b8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f01b8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f0198488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f014a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f014a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f01272f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f00a6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f00a6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f00a66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f007c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f00ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f007cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52f0029488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.53722205e-05
Iter: 2 loss: 3.37142119e-05
Iter: 3 loss: 6.11572177e-05
Iter: 4 loss: 3.01812906e-05
Iter: 5 loss: 2.5489453e-05
Iter: 6 loss: 4.44550242e-05
Iter: 7 loss: 2.44633484e-05
Iter: 8 loss: 2.08250312e-05
Iter: 9 loss: 2.58005202e-05
Iter: 10 loss: 1.90154133e-05
Iter: 11 loss: 1.65313322e-05
Iter: 12 loss: 2.6594782e-05
Iter: 13 loss: 1.59954143e-05
Iter: 14 loss: 1.48888876e-05
Iter: 15 loss: 2.90041608e-05
Iter: 16 loss: 1.48800918e-05
Iter: 17 loss: 1.39748199e-05
Iter: 18 loss: 1.4051795e-05
Iter: 19 loss: 1.32712476e-05
Iter: 20 loss: 1.22746915e-05
Iter: 21 loss: 1.38409177e-05
Iter: 22 loss: 1.18081662e-05
Iter: 23 loss: 1.08323475e-05
Iter: 24 loss: 2.17668385e-05
Iter: 25 loss: 1.08140475e-05
Iter: 26 loss: 1.03588518e-05
Iter: 27 loss: 1.01285395e-05
Iter: 28 loss: 9.91524485e-06
Iter: 29 loss: 9.34412856e-06
Iter: 30 loss: 1.60128748e-05
Iter: 31 loss: 9.33560477e-06
Iter: 32 loss: 8.83818484e-06
Iter: 33 loss: 9.27029396e-06
Iter: 34 loss: 8.54604059e-06
Iter: 35 loss: 8.10722941e-06
Iter: 36 loss: 8.16265401e-06
Iter: 37 loss: 7.77261903e-06
Iter: 38 loss: 7.25672544e-06
Iter: 39 loss: 8.85092595e-06
Iter: 40 loss: 7.10495e-06
Iter: 41 loss: 6.8965237e-06
Iter: 42 loss: 6.83599501e-06
Iter: 43 loss: 6.64489653e-06
Iter: 44 loss: 6.54757332e-06
Iter: 45 loss: 6.45836e-06
Iter: 46 loss: 6.21456229e-06
Iter: 47 loss: 6.63901255e-06
Iter: 48 loss: 6.10682e-06
Iter: 49 loss: 5.92889364e-06
Iter: 50 loss: 5.92781817e-06
Iter: 51 loss: 5.80463438e-06
Iter: 52 loss: 6.09165318e-06
Iter: 53 loss: 5.7590496e-06
Iter: 54 loss: 5.63443155e-06
Iter: 55 loss: 5.51487938e-06
Iter: 56 loss: 5.48703611e-06
Iter: 57 loss: 5.33818093e-06
Iter: 58 loss: 7.50640766e-06
Iter: 59 loss: 5.33797629e-06
Iter: 60 loss: 5.22416531e-06
Iter: 61 loss: 5.29355839e-06
Iter: 62 loss: 5.15104239e-06
Iter: 63 loss: 5.01389786e-06
Iter: 64 loss: 5.27248903e-06
Iter: 65 loss: 4.95577387e-06
Iter: 66 loss: 4.83838e-06
Iter: 67 loss: 6.26845031e-06
Iter: 68 loss: 4.83716212e-06
Iter: 69 loss: 4.75413708e-06
Iter: 70 loss: 4.67343671e-06
Iter: 71 loss: 4.65539415e-06
Iter: 72 loss: 4.54316068e-06
Iter: 73 loss: 4.83559234e-06
Iter: 74 loss: 4.50506104e-06
Iter: 75 loss: 4.43497447e-06
Iter: 76 loss: 4.43416411e-06
Iter: 77 loss: 4.36630944e-06
Iter: 78 loss: 4.35256607e-06
Iter: 79 loss: 4.30755517e-06
Iter: 80 loss: 4.23558049e-06
Iter: 81 loss: 4.38390407e-06
Iter: 82 loss: 4.20686274e-06
Iter: 83 loss: 4.14012538e-06
Iter: 84 loss: 4.80180915e-06
Iter: 85 loss: 4.13799489e-06
Iter: 86 loss: 4.07699554e-06
Iter: 87 loss: 4.10983102e-06
Iter: 88 loss: 4.03670629e-06
Iter: 89 loss: 3.96706128e-06
Iter: 90 loss: 4.08852065e-06
Iter: 91 loss: 3.93603705e-06
Iter: 92 loss: 3.8768294e-06
Iter: 93 loss: 4.23710117e-06
Iter: 94 loss: 3.86960937e-06
Iter: 95 loss: 3.81644168e-06
Iter: 96 loss: 3.9332258e-06
Iter: 97 loss: 3.79583912e-06
Iter: 98 loss: 3.74409501e-06
Iter: 99 loss: 3.79835637e-06
Iter: 100 loss: 3.71532042e-06
Iter: 101 loss: 3.66571e-06
Iter: 102 loss: 4.23384427e-06
Iter: 103 loss: 3.66487848e-06
Iter: 104 loss: 3.62805827e-06
Iter: 105 loss: 3.60514878e-06
Iter: 106 loss: 3.59029718e-06
Iter: 107 loss: 3.53739915e-06
Iter: 108 loss: 3.61000139e-06
Iter: 109 loss: 3.51097879e-06
Iter: 110 loss: 3.46924867e-06
Iter: 111 loss: 3.46919933e-06
Iter: 112 loss: 3.43071133e-06
Iter: 113 loss: 3.43885426e-06
Iter: 114 loss: 3.40238807e-06
Iter: 115 loss: 3.35969526e-06
Iter: 116 loss: 3.38427844e-06
Iter: 117 loss: 3.33199318e-06
Iter: 118 loss: 3.29383465e-06
Iter: 119 loss: 3.29344243e-06
Iter: 120 loss: 3.26419013e-06
Iter: 121 loss: 3.25285509e-06
Iter: 122 loss: 3.23702375e-06
Iter: 123 loss: 3.20486652e-06
Iter: 124 loss: 3.34583592e-06
Iter: 125 loss: 3.19837864e-06
Iter: 126 loss: 3.16856813e-06
Iter: 127 loss: 3.22979849e-06
Iter: 128 loss: 3.15668558e-06
Iter: 129 loss: 3.12427574e-06
Iter: 130 loss: 3.28063607e-06
Iter: 131 loss: 3.11875101e-06
Iter: 132 loss: 3.09539109e-06
Iter: 133 loss: 3.10836049e-06
Iter: 134 loss: 3.08025915e-06
Iter: 135 loss: 3.05128242e-06
Iter: 136 loss: 3.28670399e-06
Iter: 137 loss: 3.04950299e-06
Iter: 138 loss: 3.02819581e-06
Iter: 139 loss: 3.0226829e-06
Iter: 140 loss: 3.00954321e-06
Iter: 141 loss: 2.98150371e-06
Iter: 142 loss: 3.02149419e-06
Iter: 143 loss: 2.96780286e-06
Iter: 144 loss: 2.94571714e-06
Iter: 145 loss: 2.94537676e-06
Iter: 146 loss: 2.92850063e-06
Iter: 147 loss: 2.92651976e-06
Iter: 148 loss: 2.91436754e-06
Iter: 149 loss: 2.89412242e-06
Iter: 150 loss: 2.91456058e-06
Iter: 151 loss: 2.88272213e-06
Iter: 152 loss: 2.86066643e-06
Iter: 153 loss: 3.17078502e-06
Iter: 154 loss: 2.86063369e-06
Iter: 155 loss: 2.84625435e-06
Iter: 156 loss: 2.82504834e-06
Iter: 157 loss: 2.8245031e-06
Iter: 158 loss: 2.79724259e-06
Iter: 159 loss: 2.93774633e-06
Iter: 160 loss: 2.7928827e-06
Iter: 161 loss: 2.77275808e-06
Iter: 162 loss: 2.90228581e-06
Iter: 163 loss: 2.77049821e-06
Iter: 164 loss: 2.75461707e-06
Iter: 165 loss: 2.7749436e-06
Iter: 166 loss: 2.74645436e-06
Iter: 167 loss: 2.72733587e-06
Iter: 168 loss: 2.76220112e-06
Iter: 169 loss: 2.71907084e-06
Iter: 170 loss: 2.70143482e-06
Iter: 171 loss: 2.86125851e-06
Iter: 172 loss: 2.70054807e-06
Iter: 173 loss: 2.68816575e-06
Iter: 174 loss: 2.67432847e-06
Iter: 175 loss: 2.67238306e-06
Iter: 176 loss: 2.65144899e-06
Iter: 177 loss: 2.73044157e-06
Iter: 178 loss: 2.64644541e-06
Iter: 179 loss: 2.63117681e-06
Iter: 180 loss: 2.63114953e-06
Iter: 181 loss: 2.61977175e-06
Iter: 182 loss: 2.60114211e-06
Iter: 183 loss: 2.60102775e-06
Iter: 184 loss: 2.58241016e-06
Iter: 185 loss: 2.76015089e-06
Iter: 186 loss: 2.58169871e-06
Iter: 187 loss: 2.56656631e-06
Iter: 188 loss: 2.65340304e-06
Iter: 189 loss: 2.56450721e-06
Iter: 190 loss: 2.55446412e-06
Iter: 191 loss: 2.54032511e-06
Iter: 192 loss: 2.53971075e-06
Iter: 193 loss: 2.52160044e-06
Iter: 194 loss: 2.65928975e-06
Iter: 195 loss: 2.52022801e-06
Iter: 196 loss: 2.50654784e-06
Iter: 197 loss: 2.56705698e-06
Iter: 198 loss: 2.50384574e-06
Iter: 199 loss: 2.49227674e-06
Iter: 200 loss: 2.50787025e-06
Iter: 201 loss: 2.48663355e-06
Iter: 202 loss: 2.47361936e-06
Iter: 203 loss: 2.5193458e-06
Iter: 204 loss: 2.47028493e-06
Iter: 205 loss: 2.45858723e-06
Iter: 206 loss: 2.51174083e-06
Iter: 207 loss: 2.45633782e-06
Iter: 208 loss: 2.44667331e-06
Iter: 209 loss: 2.44261446e-06
Iter: 210 loss: 2.43761724e-06
Iter: 211 loss: 2.425209e-06
Iter: 212 loss: 2.49290133e-06
Iter: 213 loss: 2.42341639e-06
Iter: 214 loss: 2.41175371e-06
Iter: 215 loss: 2.49652476e-06
Iter: 216 loss: 2.41079397e-06
Iter: 217 loss: 2.40299778e-06
Iter: 218 loss: 2.39853671e-06
Iter: 219 loss: 2.39519363e-06
Iter: 220 loss: 2.38525035e-06
Iter: 221 loss: 2.46263198e-06
Iter: 222 loss: 2.38462781e-06
Iter: 223 loss: 2.37327913e-06
Iter: 224 loss: 2.37536233e-06
Iter: 225 loss: 2.36484243e-06
Iter: 226 loss: 2.35521293e-06
Iter: 227 loss: 2.37801169e-06
Iter: 228 loss: 2.35175298e-06
Iter: 229 loss: 2.34207391e-06
Iter: 230 loss: 2.37917448e-06
Iter: 231 loss: 2.33968103e-06
Iter: 232 loss: 2.32845423e-06
Iter: 233 loss: 2.34705317e-06
Iter: 234 loss: 2.32340244e-06
Iter: 235 loss: 2.31360855e-06
Iter: 236 loss: 2.36322967e-06
Iter: 237 loss: 2.31189574e-06
Iter: 238 loss: 2.30363139e-06
Iter: 239 loss: 2.32170805e-06
Iter: 240 loss: 2.30048977e-06
Iter: 241 loss: 2.29052e-06
Iter: 242 loss: 2.30743103e-06
Iter: 243 loss: 2.28601425e-06
Iter: 244 loss: 2.27639271e-06
Iter: 245 loss: 2.29102102e-06
Iter: 246 loss: 2.27181044e-06
Iter: 247 loss: 2.26329621e-06
Iter: 248 loss: 2.33201354e-06
Iter: 249 loss: 2.26282282e-06
Iter: 250 loss: 2.25402664e-06
Iter: 251 loss: 2.26877773e-06
Iter: 252 loss: 2.25015583e-06
Iter: 253 loss: 2.24266978e-06
Iter: 254 loss: 2.24667929e-06
Iter: 255 loss: 2.23771349e-06
Iter: 256 loss: 2.23010966e-06
Iter: 257 loss: 2.33626793e-06
Iter: 258 loss: 2.23007987e-06
Iter: 259 loss: 2.22352924e-06
Iter: 260 loss: 2.2166746e-06
Iter: 261 loss: 2.21553955e-06
Iter: 262 loss: 2.20631591e-06
Iter: 263 loss: 2.22267386e-06
Iter: 264 loss: 2.20223592e-06
Iter: 265 loss: 2.19310641e-06
Iter: 266 loss: 2.28511476e-06
Iter: 267 loss: 2.19278627e-06
Iter: 268 loss: 2.1852486e-06
Iter: 269 loss: 2.1873484e-06
Iter: 270 loss: 2.17969909e-06
Iter: 271 loss: 2.17233082e-06
Iter: 272 loss: 2.23970301e-06
Iter: 273 loss: 2.17200659e-06
Iter: 274 loss: 2.1669839e-06
Iter: 275 loss: 2.17639536e-06
Iter: 276 loss: 2.16478338e-06
Iter: 277 loss: 2.15817772e-06
Iter: 278 loss: 2.1580704e-06
Iter: 279 loss: 2.15281443e-06
Iter: 280 loss: 2.14392799e-06
Iter: 281 loss: 2.17052e-06
Iter: 282 loss: 2.14118563e-06
Iter: 283 loss: 2.13502472e-06
Iter: 284 loss: 2.22483e-06
Iter: 285 loss: 2.13502585e-06
Iter: 286 loss: 2.12961186e-06
Iter: 287 loss: 2.1241608e-06
Iter: 288 loss: 2.12295072e-06
Iter: 289 loss: 2.11555289e-06
Iter: 290 loss: 2.15187174e-06
Iter: 291 loss: 2.11423367e-06
Iter: 292 loss: 2.10762801e-06
Iter: 293 loss: 2.16090393e-06
Iter: 294 loss: 2.10721282e-06
Iter: 295 loss: 2.10255052e-06
Iter: 296 loss: 2.09670088e-06
Iter: 297 loss: 2.09625159e-06
Iter: 298 loss: 2.08882307e-06
Iter: 299 loss: 2.11407541e-06
Iter: 300 loss: 2.08688266e-06
Iter: 301 loss: 2.08001939e-06
Iter: 302 loss: 2.14557599e-06
Iter: 303 loss: 2.0797911e-06
Iter: 304 loss: 2.07491166e-06
Iter: 305 loss: 2.07317726e-06
Iter: 306 loss: 2.07047606e-06
Iter: 307 loss: 2.06313962e-06
Iter: 308 loss: 2.1037531e-06
Iter: 309 loss: 2.06214736e-06
Iter: 310 loss: 2.05611536e-06
Iter: 311 loss: 2.07585026e-06
Iter: 312 loss: 2.05446349e-06
Iter: 313 loss: 2.04948287e-06
Iter: 314 loss: 2.05351012e-06
Iter: 315 loss: 2.04642265e-06
Iter: 316 loss: 2.03973696e-06
Iter: 317 loss: 2.05511151e-06
Iter: 318 loss: 2.03733134e-06
Iter: 319 loss: 2.03213858e-06
Iter: 320 loss: 2.03216177e-06
Iter: 321 loss: 2.02864157e-06
Iter: 322 loss: 2.02258525e-06
Iter: 323 loss: 2.02258843e-06
Iter: 324 loss: 2.01652483e-06
Iter: 325 loss: 2.08374445e-06
Iter: 326 loss: 2.01633952e-06
Iter: 327 loss: 2.01080434e-06
Iter: 328 loss: 2.02388742e-06
Iter: 329 loss: 2.00877503e-06
Iter: 330 loss: 2.00481622e-06
Iter: 331 loss: 2.00125396e-06
Iter: 332 loss: 2.00024033e-06
Iter: 333 loss: 1.99298984e-06
Iter: 334 loss: 2.02395495e-06
Iter: 335 loss: 1.99137412e-06
Iter: 336 loss: 1.98504404e-06
Iter: 337 loss: 2.03901936e-06
Iter: 338 loss: 1.98474299e-06
Iter: 339 loss: 1.98090697e-06
Iter: 340 loss: 1.9804595e-06
Iter: 341 loss: 1.97765257e-06
Iter: 342 loss: 1.97237068e-06
Iter: 343 loss: 2.00961017e-06
Iter: 344 loss: 1.97191594e-06
Iter: 345 loss: 1.9675108e-06
Iter: 346 loss: 1.97038594e-06
Iter: 347 loss: 1.96471638e-06
Iter: 348 loss: 1.95975053e-06
Iter: 349 loss: 1.97368081e-06
Iter: 350 loss: 1.95820894e-06
Iter: 351 loss: 1.95319626e-06
Iter: 352 loss: 1.9711722e-06
Iter: 353 loss: 1.95194798e-06
Iter: 354 loss: 1.94681888e-06
Iter: 355 loss: 1.97383588e-06
Iter: 356 loss: 1.9460349e-06
Iter: 357 loss: 1.9424831e-06
Iter: 358 loss: 1.93920187e-06
Iter: 359 loss: 1.93836968e-06
Iter: 360 loss: 1.93406322e-06
Iter: 361 loss: 1.93397204e-06
Iter: 362 loss: 1.930488e-06
Iter: 363 loss: 1.92756897e-06
Iter: 364 loss: 1.926501e-06
Iter: 365 loss: 1.92140647e-06
Iter: 366 loss: 1.92366451e-06
Iter: 367 loss: 1.91791401e-06
Iter: 368 loss: 1.91305776e-06
Iter: 369 loss: 1.98452585e-06
Iter: 370 loss: 1.91304252e-06
Iter: 371 loss: 1.90891524e-06
Iter: 372 loss: 1.91239769e-06
Iter: 373 loss: 1.90640174e-06
Iter: 374 loss: 1.90139417e-06
Iter: 375 loss: 1.90791502e-06
Iter: 376 loss: 1.89880518e-06
Iter: 377 loss: 1.89418108e-06
Iter: 378 loss: 1.95048142e-06
Iter: 379 loss: 1.89411139e-06
Iter: 380 loss: 1.89125751e-06
Iter: 381 loss: 1.88967488e-06
Iter: 382 loss: 1.8884175e-06
Iter: 383 loss: 1.8836696e-06
Iter: 384 loss: 1.89818149e-06
Iter: 385 loss: 1.88231e-06
Iter: 386 loss: 1.87843102e-06
Iter: 387 loss: 1.91709182e-06
Iter: 388 loss: 1.87832177e-06
Iter: 389 loss: 1.87523256e-06
Iter: 390 loss: 1.87714602e-06
Iter: 391 loss: 1.87325077e-06
Iter: 392 loss: 1.86964598e-06
Iter: 393 loss: 1.87259639e-06
Iter: 394 loss: 1.86745251e-06
Iter: 395 loss: 1.86334501e-06
Iter: 396 loss: 1.90817696e-06
Iter: 397 loss: 1.86323371e-06
Iter: 398 loss: 1.86001898e-06
Iter: 399 loss: 1.85513909e-06
Iter: 400 loss: 1.85506337e-06
Iter: 401 loss: 1.85014392e-06
Iter: 402 loss: 1.86595912e-06
Iter: 403 loss: 1.84861642e-06
Iter: 404 loss: 1.84384544e-06
Iter: 405 loss: 1.8854571e-06
Iter: 406 loss: 1.8435868e-06
Iter: 407 loss: 1.83923032e-06
Iter: 408 loss: 1.84439523e-06
Iter: 409 loss: 1.83706413e-06
Iter: 410 loss: 1.83357577e-06
Iter: 411 loss: 1.84805049e-06
Iter: 412 loss: 1.83292855e-06
Iter: 413 loss: 1.82923554e-06
Iter: 414 loss: 1.83717316e-06
Iter: 415 loss: 1.82783992e-06
Iter: 416 loss: 1.82389215e-06
Iter: 417 loss: 1.82620556e-06
Iter: 418 loss: 1.82138479e-06
Iter: 419 loss: 1.81740108e-06
Iter: 420 loss: 1.84574969e-06
Iter: 421 loss: 1.81710675e-06
Iter: 422 loss: 1.81328323e-06
Iter: 423 loss: 1.82279666e-06
Iter: 424 loss: 1.81194548e-06
Iter: 425 loss: 1.80777806e-06
Iter: 426 loss: 1.81270434e-06
Iter: 427 loss: 1.80560937e-06
Iter: 428 loss: 1.80232587e-06
Iter: 429 loss: 1.82234851e-06
Iter: 430 loss: 1.80193979e-06
Iter: 431 loss: 1.7986913e-06
Iter: 432 loss: 1.80736083e-06
Iter: 433 loss: 1.79760718e-06
Iter: 434 loss: 1.7946254e-06
Iter: 435 loss: 1.79164908e-06
Iter: 436 loss: 1.79100107e-06
Iter: 437 loss: 1.78719938e-06
Iter: 438 loss: 1.80954794e-06
Iter: 439 loss: 1.78665971e-06
Iter: 440 loss: 1.78339349e-06
Iter: 441 loss: 1.8076837e-06
Iter: 442 loss: 1.78317214e-06
Iter: 443 loss: 1.78004052e-06
Iter: 444 loss: 1.7785502e-06
Iter: 445 loss: 1.77698075e-06
Iter: 446 loss: 1.77294351e-06
Iter: 447 loss: 1.79362587e-06
Iter: 448 loss: 1.77236802e-06
Iter: 449 loss: 1.76838398e-06
Iter: 450 loss: 1.78118603e-06
Iter: 451 loss: 1.76722699e-06
Iter: 452 loss: 1.7643365e-06
Iter: 453 loss: 1.76842923e-06
Iter: 454 loss: 1.76292724e-06
Iter: 455 loss: 1.7599242e-06
Iter: 456 loss: 1.7786748e-06
Iter: 457 loss: 1.7596052e-06
Iter: 458 loss: 1.75652701e-06
Iter: 459 loss: 1.76008939e-06
Iter: 460 loss: 1.75486798e-06
Iter: 461 loss: 1.75176478e-06
Iter: 462 loss: 1.76147262e-06
Iter: 463 loss: 1.75095647e-06
Iter: 464 loss: 1.74836282e-06
Iter: 465 loss: 1.76022581e-06
Iter: 466 loss: 1.74782087e-06
Iter: 467 loss: 1.74473848e-06
Iter: 468 loss: 1.74430363e-06
Iter: 469 loss: 1.74208117e-06
Iter: 470 loss: 1.73833723e-06
Iter: 471 loss: 1.7400348e-06
Iter: 472 loss: 1.73568685e-06
Iter: 473 loss: 1.731976e-06
Iter: 474 loss: 1.75627861e-06
Iter: 475 loss: 1.73163096e-06
Iter: 476 loss: 1.72828095e-06
Iter: 477 loss: 1.74830961e-06
Iter: 478 loss: 1.72792193e-06
Iter: 479 loss: 1.72484033e-06
Iter: 480 loss: 1.72276009e-06
Iter: 481 loss: 1.7216471e-06
Iter: 482 loss: 1.71822569e-06
Iter: 483 loss: 1.75953483e-06
Iter: 484 loss: 1.71817101e-06
Iter: 485 loss: 1.71544889e-06
Iter: 486 loss: 1.71873307e-06
Iter: 487 loss: 1.71404793e-06
Iter: 488 loss: 1.710795e-06
Iter: 489 loss: 1.70985481e-06
Iter: 490 loss: 1.70793282e-06
Iter: 491 loss: 1.70531121e-06
Iter: 492 loss: 1.70505723e-06
Iter: 493 loss: 1.70335147e-06
Iter: 494 loss: 1.70327894e-06
Iter: 495 loss: 1.70189651e-06
Iter: 496 loss: 1.69937539e-06
Iter: 497 loss: 1.70233022e-06
Iter: 498 loss: 1.69800376e-06
Iter: 499 loss: 1.69462453e-06
Iter: 500 loss: 1.71006855e-06
Iter: 501 loss: 1.69402313e-06
Iter: 502 loss: 1.69098348e-06
Iter: 503 loss: 1.69539817e-06
Iter: 504 loss: 1.68954875e-06
Iter: 505 loss: 1.68716906e-06
Iter: 506 loss: 1.68532949e-06
Iter: 507 loss: 1.684567e-06
Iter: 508 loss: 1.68014776e-06
Iter: 509 loss: 1.69897066e-06
Iter: 510 loss: 1.67913322e-06
Iter: 511 loss: 1.67535393e-06
Iter: 512 loss: 1.71742681e-06
Iter: 513 loss: 1.6752349e-06
Iter: 514 loss: 1.67331314e-06
Iter: 515 loss: 1.67268831e-06
Iter: 516 loss: 1.67152905e-06
Iter: 517 loss: 1.66848258e-06
Iter: 518 loss: 1.68265251e-06
Iter: 519 loss: 1.6679046e-06
Iter: 520 loss: 1.66461803e-06
Iter: 521 loss: 1.66884547e-06
Iter: 522 loss: 1.66304244e-06
Iter: 523 loss: 1.6605768e-06
Iter: 524 loss: 1.67017595e-06
Iter: 525 loss: 1.66001814e-06
Iter: 526 loss: 1.65749543e-06
Iter: 527 loss: 1.67034489e-06
Iter: 528 loss: 1.65697043e-06
Iter: 529 loss: 1.65472591e-06
Iter: 530 loss: 1.65441065e-06
Iter: 531 loss: 1.65279926e-06
Iter: 532 loss: 1.65025904e-06
Iter: 533 loss: 1.67056226e-06
Iter: 534 loss: 1.65007782e-06
Iter: 535 loss: 1.64755374e-06
Iter: 536 loss: 1.65038409e-06
Iter: 537 loss: 1.64622111e-06
Iter: 538 loss: 1.64365383e-06
Iter: 539 loss: 1.64833887e-06
Iter: 540 loss: 1.64252515e-06
Iter: 541 loss: 1.64007e-06
Iter: 542 loss: 1.63925438e-06
Iter: 543 loss: 1.63783818e-06
Iter: 544 loss: 1.63484754e-06
Iter: 545 loss: 1.66872064e-06
Iter: 546 loss: 1.63481627e-06
Iter: 547 loss: 1.63202765e-06
Iter: 548 loss: 1.63913e-06
Iter: 549 loss: 1.63108257e-06
Iter: 550 loss: 1.6286458e-06
Iter: 551 loss: 1.62969786e-06
Iter: 552 loss: 1.62698234e-06
Iter: 553 loss: 1.62441711e-06
Iter: 554 loss: 1.65337769e-06
Iter: 555 loss: 1.62440585e-06
Iter: 556 loss: 1.62238666e-06
Iter: 557 loss: 1.62133301e-06
Iter: 558 loss: 1.62042852e-06
Iter: 559 loss: 1.61796265e-06
Iter: 560 loss: 1.63688446e-06
Iter: 561 loss: 1.61775665e-06
Iter: 562 loss: 1.61556511e-06
Iter: 563 loss: 1.62542449e-06
Iter: 564 loss: 1.61518233e-06
Iter: 565 loss: 1.61357718e-06
Iter: 566 loss: 1.61239052e-06
Iter: 567 loss: 1.6117408e-06
Iter: 568 loss: 1.60938168e-06
Iter: 569 loss: 1.63627817e-06
Iter: 570 loss: 1.60936111e-06
Iter: 571 loss: 1.60741331e-06
Iter: 572 loss: 1.60702882e-06
Iter: 573 loss: 1.6057428e-06
Iter: 574 loss: 1.60282457e-06
Iter: 575 loss: 1.60552406e-06
Iter: 576 loss: 1.60121374e-06
Iter: 577 loss: 1.59820775e-06
Iter: 578 loss: 1.60602235e-06
Iter: 579 loss: 1.59711897e-06
Iter: 580 loss: 1.59451747e-06
Iter: 581 loss: 1.61489618e-06
Iter: 582 loss: 1.59434978e-06
Iter: 583 loss: 1.59176852e-06
Iter: 584 loss: 1.59613842e-06
Iter: 585 loss: 1.59056833e-06
Iter: 586 loss: 1.58830926e-06
Iter: 587 loss: 1.59162289e-06
Iter: 588 loss: 1.58732314e-06
Iter: 589 loss: 1.58492935e-06
Iter: 590 loss: 1.60230911e-06
Iter: 591 loss: 1.58470584e-06
Iter: 592 loss: 1.58267562e-06
Iter: 593 loss: 1.58254193e-06
Iter: 594 loss: 1.58104581e-06
Iter: 595 loss: 1.57909017e-06
Iter: 596 loss: 1.59904312e-06
Iter: 597 loss: 1.57905788e-06
Iter: 598 loss: 1.57701538e-06
Iter: 599 loss: 1.57747809e-06
Iter: 600 loss: 1.57563738e-06
Iter: 601 loss: 1.57344357e-06
Iter: 602 loss: 1.57888849e-06
Iter: 603 loss: 1.57263162e-06
Iter: 604 loss: 1.57039642e-06
Iter: 605 loss: 1.58505804e-06
Iter: 606 loss: 1.57018076e-06
Iter: 607 loss: 1.56813735e-06
Iter: 608 loss: 1.56634405e-06
Iter: 609 loss: 1.56579245e-06
Iter: 610 loss: 1.56297654e-06
Iter: 611 loss: 1.57597287e-06
Iter: 612 loss: 1.56237752e-06
Iter: 613 loss: 1.5599594e-06
Iter: 614 loss: 1.56191891e-06
Iter: 615 loss: 1.55845896e-06
Iter: 616 loss: 1.55596138e-06
Iter: 617 loss: 1.58494663e-06
Iter: 618 loss: 1.55591408e-06
Iter: 619 loss: 1.55386886e-06
Iter: 620 loss: 1.55740031e-06
Iter: 621 loss: 1.55294708e-06
Iter: 622 loss: 1.55110433e-06
Iter: 623 loss: 1.55118437e-06
Iter: 624 loss: 1.54963493e-06
Iter: 625 loss: 1.54685426e-06
Iter: 626 loss: 1.56887472e-06
Iter: 627 loss: 1.54664576e-06
Iter: 628 loss: 1.5447855e-06
Iter: 629 loss: 1.54542636e-06
Iter: 630 loss: 1.54344082e-06
Iter: 631 loss: 1.54152258e-06
Iter: 632 loss: 1.56239344e-06
Iter: 633 loss: 1.541448e-06
Iter: 634 loss: 1.53964743e-06
Iter: 635 loss: 1.53936503e-06
Iter: 636 loss: 1.53808594e-06
Iter: 637 loss: 1.53587757e-06
Iter: 638 loss: 1.54134545e-06
Iter: 639 loss: 1.53513201e-06
Iter: 640 loss: 1.53258065e-06
Iter: 641 loss: 1.54813688e-06
Iter: 642 loss: 1.53227461e-06
Iter: 643 loss: 1.53055521e-06
Iter: 644 loss: 1.52904454e-06
Iter: 645 loss: 1.52856114e-06
Iter: 646 loss: 1.52594498e-06
Iter: 647 loss: 1.53681765e-06
Iter: 648 loss: 1.52535904e-06
Iter: 649 loss: 1.52289681e-06
Iter: 650 loss: 1.52809821e-06
Iter: 651 loss: 1.52191296e-06
Iter: 652 loss: 1.51965969e-06
Iter: 653 loss: 1.54027748e-06
Iter: 654 loss: 1.51958795e-06
Iter: 655 loss: 1.51754784e-06
Iter: 656 loss: 1.51825623e-06
Iter: 657 loss: 1.51617496e-06
Iter: 658 loss: 1.51419681e-06
Iter: 659 loss: 1.52013627e-06
Iter: 660 loss: 1.5136435e-06
Iter: 661 loss: 1.51136658e-06
Iter: 662 loss: 1.51970937e-06
Iter: 663 loss: 1.51084453e-06
Iter: 664 loss: 1.50872654e-06
Iter: 665 loss: 1.50931714e-06
Iter: 666 loss: 1.50722485e-06
Iter: 667 loss: 1.5056321e-06
Iter: 668 loss: 1.50559595e-06
Iter: 669 loss: 1.50431765e-06
Iter: 670 loss: 1.50243591e-06
Iter: 671 loss: 1.50238918e-06
Iter: 672 loss: 1.50010874e-06
Iter: 673 loss: 1.51291442e-06
Iter: 674 loss: 1.49973926e-06
Iter: 675 loss: 1.49755419e-06
Iter: 676 loss: 1.50944686e-06
Iter: 677 loss: 1.49717857e-06
Iter: 678 loss: 1.49578864e-06
Iter: 679 loss: 1.49408129e-06
Iter: 680 loss: 1.49394896e-06
Iter: 681 loss: 1.49151197e-06
Iter: 682 loss: 1.5025322e-06
Iter: 683 loss: 1.49108064e-06
Iter: 684 loss: 1.48900858e-06
Iter: 685 loss: 1.49838888e-06
Iter: 686 loss: 1.48866832e-06
Iter: 687 loss: 1.48679987e-06
Iter: 688 loss: 1.4946404e-06
Iter: 689 loss: 1.4863972e-06
Iter: 690 loss: 1.48441518e-06
Iter: 691 loss: 1.48534355e-06
Iter: 692 loss: 1.48298204e-06
Iter: 693 loss: 1.48104687e-06
Iter: 694 loss: 1.48796551e-06
Iter: 695 loss: 1.48057165e-06
Iter: 696 loss: 1.47863705e-06
Iter: 697 loss: 1.48925528e-06
Iter: 698 loss: 1.47841092e-06
Iter: 699 loss: 1.47666822e-06
Iter: 700 loss: 1.4759953e-06
Iter: 701 loss: 1.47512196e-06
Iter: 702 loss: 1.47372862e-06
Iter: 703 loss: 1.47365e-06
Iter: 704 loss: 1.47267394e-06
Iter: 705 loss: 1.47093044e-06
Iter: 706 loss: 1.51194081e-06
Iter: 707 loss: 1.47097239e-06
Iter: 708 loss: 1.46897355e-06
Iter: 709 loss: 1.48398567e-06
Iter: 710 loss: 1.46881575e-06
Iter: 711 loss: 1.46680509e-06
Iter: 712 loss: 1.47093215e-06
Iter: 713 loss: 1.46599768e-06
Iter: 714 loss: 1.46434991e-06
Iter: 715 loss: 1.46321736e-06
Iter: 716 loss: 1.46266348e-06
Iter: 717 loss: 1.46006437e-06
Iter: 718 loss: 1.46950549e-06
Iter: 719 loss: 1.45941112e-06
Iter: 720 loss: 1.45709328e-06
Iter: 721 loss: 1.47219805e-06
Iter: 722 loss: 1.45682657e-06
Iter: 723 loss: 1.45504714e-06
Iter: 724 loss: 1.46383923e-06
Iter: 725 loss: 1.45467732e-06
Iter: 726 loss: 1.45309946e-06
Iter: 727 loss: 1.45421609e-06
Iter: 728 loss: 1.45203057e-06
Iter: 729 loss: 1.45034551e-06
Iter: 730 loss: 1.45450952e-06
Iter: 731 loss: 1.44967726e-06
Iter: 732 loss: 1.4476783e-06
Iter: 733 loss: 1.45898366e-06
Iter: 734 loss: 1.44740579e-06
Iter: 735 loss: 1.44595e-06
Iter: 736 loss: 1.44720411e-06
Iter: 737 loss: 1.44512717e-06
Iter: 738 loss: 1.44355545e-06
Iter: 739 loss: 1.45939339e-06
Iter: 740 loss: 1.44345677e-06
Iter: 741 loss: 1.44220735e-06
Iter: 742 loss: 1.44010505e-06
Iter: 743 loss: 1.44008652e-06
Iter: 744 loss: 1.43844454e-06
Iter: 745 loss: 1.43841953e-06
Iter: 746 loss: 1.43697787e-06
Iter: 747 loss: 1.43703915e-06
Iter: 748 loss: 1.43574982e-06
Iter: 749 loss: 1.4340776e-06
Iter: 750 loss: 1.43455532e-06
Iter: 751 loss: 1.43293948e-06
Iter: 752 loss: 1.4307625e-06
Iter: 753 loss: 1.43663488e-06
Iter: 754 loss: 1.43013358e-06
Iter: 755 loss: 1.42807551e-06
Iter: 756 loss: 1.44604621e-06
Iter: 757 loss: 1.42792703e-06
Iter: 758 loss: 1.42634394e-06
Iter: 759 loss: 1.43093291e-06
Iter: 760 loss: 1.42583497e-06
Iter: 761 loss: 1.42426575e-06
Iter: 762 loss: 1.42564079e-06
Iter: 763 loss: 1.4233749e-06
Iter: 764 loss: 1.4215334e-06
Iter: 765 loss: 1.42656882e-06
Iter: 766 loss: 1.42093484e-06
Iter: 767 loss: 1.41916007e-06
Iter: 768 loss: 1.43181887e-06
Iter: 769 loss: 1.41908333e-06
Iter: 770 loss: 1.41771034e-06
Iter: 771 loss: 1.41739849e-06
Iter: 772 loss: 1.41654675e-06
Iter: 773 loss: 1.4146317e-06
Iter: 774 loss: 1.43308375e-06
Iter: 775 loss: 1.41454234e-06
Iter: 776 loss: 1.41331839e-06
Iter: 777 loss: 1.41240275e-06
Iter: 778 loss: 1.41199473e-06
Iter: 779 loss: 1.41041414e-06
Iter: 780 loss: 1.42563636e-06
Iter: 781 loss: 1.41032854e-06
Iter: 782 loss: 1.40871964e-06
Iter: 783 loss: 1.40888767e-06
Iter: 784 loss: 1.40749978e-06
Iter: 785 loss: 1.40588213e-06
Iter: 786 loss: 1.4069592e-06
Iter: 787 loss: 1.40486759e-06
Iter: 788 loss: 1.40284601e-06
Iter: 789 loss: 1.40671784e-06
Iter: 790 loss: 1.40200132e-06
Iter: 791 loss: 1.40046552e-06
Iter: 792 loss: 1.40045074e-06
Iter: 793 loss: 1.39911026e-06
Iter: 794 loss: 1.39876784e-06
Iter: 795 loss: 1.39790779e-06
Iter: 796 loss: 1.3959642e-06
Iter: 797 loss: 1.40236511e-06
Iter: 798 loss: 1.3954234e-06
Iter: 799 loss: 1.3939266e-06
Iter: 800 loss: 1.39988686e-06
Iter: 801 loss: 1.39358929e-06
Iter: 802 loss: 1.39204883e-06
Iter: 803 loss: 1.39841927e-06
Iter: 804 loss: 1.39171789e-06
Iter: 805 loss: 1.39046256e-06
Iter: 806 loss: 1.39200392e-06
Iter: 807 loss: 1.38972155e-06
Iter: 808 loss: 1.3883141e-06
Iter: 809 loss: 1.39914687e-06
Iter: 810 loss: 1.38824623e-06
Iter: 811 loss: 1.38707401e-06
Iter: 812 loss: 1.38558732e-06
Iter: 813 loss: 1.38546557e-06
Iter: 814 loss: 1.3839624e-06
Iter: 815 loss: 1.40563418e-06
Iter: 816 loss: 1.38400696e-06
Iter: 817 loss: 1.38258429e-06
Iter: 818 loss: 1.38290011e-06
Iter: 819 loss: 1.38155849e-06
Iter: 820 loss: 1.38015e-06
Iter: 821 loss: 1.3788308e-06
Iter: 822 loss: 1.37840038e-06
Iter: 823 loss: 1.37637733e-06
Iter: 824 loss: 1.39198869e-06
Iter: 825 loss: 1.37620395e-06
Iter: 826 loss: 1.37470158e-06
Iter: 827 loss: 1.384391e-06
Iter: 828 loss: 1.374509e-06
Iter: 829 loss: 1.37295e-06
Iter: 830 loss: 1.37585653e-06
Iter: 831 loss: 1.37228676e-06
Iter: 832 loss: 1.37093559e-06
Iter: 833 loss: 1.37348923e-06
Iter: 834 loss: 1.3703044e-06
Iter: 835 loss: 1.36893925e-06
Iter: 836 loss: 1.37538018e-06
Iter: 837 loss: 1.36865651e-06
Iter: 838 loss: 1.36728079e-06
Iter: 839 loss: 1.36949006e-06
Iter: 840 loss: 1.3666031e-06
Iter: 841 loss: 1.36493804e-06
Iter: 842 loss: 1.37048187e-06
Iter: 843 loss: 1.3645498e-06
Iter: 844 loss: 1.36317112e-06
Iter: 845 loss: 1.37115057e-06
Iter: 846 loss: 1.36305209e-06
Iter: 847 loss: 1.36188339e-06
Iter: 848 loss: 1.36046356e-06
Iter: 849 loss: 1.36032941e-06
Iter: 850 loss: 1.35862706e-06
Iter: 851 loss: 1.37888867e-06
Iter: 852 loss: 1.35860626e-06
Iter: 853 loss: 1.35702055e-06
Iter: 854 loss: 1.35789412e-06
Iter: 855 loss: 1.35600044e-06
Iter: 856 loss: 1.35481707e-06
Iter: 857 loss: 1.35522134e-06
Iter: 858 loss: 1.35391076e-06
Iter: 859 loss: 1.35209541e-06
Iter: 860 loss: 1.35246262e-06
Iter: 861 loss: 1.35069308e-06
Iter: 862 loss: 1.34951085e-06
Iter: 863 loss: 1.34931679e-06
Iter: 864 loss: 1.34823824e-06
Iter: 865 loss: 1.34887534e-06
Iter: 866 loss: 1.34758807e-06
Iter: 867 loss: 1.34617926e-06
Iter: 868 loss: 1.34595723e-06
Iter: 869 loss: 1.34499885e-06
Iter: 870 loss: 1.34328366e-06
Iter: 871 loss: 1.36243898e-06
Iter: 872 loss: 1.34321976e-06
Iter: 873 loss: 1.34202264e-06
Iter: 874 loss: 1.34475113e-06
Iter: 875 loss: 1.34156903e-06
Iter: 876 loss: 1.34017569e-06
Iter: 877 loss: 1.34169215e-06
Iter: 878 loss: 1.33940853e-06
Iter: 879 loss: 1.33747039e-06
Iter: 880 loss: 1.34453353e-06
Iter: 881 loss: 1.33706021e-06
Iter: 882 loss: 1.33566766e-06
Iter: 883 loss: 1.33899539e-06
Iter: 884 loss: 1.33514743e-06
Iter: 885 loss: 1.33409162e-06
Iter: 886 loss: 1.34003267e-06
Iter: 887 loss: 1.33390654e-06
Iter: 888 loss: 1.33265962e-06
Iter: 889 loss: 1.33239723e-06
Iter: 890 loss: 1.33159256e-06
Iter: 891 loss: 1.33000367e-06
Iter: 892 loss: 1.33094386e-06
Iter: 893 loss: 1.32897321e-06
Iter: 894 loss: 1.32711887e-06
Iter: 895 loss: 1.32885157e-06
Iter: 896 loss: 1.32605294e-06
Iter: 897 loss: 1.32426339e-06
Iter: 898 loss: 1.35025175e-06
Iter: 899 loss: 1.32421064e-06
Iter: 900 loss: 1.32268565e-06
Iter: 901 loss: 1.32869172e-06
Iter: 902 loss: 1.3223522e-06
Iter: 903 loss: 1.32125945e-06
Iter: 904 loss: 1.3203196e-06
Iter: 905 loss: 1.32000514e-06
Iter: 906 loss: 1.31823185e-06
Iter: 907 loss: 1.33389653e-06
Iter: 908 loss: 1.31814625e-06
Iter: 909 loss: 1.31673255e-06
Iter: 910 loss: 1.3209916e-06
Iter: 911 loss: 1.31626871e-06
Iter: 912 loss: 1.31502907e-06
Iter: 913 loss: 1.31808758e-06
Iter: 914 loss: 1.31457477e-06
Iter: 915 loss: 1.31311197e-06
Iter: 916 loss: 1.3171275e-06
Iter: 917 loss: 1.31266302e-06
Iter: 918 loss: 1.3115083e-06
Iter: 919 loss: 1.31381444e-06
Iter: 920 loss: 1.31097556e-06
Iter: 921 loss: 1.30962462e-06
Iter: 922 loss: 1.31375543e-06
Iter: 923 loss: 1.30923536e-06
Iter: 924 loss: 1.30776402e-06
Iter: 925 loss: 1.31325737e-06
Iter: 926 loss: 1.30742342e-06
Iter: 927 loss: 1.3064755e-06
Iter: 928 loss: 1.30501394e-06
Iter: 929 loss: 1.30495323e-06
Iter: 930 loss: 1.30314129e-06
Iter: 931 loss: 1.31164211e-06
Iter: 932 loss: 1.30279273e-06
Iter: 933 loss: 1.30123294e-06
Iter: 934 loss: 1.30527837e-06
Iter: 935 loss: 1.30067224e-06
Iter: 936 loss: 1.2992374e-06
Iter: 937 loss: 1.32159994e-06
Iter: 938 loss: 1.29927946e-06
Iter: 939 loss: 1.29833143e-06
Iter: 940 loss: 1.29721957e-06
Iter: 941 loss: 1.29708428e-06
Iter: 942 loss: 1.29558987e-06
Iter: 943 loss: 1.30362332e-06
Iter: 944 loss: 1.29540513e-06
Iter: 945 loss: 1.29407294e-06
Iter: 946 loss: 1.30294472e-06
Iter: 947 loss: 1.29391651e-06
Iter: 948 loss: 1.29284422e-06
Iter: 949 loss: 1.29364093e-06
Iter: 950 loss: 1.292251e-06
Iter: 951 loss: 1.29098612e-06
Iter: 952 loss: 1.29785315e-06
Iter: 953 loss: 1.29074715e-06
Iter: 954 loss: 1.28987938e-06
Iter: 955 loss: 1.29069008e-06
Iter: 956 loss: 1.28926729e-06
Iter: 957 loss: 1.28814122e-06
Iter: 958 loss: 1.29216983e-06
Iter: 959 loss: 1.28787599e-06
Iter: 960 loss: 1.28654358e-06
Iter: 961 loss: 1.28824536e-06
Iter: 962 loss: 1.28578915e-06
Iter: 963 loss: 1.28443867e-06
Iter: 964 loss: 1.28698787e-06
Iter: 965 loss: 1.28379111e-06
Iter: 966 loss: 1.28251975e-06
Iter: 967 loss: 1.28196621e-06
Iter: 968 loss: 1.28126203e-06
Iter: 969 loss: 1.27941053e-06
Iter: 970 loss: 1.28603233e-06
Iter: 971 loss: 1.27889825e-06
Iter: 972 loss: 1.27766407e-06
Iter: 973 loss: 1.27762905e-06
Iter: 974 loss: 1.27654357e-06
Iter: 975 loss: 1.27747933e-06
Iter: 976 loss: 1.27586532e-06
Iter: 977 loss: 1.27465887e-06
Iter: 978 loss: 1.27381e-06
Iter: 979 loss: 1.27340741e-06
Iter: 980 loss: 1.2719139e-06
Iter: 981 loss: 1.27190094e-06
Iter: 982 loss: 1.27069245e-06
Iter: 983 loss: 1.27211251e-06
Iter: 984 loss: 1.27011742e-06
Iter: 985 loss: 1.26913653e-06
Iter: 986 loss: 1.27544843e-06
Iter: 987 loss: 1.26899204e-06
Iter: 988 loss: 1.26807652e-06
Iter: 989 loss: 1.26748137e-06
Iter: 990 loss: 1.26710245e-06
Iter: 991 loss: 1.26564714e-06
Iter: 992 loss: 1.27192311e-06
Iter: 993 loss: 1.26537589e-06
Iter: 994 loss: 1.26408008e-06
Iter: 995 loss: 1.2714379e-06
Iter: 996 loss: 1.26387738e-06
Iter: 997 loss: 1.26297198e-06
Iter: 998 loss: 1.2629456e-06
Iter: 999 loss: 1.2622105e-06
Iter: 1000 loss: 1.26069608e-06
Iter: 1001 loss: 1.26096643e-06
Iter: 1002 loss: 1.25961674e-06
Iter: 1003 loss: 1.25761096e-06
Iter: 1004 loss: 1.26323187e-06
Iter: 1005 loss: 1.257039e-06
Iter: 1006 loss: 1.25553356e-06
Iter: 1007 loss: 1.26258647e-06
Iter: 1008 loss: 1.25526276e-06
Iter: 1009 loss: 1.25394808e-06
Iter: 1010 loss: 1.26777468e-06
Iter: 1011 loss: 1.25391671e-06
Iter: 1012 loss: 1.25284873e-06
Iter: 1013 loss: 1.25141833e-06
Iter: 1014 loss: 1.25132192e-06
Iter: 1015 loss: 1.25010695e-06
Iter: 1016 loss: 1.26375153e-06
Iter: 1017 loss: 1.25006727e-06
Iter: 1018 loss: 1.24889073e-06
Iter: 1019 loss: 1.25391216e-06
Iter: 1020 loss: 1.24868461e-06
Iter: 1021 loss: 1.24778103e-06
Iter: 1022 loss: 1.24818848e-06
Iter: 1023 loss: 1.24719872e-06
Iter: 1024 loss: 1.24591224e-06
Iter: 1025 loss: 1.25208112e-06
Iter: 1026 loss: 1.24567839e-06
Iter: 1027 loss: 1.24468011e-06
Iter: 1028 loss: 1.2449965e-06
Iter: 1029 loss: 1.24393819e-06
Iter: 1030 loss: 1.24280348e-06
Iter: 1031 loss: 1.25527379e-06
Iter: 1032 loss: 1.2427862e-06
Iter: 1033 loss: 1.24204939e-06
Iter: 1034 loss: 1.24180588e-06
Iter: 1035 loss: 1.2413351e-06
Iter: 1036 loss: 1.24008261e-06
Iter: 1037 loss: 1.24084386e-06
Iter: 1038 loss: 1.23931136e-06
Iter: 1039 loss: 1.23781274e-06
Iter: 1040 loss: 1.24311782e-06
Iter: 1041 loss: 1.23740858e-06
Iter: 1042 loss: 1.2360922e-06
Iter: 1043 loss: 1.2362683e-06
Iter: 1044 loss: 1.2351303e-06
Iter: 1045 loss: 1.23363247e-06
Iter: 1046 loss: 1.25320014e-06
Iter: 1047 loss: 1.23363043e-06
Iter: 1048 loss: 1.23236475e-06
Iter: 1049 loss: 1.23781365e-06
Iter: 1050 loss: 1.23212942e-06
Iter: 1051 loss: 1.2312687e-06
Iter: 1052 loss: 1.23047062e-06
Iter: 1053 loss: 1.2302803e-06
Iter: 1054 loss: 1.2290966e-06
Iter: 1055 loss: 1.24235953e-06
Iter: 1056 loss: 1.22902804e-06
Iter: 1057 loss: 1.22782615e-06
Iter: 1058 loss: 1.22992265e-06
Iter: 1059 loss: 1.22731115e-06
Iter: 1060 loss: 1.22646657e-06
Iter: 1061 loss: 1.2287137e-06
Iter: 1062 loss: 1.22615518e-06
Iter: 1063 loss: 1.22507481e-06
Iter: 1064 loss: 1.22664926e-06
Iter: 1065 loss: 1.22452616e-06
Iter: 1066 loss: 1.22346933e-06
Iter: 1067 loss: 1.2268282e-06
Iter: 1068 loss: 1.22318511e-06
Iter: 1069 loss: 1.22219012e-06
Iter: 1070 loss: 1.22740266e-06
Iter: 1071 loss: 1.22199413e-06
Iter: 1072 loss: 1.22111942e-06
Iter: 1073 loss: 1.2202679e-06
Iter: 1074 loss: 1.22008919e-06
Iter: 1075 loss: 1.21878236e-06
Iter: 1076 loss: 1.22508322e-06
Iter: 1077 loss: 1.21853373e-06
Iter: 1078 loss: 1.21725543e-06
Iter: 1079 loss: 1.21809069e-06
Iter: 1080 loss: 1.21643234e-06
Iter: 1081 loss: 1.21490552e-06
Iter: 1082 loss: 1.22030019e-06
Iter: 1083 loss: 1.21452445e-06
Iter: 1084 loss: 1.21350149e-06
Iter: 1085 loss: 1.22406027e-06
Iter: 1086 loss: 1.21344397e-06
Iter: 1087 loss: 1.21229596e-06
Iter: 1088 loss: 1.21309472e-06
Iter: 1089 loss: 1.211582e-06
Iter: 1090 loss: 1.21053597e-06
Iter: 1091 loss: 1.21087214e-06
Iter: 1092 loss: 1.20979655e-06
Iter: 1093 loss: 1.20885807e-06
Iter: 1094 loss: 1.20882623e-06
Iter: 1095 loss: 1.20801019e-06
Iter: 1096 loss: 1.20717573e-06
Iter: 1097 loss: 1.20706591e-06
Iter: 1098 loss: 1.20593836e-06
Iter: 1099 loss: 1.2156321e-06
Iter: 1100 loss: 1.20591039e-06
Iter: 1101 loss: 1.20490972e-06
Iter: 1102 loss: 1.20600362e-06
Iter: 1103 loss: 1.20437608e-06
Iter: 1104 loss: 1.20343748e-06
Iter: 1105 loss: 1.20611162e-06
Iter: 1106 loss: 1.20312666e-06
Iter: 1107 loss: 1.20186814e-06
Iter: 1108 loss: 1.20383879e-06
Iter: 1109 loss: 1.20133063e-06
Iter: 1110 loss: 1.20019649e-06
Iter: 1111 loss: 1.20150048e-06
Iter: 1112 loss: 1.1995827e-06
Iter: 1113 loss: 1.19844776e-06
Iter: 1114 loss: 1.20091067e-06
Iter: 1115 loss: 1.19804167e-06
Iter: 1116 loss: 1.1965476e-06
Iter: 1117 loss: 1.19811125e-06
Iter: 1118 loss: 1.1957469e-06
Iter: 1119 loss: 1.19453807e-06
Iter: 1120 loss: 1.2052036e-06
Iter: 1121 loss: 1.1944785e-06
Iter: 1122 loss: 1.19363654e-06
Iter: 1123 loss: 1.19995036e-06
Iter: 1124 loss: 1.19359481e-06
Iter: 1125 loss: 1.19266565e-06
Iter: 1126 loss: 1.19118272e-06
Iter: 1127 loss: 1.19118181e-06
Iter: 1128 loss: 1.18989965e-06
Iter: 1129 loss: 1.2022183e-06
Iter: 1130 loss: 1.18985986e-06
Iter: 1131 loss: 1.18885055e-06
Iter: 1132 loss: 1.1977055e-06
Iter: 1133 loss: 1.18880143e-06
Iter: 1134 loss: 1.18813489e-06
Iter: 1135 loss: 1.18690139e-06
Iter: 1136 loss: 1.21570338e-06
Iter: 1137 loss: 1.18689547e-06
Iter: 1138 loss: 1.18581102e-06
Iter: 1139 loss: 1.1857976e-06
Iter: 1140 loss: 1.18515732e-06
Iter: 1141 loss: 1.18480148e-06
Iter: 1142 loss: 1.18449202e-06
Iter: 1143 loss: 1.18348885e-06
Iter: 1144 loss: 1.18920809e-06
Iter: 1145 loss: 1.18333196e-06
Iter: 1146 loss: 1.18233743e-06
Iter: 1147 loss: 1.18256958e-06
Iter: 1148 loss: 1.18164098e-06
Iter: 1149 loss: 1.1807133e-06
Iter: 1150 loss: 1.18212961e-06
Iter: 1151 loss: 1.18026173e-06
Iter: 1152 loss: 1.17904142e-06
Iter: 1153 loss: 1.18159664e-06
Iter: 1154 loss: 1.17856507e-06
Iter: 1155 loss: 1.17728734e-06
Iter: 1156 loss: 1.18110142e-06
Iter: 1157 loss: 1.17685704e-06
Iter: 1158 loss: 1.1757329e-06
Iter: 1159 loss: 1.18124808e-06
Iter: 1160 loss: 1.17555476e-06
Iter: 1161 loss: 1.17448531e-06
Iter: 1162 loss: 1.18184607e-06
Iter: 1163 loss: 1.17441891e-06
Iter: 1164 loss: 1.17358752e-06
Iter: 1165 loss: 1.17239188e-06
Iter: 1166 loss: 1.17235356e-06
Iter: 1167 loss: 1.1713239e-06
Iter: 1168 loss: 1.1875768e-06
Iter: 1169 loss: 1.17133482e-06
Iter: 1170 loss: 1.17032323e-06
Iter: 1171 loss: 1.17164359e-06
Iter: 1172 loss: 1.16982096e-06
Iter: 1173 loss: 1.16882143e-06
Iter: 1174 loss: 1.16894648e-06
Iter: 1175 loss: 1.16807041e-06
Iter: 1176 loss: 1.16708247e-06
Iter: 1177 loss: 1.16705155e-06
Iter: 1178 loss: 1.16651199e-06
Iter: 1179 loss: 1.16613626e-06
Iter: 1180 loss: 1.16587205e-06
Iter: 1181 loss: 1.16493561e-06
Iter: 1182 loss: 1.17033642e-06
Iter: 1183 loss: 1.16482602e-06
Iter: 1184 loss: 1.16391959e-06
Iter: 1185 loss: 1.16342449e-06
Iter: 1186 loss: 1.16309025e-06
Iter: 1187 loss: 1.16194929e-06
Iter: 1188 loss: 1.16490548e-06
Iter: 1189 loss: 1.16157491e-06
Iter: 1190 loss: 1.16044782e-06
Iter: 1191 loss: 1.16426452e-06
Iter: 1192 loss: 1.16015792e-06
Iter: 1193 loss: 1.15905061e-06
Iter: 1194 loss: 1.161049e-06
Iter: 1195 loss: 1.15859132e-06
Iter: 1196 loss: 1.15751561e-06
Iter: 1197 loss: 1.16498779e-06
Iter: 1198 loss: 1.15747321e-06
Iter: 1199 loss: 1.15641501e-06
Iter: 1200 loss: 1.16005185e-06
Iter: 1201 loss: 1.15617229e-06
Iter: 1202 loss: 1.15535977e-06
Iter: 1203 loss: 1.15485489e-06
Iter: 1204 loss: 1.15450212e-06
Iter: 1205 loss: 1.15374064e-06
Iter: 1206 loss: 1.15371631e-06
Iter: 1207 loss: 1.15304556e-06
Iter: 1208 loss: 1.15228386e-06
Iter: 1209 loss: 1.15214334e-06
Iter: 1210 loss: 1.15120758e-06
Iter: 1211 loss: 1.15524313e-06
Iter: 1212 loss: 1.15099624e-06
Iter: 1213 loss: 1.14995487e-06
Iter: 1214 loss: 1.15392447e-06
Iter: 1215 loss: 1.14972522e-06
Iter: 1216 loss: 1.14891168e-06
Iter: 1217 loss: 1.14990144e-06
Iter: 1218 loss: 1.14850184e-06
Iter: 1219 loss: 1.14761656e-06
Iter: 1220 loss: 1.1524271e-06
Iter: 1221 loss: 1.14747536e-06
Iter: 1222 loss: 1.14663351e-06
Iter: 1223 loss: 1.1454606e-06
Iter: 1224 loss: 1.1454224e-06
Iter: 1225 loss: 1.1441681e-06
Iter: 1226 loss: 1.150966e-06
Iter: 1227 loss: 1.14394072e-06
Iter: 1228 loss: 1.14290162e-06
Iter: 1229 loss: 1.14543786e-06
Iter: 1230 loss: 1.14250383e-06
Iter: 1231 loss: 1.14137515e-06
Iter: 1232 loss: 1.14690454e-06
Iter: 1233 loss: 1.14118666e-06
Iter: 1234 loss: 1.14036675e-06
Iter: 1235 loss: 1.14481463e-06
Iter: 1236 loss: 1.1402476e-06
Iter: 1237 loss: 1.13933106e-06
Iter: 1238 loss: 1.14067291e-06
Iter: 1239 loss: 1.13886597e-06
Iter: 1240 loss: 1.13794385e-06
Iter: 1241 loss: 1.13867509e-06
Iter: 1242 loss: 1.1374e-06
Iter: 1243 loss: 1.13676219e-06
Iter: 1244 loss: 1.13674025e-06
Iter: 1245 loss: 1.13617591e-06
Iter: 1246 loss: 1.13508645e-06
Iter: 1247 loss: 1.15595287e-06
Iter: 1248 loss: 1.13505598e-06
Iter: 1249 loss: 1.13425313e-06
Iter: 1250 loss: 1.14364207e-06
Iter: 1251 loss: 1.13422652e-06
Iter: 1252 loss: 1.13343333e-06
Iter: 1253 loss: 1.1357763e-06
Iter: 1254 loss: 1.13319243e-06
Iter: 1255 loss: 1.13247313e-06
Iter: 1256 loss: 1.13223393e-06
Iter: 1257 loss: 1.13179567e-06
Iter: 1258 loss: 1.13063982e-06
Iter: 1259 loss: 1.13859517e-06
Iter: 1260 loss: 1.13056626e-06
Iter: 1261 loss: 1.12967621e-06
Iter: 1262 loss: 1.12995338e-06
Iter: 1263 loss: 1.12902524e-06
Iter: 1264 loss: 1.12816781e-06
Iter: 1265 loss: 1.12923499e-06
Iter: 1266 loss: 1.12771022e-06
Iter: 1267 loss: 1.1266128e-06
Iter: 1268 loss: 1.13011811e-06
Iter: 1269 loss: 1.1263071e-06
Iter: 1270 loss: 1.12529699e-06
Iter: 1271 loss: 1.13240537e-06
Iter: 1272 loss: 1.12522662e-06
Iter: 1273 loss: 1.12448174e-06
Iter: 1274 loss: 1.12821954e-06
Iter: 1275 loss: 1.124341e-06
Iter: 1276 loss: 1.12351563e-06
Iter: 1277 loss: 1.12334328e-06
Iter: 1278 loss: 1.12283328e-06
Iter: 1279 loss: 1.12185739e-06
Iter: 1280 loss: 1.12664088e-06
Iter: 1281 loss: 1.1217013e-06
Iter: 1282 loss: 1.12085627e-06
Iter: 1283 loss: 1.1277059e-06
Iter: 1284 loss: 1.1208308e-06
Iter: 1285 loss: 1.12027465e-06
Iter: 1286 loss: 1.11926647e-06
Iter: 1287 loss: 1.13961812e-06
Iter: 1288 loss: 1.11923191e-06
Iter: 1289 loss: 1.1185266e-06
Iter: 1290 loss: 1.11852205e-06
Iter: 1291 loss: 1.11783345e-06
Iter: 1292 loss: 1.11748045e-06
Iter: 1293 loss: 1.11716747e-06
Iter: 1294 loss: 1.11630743e-06
Iter: 1295 loss: 1.11900852e-06
Iter: 1296 loss: 1.11606437e-06
Iter: 1297 loss: 1.11509144e-06
Iter: 1298 loss: 1.12023463e-06
Iter: 1299 loss: 1.11495478e-06
Iter: 1300 loss: 1.1142638e-06
Iter: 1301 loss: 1.11315148e-06
Iter: 1302 loss: 1.11313523e-06
Iter: 1303 loss: 1.11193231e-06
Iter: 1304 loss: 1.12196858e-06
Iter: 1305 loss: 1.11186785e-06
Iter: 1306 loss: 1.11106215e-06
Iter: 1307 loss: 1.1136292e-06
Iter: 1308 loss: 1.1108109e-06
Iter: 1309 loss: 1.10987162e-06
Iter: 1310 loss: 1.113591e-06
Iter: 1311 loss: 1.10964868e-06
Iter: 1312 loss: 1.10873532e-06
Iter: 1313 loss: 1.11210329e-06
Iter: 1314 loss: 1.10851875e-06
Iter: 1315 loss: 1.10785595e-06
Iter: 1316 loss: 1.10895826e-06
Iter: 1317 loss: 1.10753672e-06
Iter: 1318 loss: 1.10688927e-06
Iter: 1319 loss: 1.11144459e-06
Iter: 1320 loss: 1.10679184e-06
Iter: 1321 loss: 1.10607743e-06
Iter: 1322 loss: 1.10573114e-06
Iter: 1323 loss: 1.10540361e-06
Iter: 1324 loss: 1.10457609e-06
Iter: 1325 loss: 1.10582698e-06
Iter: 1326 loss: 1.10415976e-06
Iter: 1327 loss: 1.10327426e-06
Iter: 1328 loss: 1.11369616e-06
Iter: 1329 loss: 1.10325504e-06
Iter: 1330 loss: 1.10272777e-06
Iter: 1331 loss: 1.10192093e-06
Iter: 1332 loss: 1.10188023e-06
Iter: 1333 loss: 1.10118322e-06
Iter: 1334 loss: 1.11315512e-06
Iter: 1335 loss: 1.10114672e-06
Iter: 1336 loss: 1.10050394e-06
Iter: 1337 loss: 1.10020267e-06
Iter: 1338 loss: 1.09991583e-06
Iter: 1339 loss: 1.09901953e-06
Iter: 1340 loss: 1.09960308e-06
Iter: 1341 loss: 1.09845541e-06
Iter: 1342 loss: 1.09747907e-06
Iter: 1343 loss: 1.10250471e-06
Iter: 1344 loss: 1.0973464e-06
Iter: 1345 loss: 1.09647874e-06
Iter: 1346 loss: 1.10102019e-06
Iter: 1347 loss: 1.09635744e-06
Iter: 1348 loss: 1.09547182e-06
Iter: 1349 loss: 1.09830989e-06
Iter: 1350 loss: 1.09520477e-06
Iter: 1351 loss: 1.09448604e-06
Iter: 1352 loss: 1.09625421e-06
Iter: 1353 loss: 1.09425241e-06
Iter: 1354 loss: 1.09359007e-06
Iter: 1355 loss: 1.09558732e-06
Iter: 1356 loss: 1.09339089e-06
Iter: 1357 loss: 1.09257667e-06
Iter: 1358 loss: 1.09382677e-06
Iter: 1359 loss: 1.09209259e-06
Iter: 1360 loss: 1.09125585e-06
Iter: 1361 loss: 1.09140115e-06
Iter: 1362 loss: 1.09062807e-06
Iter: 1363 loss: 1.08992799e-06
Iter: 1364 loss: 1.08991821e-06
Iter: 1365 loss: 1.08930146e-06
Iter: 1366 loss: 1.08946699e-06
Iter: 1367 loss: 1.0888466e-06
Iter: 1368 loss: 1.08822326e-06
Iter: 1369 loss: 1.08897041e-06
Iter: 1370 loss: 1.08793938e-06
Iter: 1371 loss: 1.08715494e-06
Iter: 1372 loss: 1.09232121e-06
Iter: 1373 loss: 1.08703375e-06
Iter: 1374 loss: 1.08638778e-06
Iter: 1375 loss: 1.08567656e-06
Iter: 1376 loss: 1.08563518e-06
Iter: 1377 loss: 1.08465099e-06
Iter: 1378 loss: 1.0881671e-06
Iter: 1379 loss: 1.08446147e-06
Iter: 1380 loss: 1.08350991e-06
Iter: 1381 loss: 1.08655979e-06
Iter: 1382 loss: 1.0832041e-06
Iter: 1383 loss: 1.08217569e-06
Iter: 1384 loss: 1.08915287e-06
Iter: 1385 loss: 1.08204733e-06
Iter: 1386 loss: 1.08143286e-06
Iter: 1387 loss: 1.08242421e-06
Iter: 1388 loss: 1.08114136e-06
Iter: 1389 loss: 1.08045674e-06
Iter: 1390 loss: 1.08275333e-06
Iter: 1391 loss: 1.08026029e-06
Iter: 1392 loss: 1.07949302e-06
Iter: 1393 loss: 1.08113704e-06
Iter: 1394 loss: 1.07915935e-06
Iter: 1395 loss: 1.07831556e-06
Iter: 1396 loss: 1.0789272e-06
Iter: 1397 loss: 1.07779647e-06
Iter: 1398 loss: 1.07707797e-06
Iter: 1399 loss: 1.08031008e-06
Iter: 1400 loss: 1.07690994e-06
Iter: 1401 loss: 1.07605206e-06
Iter: 1402 loss: 1.08036306e-06
Iter: 1403 loss: 1.07585277e-06
Iter: 1404 loss: 1.07534663e-06
Iter: 1405 loss: 1.07484198e-06
Iter: 1406 loss: 1.07469714e-06
Iter: 1407 loss: 1.07390088e-06
Iter: 1408 loss: 1.08335882e-06
Iter: 1409 loss: 1.07390724e-06
Iter: 1410 loss: 1.07326036e-06
Iter: 1411 loss: 1.07327821e-06
Iter: 1412 loss: 1.07271671e-06
Iter: 1413 loss: 1.071935e-06
Iter: 1414 loss: 1.07226947e-06
Iter: 1415 loss: 1.07143194e-06
Iter: 1416 loss: 1.07040375e-06
Iter: 1417 loss: 1.07710639e-06
Iter: 1418 loss: 1.07032542e-06
Iter: 1419 loss: 1.06949153e-06
Iter: 1420 loss: 1.07525079e-06
Iter: 1421 loss: 1.06941525e-06
Iter: 1422 loss: 1.06878133e-06
Iter: 1423 loss: 1.06865548e-06
Iter: 1424 loss: 1.0681872e-06
Iter: 1425 loss: 1.06751747e-06
Iter: 1426 loss: 1.07547362e-06
Iter: 1427 loss: 1.06750213e-06
Iter: 1428 loss: 1.06692755e-06
Iter: 1429 loss: 1.06711423e-06
Iter: 1430 loss: 1.06648702e-06
Iter: 1431 loss: 1.06569735e-06
Iter: 1432 loss: 1.06662173e-06
Iter: 1433 loss: 1.06528307e-06
Iter: 1434 loss: 1.06451216e-06
Iter: 1435 loss: 1.06794528e-06
Iter: 1436 loss: 1.06440234e-06
Iter: 1437 loss: 1.06366383e-06
Iter: 1438 loss: 1.06765924e-06
Iter: 1439 loss: 1.06350524e-06
Iter: 1440 loss: 1.06290236e-06
Iter: 1441 loss: 1.06236416e-06
Iter: 1442 loss: 1.06219488e-06
Iter: 1443 loss: 1.06156847e-06
Iter: 1444 loss: 1.06906577e-06
Iter: 1445 loss: 1.06157859e-06
Iter: 1446 loss: 1.06089544e-06
Iter: 1447 loss: 1.06082234e-06
Iter: 1448 loss: 1.06038669e-06
Iter: 1449 loss: 1.05954848e-06
Iter: 1450 loss: 1.06022139e-06
Iter: 1451 loss: 1.05906975e-06
Iter: 1452 loss: 1.05825802e-06
Iter: 1453 loss: 1.06160815e-06
Iter: 1454 loss: 1.05804611e-06
Iter: 1455 loss: 1.05707522e-06
Iter: 1456 loss: 1.06436391e-06
Iter: 1457 loss: 1.0570493e-06
Iter: 1458 loss: 1.05635911e-06
Iter: 1459 loss: 1.05659979e-06
Iter: 1460 loss: 1.05588049e-06
Iter: 1461 loss: 1.0552518e-06
Iter: 1462 loss: 1.06047696e-06
Iter: 1463 loss: 1.0552103e-06
Iter: 1464 loss: 1.05453955e-06
Iter: 1465 loss: 1.0549021e-06
Iter: 1466 loss: 1.05409845e-06
Iter: 1467 loss: 1.05339461e-06
Iter: 1468 loss: 1.05510196e-06
Iter: 1469 loss: 1.05314507e-06
Iter: 1470 loss: 1.05248193e-06
Iter: 1471 loss: 1.05473964e-06
Iter: 1472 loss: 1.0523562e-06
Iter: 1473 loss: 1.05166623e-06
Iter: 1474 loss: 1.05406627e-06
Iter: 1475 loss: 1.05148706e-06
Iter: 1476 loss: 1.05080835e-06
Iter: 1477 loss: 1.05089316e-06
Iter: 1478 loss: 1.05032382e-06
Iter: 1479 loss: 1.04956666e-06
Iter: 1480 loss: 1.05200024e-06
Iter: 1481 loss: 1.04936203e-06
Iter: 1482 loss: 1.04855e-06
Iter: 1483 loss: 1.05233926e-06
Iter: 1484 loss: 1.04837807e-06
Iter: 1485 loss: 1.04771573e-06
Iter: 1486 loss: 1.04723983e-06
Iter: 1487 loss: 1.0470269e-06
Iter: 1488 loss: 1.04609171e-06
Iter: 1489 loss: 1.05045376e-06
Iter: 1490 loss: 1.0459014e-06
Iter: 1491 loss: 1.04533751e-06
Iter: 1492 loss: 1.04531159e-06
Iter: 1493 loss: 1.04487958e-06
Iter: 1494 loss: 1.04412766e-06
Iter: 1495 loss: 1.04411015e-06
Iter: 1496 loss: 1.0434768e-06
Iter: 1497 loss: 1.04346805e-06
Iter: 1498 loss: 1.04297237e-06
Iter: 1499 loss: 1.0431595e-06
Iter: 1500 loss: 1.04257299e-06
Iter: 1501 loss: 1.0419285e-06
Iter: 1502 loss: 1.04266178e-06
Iter: 1503 loss: 1.0416494e-06
Iter: 1504 loss: 1.04094954e-06
Iter: 1505 loss: 1.04390176e-06
Iter: 1506 loss: 1.0407291e-06
Iter: 1507 loss: 1.0399707e-06
Iter: 1508 loss: 1.04248295e-06
Iter: 1509 loss: 1.03971786e-06
Iter: 1510 loss: 1.03909338e-06
Iter: 1511 loss: 1.03986372e-06
Iter: 1512 loss: 1.03875072e-06
Iter: 1513 loss: 1.03810248e-06
Iter: 1514 loss: 1.03920274e-06
Iter: 1515 loss: 1.03780928e-06
Iter: 1516 loss: 1.03702916e-06
Iter: 1517 loss: 1.04116384e-06
Iter: 1518 loss: 1.03689945e-06
Iter: 1519 loss: 1.03619971e-06
Iter: 1520 loss: 1.03584841e-06
Iter: 1521 loss: 1.03553407e-06
Iter: 1522 loss: 1.03473212e-06
Iter: 1523 loss: 1.03821333e-06
Iter: 1524 loss: 1.03455977e-06
Iter: 1525 loss: 1.03384241e-06
Iter: 1526 loss: 1.04138076e-06
Iter: 1527 loss: 1.03378625e-06
Iter: 1528 loss: 1.03321986e-06
Iter: 1529 loss: 1.03298771e-06
Iter: 1530 loss: 1.03271282e-06
Iter: 1531 loss: 1.03209368e-06
Iter: 1532 loss: 1.03980756e-06
Iter: 1533 loss: 1.03209243e-06
Iter: 1534 loss: 1.03157186e-06
Iter: 1535 loss: 1.03114849e-06
Iter: 1536 loss: 1.03097489e-06
Iter: 1537 loss: 1.03017328e-06
Iter: 1538 loss: 1.03159459e-06
Iter: 1539 loss: 1.02986746e-06
Iter: 1540 loss: 1.02924434e-06
Iter: 1541 loss: 1.03856019e-06
Iter: 1542 loss: 1.02923525e-06
Iter: 1543 loss: 1.02874787e-06
Iter: 1544 loss: 1.02872673e-06
Iter: 1545 loss: 1.02836214e-06
Iter: 1546 loss: 1.0276035e-06
Iter: 1547 loss: 1.02832519e-06
Iter: 1548 loss: 1.02715808e-06
Iter: 1549 loss: 1.02642684e-06
Iter: 1550 loss: 1.03013485e-06
Iter: 1551 loss: 1.02630315e-06
Iter: 1552 loss: 1.02564513e-06
Iter: 1553 loss: 1.02849469e-06
Iter: 1554 loss: 1.02548529e-06
Iter: 1555 loss: 1.02489571e-06
Iter: 1556 loss: 1.02459785e-06
Iter: 1557 loss: 1.02428726e-06
Iter: 1558 loss: 1.02346053e-06
Iter: 1559 loss: 1.02608374e-06
Iter: 1560 loss: 1.02321019e-06
Iter: 1561 loss: 1.02247725e-06
Iter: 1562 loss: 1.03251625e-06
Iter: 1563 loss: 1.02246042e-06
Iter: 1564 loss: 1.02201091e-06
Iter: 1565 loss: 1.02154115e-06
Iter: 1566 loss: 1.02143235e-06
Iter: 1567 loss: 1.02076774e-06
Iter: 1568 loss: 1.02835099e-06
Iter: 1569 loss: 1.02073489e-06
Iter: 1570 loss: 1.0201793e-06
Iter: 1571 loss: 1.01947194e-06
Iter: 1572 loss: 1.01938406e-06
Iter: 1573 loss: 1.01863964e-06
Iter: 1574 loss: 1.02263857e-06
Iter: 1575 loss: 1.01853e-06
Iter: 1576 loss: 1.01786327e-06
Iter: 1577 loss: 1.02251e-06
Iter: 1578 loss: 1.01781643e-06
Iter: 1579 loss: 1.01724527e-06
Iter: 1580 loss: 1.01700073e-06
Iter: 1581 loss: 1.01666581e-06
Iter: 1582 loss: 1.01593037e-06
Iter: 1583 loss: 1.01931346e-06
Iter: 1584 loss: 1.01575324e-06
Iter: 1585 loss: 1.01523403e-06
Iter: 1586 loss: 1.01678393e-06
Iter: 1587 loss: 1.01506487e-06
Iter: 1588 loss: 1.01435649e-06
Iter: 1589 loss: 1.01536307e-06
Iter: 1590 loss: 1.01404362e-06
Iter: 1591 loss: 1.01326327e-06
Iter: 1592 loss: 1.01499541e-06
Iter: 1593 loss: 1.01303044e-06
Iter: 1594 loss: 1.01240357e-06
Iter: 1595 loss: 1.0141116e-06
Iter: 1596 loss: 1.01224794e-06
Iter: 1597 loss: 1.01152295e-06
Iter: 1598 loss: 1.01585397e-06
Iter: 1599 loss: 1.01139176e-06
Iter: 1600 loss: 1.01087153e-06
Iter: 1601 loss: 1.01061755e-06
Iter: 1602 loss: 1.01039961e-06
Iter: 1603 loss: 1.00973693e-06
Iter: 1604 loss: 1.01926184e-06
Iter: 1605 loss: 1.00973602e-06
Iter: 1606 loss: 1.00925286e-06
Iter: 1607 loss: 1.00843613e-06
Iter: 1608 loss: 1.00846023e-06
Iter: 1609 loss: 1.00776219e-06
Iter: 1610 loss: 1.01346075e-06
Iter: 1611 loss: 1.00763702e-06
Iter: 1612 loss: 1.00695684e-06
Iter: 1613 loss: 1.0104086e-06
Iter: 1614 loss: 1.00683167e-06
Iter: 1615 loss: 1.00632656e-06
Iter: 1616 loss: 1.00653813e-06
Iter: 1617 loss: 1.00596264e-06
Iter: 1618 loss: 1.00531543e-06
Iter: 1619 loss: 1.00639568e-06
Iter: 1620 loss: 1.00500938e-06
Iter: 1621 loss: 1.00429281e-06
Iter: 1622 loss: 1.00762986e-06
Iter: 1623 loss: 1.00416219e-06
Iter: 1624 loss: 1.00347233e-06
Iter: 1625 loss: 1.00539546e-06
Iter: 1626 loss: 1.0032287e-06
Iter: 1627 loss: 1.00256466e-06
Iter: 1628 loss: 1.00246848e-06
Iter: 1629 loss: 1.00200884e-06
Iter: 1630 loss: 1.00132411e-06
Iter: 1631 loss: 1.01056173e-06
Iter: 1632 loss: 1.00132206e-06
Iter: 1633 loss: 1.00073385e-06
Iter: 1634 loss: 1.00195825e-06
Iter: 1635 loss: 1.00052762e-06
Iter: 1636 loss: 1.00001785e-06
Iter: 1637 loss: 1.00020907e-06
Iter: 1638 loss: 9.99643476e-07
Iter: 1639 loss: 9.98935434e-07
Iter: 1640 loss: 1.00607042e-06
Iter: 1641 loss: 9.98952146e-07
Iter: 1642 loss: 9.98579708e-07
Iter: 1643 loss: 9.98105406e-07
Iter: 1644 loss: 9.98097e-07
Iter: 1645 loss: 9.97398274e-07
Iter: 1646 loss: 1.00068792e-06
Iter: 1647 loss: 9.97291522e-07
Iter: 1648 loss: 9.9650083e-07
Iter: 1649 loss: 9.98939299e-07
Iter: 1650 loss: 9.96289373e-07
Iter: 1651 loss: 9.95782557e-07
Iter: 1652 loss: 9.958178e-07
Iter: 1653 loss: 9.95373284e-07
Iter: 1654 loss: 9.94605e-07
Iter: 1655 loss: 9.97553116e-07
Iter: 1656 loss: 9.9446811e-07
Iter: 1657 loss: 9.93807589e-07
Iter: 1658 loss: 9.9640215e-07
Iter: 1659 loss: 9.93643198e-07
Iter: 1660 loss: 9.93040203e-07
Iter: 1661 loss: 9.94329412e-07
Iter: 1662 loss: 9.9285694e-07
Iter: 1663 loss: 9.92209152e-07
Iter: 1664 loss: 9.92675268e-07
Iter: 1665 loss: 9.91804e-07
Iter: 1666 loss: 9.91216439e-07
Iter: 1667 loss: 9.99010354e-07
Iter: 1668 loss: 9.91185289e-07
Iter: 1669 loss: 9.90650392e-07
Iter: 1670 loss: 9.90838089e-07
Iter: 1671 loss: 9.90283752e-07
Iter: 1672 loss: 9.89674845e-07
Iter: 1673 loss: 9.91519073e-07
Iter: 1674 loss: 9.89515456e-07
Iter: 1675 loss: 9.88818556e-07
Iter: 1676 loss: 9.91634e-07
Iter: 1677 loss: 9.8869441e-07
Iter: 1678 loss: 9.88217721e-07
Iter: 1679 loss: 9.87648264e-07
Iter: 1680 loss: 9.87595513e-07
Iter: 1681 loss: 9.87011504e-07
Iter: 1682 loss: 9.86993541e-07
Iter: 1683 loss: 9.86478426e-07
Iter: 1684 loss: 9.86376563e-07
Iter: 1685 loss: 9.86051418e-07
Iter: 1686 loss: 9.85455927e-07
Iter: 1687 loss: 9.8634132e-07
Iter: 1688 loss: 9.8517171e-07
Iter: 1689 loss: 9.84543703e-07
Iter: 1690 loss: 9.87609496e-07
Iter: 1691 loss: 9.8442024e-07
Iter: 1692 loss: 9.8376313e-07
Iter: 1693 loss: 9.8506564e-07
Iter: 1694 loss: 9.83466634e-07
Iter: 1695 loss: 9.82851589e-07
Iter: 1696 loss: 9.85225142e-07
Iter: 1697 loss: 9.82699135e-07
Iter: 1698 loss: 9.82056e-07
Iter: 1699 loss: 9.82096935e-07
Iter: 1700 loss: 9.81594894e-07
Iter: 1701 loss: 9.80947902e-07
Iter: 1702 loss: 9.80933123e-07
Iter: 1703 loss: 9.80424147e-07
Iter: 1704 loss: 9.80584446e-07
Iter: 1705 loss: 9.80094683e-07
Iter: 1706 loss: 9.79564788e-07
Iter: 1707 loss: 9.81324774e-07
Iter: 1708 loss: 9.79438482e-07
Iter: 1709 loss: 9.78722483e-07
Iter: 1710 loss: 9.79403239e-07
Iter: 1711 loss: 9.7834e-07
Iter: 1712 loss: 9.77742502e-07
Iter: 1713 loss: 9.78508183e-07
Iter: 1714 loss: 9.77444301e-07
Iter: 1715 loss: 9.76916908e-07
Iter: 1716 loss: 9.83793598e-07
Iter: 1717 loss: 9.76900651e-07
Iter: 1718 loss: 9.76441e-07
Iter: 1719 loss: 9.75893386e-07
Iter: 1720 loss: 9.7580687e-07
Iter: 1721 loss: 9.75139301e-07
Iter: 1722 loss: 9.76924298e-07
Iter: 1723 loss: 9.74930799e-07
Iter: 1724 loss: 9.74284831e-07
Iter: 1725 loss: 9.78348112e-07
Iter: 1726 loss: 9.74189788e-07
Iter: 1727 loss: 9.73541546e-07
Iter: 1728 loss: 9.74037334e-07
Iter: 1729 loss: 9.73133524e-07
Iter: 1730 loss: 9.72455723e-07
Iter: 1731 loss: 9.75611101e-07
Iter: 1732 loss: 9.72343514e-07
Iter: 1733 loss: 9.71741883e-07
Iter: 1734 loss: 9.73010629e-07
Iter: 1735 loss: 9.71547934e-07
Iter: 1736 loss: 9.70944939e-07
Iter: 1737 loss: 9.75446483e-07
Iter: 1738 loss: 9.70934e-07
Iter: 1739 loss: 9.70404358e-07
Iter: 1740 loss: 9.70216661e-07
Iter: 1741 loss: 9.69944494e-07
Iter: 1742 loss: 9.69345365e-07
Iter: 1743 loss: 9.75071771e-07
Iter: 1744 loss: 9.69296707e-07
Iter: 1745 loss: 9.68809445e-07
Iter: 1746 loss: 9.6857e-07
Iter: 1747 loss: 9.68274549e-07
Iter: 1748 loss: 9.67654387e-07
Iter: 1749 loss: 9.6873714e-07
Iter: 1750 loss: 9.67400752e-07
Iter: 1751 loss: 9.6681174e-07
Iter: 1752 loss: 9.73778924e-07
Iter: 1753 loss: 9.66809239e-07
Iter: 1754 loss: 9.66256e-07
Iter: 1755 loss: 9.65760591e-07
Iter: 1756 loss: 9.65613481e-07
Iter: 1757 loss: 9.64934429e-07
Iter: 1758 loss: 9.65665208e-07
Iter: 1759 loss: 9.64584387e-07
Iter: 1760 loss: 9.63793241e-07
Iter: 1761 loss: 9.70705173e-07
Iter: 1762 loss: 9.63737648e-07
Iter: 1763 loss: 9.63160574e-07
Iter: 1764 loss: 9.64678065e-07
Iter: 1765 loss: 9.62940703e-07
Iter: 1766 loss: 9.62477088e-07
Iter: 1767 loss: 9.62763693e-07
Iter: 1768 loss: 9.62153877e-07
Iter: 1769 loss: 9.61424576e-07
Iter: 1770 loss: 9.65123e-07
Iter: 1771 loss: 9.61307478e-07
Iter: 1772 loss: 9.60712e-07
Iter: 1773 loss: 9.63902266e-07
Iter: 1774 loss: 9.60602392e-07
Iter: 1775 loss: 9.6009876e-07
Iter: 1776 loss: 9.6030044e-07
Iter: 1777 loss: 9.59790555e-07
Iter: 1778 loss: 9.59232e-07
Iter: 1779 loss: 9.62913873e-07
Iter: 1780 loss: 9.59185e-07
Iter: 1781 loss: 9.58639e-07
Iter: 1782 loss: 9.5829364e-07
Iter: 1783 loss: 9.58075589e-07
Iter: 1784 loss: 9.5743178e-07
Iter: 1785 loss: 9.59125146e-07
Iter: 1786 loss: 9.5722271e-07
Iter: 1787 loss: 9.56633812e-07
Iter: 1788 loss: 9.65344725e-07
Iter: 1789 loss: 9.56631311e-07
Iter: 1790 loss: 9.56207e-07
Iter: 1791 loss: 9.55793666e-07
Iter: 1792 loss: 9.55735686e-07
Iter: 1793 loss: 9.55046517e-07
Iter: 1794 loss: 9.55458745e-07
Iter: 1795 loss: 9.54570282e-07
Iter: 1796 loss: 9.54080178e-07
Iter: 1797 loss: 9.54053576e-07
Iter: 1798 loss: 9.53573e-07
Iter: 1799 loss: 9.53181711e-07
Iter: 1800 loss: 9.53043354e-07
Iter: 1801 loss: 9.52383e-07
Iter: 1802 loss: 9.55694304e-07
Iter: 1803 loss: 9.52256187e-07
Iter: 1804 loss: 9.51706738e-07
Iter: 1805 loss: 9.55830387e-07
Iter: 1806 loss: 9.51674622e-07
Iter: 1807 loss: 9.51156323e-07
Iter: 1808 loss: 9.51661718e-07
Iter: 1809 loss: 9.50917297e-07
Iter: 1810 loss: 9.50336926e-07
Iter: 1811 loss: 9.51495053e-07
Iter: 1812 loss: 9.50127344e-07
Iter: 1813 loss: 9.49617402e-07
Iter: 1814 loss: 9.52941093e-07
Iter: 1815 loss: 9.49559762e-07
Iter: 1816 loss: 9.49110358e-07
Iter: 1817 loss: 9.48868887e-07
Iter: 1818 loss: 9.48618094e-07
Iter: 1819 loss: 9.48028855e-07
Iter: 1820 loss: 9.49983701e-07
Iter: 1821 loss: 9.47873161e-07
Iter: 1822 loss: 9.47297792e-07
Iter: 1823 loss: 9.52140226e-07
Iter: 1824 loss: 9.47241404e-07
Iter: 1825 loss: 9.46747946e-07
Iter: 1826 loss: 9.46211912e-07
Iter: 1827 loss: 9.46135e-07
Iter: 1828 loss: 9.45426905e-07
Iter: 1829 loss: 9.47315073e-07
Iter: 1830 loss: 9.45254612e-07
Iter: 1831 loss: 9.44579256e-07
Iter: 1832 loss: 9.49599553e-07
Iter: 1833 loss: 9.44498538e-07
Iter: 1834 loss: 9.4391703e-07
Iter: 1835 loss: 9.44765816e-07
Iter: 1836 loss: 9.43636508e-07
Iter: 1837 loss: 9.4317511e-07
Iter: 1838 loss: 9.44204e-07
Iter: 1839 loss: 9.42972235e-07
Iter: 1840 loss: 9.42312738e-07
Iter: 1841 loss: 9.45471299e-07
Iter: 1842 loss: 9.42237364e-07
Iter: 1843 loss: 9.41701046e-07
Iter: 1844 loss: 9.42477186e-07
Iter: 1845 loss: 9.41444e-07
Iter: 1846 loss: 9.40993971e-07
Iter: 1847 loss: 9.43457906e-07
Iter: 1848 loss: 9.4091e-07
Iter: 1849 loss: 9.40456175e-07
Iter: 1850 loss: 9.40948439e-07
Iter: 1851 loss: 9.40313384e-07
Iter: 1852 loss: 9.39701863e-07
Iter: 1853 loss: 9.39828e-07
Iter: 1854 loss: 9.39265419e-07
Iter: 1855 loss: 9.38723929e-07
Iter: 1856 loss: 9.41983103e-07
Iter: 1857 loss: 9.38657365e-07
Iter: 1858 loss: 9.38046355e-07
Iter: 1859 loss: 9.39555207e-07
Iter: 1860 loss: 9.37816822e-07
Iter: 1861 loss: 9.37270784e-07
Iter: 1862 loss: 9.37135837e-07
Iter: 1863 loss: 9.36803929e-07
Iter: 1864 loss: 9.36137212e-07
Iter: 1865 loss: 9.38246671e-07
Iter: 1866 loss: 9.35929734e-07
Iter: 1867 loss: 9.3540973e-07
Iter: 1868 loss: 9.40931272e-07
Iter: 1869 loss: 9.35370167e-07
Iter: 1870 loss: 9.34914965e-07
Iter: 1871 loss: 9.35181e-07
Iter: 1872 loss: 9.34627e-07
Iter: 1873 loss: 9.34072375e-07
Iter: 1874 loss: 9.3476848e-07
Iter: 1875 loss: 9.33846479e-07
Iter: 1876 loss: 9.33201591e-07
Iter: 1877 loss: 9.39126039e-07
Iter: 1878 loss: 9.33134629e-07
Iter: 1879 loss: 9.32751561e-07
Iter: 1880 loss: 9.32701255e-07
Iter: 1881 loss: 9.3237685e-07
Iter: 1882 loss: 9.3187623e-07
Iter: 1883 loss: 9.35325374e-07
Iter: 1884 loss: 9.31803697e-07
Iter: 1885 loss: 9.31362422e-07
Iter: 1886 loss: 9.31520447e-07
Iter: 1887 loss: 9.31060356e-07
Iter: 1888 loss: 9.303306e-07
Iter: 1889 loss: 9.31184559e-07
Iter: 1890 loss: 9.29990051e-07
Iter: 1891 loss: 9.29418547e-07
Iter: 1892 loss: 9.34277864e-07
Iter: 1893 loss: 9.29401153e-07
Iter: 1894 loss: 9.2893373e-07
Iter: 1895 loss: 9.30111923e-07
Iter: 1896 loss: 9.28766156e-07
Iter: 1897 loss: 9.28291797e-07
Iter: 1898 loss: 9.27538963e-07
Iter: 1899 loss: 9.2748877e-07
Iter: 1900 loss: 9.26845246e-07
Iter: 1901 loss: 9.335252e-07
Iter: 1902 loss: 9.26827227e-07
Iter: 1903 loss: 9.26371399e-07
Iter: 1904 loss: 9.2961568e-07
Iter: 1905 loss: 9.26316375e-07
Iter: 1906 loss: 9.25774657e-07
Iter: 1907 loss: 9.25394829e-07
Iter: 1908 loss: 9.25223048e-07
Iter: 1909 loss: 9.24586516e-07
Iter: 1910 loss: 9.28615236e-07
Iter: 1911 loss: 9.24520464e-07
Iter: 1912 loss: 9.23928042e-07
Iter: 1913 loss: 9.28782356e-07
Iter: 1914 loss: 9.23903883e-07
Iter: 1915 loss: 9.2348273e-07
Iter: 1916 loss: 9.2303236e-07
Iter: 1917 loss: 9.22982849e-07
Iter: 1918 loss: 9.22288052e-07
Iter: 1919 loss: 9.28092163e-07
Iter: 1920 loss: 9.2227117e-07
Iter: 1921 loss: 9.21716037e-07
Iter: 1922 loss: 9.2222291e-07
Iter: 1923 loss: 9.21389926e-07
Iter: 1924 loss: 9.20886123e-07
Iter: 1925 loss: 9.22151742e-07
Iter: 1926 loss: 9.20692685e-07
Iter: 1927 loss: 9.20139087e-07
Iter: 1928 loss: 9.22560616e-07
Iter: 1929 loss: 9.20046034e-07
Iter: 1930 loss: 9.19538e-07
Iter: 1931 loss: 9.21775381e-07
Iter: 1932 loss: 9.19461058e-07
Iter: 1933 loss: 9.19035301e-07
Iter: 1934 loss: 9.18336696e-07
Iter: 1935 loss: 9.18341e-07
Iter: 1936 loss: 9.17698912e-07
Iter: 1937 loss: 9.22172831e-07
Iter: 1938 loss: 9.176307e-07
Iter: 1939 loss: 9.17105e-07
Iter: 1940 loss: 9.19682293e-07
Iter: 1941 loss: 9.16996896e-07
Iter: 1942 loss: 9.16399586e-07
Iter: 1943 loss: 9.17458635e-07
Iter: 1944 loss: 9.16109684e-07
Iter: 1945 loss: 9.15621797e-07
Iter: 1946 loss: 9.17019065e-07
Iter: 1947 loss: 9.15489068e-07
Iter: 1948 loss: 9.14979864e-07
Iter: 1949 loss: 9.19001423e-07
Iter: 1950 loss: 9.14993791e-07
Iter: 1951 loss: 9.14568545e-07
Iter: 1952 loss: 9.14100042e-07
Iter: 1953 loss: 9.14079124e-07
Iter: 1954 loss: 9.13670874e-07
Iter: 1955 loss: 9.13653139e-07
Iter: 1956 loss: 9.13288488e-07
Iter: 1957 loss: 9.13028259e-07
Iter: 1958 loss: 9.12899168e-07
Iter: 1959 loss: 9.12316182e-07
Iter: 1960 loss: 9.13627275e-07
Iter: 1961 loss: 9.1205419e-07
Iter: 1962 loss: 9.1151469e-07
Iter: 1963 loss: 9.17073066e-07
Iter: 1964 loss: 9.11514405e-07
Iter: 1965 loss: 9.11086545e-07
Iter: 1966 loss: 9.11489337e-07
Iter: 1967 loss: 9.10894528e-07
Iter: 1968 loss: 9.10368783e-07
Iter: 1969 loss: 9.10221502e-07
Iter: 1970 loss: 9.09883056e-07
Iter: 1971 loss: 9.09300866e-07
Iter: 1972 loss: 9.10638619e-07
Iter: 1973 loss: 9.09086907e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.6
+ date
Sat Nov  7 15:01:45 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.6/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.6_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi1.6_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196bf8048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196bfc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196b52488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196b52400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196b1c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196b1c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196b1c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196a86598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196a9d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196a62840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196a25400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196a4f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196a4f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4196978598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41969a19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f7bf730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f7b42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f419693d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f794488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f794620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f763268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f7639d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f712158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f7156a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f715c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f6aed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f6750d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f675bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f6756a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f655400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f6558c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41969a1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f5ba9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f5ce6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f5baea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f418f5712f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.41425732e-05
Iter: 2 loss: 2.12603627e-05
Iter: 3 loss: 2.28407971e-05
Iter: 4 loss: 1.9365194e-05
Iter: 5 loss: 1.68090755e-05
Iter: 6 loss: 3.01099317e-05
Iter: 7 loss: 1.64041248e-05
Iter: 8 loss: 1.49218195e-05
Iter: 9 loss: 1.61506341e-05
Iter: 10 loss: 1.40411194e-05
Iter: 11 loss: 1.25559627e-05
Iter: 12 loss: 2.68049371e-05
Iter: 13 loss: 1.24999133e-05
Iter: 14 loss: 1.16482379e-05
Iter: 15 loss: 1.22868278e-05
Iter: 16 loss: 1.11258469e-05
Iter: 17 loss: 1.03047059e-05
Iter: 18 loss: 1.28972433e-05
Iter: 19 loss: 1.00681546e-05
Iter: 20 loss: 9.2878854e-06
Iter: 21 loss: 1.33264257e-05
Iter: 22 loss: 9.16350291e-06
Iter: 23 loss: 8.6130849e-06
Iter: 24 loss: 1.06812086e-05
Iter: 25 loss: 8.47978572e-06
Iter: 26 loss: 8.04219417e-06
Iter: 27 loss: 8.45072645e-06
Iter: 28 loss: 7.79028051e-06
Iter: 29 loss: 7.32022181e-06
Iter: 30 loss: 1.03077737e-05
Iter: 31 loss: 7.26758162e-06
Iter: 32 loss: 6.87775446e-06
Iter: 33 loss: 7.4274094e-06
Iter: 34 loss: 6.68561279e-06
Iter: 35 loss: 6.35788638e-06
Iter: 36 loss: 6.54908e-06
Iter: 37 loss: 6.14544206e-06
Iter: 38 loss: 5.76017328e-06
Iter: 39 loss: 8.09805533e-06
Iter: 40 loss: 5.71307737e-06
Iter: 41 loss: 5.47353784e-06
Iter: 42 loss: 6.1500532e-06
Iter: 43 loss: 5.3973481e-06
Iter: 44 loss: 5.21462107e-06
Iter: 45 loss: 7.52520464e-06
Iter: 46 loss: 5.21312722e-06
Iter: 47 loss: 5.05052321e-06
Iter: 48 loss: 5.60023682e-06
Iter: 49 loss: 5.00668648e-06
Iter: 50 loss: 4.90230104e-06
Iter: 51 loss: 4.90583761e-06
Iter: 52 loss: 4.81976167e-06
Iter: 53 loss: 4.67981681e-06
Iter: 54 loss: 6.01478405e-06
Iter: 55 loss: 4.67448e-06
Iter: 56 loss: 4.5815068e-06
Iter: 57 loss: 4.51398046e-06
Iter: 58 loss: 4.48215815e-06
Iter: 59 loss: 4.35408219e-06
Iter: 60 loss: 4.7597332e-06
Iter: 61 loss: 4.31723129e-06
Iter: 62 loss: 4.1938988e-06
Iter: 63 loss: 5.31029764e-06
Iter: 64 loss: 4.18828222e-06
Iter: 65 loss: 4.10174971e-06
Iter: 66 loss: 4.06584741e-06
Iter: 67 loss: 4.02032356e-06
Iter: 68 loss: 3.91272079e-06
Iter: 69 loss: 4.30867749e-06
Iter: 70 loss: 3.88611716e-06
Iter: 71 loss: 3.78376444e-06
Iter: 72 loss: 4.51710912e-06
Iter: 73 loss: 3.77478341e-06
Iter: 74 loss: 3.71214446e-06
Iter: 75 loss: 3.67216262e-06
Iter: 76 loss: 3.64763355e-06
Iter: 77 loss: 3.56702685e-06
Iter: 78 loss: 4.15570867e-06
Iter: 79 loss: 3.5603e-06
Iter: 80 loss: 3.49411175e-06
Iter: 81 loss: 3.65059304e-06
Iter: 82 loss: 3.47002197e-06
Iter: 83 loss: 3.41194209e-06
Iter: 84 loss: 3.50264236e-06
Iter: 85 loss: 3.38455629e-06
Iter: 86 loss: 3.33941261e-06
Iter: 87 loss: 3.33721573e-06
Iter: 88 loss: 3.30547391e-06
Iter: 89 loss: 3.24365169e-06
Iter: 90 loss: 4.50337848e-06
Iter: 91 loss: 3.24321763e-06
Iter: 92 loss: 3.19641686e-06
Iter: 93 loss: 3.89396e-06
Iter: 94 loss: 3.19635774e-06
Iter: 95 loss: 3.15274974e-06
Iter: 96 loss: 3.19845958e-06
Iter: 97 loss: 3.12867974e-06
Iter: 98 loss: 3.089247e-06
Iter: 99 loss: 3.04731884e-06
Iter: 100 loss: 3.040416e-06
Iter: 101 loss: 3.01528394e-06
Iter: 102 loss: 3.00614124e-06
Iter: 103 loss: 2.97937368e-06
Iter: 104 loss: 2.94585288e-06
Iter: 105 loss: 2.94303914e-06
Iter: 106 loss: 2.90117396e-06
Iter: 107 loss: 3.03128445e-06
Iter: 108 loss: 2.88902356e-06
Iter: 109 loss: 2.85095666e-06
Iter: 110 loss: 3.08441895e-06
Iter: 111 loss: 2.84644761e-06
Iter: 112 loss: 2.81231951e-06
Iter: 113 loss: 2.88841557e-06
Iter: 114 loss: 2.79928167e-06
Iter: 115 loss: 2.76689161e-06
Iter: 116 loss: 2.78820244e-06
Iter: 117 loss: 2.74659965e-06
Iter: 118 loss: 2.71130193e-06
Iter: 119 loss: 2.80677386e-06
Iter: 120 loss: 2.69964539e-06
Iter: 121 loss: 2.66878624e-06
Iter: 122 loss: 2.95970426e-06
Iter: 123 loss: 2.66744064e-06
Iter: 124 loss: 2.64191158e-06
Iter: 125 loss: 2.80192194e-06
Iter: 126 loss: 2.63903485e-06
Iter: 127 loss: 2.62132539e-06
Iter: 128 loss: 2.61414152e-06
Iter: 129 loss: 2.6046032e-06
Iter: 130 loss: 2.5794493e-06
Iter: 131 loss: 2.65389099e-06
Iter: 132 loss: 2.5717527e-06
Iter: 133 loss: 2.54702763e-06
Iter: 134 loss: 2.70995292e-06
Iter: 135 loss: 2.54461247e-06
Iter: 136 loss: 2.52386e-06
Iter: 137 loss: 2.52108566e-06
Iter: 138 loss: 2.50645644e-06
Iter: 139 loss: 2.47932121e-06
Iter: 140 loss: 2.53498501e-06
Iter: 141 loss: 2.46866716e-06
Iter: 142 loss: 2.44724833e-06
Iter: 143 loss: 2.66388724e-06
Iter: 144 loss: 2.44646571e-06
Iter: 145 loss: 2.42764668e-06
Iter: 146 loss: 2.45626097e-06
Iter: 147 loss: 2.41859743e-06
Iter: 148 loss: 2.40037707e-06
Iter: 149 loss: 2.39068231e-06
Iter: 150 loss: 2.38233588e-06
Iter: 151 loss: 2.35793414e-06
Iter: 152 loss: 2.47478147e-06
Iter: 153 loss: 2.35353127e-06
Iter: 154 loss: 2.33365017e-06
Iter: 155 loss: 2.55663235e-06
Iter: 156 loss: 2.33320407e-06
Iter: 157 loss: 2.32040702e-06
Iter: 158 loss: 2.3070827e-06
Iter: 159 loss: 2.30467253e-06
Iter: 160 loss: 2.28450199e-06
Iter: 161 loss: 2.39098927e-06
Iter: 162 loss: 2.28131466e-06
Iter: 163 loss: 2.26864518e-06
Iter: 164 loss: 2.26861857e-06
Iter: 165 loss: 2.25698045e-06
Iter: 166 loss: 2.23570169e-06
Iter: 167 loss: 2.75195544e-06
Iter: 168 loss: 2.23569168e-06
Iter: 169 loss: 2.22014387e-06
Iter: 170 loss: 2.28998124e-06
Iter: 171 loss: 2.21710934e-06
Iter: 172 loss: 2.20053334e-06
Iter: 173 loss: 2.31482068e-06
Iter: 174 loss: 2.19903882e-06
Iter: 175 loss: 2.18666946e-06
Iter: 176 loss: 2.1914127e-06
Iter: 177 loss: 2.17805928e-06
Iter: 178 loss: 2.16608692e-06
Iter: 179 loss: 2.20741572e-06
Iter: 180 loss: 2.16287231e-06
Iter: 181 loss: 2.15048749e-06
Iter: 182 loss: 2.18599621e-06
Iter: 183 loss: 2.14666306e-06
Iter: 184 loss: 2.13405406e-06
Iter: 185 loss: 2.19124013e-06
Iter: 186 loss: 2.13164685e-06
Iter: 187 loss: 2.11995894e-06
Iter: 188 loss: 2.12416126e-06
Iter: 189 loss: 2.11168958e-06
Iter: 190 loss: 2.09969244e-06
Iter: 191 loss: 2.09856e-06
Iter: 192 loss: 2.08970596e-06
Iter: 193 loss: 2.07560583e-06
Iter: 194 loss: 2.26094016e-06
Iter: 195 loss: 2.07556491e-06
Iter: 196 loss: 2.06423465e-06
Iter: 197 loss: 2.09679229e-06
Iter: 198 loss: 2.06070945e-06
Iter: 199 loss: 2.05153788e-06
Iter: 200 loss: 2.05843844e-06
Iter: 201 loss: 2.04583284e-06
Iter: 202 loss: 2.0341954e-06
Iter: 203 loss: 2.13732665e-06
Iter: 204 loss: 2.03359741e-06
Iter: 205 loss: 2.02407887e-06
Iter: 206 loss: 2.04811704e-06
Iter: 207 loss: 2.02078036e-06
Iter: 208 loss: 2.01488683e-06
Iter: 209 loss: 2.00383192e-06
Iter: 210 loss: 2.26191287e-06
Iter: 211 loss: 2.00381805e-06
Iter: 212 loss: 1.99344663e-06
Iter: 213 loss: 1.99340548e-06
Iter: 214 loss: 1.98504222e-06
Iter: 215 loss: 2.01452031e-06
Iter: 216 loss: 1.9828019e-06
Iter: 217 loss: 1.97691315e-06
Iter: 218 loss: 1.96411747e-06
Iter: 219 loss: 2.16539047e-06
Iter: 220 loss: 1.96369888e-06
Iter: 221 loss: 1.95721623e-06
Iter: 222 loss: 1.95559028e-06
Iter: 223 loss: 1.94943914e-06
Iter: 224 loss: 1.95786879e-06
Iter: 225 loss: 1.94638346e-06
Iter: 226 loss: 1.93824781e-06
Iter: 227 loss: 1.93252436e-06
Iter: 228 loss: 1.92966922e-06
Iter: 229 loss: 1.91864524e-06
Iter: 230 loss: 1.98586258e-06
Iter: 231 loss: 1.91726804e-06
Iter: 232 loss: 1.90953551e-06
Iter: 233 loss: 1.93973483e-06
Iter: 234 loss: 1.90767514e-06
Iter: 235 loss: 1.89980335e-06
Iter: 236 loss: 1.90388573e-06
Iter: 237 loss: 1.89446041e-06
Iter: 238 loss: 1.88675608e-06
Iter: 239 loss: 1.88673641e-06
Iter: 240 loss: 1.88289e-06
Iter: 241 loss: 1.88905744e-06
Iter: 242 loss: 1.88116474e-06
Iter: 243 loss: 1.87482465e-06
Iter: 244 loss: 1.87429532e-06
Iter: 245 loss: 1.86961756e-06
Iter: 246 loss: 1.86309546e-06
Iter: 247 loss: 1.86675675e-06
Iter: 248 loss: 1.85877241e-06
Iter: 249 loss: 1.85166232e-06
Iter: 250 loss: 1.89352227e-06
Iter: 251 loss: 1.85071656e-06
Iter: 252 loss: 1.84353e-06
Iter: 253 loss: 1.87981493e-06
Iter: 254 loss: 1.84241208e-06
Iter: 255 loss: 1.83672182e-06
Iter: 256 loss: 1.83215809e-06
Iter: 257 loss: 1.83047405e-06
Iter: 258 loss: 1.82308577e-06
Iter: 259 loss: 1.84467672e-06
Iter: 260 loss: 1.82079748e-06
Iter: 261 loss: 1.81410678e-06
Iter: 262 loss: 1.9029967e-06
Iter: 263 loss: 1.81408279e-06
Iter: 264 loss: 1.80927543e-06
Iter: 265 loss: 1.80898155e-06
Iter: 266 loss: 1.80538314e-06
Iter: 267 loss: 1.79928907e-06
Iter: 268 loss: 1.79469657e-06
Iter: 269 loss: 1.79265226e-06
Iter: 270 loss: 1.78367827e-06
Iter: 271 loss: 1.8751698e-06
Iter: 272 loss: 1.78339496e-06
Iter: 273 loss: 1.77740992e-06
Iter: 274 loss: 1.80178563e-06
Iter: 275 loss: 1.77608206e-06
Iter: 276 loss: 1.77029301e-06
Iter: 277 loss: 1.79851361e-06
Iter: 278 loss: 1.7693028e-06
Iter: 279 loss: 1.7643697e-06
Iter: 280 loss: 1.78228345e-06
Iter: 281 loss: 1.76309914e-06
Iter: 282 loss: 1.75846537e-06
Iter: 283 loss: 1.76555716e-06
Iter: 284 loss: 1.75628747e-06
Iter: 285 loss: 1.75128503e-06
Iter: 286 loss: 1.75183175e-06
Iter: 287 loss: 1.74742911e-06
Iter: 288 loss: 1.74147146e-06
Iter: 289 loss: 1.77190157e-06
Iter: 290 loss: 1.74056549e-06
Iter: 291 loss: 1.73526632e-06
Iter: 292 loss: 1.74747265e-06
Iter: 293 loss: 1.73323986e-06
Iter: 294 loss: 1.72664181e-06
Iter: 295 loss: 1.75519483e-06
Iter: 296 loss: 1.72531691e-06
Iter: 297 loss: 1.72116688e-06
Iter: 298 loss: 1.71612282e-06
Iter: 299 loss: 1.71553597e-06
Iter: 300 loss: 1.70976296e-06
Iter: 301 loss: 1.74011211e-06
Iter: 302 loss: 1.70883288e-06
Iter: 303 loss: 1.70301428e-06
Iter: 304 loss: 1.7548108e-06
Iter: 305 loss: 1.7027055e-06
Iter: 306 loss: 1.69918076e-06
Iter: 307 loss: 1.69557802e-06
Iter: 308 loss: 1.69480381e-06
Iter: 309 loss: 1.68929455e-06
Iter: 310 loss: 1.69581483e-06
Iter: 311 loss: 1.68634301e-06
Iter: 312 loss: 1.68026804e-06
Iter: 313 loss: 1.73729018e-06
Iter: 314 loss: 1.68007205e-06
Iter: 315 loss: 1.67548546e-06
Iter: 316 loss: 1.71552415e-06
Iter: 317 loss: 1.67519818e-06
Iter: 318 loss: 1.67205076e-06
Iter: 319 loss: 1.67273038e-06
Iter: 320 loss: 1.66965e-06
Iter: 321 loss: 1.66489417e-06
Iter: 322 loss: 1.67473149e-06
Iter: 323 loss: 1.66297491e-06
Iter: 324 loss: 1.65805022e-06
Iter: 325 loss: 1.66029542e-06
Iter: 326 loss: 1.65487472e-06
Iter: 327 loss: 1.64992321e-06
Iter: 328 loss: 1.68469819e-06
Iter: 329 loss: 1.64942094e-06
Iter: 330 loss: 1.64566268e-06
Iter: 331 loss: 1.66630662e-06
Iter: 332 loss: 1.64512198e-06
Iter: 333 loss: 1.64136964e-06
Iter: 334 loss: 1.64231483e-06
Iter: 335 loss: 1.63872301e-06
Iter: 336 loss: 1.6340266e-06
Iter: 337 loss: 1.64882067e-06
Iter: 338 loss: 1.63271432e-06
Iter: 339 loss: 1.62914819e-06
Iter: 340 loss: 1.62493666e-06
Iter: 341 loss: 1.62442893e-06
Iter: 342 loss: 1.62163565e-06
Iter: 343 loss: 1.62070523e-06
Iter: 344 loss: 1.61817104e-06
Iter: 345 loss: 1.61671028e-06
Iter: 346 loss: 1.61568164e-06
Iter: 347 loss: 1.61153343e-06
Iter: 348 loss: 1.61038201e-06
Iter: 349 loss: 1.60777245e-06
Iter: 350 loss: 1.60277295e-06
Iter: 351 loss: 1.63218374e-06
Iter: 352 loss: 1.60214427e-06
Iter: 353 loss: 1.59865817e-06
Iter: 354 loss: 1.6505121e-06
Iter: 355 loss: 1.59863077e-06
Iter: 356 loss: 1.59545948e-06
Iter: 357 loss: 1.59437297e-06
Iter: 358 loss: 1.59251374e-06
Iter: 359 loss: 1.58875309e-06
Iter: 360 loss: 1.59242472e-06
Iter: 361 loss: 1.58655826e-06
Iter: 362 loss: 1.58298803e-06
Iter: 363 loss: 1.62307902e-06
Iter: 364 loss: 1.58288765e-06
Iter: 365 loss: 1.58017087e-06
Iter: 366 loss: 1.57973102e-06
Iter: 367 loss: 1.57795057e-06
Iter: 368 loss: 1.57384534e-06
Iter: 369 loss: 1.5847628e-06
Iter: 370 loss: 1.57248974e-06
Iter: 371 loss: 1.5686926e-06
Iter: 372 loss: 1.60849527e-06
Iter: 373 loss: 1.56859119e-06
Iter: 374 loss: 1.56634496e-06
Iter: 375 loss: 1.56236263e-06
Iter: 376 loss: 1.65835945e-06
Iter: 377 loss: 1.56241083e-06
Iter: 378 loss: 1.55708267e-06
Iter: 379 loss: 1.56970691e-06
Iter: 380 loss: 1.55521616e-06
Iter: 381 loss: 1.55199473e-06
Iter: 382 loss: 1.55183284e-06
Iter: 383 loss: 1.54922463e-06
Iter: 384 loss: 1.54791667e-06
Iter: 385 loss: 1.54667566e-06
Iter: 386 loss: 1.54303166e-06
Iter: 387 loss: 1.55533587e-06
Iter: 388 loss: 1.54196084e-06
Iter: 389 loss: 1.53842052e-06
Iter: 390 loss: 1.54326312e-06
Iter: 391 loss: 1.53664109e-06
Iter: 392 loss: 1.53364977e-06
Iter: 393 loss: 1.55921339e-06
Iter: 394 loss: 1.53352994e-06
Iter: 395 loss: 1.53037718e-06
Iter: 396 loss: 1.53813892e-06
Iter: 397 loss: 1.52923144e-06
Iter: 398 loss: 1.5266512e-06
Iter: 399 loss: 1.52290045e-06
Iter: 400 loss: 1.52283815e-06
Iter: 401 loss: 1.51858274e-06
Iter: 402 loss: 1.54385157e-06
Iter: 403 loss: 1.51807797e-06
Iter: 404 loss: 1.51483255e-06
Iter: 405 loss: 1.55209625e-06
Iter: 406 loss: 1.51479435e-06
Iter: 407 loss: 1.51247571e-06
Iter: 408 loss: 1.50820597e-06
Iter: 409 loss: 1.61002083e-06
Iter: 410 loss: 1.5081971e-06
Iter: 411 loss: 1.50373785e-06
Iter: 412 loss: 1.50371977e-06
Iter: 413 loss: 1.50207404e-06
Iter: 414 loss: 1.49965922e-06
Iter: 415 loss: 1.49955667e-06
Iter: 416 loss: 1.49547191e-06
Iter: 417 loss: 1.49806681e-06
Iter: 418 loss: 1.49283e-06
Iter: 419 loss: 1.48986828e-06
Iter: 420 loss: 1.48988306e-06
Iter: 421 loss: 1.48732352e-06
Iter: 422 loss: 1.49141897e-06
Iter: 423 loss: 1.4861298e-06
Iter: 424 loss: 1.48342383e-06
Iter: 425 loss: 1.48031722e-06
Iter: 426 loss: 1.47992625e-06
Iter: 427 loss: 1.47620472e-06
Iter: 428 loss: 1.51560812e-06
Iter: 429 loss: 1.47611979e-06
Iter: 430 loss: 1.47360595e-06
Iter: 431 loss: 1.49785342e-06
Iter: 432 loss: 1.47348283e-06
Iter: 433 loss: 1.47120636e-06
Iter: 434 loss: 1.47078867e-06
Iter: 435 loss: 1.46925061e-06
Iter: 436 loss: 1.46638206e-06
Iter: 437 loss: 1.46770594e-06
Iter: 438 loss: 1.4644736e-06
Iter: 439 loss: 1.46084608e-06
Iter: 440 loss: 1.47271055e-06
Iter: 441 loss: 1.45984086e-06
Iter: 442 loss: 1.45644117e-06
Iter: 443 loss: 1.4677039e-06
Iter: 444 loss: 1.45544482e-06
Iter: 445 loss: 1.45256604e-06
Iter: 446 loss: 1.48213235e-06
Iter: 447 loss: 1.45253671e-06
Iter: 448 loss: 1.45028207e-06
Iter: 449 loss: 1.44850173e-06
Iter: 450 loss: 1.44781757e-06
Iter: 451 loss: 1.44504224e-06
Iter: 452 loss: 1.47616186e-06
Iter: 453 loss: 1.44495846e-06
Iter: 454 loss: 1.44279227e-06
Iter: 455 loss: 1.44214926e-06
Iter: 456 loss: 1.44074727e-06
Iter: 457 loss: 1.43763953e-06
Iter: 458 loss: 1.43681586e-06
Iter: 459 loss: 1.43496072e-06
Iter: 460 loss: 1.43232364e-06
Iter: 461 loss: 1.43211935e-06
Iter: 462 loss: 1.4299028e-06
Iter: 463 loss: 1.43261104e-06
Iter: 464 loss: 1.42878582e-06
Iter: 465 loss: 1.42635179e-06
Iter: 466 loss: 1.42331976e-06
Iter: 467 loss: 1.42307283e-06
Iter: 468 loss: 1.42236217e-06
Iter: 469 loss: 1.42121155e-06
Iter: 470 loss: 1.41964733e-06
Iter: 471 loss: 1.41868964e-06
Iter: 472 loss: 1.4181735e-06
Iter: 473 loss: 1.41580813e-06
Iter: 474 loss: 1.41166402e-06
Iter: 475 loss: 1.41164287e-06
Iter: 476 loss: 1.40794521e-06
Iter: 477 loss: 1.45842296e-06
Iter: 478 loss: 1.40794009e-06
Iter: 479 loss: 1.40545399e-06
Iter: 480 loss: 1.41593625e-06
Iter: 481 loss: 1.40489294e-06
Iter: 482 loss: 1.40186864e-06
Iter: 483 loss: 1.40616271e-06
Iter: 484 loss: 1.40045813e-06
Iter: 485 loss: 1.39727968e-06
Iter: 486 loss: 1.4189618e-06
Iter: 487 loss: 1.396936e-06
Iter: 488 loss: 1.39510655e-06
Iter: 489 loss: 1.39449958e-06
Iter: 490 loss: 1.39344183e-06
Iter: 491 loss: 1.39081158e-06
Iter: 492 loss: 1.41285454e-06
Iter: 493 loss: 1.39068823e-06
Iter: 494 loss: 1.38865175e-06
Iter: 495 loss: 1.38585028e-06
Iter: 496 loss: 1.38567225e-06
Iter: 497 loss: 1.38261498e-06
Iter: 498 loss: 1.41190094e-06
Iter: 499 loss: 1.38256087e-06
Iter: 500 loss: 1.38026269e-06
Iter: 501 loss: 1.3960389e-06
Iter: 502 loss: 1.3800551e-06
Iter: 503 loss: 1.37820882e-06
Iter: 504 loss: 1.3767642e-06
Iter: 505 loss: 1.3762351e-06
Iter: 506 loss: 1.37340726e-06
Iter: 507 loss: 1.39033602e-06
Iter: 508 loss: 1.37302823e-06
Iter: 509 loss: 1.37067241e-06
Iter: 510 loss: 1.3898923e-06
Iter: 511 loss: 1.37051916e-06
Iter: 512 loss: 1.36887672e-06
Iter: 513 loss: 1.36567496e-06
Iter: 514 loss: 1.43171519e-06
Iter: 515 loss: 1.36563699e-06
Iter: 516 loss: 1.36289168e-06
Iter: 517 loss: 1.37033294e-06
Iter: 518 loss: 1.3620006e-06
Iter: 519 loss: 1.35867128e-06
Iter: 520 loss: 1.36803692e-06
Iter: 521 loss: 1.35757818e-06
Iter: 522 loss: 1.35581217e-06
Iter: 523 loss: 1.35570042e-06
Iter: 524 loss: 1.35419168e-06
Iter: 525 loss: 1.35274649e-06
Iter: 526 loss: 1.35238247e-06
Iter: 527 loss: 1.34997731e-06
Iter: 528 loss: 1.35623816e-06
Iter: 529 loss: 1.34916786e-06
Iter: 530 loss: 1.34627248e-06
Iter: 531 loss: 1.3553672e-06
Iter: 532 loss: 1.34547815e-06
Iter: 533 loss: 1.34333368e-06
Iter: 534 loss: 1.3523038e-06
Iter: 535 loss: 1.34291054e-06
Iter: 536 loss: 1.34088191e-06
Iter: 537 loss: 1.3405305e-06
Iter: 538 loss: 1.33919707e-06
Iter: 539 loss: 1.33608e-06
Iter: 540 loss: 1.35521282e-06
Iter: 541 loss: 1.335653e-06
Iter: 542 loss: 1.33367405e-06
Iter: 543 loss: 1.34897482e-06
Iter: 544 loss: 1.33353387e-06
Iter: 545 loss: 1.33188314e-06
Iter: 546 loss: 1.33060269e-06
Iter: 547 loss: 1.33005369e-06
Iter: 548 loss: 1.32805076e-06
Iter: 549 loss: 1.32801733e-06
Iter: 550 loss: 1.32628509e-06
Iter: 551 loss: 1.32327534e-06
Iter: 552 loss: 1.32325374e-06
Iter: 553 loss: 1.32088906e-06
Iter: 554 loss: 1.32404261e-06
Iter: 555 loss: 1.31965612e-06
Iter: 556 loss: 1.31668776e-06
Iter: 557 loss: 1.32914397e-06
Iter: 558 loss: 1.31596971e-06
Iter: 559 loss: 1.31401418e-06
Iter: 560 loss: 1.31396519e-06
Iter: 561 loss: 1.31237221e-06
Iter: 562 loss: 1.31144395e-06
Iter: 563 loss: 1.31067213e-06
Iter: 564 loss: 1.30826129e-06
Iter: 565 loss: 1.30984313e-06
Iter: 566 loss: 1.30674198e-06
Iter: 567 loss: 1.30438184e-06
Iter: 568 loss: 1.33755839e-06
Iter: 569 loss: 1.3043699e-06
Iter: 570 loss: 1.30270314e-06
Iter: 571 loss: 1.30317198e-06
Iter: 572 loss: 1.30155115e-06
Iter: 573 loss: 1.29944704e-06
Iter: 574 loss: 1.30441595e-06
Iter: 575 loss: 1.29869227e-06
Iter: 576 loss: 1.29687385e-06
Iter: 577 loss: 1.31360048e-06
Iter: 578 loss: 1.29671992e-06
Iter: 579 loss: 1.29511841e-06
Iter: 580 loss: 1.29551086e-06
Iter: 581 loss: 1.29391242e-06
Iter: 582 loss: 1.29199964e-06
Iter: 583 loss: 1.30375588e-06
Iter: 584 loss: 1.29174236e-06
Iter: 585 loss: 1.28993383e-06
Iter: 586 loss: 1.29494924e-06
Iter: 587 loss: 1.28940394e-06
Iter: 588 loss: 1.28790055e-06
Iter: 589 loss: 1.28775798e-06
Iter: 590 loss: 1.28665647e-06
Iter: 591 loss: 1.28434647e-06
Iter: 592 loss: 1.28606507e-06
Iter: 593 loss: 1.2829687e-06
Iter: 594 loss: 1.27990734e-06
Iter: 595 loss: 1.2857729e-06
Iter: 596 loss: 1.27860199e-06
Iter: 597 loss: 1.27726048e-06
Iter: 598 loss: 1.27717055e-06
Iter: 599 loss: 1.27561077e-06
Iter: 600 loss: 1.27325825e-06
Iter: 601 loss: 1.27318913e-06
Iter: 602 loss: 1.27053124e-06
Iter: 603 loss: 1.27869725e-06
Iter: 604 loss: 1.26974885e-06
Iter: 605 loss: 1.26798409e-06
Iter: 606 loss: 1.27991643e-06
Iter: 607 loss: 1.26782595e-06
Iter: 608 loss: 1.265734e-06
Iter: 609 loss: 1.2660629e-06
Iter: 610 loss: 1.26407451e-06
Iter: 611 loss: 1.26207874e-06
Iter: 612 loss: 1.26980854e-06
Iter: 613 loss: 1.26163673e-06
Iter: 614 loss: 1.25956285e-06
Iter: 615 loss: 1.27274643e-06
Iter: 616 loss: 1.25935435e-06
Iter: 617 loss: 1.25775898e-06
Iter: 618 loss: 1.25928705e-06
Iter: 619 loss: 1.25692429e-06
Iter: 620 loss: 1.25522183e-06
Iter: 621 loss: 1.26943041e-06
Iter: 622 loss: 1.25513679e-06
Iter: 623 loss: 1.25387896e-06
Iter: 624 loss: 1.25270174e-06
Iter: 625 loss: 1.25242525e-06
Iter: 626 loss: 1.2502253e-06
Iter: 627 loss: 1.2528883e-06
Iter: 628 loss: 1.24899191e-06
Iter: 629 loss: 1.24685539e-06
Iter: 630 loss: 1.25801944e-06
Iter: 631 loss: 1.24651979e-06
Iter: 632 loss: 1.24466283e-06
Iter: 633 loss: 1.2488473e-06
Iter: 634 loss: 1.24398775e-06
Iter: 635 loss: 1.24214455e-06
Iter: 636 loss: 1.25600309e-06
Iter: 637 loss: 1.24202052e-06
Iter: 638 loss: 1.24026872e-06
Iter: 639 loss: 1.24132339e-06
Iter: 640 loss: 1.23916323e-06
Iter: 641 loss: 1.23739756e-06
Iter: 642 loss: 1.2380558e-06
Iter: 643 loss: 1.23617792e-06
Iter: 644 loss: 1.2340704e-06
Iter: 645 loss: 1.24283179e-06
Iter: 646 loss: 1.23358e-06
Iter: 647 loss: 1.23194081e-06
Iter: 648 loss: 1.24515407e-06
Iter: 649 loss: 1.23184418e-06
Iter: 650 loss: 1.23011705e-06
Iter: 651 loss: 1.23060522e-06
Iter: 652 loss: 1.22891288e-06
Iter: 653 loss: 1.2271646e-06
Iter: 654 loss: 1.24095584e-06
Iter: 655 loss: 1.22704228e-06
Iter: 656 loss: 1.22549261e-06
Iter: 657 loss: 1.22988035e-06
Iter: 658 loss: 1.22499796e-06
Iter: 659 loss: 1.22355277e-06
Iter: 660 loss: 1.22443453e-06
Iter: 661 loss: 1.22258393e-06
Iter: 662 loss: 1.22060237e-06
Iter: 663 loss: 1.23016287e-06
Iter: 664 loss: 1.22025256e-06
Iter: 665 loss: 1.21891321e-06
Iter: 666 loss: 1.21717881e-06
Iter: 667 loss: 1.21706523e-06
Iter: 668 loss: 1.21465962e-06
Iter: 669 loss: 1.21958124e-06
Iter: 670 loss: 1.21374433e-06
Iter: 671 loss: 1.21212327e-06
Iter: 672 loss: 1.2121053e-06
Iter: 673 loss: 1.21077062e-06
Iter: 674 loss: 1.21314542e-06
Iter: 675 loss: 1.21014477e-06
Iter: 676 loss: 1.20871073e-06
Iter: 677 loss: 1.2106766e-06
Iter: 678 loss: 1.20791526e-06
Iter: 679 loss: 1.20621144e-06
Iter: 680 loss: 1.20716e-06
Iter: 681 loss: 1.20511208e-06
Iter: 682 loss: 1.20318919e-06
Iter: 683 loss: 1.20788877e-06
Iter: 684 loss: 1.20255788e-06
Iter: 685 loss: 1.20079017e-06
Iter: 686 loss: 1.21521771e-06
Iter: 687 loss: 1.20071115e-06
Iter: 688 loss: 1.19887193e-06
Iter: 689 loss: 1.20081882e-06
Iter: 690 loss: 1.19788604e-06
Iter: 691 loss: 1.19648791e-06
Iter: 692 loss: 1.21178255e-06
Iter: 693 loss: 1.19641868e-06
Iter: 694 loss: 1.19520041e-06
Iter: 695 loss: 1.19564902e-06
Iter: 696 loss: 1.194378e-06
Iter: 697 loss: 1.19302058e-06
Iter: 698 loss: 1.19658523e-06
Iter: 699 loss: 1.19257675e-06
Iter: 700 loss: 1.19090305e-06
Iter: 701 loss: 1.19284311e-06
Iter: 702 loss: 1.18995308e-06
Iter: 703 loss: 1.1883252e-06
Iter: 704 loss: 1.19295476e-06
Iter: 705 loss: 1.18778325e-06
Iter: 706 loss: 1.18629373e-06
Iter: 707 loss: 1.18534763e-06
Iter: 708 loss: 1.18479829e-06
Iter: 709 loss: 1.18253956e-06
Iter: 710 loss: 1.19649064e-06
Iter: 711 loss: 1.18228138e-06
Iter: 712 loss: 1.1807391e-06
Iter: 713 loss: 1.20478171e-06
Iter: 714 loss: 1.18070648e-06
Iter: 715 loss: 1.17961577e-06
Iter: 716 loss: 1.17848163e-06
Iter: 717 loss: 1.17828449e-06
Iter: 718 loss: 1.17636978e-06
Iter: 719 loss: 1.17756554e-06
Iter: 720 loss: 1.17508466e-06
Iter: 721 loss: 1.17268257e-06
Iter: 722 loss: 1.18697335e-06
Iter: 723 loss: 1.17237255e-06
Iter: 724 loss: 1.17061199e-06
Iter: 725 loss: 1.1821719e-06
Iter: 726 loss: 1.17045226e-06
Iter: 727 loss: 1.16914418e-06
Iter: 728 loss: 1.17693412e-06
Iter: 729 loss: 1.16902743e-06
Iter: 730 loss: 1.16781655e-06
Iter: 731 loss: 1.16790329e-06
Iter: 732 loss: 1.16686658e-06
Iter: 733 loss: 1.1652628e-06
Iter: 734 loss: 1.17580385e-06
Iter: 735 loss: 1.16516981e-06
Iter: 736 loss: 1.16400338e-06
Iter: 737 loss: 1.16491685e-06
Iter: 738 loss: 1.16338731e-06
Iter: 739 loss: 1.16221554e-06
Iter: 740 loss: 1.16564274e-06
Iter: 741 loss: 1.16187994e-06
Iter: 742 loss: 1.16033721e-06
Iter: 743 loss: 1.16000342e-06
Iter: 744 loss: 1.1589641e-06
Iter: 745 loss: 1.15734156e-06
Iter: 746 loss: 1.15769376e-06
Iter: 747 loss: 1.15616274e-06
Iter: 748 loss: 1.15385342e-06
Iter: 749 loss: 1.16474121e-06
Iter: 750 loss: 1.15340913e-06
Iter: 751 loss: 1.15217267e-06
Iter: 752 loss: 1.15210355e-06
Iter: 753 loss: 1.15102068e-06
Iter: 754 loss: 1.15033799e-06
Iter: 755 loss: 1.14987824e-06
Iter: 756 loss: 1.14817544e-06
Iter: 757 loss: 1.15041257e-06
Iter: 758 loss: 1.14732666e-06
Iter: 759 loss: 1.14579359e-06
Iter: 760 loss: 1.14923239e-06
Iter: 761 loss: 1.14525096e-06
Iter: 762 loss: 1.14380964e-06
Iter: 763 loss: 1.15561181e-06
Iter: 764 loss: 1.14368481e-06
Iter: 765 loss: 1.14227259e-06
Iter: 766 loss: 1.14681848e-06
Iter: 767 loss: 1.14186219e-06
Iter: 768 loss: 1.14059617e-06
Iter: 769 loss: 1.14460704e-06
Iter: 770 loss: 1.1402276e-06
Iter: 771 loss: 1.13920851e-06
Iter: 772 loss: 1.14286138e-06
Iter: 773 loss: 1.13894725e-06
Iter: 774 loss: 1.1378113e-06
Iter: 775 loss: 1.13728049e-06
Iter: 776 loss: 1.13677811e-06
Iter: 777 loss: 1.13504962e-06
Iter: 778 loss: 1.14181535e-06
Iter: 779 loss: 1.13464057e-06
Iter: 780 loss: 1.13312205e-06
Iter: 781 loss: 1.13835267e-06
Iter: 782 loss: 1.1327304e-06
Iter: 783 loss: 1.13135854e-06
Iter: 784 loss: 1.13403394e-06
Iter: 785 loss: 1.13076214e-06
Iter: 786 loss: 1.12951261e-06
Iter: 787 loss: 1.13089197e-06
Iter: 788 loss: 1.12878092e-06
Iter: 789 loss: 1.12736348e-06
Iter: 790 loss: 1.13215333e-06
Iter: 791 loss: 1.12694988e-06
Iter: 792 loss: 1.12582723e-06
Iter: 793 loss: 1.14100271e-06
Iter: 794 loss: 1.12579505e-06
Iter: 795 loss: 1.12475618e-06
Iter: 796 loss: 1.1232728e-06
Iter: 797 loss: 1.12324528e-06
Iter: 798 loss: 1.12162343e-06
Iter: 799 loss: 1.12144176e-06
Iter: 800 loss: 1.12030648e-06
Iter: 801 loss: 1.11836584e-06
Iter: 802 loss: 1.14094451e-06
Iter: 803 loss: 1.11829013e-06
Iter: 804 loss: 1.11727923e-06
Iter: 805 loss: 1.11728514e-06
Iter: 806 loss: 1.11653458e-06
Iter: 807 loss: 1.11534405e-06
Iter: 808 loss: 1.11533882e-06
Iter: 809 loss: 1.11376062e-06
Iter: 810 loss: 1.12321516e-06
Iter: 811 loss: 1.1135387e-06
Iter: 812 loss: 1.11232282e-06
Iter: 813 loss: 1.11488782e-06
Iter: 814 loss: 1.11180191e-06
Iter: 815 loss: 1.11067106e-06
Iter: 816 loss: 1.11305167e-06
Iter: 817 loss: 1.11023201e-06
Iter: 818 loss: 1.10903829e-06
Iter: 819 loss: 1.11332906e-06
Iter: 820 loss: 1.10874328e-06
Iter: 821 loss: 1.10767269e-06
Iter: 822 loss: 1.10976453e-06
Iter: 823 loss: 1.10713529e-06
Iter: 824 loss: 1.10596011e-06
Iter: 825 loss: 1.10662745e-06
Iter: 826 loss: 1.10522035e-06
Iter: 827 loss: 1.10361395e-06
Iter: 828 loss: 1.11006534e-06
Iter: 829 loss: 1.10328131e-06
Iter: 830 loss: 1.10207452e-06
Iter: 831 loss: 1.10965459e-06
Iter: 832 loss: 1.10195845e-06
Iter: 833 loss: 1.10061342e-06
Iter: 834 loss: 1.10215228e-06
Iter: 835 loss: 1.09995403e-06
Iter: 836 loss: 1.09860935e-06
Iter: 837 loss: 1.09868506e-06
Iter: 838 loss: 1.09756104e-06
Iter: 839 loss: 1.09604059e-06
Iter: 840 loss: 1.10057613e-06
Iter: 841 loss: 1.09556595e-06
Iter: 842 loss: 1.09408927e-06
Iter: 843 loss: 1.0962591e-06
Iter: 844 loss: 1.09332348e-06
Iter: 845 loss: 1.09251891e-06
Iter: 846 loss: 1.09228199e-06
Iter: 847 loss: 1.09153871e-06
Iter: 848 loss: 1.09093708e-06
Iter: 849 loss: 1.09073426e-06
Iter: 850 loss: 1.08958159e-06
Iter: 851 loss: 1.08993163e-06
Iter: 852 loss: 1.08878612e-06
Iter: 853 loss: 1.08727443e-06
Iter: 854 loss: 1.10488668e-06
Iter: 855 loss: 1.0872759e-06
Iter: 856 loss: 1.08652955e-06
Iter: 857 loss: 1.08530628e-06
Iter: 858 loss: 1.08525694e-06
Iter: 859 loss: 1.08392032e-06
Iter: 860 loss: 1.10131668e-06
Iter: 861 loss: 1.08390145e-06
Iter: 862 loss: 1.08291101e-06
Iter: 863 loss: 1.08321888e-06
Iter: 864 loss: 1.08214817e-06
Iter: 865 loss: 1.08102665e-06
Iter: 866 loss: 1.08469476e-06
Iter: 867 loss: 1.08075244e-06
Iter: 868 loss: 1.079453e-06
Iter: 869 loss: 1.08019753e-06
Iter: 870 loss: 1.07862388e-06
Iter: 871 loss: 1.07728988e-06
Iter: 872 loss: 1.0966553e-06
Iter: 873 loss: 1.07730921e-06
Iter: 874 loss: 1.07639585e-06
Iter: 875 loss: 1.07680444e-06
Iter: 876 loss: 1.07571611e-06
Iter: 877 loss: 1.07460903e-06
Iter: 878 loss: 1.0754577e-06
Iter: 879 loss: 1.07396352e-06
Iter: 880 loss: 1.07253345e-06
Iter: 881 loss: 1.07275582e-06
Iter: 882 loss: 1.0715014e-06
Iter: 883 loss: 1.07081075e-06
Iter: 884 loss: 1.07055371e-06
Iter: 885 loss: 1.06970447e-06
Iter: 886 loss: 1.06901643e-06
Iter: 887 loss: 1.06873154e-06
Iter: 888 loss: 1.06738344e-06
Iter: 889 loss: 1.06802918e-06
Iter: 890 loss: 1.06651828e-06
Iter: 891 loss: 1.06521441e-06
Iter: 892 loss: 1.07367032e-06
Iter: 893 loss: 1.06509049e-06
Iter: 894 loss: 1.06415632e-06
Iter: 895 loss: 1.07123924e-06
Iter: 896 loss: 1.06404354e-06
Iter: 897 loss: 1.06311347e-06
Iter: 898 loss: 1.0621543e-06
Iter: 899 loss: 1.06194943e-06
Iter: 900 loss: 1.06074936e-06
Iter: 901 loss: 1.06385312e-06
Iter: 902 loss: 1.06036953e-06
Iter: 903 loss: 1.05898744e-06
Iter: 904 loss: 1.06014625e-06
Iter: 905 loss: 1.05813092e-06
Iter: 906 loss: 1.05714423e-06
Iter: 907 loss: 1.0570393e-06
Iter: 908 loss: 1.05631182e-06
Iter: 909 loss: 1.05571326e-06
Iter: 910 loss: 1.0555566e-06
Iter: 911 loss: 1.05417757e-06
Iter: 912 loss: 1.05632171e-06
Iter: 913 loss: 1.05352922e-06
Iter: 914 loss: 1.05208255e-06
Iter: 915 loss: 1.05717959e-06
Iter: 916 loss: 1.05173558e-06
Iter: 917 loss: 1.05076356e-06
Iter: 918 loss: 1.06072366e-06
Iter: 919 loss: 1.05074707e-06
Iter: 920 loss: 1.04998048e-06
Iter: 921 loss: 1.05001368e-06
Iter: 922 loss: 1.0494125e-06
Iter: 923 loss: 1.04819458e-06
Iter: 924 loss: 1.05634535e-06
Iter: 925 loss: 1.048081e-06
Iter: 926 loss: 1.04732305e-06
Iter: 927 loss: 1.04671881e-06
Iter: 928 loss: 1.04645187e-06
Iter: 929 loss: 1.04538822e-06
Iter: 930 loss: 1.04554852e-06
Iter: 931 loss: 1.04452761e-06
Iter: 932 loss: 1.04335072e-06
Iter: 933 loss: 1.0433746e-06
Iter: 934 loss: 1.04252331e-06
Iter: 935 loss: 1.04352011e-06
Iter: 936 loss: 1.042034e-06
Iter: 937 loss: 1.04113246e-06
Iter: 938 loss: 1.04090827e-06
Iter: 939 loss: 1.0403088e-06
Iter: 940 loss: 1.03890102e-06
Iter: 941 loss: 1.04216952e-06
Iter: 942 loss: 1.03836896e-06
Iter: 943 loss: 1.03721914e-06
Iter: 944 loss: 1.05418496e-06
Iter: 945 loss: 1.03722118e-06
Iter: 946 loss: 1.03624927e-06
Iter: 947 loss: 1.03676462e-06
Iter: 948 loss: 1.03560478e-06
Iter: 949 loss: 1.034619e-06
Iter: 950 loss: 1.03581419e-06
Iter: 951 loss: 1.03415164e-06
Iter: 952 loss: 1.03303796e-06
Iter: 953 loss: 1.03719822e-06
Iter: 954 loss: 1.03276011e-06
Iter: 955 loss: 1.03169725e-06
Iter: 956 loss: 1.0376699e-06
Iter: 957 loss: 1.03155207e-06
Iter: 958 loss: 1.03078582e-06
Iter: 959 loss: 1.03473269e-06
Iter: 960 loss: 1.03068191e-06
Iter: 961 loss: 1.0299766e-06
Iter: 962 loss: 1.03110483e-06
Iter: 963 loss: 1.02962917e-06
Iter: 964 loss: 1.02886656e-06
Iter: 965 loss: 1.0289541e-06
Iter: 966 loss: 1.02827357e-06
Iter: 967 loss: 1.0270852e-06
Iter: 968 loss: 1.02794752e-06
Iter: 969 loss: 1.02633612e-06
Iter: 970 loss: 1.02523109e-06
Iter: 971 loss: 1.02750312e-06
Iter: 972 loss: 1.02476292e-06
Iter: 973 loss: 1.0235517e-06
Iter: 974 loss: 1.02947388e-06
Iter: 975 loss: 1.02336048e-06
Iter: 976 loss: 1.02224681e-06
Iter: 977 loss: 1.03258162e-06
Iter: 978 loss: 1.0222526e-06
Iter: 979 loss: 1.02153763e-06
Iter: 980 loss: 1.02036518e-06
Iter: 981 loss: 1.02030549e-06
Iter: 982 loss: 1.01923115e-06
Iter: 983 loss: 1.02483534e-06
Iter: 984 loss: 1.01901719e-06
Iter: 985 loss: 1.01795251e-06
Iter: 986 loss: 1.02373497e-06
Iter: 987 loss: 1.01781166e-06
Iter: 988 loss: 1.01681485e-06
Iter: 989 loss: 1.02345257e-06
Iter: 990 loss: 1.01679689e-06
Iter: 991 loss: 1.01611158e-06
Iter: 992 loss: 1.01493083e-06
Iter: 993 loss: 1.01497449e-06
Iter: 994 loss: 1.01398734e-06
Iter: 995 loss: 1.02638523e-06
Iter: 996 loss: 1.01401247e-06
Iter: 997 loss: 1.01320211e-06
Iter: 998 loss: 1.01461467e-06
Iter: 999 loss: 1.01286719e-06
Iter: 1000 loss: 1.01189721e-06
Iter: 1001 loss: 1.01640751e-06
Iter: 1002 loss: 1.01170122e-06
Iter: 1003 loss: 1.01089108e-06
Iter: 1004 loss: 1.01417436e-06
Iter: 1005 loss: 1.01075682e-06
Iter: 1006 loss: 1.01012461e-06
Iter: 1007 loss: 1.01003218e-06
Iter: 1008 loss: 1.00962029e-06
Iter: 1009 loss: 1.00859643e-06
Iter: 1010 loss: 1.0083412e-06
Iter: 1011 loss: 1.00764566e-06
Iter: 1012 loss: 1.00645468e-06
Iter: 1013 loss: 1.01562455e-06
Iter: 1014 loss: 1.00637078e-06
Iter: 1015 loss: 1.00542229e-06
Iter: 1016 loss: 1.00590023e-06
Iter: 1017 loss: 1.00484795e-06
Iter: 1018 loss: 1.00349189e-06
Iter: 1019 loss: 1.00336786e-06
Iter: 1020 loss: 1.00238753e-06
Iter: 1021 loss: 1.00128443e-06
Iter: 1022 loss: 1.01904652e-06
Iter: 1023 loss: 1.00126226e-06
Iter: 1024 loss: 1.00042917e-06
Iter: 1025 loss: 1.00873422e-06
Iter: 1026 loss: 1.00043712e-06
Iter: 1027 loss: 9.99749091e-07
Iter: 1028 loss: 9.99135e-07
Iter: 1029 loss: 9.99036502e-07
Iter: 1030 loss: 9.98024916e-07
Iter: 1031 loss: 1.00121451e-06
Iter: 1032 loss: 9.9775491e-07
Iter: 1033 loss: 9.96944664e-07
Iter: 1034 loss: 1.00647958e-06
Iter: 1035 loss: 9.96937388e-07
Iter: 1036 loss: 9.96207177e-07
Iter: 1037 loss: 9.95412165e-07
Iter: 1038 loss: 9.95337132e-07
Iter: 1039 loss: 9.9440058e-07
Iter: 1040 loss: 1.00375598e-06
Iter: 1041 loss: 9.94347147e-07
Iter: 1042 loss: 9.93452886e-07
Iter: 1043 loss: 9.95173195e-07
Iter: 1044 loss: 9.93097387e-07
Iter: 1045 loss: 9.92386276e-07
Iter: 1046 loss: 9.93761546e-07
Iter: 1047 loss: 9.92088871e-07
Iter: 1048 loss: 9.91119805e-07
Iter: 1049 loss: 9.91795559e-07
Iter: 1050 loss: 9.90529202e-07
Iter: 1051 loss: 9.89602199e-07
Iter: 1052 loss: 9.93382628e-07
Iter: 1053 loss: 9.89380737e-07
Iter: 1054 loss: 9.88599822e-07
Iter: 1055 loss: 9.90253284e-07
Iter: 1056 loss: 9.88249212e-07
Iter: 1057 loss: 9.87353e-07
Iter: 1058 loss: 9.87686235e-07
Iter: 1059 loss: 9.86722e-07
Iter: 1060 loss: 9.85580755e-07
Iter: 1061 loss: 9.88017746e-07
Iter: 1062 loss: 9.85074621e-07
Iter: 1063 loss: 9.83949121e-07
Iter: 1064 loss: 9.89950422e-07
Iter: 1065 loss: 9.83744e-07
Iter: 1066 loss: 9.82712322e-07
Iter: 1067 loss: 9.85156476e-07
Iter: 1068 loss: 9.82364099e-07
Iter: 1069 loss: 9.81337166e-07
Iter: 1070 loss: 9.91798629e-07
Iter: 1071 loss: 9.81317271e-07
Iter: 1072 loss: 9.80556479e-07
Iter: 1073 loss: 9.80552386e-07
Iter: 1074 loss: 9.79959623e-07
Iter: 1075 loss: 9.79176207e-07
Iter: 1076 loss: 9.82559641e-07
Iter: 1077 loss: 9.79057177e-07
Iter: 1078 loss: 9.78158937e-07
Iter: 1079 loss: 9.8305236e-07
Iter: 1080 loss: 9.78074809e-07
Iter: 1081 loss: 9.77576747e-07
Iter: 1082 loss: 9.77733293e-07
Iter: 1083 loss: 9.77177e-07
Iter: 1084 loss: 9.76391675e-07
Iter: 1085 loss: 9.79825245e-07
Iter: 1086 loss: 9.76218416e-07
Iter: 1087 loss: 9.75487183e-07
Iter: 1088 loss: 9.75087687e-07
Iter: 1089 loss: 9.74755e-07
Iter: 1090 loss: 9.73785063e-07
Iter: 1091 loss: 9.7629254e-07
Iter: 1092 loss: 9.73452643e-07
Iter: 1093 loss: 9.72570206e-07
Iter: 1094 loss: 9.79130391e-07
Iter: 1095 loss: 9.72521434e-07
Iter: 1096 loss: 9.71573172e-07
Iter: 1097 loss: 9.71107397e-07
Iter: 1098 loss: 9.7065481e-07
Iter: 1099 loss: 9.69607e-07
Iter: 1100 loss: 9.73151145e-07
Iter: 1101 loss: 9.69298753e-07
Iter: 1102 loss: 9.68431095e-07
Iter: 1103 loss: 9.73411e-07
Iter: 1104 loss: 9.68301492e-07
Iter: 1105 loss: 9.6752035e-07
Iter: 1106 loss: 9.69280336e-07
Iter: 1107 loss: 9.67284905e-07
Iter: 1108 loss: 9.66542757e-07
Iter: 1109 loss: 9.6748829e-07
Iter: 1110 loss: 9.66127459e-07
Iter: 1111 loss: 9.65318577e-07
Iter: 1112 loss: 9.7600423e-07
Iter: 1113 loss: 9.65352456e-07
Iter: 1114 loss: 9.64701144e-07
Iter: 1115 loss: 9.64074161e-07
Iter: 1116 loss: 9.63921821e-07
Iter: 1117 loss: 9.63321327e-07
Iter: 1118 loss: 9.6336862e-07
Iter: 1119 loss: 9.62801778e-07
Iter: 1120 loss: 9.61809e-07
Iter: 1121 loss: 9.86921691e-07
Iter: 1122 loss: 9.61814294e-07
Iter: 1123 loss: 9.60791795e-07
Iter: 1124 loss: 9.69998609e-07
Iter: 1125 loss: 9.60743137e-07
Iter: 1126 loss: 9.60084208e-07
Iter: 1127 loss: 9.63669095e-07
Iter: 1128 loss: 9.59951876e-07
Iter: 1129 loss: 9.59402541e-07
Iter: 1130 loss: 9.58357532e-07
Iter: 1131 loss: 9.82234724e-07
Iter: 1132 loss: 9.58393e-07
Iter: 1133 loss: 9.57375391e-07
Iter: 1134 loss: 9.63658749e-07
Iter: 1135 loss: 9.57239649e-07
Iter: 1136 loss: 9.56307e-07
Iter: 1137 loss: 9.60707439e-07
Iter: 1138 loss: 9.56155532e-07
Iter: 1139 loss: 9.5528e-07
Iter: 1140 loss: 9.57987822e-07
Iter: 1141 loss: 9.55061523e-07
Iter: 1142 loss: 9.54308916e-07
Iter: 1143 loss: 9.54242e-07
Iter: 1144 loss: 9.53676135e-07
Iter: 1145 loss: 9.52566e-07
Iter: 1146 loss: 9.54337679e-07
Iter: 1147 loss: 9.52017729e-07
Iter: 1148 loss: 9.50994377e-07
Iter: 1149 loss: 9.57080942e-07
Iter: 1150 loss: 9.50809294e-07
Iter: 1151 loss: 9.50154572e-07
Iter: 1152 loss: 9.50137633e-07
Iter: 1153 loss: 9.49591708e-07
Iter: 1154 loss: 9.49202331e-07
Iter: 1155 loss: 9.49024127e-07
Iter: 1156 loss: 9.48183697e-07
Iter: 1157 loss: 9.53772314e-07
Iter: 1158 loss: 9.48082629e-07
Iter: 1159 loss: 9.47348269e-07
Iter: 1160 loss: 9.49034245e-07
Iter: 1161 loss: 9.47095543e-07
Iter: 1162 loss: 9.46343221e-07
Iter: 1163 loss: 9.4673652e-07
Iter: 1164 loss: 9.45866759e-07
Iter: 1165 loss: 9.4512518e-07
Iter: 1166 loss: 9.48629918e-07
Iter: 1167 loss: 9.45048271e-07
Iter: 1168 loss: 9.4433517e-07
Iter: 1169 loss: 9.47033925e-07
Iter: 1170 loss: 9.44186866e-07
Iter: 1171 loss: 9.43554824e-07
Iter: 1172 loss: 9.42827683e-07
Iter: 1173 loss: 9.42781071e-07
Iter: 1174 loss: 9.41701501e-07
Iter: 1175 loss: 9.45003251e-07
Iter: 1176 loss: 9.41392e-07
Iter: 1177 loss: 9.4047931e-07
Iter: 1178 loss: 9.43083364e-07
Iter: 1179 loss: 9.40162863e-07
Iter: 1180 loss: 9.39281222e-07
Iter: 1181 loss: 9.421492e-07
Iter: 1182 loss: 9.39035033e-07
Iter: 1183 loss: 9.3803169e-07
Iter: 1184 loss: 9.45149e-07
Iter: 1185 loss: 9.37925449e-07
Iter: 1186 loss: 9.37331833e-07
Iter: 1187 loss: 9.37349796e-07
Iter: 1188 loss: 9.36936317e-07
Iter: 1189 loss: 9.35997036e-07
Iter: 1190 loss: 9.3555434e-07
Iter: 1191 loss: 9.35178491e-07
Iter: 1192 loss: 9.34409229e-07
Iter: 1193 loss: 9.34406899e-07
Iter: 1194 loss: 9.33746492e-07
Iter: 1195 loss: 9.36329911e-07
Iter: 1196 loss: 9.33669469e-07
Iter: 1197 loss: 9.3298479e-07
Iter: 1198 loss: 9.33040496e-07
Iter: 1199 loss: 9.3242204e-07
Iter: 1200 loss: 9.31704e-07
Iter: 1201 loss: 9.38376502e-07
Iter: 1202 loss: 9.31681825e-07
Iter: 1203 loss: 9.31050806e-07
Iter: 1204 loss: 9.31585419e-07
Iter: 1205 loss: 9.30706108e-07
Iter: 1206 loss: 9.30037913e-07
Iter: 1207 loss: 9.30198439e-07
Iter: 1208 loss: 9.2957265e-07
Iter: 1209 loss: 9.28643487e-07
Iter: 1210 loss: 9.35018079e-07
Iter: 1211 loss: 9.28582153e-07
Iter: 1212 loss: 9.27974213e-07
Iter: 1213 loss: 9.30124884e-07
Iter: 1214 loss: 9.2780931e-07
Iter: 1215 loss: 9.27261283e-07
Iter: 1216 loss: 9.26899304e-07
Iter: 1217 loss: 9.26674716e-07
Iter: 1218 loss: 9.25706104e-07
Iter: 1219 loss: 9.2698383e-07
Iter: 1220 loss: 9.25292227e-07
Iter: 1221 loss: 9.24394897e-07
Iter: 1222 loss: 9.30184967e-07
Iter: 1223 loss: 9.24332369e-07
Iter: 1224 loss: 9.23617506e-07
Iter: 1225 loss: 9.24014955e-07
Iter: 1226 loss: 9.23170774e-07
Iter: 1227 loss: 9.22281743e-07
Iter: 1228 loss: 9.33064939e-07
Iter: 1229 loss: 9.22299137e-07
Iter: 1230 loss: 9.21734852e-07
Iter: 1231 loss: 9.21353376e-07
Iter: 1232 loss: 9.21143453e-07
Iter: 1233 loss: 9.20269713e-07
Iter: 1234 loss: 9.20542846e-07
Iter: 1235 loss: 9.19587819e-07
Iter: 1236 loss: 9.18935882e-07
Iter: 1237 loss: 9.18902e-07
Iter: 1238 loss: 9.18176e-07
Iter: 1239 loss: 9.20507091e-07
Iter: 1240 loss: 9.1792964e-07
Iter: 1241 loss: 9.17396619e-07
Iter: 1242 loss: 9.17261332e-07
Iter: 1243 loss: 9.16918054e-07
Iter: 1244 loss: 9.16206716e-07
Iter: 1245 loss: 9.24783251e-07
Iter: 1246 loss: 9.16234967e-07
Iter: 1247 loss: 9.15772375e-07
Iter: 1248 loss: 9.15454621e-07
Iter: 1249 loss: 9.15291594e-07
Iter: 1250 loss: 9.14522047e-07
Iter: 1251 loss: 9.14460031e-07
Iter: 1252 loss: 9.13875738e-07
Iter: 1253 loss: 9.13004214e-07
Iter: 1254 loss: 9.12996484e-07
Iter: 1255 loss: 9.12423673e-07
Iter: 1256 loss: 9.11903953e-07
Iter: 1257 loss: 9.1177634e-07
Iter: 1258 loss: 9.11013785e-07
Iter: 1259 loss: 9.11854158e-07
Iter: 1260 loss: 9.10641802e-07
Iter: 1261 loss: 9.09770165e-07
Iter: 1262 loss: 9.15801365e-07
Iter: 1263 loss: 9.09666312e-07
Iter: 1264 loss: 9.08974698e-07
Iter: 1265 loss: 9.09953201e-07
Iter: 1266 loss: 9.08682523e-07
Iter: 1267 loss: 9.07847891e-07
Iter: 1268 loss: 9.0959503e-07
Iter: 1269 loss: 9.07481308e-07
Iter: 1270 loss: 9.06694936e-07
Iter: 1271 loss: 9.14713041e-07
Iter: 1272 loss: 9.06710682e-07
Iter: 1273 loss: 9.06190962e-07
Iter: 1274 loss: 9.0577214e-07
Iter: 1275 loss: 9.056198e-07
Iter: 1276 loss: 9.04853891e-07
Iter: 1277 loss: 9.11555105e-07
Iter: 1278 loss: 9.04839453e-07
Iter: 1279 loss: 9.04228102e-07
Iter: 1280 loss: 9.08122615e-07
Iter: 1281 loss: 9.04137664e-07
Iter: 1282 loss: 9.03655859e-07
Iter: 1283 loss: 9.03024e-07
Iter: 1284 loss: 9.02970612e-07
Iter: 1285 loss: 9.02247791e-07
Iter: 1286 loss: 9.0465528e-07
Iter: 1287 loss: 9.0205657e-07
Iter: 1288 loss: 9.01504393e-07
Iter: 1289 loss: 9.01513317e-07
Iter: 1290 loss: 9.0109188e-07
Iter: 1291 loss: 9.00534701e-07
Iter: 1292 loss: 9.00503892e-07
Iter: 1293 loss: 8.99709221e-07
Iter: 1294 loss: 9.00748091e-07
Iter: 1295 loss: 8.99308134e-07
Iter: 1296 loss: 8.98530402e-07
Iter: 1297 loss: 9.03705654e-07
Iter: 1298 loss: 8.98485212e-07
Iter: 1299 loss: 8.97800362e-07
Iter: 1300 loss: 9.02278089e-07
Iter: 1301 loss: 8.9775358e-07
Iter: 1302 loss: 8.97295308e-07
Iter: 1303 loss: 8.96402526e-07
Iter: 1304 loss: 9.15398061e-07
Iter: 1305 loss: 8.9638911e-07
Iter: 1306 loss: 8.9532341e-07
Iter: 1307 loss: 9.00261057e-07
Iter: 1308 loss: 8.9514873e-07
Iter: 1309 loss: 8.94307959e-07
Iter: 1310 loss: 8.98983217e-07
Iter: 1311 loss: 8.94213144e-07
Iter: 1312 loss: 8.93553477e-07
Iter: 1313 loss: 8.95333358e-07
Iter: 1314 loss: 8.93302854e-07
Iter: 1315 loss: 8.92517846e-07
Iter: 1316 loss: 8.92867774e-07
Iter: 1317 loss: 8.92001822e-07
Iter: 1318 loss: 8.91541049e-07
Iter: 1319 loss: 8.91454079e-07
Iter: 1320 loss: 8.90986257e-07
Iter: 1321 loss: 8.90933507e-07
Iter: 1322 loss: 8.90618651e-07
Iter: 1323 loss: 8.89918795e-07
Iter: 1324 loss: 8.92242838e-07
Iter: 1325 loss: 8.89726095e-07
Iter: 1326 loss: 8.89145269e-07
Iter: 1327 loss: 8.89321598e-07
Iter: 1328 loss: 8.88713203e-07
Iter: 1329 loss: 8.88012039e-07
Iter: 1330 loss: 8.89503212e-07
Iter: 1331 loss: 8.87712758e-07
Iter: 1332 loss: 8.87099304e-07
Iter: 1333 loss: 8.9262744e-07
Iter: 1334 loss: 8.87049055e-07
Iter: 1335 loss: 8.86394332e-07
Iter: 1336 loss: 8.86571513e-07
Iter: 1337 loss: 8.85919349e-07
Iter: 1338 loss: 8.85226541e-07
Iter: 1339 loss: 8.86229429e-07
Iter: 1340 loss: 8.84892415e-07
Iter: 1341 loss: 8.84219617e-07
Iter: 1342 loss: 8.85522354e-07
Iter: 1343 loss: 8.83947166e-07
Iter: 1344 loss: 8.83137e-07
Iter: 1345 loss: 8.90442834e-07
Iter: 1346 loss: 8.83143287e-07
Iter: 1347 loss: 8.82534323e-07
Iter: 1348 loss: 8.82387098e-07
Iter: 1349 loss: 8.81998346e-07
Iter: 1350 loss: 8.81254e-07
Iter: 1351 loss: 8.82179847e-07
Iter: 1352 loss: 8.80860739e-07
Iter: 1353 loss: 8.80073401e-07
Iter: 1354 loss: 8.81229653e-07
Iter: 1355 loss: 8.79671859e-07
Iter: 1356 loss: 8.79157142e-07
Iter: 1357 loss: 8.79131e-07
Iter: 1358 loss: 8.78638275e-07
Iter: 1359 loss: 8.79853872e-07
Iter: 1360 loss: 8.78491107e-07
Iter: 1361 loss: 8.77984633e-07
Iter: 1362 loss: 8.7780893e-07
Iter: 1363 loss: 8.77571267e-07
Iter: 1364 loss: 8.76824913e-07
Iter: 1365 loss: 8.788831e-07
Iter: 1366 loss: 8.76636591e-07
Iter: 1367 loss: 8.75869887e-07
Iter: 1368 loss: 8.77679668e-07
Iter: 1369 loss: 8.75643195e-07
Iter: 1370 loss: 8.748857e-07
Iter: 1371 loss: 8.78335413e-07
Iter: 1372 loss: 8.74764453e-07
Iter: 1373 loss: 8.74212333e-07
Iter: 1374 loss: 8.75459932e-07
Iter: 1375 loss: 8.74038619e-07
Iter: 1376 loss: 8.7337088e-07
Iter: 1377 loss: 8.7488047e-07
Iter: 1378 loss: 8.73121962e-07
Iter: 1379 loss: 8.72371402e-07
Iter: 1380 loss: 8.7322428e-07
Iter: 1381 loss: 8.72081159e-07
Iter: 1382 loss: 8.71452926e-07
Iter: 1383 loss: 8.71457701e-07
Iter: 1384 loss: 8.70943e-07
Iter: 1385 loss: 8.70123e-07
Iter: 1386 loss: 8.75697424e-07
Iter: 1387 loss: 8.70007398e-07
Iter: 1388 loss: 8.69418045e-07
Iter: 1389 loss: 8.76352431e-07
Iter: 1390 loss: 8.69383769e-07
Iter: 1391 loss: 8.68939367e-07
Iter: 1392 loss: 8.68282314e-07
Iter: 1393 loss: 8.68235361e-07
Iter: 1394 loss: 8.6741727e-07
Iter: 1395 loss: 8.71761813e-07
Iter: 1396 loss: 8.6731643e-07
Iter: 1397 loss: 8.66723894e-07
Iter: 1398 loss: 8.68749453e-07
Iter: 1399 loss: 8.66609071e-07
Iter: 1400 loss: 8.65806896e-07
Iter: 1401 loss: 8.68718871e-07
Iter: 1402 loss: 8.65600668e-07
Iter: 1403 loss: 8.6509624e-07
Iter: 1404 loss: 8.64752792e-07
Iter: 1405 loss: 8.64589083e-07
Iter: 1406 loss: 8.63862851e-07
Iter: 1407 loss: 8.65732488e-07
Iter: 1408 loss: 8.63652303e-07
Iter: 1409 loss: 8.62795446e-07
Iter: 1410 loss: 8.67367703e-07
Iter: 1411 loss: 8.62684942e-07
Iter: 1412 loss: 8.62024535e-07
Iter: 1413 loss: 8.63973355e-07
Iter: 1414 loss: 8.61830415e-07
Iter: 1415 loss: 8.61313708e-07
Iter: 1416 loss: 8.64531e-07
Iter: 1417 loss: 8.61256581e-07
Iter: 1418 loss: 8.60818773e-07
Iter: 1419 loss: 8.6072e-07
Iter: 1420 loss: 8.6041905e-07
Iter: 1421 loss: 8.59695206e-07
Iter: 1422 loss: 8.6065495e-07
Iter: 1423 loss: 8.59295255e-07
Iter: 1424 loss: 8.58578574e-07
Iter: 1425 loss: 8.5972539e-07
Iter: 1426 loss: 8.58302656e-07
Iter: 1427 loss: 8.57600753e-07
Iter: 1428 loss: 8.60211742e-07
Iter: 1429 loss: 8.5742596e-07
Iter: 1430 loss: 8.56799147e-07
Iter: 1431 loss: 8.64248136e-07
Iter: 1432 loss: 8.56814154e-07
Iter: 1433 loss: 8.56381689e-07
Iter: 1434 loss: 8.55965197e-07
Iter: 1435 loss: 8.55827068e-07
Iter: 1436 loss: 8.5513e-07
Iter: 1437 loss: 8.56743782e-07
Iter: 1438 loss: 8.54875e-07
Iter: 1439 loss: 8.54372672e-07
Iter: 1440 loss: 8.5437182e-07
Iter: 1441 loss: 8.53967379e-07
Iter: 1442 loss: 8.53373649e-07
Iter: 1443 loss: 8.53373081e-07
Iter: 1444 loss: 8.52710741e-07
Iter: 1445 loss: 8.53493702e-07
Iter: 1446 loss: 8.52352969e-07
Iter: 1447 loss: 8.51583422e-07
Iter: 1448 loss: 8.55302e-07
Iter: 1449 loss: 8.51419941e-07
Iter: 1450 loss: 8.508257e-07
Iter: 1451 loss: 8.53179586e-07
Iter: 1452 loss: 8.50634478e-07
Iter: 1453 loss: 8.49878461e-07
Iter: 1454 loss: 8.52333415e-07
Iter: 1455 loss: 8.49634887e-07
Iter: 1456 loss: 8.49073672e-07
Iter: 1457 loss: 8.493613e-07
Iter: 1458 loss: 8.48706406e-07
Iter: 1459 loss: 8.48164632e-07
Iter: 1460 loss: 8.54447819e-07
Iter: 1461 loss: 8.48143713e-07
Iter: 1462 loss: 8.4775121e-07
Iter: 1463 loss: 8.47282706e-07
Iter: 1464 loss: 8.47202443e-07
Iter: 1465 loss: 8.46422665e-07
Iter: 1466 loss: 8.48326863e-07
Iter: 1467 loss: 8.46117928e-07
Iter: 1468 loss: 8.45502313e-07
Iter: 1469 loss: 8.49898413e-07
Iter: 1470 loss: 8.45397039e-07
Iter: 1471 loss: 8.44827696e-07
Iter: 1472 loss: 8.44624878e-07
Iter: 1473 loss: 8.44310534e-07
Iter: 1474 loss: 8.43677526e-07
Iter: 1475 loss: 8.43664225e-07
Iter: 1476 loss: 8.4315684e-07
Iter: 1477 loss: 8.45277327e-07
Iter: 1478 loss: 8.43084422e-07
Iter: 1479 loss: 8.42709937e-07
Iter: 1480 loss: 8.42334885e-07
Iter: 1481 loss: 8.4226e-07
Iter: 1482 loss: 8.41686301e-07
Iter: 1483 loss: 8.46631394e-07
Iter: 1484 loss: 8.41647875e-07
Iter: 1485 loss: 8.41123324e-07
Iter: 1486 loss: 8.41227461e-07
Iter: 1487 loss: 8.40731332e-07
Iter: 1488 loss: 8.40051939e-07
Iter: 1489 loss: 8.39538188e-07
Iter: 1490 loss: 8.39319569e-07
Iter: 1491 loss: 8.38526091e-07
Iter: 1492 loss: 8.47430101e-07
Iter: 1493 loss: 8.38511937e-07
Iter: 1494 loss: 8.37976245e-07
Iter: 1495 loss: 8.44694341e-07
Iter: 1496 loss: 8.37956748e-07
Iter: 1497 loss: 8.37548839e-07
Iter: 1498 loss: 8.37275593e-07
Iter: 1499 loss: 8.37087214e-07
Iter: 1500 loss: 8.36511617e-07
Iter: 1501 loss: 8.37086418e-07
Iter: 1502 loss: 8.3619409e-07
Iter: 1503 loss: 8.35408741e-07
Iter: 1504 loss: 8.37259108e-07
Iter: 1505 loss: 8.35205185e-07
Iter: 1506 loss: 8.34518346e-07
Iter: 1507 loss: 8.42043505e-07
Iter: 1508 loss: 8.34559842e-07
Iter: 1509 loss: 8.34056323e-07
Iter: 1510 loss: 8.34243792e-07
Iter: 1511 loss: 8.33740842e-07
Iter: 1512 loss: 8.33103627e-07
Iter: 1513 loss: 8.33270349e-07
Iter: 1514 loss: 8.32641149e-07
Iter: 1515 loss: 8.32020817e-07
Iter: 1516 loss: 8.32037585e-07
Iter: 1517 loss: 8.31580792e-07
Iter: 1518 loss: 8.33215267e-07
Iter: 1519 loss: 8.31427883e-07
Iter: 1520 loss: 8.30909e-07
Iter: 1521 loss: 8.30664135e-07
Iter: 1522 loss: 8.30411068e-07
Iter: 1523 loss: 8.29755663e-07
Iter: 1524 loss: 8.31670604e-07
Iter: 1525 loss: 8.2955512e-07
Iter: 1526 loss: 8.29064675e-07
Iter: 1527 loss: 8.32955948e-07
Iter: 1528 loss: 8.29036537e-07
Iter: 1529 loss: 8.28503346e-07
Iter: 1530 loss: 8.29328087e-07
Iter: 1531 loss: 8.28268753e-07
Iter: 1532 loss: 8.27791212e-07
Iter: 1533 loss: 8.27522626e-07
Iter: 1534 loss: 8.27289e-07
Iter: 1535 loss: 8.26603639e-07
Iter: 1536 loss: 8.27940198e-07
Iter: 1537 loss: 8.26308678e-07
Iter: 1538 loss: 8.25552e-07
Iter: 1539 loss: 8.27566964e-07
Iter: 1540 loss: 8.25299139e-07
Iter: 1541 loss: 8.24819665e-07
Iter: 1542 loss: 8.24762822e-07
Iter: 1543 loss: 8.24289771e-07
Iter: 1544 loss: 8.24368385e-07
Iter: 1545 loss: 8.23892606e-07
Iter: 1546 loss: 8.2338596e-07
Iter: 1547 loss: 8.24489462e-07
Iter: 1548 loss: 8.23166715e-07
Iter: 1549 loss: 8.22580603e-07
Iter: 1550 loss: 8.25115706e-07
Iter: 1551 loss: 8.22441052e-07
Iter: 1552 loss: 8.21894957e-07
Iter: 1553 loss: 8.2316069e-07
Iter: 1554 loss: 8.21720505e-07
Iter: 1555 loss: 8.21194817e-07
Iter: 1556 loss: 8.21144226e-07
Iter: 1557 loss: 8.20803905e-07
Iter: 1558 loss: 8.20217565e-07
Iter: 1559 loss: 8.26973178e-07
Iter: 1560 loss: 8.20196533e-07
Iter: 1561 loss: 8.19680622e-07
Iter: 1562 loss: 8.21770868e-07
Iter: 1563 loss: 8.19564832e-07
Iter: 1564 loss: 8.19168463e-07
Iter: 1565 loss: 8.19260947e-07
Iter: 1566 loss: 8.18882825e-07
Iter: 1567 loss: 8.1837328e-07
Iter: 1568 loss: 8.1882007e-07
Iter: 1569 loss: 8.18074682e-07
Iter: 1570 loss: 8.17484931e-07
Iter: 1571 loss: 8.20676064e-07
Iter: 1572 loss: 8.17410637e-07
Iter: 1573 loss: 8.16837883e-07
Iter: 1574 loss: 8.18689841e-07
Iter: 1575 loss: 8.16668489e-07
Iter: 1576 loss: 8.1621738e-07
Iter: 1577 loss: 8.16386432e-07
Iter: 1578 loss: 8.15910937e-07
Iter: 1579 loss: 8.15311409e-07
Iter: 1580 loss: 8.15079602e-07
Iter: 1581 loss: 8.14677946e-07
Iter: 1582 loss: 8.14105306e-07
Iter: 1583 loss: 8.1410559e-07
Iter: 1584 loss: 8.13611e-07
Iter: 1585 loss: 8.16256488e-07
Iter: 1586 loss: 8.13511406e-07
Iter: 1587 loss: 8.13056715e-07
Iter: 1588 loss: 8.12464293e-07
Iter: 1589 loss: 8.12448775e-07
Iter: 1590 loss: 8.11827e-07
Iter: 1591 loss: 8.17438831e-07
Iter: 1592 loss: 8.11805535e-07
Iter: 1593 loss: 8.11240739e-07
Iter: 1594 loss: 8.13275392e-07
Iter: 1595 loss: 8.1111267e-07
Iter: 1596 loss: 8.10637573e-07
Iter: 1597 loss: 8.10481538e-07
Iter: 1598 loss: 8.10239726e-07
Iter: 1599 loss: 8.09638948e-07
Iter: 1600 loss: 8.15785711e-07
Iter: 1601 loss: 8.09624737e-07
Iter: 1602 loss: 8.09142875e-07
Iter: 1603 loss: 8.11991242e-07
Iter: 1604 loss: 8.09094274e-07
Iter: 1605 loss: 8.08751e-07
Iter: 1606 loss: 8.08139e-07
Iter: 1607 loss: 8.0812e-07
Iter: 1608 loss: 8.07526078e-07
Iter: 1609 loss: 8.12206849e-07
Iter: 1610 loss: 8.07506e-07
Iter: 1611 loss: 8.07074798e-07
Iter: 1612 loss: 8.07951608e-07
Iter: 1613 loss: 8.06913249e-07
Iter: 1614 loss: 8.06338221e-07
Iter: 1615 loss: 8.09013613e-07
Iter: 1616 loss: 8.06266314e-07
Iter: 1617 loss: 8.05744094e-07
Iter: 1618 loss: 8.05840102e-07
Iter: 1619 loss: 8.05382911e-07
Iter: 1620 loss: 8.04816e-07
Iter: 1621 loss: 8.05352784e-07
Iter: 1622 loss: 8.04545664e-07
Iter: 1623 loss: 8.03766397e-07
Iter: 1624 loss: 8.05645072e-07
Iter: 1625 loss: 8.03471721e-07
Iter: 1626 loss: 8.03025387e-07
Iter: 1627 loss: 8.03011517e-07
Iter: 1628 loss: 8.02544434e-07
Iter: 1629 loss: 8.02583259e-07
Iter: 1630 loss: 8.02147213e-07
Iter: 1631 loss: 8.01652391e-07
Iter: 1632 loss: 8.01632439e-07
Iter: 1633 loss: 8.01265742e-07
Iter: 1634 loss: 8.0063e-07
Iter: 1635 loss: 8.0433972e-07
Iter: 1636 loss: 8.00542125e-07
Iter: 1637 loss: 8.00221187e-07
Iter: 1638 loss: 8.00221187e-07
Iter: 1639 loss: 7.99921509e-07
Iter: 1640 loss: 7.9932704e-07
Iter: 1641 loss: 8.09863479e-07
Iter: 1642 loss: 7.99320389e-07
Iter: 1643 loss: 7.98693918e-07
Iter: 1644 loss: 8.05239097e-07
Iter: 1645 loss: 7.98692554e-07
Iter: 1646 loss: 7.98314261e-07
Iter: 1647 loss: 7.98968244e-07
Iter: 1648 loss: 7.98120595e-07
Iter: 1649 loss: 7.97696771e-07
Iter: 1650 loss: 7.97267603e-07
Iter: 1651 loss: 7.97219172e-07
Iter: 1652 loss: 7.9652574e-07
Iter: 1653 loss: 8.04833178e-07
Iter: 1654 loss: 7.96518918e-07
Iter: 1655 loss: 7.96100153e-07
Iter: 1656 loss: 7.98151063e-07
Iter: 1657 loss: 7.95969868e-07
Iter: 1658 loss: 7.95687697e-07
Iter: 1659 loss: 7.9582037e-07
Iter: 1660 loss: 7.95420647e-07
Iter: 1661 loss: 7.94953564e-07
Iter: 1662 loss: 7.94936454e-07
Iter: 1663 loss: 7.94554467e-07
Iter: 1664 loss: 7.94007747e-07
Iter: 1665 loss: 7.99422139e-07
Iter: 1666 loss: 7.94019684e-07
Iter: 1667 loss: 7.93481036e-07
Iter: 1668 loss: 7.94058678e-07
Iter: 1669 loss: 7.93227059e-07
Iter: 1670 loss: 7.92572678e-07
Iter: 1671 loss: 7.93192044e-07
Iter: 1672 loss: 7.92262711e-07
Iter: 1673 loss: 7.91706e-07
Iter: 1674 loss: 7.92637e-07
Iter: 1675 loss: 7.91409832e-07
Iter: 1676 loss: 7.90948206e-07
Iter: 1677 loss: 7.97575126e-07
Iter: 1678 loss: 7.90973445e-07
Iter: 1679 loss: 7.90487547e-07
Iter: 1680 loss: 7.91180355e-07
Iter: 1681 loss: 7.90275408e-07
Iter: 1682 loss: 7.89906437e-07
Iter: 1683 loss: 7.89521437e-07
Iter: 1684 loss: 7.89463911e-07
Iter: 1685 loss: 7.88904231e-07
Iter: 1686 loss: 7.92195408e-07
Iter: 1687 loss: 7.88825162e-07
Iter: 1688 loss: 7.88314196e-07
Iter: 1689 loss: 7.91693651e-07
Iter: 1690 loss: 7.88249793e-07
Iter: 1691 loss: 7.87848e-07
Iter: 1692 loss: 7.87689942e-07
Iter: 1693 loss: 7.87487522e-07
Iter: 1694 loss: 7.8693995e-07
Iter: 1695 loss: 7.9151863e-07
Iter: 1696 loss: 7.86894589e-07
Iter: 1697 loss: 7.86402666e-07
Iter: 1698 loss: 7.87071428e-07
Iter: 1699 loss: 7.8613084e-07
Iter: 1700 loss: 7.85673365e-07
Iter: 1701 loss: 7.85925295e-07
Iter: 1702 loss: 7.85353052e-07
Iter: 1703 loss: 7.84748295e-07
Iter: 1704 loss: 7.87869794e-07
Iter: 1705 loss: 7.84644385e-07
Iter: 1706 loss: 7.8412404e-07
Iter: 1707 loss: 7.87451711e-07
Iter: 1708 loss: 7.84047756e-07
Iter: 1709 loss: 7.83643259e-07
Iter: 1710 loss: 7.83830387e-07
Iter: 1711 loss: 7.83357564e-07
Iter: 1712 loss: 7.82911513e-07
Iter: 1713 loss: 7.84103634e-07
Iter: 1714 loss: 7.82795155e-07
Iter: 1715 loss: 7.82387701e-07
Iter: 1716 loss: 7.84161443e-07
Iter: 1717 loss: 7.82300617e-07
Iter: 1718 loss: 7.81764129e-07
Iter: 1719 loss: 7.83065047e-07
Iter: 1720 loss: 7.81603433e-07
Iter: 1721 loss: 7.81173526e-07
Iter: 1722 loss: 7.80955e-07
Iter: 1723 loss: 7.80821e-07
Iter: 1724 loss: 7.80218329e-07
Iter: 1725 loss: 7.81267318e-07
Iter: 1726 loss: 7.7995287e-07
Iter: 1727 loss: 7.79264383e-07
Iter: 1728 loss: 7.80329287e-07
Iter: 1729 loss: 7.78911613e-07
Iter: 1730 loss: 7.78306514e-07
Iter: 1731 loss: 7.82582e-07
Iter: 1732 loss: 7.78255526e-07
Iter: 1733 loss: 7.77816808e-07
Iter: 1734 loss: 7.82539e-07
Iter: 1735 loss: 7.77794241e-07
Iter: 1736 loss: 7.77398839e-07
Iter: 1737 loss: 7.7698553e-07
Iter: 1738 loss: 7.7689964e-07
Iter: 1739 loss: 7.76407887e-07
Iter: 1740 loss: 7.8184263e-07
Iter: 1741 loss: 7.76391289e-07
Iter: 1742 loss: 7.7598213e-07
Iter: 1743 loss: 7.767444e-07
Iter: 1744 loss: 7.75842e-07
Iter: 1745 loss: 7.75369131e-07
Iter: 1746 loss: 7.75914145e-07
Iter: 1747 loss: 7.75187686e-07
Iter: 1748 loss: 7.74680643e-07
Iter: 1749 loss: 7.78450101e-07
Iter: 1750 loss: 7.74632e-07
Iter: 1751 loss: 7.74305818e-07
Iter: 1752 loss: 7.74521595e-07
Iter: 1753 loss: 7.74112891e-07
Iter: 1754 loss: 7.73700833e-07
Iter: 1755 loss: 7.74680757e-07
Iter: 1756 loss: 7.73539284e-07
Iter: 1757 loss: 7.7315e-07
Iter: 1758 loss: 7.76602405e-07
Iter: 1759 loss: 7.73127795e-07
Iter: 1760 loss: 7.72777071e-07
Iter: 1761 loss: 7.72326302e-07
Iter: 1762 loss: 7.722698e-07
Iter: 1763 loss: 7.71791065e-07
Iter: 1764 loss: 7.74015462e-07
Iter: 1765 loss: 7.71688747e-07
Iter: 1766 loss: 7.71210921e-07
Iter: 1767 loss: 7.7082268e-07
Iter: 1768 loss: 7.70699273e-07
Iter: 1769 loss: 7.70069505e-07
Iter: 1770 loss: 7.75437343e-07
Iter: 1771 loss: 7.70054157e-07
Iter: 1772 loss: 7.69506357e-07
Iter: 1773 loss: 7.71393729e-07
Iter: 1774 loss: 7.69405688e-07
Iter: 1775 loss: 7.68840323e-07
Iter: 1776 loss: 7.72799353e-07
Iter: 1777 loss: 7.68798657e-07
Iter: 1778 loss: 7.68468908e-07
Iter: 1779 loss: 7.68200209e-07
Iter: 1780 loss: 7.68096299e-07
Iter: 1781 loss: 7.67508254e-07
Iter: 1782 loss: 7.68844416e-07
Iter: 1783 loss: 7.67315782e-07
Iter: 1784 loss: 7.66789299e-07
Iter: 1785 loss: 7.73359602e-07
Iter: 1786 loss: 7.66798848e-07
Iter: 1787 loss: 7.66465234e-07
Iter: 1788 loss: 7.66351263e-07
Iter: 1789 loss: 7.66164362e-07
Iter: 1790 loss: 7.65742243e-07
Iter: 1791 loss: 7.69181554e-07
Iter: 1792 loss: 7.65705522e-07
Iter: 1793 loss: 7.65308869e-07
Iter: 1794 loss: 7.65310347e-07
Iter: 1795 loss: 7.65041591e-07
Iter: 1796 loss: 7.64593551e-07
Iter: 1797 loss: 7.69994301e-07
Iter: 1798 loss: 7.64609183e-07
Iter: 1799 loss: 7.64291599e-07
Iter: 1800 loss: 7.63850267e-07
Iter: 1801 loss: 7.63849584e-07
Iter: 1802 loss: 7.63330149e-07
Iter: 1803 loss: 7.64658807e-07
Iter: 1804 loss: 7.63153764e-07
Iter: 1805 loss: 7.62700495e-07
Iter: 1806 loss: 7.64511412e-07
Iter: 1807 loss: 7.62557875e-07
Iter: 1808 loss: 7.62062427e-07
Iter: 1809 loss: 7.62494324e-07
Iter: 1810 loss: 7.61796571e-07
Iter: 1811 loss: 7.61283559e-07
Iter: 1812 loss: 7.64798358e-07
Iter: 1813 loss: 7.61218075e-07
Iter: 1814 loss: 7.60834382e-07
Iter: 1815 loss: 7.63157686e-07
Iter: 1816 loss: 7.60794137e-07
Iter: 1817 loss: 7.60384467e-07
Iter: 1818 loss: 7.59845761e-07
Iter: 1819 loss: 7.59782e-07
Iter: 1820 loss: 7.59341333e-07
Iter: 1821 loss: 7.62286334e-07
Iter: 1822 loss: 7.59251577e-07
Iter: 1823 loss: 7.58882777e-07
Iter: 1824 loss: 7.62184129e-07
Iter: 1825 loss: 7.58832e-07
Iter: 1826 loss: 7.58495389e-07
Iter: 1827 loss: 7.58293311e-07
Iter: 1828 loss: 7.58151543e-07
Iter: 1829 loss: 7.5770015e-07
Iter: 1830 loss: 7.61319598e-07
Iter: 1831 loss: 7.57663145e-07
Iter: 1832 loss: 7.57301109e-07
Iter: 1833 loss: 7.58754709e-07
Iter: 1834 loss: 7.57223575e-07
Iter: 1835 loss: 7.56879444e-07
Iter: 1836 loss: 7.57051112e-07
Iter: 1837 loss: 7.56645079e-07
Iter: 1838 loss: 7.56121267e-07
Iter: 1839 loss: 7.56800148e-07
Iter: 1840 loss: 7.55878489e-07
Iter: 1841 loss: 7.55398162e-07
Iter: 1842 loss: 7.56183567e-07
Iter: 1843 loss: 7.55162773e-07
Iter: 1844 loss: 7.54722123e-07
Iter: 1845 loss: 7.54520613e-07
Iter: 1846 loss: 7.54263e-07
Iter: 1847 loss: 7.53642666e-07
Iter: 1848 loss: 7.59072236e-07
Iter: 1849 loss: 7.53624704e-07
Iter: 1850 loss: 7.53120048e-07
Iter: 1851 loss: 7.57748921e-07
Iter: 1852 loss: 7.5312488e-07
Iter: 1853 loss: 7.52719757e-07
Iter: 1854 loss: 7.5262551e-07
Iter: 1855 loss: 7.52382164e-07
Iter: 1856 loss: 7.51905077e-07
Iter: 1857 loss: 7.53635561e-07
Iter: 1858 loss: 7.51769619e-07
Iter: 1859 loss: 7.51376206e-07
Iter: 1860 loss: 7.53623112e-07
Iter: 1861 loss: 7.51312655e-07
Iter: 1862 loss: 7.50915e-07
Iter: 1863 loss: 7.51476875e-07
Iter: 1864 loss: 7.50733079e-07
Iter: 1865 loss: 7.50259233e-07
Iter: 1866 loss: 7.51015307e-07
Iter: 1867 loss: 7.50034815e-07
Iter: 1868 loss: 7.49665048e-07
Iter: 1869 loss: 7.54324674e-07
Iter: 1870 loss: 7.49667379e-07
Iter: 1871 loss: 7.49385549e-07
Iter: 1872 loss: 7.49354513e-07
Iter: 1873 loss: 7.49176081e-07
Iter: 1874 loss: 7.48831383e-07
Iter: 1875 loss: 7.49473543e-07
Iter: 1876 loss: 7.48668754e-07
Iter: 1877 loss: 7.48273351e-07
Iter: 1878 loss: 7.49662263e-07
Iter: 1879 loss: 7.48152502e-07
Iter: 1880 loss: 7.47754598e-07
Iter: 1881 loss: 7.47813033e-07
Iter: 1882 loss: 7.47517788e-07
Iter: 1883 loss: 7.46946341e-07
Iter: 1884 loss: 7.47239369e-07
Iter: 1885 loss: 7.46600108e-07
Iter: 1886 loss: 7.46075e-07
Iter: 1887 loss: 7.52822245e-07
Iter: 1888 loss: 7.46078172e-07
Iter: 1889 loss: 7.45719262e-07
Iter: 1890 loss: 7.47803938e-07
Iter: 1891 loss: 7.45686e-07
Iter: 1892 loss: 7.45338e-07
Iter: 1893 loss: 7.45040722e-07
Iter: 1894 loss: 7.44922033e-07
Iter: 1895 loss: 7.44422437e-07
Iter: 1896 loss: 7.46335672e-07
Iter: 1897 loss: 7.44303122e-07
Iter: 1898 loss: 7.43893736e-07
Iter: 1899 loss: 7.48542e-07
Iter: 1900 loss: 7.43877308e-07
Iter: 1901 loss: 7.43544092e-07
Iter: 1902 loss: 7.43090936e-07
Iter: 1903 loss: 7.43105602e-07
Iter: 1904 loss: 7.42779889e-07
Iter: 1905 loss: 7.4277e-07
Iter: 1906 loss: 7.42498287e-07
Iter: 1907 loss: 7.42302291e-07
Iter: 1908 loss: 7.42233e-07
Iter: 1909 loss: 7.41805707e-07
Iter: 1910 loss: 7.43079681e-07
Iter: 1911 loss: 7.41686904e-07
Iter: 1912 loss: 7.41324072e-07
Iter: 1913 loss: 7.42238683e-07
Iter: 1914 loss: 7.411507e-07
Iter: 1915 loss: 7.40747225e-07
Iter: 1916 loss: 7.41652798e-07
Iter: 1917 loss: 7.40606083e-07
Iter: 1918 loss: 7.40138489e-07
Iter: 1919 loss: 7.40484609e-07
Iter: 1920 loss: 7.39867914e-07
Iter: 1921 loss: 7.39354277e-07
Iter: 1922 loss: 7.40773146e-07
Iter: 1923 loss: 7.39195457e-07
Iter: 1924 loss: 7.38771405e-07
Iter: 1925 loss: 7.38784706e-07
Iter: 1926 loss: 7.38486335e-07
Iter: 1927 loss: 7.38533458e-07
Iter: 1928 loss: 7.38238441e-07
Iter: 1929 loss: 7.37852247e-07
Iter: 1930 loss: 7.37816379e-07
Iter: 1931 loss: 7.37485777e-07
Iter: 1932 loss: 7.37152618e-07
Iter: 1933 loss: 7.37169501e-07
Iter: 1934 loss: 7.36861125e-07
Iter: 1935 loss: 7.36538e-07
Iter: 1936 loss: 7.36520235e-07
Iter: 1937 loss: 7.36117443e-07
Iter: 1938 loss: 7.41317308e-07
Iter: 1939 loss: 7.36125e-07
Iter: 1940 loss: 7.35864205e-07
Iter: 1941 loss: 7.35755407e-07
Iter: 1942 loss: 7.3560409e-07
Iter: 1943 loss: 7.35220453e-07
Iter: 1944 loss: 7.35618698e-07
Iter: 1945 loss: 7.35031335e-07
Iter: 1946 loss: 7.34523951e-07
Iter: 1947 loss: 7.36201969e-07
Iter: 1948 loss: 7.34387754e-07
Iter: 1949 loss: 7.33994966e-07
Iter: 1950 loss: 7.35009849e-07
Iter: 1951 loss: 7.33832508e-07
Iter: 1952 loss: 7.33373611e-07
Iter: 1953 loss: 7.33903903e-07
Iter: 1954 loss: 7.33192792e-07
Iter: 1955 loss: 7.32670742e-07
Iter: 1956 loss: 7.34788159e-07
Iter: 1957 loss: 7.32597073e-07
Iter: 1958 loss: 7.32213493e-07
Iter: 1959 loss: 7.3473791e-07
Iter: 1960 loss: 7.321878e-07
Iter: 1961 loss: 7.31838554e-07
Iter: 1962 loss: 7.32534318e-07
Iter: 1963 loss: 7.31712475e-07
Iter: 1964 loss: 7.31360046e-07
Iter: 1965 loss: 7.310623e-07
Iter: 1966 loss: 7.30953218e-07
Iter: 1967 loss: 7.305797e-07
Iter: 1968 loss: 7.36213394e-07
Iter: 1969 loss: 7.30575039e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2
+ date
Sat Nov  7 15:37:56 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3f8e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3f4d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3f52488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3f17620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3f10730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3f28ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e7c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e7c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e7c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e54c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e78730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e2c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e2cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3dea598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3dea158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3dea730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3d97620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3d6e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3d6ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3d03268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3d03400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3ce4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3c818c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3c81ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3c5f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3c72d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc70e6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc70e6598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc711c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc712c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc711c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3dea048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc711ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cd3e7c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc70587b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1cc70e6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.78658081e-05
Iter: 2 loss: 2.42443e-05
Iter: 3 loss: 2.70077344e-05
Iter: 4 loss: 2.20205438e-05
Iter: 5 loss: 1.92172593e-05
Iter: 6 loss: 3.18958701e-05
Iter: 7 loss: 1.8673556e-05
Iter: 8 loss: 1.67132e-05
Iter: 9 loss: 1.80450315e-05
Iter: 10 loss: 1.54948211e-05
Iter: 11 loss: 1.36814242e-05
Iter: 12 loss: 2.32096772e-05
Iter: 13 loss: 1.34014845e-05
Iter: 14 loss: 1.22928614e-05
Iter: 15 loss: 2.043118e-05
Iter: 16 loss: 1.22003576e-05
Iter: 17 loss: 1.15520506e-05
Iter: 18 loss: 1.12164316e-05
Iter: 19 loss: 1.09175744e-05
Iter: 20 loss: 9.89510681e-06
Iter: 21 loss: 1.32534724e-05
Iter: 22 loss: 9.6117019e-06
Iter: 23 loss: 8.8936722e-06
Iter: 24 loss: 1.3228766e-05
Iter: 25 loss: 8.80490552e-06
Iter: 26 loss: 8.24096242e-06
Iter: 27 loss: 1.05755626e-05
Iter: 28 loss: 8.11936206e-06
Iter: 29 loss: 7.64001561e-06
Iter: 30 loss: 8.70870645e-06
Iter: 31 loss: 7.45772832e-06
Iter: 32 loss: 7.01158e-06
Iter: 33 loss: 9.18201113e-06
Iter: 34 loss: 6.93368929e-06
Iter: 35 loss: 6.4958258e-06
Iter: 36 loss: 7.83334326e-06
Iter: 37 loss: 6.36604273e-06
Iter: 38 loss: 6.10792631e-06
Iter: 39 loss: 6.12458598e-06
Iter: 40 loss: 5.90634409e-06
Iter: 41 loss: 5.65999835e-06
Iter: 42 loss: 9.02378633e-06
Iter: 43 loss: 5.65896789e-06
Iter: 44 loss: 5.45326111e-06
Iter: 45 loss: 6.57053351e-06
Iter: 46 loss: 5.42277076e-06
Iter: 47 loss: 5.2918258e-06
Iter: 48 loss: 5.16298132e-06
Iter: 49 loss: 5.13511532e-06
Iter: 50 loss: 4.94298365e-06
Iter: 51 loss: 6.48682817e-06
Iter: 52 loss: 4.93007292e-06
Iter: 53 loss: 4.79250048e-06
Iter: 54 loss: 5.42062389e-06
Iter: 55 loss: 4.76621381e-06
Iter: 56 loss: 4.65612857e-06
Iter: 57 loss: 4.57851047e-06
Iter: 58 loss: 4.53968187e-06
Iter: 59 loss: 4.37692688e-06
Iter: 60 loss: 4.94555934e-06
Iter: 61 loss: 4.33458399e-06
Iter: 62 loss: 4.20209881e-06
Iter: 63 loss: 5.20263575e-06
Iter: 64 loss: 4.19181379e-06
Iter: 65 loss: 4.08932965e-06
Iter: 66 loss: 4.26852148e-06
Iter: 67 loss: 4.04413095e-06
Iter: 68 loss: 3.94167091e-06
Iter: 69 loss: 4.54121482e-06
Iter: 70 loss: 3.92818583e-06
Iter: 71 loss: 3.84654732e-06
Iter: 72 loss: 4.12323971e-06
Iter: 73 loss: 3.82439475e-06
Iter: 74 loss: 3.75570312e-06
Iter: 75 loss: 3.94908602e-06
Iter: 76 loss: 3.73386365e-06
Iter: 77 loss: 3.66077779e-06
Iter: 78 loss: 3.70002908e-06
Iter: 79 loss: 3.61249681e-06
Iter: 80 loss: 3.54182112e-06
Iter: 81 loss: 4.11478277e-06
Iter: 82 loss: 3.53723954e-06
Iter: 83 loss: 3.48292224e-06
Iter: 84 loss: 3.90262903e-06
Iter: 85 loss: 3.4789382e-06
Iter: 86 loss: 3.43831334e-06
Iter: 87 loss: 3.35880668e-06
Iter: 88 loss: 4.950326e-06
Iter: 89 loss: 3.35818595e-06
Iter: 90 loss: 3.27832367e-06
Iter: 91 loss: 3.63084018e-06
Iter: 92 loss: 3.26242889e-06
Iter: 93 loss: 3.20593199e-06
Iter: 94 loss: 3.20591084e-06
Iter: 95 loss: 3.16728347e-06
Iter: 96 loss: 3.13897908e-06
Iter: 97 loss: 3.12592692e-06
Iter: 98 loss: 3.07275127e-06
Iter: 99 loss: 3.17021568e-06
Iter: 100 loss: 3.04971672e-06
Iter: 101 loss: 2.98919622e-06
Iter: 102 loss: 3.22085907e-06
Iter: 103 loss: 2.97487259e-06
Iter: 104 loss: 2.92879258e-06
Iter: 105 loss: 3.15839e-06
Iter: 106 loss: 2.9210039e-06
Iter: 107 loss: 2.88059209e-06
Iter: 108 loss: 3.17108697e-06
Iter: 109 loss: 2.87707189e-06
Iter: 110 loss: 2.84813041e-06
Iter: 111 loss: 2.83747863e-06
Iter: 112 loss: 2.82134738e-06
Iter: 113 loss: 2.77844219e-06
Iter: 114 loss: 3.11066196e-06
Iter: 115 loss: 2.77535e-06
Iter: 116 loss: 2.74963622e-06
Iter: 117 loss: 2.74899503e-06
Iter: 118 loss: 2.72895704e-06
Iter: 119 loss: 2.69968405e-06
Iter: 120 loss: 2.69970951e-06
Iter: 121 loss: 2.67855648e-06
Iter: 122 loss: 2.65362814e-06
Iter: 123 loss: 2.65091217e-06
Iter: 124 loss: 2.61824084e-06
Iter: 125 loss: 2.73951241e-06
Iter: 126 loss: 2.61018545e-06
Iter: 127 loss: 2.58211821e-06
Iter: 128 loss: 2.61706191e-06
Iter: 129 loss: 2.56752219e-06
Iter: 130 loss: 2.5378979e-06
Iter: 131 loss: 2.87292869e-06
Iter: 132 loss: 2.53730832e-06
Iter: 133 loss: 2.51816573e-06
Iter: 134 loss: 2.52277869e-06
Iter: 135 loss: 2.50419362e-06
Iter: 136 loss: 2.47429944e-06
Iter: 137 loss: 2.50802236e-06
Iter: 138 loss: 2.45827187e-06
Iter: 139 loss: 2.42880787e-06
Iter: 140 loss: 2.47535559e-06
Iter: 141 loss: 2.41503517e-06
Iter: 142 loss: 2.38609209e-06
Iter: 143 loss: 2.51172332e-06
Iter: 144 loss: 2.38020516e-06
Iter: 145 loss: 2.36079586e-06
Iter: 146 loss: 2.36076266e-06
Iter: 147 loss: 2.34543222e-06
Iter: 148 loss: 2.3273742e-06
Iter: 149 loss: 2.32529169e-06
Iter: 150 loss: 2.30731234e-06
Iter: 151 loss: 2.47673074e-06
Iter: 152 loss: 2.30658907e-06
Iter: 153 loss: 2.28962017e-06
Iter: 154 loss: 2.33613e-06
Iter: 155 loss: 2.28404656e-06
Iter: 156 loss: 2.26847555e-06
Iter: 157 loss: 2.34649315e-06
Iter: 158 loss: 2.26579959e-06
Iter: 159 loss: 2.25049462e-06
Iter: 160 loss: 2.22968129e-06
Iter: 161 loss: 2.22862036e-06
Iter: 162 loss: 2.20779884e-06
Iter: 163 loss: 2.32368211e-06
Iter: 164 loss: 2.20478137e-06
Iter: 165 loss: 2.18642572e-06
Iter: 166 loss: 2.22607491e-06
Iter: 167 loss: 2.17924526e-06
Iter: 168 loss: 2.164036e-06
Iter: 169 loss: 2.34016261e-06
Iter: 170 loss: 2.16373337e-06
Iter: 171 loss: 2.15052114e-06
Iter: 172 loss: 2.13949102e-06
Iter: 173 loss: 2.13578301e-06
Iter: 174 loss: 2.12074838e-06
Iter: 175 loss: 2.17774959e-06
Iter: 176 loss: 2.11719066e-06
Iter: 177 loss: 2.10133453e-06
Iter: 178 loss: 2.11625456e-06
Iter: 179 loss: 2.09223799e-06
Iter: 180 loss: 2.07708536e-06
Iter: 181 loss: 2.26237444e-06
Iter: 182 loss: 2.07688527e-06
Iter: 183 loss: 2.06619757e-06
Iter: 184 loss: 2.09643372e-06
Iter: 185 loss: 2.06279492e-06
Iter: 186 loss: 2.05083779e-06
Iter: 187 loss: 2.07507378e-06
Iter: 188 loss: 2.04583785e-06
Iter: 189 loss: 2.03415243e-06
Iter: 190 loss: 2.04041044e-06
Iter: 191 loss: 2.02643878e-06
Iter: 192 loss: 2.01645616e-06
Iter: 193 loss: 2.01617377e-06
Iter: 194 loss: 2.00992599e-06
Iter: 195 loss: 2.00422414e-06
Iter: 196 loss: 2.00266095e-06
Iter: 197 loss: 1.99014903e-06
Iter: 198 loss: 1.98825478e-06
Iter: 199 loss: 1.97957229e-06
Iter: 200 loss: 1.96898691e-06
Iter: 201 loss: 1.96890892e-06
Iter: 202 loss: 1.96227143e-06
Iter: 203 loss: 1.95232224e-06
Iter: 204 loss: 1.95212669e-06
Iter: 205 loss: 1.93782898e-06
Iter: 206 loss: 2.0232153e-06
Iter: 207 loss: 1.93603842e-06
Iter: 208 loss: 1.92490324e-06
Iter: 209 loss: 2.01474381e-06
Iter: 210 loss: 1.92415769e-06
Iter: 211 loss: 1.91785398e-06
Iter: 212 loss: 1.91687923e-06
Iter: 213 loss: 1.91245567e-06
Iter: 214 loss: 1.90177127e-06
Iter: 215 loss: 1.89617185e-06
Iter: 216 loss: 1.89137893e-06
Iter: 217 loss: 1.88047989e-06
Iter: 218 loss: 1.96570591e-06
Iter: 219 loss: 1.87971978e-06
Iter: 220 loss: 1.87033152e-06
Iter: 221 loss: 1.96157544e-06
Iter: 222 loss: 1.86996192e-06
Iter: 223 loss: 1.86209832e-06
Iter: 224 loss: 1.85546605e-06
Iter: 225 loss: 1.85325041e-06
Iter: 226 loss: 1.84575811e-06
Iter: 227 loss: 1.84566568e-06
Iter: 228 loss: 1.83929751e-06
Iter: 229 loss: 1.84641351e-06
Iter: 230 loss: 1.83582142e-06
Iter: 231 loss: 1.82893518e-06
Iter: 232 loss: 1.82227711e-06
Iter: 233 loss: 1.82086751e-06
Iter: 234 loss: 1.81132282e-06
Iter: 235 loss: 1.90043284e-06
Iter: 236 loss: 1.81093287e-06
Iter: 237 loss: 1.804053e-06
Iter: 238 loss: 1.81604014e-06
Iter: 239 loss: 1.80102359e-06
Iter: 240 loss: 1.79257768e-06
Iter: 241 loss: 1.80949405e-06
Iter: 242 loss: 1.78904372e-06
Iter: 243 loss: 1.78221899e-06
Iter: 244 loss: 1.81728637e-06
Iter: 245 loss: 1.78114442e-06
Iter: 246 loss: 1.77379388e-06
Iter: 247 loss: 1.79204142e-06
Iter: 248 loss: 1.77129186e-06
Iter: 249 loss: 1.76512322e-06
Iter: 250 loss: 1.76861568e-06
Iter: 251 loss: 1.76116691e-06
Iter: 252 loss: 1.75373293e-06
Iter: 253 loss: 1.78374887e-06
Iter: 254 loss: 1.75211812e-06
Iter: 255 loss: 1.7449529e-06
Iter: 256 loss: 1.75490959e-06
Iter: 257 loss: 1.74132845e-06
Iter: 258 loss: 1.73451474e-06
Iter: 259 loss: 1.76342792e-06
Iter: 260 loss: 1.7330492e-06
Iter: 261 loss: 1.72473551e-06
Iter: 262 loss: 1.75720311e-06
Iter: 263 loss: 1.72271962e-06
Iter: 264 loss: 1.71756119e-06
Iter: 265 loss: 1.74001832e-06
Iter: 266 loss: 1.7164939e-06
Iter: 267 loss: 1.71169086e-06
Iter: 268 loss: 1.73009266e-06
Iter: 269 loss: 1.71062607e-06
Iter: 270 loss: 1.70588442e-06
Iter: 271 loss: 1.69928057e-06
Iter: 272 loss: 1.69907048e-06
Iter: 273 loss: 1.69250609e-06
Iter: 274 loss: 1.74257025e-06
Iter: 275 loss: 1.69213035e-06
Iter: 276 loss: 1.68694044e-06
Iter: 277 loss: 1.67931285e-06
Iter: 278 loss: 1.67915744e-06
Iter: 279 loss: 1.67468943e-06
Iter: 280 loss: 1.6733145e-06
Iter: 281 loss: 1.66879408e-06
Iter: 282 loss: 1.6658978e-06
Iter: 283 loss: 1.66413452e-06
Iter: 284 loss: 1.65852646e-06
Iter: 285 loss: 1.70395538e-06
Iter: 286 loss: 1.65805204e-06
Iter: 287 loss: 1.65260917e-06
Iter: 288 loss: 1.65253505e-06
Iter: 289 loss: 1.64814742e-06
Iter: 290 loss: 1.64251526e-06
Iter: 291 loss: 1.64459107e-06
Iter: 292 loss: 1.63874415e-06
Iter: 293 loss: 1.63089135e-06
Iter: 294 loss: 1.66943482e-06
Iter: 295 loss: 1.62952392e-06
Iter: 296 loss: 1.6235781e-06
Iter: 297 loss: 1.67265534e-06
Iter: 298 loss: 1.62329593e-06
Iter: 299 loss: 1.61873299e-06
Iter: 300 loss: 1.64830465e-06
Iter: 301 loss: 1.6182172e-06
Iter: 302 loss: 1.61464982e-06
Iter: 303 loss: 1.61299431e-06
Iter: 304 loss: 1.61125183e-06
Iter: 305 loss: 1.60573086e-06
Iter: 306 loss: 1.64774133e-06
Iter: 307 loss: 1.60528771e-06
Iter: 308 loss: 1.6016736e-06
Iter: 309 loss: 1.59862475e-06
Iter: 310 loss: 1.59749288e-06
Iter: 311 loss: 1.59244132e-06
Iter: 312 loss: 1.60655804e-06
Iter: 313 loss: 1.59074784e-06
Iter: 314 loss: 1.58464491e-06
Iter: 315 loss: 1.60017112e-06
Iter: 316 loss: 1.58257274e-06
Iter: 317 loss: 1.57753141e-06
Iter: 318 loss: 1.58479907e-06
Iter: 319 loss: 1.57504292e-06
Iter: 320 loss: 1.56933424e-06
Iter: 321 loss: 1.62252582e-06
Iter: 322 loss: 1.56909255e-06
Iter: 323 loss: 1.56502222e-06
Iter: 324 loss: 1.57785439e-06
Iter: 325 loss: 1.56380793e-06
Iter: 326 loss: 1.56015312e-06
Iter: 327 loss: 1.5566734e-06
Iter: 328 loss: 1.55581392e-06
Iter: 329 loss: 1.55061753e-06
Iter: 330 loss: 1.60641605e-06
Iter: 331 loss: 1.55051418e-06
Iter: 332 loss: 1.54635245e-06
Iter: 333 loss: 1.55149223e-06
Iter: 334 loss: 1.5441226e-06
Iter: 335 loss: 1.53964288e-06
Iter: 336 loss: 1.54527345e-06
Iter: 337 loss: 1.53735232e-06
Iter: 338 loss: 1.5330653e-06
Iter: 339 loss: 1.58739908e-06
Iter: 340 loss: 1.53306746e-06
Iter: 341 loss: 1.52921837e-06
Iter: 342 loss: 1.53517772e-06
Iter: 343 loss: 1.52746077e-06
Iter: 344 loss: 1.52411644e-06
Iter: 345 loss: 1.52756729e-06
Iter: 346 loss: 1.52227665e-06
Iter: 347 loss: 1.51828533e-06
Iter: 348 loss: 1.54261295e-06
Iter: 349 loss: 1.51774736e-06
Iter: 350 loss: 1.51451763e-06
Iter: 351 loss: 1.51306085e-06
Iter: 352 loss: 1.51154939e-06
Iter: 353 loss: 1.50629376e-06
Iter: 354 loss: 1.50355913e-06
Iter: 355 loss: 1.50109531e-06
Iter: 356 loss: 1.49551386e-06
Iter: 357 loss: 1.51403185e-06
Iter: 358 loss: 1.4939767e-06
Iter: 359 loss: 1.4880975e-06
Iter: 360 loss: 1.53376754e-06
Iter: 361 loss: 1.48762661e-06
Iter: 362 loss: 1.48346589e-06
Iter: 363 loss: 1.52135931e-06
Iter: 364 loss: 1.48333311e-06
Iter: 365 loss: 1.48034314e-06
Iter: 366 loss: 1.48215963e-06
Iter: 367 loss: 1.47838364e-06
Iter: 368 loss: 1.47487526e-06
Iter: 369 loss: 1.48111837e-06
Iter: 370 loss: 1.47330206e-06
Iter: 371 loss: 1.46873799e-06
Iter: 372 loss: 1.47059723e-06
Iter: 373 loss: 1.46560501e-06
Iter: 374 loss: 1.4610473e-06
Iter: 375 loss: 1.50371648e-06
Iter: 376 loss: 1.46085154e-06
Iter: 377 loss: 1.45755189e-06
Iter: 378 loss: 1.47768765e-06
Iter: 379 loss: 1.45713284e-06
Iter: 380 loss: 1.45376475e-06
Iter: 381 loss: 1.45761283e-06
Iter: 382 loss: 1.4519452e-06
Iter: 383 loss: 1.44810826e-06
Iter: 384 loss: 1.45465037e-06
Iter: 385 loss: 1.44619253e-06
Iter: 386 loss: 1.44300407e-06
Iter: 387 loss: 1.4611619e-06
Iter: 388 loss: 1.44255819e-06
Iter: 389 loss: 1.4399393e-06
Iter: 390 loss: 1.44244427e-06
Iter: 391 loss: 1.43840157e-06
Iter: 392 loss: 1.43479633e-06
Iter: 393 loss: 1.4484699e-06
Iter: 394 loss: 1.4338882e-06
Iter: 395 loss: 1.43123646e-06
Iter: 396 loss: 1.42649196e-06
Iter: 397 loss: 1.54181907e-06
Iter: 398 loss: 1.42650276e-06
Iter: 399 loss: 1.42093438e-06
Iter: 400 loss: 1.44835121e-06
Iter: 401 loss: 1.42001454e-06
Iter: 402 loss: 1.41548253e-06
Iter: 403 loss: 1.43118405e-06
Iter: 404 loss: 1.41429143e-06
Iter: 405 loss: 1.40996804e-06
Iter: 406 loss: 1.44386013e-06
Iter: 407 loss: 1.40962788e-06
Iter: 408 loss: 1.40650468e-06
Iter: 409 loss: 1.42660951e-06
Iter: 410 loss: 1.40617874e-06
Iter: 411 loss: 1.40345674e-06
Iter: 412 loss: 1.40015618e-06
Iter: 413 loss: 1.39990993e-06
Iter: 414 loss: 1.39552105e-06
Iter: 415 loss: 1.42040426e-06
Iter: 416 loss: 1.39485019e-06
Iter: 417 loss: 1.39188069e-06
Iter: 418 loss: 1.40265934e-06
Iter: 419 loss: 1.39111717e-06
Iter: 420 loss: 1.38734049e-06
Iter: 421 loss: 1.40470559e-06
Iter: 422 loss: 1.38669031e-06
Iter: 423 loss: 1.38398696e-06
Iter: 424 loss: 1.39363488e-06
Iter: 425 loss: 1.3832796e-06
Iter: 426 loss: 1.38114854e-06
Iter: 427 loss: 1.38008227e-06
Iter: 428 loss: 1.37900452e-06
Iter: 429 loss: 1.37572715e-06
Iter: 430 loss: 1.39603367e-06
Iter: 431 loss: 1.37529446e-06
Iter: 432 loss: 1.37233292e-06
Iter: 433 loss: 1.37479037e-06
Iter: 434 loss: 1.37055872e-06
Iter: 435 loss: 1.36713857e-06
Iter: 436 loss: 1.38444557e-06
Iter: 437 loss: 1.36654694e-06
Iter: 438 loss: 1.36372307e-06
Iter: 439 loss: 1.36543531e-06
Iter: 440 loss: 1.36191375e-06
Iter: 441 loss: 1.358551e-06
Iter: 442 loss: 1.35904543e-06
Iter: 443 loss: 1.35597861e-06
Iter: 444 loss: 1.35149855e-06
Iter: 445 loss: 1.37259735e-06
Iter: 446 loss: 1.35073037e-06
Iter: 447 loss: 1.34734705e-06
Iter: 448 loss: 1.36123617e-06
Iter: 449 loss: 1.34661286e-06
Iter: 450 loss: 1.34318725e-06
Iter: 451 loss: 1.34844458e-06
Iter: 452 loss: 1.34158768e-06
Iter: 453 loss: 1.33890148e-06
Iter: 454 loss: 1.33881213e-06
Iter: 455 loss: 1.33689059e-06
Iter: 456 loss: 1.33459e-06
Iter: 457 loss: 1.3342916e-06
Iter: 458 loss: 1.33079504e-06
Iter: 459 loss: 1.33886897e-06
Iter: 460 loss: 1.3295263e-06
Iter: 461 loss: 1.32667424e-06
Iter: 462 loss: 1.32666764e-06
Iter: 463 loss: 1.32412811e-06
Iter: 464 loss: 1.32436276e-06
Iter: 465 loss: 1.32225546e-06
Iter: 466 loss: 1.31993249e-06
Iter: 467 loss: 1.31623096e-06
Iter: 468 loss: 1.31618867e-06
Iter: 469 loss: 1.31472962e-06
Iter: 470 loss: 1.3138789e-06
Iter: 471 loss: 1.31194543e-06
Iter: 472 loss: 1.31047659e-06
Iter: 473 loss: 1.30983744e-06
Iter: 474 loss: 1.30674937e-06
Iter: 475 loss: 1.31473621e-06
Iter: 476 loss: 1.30566673e-06
Iter: 477 loss: 1.30288754e-06
Iter: 478 loss: 1.31371962e-06
Iter: 479 loss: 1.30227431e-06
Iter: 480 loss: 1.29992281e-06
Iter: 481 loss: 1.29840942e-06
Iter: 482 loss: 1.2975064e-06
Iter: 483 loss: 1.29408772e-06
Iter: 484 loss: 1.32859611e-06
Iter: 485 loss: 1.29402872e-06
Iter: 486 loss: 1.29127284e-06
Iter: 487 loss: 1.29908096e-06
Iter: 488 loss: 1.29048294e-06
Iter: 489 loss: 1.28784814e-06
Iter: 490 loss: 1.2901985e-06
Iter: 491 loss: 1.2862547e-06
Iter: 492 loss: 1.28280544e-06
Iter: 493 loss: 1.29202203e-06
Iter: 494 loss: 1.28163106e-06
Iter: 495 loss: 1.27949511e-06
Iter: 496 loss: 1.2795208e-06
Iter: 497 loss: 1.27787348e-06
Iter: 498 loss: 1.27579165e-06
Iter: 499 loss: 1.27566204e-06
Iter: 500 loss: 1.2731166e-06
Iter: 501 loss: 1.30811634e-06
Iter: 502 loss: 1.27310773e-06
Iter: 503 loss: 1.27097701e-06
Iter: 504 loss: 1.27009503e-06
Iter: 505 loss: 1.26887244e-06
Iter: 506 loss: 1.26697682e-06
Iter: 507 loss: 1.26614418e-06
Iter: 508 loss: 1.26508326e-06
Iter: 509 loss: 1.26205737e-06
Iter: 510 loss: 1.28791203e-06
Iter: 511 loss: 1.26187865e-06
Iter: 512 loss: 1.25949464e-06
Iter: 513 loss: 1.27359431e-06
Iter: 514 loss: 1.25909548e-06
Iter: 515 loss: 1.25754741e-06
Iter: 516 loss: 1.25717747e-06
Iter: 517 loss: 1.25606721e-06
Iter: 518 loss: 1.25318752e-06
Iter: 519 loss: 1.25205e-06
Iter: 520 loss: 1.25053771e-06
Iter: 521 loss: 1.24728763e-06
Iter: 522 loss: 1.26855309e-06
Iter: 523 loss: 1.24699511e-06
Iter: 524 loss: 1.24413759e-06
Iter: 525 loss: 1.2564085e-06
Iter: 526 loss: 1.24357166e-06
Iter: 527 loss: 1.24089797e-06
Iter: 528 loss: 1.24569851e-06
Iter: 529 loss: 1.2397395e-06
Iter: 530 loss: 1.23730501e-06
Iter: 531 loss: 1.25031e-06
Iter: 532 loss: 1.23696736e-06
Iter: 533 loss: 1.2344625e-06
Iter: 534 loss: 1.23753659e-06
Iter: 535 loss: 1.23321786e-06
Iter: 536 loss: 1.23061125e-06
Iter: 537 loss: 1.24307871e-06
Iter: 538 loss: 1.23012751e-06
Iter: 539 loss: 1.22814413e-06
Iter: 540 loss: 1.24367443e-06
Iter: 541 loss: 1.22803658e-06
Iter: 542 loss: 1.22650442e-06
Iter: 543 loss: 1.22688789e-06
Iter: 544 loss: 1.22536426e-06
Iter: 545 loss: 1.22286883e-06
Iter: 546 loss: 1.23074437e-06
Iter: 547 loss: 1.22222889e-06
Iter: 548 loss: 1.22022198e-06
Iter: 549 loss: 1.21881033e-06
Iter: 550 loss: 1.21815333e-06
Iter: 551 loss: 1.21558514e-06
Iter: 552 loss: 1.22381698e-06
Iter: 553 loss: 1.21486164e-06
Iter: 554 loss: 1.21273331e-06
Iter: 555 loss: 1.23639984e-06
Iter: 556 loss: 1.21267567e-06
Iter: 557 loss: 1.210753e-06
Iter: 558 loss: 1.21326389e-06
Iter: 559 loss: 1.20980951e-06
Iter: 560 loss: 1.20786058e-06
Iter: 561 loss: 1.20774916e-06
Iter: 562 loss: 1.20624861e-06
Iter: 563 loss: 1.20386812e-06
Iter: 564 loss: 1.20744221e-06
Iter: 565 loss: 1.20272352e-06
Iter: 566 loss: 1.19966057e-06
Iter: 567 loss: 1.21450216e-06
Iter: 568 loss: 1.1990262e-06
Iter: 569 loss: 1.19683818e-06
Iter: 570 loss: 1.203784e-06
Iter: 571 loss: 1.19616288e-06
Iter: 572 loss: 1.19372169e-06
Iter: 573 loss: 1.2012863e-06
Iter: 574 loss: 1.19297601e-06
Iter: 575 loss: 1.19052379e-06
Iter: 576 loss: 1.19643096e-06
Iter: 577 loss: 1.18969626e-06
Iter: 578 loss: 1.18743515e-06
Iter: 579 loss: 1.19912022e-06
Iter: 580 loss: 1.18715161e-06
Iter: 581 loss: 1.1851065e-06
Iter: 582 loss: 1.19054448e-06
Iter: 583 loss: 1.1844204e-06
Iter: 584 loss: 1.18276148e-06
Iter: 585 loss: 1.1943373e-06
Iter: 586 loss: 1.18253342e-06
Iter: 587 loss: 1.18129628e-06
Iter: 588 loss: 1.18345338e-06
Iter: 589 loss: 1.18064418e-06
Iter: 590 loss: 1.178866e-06
Iter: 591 loss: 1.17940806e-06
Iter: 592 loss: 1.17762534e-06
Iter: 593 loss: 1.17540935e-06
Iter: 594 loss: 1.17625871e-06
Iter: 595 loss: 1.17383775e-06
Iter: 596 loss: 1.17174693e-06
Iter: 597 loss: 1.17311538e-06
Iter: 598 loss: 1.17054128e-06
Iter: 599 loss: 1.16861861e-06
Iter: 600 loss: 1.16855267e-06
Iter: 601 loss: 1.16683509e-06
Iter: 602 loss: 1.16473802e-06
Iter: 603 loss: 1.16457795e-06
Iter: 604 loss: 1.16242018e-06
Iter: 605 loss: 1.1685986e-06
Iter: 606 loss: 1.16173169e-06
Iter: 607 loss: 1.15940952e-06
Iter: 608 loss: 1.16387173e-06
Iter: 609 loss: 1.15845796e-06
Iter: 610 loss: 1.15615342e-06
Iter: 611 loss: 1.16470233e-06
Iter: 612 loss: 1.15550824e-06
Iter: 613 loss: 1.15311195e-06
Iter: 614 loss: 1.16431352e-06
Iter: 615 loss: 1.15269768e-06
Iter: 616 loss: 1.1510474e-06
Iter: 617 loss: 1.15731245e-06
Iter: 618 loss: 1.15058583e-06
Iter: 619 loss: 1.14871466e-06
Iter: 620 loss: 1.15345915e-06
Iter: 621 loss: 1.14795512e-06
Iter: 622 loss: 1.14662464e-06
Iter: 623 loss: 1.16503611e-06
Iter: 624 loss: 1.14661259e-06
Iter: 625 loss: 1.14543423e-06
Iter: 626 loss: 1.14378327e-06
Iter: 627 loss: 1.14366958e-06
Iter: 628 loss: 1.14158e-06
Iter: 629 loss: 1.15088278e-06
Iter: 630 loss: 1.14107024e-06
Iter: 631 loss: 1.13940428e-06
Iter: 632 loss: 1.13941314e-06
Iter: 633 loss: 1.13805197e-06
Iter: 634 loss: 1.13570491e-06
Iter: 635 loss: 1.14982447e-06
Iter: 636 loss: 1.13538306e-06
Iter: 637 loss: 1.13356737e-06
Iter: 638 loss: 1.14842828e-06
Iter: 639 loss: 1.13350393e-06
Iter: 640 loss: 1.13198314e-06
Iter: 641 loss: 1.13045076e-06
Iter: 642 loss: 1.13015028e-06
Iter: 643 loss: 1.12803446e-06
Iter: 644 loss: 1.13292094e-06
Iter: 645 loss: 1.12716157e-06
Iter: 646 loss: 1.12487578e-06
Iter: 647 loss: 1.12653481e-06
Iter: 648 loss: 1.1234838e-06
Iter: 649 loss: 1.12170994e-06
Iter: 650 loss: 1.12160819e-06
Iter: 651 loss: 1.12008229e-06
Iter: 652 loss: 1.12129089e-06
Iter: 653 loss: 1.11920031e-06
Iter: 654 loss: 1.11765689e-06
Iter: 655 loss: 1.11966403e-06
Iter: 656 loss: 1.11684562e-06
Iter: 657 loss: 1.11494046e-06
Iter: 658 loss: 1.11786801e-06
Iter: 659 loss: 1.11406666e-06
Iter: 660 loss: 1.11275756e-06
Iter: 661 loss: 1.11273994e-06
Iter: 662 loss: 1.11146664e-06
Iter: 663 loss: 1.11029453e-06
Iter: 664 loss: 1.11003169e-06
Iter: 665 loss: 1.1082675e-06
Iter: 666 loss: 1.11627946e-06
Iter: 667 loss: 1.10795713e-06
Iter: 668 loss: 1.10637529e-06
Iter: 669 loss: 1.10781889e-06
Iter: 670 loss: 1.10546307e-06
Iter: 671 loss: 1.1038469e-06
Iter: 672 loss: 1.10597387e-06
Iter: 673 loss: 1.1030196e-06
Iter: 674 loss: 1.1012753e-06
Iter: 675 loss: 1.10991778e-06
Iter: 676 loss: 1.10098881e-06
Iter: 677 loss: 1.0992361e-06
Iter: 678 loss: 1.10336566e-06
Iter: 679 loss: 1.09858161e-06
Iter: 680 loss: 1.09676e-06
Iter: 681 loss: 1.10755843e-06
Iter: 682 loss: 1.09656526e-06
Iter: 683 loss: 1.09508596e-06
Iter: 684 loss: 1.09568248e-06
Iter: 685 loss: 1.09407529e-06
Iter: 686 loss: 1.09232974e-06
Iter: 687 loss: 1.092057e-06
Iter: 688 loss: 1.09087478e-06
Iter: 689 loss: 1.08847257e-06
Iter: 690 loss: 1.10132783e-06
Iter: 691 loss: 1.08807251e-06
Iter: 692 loss: 1.08664631e-06
Iter: 693 loss: 1.08666222e-06
Iter: 694 loss: 1.08558174e-06
Iter: 695 loss: 1.08465304e-06
Iter: 696 loss: 1.08439792e-06
Iter: 697 loss: 1.08251641e-06
Iter: 698 loss: 1.08351173e-06
Iter: 699 loss: 1.08129029e-06
Iter: 700 loss: 1.07954634e-06
Iter: 701 loss: 1.09238454e-06
Iter: 702 loss: 1.07943947e-06
Iter: 703 loss: 1.07794108e-06
Iter: 704 loss: 1.08445113e-06
Iter: 705 loss: 1.07756864e-06
Iter: 706 loss: 1.07592336e-06
Iter: 707 loss: 1.08318784e-06
Iter: 708 loss: 1.07561709e-06
Iter: 709 loss: 1.07441463e-06
Iter: 710 loss: 1.0767485e-06
Iter: 711 loss: 1.07394681e-06
Iter: 712 loss: 1.07260166e-06
Iter: 713 loss: 1.07347569e-06
Iter: 714 loss: 1.07175458e-06
Iter: 715 loss: 1.07018627e-06
Iter: 716 loss: 1.07134e-06
Iter: 717 loss: 1.06915172e-06
Iter: 718 loss: 1.06718937e-06
Iter: 719 loss: 1.07241237e-06
Iter: 720 loss: 1.06650759e-06
Iter: 721 loss: 1.06456673e-06
Iter: 722 loss: 1.06719745e-06
Iter: 723 loss: 1.06357891e-06
Iter: 724 loss: 1.06210575e-06
Iter: 725 loss: 1.06206983e-06
Iter: 726 loss: 1.06092443e-06
Iter: 727 loss: 1.05988909e-06
Iter: 728 loss: 1.05963011e-06
Iter: 729 loss: 1.0581366e-06
Iter: 730 loss: 1.05814797e-06
Iter: 731 loss: 1.05730646e-06
Iter: 732 loss: 1.05565459e-06
Iter: 733 loss: 1.08363668e-06
Iter: 734 loss: 1.05563697e-06
Iter: 735 loss: 1.05362233e-06
Iter: 736 loss: 1.06711605e-06
Iter: 737 loss: 1.05343327e-06
Iter: 738 loss: 1.05179561e-06
Iter: 739 loss: 1.06543939e-06
Iter: 740 loss: 1.05171807e-06
Iter: 741 loss: 1.05060894e-06
Iter: 742 loss: 1.04923561e-06
Iter: 743 loss: 1.04910873e-06
Iter: 744 loss: 1.04736807e-06
Iter: 745 loss: 1.05416166e-06
Iter: 746 loss: 1.04692185e-06
Iter: 747 loss: 1.04577384e-06
Iter: 748 loss: 1.04575565e-06
Iter: 749 loss: 1.04458684e-06
Iter: 750 loss: 1.04517221e-06
Iter: 751 loss: 1.04387755e-06
Iter: 752 loss: 1.04251762e-06
Iter: 753 loss: 1.04346213e-06
Iter: 754 loss: 1.04175501e-06
Iter: 755 loss: 1.04011406e-06
Iter: 756 loss: 1.04636433e-06
Iter: 757 loss: 1.03974139e-06
Iter: 758 loss: 1.03830075e-06
Iter: 759 loss: 1.03900629e-06
Iter: 760 loss: 1.03723301e-06
Iter: 761 loss: 1.03560092e-06
Iter: 762 loss: 1.03877755e-06
Iter: 763 loss: 1.03489788e-06
Iter: 764 loss: 1.03275056e-06
Iter: 765 loss: 1.03613786e-06
Iter: 766 loss: 1.03170441e-06
Iter: 767 loss: 1.03007642e-06
Iter: 768 loss: 1.04628521e-06
Iter: 769 loss: 1.03003299e-06
Iter: 770 loss: 1.02859178e-06
Iter: 771 loss: 1.03576747e-06
Iter: 772 loss: 1.02838203e-06
Iter: 773 loss: 1.02720276e-06
Iter: 774 loss: 1.02689501e-06
Iter: 775 loss: 1.02612989e-06
Iter: 776 loss: 1.02463525e-06
Iter: 777 loss: 1.03242826e-06
Iter: 778 loss: 1.02438662e-06
Iter: 779 loss: 1.02300623e-06
Iter: 780 loss: 1.02620857e-06
Iter: 781 loss: 1.02255751e-06
Iter: 782 loss: 1.02099898e-06
Iter: 783 loss: 1.02632282e-06
Iter: 784 loss: 1.02060244e-06
Iter: 785 loss: 1.01913975e-06
Iter: 786 loss: 1.02092122e-06
Iter: 787 loss: 1.01836054e-06
Iter: 788 loss: 1.01711612e-06
Iter: 789 loss: 1.0178087e-06
Iter: 790 loss: 1.0162928e-06
Iter: 791 loss: 1.01470619e-06
Iter: 792 loss: 1.0385686e-06
Iter: 793 loss: 1.01470573e-06
Iter: 794 loss: 1.01363776e-06
Iter: 795 loss: 1.01308797e-06
Iter: 796 loss: 1.01264868e-06
Iter: 797 loss: 1.0115624e-06
Iter: 798 loss: 1.01465503e-06
Iter: 799 loss: 1.01121941e-06
Iter: 800 loss: 1.00999614e-06
Iter: 801 loss: 1.01012006e-06
Iter: 802 loss: 1.00901775e-06
Iter: 803 loss: 1.00738418e-06
Iter: 804 loss: 1.02422712e-06
Iter: 805 loss: 1.00731393e-06
Iter: 806 loss: 1.00628063e-06
Iter: 807 loss: 1.00515945e-06
Iter: 808 loss: 1.00498119e-06
Iter: 809 loss: 1.00317311e-06
Iter: 810 loss: 1.01480668e-06
Iter: 811 loss: 1.00302941e-06
Iter: 812 loss: 1.00190687e-06
Iter: 813 loss: 1.01788748e-06
Iter: 814 loss: 1.00186844e-06
Iter: 815 loss: 1.00117188e-06
Iter: 816 loss: 9.99344593e-07
Iter: 817 loss: 1.01675289e-06
Iter: 818 loss: 9.99101303e-07
Iter: 819 loss: 9.97419e-07
Iter: 820 loss: 1.02226932e-06
Iter: 821 loss: 9.97409e-07
Iter: 822 loss: 9.96146696e-07
Iter: 823 loss: 1.00510454e-06
Iter: 824 loss: 9.96082463e-07
Iter: 825 loss: 9.95135451e-07
Iter: 826 loss: 9.94798256e-07
Iter: 827 loss: 9.94279276e-07
Iter: 828 loss: 9.92835908e-07
Iter: 829 loss: 9.9624458e-07
Iter: 830 loss: 9.92311e-07
Iter: 831 loss: 9.91058187e-07
Iter: 832 loss: 1.01085152e-06
Iter: 833 loss: 9.91035449e-07
Iter: 834 loss: 9.90422677e-07
Iter: 835 loss: 9.90046601e-07
Iter: 836 loss: 9.89760451e-07
Iter: 837 loss: 9.88650754e-07
Iter: 838 loss: 9.87888484e-07
Iter: 839 loss: 9.87505246e-07
Iter: 840 loss: 9.85903171e-07
Iter: 841 loss: 9.98945893e-07
Iter: 842 loss: 9.85824499e-07
Iter: 843 loss: 9.84829285e-07
Iter: 844 loss: 9.8551061e-07
Iter: 845 loss: 9.84230837e-07
Iter: 846 loss: 9.82843176e-07
Iter: 847 loss: 9.86110763e-07
Iter: 848 loss: 9.82287929e-07
Iter: 849 loss: 9.81143785e-07
Iter: 850 loss: 9.93847607e-07
Iter: 851 loss: 9.81139237e-07
Iter: 852 loss: 9.80077e-07
Iter: 853 loss: 9.79889592e-07
Iter: 854 loss: 9.79134e-07
Iter: 855 loss: 9.77717377e-07
Iter: 856 loss: 9.84846906e-07
Iter: 857 loss: 9.77474201e-07
Iter: 858 loss: 9.76492856e-07
Iter: 859 loss: 9.81692892e-07
Iter: 860 loss: 9.7625923e-07
Iter: 861 loss: 9.75355533e-07
Iter: 862 loss: 9.74301e-07
Iter: 863 loss: 9.7423117e-07
Iter: 864 loss: 9.73085434e-07
Iter: 865 loss: 9.73096917e-07
Iter: 866 loss: 9.72075895e-07
Iter: 867 loss: 9.72784392e-07
Iter: 868 loss: 9.71498594e-07
Iter: 869 loss: 9.70495e-07
Iter: 870 loss: 9.7727434e-07
Iter: 871 loss: 9.70420842e-07
Iter: 872 loss: 9.69444272e-07
Iter: 873 loss: 9.69472808e-07
Iter: 874 loss: 9.68677568e-07
Iter: 875 loss: 9.67532628e-07
Iter: 876 loss: 9.68137783e-07
Iter: 877 loss: 9.66828679e-07
Iter: 878 loss: 9.65490131e-07
Iter: 879 loss: 9.69361736e-07
Iter: 880 loss: 9.65122126e-07
Iter: 881 loss: 9.63719344e-07
Iter: 882 loss: 9.65530717e-07
Iter: 883 loss: 9.63068942e-07
Iter: 884 loss: 9.61721412e-07
Iter: 885 loss: 9.67897563e-07
Iter: 886 loss: 9.61498245e-07
Iter: 887 loss: 9.60286343e-07
Iter: 888 loss: 9.66670086e-07
Iter: 889 loss: 9.60113766e-07
Iter: 890 loss: 9.58989631e-07
Iter: 891 loss: 9.58569558e-07
Iter: 892 loss: 9.57922e-07
Iter: 893 loss: 9.57255111e-07
Iter: 894 loss: 9.57073667e-07
Iter: 895 loss: 9.5641758e-07
Iter: 896 loss: 9.55301e-07
Iter: 897 loss: 9.82876e-07
Iter: 898 loss: 9.55282871e-07
Iter: 899 loss: 9.53895324e-07
Iter: 900 loss: 9.56750569e-07
Iter: 901 loss: 9.53324218e-07
Iter: 902 loss: 9.52125902e-07
Iter: 903 loss: 9.52097764e-07
Iter: 904 loss: 9.5143713e-07
Iter: 905 loss: 9.53261917e-07
Iter: 906 loss: 9.51215952e-07
Iter: 907 loss: 9.5037808e-07
Iter: 908 loss: 9.50393371e-07
Iter: 909 loss: 9.49681237e-07
Iter: 910 loss: 9.48599e-07
Iter: 911 loss: 9.51370339e-07
Iter: 912 loss: 9.48253842e-07
Iter: 913 loss: 9.47231e-07
Iter: 914 loss: 9.52765618e-07
Iter: 915 loss: 9.47063029e-07
Iter: 916 loss: 9.46188948e-07
Iter: 917 loss: 9.45641432e-07
Iter: 918 loss: 9.45216414e-07
Iter: 919 loss: 9.44092562e-07
Iter: 920 loss: 9.45693273e-07
Iter: 921 loss: 9.4350861e-07
Iter: 922 loss: 9.42163297e-07
Iter: 923 loss: 9.4831131e-07
Iter: 924 loss: 9.41917733e-07
Iter: 925 loss: 9.40777795e-07
Iter: 926 loss: 9.42170573e-07
Iter: 927 loss: 9.40201858e-07
Iter: 928 loss: 9.38748826e-07
Iter: 929 loss: 9.44495469e-07
Iter: 930 loss: 9.38438802e-07
Iter: 931 loss: 9.37343259e-07
Iter: 932 loss: 9.43229452e-07
Iter: 933 loss: 9.37203254e-07
Iter: 934 loss: 9.36210199e-07
Iter: 935 loss: 9.41656367e-07
Iter: 936 loss: 9.3610322e-07
Iter: 937 loss: 9.35255457e-07
Iter: 938 loss: 9.35575486e-07
Iter: 939 loss: 9.34677701e-07
Iter: 940 loss: 9.33537649e-07
Iter: 941 loss: 9.37526e-07
Iter: 942 loss: 9.33244621e-07
Iter: 943 loss: 9.3244762e-07
Iter: 944 loss: 9.40812129e-07
Iter: 945 loss: 9.32398848e-07
Iter: 946 loss: 9.31647605e-07
Iter: 947 loss: 9.30507497e-07
Iter: 948 loss: 9.30482e-07
Iter: 949 loss: 9.29545536e-07
Iter: 950 loss: 9.36727815e-07
Iter: 951 loss: 9.29464932e-07
Iter: 952 loss: 9.28603185e-07
Iter: 953 loss: 9.31478382e-07
Iter: 954 loss: 9.28334202e-07
Iter: 955 loss: 9.27440794e-07
Iter: 956 loss: 9.26543748e-07
Iter: 957 loss: 9.26371627e-07
Iter: 958 loss: 9.25139375e-07
Iter: 959 loss: 9.28083523e-07
Iter: 960 loss: 9.24733399e-07
Iter: 961 loss: 9.23546224e-07
Iter: 962 loss: 9.33556407e-07
Iter: 963 loss: 9.23503308e-07
Iter: 964 loss: 9.225854e-07
Iter: 965 loss: 9.24395806e-07
Iter: 966 loss: 9.22198751e-07
Iter: 967 loss: 9.2104824e-07
Iter: 968 loss: 9.23360176e-07
Iter: 969 loss: 9.20604577e-07
Iter: 970 loss: 9.195046e-07
Iter: 971 loss: 9.22021741e-07
Iter: 972 loss: 9.19131935e-07
Iter: 973 loss: 9.18403316e-07
Iter: 974 loss: 9.24663652e-07
Iter: 975 loss: 9.1833482e-07
Iter: 976 loss: 9.17449825e-07
Iter: 977 loss: 9.1783e-07
Iter: 978 loss: 9.1680522e-07
Iter: 979 loss: 9.15899363e-07
Iter: 980 loss: 9.19922115e-07
Iter: 981 loss: 9.15698934e-07
Iter: 982 loss: 9.14851057e-07
Iter: 983 loss: 9.20960701e-07
Iter: 984 loss: 9.14708608e-07
Iter: 985 loss: 9.14275574e-07
Iter: 986 loss: 9.13263591e-07
Iter: 987 loss: 9.31097702e-07
Iter: 988 loss: 9.13217036e-07
Iter: 989 loss: 9.12107225e-07
Iter: 990 loss: 9.23632342e-07
Iter: 991 loss: 9.12097732e-07
Iter: 992 loss: 9.11293171e-07
Iter: 993 loss: 9.13693214e-07
Iter: 994 loss: 9.11067957e-07
Iter: 995 loss: 9.10192057e-07
Iter: 996 loss: 9.10899871e-07
Iter: 997 loss: 9.09650566e-07
Iter: 998 loss: 9.08746472e-07
Iter: 999 loss: 9.11268955e-07
Iter: 1000 loss: 9.08457082e-07
Iter: 1001 loss: 9.07517688e-07
Iter: 1002 loss: 9.07265644e-07
Iter: 1003 loss: 9.06640594e-07
Iter: 1004 loss: 9.05437162e-07
Iter: 1005 loss: 9.15588316e-07
Iter: 1006 loss: 9.05342745e-07
Iter: 1007 loss: 9.04571834e-07
Iter: 1008 loss: 9.07639276e-07
Iter: 1009 loss: 9.04366289e-07
Iter: 1010 loss: 9.03391879e-07
Iter: 1011 loss: 9.04723265e-07
Iter: 1012 loss: 9.02951058e-07
Iter: 1013 loss: 9.0198256e-07
Iter: 1014 loss: 9.07165941e-07
Iter: 1015 loss: 9.01842384e-07
Iter: 1016 loss: 9.01118085e-07
Iter: 1017 loss: 9.06158448e-07
Iter: 1018 loss: 9.0103822e-07
Iter: 1019 loss: 9.00403506e-07
Iter: 1020 loss: 9.00096325e-07
Iter: 1021 loss: 8.99749e-07
Iter: 1022 loss: 8.98864926e-07
Iter: 1023 loss: 9.07387857e-07
Iter: 1024 loss: 8.98846793e-07
Iter: 1025 loss: 8.98212875e-07
Iter: 1026 loss: 8.97496193e-07
Iter: 1027 loss: 8.97466293e-07
Iter: 1028 loss: 8.96352617e-07
Iter: 1029 loss: 8.97633697e-07
Iter: 1030 loss: 8.95830567e-07
Iter: 1031 loss: 8.94851098e-07
Iter: 1032 loss: 9.03570367e-07
Iter: 1033 loss: 8.94719506e-07
Iter: 1034 loss: 8.93894367e-07
Iter: 1035 loss: 8.98496182e-07
Iter: 1036 loss: 8.93794e-07
Iter: 1037 loss: 8.93160404e-07
Iter: 1038 loss: 8.92041612e-07
Iter: 1039 loss: 9.15831606e-07
Iter: 1040 loss: 8.92027401e-07
Iter: 1041 loss: 8.90839033e-07
Iter: 1042 loss: 8.9484007e-07
Iter: 1043 loss: 8.90552883e-07
Iter: 1044 loss: 8.89254409e-07
Iter: 1045 loss: 8.93579454e-07
Iter: 1046 loss: 8.88890781e-07
Iter: 1047 loss: 8.87959686e-07
Iter: 1048 loss: 8.87954968e-07
Iter: 1049 loss: 8.87268357e-07
Iter: 1050 loss: 8.87584861e-07
Iter: 1051 loss: 8.86754094e-07
Iter: 1052 loss: 8.85921565e-07
Iter: 1053 loss: 8.91884042e-07
Iter: 1054 loss: 8.85839825e-07
Iter: 1055 loss: 8.85019574e-07
Iter: 1056 loss: 8.86045427e-07
Iter: 1057 loss: 8.84516624e-07
Iter: 1058 loss: 8.83851e-07
Iter: 1059 loss: 8.90313913e-07
Iter: 1060 loss: 8.83835469e-07
Iter: 1061 loss: 8.83336668e-07
Iter: 1062 loss: 8.82977702e-07
Iter: 1063 loss: 8.82861229e-07
Iter: 1064 loss: 8.81829351e-07
Iter: 1065 loss: 8.82953259e-07
Iter: 1066 loss: 8.81309e-07
Iter: 1067 loss: 8.80412927e-07
Iter: 1068 loss: 8.83295456e-07
Iter: 1069 loss: 8.80125185e-07
Iter: 1070 loss: 8.79393554e-07
Iter: 1071 loss: 8.85669238e-07
Iter: 1072 loss: 8.79361608e-07
Iter: 1073 loss: 8.78738433e-07
Iter: 1074 loss: 8.79117295e-07
Iter: 1075 loss: 8.78350875e-07
Iter: 1076 loss: 8.77368848e-07
Iter: 1077 loss: 8.77595312e-07
Iter: 1078 loss: 8.76622948e-07
Iter: 1079 loss: 8.75712772e-07
Iter: 1080 loss: 8.77677508e-07
Iter: 1081 loss: 8.75329192e-07
Iter: 1082 loss: 8.74271677e-07
Iter: 1083 loss: 8.76483909e-07
Iter: 1084 loss: 8.73917884e-07
Iter: 1085 loss: 8.72777093e-07
Iter: 1086 loss: 8.78931189e-07
Iter: 1087 loss: 8.72642772e-07
Iter: 1088 loss: 8.71896532e-07
Iter: 1089 loss: 8.8300942e-07
Iter: 1090 loss: 8.7193e-07
Iter: 1091 loss: 8.71449288e-07
Iter: 1092 loss: 8.71522104e-07
Iter: 1093 loss: 8.71071506e-07
Iter: 1094 loss: 8.70289909e-07
Iter: 1095 loss: 8.72031194e-07
Iter: 1096 loss: 8.70004328e-07
Iter: 1097 loss: 8.69243536e-07
Iter: 1098 loss: 8.70910412e-07
Iter: 1099 loss: 8.6897694e-07
Iter: 1100 loss: 8.68226152e-07
Iter: 1101 loss: 8.70356189e-07
Iter: 1102 loss: 8.6792727e-07
Iter: 1103 loss: 8.67163294e-07
Iter: 1104 loss: 8.67160679e-07
Iter: 1105 loss: 8.66536084e-07
Iter: 1106 loss: 8.65530467e-07
Iter: 1107 loss: 8.68741552e-07
Iter: 1108 loss: 8.65194124e-07
Iter: 1109 loss: 8.64410822e-07
Iter: 1110 loss: 8.69961752e-07
Iter: 1111 loss: 8.64318849e-07
Iter: 1112 loss: 8.63534638e-07
Iter: 1113 loss: 8.65214929e-07
Iter: 1114 loss: 8.63172374e-07
Iter: 1115 loss: 8.62333536e-07
Iter: 1116 loss: 8.63796913e-07
Iter: 1117 loss: 8.61994749e-07
Iter: 1118 loss: 8.61271587e-07
Iter: 1119 loss: 8.62681418e-07
Iter: 1120 loss: 8.60937178e-07
Iter: 1121 loss: 8.60007958e-07
Iter: 1122 loss: 8.61911758e-07
Iter: 1123 loss: 8.59665931e-07
Iter: 1124 loss: 8.58692943e-07
Iter: 1125 loss: 8.59957652e-07
Iter: 1126 loss: 8.58175895e-07
Iter: 1127 loss: 8.57672717e-07
Iter: 1128 loss: 8.57577788e-07
Iter: 1129 loss: 8.57147199e-07
Iter: 1130 loss: 8.56675911e-07
Iter: 1131 loss: 8.56536587e-07
Iter: 1132 loss: 8.55871519e-07
Iter: 1133 loss: 8.58882231e-07
Iter: 1134 loss: 8.55754195e-07
Iter: 1135 loss: 8.54946734e-07
Iter: 1136 loss: 8.56084398e-07
Iter: 1137 loss: 8.54504151e-07
Iter: 1138 loss: 8.53927077e-07
Iter: 1139 loss: 8.5454667e-07
Iter: 1140 loss: 8.53546339e-07
Iter: 1141 loss: 8.52688402e-07
Iter: 1142 loss: 8.56325755e-07
Iter: 1143 loss: 8.52487517e-07
Iter: 1144 loss: 8.51822847e-07
Iter: 1145 loss: 8.5139277e-07
Iter: 1146 loss: 8.51135383e-07
Iter: 1147 loss: 8.50157107e-07
Iter: 1148 loss: 8.58713747e-07
Iter: 1149 loss: 8.50095716e-07
Iter: 1150 loss: 8.49323214e-07
Iter: 1151 loss: 8.52912535e-07
Iter: 1152 loss: 8.49148762e-07
Iter: 1153 loss: 8.48592265e-07
Iter: 1154 loss: 8.48109153e-07
Iter: 1155 loss: 8.47900083e-07
Iter: 1156 loss: 8.47016793e-07
Iter: 1157 loss: 8.52109679e-07
Iter: 1158 loss: 8.46907483e-07
Iter: 1159 loss: 8.45990712e-07
Iter: 1160 loss: 8.46492071e-07
Iter: 1161 loss: 8.45480599e-07
Iter: 1162 loss: 8.44895339e-07
Iter: 1163 loss: 8.44907618e-07
Iter: 1164 loss: 8.44388467e-07
Iter: 1165 loss: 8.45296313e-07
Iter: 1166 loss: 8.44163537e-07
Iter: 1167 loss: 8.4343958e-07
Iter: 1168 loss: 8.43294345e-07
Iter: 1169 loss: 8.42870577e-07
Iter: 1170 loss: 8.42099e-07
Iter: 1171 loss: 8.46584953e-07
Iter: 1172 loss: 8.4203225e-07
Iter: 1173 loss: 8.41305678e-07
Iter: 1174 loss: 8.43249e-07
Iter: 1175 loss: 8.41067674e-07
Iter: 1176 loss: 8.40397092e-07
Iter: 1177 loss: 8.39520965e-07
Iter: 1178 loss: 8.39474126e-07
Iter: 1179 loss: 8.38714413e-07
Iter: 1180 loss: 8.386952e-07
Iter: 1181 loss: 8.3810221e-07
Iter: 1182 loss: 8.3785369e-07
Iter: 1183 loss: 8.37524794e-07
Iter: 1184 loss: 8.36620188e-07
Iter: 1185 loss: 8.40454959e-07
Iter: 1186 loss: 8.36482343e-07
Iter: 1187 loss: 8.35834499e-07
Iter: 1188 loss: 8.42080226e-07
Iter: 1189 loss: 8.35868036e-07
Iter: 1190 loss: 8.35364517e-07
Iter: 1191 loss: 8.34679156e-07
Iter: 1192 loss: 8.34625553e-07
Iter: 1193 loss: 8.33583556e-07
Iter: 1194 loss: 8.36386675e-07
Iter: 1195 loss: 8.33298941e-07
Iter: 1196 loss: 8.32525814e-07
Iter: 1197 loss: 8.36171466e-07
Iter: 1198 loss: 8.32401838e-07
Iter: 1199 loss: 8.316606e-07
Iter: 1200 loss: 8.37823791e-07
Iter: 1201 loss: 8.31582e-07
Iter: 1202 loss: 8.31011562e-07
Iter: 1203 loss: 8.31547425e-07
Iter: 1204 loss: 8.30641e-07
Iter: 1205 loss: 8.30096781e-07
Iter: 1206 loss: 8.31182092e-07
Iter: 1207 loss: 8.29896294e-07
Iter: 1208 loss: 8.29212752e-07
Iter: 1209 loss: 8.30787485e-07
Iter: 1210 loss: 8.28957525e-07
Iter: 1211 loss: 8.28271482e-07
Iter: 1212 loss: 8.30554768e-07
Iter: 1213 loss: 8.2809305e-07
Iter: 1214 loss: 8.27620056e-07
Iter: 1215 loss: 8.27548206e-07
Iter: 1216 loss: 8.27173267e-07
Iter: 1217 loss: 8.26210567e-07
Iter: 1218 loss: 8.2792576e-07
Iter: 1219 loss: 8.25873485e-07
Iter: 1220 loss: 8.25165557e-07
Iter: 1221 loss: 8.32571686e-07
Iter: 1222 loss: 8.25165728e-07
Iter: 1223 loss: 8.24531867e-07
Iter: 1224 loss: 8.24572794e-07
Iter: 1225 loss: 8.24039148e-07
Iter: 1226 loss: 8.23323774e-07
Iter: 1227 loss: 8.27584699e-07
Iter: 1228 loss: 8.23233052e-07
Iter: 1229 loss: 8.22524839e-07
Iter: 1230 loss: 8.24014933e-07
Iter: 1231 loss: 8.2227433e-07
Iter: 1232 loss: 8.21746482e-07
Iter: 1233 loss: 8.21617903e-07
Iter: 1234 loss: 8.21216702e-07
Iter: 1235 loss: 8.20432092e-07
Iter: 1236 loss: 8.25047834e-07
Iter: 1237 loss: 8.20298453e-07
Iter: 1238 loss: 8.19540219e-07
Iter: 1239 loss: 8.25419647e-07
Iter: 1240 loss: 8.19446711e-07
Iter: 1241 loss: 8.19007425e-07
Iter: 1242 loss: 8.18245553e-07
Iter: 1243 loss: 8.36271056e-07
Iter: 1244 loss: 8.18245951e-07
Iter: 1245 loss: 8.17758291e-07
Iter: 1246 loss: 8.17700311e-07
Iter: 1247 loss: 8.17207e-07
Iter: 1248 loss: 8.16455895e-07
Iter: 1249 loss: 8.16480679e-07
Iter: 1250 loss: 8.15654857e-07
Iter: 1251 loss: 8.21803383e-07
Iter: 1252 loss: 8.15562203e-07
Iter: 1253 loss: 8.14970633e-07
Iter: 1254 loss: 8.15388034e-07
Iter: 1255 loss: 8.14644523e-07
Iter: 1256 loss: 8.13987583e-07
Iter: 1257 loss: 8.16594593e-07
Iter: 1258 loss: 8.13796646e-07
Iter: 1259 loss: 8.13003453e-07
Iter: 1260 loss: 8.15382805e-07
Iter: 1261 loss: 8.12773465e-07
Iter: 1262 loss: 8.121051e-07
Iter: 1263 loss: 8.14716259e-07
Iter: 1264 loss: 8.11934683e-07
Iter: 1265 loss: 8.11293717e-07
Iter: 1266 loss: 8.12013e-07
Iter: 1267 loss: 8.10884217e-07
Iter: 1268 loss: 8.10179529e-07
Iter: 1269 loss: 8.1404653e-07
Iter: 1270 loss: 8.10131041e-07
Iter: 1271 loss: 8.09512301e-07
Iter: 1272 loss: 8.09563744e-07
Iter: 1273 loss: 8.09073583e-07
Iter: 1274 loss: 8.08595587e-07
Iter: 1275 loss: 8.08576033e-07
Iter: 1276 loss: 8.08155164e-07
Iter: 1277 loss: 8.07753679e-07
Iter: 1278 loss: 8.07643744e-07
Iter: 1279 loss: 8.07036258e-07
Iter: 1280 loss: 8.06617948e-07
Iter: 1281 loss: 8.06372498e-07
Iter: 1282 loss: 8.05837487e-07
Iter: 1283 loss: 8.05764898e-07
Iter: 1284 loss: 8.05327716e-07
Iter: 1285 loss: 8.04707724e-07
Iter: 1286 loss: 8.04666854e-07
Iter: 1287 loss: 8.03907596e-07
Iter: 1288 loss: 8.05614832e-07
Iter: 1289 loss: 8.03646913e-07
Iter: 1290 loss: 8.0285713e-07
Iter: 1291 loss: 8.06555249e-07
Iter: 1292 loss: 8.02692625e-07
Iter: 1293 loss: 8.01982765e-07
Iter: 1294 loss: 8.04369165e-07
Iter: 1295 loss: 8.017808e-07
Iter: 1296 loss: 8.01093393e-07
Iter: 1297 loss: 8.04011336e-07
Iter: 1298 loss: 8.01006536e-07
Iter: 1299 loss: 8.00354087e-07
Iter: 1300 loss: 8.01359761e-07
Iter: 1301 loss: 8.00070893e-07
Iter: 1302 loss: 7.99448742e-07
Iter: 1303 loss: 8.01570195e-07
Iter: 1304 loss: 7.99296174e-07
Iter: 1305 loss: 7.98626331e-07
Iter: 1306 loss: 7.99757856e-07
Iter: 1307 loss: 7.98360702e-07
Iter: 1308 loss: 7.97807161e-07
Iter: 1309 loss: 8.03119519e-07
Iter: 1310 loss: 7.9776396e-07
Iter: 1311 loss: 7.97281132e-07
Iter: 1312 loss: 7.97832058e-07
Iter: 1313 loss: 7.97028633e-07
Iter: 1314 loss: 7.96469521e-07
Iter: 1315 loss: 7.96805864e-07
Iter: 1316 loss: 7.96098618e-07
Iter: 1317 loss: 7.95501307e-07
Iter: 1318 loss: 7.95374262e-07
Iter: 1319 loss: 7.94945208e-07
Iter: 1320 loss: 7.94195557e-07
Iter: 1321 loss: 8.06585945e-07
Iter: 1322 loss: 7.94197035e-07
Iter: 1323 loss: 7.93608933e-07
Iter: 1324 loss: 7.94271386e-07
Iter: 1325 loss: 7.93343077e-07
Iter: 1326 loss: 7.92800108e-07
Iter: 1327 loss: 7.92113724e-07
Iter: 1328 loss: 7.9203619e-07
Iter: 1329 loss: 7.91198772e-07
Iter: 1330 loss: 7.98770657e-07
Iter: 1331 loss: 7.91109073e-07
Iter: 1332 loss: 7.90467425e-07
Iter: 1333 loss: 7.95589e-07
Iter: 1334 loss: 7.90411946e-07
Iter: 1335 loss: 7.89926787e-07
Iter: 1336 loss: 7.90908757e-07
Iter: 1337 loss: 7.89686396e-07
Iter: 1338 loss: 7.89111084e-07
Iter: 1339 loss: 7.89721355e-07
Iter: 1340 loss: 7.88872967e-07
Iter: 1341 loss: 7.88132411e-07
Iter: 1342 loss: 7.90686158e-07
Iter: 1343 loss: 7.8792732e-07
Iter: 1344 loss: 7.8735e-07
Iter: 1345 loss: 7.9013671e-07
Iter: 1346 loss: 7.87252e-07
Iter: 1347 loss: 7.8667972e-07
Iter: 1348 loss: 7.89288435e-07
Iter: 1349 loss: 7.86593091e-07
Iter: 1350 loss: 7.86151077e-07
Iter: 1351 loss: 7.85918928e-07
Iter: 1352 loss: 7.85732311e-07
Iter: 1353 loss: 7.85019665e-07
Iter: 1354 loss: 7.86210705e-07
Iter: 1355 loss: 7.84687131e-07
Iter: 1356 loss: 7.8412063e-07
Iter: 1357 loss: 7.87771569e-07
Iter: 1358 loss: 7.84059409e-07
Iter: 1359 loss: 7.83487565e-07
Iter: 1360 loss: 7.84953613e-07
Iter: 1361 loss: 7.83316864e-07
Iter: 1362 loss: 7.82586653e-07
Iter: 1363 loss: 7.8326434e-07
Iter: 1364 loss: 7.82253551e-07
Iter: 1365 loss: 7.81566e-07
Iter: 1366 loss: 7.83732162e-07
Iter: 1367 loss: 7.81439098e-07
Iter: 1368 loss: 7.80852361e-07
Iter: 1369 loss: 7.79988852e-07
Iter: 1370 loss: 7.79989136e-07
Iter: 1371 loss: 7.79726e-07
Iter: 1372 loss: 7.79428433e-07
Iter: 1373 loss: 7.78941512e-07
Iter: 1374 loss: 7.78498816e-07
Iter: 1375 loss: 7.78399738e-07
Iter: 1376 loss: 7.77668561e-07
Iter: 1377 loss: 7.79841116e-07
Iter: 1378 loss: 7.77430841e-07
Iter: 1379 loss: 7.76781917e-07
Iter: 1380 loss: 7.84730503e-07
Iter: 1381 loss: 7.7678942e-07
Iter: 1382 loss: 7.76395666e-07
Iter: 1383 loss: 7.77371042e-07
Iter: 1384 loss: 7.76278625e-07
Iter: 1385 loss: 7.75770559e-07
Iter: 1386 loss: 7.75486228e-07
Iter: 1387 loss: 7.75291198e-07
Iter: 1388 loss: 7.74584691e-07
Iter: 1389 loss: 7.75271815e-07
Iter: 1390 loss: 7.74246359e-07
Iter: 1391 loss: 7.73644388e-07
Iter: 1392 loss: 7.80953371e-07
Iter: 1393 loss: 7.73624436e-07
Iter: 1394 loss: 7.73166e-07
Iter: 1395 loss: 7.73441343e-07
Iter: 1396 loss: 7.72832209e-07
Iter: 1397 loss: 7.72142357e-07
Iter: 1398 loss: 7.75138176e-07
Iter: 1399 loss: 7.72029466e-07
Iter: 1400 loss: 7.71575856e-07
Iter: 1401 loss: 7.71490818e-07
Iter: 1402 loss: 7.71196e-07
Iter: 1403 loss: 7.70463885e-07
Iter: 1404 loss: 7.70993211e-07
Iter: 1405 loss: 7.70083886e-07
Iter: 1406 loss: 7.69287567e-07
Iter: 1407 loss: 7.76998945e-07
Iter: 1408 loss: 7.69259373e-07
Iter: 1409 loss: 7.68692928e-07
Iter: 1410 loss: 7.71322334e-07
Iter: 1411 loss: 7.68610391e-07
Iter: 1412 loss: 7.68095106e-07
Iter: 1413 loss: 7.68516e-07
Iter: 1414 loss: 7.67728807e-07
Iter: 1415 loss: 7.67116717e-07
Iter: 1416 loss: 7.68143536e-07
Iter: 1417 loss: 7.66868595e-07
Iter: 1418 loss: 7.66281687e-07
Iter: 1419 loss: 7.7500215e-07
Iter: 1420 loss: 7.66292715e-07
Iter: 1421 loss: 7.65964216e-07
Iter: 1422 loss: 7.65526579e-07
Iter: 1423 loss: 7.65488153e-07
Iter: 1424 loss: 7.64890956e-07
Iter: 1425 loss: 7.6851677e-07
Iter: 1426 loss: 7.64809329e-07
Iter: 1427 loss: 7.6428438e-07
Iter: 1428 loss: 7.63940307e-07
Iter: 1429 loss: 7.63726518e-07
Iter: 1430 loss: 7.63087542e-07
Iter: 1431 loss: 7.67192887e-07
Iter: 1432 loss: 7.63018193e-07
Iter: 1433 loss: 7.62399679e-07
Iter: 1434 loss: 7.66117182e-07
Iter: 1435 loss: 7.6237842e-07
Iter: 1436 loss: 7.61884621e-07
Iter: 1437 loss: 7.61736828e-07
Iter: 1438 loss: 7.61400941e-07
Iter: 1439 loss: 7.60848252e-07
Iter: 1440 loss: 7.63471462e-07
Iter: 1441 loss: 7.60676926e-07
Iter: 1442 loss: 7.60119178e-07
Iter: 1443 loss: 7.60509636e-07
Iter: 1444 loss: 7.59718375e-07
Iter: 1445 loss: 7.59103159e-07
Iter: 1446 loss: 7.60567787e-07
Iter: 1447 loss: 7.58827753e-07
Iter: 1448 loss: 7.58256306e-07
Iter: 1449 loss: 7.64551601e-07
Iter: 1450 loss: 7.58253805e-07
Iter: 1451 loss: 7.57714247e-07
Iter: 1452 loss: 7.58213105e-07
Iter: 1453 loss: 7.57424459e-07
Iter: 1454 loss: 7.56827831e-07
Iter: 1455 loss: 7.58622264e-07
Iter: 1456 loss: 7.56643203e-07
Iter: 1457 loss: 7.56196073e-07
Iter: 1458 loss: 7.62034631e-07
Iter: 1459 loss: 7.56185386e-07
Iter: 1460 loss: 7.55854785e-07
Iter: 1461 loss: 7.55152e-07
Iter: 1462 loss: 7.66749679e-07
Iter: 1463 loss: 7.55150268e-07
Iter: 1464 loss: 7.54514474e-07
Iter: 1465 loss: 7.59678e-07
Iter: 1466 loss: 7.54449843e-07
Iter: 1467 loss: 7.53899371e-07
Iter: 1468 loss: 7.5484229e-07
Iter: 1469 loss: 7.53562063e-07
Iter: 1470 loss: 7.52964922e-07
Iter: 1471 loss: 7.55227e-07
Iter: 1472 loss: 7.52815254e-07
Iter: 1473 loss: 7.52239259e-07
Iter: 1474 loss: 7.53994584e-07
Iter: 1475 loss: 7.52111077e-07
Iter: 1476 loss: 7.5146346e-07
Iter: 1477 loss: 7.53690699e-07
Iter: 1478 loss: 7.51311177e-07
Iter: 1479 loss: 7.50788445e-07
Iter: 1480 loss: 7.5048456e-07
Iter: 1481 loss: 7.5029925e-07
Iter: 1482 loss: 7.49571541e-07
Iter: 1483 loss: 7.52096639e-07
Iter: 1484 loss: 7.49372475e-07
Iter: 1485 loss: 7.48826722e-07
Iter: 1486 loss: 7.52431731e-07
Iter: 1487 loss: 7.48723778e-07
Iter: 1488 loss: 7.48151251e-07
Iter: 1489 loss: 7.49226842e-07
Iter: 1490 loss: 7.47943716e-07
Iter: 1491 loss: 7.47460888e-07
Iter: 1492 loss: 7.51973914e-07
Iter: 1493 loss: 7.47390914e-07
Iter: 1494 loss: 7.46926503e-07
Iter: 1495 loss: 7.47318381e-07
Iter: 1496 loss: 7.46629894e-07
Iter: 1497 loss: 7.46235742e-07
Iter: 1498 loss: 7.50997e-07
Iter: 1499 loss: 7.46223179e-07
Iter: 1500 loss: 7.45889395e-07
Iter: 1501 loss: 7.45050102e-07
Iter: 1502 loss: 7.53020458e-07
Iter: 1503 loss: 7.44927092e-07
Iter: 1504 loss: 7.44179147e-07
Iter: 1505 loss: 7.52557071e-07
Iter: 1506 loss: 7.44184376e-07
Iter: 1507 loss: 7.4366028e-07
Iter: 1508 loss: 7.44980355e-07
Iter: 1509 loss: 7.43476789e-07
Iter: 1510 loss: 7.42858e-07
Iter: 1511 loss: 7.44755312e-07
Iter: 1512 loss: 7.4266e-07
Iter: 1513 loss: 7.42151542e-07
Iter: 1514 loss: 7.43938926e-07
Iter: 1515 loss: 7.41993517e-07
Iter: 1516 loss: 7.41406893e-07
Iter: 1517 loss: 7.42687064e-07
Iter: 1518 loss: 7.41171e-07
Iter: 1519 loss: 7.40617e-07
Iter: 1520 loss: 7.41267286e-07
Iter: 1521 loss: 7.4032431e-07
Iter: 1522 loss: 7.3963281e-07
Iter: 1523 loss: 7.40203348e-07
Iter: 1524 loss: 7.39277539e-07
Iter: 1525 loss: 7.38509e-07
Iter: 1526 loss: 7.39340862e-07
Iter: 1527 loss: 7.38053131e-07
Iter: 1528 loss: 7.37474e-07
Iter: 1529 loss: 7.37459914e-07
Iter: 1530 loss: 7.36956792e-07
Iter: 1531 loss: 7.3818353e-07
Iter: 1532 loss: 7.36817924e-07
Iter: 1533 loss: 7.36332936e-07
Iter: 1534 loss: 7.38622816e-07
Iter: 1535 loss: 7.36248126e-07
Iter: 1536 loss: 7.35735398e-07
Iter: 1537 loss: 7.35938897e-07
Iter: 1538 loss: 7.35376034e-07
Iter: 1539 loss: 7.3476906e-07
Iter: 1540 loss: 7.3931119e-07
Iter: 1541 loss: 7.34713581e-07
Iter: 1542 loss: 7.34354956e-07
Iter: 1543 loss: 7.33879e-07
Iter: 1544 loss: 7.33865591e-07
Iter: 1545 loss: 7.33074216e-07
Iter: 1546 loss: 7.35722097e-07
Iter: 1547 loss: 7.32880096e-07
Iter: 1548 loss: 7.32309331e-07
Iter: 1549 loss: 7.3477247e-07
Iter: 1550 loss: 7.32191324e-07
Iter: 1551 loss: 7.31678824e-07
Iter: 1552 loss: 7.34364676e-07
Iter: 1553 loss: 7.31553541e-07
Iter: 1554 loss: 7.31098e-07
Iter: 1555 loss: 7.31299565e-07
Iter: 1556 loss: 7.30755801e-07
Iter: 1557 loss: 7.3021971e-07
Iter: 1558 loss: 7.35371827e-07
Iter: 1559 loss: 7.30164743e-07
Iter: 1560 loss: 7.29799694e-07
Iter: 1561 loss: 7.29369333e-07
Iter: 1562 loss: 7.29292651e-07
Iter: 1563 loss: 7.28657369e-07
Iter: 1564 loss: 7.30231932e-07
Iter: 1565 loss: 7.28415557e-07
Iter: 1566 loss: 7.27809947e-07
Iter: 1567 loss: 7.2837031e-07
Iter: 1568 loss: 7.27409e-07
Iter: 1569 loss: 7.26826556e-07
Iter: 1570 loss: 7.32604121e-07
Iter: 1571 loss: 7.26791654e-07
Iter: 1572 loss: 7.26373401e-07
Iter: 1573 loss: 7.30305032e-07
Iter: 1574 loss: 7.26331166e-07
Iter: 1575 loss: 7.25852942e-07
Iter: 1576 loss: 7.25824179e-07
Iter: 1577 loss: 7.25445148e-07
Iter: 1578 loss: 7.24908887e-07
Iter: 1579 loss: 7.26579628e-07
Iter: 1580 loss: 7.24761378e-07
Iter: 1581 loss: 7.24287645e-07
Iter: 1582 loss: 7.24402412e-07
Iter: 1583 loss: 7.23922597e-07
Iter: 1584 loss: 7.23337052e-07
Iter: 1585 loss: 7.25047073e-07
Iter: 1586 loss: 7.231273e-07
Iter: 1587 loss: 7.22614061e-07
Iter: 1588 loss: 7.2926855e-07
Iter: 1589 loss: 7.22605478e-07
Iter: 1590 loss: 7.22139418e-07
Iter: 1591 loss: 7.21803531e-07
Iter: 1592 loss: 7.21699394e-07
Iter: 1593 loss: 7.2104217e-07
Iter: 1594 loss: 7.26254484e-07
Iter: 1595 loss: 7.21005961e-07
Iter: 1596 loss: 7.20518813e-07
Iter: 1597 loss: 7.20983849e-07
Iter: 1598 loss: 7.20237779e-07
Iter: 1599 loss: 7.1966241e-07
Iter: 1600 loss: 7.20895571e-07
Iter: 1601 loss: 7.19458399e-07
Iter: 1602 loss: 7.18980232e-07
Iter: 1603 loss: 7.22967e-07
Iter: 1604 loss: 7.18914634e-07
Iter: 1605 loss: 7.18507465e-07
Iter: 1606 loss: 7.18894114e-07
Iter: 1607 loss: 7.18254739e-07
Iter: 1608 loss: 7.1765777e-07
Iter: 1609 loss: 7.17527769e-07
Iter: 1610 loss: 7.17209332e-07
Iter: 1611 loss: 7.16738725e-07
Iter: 1612 loss: 7.16728607e-07
Iter: 1613 loss: 7.16235832e-07
Iter: 1614 loss: 7.1711878e-07
Iter: 1615 loss: 7.16005161e-07
Iter: 1616 loss: 7.15610838e-07
Iter: 1617 loss: 7.15211058e-07
Iter: 1618 loss: 7.15138299e-07
Iter: 1619 loss: 7.1453519e-07
Iter: 1620 loss: 7.17319381e-07
Iter: 1621 loss: 7.14414284e-07
Iter: 1622 loss: 7.13834538e-07
Iter: 1623 loss: 7.15535521e-07
Iter: 1624 loss: 7.13606539e-07
Iter: 1625 loss: 7.13021677e-07
Iter: 1626 loss: 7.14283374e-07
Iter: 1627 loss: 7.12790097e-07
Iter: 1628 loss: 7.12214728e-07
Iter: 1629 loss: 7.13580334e-07
Iter: 1630 loss: 7.12009523e-07
Iter: 1631 loss: 7.11357302e-07
Iter: 1632 loss: 7.1702334e-07
Iter: 1633 loss: 7.11349628e-07
Iter: 1634 loss: 7.10905624e-07
Iter: 1635 loss: 7.11400617e-07
Iter: 1636 loss: 7.10667678e-07
Iter: 1637 loss: 7.10254e-07
Iter: 1638 loss: 7.11458483e-07
Iter: 1639 loss: 7.10040126e-07
Iter: 1640 loss: 7.09525239e-07
Iter: 1641 loss: 7.10644144e-07
Iter: 1642 loss: 7.09354708e-07
Iter: 1643 loss: 7.08886205e-07
Iter: 1644 loss: 7.1009805e-07
Iter: 1645 loss: 7.08744835e-07
Iter: 1646 loss: 7.08244784e-07
Iter: 1647 loss: 7.11425287e-07
Iter: 1648 loss: 7.08239838e-07
Iter: 1649 loss: 7.07861773e-07
Iter: 1650 loss: 7.0808386e-07
Iter: 1651 loss: 7.07618256e-07
Iter: 1652 loss: 7.07230811e-07
Iter: 1653 loss: 7.11063592e-07
Iter: 1654 loss: 7.07192044e-07
Iter: 1655 loss: 7.06783794e-07
Iter: 1656 loss: 7.0649e-07
Iter: 1657 loss: 7.06419087e-07
Iter: 1658 loss: 7.05875777e-07
Iter: 1659 loss: 7.06273795e-07
Iter: 1660 loss: 7.05525167e-07
Iter: 1661 loss: 7.05012383e-07
Iter: 1662 loss: 7.07221488e-07
Iter: 1663 loss: 7.04866579e-07
Iter: 1664 loss: 7.04286208e-07
Iter: 1665 loss: 7.04533477e-07
Iter: 1666 loss: 7.03894443e-07
Iter: 1667 loss: 7.0327394e-07
Iter: 1668 loss: 7.09392111e-07
Iter: 1669 loss: 7.03253136e-07
Iter: 1670 loss: 7.02781961e-07
Iter: 1671 loss: 7.04453328e-07
Iter: 1672 loss: 7.02650254e-07
Iter: 1673 loss: 7.02186526e-07
Iter: 1674 loss: 7.03606645e-07
Iter: 1675 loss: 7.0207841e-07
Iter: 1676 loss: 7.01554029e-07
Iter: 1677 loss: 7.02607622e-07
Iter: 1678 loss: 7.01376734e-07
Iter: 1679 loss: 7.00946771e-07
Iter: 1680 loss: 7.01697445e-07
Iter: 1681 loss: 7.00768851e-07
Iter: 1682 loss: 7.0019496e-07
Iter: 1683 loss: 7.01657768e-07
Iter: 1684 loss: 7.00026817e-07
Iter: 1685 loss: 6.99617772e-07
Iter: 1686 loss: 7.01515376e-07
Iter: 1687 loss: 6.9955172e-07
Iter: 1688 loss: 6.99150917e-07
Iter: 1689 loss: 6.99772272e-07
Iter: 1690 loss: 6.98945541e-07
Iter: 1691 loss: 6.9843594e-07
Iter: 1692 loss: 7.00766122e-07
Iter: 1693 loss: 6.98393e-07
Iter: 1694 loss: 6.97996484e-07
Iter: 1695 loss: 6.99466341e-07
Iter: 1696 loss: 6.97883479e-07
Iter: 1697 loss: 6.97448399e-07
Iter: 1698 loss: 6.97519624e-07
Iter: 1699 loss: 6.9717106e-07
Iter: 1700 loss: 6.96731831e-07
Iter: 1701 loss: 6.97035091e-07
Iter: 1702 loss: 6.965e-07
Iter: 1703 loss: 6.95914878e-07
Iter: 1704 loss: 6.96808e-07
Iter: 1705 loss: 6.95689096e-07
Iter: 1706 loss: 6.95138738e-07
Iter: 1707 loss: 6.96434711e-07
Iter: 1708 loss: 6.94925916e-07
Iter: 1709 loss: 6.94346227e-07
Iter: 1710 loss: 7.00053647e-07
Iter: 1711 loss: 6.94301946e-07
Iter: 1712 loss: 6.93898755e-07
Iter: 1713 loss: 6.95343203e-07
Iter: 1714 loss: 6.93785182e-07
Iter: 1715 loss: 6.93391598e-07
Iter: 1716 loss: 6.93767106e-07
Iter: 1717 loss: 6.93243067e-07
Iter: 1718 loss: 6.92711296e-07
Iter: 1719 loss: 6.93378468e-07
Iter: 1720 loss: 6.92464596e-07
Iter: 1721 loss: 6.91904e-07
Iter: 1722 loss: 6.94645564e-07
Iter: 1723 loss: 6.91777416e-07
Iter: 1724 loss: 6.91389459e-07
Iter: 1725 loss: 6.93644267e-07
Iter: 1726 loss: 6.9129436e-07
Iter: 1727 loss: 6.90981e-07
Iter: 1728 loss: 6.9167703e-07
Iter: 1729 loss: 6.90834725e-07
Iter: 1730 loss: 6.90411639e-07
Iter: 1731 loss: 6.914e-07
Iter: 1732 loss: 6.90209959e-07
Iter: 1733 loss: 6.89833314e-07
Iter: 1734 loss: 6.91572666e-07
Iter: 1735 loss: 6.89707463e-07
Iter: 1736 loss: 6.89362082e-07
Iter: 1737 loss: 6.89430522e-07
Iter: 1738 loss: 6.89104695e-07
Iter: 1739 loss: 6.88618e-07
Iter: 1740 loss: 6.88687351e-07
Iter: 1741 loss: 6.88305e-07
Iter: 1742 loss: 6.87666102e-07
Iter: 1743 loss: 6.89550234e-07
Iter: 1744 loss: 6.87497845e-07
Iter: 1745 loss: 6.86974431e-07
Iter: 1746 loss: 6.89382318e-07
Iter: 1747 loss: 6.8686893e-07
Iter: 1748 loss: 6.86328235e-07
Iter: 1749 loss: 6.88234934e-07
Iter: 1750 loss: 6.86185786e-07
Iter: 1751 loss: 6.85643329e-07
Iter: 1752 loss: 6.89174954e-07
Iter: 1753 loss: 6.85598e-07
Iter: 1754 loss: 6.85265093e-07
Iter: 1755 loss: 6.85092743e-07
Iter: 1756 loss: 6.8492011e-07
Iter: 1757 loss: 6.84420513e-07
Iter: 1758 loss: 6.8654731e-07
Iter: 1759 loss: 6.84358042e-07
Iter: 1760 loss: 6.83851056e-07
Iter: 1761 loss: 6.8583347e-07
Iter: 1762 loss: 6.83733674e-07
Iter: 1763 loss: 6.83384485e-07
Iter: 1764 loss: 6.85059717e-07
Iter: 1765 loss: 6.83321787e-07
Iter: 1766 loss: 6.82972711e-07
Iter: 1767 loss: 6.83385679e-07
Iter: 1768 loss: 6.82781206e-07
Iter: 1769 loss: 6.82389043e-07
Iter: 1770 loss: 6.84717293e-07
Iter: 1771 loss: 6.82391033e-07
Iter: 1772 loss: 6.82036216e-07
Iter: 1773 loss: 6.81731763e-07
Iter: 1774 loss: 6.816839e-07
Iter: 1775 loss: 6.81108247e-07
Iter: 1776 loss: 6.83721055e-07
Iter: 1777 loss: 6.81020083e-07
Iter: 1778 loss: 6.80616949e-07
Iter: 1779 loss: 6.81182428e-07
Iter: 1780 loss: 6.80357971e-07
Iter: 1781 loss: 6.79861728e-07
Iter: 1782 loss: 6.80206654e-07
Iter: 1783 loss: 6.79581603e-07
Iter: 1784 loss: 6.790263e-07
Iter: 1785 loss: 6.82014502e-07
Iter: 1786 loss: 6.78952574e-07
Iter: 1787 loss: 6.78540687e-07
Iter: 1788 loss: 6.79359346e-07
Iter: 1789 loss: 6.78344406e-07
Iter: 1790 loss: 6.77896708e-07
Iter: 1791 loss: 6.8435088e-07
Iter: 1792 loss: 6.77909725e-07
Iter: 1793 loss: 6.77578328e-07
Iter: 1794 loss: 6.77393814e-07
Iter: 1795 loss: 6.77292576e-07
Iter: 1796 loss: 6.7685005e-07
Iter: 1797 loss: 6.7767678e-07
Iter: 1798 loss: 6.76624438e-07
Iter: 1799 loss: 6.76133254e-07
Iter: 1800 loss: 6.80927315e-07
Iter: 1801 loss: 6.76127115e-07
Iter: 1802 loss: 6.75771844e-07
Iter: 1803 loss: 6.76416562e-07
Iter: 1804 loss: 6.75637637e-07
Iter: 1805 loss: 6.75296064e-07
Iter: 1806 loss: 6.77282799e-07
Iter: 1807 loss: 6.75229614e-07
Iter: 1808 loss: 6.74883836e-07
Iter: 1809 loss: 6.74934597e-07
Iter: 1810 loss: 6.74581088e-07
Iter: 1811 loss: 6.74203307e-07
Iter: 1812 loss: 6.75250647e-07
Iter: 1813 loss: 6.74065632e-07
Iter: 1814 loss: 6.73608838e-07
Iter: 1815 loss: 6.74329897e-07
Iter: 1816 loss: 6.73385046e-07
Iter: 1817 loss: 6.72942633e-07
Iter: 1818 loss: 6.73449676e-07
Iter: 1819 loss: 6.72699343e-07
Iter: 1820 loss: 6.72233796e-07
Iter: 1821 loss: 6.72804845e-07
Iter: 1822 loss: 6.71973339e-07
Iter: 1823 loss: 6.71374721e-07
Iter: 1824 loss: 6.74602575e-07
Iter: 1825 loss: 6.71281668e-07
Iter: 1826 loss: 6.70777638e-07
Iter: 1827 loss: 6.72856061e-07
Iter: 1828 loss: 6.70664576e-07
Iter: 1829 loss: 6.70297879e-07
Iter: 1830 loss: 6.7226631e-07
Iter: 1831 loss: 6.70214433e-07
Iter: 1832 loss: 6.69795895e-07
Iter: 1833 loss: 6.69959149e-07
Iter: 1834 loss: 6.69527481e-07
Iter: 1835 loss: 6.69061535e-07
Iter: 1836 loss: 6.69558517e-07
Iter: 1837 loss: 6.68751966e-07
Iter: 1838 loss: 6.68320354e-07
Iter: 1839 loss: 6.74460694e-07
Iter: 1840 loss: 6.68311316e-07
Iter: 1841 loss: 6.67968891e-07
Iter: 1842 loss: 6.68724397e-07
Iter: 1843 loss: 6.67817119e-07
Iter: 1844 loss: 6.67554445e-07
Iter: 1845 loss: 6.68613e-07
Iter: 1846 loss: 6.67493111e-07
Iter: 1847 loss: 6.67173254e-07
Iter: 1848 loss: 6.6696623e-07
Iter: 1849 loss: 6.66804e-07
Iter: 1850 loss: 6.66296671e-07
Iter: 1851 loss: 6.68331e-07
Iter: 1852 loss: 6.66215e-07
Iter: 1853 loss: 6.65831408e-07
Iter: 1854 loss: 6.66549226e-07
Iter: 1855 loss: 6.65690948e-07
Iter: 1856 loss: 6.65180437e-07
Iter: 1857 loss: 6.66203903e-07
Iter: 1858 loss: 6.64984441e-07
Iter: 1859 loss: 6.64510821e-07
Iter: 1860 loss: 6.64908555e-07
Iter: 1861 loss: 6.64186132e-07
Iter: 1862 loss: 6.63735e-07
Iter: 1863 loss: 6.66038261e-07
Iter: 1864 loss: 6.63669653e-07
Iter: 1865 loss: 6.63209505e-07
Iter: 1866 loss: 6.64579488e-07
Iter: 1867 loss: 6.63057222e-07
Iter: 1868 loss: 6.62597131e-07
Iter: 1869 loss: 6.65927e-07
Iter: 1870 loss: 6.62571551e-07
Iter: 1871 loss: 6.6227642e-07
Iter: 1872 loss: 6.61967e-07
Iter: 1873 loss: 6.61905e-07
Iter: 1874 loss: 6.6146265e-07
Iter: 1875 loss: 6.67863333e-07
Iter: 1876 loss: 6.61489e-07
Iter: 1877 loss: 6.61157969e-07
Iter: 1878 loss: 6.62480602e-07
Iter: 1879 loss: 6.61105219e-07
Iter: 1880 loss: 6.60850105e-07
Iter: 1881 loss: 6.60707201e-07
Iter: 1882 loss: 6.60543435e-07
Iter: 1883 loss: 6.60180149e-07
Iter: 1884 loss: 6.61904096e-07
Iter: 1885 loss: 6.60111255e-07
Iter: 1886 loss: 6.59702835e-07
Iter: 1887 loss: 6.59929356e-07
Iter: 1888 loss: 6.59439252e-07
Iter: 1889 loss: 6.59074828e-07
Iter: 1890 loss: 6.59393095e-07
Iter: 1891 loss: 6.58826423e-07
Iter: 1892 loss: 6.58349109e-07
Iter: 1893 loss: 6.5989849e-07
Iter: 1894 loss: 6.58205067e-07
Iter: 1895 loss: 6.57688304e-07
Iter: 1896 loss: 6.59769114e-07
Iter: 1897 loss: 6.57580244e-07
Iter: 1898 loss: 6.57178816e-07
Iter: 1899 loss: 6.58367185e-07
Iter: 1900 loss: 6.57054557e-07
Iter: 1901 loss: 6.56661655e-07
Iter: 1902 loss: 6.5690665e-07
Iter: 1903 loss: 6.56415523e-07
Iter: 1904 loss: 6.55980216e-07
Iter: 1905 loss: 6.60505862e-07
Iter: 1906 loss: 6.55975e-07
Iter: 1907 loss: 6.55587883e-07
Iter: 1908 loss: 6.56265115e-07
Iter: 1909 loss: 6.55437304e-07
Iter: 1910 loss: 6.55084136e-07
Iter: 1911 loss: 6.55018425e-07
Iter: 1912 loss: 6.54804e-07
Iter: 1913 loss: 6.54449309e-07
Iter: 1914 loss: 6.54417477e-07
Iter: 1915 loss: 6.5418044e-07
Iter: 1916 loss: 6.53959546e-07
Iter: 1917 loss: 6.53883035e-07
Iter: 1918 loss: 6.53499228e-07
Iter: 1919 loss: 6.54896496e-07
Iter: 1920 loss: 6.53420102e-07
Iter: 1921 loss: 6.53019356e-07
Iter: 1922 loss: 6.53943175e-07
Iter: 1923 loss: 6.5283848e-07
Iter: 1924 loss: 6.5246013e-07
Iter: 1925 loss: 6.52518565e-07
Iter: 1926 loss: 6.52149538e-07
Iter: 1927 loss: 6.51712412e-07
Iter: 1928 loss: 6.52839731e-07
Iter: 1929 loss: 6.51584628e-07
Iter: 1930 loss: 6.51110838e-07
Iter: 1931 loss: 6.5405095e-07
Iter: 1932 loss: 6.51102823e-07
Iter: 1933 loss: 6.50752781e-07
Iter: 1934 loss: 6.51994355e-07
Iter: 1935 loss: 6.50653249e-07
Iter: 1936 loss: 6.50335664e-07
Iter: 1937 loss: 6.50139782e-07
Iter: 1938 loss: 6.4997414e-07
Iter: 1939 loss: 6.49472895e-07
Iter: 1940 loss: 6.53038455e-07
Iter: 1941 loss: 6.4942526e-07
Iter: 1942 loss: 6.49041397e-07
Iter: 1943 loss: 6.51898063e-07
Iter: 1944 loss: 6.49005528e-07
Iter: 1945 loss: 6.48682089e-07
Iter: 1946 loss: 6.48364e-07
Iter: 1947 loss: 6.48326932e-07
Iter: 1948 loss: 6.47912827e-07
Iter: 1949 loss: 6.47918114e-07
Iter: 1950 loss: 6.47556249e-07
Iter: 1951 loss: 6.47335924e-07
Iter: 1952 loss: 6.47191882e-07
Iter: 1953 loss: 6.46825811e-07
Iter: 1954 loss: 6.47904528e-07
Iter: 1955 loss: 6.46732133e-07
Iter: 1956 loss: 6.46354806e-07
Iter: 1957 loss: 6.48786795e-07
Iter: 1958 loss: 6.46310582e-07
Iter: 1959 loss: 6.4599908e-07
Iter: 1960 loss: 6.45732712e-07
Iter: 1961 loss: 6.45667569e-07
Iter: 1962 loss: 6.45164846e-07
Iter: 1963 loss: 6.45337138e-07
Iter: 1964 loss: 6.44839e-07
Iter: 1965 loss: 6.44238469e-07
Iter: 1966 loss: 6.51331959e-07
Iter: 1967 loss: 6.44237502e-07
Iter: 1968 loss: 6.43869612e-07
Iter: 1969 loss: 6.4502e-07
Iter: 1970 loss: 6.43771443e-07
Iter: 1971 loss: 6.43441922e-07
Iter: 1972 loss: 6.44069814e-07
Iter: 1973 loss: 6.43290377e-07
Iter: 1974 loss: 6.42876614e-07
Iter: 1975 loss: 6.4316e-07
Iter: 1976 loss: 6.42591885e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.4
+ date
Sat Nov  7 16:11:16 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f2 --psi -2 --alpha 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi-2_phi2.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37c0e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37c0e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37b0e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37b0e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37b0e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37ab4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37b0e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37a77f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37a598c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fc4b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe37a2d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fc620d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fc629d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fbc10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fbd89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fb58048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fb51378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fb51510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fb26400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fba4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fba4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fb34ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fa85400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fab18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fab1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fa642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fa052f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fa058c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde7551840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde74d29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde74d2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efe2fab1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde7504950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde756e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde756e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efde74941e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.30091318e-05
Iter: 2 loss: 2.01292205e-05
Iter: 3 loss: 2.52490936e-05
Iter: 4 loss: 1.88622344e-05
Iter: 5 loss: 1.71017236e-05
Iter: 6 loss: 1.82248477e-05
Iter: 7 loss: 1.59797073e-05
Iter: 8 loss: 1.40328339e-05
Iter: 9 loss: 2.01942221e-05
Iter: 10 loss: 1.34728889e-05
Iter: 11 loss: 1.16306328e-05
Iter: 12 loss: 1.77895254e-05
Iter: 13 loss: 1.11310346e-05
Iter: 14 loss: 1.04321607e-05
Iter: 15 loss: 1.1550379e-05
Iter: 16 loss: 1.01082278e-05
Iter: 17 loss: 9.26757275e-06
Iter: 18 loss: 1.08993154e-05
Iter: 19 loss: 8.91892887e-06
Iter: 20 loss: 8.18656099e-06
Iter: 21 loss: 1.34610364e-05
Iter: 22 loss: 8.12306916e-06
Iter: 23 loss: 7.62572881e-06
Iter: 24 loss: 9.4053039e-06
Iter: 25 loss: 7.49916944e-06
Iter: 26 loss: 7.0654487e-06
Iter: 27 loss: 8.60664113e-06
Iter: 28 loss: 6.95439621e-06
Iter: 29 loss: 6.5462209e-06
Iter: 30 loss: 7.23943958e-06
Iter: 31 loss: 6.36326058e-06
Iter: 32 loss: 5.97694e-06
Iter: 33 loss: 7.42041357e-06
Iter: 34 loss: 5.88309285e-06
Iter: 35 loss: 5.59393811e-06
Iter: 36 loss: 6.11266705e-06
Iter: 37 loss: 5.46821911e-06
Iter: 38 loss: 5.18074467e-06
Iter: 39 loss: 5.97057715e-06
Iter: 40 loss: 5.08709127e-06
Iter: 41 loss: 4.83314489e-06
Iter: 42 loss: 6.3364264e-06
Iter: 43 loss: 4.80057315e-06
Iter: 44 loss: 4.66000756e-06
Iter: 45 loss: 4.65955418e-06
Iter: 46 loss: 4.54852579e-06
Iter: 47 loss: 4.4325e-06
Iter: 48 loss: 4.41217298e-06
Iter: 49 loss: 4.2745005e-06
Iter: 50 loss: 5.43622627e-06
Iter: 51 loss: 4.26663655e-06
Iter: 52 loss: 4.15745399e-06
Iter: 53 loss: 4.39263113e-06
Iter: 54 loss: 4.11495512e-06
Iter: 55 loss: 4.01173384e-06
Iter: 56 loss: 3.97546864e-06
Iter: 57 loss: 3.91719823e-06
Iter: 58 loss: 3.77743595e-06
Iter: 59 loss: 4.07522566e-06
Iter: 60 loss: 3.72260547e-06
Iter: 61 loss: 3.6073825e-06
Iter: 62 loss: 5.14898875e-06
Iter: 63 loss: 3.60685794e-06
Iter: 64 loss: 3.52914503e-06
Iter: 65 loss: 3.89169145e-06
Iter: 66 loss: 3.51470271e-06
Iter: 67 loss: 3.44986415e-06
Iter: 68 loss: 3.41585178e-06
Iter: 69 loss: 3.38616928e-06
Iter: 70 loss: 3.3030683e-06
Iter: 71 loss: 3.88767512e-06
Iter: 72 loss: 3.29550903e-06
Iter: 73 loss: 3.22744131e-06
Iter: 74 loss: 3.38986251e-06
Iter: 75 loss: 3.20276649e-06
Iter: 76 loss: 3.13502369e-06
Iter: 77 loss: 3.20629761e-06
Iter: 78 loss: 3.09745928e-06
Iter: 79 loss: 3.02878584e-06
Iter: 80 loss: 3.37357142e-06
Iter: 81 loss: 3.01724867e-06
Iter: 82 loss: 2.9699429e-06
Iter: 83 loss: 2.96987355e-06
Iter: 84 loss: 2.93687981e-06
Iter: 85 loss: 2.89123363e-06
Iter: 86 loss: 2.88928e-06
Iter: 87 loss: 2.8338909e-06
Iter: 88 loss: 3.13835903e-06
Iter: 89 loss: 2.82584233e-06
Iter: 90 loss: 2.78251491e-06
Iter: 91 loss: 2.96063263e-06
Iter: 92 loss: 2.77311915e-06
Iter: 93 loss: 2.73369187e-06
Iter: 94 loss: 2.81871985e-06
Iter: 95 loss: 2.71817908e-06
Iter: 96 loss: 2.68067697e-06
Iter: 97 loss: 2.67415e-06
Iter: 98 loss: 2.6486523e-06
Iter: 99 loss: 2.59905232e-06
Iter: 100 loss: 2.77082518e-06
Iter: 101 loss: 2.58594764e-06
Iter: 102 loss: 2.54839279e-06
Iter: 103 loss: 2.89930949e-06
Iter: 104 loss: 2.54689485e-06
Iter: 105 loss: 2.51423626e-06
Iter: 106 loss: 2.60884144e-06
Iter: 107 loss: 2.50403355e-06
Iter: 108 loss: 2.47691423e-06
Iter: 109 loss: 2.53003327e-06
Iter: 110 loss: 2.46558056e-06
Iter: 111 loss: 2.43559543e-06
Iter: 112 loss: 2.42167198e-06
Iter: 113 loss: 2.40674035e-06
Iter: 114 loss: 2.3678308e-06
Iter: 115 loss: 2.55814757e-06
Iter: 116 loss: 2.36090182e-06
Iter: 117 loss: 2.33477022e-06
Iter: 118 loss: 2.33467608e-06
Iter: 119 loss: 2.31581248e-06
Iter: 120 loss: 2.35224434e-06
Iter: 121 loss: 2.30784985e-06
Iter: 122 loss: 2.28610247e-06
Iter: 123 loss: 2.30685873e-06
Iter: 124 loss: 2.27379087e-06
Iter: 125 loss: 2.25226972e-06
Iter: 126 loss: 2.2721897e-06
Iter: 127 loss: 2.23994948e-06
Iter: 128 loss: 2.21843447e-06
Iter: 129 loss: 2.34596632e-06
Iter: 130 loss: 2.21570326e-06
Iter: 131 loss: 2.19099866e-06
Iter: 132 loss: 2.22095241e-06
Iter: 133 loss: 2.17802699e-06
Iter: 134 loss: 2.15858927e-06
Iter: 135 loss: 2.20052243e-06
Iter: 136 loss: 2.15102773e-06
Iter: 137 loss: 2.12817213e-06
Iter: 138 loss: 2.13297699e-06
Iter: 139 loss: 2.11118731e-06
Iter: 140 loss: 2.0898533e-06
Iter: 141 loss: 2.36248547e-06
Iter: 142 loss: 2.08971346e-06
Iter: 143 loss: 2.07277799e-06
Iter: 144 loss: 2.10621056e-06
Iter: 145 loss: 2.06584014e-06
Iter: 146 loss: 2.04777234e-06
Iter: 147 loss: 2.13450539e-06
Iter: 148 loss: 2.04468756e-06
Iter: 149 loss: 2.02923866e-06
Iter: 150 loss: 2.02249657e-06
Iter: 151 loss: 2.01469811e-06
Iter: 152 loss: 1.99522e-06
Iter: 153 loss: 2.0595578e-06
Iter: 154 loss: 1.98973385e-06
Iter: 155 loss: 1.98055227e-06
Iter: 156 loss: 1.97959389e-06
Iter: 157 loss: 1.97052418e-06
Iter: 158 loss: 1.96564224e-06
Iter: 159 loss: 1.96158635e-06
Iter: 160 loss: 1.9470051e-06
Iter: 161 loss: 1.94820723e-06
Iter: 162 loss: 1.9357135e-06
Iter: 163 loss: 1.92115294e-06
Iter: 164 loss: 2.0052446e-06
Iter: 165 loss: 1.91913045e-06
Iter: 166 loss: 1.9061257e-06
Iter: 167 loss: 1.97210443e-06
Iter: 168 loss: 1.90402534e-06
Iter: 169 loss: 1.8918322e-06
Iter: 170 loss: 1.89801153e-06
Iter: 171 loss: 1.883761e-06
Iter: 172 loss: 1.87106014e-06
Iter: 173 loss: 1.94660061e-06
Iter: 174 loss: 1.86942111e-06
Iter: 175 loss: 1.85812144e-06
Iter: 176 loss: 1.86600073e-06
Iter: 177 loss: 1.85102408e-06
Iter: 178 loss: 1.83844531e-06
Iter: 179 loss: 1.83735233e-06
Iter: 180 loss: 1.82806218e-06
Iter: 181 loss: 1.81585926e-06
Iter: 182 loss: 1.81576229e-06
Iter: 183 loss: 1.80632628e-06
Iter: 184 loss: 1.83506688e-06
Iter: 185 loss: 1.80343682e-06
Iter: 186 loss: 1.79300196e-06
Iter: 187 loss: 1.78981486e-06
Iter: 188 loss: 1.78360483e-06
Iter: 189 loss: 1.7726037e-06
Iter: 190 loss: 1.83503118e-06
Iter: 191 loss: 1.77109496e-06
Iter: 192 loss: 1.76369883e-06
Iter: 193 loss: 1.87160379e-06
Iter: 194 loss: 1.7636778e-06
Iter: 195 loss: 1.75738217e-06
Iter: 196 loss: 1.75532796e-06
Iter: 197 loss: 1.75176888e-06
Iter: 198 loss: 1.74253694e-06
Iter: 199 loss: 1.74653883e-06
Iter: 200 loss: 1.73617764e-06
Iter: 201 loss: 1.72703699e-06
Iter: 202 loss: 1.75983132e-06
Iter: 203 loss: 1.72481202e-06
Iter: 204 loss: 1.71411511e-06
Iter: 205 loss: 1.73396165e-06
Iter: 206 loss: 1.70978365e-06
Iter: 207 loss: 1.70092471e-06
Iter: 208 loss: 1.82775614e-06
Iter: 209 loss: 1.70091187e-06
Iter: 210 loss: 1.69572854e-06
Iter: 211 loss: 1.68623819e-06
Iter: 212 loss: 1.91361914e-06
Iter: 213 loss: 1.68627162e-06
Iter: 214 loss: 1.67453823e-06
Iter: 215 loss: 1.72030263e-06
Iter: 216 loss: 1.67180656e-06
Iter: 217 loss: 1.66301561e-06
Iter: 218 loss: 1.75111381e-06
Iter: 219 loss: 1.66267728e-06
Iter: 220 loss: 1.65576762e-06
Iter: 221 loss: 1.65732331e-06
Iter: 222 loss: 1.65071924e-06
Iter: 223 loss: 1.64241487e-06
Iter: 224 loss: 1.70816293e-06
Iter: 225 loss: 1.64191488e-06
Iter: 226 loss: 1.63595359e-06
Iter: 227 loss: 1.64894607e-06
Iter: 228 loss: 1.63364552e-06
Iter: 229 loss: 1.62567312e-06
Iter: 230 loss: 1.62316655e-06
Iter: 231 loss: 1.61843582e-06
Iter: 232 loss: 1.61445234e-06
Iter: 233 loss: 1.61343428e-06
Iter: 234 loss: 1.60962099e-06
Iter: 235 loss: 1.60796685e-06
Iter: 236 loss: 1.60593595e-06
Iter: 237 loss: 1.59958859e-06
Iter: 238 loss: 1.59106935e-06
Iter: 239 loss: 1.59055674e-06
Iter: 240 loss: 1.58161765e-06
Iter: 241 loss: 1.63429218e-06
Iter: 242 loss: 1.58041416e-06
Iter: 243 loss: 1.57240765e-06
Iter: 244 loss: 1.60818047e-06
Iter: 245 loss: 1.57088448e-06
Iter: 246 loss: 1.5630992e-06
Iter: 247 loss: 1.60620243e-06
Iter: 248 loss: 1.56195e-06
Iter: 249 loss: 1.55564692e-06
Iter: 250 loss: 1.56088572e-06
Iter: 251 loss: 1.55187809e-06
Iter: 252 loss: 1.54650934e-06
Iter: 253 loss: 1.55271186e-06
Iter: 254 loss: 1.54364386e-06
Iter: 255 loss: 1.53528413e-06
Iter: 256 loss: 1.55567466e-06
Iter: 257 loss: 1.53223e-06
Iter: 258 loss: 1.52664916e-06
Iter: 259 loss: 1.54034876e-06
Iter: 260 loss: 1.52464099e-06
Iter: 261 loss: 1.51727681e-06
Iter: 262 loss: 1.55638259e-06
Iter: 263 loss: 1.51611255e-06
Iter: 264 loss: 1.51084146e-06
Iter: 265 loss: 1.51483607e-06
Iter: 266 loss: 1.50757114e-06
Iter: 267 loss: 1.50271057e-06
Iter: 268 loss: 1.57172599e-06
Iter: 269 loss: 1.50270625e-06
Iter: 270 loss: 1.49860398e-06
Iter: 271 loss: 1.4986781e-06
Iter: 272 loss: 1.49530183e-06
Iter: 273 loss: 1.49009486e-06
Iter: 274 loss: 1.50728329e-06
Iter: 275 loss: 1.48858476e-06
Iter: 276 loss: 1.48408117e-06
Iter: 277 loss: 1.48479342e-06
Iter: 278 loss: 1.48077356e-06
Iter: 279 loss: 1.47502078e-06
Iter: 280 loss: 1.49183813e-06
Iter: 281 loss: 1.47329342e-06
Iter: 282 loss: 1.46679236e-06
Iter: 283 loss: 1.47416711e-06
Iter: 284 loss: 1.46330194e-06
Iter: 285 loss: 1.45827846e-06
Iter: 286 loss: 1.45825527e-06
Iter: 287 loss: 1.45397098e-06
Iter: 288 loss: 1.45331944e-06
Iter: 289 loss: 1.45047386e-06
Iter: 290 loss: 1.44486364e-06
Iter: 291 loss: 1.44484829e-06
Iter: 292 loss: 1.44038825e-06
Iter: 293 loss: 1.4343733e-06
Iter: 294 loss: 1.4785835e-06
Iter: 295 loss: 1.4338998e-06
Iter: 296 loss: 1.42916372e-06
Iter: 297 loss: 1.44456521e-06
Iter: 298 loss: 1.42787849e-06
Iter: 299 loss: 1.42215708e-06
Iter: 300 loss: 1.44497949e-06
Iter: 301 loss: 1.42090153e-06
Iter: 302 loss: 1.41675696e-06
Iter: 303 loss: 1.42973818e-06
Iter: 304 loss: 1.41542387e-06
Iter: 305 loss: 1.41113071e-06
Iter: 306 loss: 1.43251691e-06
Iter: 307 loss: 1.4103432e-06
Iter: 308 loss: 1.4064492e-06
Iter: 309 loss: 1.40533666e-06
Iter: 310 loss: 1.40299244e-06
Iter: 311 loss: 1.39820247e-06
Iter: 312 loss: 1.41179294e-06
Iter: 313 loss: 1.39658755e-06
Iter: 314 loss: 1.3918791e-06
Iter: 315 loss: 1.40216662e-06
Iter: 316 loss: 1.3900592e-06
Iter: 317 loss: 1.38598864e-06
Iter: 318 loss: 1.40720419e-06
Iter: 319 loss: 1.3852964e-06
Iter: 320 loss: 1.3811175e-06
Iter: 321 loss: 1.38462212e-06
Iter: 322 loss: 1.37866709e-06
Iter: 323 loss: 1.3748587e-06
Iter: 324 loss: 1.40225848e-06
Iter: 325 loss: 1.37449672e-06
Iter: 326 loss: 1.37070515e-06
Iter: 327 loss: 1.37649295e-06
Iter: 328 loss: 1.36880794e-06
Iter: 329 loss: 1.36448853e-06
Iter: 330 loss: 1.3677959e-06
Iter: 331 loss: 1.36183826e-06
Iter: 332 loss: 1.35713992e-06
Iter: 333 loss: 1.36294148e-06
Iter: 334 loss: 1.35474772e-06
Iter: 335 loss: 1.34949914e-06
Iter: 336 loss: 1.37426537e-06
Iter: 337 loss: 1.34852371e-06
Iter: 338 loss: 1.34489835e-06
Iter: 339 loss: 1.39323174e-06
Iter: 340 loss: 1.34487505e-06
Iter: 341 loss: 1.34208437e-06
Iter: 342 loss: 1.34847369e-06
Iter: 343 loss: 1.34102083e-06
Iter: 344 loss: 1.33821072e-06
Iter: 345 loss: 1.34299285e-06
Iter: 346 loss: 1.3369006e-06
Iter: 347 loss: 1.33352705e-06
Iter: 348 loss: 1.34143988e-06
Iter: 349 loss: 1.33225035e-06
Iter: 350 loss: 1.32938487e-06
Iter: 351 loss: 1.32489e-06
Iter: 352 loss: 1.3247743e-06
Iter: 353 loss: 1.31986462e-06
Iter: 354 loss: 1.36408482e-06
Iter: 355 loss: 1.31960621e-06
Iter: 356 loss: 1.3150991e-06
Iter: 357 loss: 1.31917022e-06
Iter: 358 loss: 1.31245565e-06
Iter: 359 loss: 1.30833473e-06
Iter: 360 loss: 1.37053689e-06
Iter: 361 loss: 1.30836872e-06
Iter: 362 loss: 1.30598346e-06
Iter: 363 loss: 1.30886076e-06
Iter: 364 loss: 1.30465401e-06
Iter: 365 loss: 1.30114927e-06
Iter: 366 loss: 1.30431988e-06
Iter: 367 loss: 1.29908574e-06
Iter: 368 loss: 1.29487273e-06
Iter: 369 loss: 1.31354545e-06
Iter: 370 loss: 1.29407545e-06
Iter: 371 loss: 1.29150578e-06
Iter: 372 loss: 1.28795477e-06
Iter: 373 loss: 1.28777924e-06
Iter: 374 loss: 1.28320528e-06
Iter: 375 loss: 1.3432566e-06
Iter: 376 loss: 1.28313604e-06
Iter: 377 loss: 1.28041256e-06
Iter: 378 loss: 1.30486796e-06
Iter: 379 loss: 1.28032241e-06
Iter: 380 loss: 1.2779517e-06
Iter: 381 loss: 1.28009049e-06
Iter: 382 loss: 1.27664919e-06
Iter: 383 loss: 1.27382418e-06
Iter: 384 loss: 1.27283533e-06
Iter: 385 loss: 1.27123189e-06
Iter: 386 loss: 1.2676536e-06
Iter: 387 loss: 1.31187335e-06
Iter: 388 loss: 1.26763757e-06
Iter: 389 loss: 1.26551413e-06
Iter: 390 loss: 1.26186615e-06
Iter: 391 loss: 1.26184364e-06
Iter: 392 loss: 1.25712813e-06
Iter: 393 loss: 1.2737e-06
Iter: 394 loss: 1.25587508e-06
Iter: 395 loss: 1.25278234e-06
Iter: 396 loss: 1.27584e-06
Iter: 397 loss: 1.25252484e-06
Iter: 398 loss: 1.2495907e-06
Iter: 399 loss: 1.25788654e-06
Iter: 400 loss: 1.24862174e-06
Iter: 401 loss: 1.24529788e-06
Iter: 402 loss: 1.25125632e-06
Iter: 403 loss: 1.24381836e-06
Iter: 404 loss: 1.24070255e-06
Iter: 405 loss: 1.25171221e-06
Iter: 406 loss: 1.23987229e-06
Iter: 407 loss: 1.23718416e-06
Iter: 408 loss: 1.24268831e-06
Iter: 409 loss: 1.23615837e-06
Iter: 410 loss: 1.23264613e-06
Iter: 411 loss: 1.23505902e-06
Iter: 412 loss: 1.23051154e-06
Iter: 413 loss: 1.22790084e-06
Iter: 414 loss: 1.25989254e-06
Iter: 415 loss: 1.22785264e-06
Iter: 416 loss: 1.22534959e-06
Iter: 417 loss: 1.23305722e-06
Iter: 418 loss: 1.22457482e-06
Iter: 419 loss: 1.22250242e-06
Iter: 420 loss: 1.22163647e-06
Iter: 421 loss: 1.22049266e-06
Iter: 422 loss: 1.21732501e-06
Iter: 423 loss: 1.22919732e-06
Iter: 424 loss: 1.21656808e-06
Iter: 425 loss: 1.21314724e-06
Iter: 426 loss: 1.22337372e-06
Iter: 427 loss: 1.21202584e-06
Iter: 428 loss: 1.2098493e-06
Iter: 429 loss: 1.20881066e-06
Iter: 430 loss: 1.207678e-06
Iter: 431 loss: 1.20404422e-06
Iter: 432 loss: 1.21680955e-06
Iter: 433 loss: 1.20308232e-06
Iter: 434 loss: 1.19964591e-06
Iter: 435 loss: 1.21584912e-06
Iter: 436 loss: 1.19900847e-06
Iter: 437 loss: 1.1960625e-06
Iter: 438 loss: 1.2087196e-06
Iter: 439 loss: 1.19540528e-06
Iter: 440 loss: 1.19284255e-06
Iter: 441 loss: 1.20561583e-06
Iter: 442 loss: 1.19238e-06
Iter: 443 loss: 1.19030096e-06
Iter: 444 loss: 1.18669459e-06
Iter: 445 loss: 1.18668675e-06
Iter: 446 loss: 1.18384958e-06
Iter: 447 loss: 1.18378546e-06
Iter: 448 loss: 1.18169771e-06
Iter: 449 loss: 1.18580556e-06
Iter: 450 loss: 1.18082914e-06
Iter: 451 loss: 1.1786608e-06
Iter: 452 loss: 1.19425181e-06
Iter: 453 loss: 1.17847799e-06
Iter: 454 loss: 1.17638058e-06
Iter: 455 loss: 1.17491754e-06
Iter: 456 loss: 1.17410559e-06
Iter: 457 loss: 1.17183492e-06
Iter: 458 loss: 1.17558477e-06
Iter: 459 loss: 1.17070886e-06
Iter: 460 loss: 1.16759736e-06
Iter: 461 loss: 1.17702916e-06
Iter: 462 loss: 1.16664182e-06
Iter: 463 loss: 1.16356023e-06
Iter: 464 loss: 1.17833497e-06
Iter: 465 loss: 1.16305569e-06
Iter: 466 loss: 1.16084459e-06
Iter: 467 loss: 1.15847934e-06
Iter: 468 loss: 1.15807416e-06
Iter: 469 loss: 1.15471312e-06
Iter: 470 loss: 1.17416766e-06
Iter: 471 loss: 1.15426565e-06
Iter: 472 loss: 1.15153739e-06
Iter: 473 loss: 1.16597926e-06
Iter: 474 loss: 1.15106559e-06
Iter: 475 loss: 1.14881323e-06
Iter: 476 loss: 1.16526496e-06
Iter: 477 loss: 1.14862985e-06
Iter: 478 loss: 1.14693466e-06
Iter: 479 loss: 1.14531633e-06
Iter: 480 loss: 1.14496527e-06
Iter: 481 loss: 1.14197894e-06
Iter: 482 loss: 1.15058958e-06
Iter: 483 loss: 1.14093984e-06
Iter: 484 loss: 1.13826093e-06
Iter: 485 loss: 1.15338821e-06
Iter: 486 loss: 1.13786359e-06
Iter: 487 loss: 1.13578312e-06
Iter: 488 loss: 1.15712135e-06
Iter: 489 loss: 1.13571764e-06
Iter: 490 loss: 1.13421356e-06
Iter: 491 loss: 1.13527847e-06
Iter: 492 loss: 1.13324165e-06
Iter: 493 loss: 1.13120518e-06
Iter: 494 loss: 1.13025e-06
Iter: 495 loss: 1.1291944e-06
Iter: 496 loss: 1.12607245e-06
Iter: 497 loss: 1.13868828e-06
Iter: 498 loss: 1.12542023e-06
Iter: 499 loss: 1.12320652e-06
Iter: 500 loss: 1.14006275e-06
Iter: 501 loss: 1.12298153e-06
Iter: 502 loss: 1.12104658e-06
Iter: 503 loss: 1.12105795e-06
Iter: 504 loss: 1.11944428e-06
Iter: 505 loss: 1.11673705e-06
Iter: 506 loss: 1.12697467e-06
Iter: 507 loss: 1.11609324e-06
Iter: 508 loss: 1.11367649e-06
Iter: 509 loss: 1.11503482e-06
Iter: 510 loss: 1.1121034e-06
Iter: 511 loss: 1.10987958e-06
Iter: 512 loss: 1.1199038e-06
Iter: 513 loss: 1.10951601e-06
Iter: 514 loss: 1.10696044e-06
Iter: 515 loss: 1.11940221e-06
Iter: 516 loss: 1.10649455e-06
Iter: 517 loss: 1.10442375e-06
Iter: 518 loss: 1.10571693e-06
Iter: 519 loss: 1.10307735e-06
Iter: 520 loss: 1.10094936e-06
Iter: 521 loss: 1.10221538e-06
Iter: 522 loss: 1.09958978e-06
Iter: 523 loss: 1.09718349e-06
Iter: 524 loss: 1.1310334e-06
Iter: 525 loss: 1.09713619e-06
Iter: 526 loss: 1.09484472e-06
Iter: 527 loss: 1.09667383e-06
Iter: 528 loss: 1.09340522e-06
Iter: 529 loss: 1.09164569e-06
Iter: 530 loss: 1.09510495e-06
Iter: 531 loss: 1.0909514e-06
Iter: 532 loss: 1.08886252e-06
Iter: 533 loss: 1.0925944e-06
Iter: 534 loss: 1.08799497e-06
Iter: 535 loss: 1.08554309e-06
Iter: 536 loss: 1.09167604e-06
Iter: 537 loss: 1.08478844e-06
Iter: 538 loss: 1.08299128e-06
Iter: 539 loss: 1.09832263e-06
Iter: 540 loss: 1.0829242e-06
Iter: 541 loss: 1.08122697e-06
Iter: 542 loss: 1.07900928e-06
Iter: 543 loss: 1.0788217e-06
Iter: 544 loss: 1.07633946e-06
Iter: 545 loss: 1.09330813e-06
Iter: 546 loss: 1.07608071e-06
Iter: 547 loss: 1.07381402e-06
Iter: 548 loss: 1.07523852e-06
Iter: 549 loss: 1.07238657e-06
Iter: 550 loss: 1.07079018e-06
Iter: 551 loss: 1.07076312e-06
Iter: 552 loss: 1.06917116e-06
Iter: 553 loss: 1.06806897e-06
Iter: 554 loss: 1.06748337e-06
Iter: 555 loss: 1.06521838e-06
Iter: 556 loss: 1.07117944e-06
Iter: 557 loss: 1.06443201e-06
Iter: 558 loss: 1.06246762e-06
Iter: 559 loss: 1.07731069e-06
Iter: 560 loss: 1.06242555e-06
Iter: 561 loss: 1.06081984e-06
Iter: 562 loss: 1.06970106e-06
Iter: 563 loss: 1.06068273e-06
Iter: 564 loss: 1.05908919e-06
Iter: 565 loss: 1.05724712e-06
Iter: 566 loss: 1.05697814e-06
Iter: 567 loss: 1.05487618e-06
Iter: 568 loss: 1.05956826e-06
Iter: 569 loss: 1.05402546e-06
Iter: 570 loss: 1.05179436e-06
Iter: 571 loss: 1.05742424e-06
Iter: 572 loss: 1.0509907e-06
Iter: 573 loss: 1.04877654e-06
Iter: 574 loss: 1.07072128e-06
Iter: 575 loss: 1.04868434e-06
Iter: 576 loss: 1.04706487e-06
Iter: 577 loss: 1.04647972e-06
Iter: 578 loss: 1.04555716e-06
Iter: 579 loss: 1.04313722e-06
Iter: 580 loss: 1.05369691e-06
Iter: 581 loss: 1.04265087e-06
Iter: 582 loss: 1.04069727e-06
Iter: 583 loss: 1.04695312e-06
Iter: 584 loss: 1.04016351e-06
Iter: 585 loss: 1.03828359e-06
Iter: 586 loss: 1.03970933e-06
Iter: 587 loss: 1.03706054e-06
Iter: 588 loss: 1.03491948e-06
Iter: 589 loss: 1.04425078e-06
Iter: 590 loss: 1.03447633e-06
Iter: 591 loss: 1.03240404e-06
Iter: 592 loss: 1.04635421e-06
Iter: 593 loss: 1.03212278e-06
Iter: 594 loss: 1.03085472e-06
Iter: 595 loss: 1.02954868e-06
Iter: 596 loss: 1.02931858e-06
Iter: 597 loss: 1.02722595e-06
Iter: 598 loss: 1.04766093e-06
Iter: 599 loss: 1.02714762e-06
Iter: 600 loss: 1.0250925e-06
Iter: 601 loss: 1.02856848e-06
Iter: 602 loss: 1.02406591e-06
Iter: 603 loss: 1.02272952e-06
Iter: 604 loss: 1.02134049e-06
Iter: 605 loss: 1.02114632e-06
Iter: 606 loss: 1.01850264e-06
Iter: 607 loss: 1.02704644e-06
Iter: 608 loss: 1.0178037e-06
Iter: 609 loss: 1.01561682e-06
Iter: 610 loss: 1.03013781e-06
Iter: 611 loss: 1.0153675e-06
Iter: 612 loss: 1.01394244e-06
Iter: 613 loss: 1.02515787e-06
Iter: 614 loss: 1.01379783e-06
Iter: 615 loss: 1.01245541e-06
Iter: 616 loss: 1.01079263e-06
Iter: 617 loss: 1.01062074e-06
Iter: 618 loss: 1.0085605e-06
Iter: 619 loss: 1.02565764e-06
Iter: 620 loss: 1.00833654e-06
Iter: 621 loss: 1.00696241e-06
Iter: 622 loss: 1.0118672e-06
Iter: 623 loss: 1.00663271e-06
Iter: 624 loss: 1.00499767e-06
Iter: 625 loss: 1.00352668e-06
Iter: 626 loss: 1.00310081e-06
Iter: 627 loss: 1.00155239e-06
Iter: 628 loss: 1.00152124e-06
Iter: 629 loss: 1.00031173e-06
Iter: 630 loss: 1.00046441e-06
Iter: 631 loss: 9.99363465e-07
Iter: 632 loss: 9.97871666e-07
Iter: 633 loss: 1.00110947e-06
Iter: 634 loss: 9.97284133e-07
Iter: 635 loss: 9.95467872e-07
Iter: 636 loss: 1.00966577e-06
Iter: 637 loss: 9.95384653e-07
Iter: 638 loss: 9.94224933e-07
Iter: 639 loss: 9.95643632e-07
Iter: 640 loss: 9.93611593e-07
Iter: 641 loss: 9.92256901e-07
Iter: 642 loss: 9.90414151e-07
Iter: 643 loss: 9.90347189e-07
Iter: 644 loss: 9.87921567e-07
Iter: 645 loss: 9.99258873e-07
Iter: 646 loss: 9.87536737e-07
Iter: 647 loss: 9.85611791e-07
Iter: 648 loss: 9.93612502e-07
Iter: 649 loss: 9.85222755e-07
Iter: 650 loss: 9.8336227e-07
Iter: 651 loss: 9.94783932e-07
Iter: 652 loss: 9.83183554e-07
Iter: 653 loss: 9.81627863e-07
Iter: 654 loss: 9.83815e-07
Iter: 655 loss: 9.80884579e-07
Iter: 656 loss: 9.7965119e-07
Iter: 657 loss: 9.79564902e-07
Iter: 658 loss: 9.78554681e-07
Iter: 659 loss: 9.76655656e-07
Iter: 660 loss: 9.8894759e-07
Iter: 661 loss: 9.76433739e-07
Iter: 662 loss: 9.74690579e-07
Iter: 663 loss: 9.79903234e-07
Iter: 664 loss: 9.74168188e-07
Iter: 665 loss: 9.728451e-07
Iter: 666 loss: 9.79547394e-07
Iter: 667 loss: 9.72639555e-07
Iter: 668 loss: 9.71265194e-07
Iter: 669 loss: 9.72445378e-07
Iter: 670 loss: 9.70473366e-07
Iter: 671 loss: 9.69094344e-07
Iter: 672 loss: 9.78937464e-07
Iter: 673 loss: 9.68987138e-07
Iter: 674 loss: 9.67638584e-07
Iter: 675 loss: 9.68624818e-07
Iter: 676 loss: 9.66830839e-07
Iter: 677 loss: 9.65422601e-07
Iter: 678 loss: 9.6686108e-07
Iter: 679 loss: 9.64665446e-07
Iter: 680 loss: 9.63052e-07
Iter: 681 loss: 9.62379318e-07
Iter: 682 loss: 9.61526e-07
Iter: 683 loss: 9.59382646e-07
Iter: 684 loss: 9.75534135e-07
Iter: 685 loss: 9.59210524e-07
Iter: 686 loss: 9.57624479e-07
Iter: 687 loss: 9.6435781e-07
Iter: 688 loss: 9.57344128e-07
Iter: 689 loss: 9.55778091e-07
Iter: 690 loss: 9.6278643e-07
Iter: 691 loss: 9.55533096e-07
Iter: 692 loss: 9.54256734e-07
Iter: 693 loss: 9.56908707e-07
Iter: 694 loss: 9.53805625e-07
Iter: 695 loss: 9.52484584e-07
Iter: 696 loss: 9.53009248e-07
Iter: 697 loss: 9.5161e-07
Iter: 698 loss: 9.50036622e-07
Iter: 699 loss: 9.557466e-07
Iter: 700 loss: 9.49618823e-07
Iter: 701 loss: 9.48115144e-07
Iter: 702 loss: 9.55326e-07
Iter: 703 loss: 9.47886519e-07
Iter: 704 loss: 9.46389093e-07
Iter: 705 loss: 9.50209483e-07
Iter: 706 loss: 9.45853e-07
Iter: 707 loss: 9.44251099e-07
Iter: 708 loss: 9.47903914e-07
Iter: 709 loss: 9.43704265e-07
Iter: 710 loss: 9.4249981e-07
Iter: 711 loss: 9.57922566e-07
Iter: 712 loss: 9.424773e-07
Iter: 713 loss: 9.41730946e-07
Iter: 714 loss: 9.4009431e-07
Iter: 715 loss: 9.71298391e-07
Iter: 716 loss: 9.40114262e-07
Iter: 717 loss: 9.3828487e-07
Iter: 718 loss: 9.54519805e-07
Iter: 719 loss: 9.38207563e-07
Iter: 720 loss: 9.37114237e-07
Iter: 721 loss: 9.359091e-07
Iter: 722 loss: 9.35743969e-07
Iter: 723 loss: 9.33763943e-07
Iter: 724 loss: 9.40303494e-07
Iter: 725 loss: 9.33168167e-07
Iter: 726 loss: 9.31535169e-07
Iter: 727 loss: 9.37536e-07
Iter: 728 loss: 9.31094291e-07
Iter: 729 loss: 9.29776661e-07
Iter: 730 loss: 9.4603547e-07
Iter: 731 loss: 9.29747841e-07
Iter: 732 loss: 9.28484269e-07
Iter: 733 loss: 9.2799246e-07
Iter: 734 loss: 9.27260885e-07
Iter: 735 loss: 9.25799611e-07
Iter: 736 loss: 9.28077213e-07
Iter: 737 loss: 9.2508435e-07
Iter: 738 loss: 9.23573225e-07
Iter: 739 loss: 9.35018647e-07
Iter: 740 loss: 9.23486311e-07
Iter: 741 loss: 9.22104391e-07
Iter: 742 loss: 9.24241135e-07
Iter: 743 loss: 9.21457968e-07
Iter: 744 loss: 9.19902732e-07
Iter: 745 loss: 9.3164806e-07
Iter: 746 loss: 9.19850379e-07
Iter: 747 loss: 9.1907e-07
Iter: 748 loss: 9.22223421e-07
Iter: 749 loss: 9.18888702e-07
Iter: 750 loss: 9.18009732e-07
Iter: 751 loss: 9.17280317e-07
Iter: 752 loss: 9.1699485e-07
Iter: 753 loss: 9.15278406e-07
Iter: 754 loss: 9.166464e-07
Iter: 755 loss: 9.14267559e-07
Iter: 756 loss: 9.1298989e-07
Iter: 757 loss: 9.23985226e-07
Iter: 758 loss: 9.1296306e-07
Iter: 759 loss: 9.11826305e-07
Iter: 760 loss: 9.12214e-07
Iter: 761 loss: 9.11001905e-07
Iter: 762 loss: 9.09750838e-07
Iter: 763 loss: 9.09592416e-07
Iter: 764 loss: 9.08747552e-07
Iter: 765 loss: 9.06845514e-07
Iter: 766 loss: 9.21184551e-07
Iter: 767 loss: 9.06667196e-07
Iter: 768 loss: 9.0558359e-07
Iter: 769 loss: 9.11281745e-07
Iter: 770 loss: 9.05465185e-07
Iter: 771 loss: 9.04085937e-07
Iter: 772 loss: 9.05210925e-07
Iter: 773 loss: 9.03368345e-07
Iter: 774 loss: 9.01898602e-07
Iter: 775 loss: 9.02895522e-07
Iter: 776 loss: 9.00912426e-07
Iter: 777 loss: 8.994827e-07
Iter: 778 loss: 9.04386e-07
Iter: 779 loss: 8.99014594e-07
Iter: 780 loss: 8.9797885e-07
Iter: 781 loss: 8.97969812e-07
Iter: 782 loss: 8.97141433e-07
Iter: 783 loss: 8.97635687e-07
Iter: 784 loss: 8.96543042e-07
Iter: 785 loss: 8.95504172e-07
Iter: 786 loss: 8.99570807e-07
Iter: 787 loss: 8.95330288e-07
Iter: 788 loss: 8.94147e-07
Iter: 789 loss: 8.93886067e-07
Iter: 790 loss: 8.93146364e-07
Iter: 791 loss: 8.9179116e-07
Iter: 792 loss: 8.96318966e-07
Iter: 793 loss: 8.9144919e-07
Iter: 794 loss: 8.90379624e-07
Iter: 795 loss: 8.91680884e-07
Iter: 796 loss: 8.89844159e-07
Iter: 797 loss: 8.88221166e-07
Iter: 798 loss: 8.92434741e-07
Iter: 799 loss: 8.87624537e-07
Iter: 800 loss: 8.86572536e-07
Iter: 801 loss: 8.90429931e-07
Iter: 802 loss: 8.86239661e-07
Iter: 803 loss: 8.85155373e-07
Iter: 804 loss: 8.86255577e-07
Iter: 805 loss: 8.84492465e-07
Iter: 806 loss: 8.83046937e-07
Iter: 807 loss: 8.88671707e-07
Iter: 808 loss: 8.82769939e-07
Iter: 809 loss: 8.81609083e-07
Iter: 810 loss: 8.91680429e-07
Iter: 811 loss: 8.81551045e-07
Iter: 812 loss: 8.80631319e-07
Iter: 813 loss: 8.80549521e-07
Iter: 814 loss: 8.79804361e-07
Iter: 815 loss: 8.78640151e-07
Iter: 816 loss: 8.81456913e-07
Iter: 817 loss: 8.78144192e-07
Iter: 818 loss: 8.76987542e-07
Iter: 819 loss: 8.87206454e-07
Iter: 820 loss: 8.76928766e-07
Iter: 821 loss: 8.76034051e-07
Iter: 822 loss: 8.80130131e-07
Iter: 823 loss: 8.75876424e-07
Iter: 824 loss: 8.7507442e-07
Iter: 825 loss: 8.73851377e-07
Iter: 826 loss: 8.73829379e-07
Iter: 827 loss: 8.72800683e-07
Iter: 828 loss: 8.728083e-07
Iter: 829 loss: 8.72035685e-07
Iter: 830 loss: 8.70552299e-07
Iter: 831 loss: 9.0269657e-07
Iter: 832 loss: 8.70554118e-07
Iter: 833 loss: 8.68902248e-07
Iter: 834 loss: 8.7404311e-07
Iter: 835 loss: 8.68425332e-07
Iter: 836 loss: 8.67151243e-07
Iter: 837 loss: 8.77159891e-07
Iter: 838 loss: 8.67108042e-07
Iter: 839 loss: 8.66043649e-07
Iter: 840 loss: 8.68889856e-07
Iter: 841 loss: 8.6575136e-07
Iter: 842 loss: 8.64475794e-07
Iter: 843 loss: 8.63932485e-07
Iter: 844 loss: 8.6332193e-07
Iter: 845 loss: 8.62138904e-07
Iter: 846 loss: 8.73378895e-07
Iter: 847 loss: 8.62063189e-07
Iter: 848 loss: 8.60959e-07
Iter: 849 loss: 8.66596054e-07
Iter: 850 loss: 8.60823548e-07
Iter: 851 loss: 8.6000955e-07
Iter: 852 loss: 8.59470902e-07
Iter: 853 loss: 8.5915525e-07
Iter: 854 loss: 8.5793306e-07
Iter: 855 loss: 8.65320089e-07
Iter: 856 loss: 8.5777117e-07
Iter: 857 loss: 8.56705356e-07
Iter: 858 loss: 8.64914568e-07
Iter: 859 loss: 8.56589622e-07
Iter: 860 loss: 8.55865892e-07
Iter: 861 loss: 8.56028e-07
Iter: 862 loss: 8.55250278e-07
Iter: 863 loss: 8.54322707e-07
Iter: 864 loss: 8.55564792e-07
Iter: 865 loss: 8.53842209e-07
Iter: 866 loss: 8.5268573e-07
Iter: 867 loss: 8.59025135e-07
Iter: 868 loss: 8.52532594e-07
Iter: 869 loss: 8.51620541e-07
Iter: 870 loss: 8.52236e-07
Iter: 871 loss: 8.51001175e-07
Iter: 872 loss: 8.49986861e-07
Iter: 873 loss: 8.49338562e-07
Iter: 874 loss: 8.48997e-07
Iter: 875 loss: 8.47329261e-07
Iter: 876 loss: 8.59656666e-07
Iter: 877 loss: 8.47235583e-07
Iter: 878 loss: 8.4619478e-07
Iter: 879 loss: 8.48718287e-07
Iter: 880 loss: 8.4579932e-07
Iter: 881 loss: 8.44636133e-07
Iter: 882 loss: 8.49963783e-07
Iter: 883 loss: 8.44388524e-07
Iter: 884 loss: 8.43254725e-07
Iter: 885 loss: 8.4377524e-07
Iter: 886 loss: 8.42533723e-07
Iter: 887 loss: 8.41555e-07
Iter: 888 loss: 8.55646704e-07
Iter: 889 loss: 8.4156261e-07
Iter: 890 loss: 8.40862072e-07
Iter: 891 loss: 8.41036922e-07
Iter: 892 loss: 8.40343034e-07
Iter: 893 loss: 8.39159497e-07
Iter: 894 loss: 8.40165058e-07
Iter: 895 loss: 8.38516712e-07
Iter: 896 loss: 8.37511e-07
Iter: 897 loss: 8.37502114e-07
Iter: 898 loss: 8.3694772e-07
Iter: 899 loss: 8.36233426e-07
Iter: 900 loss: 8.36140771e-07
Iter: 901 loss: 8.35192282e-07
Iter: 902 loss: 8.37007633e-07
Iter: 903 loss: 8.34778348e-07
Iter: 904 loss: 8.33755507e-07
Iter: 905 loss: 8.4178464e-07
Iter: 906 loss: 8.33686613e-07
Iter: 907 loss: 8.32752562e-07
Iter: 908 loss: 8.3259124e-07
Iter: 909 loss: 8.32007743e-07
Iter: 910 loss: 8.30913677e-07
Iter: 911 loss: 8.31958e-07
Iter: 912 loss: 8.3027021e-07
Iter: 913 loss: 8.2892e-07
Iter: 914 loss: 8.35387709e-07
Iter: 915 loss: 8.28713723e-07
Iter: 916 loss: 8.27709641e-07
Iter: 917 loss: 8.30606041e-07
Iter: 918 loss: 8.2745521e-07
Iter: 919 loss: 8.2639184e-07
Iter: 920 loss: 8.28777274e-07
Iter: 921 loss: 8.25987115e-07
Iter: 922 loss: 8.24793517e-07
Iter: 923 loss: 8.28616066e-07
Iter: 924 loss: 8.24520043e-07
Iter: 925 loss: 8.2348123e-07
Iter: 926 loss: 8.30332795e-07
Iter: 927 loss: 8.23473385e-07
Iter: 928 loss: 8.2256804e-07
Iter: 929 loss: 8.22606182e-07
Iter: 930 loss: 8.21888477e-07
Iter: 931 loss: 8.2100189e-07
Iter: 932 loss: 8.34811431e-07
Iter: 933 loss: 8.21003766e-07
Iter: 934 loss: 8.20418961e-07
Iter: 935 loss: 8.20734272e-07
Iter: 936 loss: 8.20034529e-07
Iter: 937 loss: 8.19076774e-07
Iter: 938 loss: 8.19211891e-07
Iter: 939 loss: 8.18353e-07
Iter: 940 loss: 8.17434511e-07
Iter: 941 loss: 8.18008e-07
Iter: 942 loss: 8.16836518e-07
Iter: 943 loss: 8.15937256e-07
Iter: 944 loss: 8.28789553e-07
Iter: 945 loss: 8.15953399e-07
Iter: 946 loss: 8.15129056e-07
Iter: 947 loss: 8.14922032e-07
Iter: 948 loss: 8.1440578e-07
Iter: 949 loss: 8.13362703e-07
Iter: 950 loss: 8.14163172e-07
Iter: 951 loss: 8.12685641e-07
Iter: 952 loss: 8.11635346e-07
Iter: 953 loss: 8.14897703e-07
Iter: 954 loss: 8.11275527e-07
Iter: 955 loss: 8.10036227e-07
Iter: 956 loss: 8.12723442e-07
Iter: 957 loss: 8.09550215e-07
Iter: 958 loss: 8.08591381e-07
Iter: 959 loss: 8.19830689e-07
Iter: 960 loss: 8.08565858e-07
Iter: 961 loss: 8.0783974e-07
Iter: 962 loss: 8.08545906e-07
Iter: 963 loss: 8.07416427e-07
Iter: 964 loss: 8.06309686e-07
Iter: 965 loss: 8.09701248e-07
Iter: 966 loss: 8.06031665e-07
Iter: 967 loss: 8.05121488e-07
Iter: 968 loss: 8.10218467e-07
Iter: 969 loss: 8.05028662e-07
Iter: 970 loss: 8.0436007e-07
Iter: 971 loss: 8.08065295e-07
Iter: 972 loss: 8.04268893e-07
Iter: 973 loss: 8.03772537e-07
Iter: 974 loss: 8.03743092e-07
Iter: 975 loss: 8.0329869e-07
Iter: 976 loss: 8.0240568e-07
Iter: 977 loss: 8.0266517e-07
Iter: 978 loss: 8.01767612e-07
Iter: 979 loss: 8.00877558e-07
Iter: 980 loss: 8.06589128e-07
Iter: 981 loss: 8.00761541e-07
Iter: 982 loss: 8.00029511e-07
Iter: 983 loss: 8.00801786e-07
Iter: 984 loss: 7.99526333e-07
Iter: 985 loss: 7.98507529e-07
Iter: 986 loss: 8.0509642e-07
Iter: 987 loss: 7.98455289e-07
Iter: 988 loss: 7.97708253e-07
Iter: 989 loss: 7.97377879e-07
Iter: 990 loss: 7.97061261e-07
Iter: 991 loss: 7.9586971e-07
Iter: 992 loss: 7.98684937e-07
Iter: 993 loss: 7.95435312e-07
Iter: 994 loss: 7.94518144e-07
Iter: 995 loss: 7.96904544e-07
Iter: 996 loss: 7.94237621e-07
Iter: 997 loss: 7.93254e-07
Iter: 998 loss: 7.94714765e-07
Iter: 999 loss: 7.92820401e-07
Iter: 1000 loss: 7.91980142e-07
Iter: 1001 loss: 8.00558723e-07
Iter: 1002 loss: 7.91974401e-07
Iter: 1003 loss: 7.91087473e-07
Iter: 1004 loss: 7.93791287e-07
Iter: 1005 loss: 7.90860781e-07
Iter: 1006 loss: 7.9017525e-07
Iter: 1007 loss: 7.92229798e-07
Iter: 1008 loss: 7.89905073e-07
Iter: 1009 loss: 7.89065325e-07
Iter: 1010 loss: 7.90879653e-07
Iter: 1011 loss: 7.88680325e-07
Iter: 1012 loss: 7.88099555e-07
Iter: 1013 loss: 7.88635361e-07
Iter: 1014 loss: 7.87705744e-07
Iter: 1015 loss: 7.86775558e-07
Iter: 1016 loss: 7.88385705e-07
Iter: 1017 loss: 7.8631524e-07
Iter: 1018 loss: 7.85487828e-07
Iter: 1019 loss: 7.88243256e-07
Iter: 1020 loss: 7.85293935e-07
Iter: 1021 loss: 7.84521887e-07
Iter: 1022 loss: 7.88318744e-07
Iter: 1023 loss: 7.84348913e-07
Iter: 1024 loss: 7.83589257e-07
Iter: 1025 loss: 7.84932809e-07
Iter: 1026 loss: 7.83301061e-07
Iter: 1027 loss: 7.82539132e-07
Iter: 1028 loss: 7.83196128e-07
Iter: 1029 loss: 7.82116274e-07
Iter: 1030 loss: 7.81159656e-07
Iter: 1031 loss: 7.83442943e-07
Iter: 1032 loss: 7.80819391e-07
Iter: 1033 loss: 7.79971742e-07
Iter: 1034 loss: 7.823121e-07
Iter: 1035 loss: 7.79701963e-07
Iter: 1036 loss: 7.78843798e-07
Iter: 1037 loss: 7.80171774e-07
Iter: 1038 loss: 7.78394906e-07
Iter: 1039 loss: 7.77371724e-07
Iter: 1040 loss: 7.81415906e-07
Iter: 1041 loss: 7.77089895e-07
Iter: 1042 loss: 7.76504407e-07
Iter: 1043 loss: 7.76475758e-07
Iter: 1044 loss: 7.760828e-07
Iter: 1045 loss: 7.75341164e-07
Iter: 1046 loss: 7.92757191e-07
Iter: 1047 loss: 7.75376293e-07
Iter: 1048 loss: 7.74349814e-07
Iter: 1049 loss: 7.82323241e-07
Iter: 1050 loss: 7.74306102e-07
Iter: 1051 loss: 7.73751935e-07
Iter: 1052 loss: 7.73056911e-07
Iter: 1053 loss: 7.72971e-07
Iter: 1054 loss: 7.72199e-07
Iter: 1055 loss: 7.79676668e-07
Iter: 1056 loss: 7.72127237e-07
Iter: 1057 loss: 7.71352e-07
Iter: 1058 loss: 7.72260478e-07
Iter: 1059 loss: 7.70929e-07
Iter: 1060 loss: 7.70191889e-07
Iter: 1061 loss: 7.74277055e-07
Iter: 1062 loss: 7.7008167e-07
Iter: 1063 loss: 7.69343842e-07
Iter: 1064 loss: 7.71019586e-07
Iter: 1065 loss: 7.69111693e-07
Iter: 1066 loss: 7.68339589e-07
Iter: 1067 loss: 7.6815013e-07
Iter: 1068 loss: 7.67685606e-07
Iter: 1069 loss: 7.66776509e-07
Iter: 1070 loss: 7.72407475e-07
Iter: 1071 loss: 7.66646622e-07
Iter: 1072 loss: 7.65882533e-07
Iter: 1073 loss: 7.65323307e-07
Iter: 1074 loss: 7.6512049e-07
Iter: 1075 loss: 7.63983167e-07
Iter: 1076 loss: 7.73649731e-07
Iter: 1077 loss: 7.6388136e-07
Iter: 1078 loss: 7.631578e-07
Iter: 1079 loss: 7.69559392e-07
Iter: 1080 loss: 7.63104197e-07
Iter: 1081 loss: 7.62416903e-07
Iter: 1082 loss: 7.64423589e-07
Iter: 1083 loss: 7.6222824e-07
Iter: 1084 loss: 7.6160768e-07
Iter: 1085 loss: 7.61438628e-07
Iter: 1086 loss: 7.61038564e-07
Iter: 1087 loss: 7.6019785e-07
Iter: 1088 loss: 7.65596212e-07
Iter: 1089 loss: 7.60043179e-07
Iter: 1090 loss: 7.59499414e-07
Iter: 1091 loss: 7.60595071e-07
Iter: 1092 loss: 7.59246745e-07
Iter: 1093 loss: 7.58541319e-07
Iter: 1094 loss: 7.58579631e-07
Iter: 1095 loss: 7.58021e-07
Iter: 1096 loss: 7.57217322e-07
Iter: 1097 loss: 7.60511057e-07
Iter: 1098 loss: 7.57109774e-07
Iter: 1099 loss: 7.56374845e-07
Iter: 1100 loss: 7.62317541e-07
Iter: 1101 loss: 7.56318627e-07
Iter: 1102 loss: 7.55716144e-07
Iter: 1103 loss: 7.55557892e-07
Iter: 1104 loss: 7.55216888e-07
Iter: 1105 loss: 7.54456096e-07
Iter: 1106 loss: 7.58708666e-07
Iter: 1107 loss: 7.54329676e-07
Iter: 1108 loss: 7.53632719e-07
Iter: 1109 loss: 7.5402545e-07
Iter: 1110 loss: 7.53101062e-07
Iter: 1111 loss: 7.52294113e-07
Iter: 1112 loss: 7.53744303e-07
Iter: 1113 loss: 7.51949642e-07
Iter: 1114 loss: 7.51054642e-07
Iter: 1115 loss: 7.5251404e-07
Iter: 1116 loss: 7.50645711e-07
Iter: 1117 loss: 7.50118659e-07
Iter: 1118 loss: 7.50069603e-07
Iter: 1119 loss: 7.49570688e-07
Iter: 1120 loss: 7.49500089e-07
Iter: 1121 loss: 7.49193077e-07
Iter: 1122 loss: 7.48566379e-07
Iter: 1123 loss: 7.49260721e-07
Iter: 1124 loss: 7.48260788e-07
Iter: 1125 loss: 7.474315e-07
Iter: 1126 loss: 7.4989623e-07
Iter: 1127 loss: 7.47174568e-07
Iter: 1128 loss: 7.46515752e-07
Iter: 1129 loss: 7.4877596e-07
Iter: 1130 loss: 7.46285082e-07
Iter: 1131 loss: 7.45732e-07
Iter: 1132 loss: 7.45868306e-07
Iter: 1133 loss: 7.45245416e-07
Iter: 1134 loss: 7.44496447e-07
Iter: 1135 loss: 7.47502781e-07
Iter: 1136 loss: 7.4430352e-07
Iter: 1137 loss: 7.43605824e-07
Iter: 1138 loss: 7.48492482e-07
Iter: 1139 loss: 7.43571718e-07
Iter: 1140 loss: 7.43001351e-07
Iter: 1141 loss: 7.43729174e-07
Iter: 1142 loss: 7.42709e-07
Iter: 1143 loss: 7.42022053e-07
Iter: 1144 loss: 7.42330087e-07
Iter: 1145 loss: 7.41511428e-07
Iter: 1146 loss: 7.40728865e-07
Iter: 1147 loss: 7.44749e-07
Iter: 1148 loss: 7.4063729e-07
Iter: 1149 loss: 7.39909581e-07
Iter: 1150 loss: 7.41933661e-07
Iter: 1151 loss: 7.3973e-07
Iter: 1152 loss: 7.39076711e-07
Iter: 1153 loss: 7.39281745e-07
Iter: 1154 loss: 7.38610083e-07
Iter: 1155 loss: 7.38034259e-07
Iter: 1156 loss: 7.38028348e-07
Iter: 1157 loss: 7.37554501e-07
Iter: 1158 loss: 7.3751113e-07
Iter: 1159 loss: 7.3721634e-07
Iter: 1160 loss: 7.3661738e-07
Iter: 1161 loss: 7.36171728e-07
Iter: 1162 loss: 7.36021434e-07
Iter: 1163 loss: 7.3512922e-07
Iter: 1164 loss: 7.43650389e-07
Iter: 1165 loss: 7.35105118e-07
Iter: 1166 loss: 7.34541402e-07
Iter: 1167 loss: 7.37874757e-07
Iter: 1168 loss: 7.34489731e-07
Iter: 1169 loss: 7.34031062e-07
Iter: 1170 loss: 7.3294234e-07
Iter: 1171 loss: 7.46215903e-07
Iter: 1172 loss: 7.32865942e-07
Iter: 1173 loss: 7.31910518e-07
Iter: 1174 loss: 7.45248428e-07
Iter: 1175 loss: 7.31905061e-07
Iter: 1176 loss: 7.31058037e-07
Iter: 1177 loss: 7.35228923e-07
Iter: 1178 loss: 7.30889326e-07
Iter: 1179 loss: 7.302732e-07
Iter: 1180 loss: 7.31959233e-07
Iter: 1181 loss: 7.30052534e-07
Iter: 1182 loss: 7.29511555e-07
Iter: 1183 loss: 7.30243187e-07
Iter: 1184 loss: 7.29249791e-07
Iter: 1185 loss: 7.28560394e-07
Iter: 1186 loss: 7.29776e-07
Iter: 1187 loss: 7.28246846e-07
Iter: 1188 loss: 7.27554777e-07
Iter: 1189 loss: 7.3045851e-07
Iter: 1190 loss: 7.27425572e-07
Iter: 1191 loss: 7.26699795e-07
Iter: 1192 loss: 7.29083069e-07
Iter: 1193 loss: 7.26465146e-07
Iter: 1194 loss: 7.25973848e-07
Iter: 1195 loss: 7.31583668e-07
Iter: 1196 loss: 7.25948041e-07
Iter: 1197 loss: 7.25449638e-07
Iter: 1198 loss: 7.2460773e-07
Iter: 1199 loss: 7.45007128e-07
Iter: 1200 loss: 7.24597498e-07
Iter: 1201 loss: 7.23706933e-07
Iter: 1202 loss: 7.26820872e-07
Iter: 1203 loss: 7.23542485e-07
Iter: 1204 loss: 7.23028279e-07
Iter: 1205 loss: 7.23011112e-07
Iter: 1206 loss: 7.2260957e-07
Iter: 1207 loss: 7.22139816e-07
Iter: 1208 loss: 7.22158745e-07
Iter: 1209 loss: 7.21250785e-07
Iter: 1210 loss: 7.23634685e-07
Iter: 1211 loss: 7.21035576e-07
Iter: 1212 loss: 7.20373635e-07
Iter: 1213 loss: 7.21707e-07
Iter: 1214 loss: 7.20085268e-07
Iter: 1215 loss: 7.19276557e-07
Iter: 1216 loss: 7.24769563e-07
Iter: 1217 loss: 7.19186119e-07
Iter: 1218 loss: 7.18625927e-07
Iter: 1219 loss: 7.19093123e-07
Iter: 1220 loss: 7.18262868e-07
Iter: 1221 loss: 7.17606e-07
Iter: 1222 loss: 7.18881381e-07
Iter: 1223 loss: 7.17368096e-07
Iter: 1224 loss: 7.16760042e-07
Iter: 1225 loss: 7.18748822e-07
Iter: 1226 loss: 7.16540399e-07
Iter: 1227 loss: 7.15828605e-07
Iter: 1228 loss: 7.18199317e-07
Iter: 1229 loss: 7.15626243e-07
Iter: 1230 loss: 7.15003523e-07
Iter: 1231 loss: 7.22117704e-07
Iter: 1232 loss: 7.15047236e-07
Iter: 1233 loss: 7.14613066e-07
Iter: 1234 loss: 7.14098292e-07
Iter: 1235 loss: 7.14063503e-07
Iter: 1236 loss: 7.13463123e-07
Iter: 1237 loss: 7.1649356e-07
Iter: 1238 loss: 7.13373424e-07
Iter: 1239 loss: 7.12781e-07
Iter: 1240 loss: 7.12359e-07
Iter: 1241 loss: 7.12165502e-07
Iter: 1242 loss: 7.11498672e-07
Iter: 1243 loss: 7.11506857e-07
Iter: 1244 loss: 7.11052621e-07
Iter: 1245 loss: 7.11493215e-07
Iter: 1246 loss: 7.10717245e-07
Iter: 1247 loss: 7.10139602e-07
Iter: 1248 loss: 7.10243853e-07
Iter: 1249 loss: 7.09688607e-07
Iter: 1250 loss: 7.09015239e-07
Iter: 1251 loss: 7.1273314e-07
Iter: 1252 loss: 7.08890298e-07
Iter: 1253 loss: 7.08252e-07
Iter: 1254 loss: 7.11880602e-07
Iter: 1255 loss: 7.08118591e-07
Iter: 1256 loss: 7.07578693e-07
Iter: 1257 loss: 7.07097968e-07
Iter: 1258 loss: 7.06949436e-07
Iter: 1259 loss: 7.06141748e-07
Iter: 1260 loss: 7.09801e-07
Iter: 1261 loss: 7.0600413e-07
Iter: 1262 loss: 7.05402158e-07
Iter: 1263 loss: 7.08320613e-07
Iter: 1264 loss: 7.05325078e-07
Iter: 1265 loss: 7.0462238e-07
Iter: 1266 loss: 7.07023446e-07
Iter: 1267 loss: 7.04422632e-07
Iter: 1268 loss: 7.03814578e-07
Iter: 1269 loss: 7.06482751e-07
Iter: 1270 loss: 7.03697538e-07
Iter: 1271 loss: 7.03335672e-07
Iter: 1272 loss: 7.0304e-07
Iter: 1273 loss: 7.02927309e-07
Iter: 1274 loss: 7.02118086e-07
Iter: 1275 loss: 7.03592946e-07
Iter: 1276 loss: 7.01813576e-07
Iter: 1277 loss: 7.0116721e-07
Iter: 1278 loss: 7.03368414e-07
Iter: 1279 loss: 7.01063072e-07
Iter: 1280 loss: 7.00271301e-07
Iter: 1281 loss: 7.02514797e-07
Iter: 1282 loss: 7.00045177e-07
Iter: 1283 loss: 6.99397106e-07
Iter: 1284 loss: 7.0131307e-07
Iter: 1285 loss: 6.9919281e-07
Iter: 1286 loss: 6.98639496e-07
Iter: 1287 loss: 6.99331281e-07
Iter: 1288 loss: 6.98337089e-07
Iter: 1289 loss: 6.97648716e-07
Iter: 1290 loss: 6.99842815e-07
Iter: 1291 loss: 6.97448456e-07
Iter: 1292 loss: 6.96883319e-07
Iter: 1293 loss: 7.0295016e-07
Iter: 1294 loss: 6.96864163e-07
Iter: 1295 loss: 6.96450172e-07
Iter: 1296 loss: 6.95930339e-07
Iter: 1297 loss: 6.95901235e-07
Iter: 1298 loss: 6.95084964e-07
Iter: 1299 loss: 6.96696134e-07
Iter: 1300 loss: 6.94783807e-07
Iter: 1301 loss: 6.94170751e-07
Iter: 1302 loss: 7.03969704e-07
Iter: 1303 loss: 6.94164e-07
Iter: 1304 loss: 6.9361181e-07
Iter: 1305 loss: 6.95355311e-07
Iter: 1306 loss: 6.93476409e-07
Iter: 1307 loss: 6.9302007e-07
Iter: 1308 loss: 6.92337e-07
Iter: 1309 loss: 6.92300432e-07
Iter: 1310 loss: 6.91718924e-07
Iter: 1311 loss: 7.0100748e-07
Iter: 1312 loss: 6.9170585e-07
Iter: 1313 loss: 6.91243e-07
Iter: 1314 loss: 6.9115174e-07
Iter: 1315 loss: 6.90856837e-07
Iter: 1316 loss: 6.90187903e-07
Iter: 1317 loss: 6.92377739e-07
Iter: 1318 loss: 6.89960757e-07
Iter: 1319 loss: 6.89316835e-07
Iter: 1320 loss: 6.94123742e-07
Iter: 1321 loss: 6.89277385e-07
Iter: 1322 loss: 6.888e-07
Iter: 1323 loss: 6.88561499e-07
Iter: 1324 loss: 6.88396085e-07
Iter: 1325 loss: 6.87755062e-07
Iter: 1326 loss: 6.90895888e-07
Iter: 1327 loss: 6.87647173e-07
Iter: 1328 loss: 6.87060037e-07
Iter: 1329 loss: 6.88993964e-07
Iter: 1330 loss: 6.86925e-07
Iter: 1331 loss: 6.86317776e-07
Iter: 1332 loss: 6.88765795e-07
Iter: 1333 loss: 6.86130647e-07
Iter: 1334 loss: 6.85635882e-07
Iter: 1335 loss: 6.85511338e-07
Iter: 1336 loss: 6.8514953e-07
Iter: 1337 loss: 6.84458939e-07
Iter: 1338 loss: 6.87062766e-07
Iter: 1339 loss: 6.8433917e-07
Iter: 1340 loss: 6.83846793e-07
Iter: 1341 loss: 6.83825647e-07
Iter: 1342 loss: 6.83495387e-07
Iter: 1343 loss: 6.82983e-07
Iter: 1344 loss: 6.82944915e-07
Iter: 1345 loss: 6.82298662e-07
Iter: 1346 loss: 6.83910685e-07
Iter: 1347 loss: 6.82079e-07
Iter: 1348 loss: 6.81507288e-07
Iter: 1349 loss: 6.82671157e-07
Iter: 1350 loss: 6.81269967e-07
Iter: 1351 loss: 6.80539586e-07
Iter: 1352 loss: 6.83060421e-07
Iter: 1353 loss: 6.80338417e-07
Iter: 1354 loss: 6.79725758e-07
Iter: 1355 loss: 6.81923098e-07
Iter: 1356 loss: 6.7955915e-07
Iter: 1357 loss: 6.79067227e-07
Iter: 1358 loss: 6.81734605e-07
Iter: 1359 loss: 6.78975539e-07
Iter: 1360 loss: 6.78395281e-07
Iter: 1361 loss: 6.7784697e-07
Iter: 1362 loss: 6.7773783e-07
Iter: 1363 loss: 6.77033483e-07
Iter: 1364 loss: 6.80324e-07
Iter: 1365 loss: 6.76887282e-07
Iter: 1366 loss: 6.76299749e-07
Iter: 1367 loss: 6.81976132e-07
Iter: 1368 loss: 6.76276045e-07
Iter: 1369 loss: 6.75868364e-07
Iter: 1370 loss: 6.76095283e-07
Iter: 1371 loss: 6.75596539e-07
Iter: 1372 loss: 6.7506187e-07
Iter: 1373 loss: 6.75884678e-07
Iter: 1374 loss: 6.7480596e-07
Iter: 1375 loss: 6.74265266e-07
Iter: 1376 loss: 6.78629249e-07
Iter: 1377 loss: 6.74196144e-07
Iter: 1378 loss: 6.73629927e-07
Iter: 1379 loss: 6.73886802e-07
Iter: 1380 loss: 6.73242084e-07
Iter: 1381 loss: 6.72692408e-07
Iter: 1382 loss: 6.73813588e-07
Iter: 1383 loss: 6.72412966e-07
Iter: 1384 loss: 6.71883186e-07
Iter: 1385 loss: 6.72023646e-07
Iter: 1386 loss: 6.71466864e-07
Iter: 1387 loss: 6.70828626e-07
Iter: 1388 loss: 6.74895318e-07
Iter: 1389 loss: 6.70743361e-07
Iter: 1390 loss: 6.70205e-07
Iter: 1391 loss: 6.72844067e-07
Iter: 1392 loss: 6.7010285e-07
Iter: 1393 loss: 6.69540896e-07
Iter: 1394 loss: 6.69705742e-07
Iter: 1395 loss: 6.69126393e-07
Iter: 1396 loss: 6.68552332e-07
Iter: 1397 loss: 6.74338196e-07
Iter: 1398 loss: 6.68529083e-07
Iter: 1399 loss: 6.68062341e-07
Iter: 1400 loss: 6.67994755e-07
Iter: 1401 loss: 6.67737538e-07
Iter: 1402 loss: 6.67074914e-07
Iter: 1403 loss: 6.68023915e-07
Iter: 1404 loss: 6.66754659e-07
Iter: 1405 loss: 6.66216636e-07
Iter: 1406 loss: 6.73419663e-07
Iter: 1407 loss: 6.6621368e-07
Iter: 1408 loss: 6.65801053e-07
Iter: 1409 loss: 6.66663141e-07
Iter: 1410 loss: 6.65649566e-07
Iter: 1411 loss: 6.65161565e-07
Iter: 1412 loss: 6.64789468e-07
Iter: 1413 loss: 6.64626441e-07
Iter: 1414 loss: 6.64277479e-07
Iter: 1415 loss: 6.6420273e-07
Iter: 1416 loss: 6.63925562e-07
Iter: 1417 loss: 6.63594619e-07
Iter: 1418 loss: 6.6358848e-07
Iter: 1419 loss: 6.63018e-07
Iter: 1420 loss: 6.62361685e-07
Iter: 1421 loss: 6.62291882e-07
Iter: 1422 loss: 6.61440083e-07
Iter: 1423 loss: 6.6862134e-07
Iter: 1424 loss: 6.61403135e-07
Iter: 1425 loss: 6.60868523e-07
Iter: 1426 loss: 6.64285608e-07
Iter: 1427 loss: 6.60798833e-07
Iter: 1428 loss: 6.60311628e-07
Iter: 1429 loss: 6.60825208e-07
Iter: 1430 loss: 6.60047e-07
Iter: 1431 loss: 6.59387695e-07
Iter: 1432 loss: 6.62759476e-07
Iter: 1433 loss: 6.5926406e-07
Iter: 1434 loss: 6.58829833e-07
Iter: 1435 loss: 6.59396846e-07
Iter: 1436 loss: 6.58600243e-07
Iter: 1437 loss: 6.58053409e-07
Iter: 1438 loss: 6.59933278e-07
Iter: 1439 loss: 6.57997703e-07
Iter: 1440 loss: 6.57463602e-07
Iter: 1441 loss: 6.57792782e-07
Iter: 1442 loss: 6.57161422e-07
Iter: 1443 loss: 6.5658196e-07
Iter: 1444 loss: 6.60285536e-07
Iter: 1445 loss: 6.565e-07
Iter: 1446 loss: 6.56062639e-07
Iter: 1447 loss: 6.58631507e-07
Iter: 1448 loss: 6.56003067e-07
Iter: 1449 loss: 6.556578e-07
Iter: 1450 loss: 6.55212716e-07
Iter: 1451 loss: 6.55169686e-07
Iter: 1452 loss: 6.54526502e-07
Iter: 1453 loss: 6.63453079e-07
Iter: 1454 loss: 6.54533551e-07
Iter: 1455 loss: 6.54277926e-07
Iter: 1456 loss: 6.53636789e-07
Iter: 1457 loss: 6.59818966e-07
Iter: 1458 loss: 6.53557549e-07
Iter: 1459 loss: 6.52729341e-07
Iter: 1460 loss: 6.57241173e-07
Iter: 1461 loss: 6.52574386e-07
Iter: 1462 loss: 6.51910852e-07
Iter: 1463 loss: 6.54810378e-07
Iter: 1464 loss: 6.51795119e-07
Iter: 1465 loss: 6.51228e-07
Iter: 1466 loss: 6.53327334e-07
Iter: 1467 loss: 6.51119876e-07
Iter: 1468 loss: 6.50565937e-07
Iter: 1469 loss: 6.52660901e-07
Iter: 1470 loss: 6.50474931e-07
Iter: 1471 loss: 6.4994e-07
Iter: 1472 loss: 6.50132733e-07
Iter: 1473 loss: 6.49525759e-07
Iter: 1474 loss: 6.4900496e-07
Iter: 1475 loss: 6.53271286e-07
Iter: 1476 loss: 6.48986145e-07
Iter: 1477 loss: 6.48559649e-07
Iter: 1478 loss: 6.48747232e-07
Iter: 1479 loss: 6.48304194e-07
Iter: 1480 loss: 6.47799e-07
Iter: 1481 loss: 6.50148195e-07
Iter: 1482 loss: 6.47687102e-07
Iter: 1483 loss: 6.47141803e-07
Iter: 1484 loss: 6.48412424e-07
Iter: 1485 loss: 6.4701436e-07
Iter: 1486 loss: 6.46418e-07
Iter: 1487 loss: 6.4865975e-07
Iter: 1488 loss: 6.46305693e-07
Iter: 1489 loss: 6.45842874e-07
Iter: 1490 loss: 6.48053515e-07
Iter: 1491 loss: 6.45814566e-07
Iter: 1492 loss: 6.45419391e-07
Iter: 1493 loss: 6.46102649e-07
Iter: 1494 loss: 6.45217085e-07
Iter: 1495 loss: 6.44829868e-07
Iter: 1496 loss: 6.44063675e-07
Iter: 1497 loss: 6.58824831e-07
Iter: 1498 loss: 6.4405009e-07
Iter: 1499 loss: 6.43337216e-07
Iter: 1500 loss: 6.53389748e-07
Iter: 1501 loss: 6.43341764e-07
Iter: 1502 loss: 6.42892871e-07
Iter: 1503 loss: 6.42859277e-07
Iter: 1504 loss: 6.42478312e-07
Iter: 1505 loss: 6.4189453e-07
Iter: 1506 loss: 6.46428816e-07
Iter: 1507 loss: 6.418677e-07
Iter: 1508 loss: 6.4141625e-07
Iter: 1509 loss: 6.45074351e-07
Iter: 1510 loss: 6.41388169e-07
Iter: 1511 loss: 6.40985377e-07
Iter: 1512 loss: 6.40630333e-07
Iter: 1513 loss: 6.40564508e-07
Iter: 1514 loss: 6.39975951e-07
Iter: 1515 loss: 6.42630653e-07
Iter: 1516 loss: 6.39854136e-07
Iter: 1517 loss: 6.39309633e-07
Iter: 1518 loss: 6.41025792e-07
Iter: 1519 loss: 6.39079644e-07
Iter: 1520 loss: 6.3864934e-07
Iter: 1521 loss: 6.40562575e-07
Iter: 1522 loss: 6.38509164e-07
Iter: 1523 loss: 6.38068514e-07
Iter: 1524 loss: 6.4043104e-07
Iter: 1525 loss: 6.37985352e-07
Iter: 1526 loss: 6.37651851e-07
Iter: 1527 loss: 6.38899905e-07
Iter: 1528 loss: 6.37569087e-07
Iter: 1529 loss: 6.37231494e-07
Iter: 1530 loss: 6.37504854e-07
Iter: 1531 loss: 6.37056473e-07
Iter: 1532 loss: 6.3657194e-07
Iter: 1533 loss: 6.36999061e-07
Iter: 1534 loss: 6.36356731e-07
Iter: 1535 loss: 6.35872198e-07
Iter: 1536 loss: 6.3666522e-07
Iter: 1537 loss: 6.3558673e-07
Iter: 1538 loss: 6.3494997e-07
Iter: 1539 loss: 6.35111064e-07
Iter: 1540 loss: 6.34519324e-07
Iter: 1541 loss: 6.33825e-07
Iter: 1542 loss: 6.3903417e-07
Iter: 1543 loss: 6.33753e-07
Iter: 1544 loss: 6.33182822e-07
Iter: 1545 loss: 6.34602316e-07
Iter: 1546 loss: 6.32974889e-07
Iter: 1547 loss: 6.32494334e-07
Iter: 1548 loss: 6.37685503e-07
Iter: 1549 loss: 6.32454544e-07
Iter: 1550 loss: 6.32107458e-07
Iter: 1551 loss: 6.32155434e-07
Iter: 1552 loss: 6.31842056e-07
Iter: 1553 loss: 6.31350417e-07
Iter: 1554 loss: 6.31561477e-07
Iter: 1555 loss: 6.30998e-07
Iter: 1556 loss: 6.30429099e-07
Iter: 1557 loss: 6.36672667e-07
Iter: 1558 loss: 6.3040352e-07
Iter: 1559 loss: 6.29998908e-07
Iter: 1560 loss: 6.31507305e-07
Iter: 1561 loss: 6.29875331e-07
Iter: 1562 loss: 6.29577e-07
Iter: 1563 loss: 6.30650334e-07
Iter: 1564 loss: 6.29422971e-07
Iter: 1565 loss: 6.29041438e-07
Iter: 1566 loss: 6.29478109e-07
Iter: 1567 loss: 6.28819407e-07
Iter: 1568 loss: 6.28400471e-07
Iter: 1569 loss: 6.30199224e-07
Iter: 1570 loss: 6.28347664e-07
Iter: 1571 loss: 6.27967097e-07
Iter: 1572 loss: 6.27744953e-07
Iter: 1573 loss: 6.276249e-07
Iter: 1574 loss: 6.26991437e-07
Iter: 1575 loss: 6.28080784e-07
Iter: 1576 loss: 6.26751216e-07
Iter: 1577 loss: 6.26219901e-07
Iter: 1578 loss: 6.285984e-07
Iter: 1579 loss: 6.26109e-07
Iter: 1580 loss: 6.25582402e-07
Iter: 1581 loss: 6.26523217e-07
Iter: 1582 loss: 6.25336384e-07
Iter: 1583 loss: 6.24830363e-07
Iter: 1584 loss: 6.28807584e-07
Iter: 1585 loss: 6.24777613e-07
Iter: 1586 loss: 6.24387667e-07
Iter: 1587 loss: 6.26057385e-07
Iter: 1588 loss: 6.24307063e-07
Iter: 1589 loss: 6.2388807e-07
Iter: 1590 loss: 6.23473852e-07
Iter: 1591 loss: 6.23404162e-07
Iter: 1592 loss: 6.22921789e-07
Iter: 1593 loss: 6.27119732e-07
Iter: 1594 loss: 6.22915422e-07
Iter: 1595 loss: 6.22546395e-07
Iter: 1596 loss: 6.24584686e-07
Iter: 1597 loss: 6.22521213e-07
Iter: 1598 loss: 6.22141215e-07
Iter: 1599 loss: 6.21897925e-07
Iter: 1600 loss: 6.21697893e-07
Iter: 1601 loss: 6.21252298e-07
Iter: 1602 loss: 6.26656515e-07
Iter: 1603 loss: 6.21262643e-07
Iter: 1604 loss: 6.20965352e-07
Iter: 1605 loss: 6.20616788e-07
Iter: 1606 loss: 6.20580863e-07
Iter: 1607 loss: 6.20000719e-07
Iter: 1608 loss: 6.21928223e-07
Iter: 1609 loss: 6.198e-07
Iter: 1610 loss: 6.19388572e-07
Iter: 1611 loss: 6.21218362e-07
Iter: 1612 loss: 6.19243e-07
Iter: 1613 loss: 6.18812521e-07
Iter: 1614 loss: 6.18674449e-07
Iter: 1615 loss: 6.18379772e-07
Iter: 1616 loss: 6.17827311e-07
Iter: 1617 loss: 6.19221737e-07
Iter: 1618 loss: 6.17619037e-07
Iter: 1619 loss: 6.17029514e-07
Iter: 1620 loss: 6.2198086e-07
Iter: 1621 loss: 6.17025933e-07
Iter: 1622 loss: 6.16637521e-07
Iter: 1623 loss: 6.18603053e-07
Iter: 1624 loss: 6.1657488e-07
Iter: 1625 loss: 6.1613116e-07
Iter: 1626 loss: 6.16240868e-07
Iter: 1627 loss: 6.15840804e-07
Iter: 1628 loss: 6.15374915e-07
Iter: 1629 loss: 6.16752743e-07
Iter: 1630 loss: 6.15223371e-07
Iter: 1631 loss: 6.1490897e-07
Iter: 1632 loss: 6.19069453e-07
Iter: 1633 loss: 6.14934152e-07
Iter: 1634 loss: 6.14637599e-07
Iter: 1635 loss: 6.14658461e-07
Iter: 1636 loss: 6.14380951e-07
Iter: 1637 loss: 6.13964403e-07
Iter: 1638 loss: 6.15244062e-07
Iter: 1639 loss: 6.13851171e-07
Iter: 1640 loss: 6.13417797e-07
Iter: 1641 loss: 6.14294606e-07
Iter: 1642 loss: 6.13261818e-07
Iter: 1643 loss: 6.12925191e-07
Iter: 1644 loss: 6.13741122e-07
Iter: 1645 loss: 6.12735107e-07
Iter: 1646 loss: 6.12335384e-07
Iter: 1647 loss: 6.12496137e-07
Iter: 1648 loss: 6.12038264e-07
Iter: 1649 loss: 6.11553389e-07
Iter: 1650 loss: 6.14581495e-07
Iter: 1651 loss: 6.11492794e-07
Iter: 1652 loss: 6.1105419e-07
Iter: 1653 loss: 6.11234327e-07
Iter: 1654 loss: 6.10741267e-07
Iter: 1655 loss: 6.10272934e-07
Iter: 1656 loss: 6.11094151e-07
Iter: 1657 loss: 6.10071766e-07
Iter: 1658 loss: 6.09525955e-07
Iter: 1659 loss: 6.1204986e-07
Iter: 1660 loss: 6.09444555e-07
Iter: 1661 loss: 6.08917048e-07
Iter: 1662 loss: 6.12626081e-07
Iter: 1663 loss: 6.08898233e-07
Iter: 1664 loss: 6.08580422e-07
Iter: 1665 loss: 6.08351797e-07
Iter: 1666 loss: 6.08237542e-07
Iter: 1667 loss: 6.07899324e-07
Iter: 1668 loss: 6.12630231e-07
Iter: 1669 loss: 6.07916547e-07
Iter: 1670 loss: 6.07547634e-07
Iter: 1671 loss: 6.07887785e-07
Iter: 1672 loss: 6.07359198e-07
Iter: 1673 loss: 6.07087145e-07
Iter: 1674 loss: 6.08465314e-07
Iter: 1675 loss: 6.07022173e-07
Iter: 1676 loss: 6.06682192e-07
Iter: 1677 loss: 6.06714934e-07
Iter: 1678 loss: 6.06483127e-07
Iter: 1679 loss: 6.06011042e-07
Iter: 1680 loss: 6.07048719e-07
Iter: 1681 loss: 6.05851653e-07
Iter: 1682 loss: 6.05455057e-07
Iter: 1683 loss: 6.06302706e-07
Iter: 1684 loss: 6.05329717e-07
Iter: 1685 loss: 6.04928232e-07
Iter: 1686 loss: 6.06097956e-07
Iter: 1687 loss: 6.04789079e-07
Iter: 1688 loss: 6.04327283e-07
Iter: 1689 loss: 6.05030323e-07
Iter: 1690 loss: 6.0408388e-07
Iter: 1691 loss: 6.03566434e-07
Iter: 1692 loss: 6.0493312e-07
Iter: 1693 loss: 6.03345711e-07
Iter: 1694 loss: 6.02845944e-07
Iter: 1695 loss: 6.04240086e-07
Iter: 1696 loss: 6.02721911e-07
Iter: 1697 loss: 6.02275463e-07
Iter: 1698 loss: 6.05475464e-07
Iter: 1699 loss: 6.02262276e-07
Iter: 1700 loss: 6.01824581e-07
Iter: 1701 loss: 6.02426e-07
Iter: 1702 loss: 6.01593797e-07
Iter: 1703 loss: 6.01242505e-07
Iter: 1704 loss: 6.02065711e-07
Iter: 1705 loss: 6.0115218e-07
Iter: 1706 loss: 6.00722103e-07
Iter: 1707 loss: 6.04771742e-07
Iter: 1708 loss: 6.00676913e-07
Iter: 1709 loss: 6.00434078e-07
Iter: 1710 loss: 6.0024513e-07
Iter: 1711 loss: 6.0011962e-07
Iter: 1712 loss: 5.99794816e-07
Iter: 1713 loss: 6.0217036e-07
Iter: 1714 loss: 5.99770772e-07
Iter: 1715 loss: 5.99494342e-07
Iter: 1716 loss: 5.99732573e-07
Iter: 1717 loss: 5.99295049e-07
Iter: 1718 loss: 5.98848032e-07
Iter: 1719 loss: 5.98733891e-07
Iter: 1720 loss: 5.98429779e-07
Iter: 1721 loss: 5.97962412e-07
Iter: 1722 loss: 6.01526779e-07
Iter: 1723 loss: 5.97953147e-07
Iter: 1724 loss: 5.97546034e-07
Iter: 1725 loss: 5.98302336e-07
Iter: 1726 loss: 5.97379881e-07
Iter: 1727 loss: 5.96900122e-07
Iter: 1728 loss: 5.97683425e-07
Iter: 1729 loss: 5.96695145e-07
Iter: 1730 loss: 5.96239261e-07
Iter: 1731 loss: 5.97484e-07
Iter: 1732 loss: 5.96076234e-07
Iter: 1733 loss: 5.95652409e-07
Iter: 1734 loss: 5.97826215e-07
Iter: 1735 loss: 5.95585959e-07
Iter: 1736 loss: 5.95229267e-07
Iter: 1737 loss: 5.9710942e-07
Iter: 1738 loss: 5.95194479e-07
Iter: 1739 loss: 5.94835512e-07
Iter: 1740 loss: 5.94836706e-07
Iter: 1741 loss: 5.94605467e-07
Iter: 1742 loss: 5.94169819e-07
Iter: 1743 loss: 5.97904318e-07
Iter: 1744 loss: 5.94155608e-07
Iter: 1745 loss: 5.93786467e-07
Iter: 1746 loss: 5.94447556e-07
Iter: 1747 loss: 5.93624748e-07
Iter: 1748 loss: 5.93318816e-07
Iter: 1749 loss: 5.93672326e-07
Iter: 1750 loss: 5.93193477e-07
Iter: 1751 loss: 5.92825927e-07
Iter: 1752 loss: 5.93655045e-07
Iter: 1753 loss: 5.92745e-07
Iter: 1754 loss: 5.92295464e-07
Iter: 1755 loss: 5.93528512e-07
Iter: 1756 loss: 5.92167453e-07
Iter: 1757 loss: 5.91888409e-07
Iter: 1758 loss: 5.9176034e-07
Iter: 1759 loss: 5.91551327e-07
Iter: 1760 loss: 5.91137791e-07
Iter: 1761 loss: 5.92333038e-07
Iter: 1762 loss: 5.90996137e-07
Iter: 1763 loss: 5.90578452e-07
Iter: 1764 loss: 5.94159701e-07
Iter: 1765 loss: 5.90552418e-07
Iter: 1766 loss: 5.90175432e-07
Iter: 1767 loss: 5.90272862e-07
Iter: 1768 loss: 5.89914691e-07
Iter: 1769 loss: 5.89522415e-07
Iter: 1770 loss: 5.91687694e-07
Iter: 1771 loss: 5.89472847e-07
Iter: 1772 loss: 5.89068236e-07
Iter: 1773 loss: 5.90909622e-07
Iter: 1774 loss: 5.88999399e-07
Iter: 1775 loss: 5.8863975e-07
Iter: 1776 loss: 5.88667547e-07
Iter: 1777 loss: 5.88382704e-07
Iter: 1778 loss: 5.88030161e-07
Iter: 1779 loss: 5.88016235e-07
Iter: 1780 loss: 5.87768454e-07
Iter: 1781 loss: 5.87928923e-07
Iter: 1782 loss: 5.87645502e-07
Iter: 1783 loss: 5.87385443e-07
Iter: 1784 loss: 5.87239128e-07
Iter: 1785 loss: 5.87147554e-07
Iter: 1786 loss: 5.86711735e-07
Iter: 1787 loss: 5.89434308e-07
Iter: 1788 loss: 5.86650913e-07
Iter: 1789 loss: 5.86349074e-07
Iter: 1790 loss: 5.87978832e-07
Iter: 1791 loss: 5.86304736e-07
Iter: 1792 loss: 5.86022736e-07
Iter: 1793 loss: 5.85439238e-07
Iter: 1794 loss: 5.96427924e-07
Iter: 1795 loss: 5.85430598e-07
Iter: 1796 loss: 5.84937311e-07
Iter: 1797 loss: 5.89519288e-07
Iter: 1798 loss: 5.84905251e-07
Iter: 1799 loss: 5.8445994e-07
Iter: 1800 loss: 5.86106694e-07
Iter: 1801 loss: 5.84343468e-07
Iter: 1802 loss: 5.83934934e-07
Iter: 1803 loss: 5.8504952e-07
Iter: 1804 loss: 5.83829149e-07
Iter: 1805 loss: 5.83454039e-07
Iter: 1806 loss: 5.84518602e-07
Iter: 1807 loss: 5.8330113e-07
Iter: 1808 loss: 5.82912605e-07
Iter: 1809 loss: 5.84313284e-07
Iter: 1810 loss: 5.82796474e-07
Iter: 1811 loss: 5.82362645e-07
Iter: 1812 loss: 5.84030772e-07
Iter: 1813 loss: 5.82284031e-07
Iter: 1814 loss: 5.81987592e-07
Iter: 1815 loss: 5.83397593e-07
Iter: 1816 loss: 5.81964684e-07
Iter: 1817 loss: 5.81622828e-07
Iter: 1818 loss: 5.81565246e-07
Iter: 1819 loss: 5.81341737e-07
Iter: 1820 loss: 5.80946789e-07
Iter: 1821 loss: 5.81425866e-07
Iter: 1822 loss: 5.80757e-07
Iter: 1823 loss: 5.80383e-07
Iter: 1824 loss: 5.83516908e-07
Iter: 1825 loss: 5.80384778e-07
Iter: 1826 loss: 5.80067478e-07
Iter: 1827 loss: 5.80471692e-07
Iter: 1828 loss: 5.79914968e-07
Iter: 1829 loss: 5.79539119e-07
Iter: 1830 loss: 5.79782409e-07
Iter: 1831 loss: 5.79294067e-07
Iter: 1832 loss: 5.78872744e-07
Iter: 1833 loss: 5.8065217e-07
Iter: 1834 loss: 5.78783443e-07
Iter: 1835 loss: 5.78433969e-07
Iter: 1836 loss: 5.79007803e-07
Iter: 1837 loss: 5.78255595e-07
Iter: 1838 loss: 5.77815968e-07
Iter: 1839 loss: 5.7862178e-07
Iter: 1840 loss: 5.77615367e-07
Iter: 1841 loss: 5.77225819e-07
Iter: 1842 loss: 5.8122464e-07
Iter: 1843 loss: 5.77214394e-07
Iter: 1844 loss: 5.76873049e-07
Iter: 1845 loss: 5.76821662e-07
Iter: 1846 loss: 5.76610432e-07
Iter: 1847 loss: 5.76205252e-07
Iter: 1848 loss: 5.81426e-07
Iter: 1849 loss: 5.76192576e-07
Iter: 1850 loss: 5.75977253e-07
Iter: 1851 loss: 5.76313e-07
Iter: 1852 loss: 5.7582406e-07
Iter: 1853 loss: 5.75529668e-07
Iter: 1854 loss: 5.76567743e-07
Iter: 1855 loss: 5.75496642e-07
Iter: 1856 loss: 5.75187926e-07
Iter: 1857 loss: 5.74753244e-07
Iter: 1858 loss: 5.7474324e-07
Iter: 1859 loss: 5.74193791e-07
Iter: 1860 loss: 5.77452113e-07
Iter: 1861 loss: 5.74131491e-07
Iter: 1862 loss: 5.73743932e-07
Iter: 1863 loss: 5.77149649e-07
Iter: 1864 loss: 5.73744671e-07
Iter: 1865 loss: 5.73402133e-07
Iter: 1866 loss: 5.73121554e-07
Iter: 1867 loss: 5.73041348e-07
Iter: 1868 loss: 5.72567956e-07
Iter: 1869 loss: 5.74350963e-07
Iter: 1870 loss: 5.72503609e-07
Iter: 1871 loss: 5.72108661e-07
Iter: 1872 loss: 5.72963643e-07
Iter: 1873 loss: 5.71928e-07
Iter: 1874 loss: 5.71462465e-07
Iter: 1875 loss: 5.72392878e-07
Iter: 1876 loss: 5.71286e-07
Iter: 1877 loss: 5.70858049e-07
Iter: 1878 loss: 5.74414457e-07
Iter: 1879 loss: 5.70835141e-07
Iter: 1880 loss: 5.70542056e-07
Iter: 1881 loss: 5.71481337e-07
Iter: 1882 loss: 5.70481461e-07
Iter: 1883 loss: 5.70155294e-07
Iter: 1884 loss: 5.70541829e-07
Iter: 1885 loss: 5.69935651e-07
Iter: 1886 loss: 5.69567192e-07
Iter: 1887 loss: 5.7171917e-07
Iter: 1888 loss: 5.69502049e-07
Iter: 1889 loss: 5.6921067e-07
Iter: 1890 loss: 5.69832878e-07
Iter: 1891 loss: 5.69070266e-07
Iter: 1892 loss: 5.68716928e-07
Iter: 1893 loss: 5.6909812e-07
Iter: 1894 loss: 5.68516668e-07
Iter: 1895 loss: 5.6812587e-07
Iter: 1896 loss: 5.69042641e-07
Iter: 1897 loss: 5.68015707e-07
Iter: 1898 loss: 5.67671691e-07
Iter: 1899 loss: 5.67810616e-07
Iter: 1900 loss: 5.67480413e-07
Iter: 1901 loss: 5.67012307e-07
Iter: 1902 loss: 5.70781879e-07
Iter: 1903 loss: 5.66970073e-07
Iter: 1904 loss: 5.66641518e-07
Iter: 1905 loss: 5.66915219e-07
Iter: 1906 loss: 5.66466781e-07
Iter: 1907 loss: 5.66072629e-07
Iter: 1908 loss: 5.66922893e-07
Iter: 1909 loss: 5.6593592e-07
Iter: 1910 loss: 5.65614528e-07
Iter: 1911 loss: 5.65693199e-07
Iter: 1912 loss: 5.65381811e-07
Iter: 1913 loss: 5.64879031e-07
Iter: 1914 loss: 5.66637198e-07
Iter: 1915 loss: 5.64774609e-07
Iter: 1916 loss: 5.64380798e-07
Iter: 1917 loss: 5.69202086e-07
Iter: 1918 loss: 5.64361699e-07
Iter: 1919 loss: 5.64095103e-07
Iter: 1920 loss: 5.64489e-07
Iter: 1921 loss: 5.6396e-07
Iter: 1922 loss: 5.63598064e-07
Iter: 1923 loss: 5.65148753e-07
Iter: 1924 loss: 5.635099e-07
Iter: 1925 loss: 5.63247568e-07
Iter: 1926 loss: 5.63872163e-07
Iter: 1927 loss: 5.6310023e-07
Iter: 1928 loss: 5.62786681e-07
Iter: 1929 loss: 5.6295778e-07
Iter: 1930 loss: 5.62625132e-07
Iter: 1931 loss: 5.62232856e-07
Iter: 1932 loss: 5.63225512e-07
Iter: 1933 loss: 5.62083187e-07
Iter: 1934 loss: 5.61715069e-07
Iter: 1935 loss: 5.62975799e-07
Iter: 1936 loss: 5.61637762e-07
Iter: 1937 loss: 5.61319666e-07
Iter: 1938 loss: 5.62012133e-07
Iter: 1939 loss: 5.61186141e-07
Iter: 1940 loss: 5.60840874e-07
Iter: 1941 loss: 5.62665548e-07
Iter: 1942 loss: 5.6078477e-07
Iter: 1943 loss: 5.60448029e-07
Iter: 1944 loss: 5.60009823e-07
Iter: 1945 loss: 5.60000785e-07
Iter: 1946 loss: 5.59485215e-07
Iter: 1947 loss: 5.63384447e-07
Iter: 1948 loss: 5.59411205e-07
Iter: 1949 loss: 5.59054286e-07
Iter: 1950 loss: 5.59539e-07
Iter: 1951 loss: 5.58912234e-07
Iter: 1952 loss: 5.58507054e-07
Iter: 1953 loss: 5.61909701e-07
Iter: 1954 loss: 5.58460727e-07
Iter: 1955 loss: 5.58178556e-07
Iter: 1956 loss: 5.59924217e-07
Iter: 1957 loss: 5.58159172e-07
Iter: 1958 loss: 5.57913211e-07
Iter: 1959 loss: 5.58108411e-07
Iter: 1960 loss: 5.57727617e-07
Iter: 1961 loss: 5.57445958e-07
Iter: 1962 loss: 5.58666898e-07
Iter: 1963 loss: 5.57396675e-07
Iter: 1964 loss: 5.57099838e-07
Iter: 1965 loss: 5.57038902e-07
Iter: 1966 loss: 5.56890882e-07
Iter: 1967 loss: 5.56508724e-07
Iter: 1968 loss: 5.58469083e-07
Iter: 1969 loss: 5.56395889e-07
Iter: 1970 loss: 5.56058524e-07
Iter: 1971 loss: 5.56195687e-07
Iter: 1972 loss: 5.55861277e-07
Iter: 1973 loss: 5.554989e-07
Iter: 1974 loss: 5.58292413e-07
Iter: 1975 loss: 5.55494637e-07
Iter: 1976 loss: 5.55178872e-07
Iter: 1977 loss: 5.55704105e-07
Iter: 1978 loss: 5.55017323e-07
Iter: 1979 loss: 5.54722362e-07
Iter: 1980 loss: 5.55351e-07
Iter: 1981 loss: 5.54594578e-07
Iter: 1982 loss: 5.54241296e-07
Iter: 1983 loss: 5.54505164e-07
Iter: 1984 loss: 5.54049734e-07
Iter: 1985 loss: 5.53633299e-07
Iter: 1986 loss: 5.54998849e-07
Iter: 1987 loss: 5.5354019e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.8
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.8/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.8!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.8!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi3
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi3/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi3!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi3!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-2_phi3/500_500_500_500_1
+ for psi in $PSI
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.4
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.4/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.4!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.4!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.8
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.8/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.8!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.8!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.2
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.2/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.2!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.2!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.6
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.6/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.6!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.6!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.4
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.4/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.4!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.4!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.8
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.8/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.8!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.8!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi3
+ date
Sat Nov  7 16:47:40 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi3/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi3!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi3!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi-1_phi3/500_500_500_500_1
