+ RUN=2
+ export CUDA_VISIBLE_DEVICES=2
+ CUDA_VISIBLE_DEVICES=2
+ LAYERS=300_300_300_1
+ case $RUN in
+ PSI=0
+ OPTIONS='			 --optimizer adam 				 --n_pairs 50000 				 --batch_size 5000 				 --max_epochs 30 				 --learning_rate 0.001 				 --decay_rate 0.8 				 --loss_func weighted_MAPE 
'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output72
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output73
+ for fn in f1
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0 /home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0
+ date
Sat Oct 31 13:56:03 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --function f1 --psi 0 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 30 --learning_rate 0.001 --decay_rate 0.8 --loss_func weighted_MAPE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73104647b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7310465268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7310459c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73104a1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73103801e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731039bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731033b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7310315158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731020cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7310207620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73100e70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73100f3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731030a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73101dd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731004ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731007b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7310079f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72c00d6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73100bc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73100b3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72c00978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72c007a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b87c3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b87f4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b87842f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b87b2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f731012c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b8717268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b8721c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72c0049730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72c00541e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72c003abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b86af6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b8657158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b865fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f72b8607620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.06436856
test_loss: 0.06273008
train_loss: 0.054462194
test_loss: 0.05411133
train_loss: 0.052059136
test_loss: 0.052788068
train_loss: 0.052406568
test_loss: 0.052376453
train_loss: 0.052076302
test_loss: 0.052231032
train_loss: 0.0518391
test_loss: 0.05217499
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fd0f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fc78268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fcaac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fcc4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fbfd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fc0fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fc4a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fc5d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fbd3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fbce620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76eca0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76ebbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76e87598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fb99048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f9fb79a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76e3c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76e4af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76de1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76e08400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76e14e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f76dd48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f504c6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f504c7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f50493840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f504722f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f50435d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f503e17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f50400268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f503ddc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f504ef730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f503841e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f5035ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f5032e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f5034c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f50301b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f5030a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00436083693
Iter: 2 loss: 0.00432762364
Iter: 3 loss: 0.00431449525
Iter: 4 loss: 0.00430043926
Iter: 5 loss: 0.0043293573
Iter: 6 loss: 0.00429480802
Iter: 7 loss: 0.00427000551
Iter: 8 loss: 0.00425629131
Iter: 9 loss: 0.0042456
Iter: 10 loss: 0.00420846557
Iter: 11 loss: 0.00416124938
Iter: 12 loss: 0.00415813364
Iter: 13 loss: 0.00411284901
Iter: 14 loss: 0.00410996843
Iter: 15 loss: 0.00407434627
Iter: 16 loss: 0.00400258321
Iter: 17 loss: 0.00502932444
Iter: 18 loss: 0.00400082115
Iter: 19 loss: 0.00393688679
Iter: 20 loss: 0.00451949425
Iter: 21 loss: 0.00393488351
Iter: 22 loss: 0.00386893749
Iter: 23 loss: 0.00397335552
Iter: 24 loss: 0.00383742363
Iter: 25 loss: 0.00378542766
Iter: 26 loss: 0.00382443
Iter: 27 loss: 0.00375734223
Iter: 28 loss: 0.00369391963
Iter: 29 loss: 0.00462457351
Iter: 30 loss: 0.00369359553
Iter: 31 loss: 0.00363627891
Iter: 32 loss: 0.00361048291
Iter: 33 loss: 0.00358180655
Iter: 34 loss: 0.00346888253
Iter: 35 loss: 0.00344214495
Iter: 36 loss: 0.00338539598
Iter: 37 loss: 0.00322333188
Iter: 38 loss: 0.00322257448
Iter: 39 loss: 0.00310148438
Iter: 40 loss: 0.00306867762
Iter: 41 loss: 0.00300735561
Iter: 42 loss: 0.00289982604
Iter: 43 loss: 0.00487913098
Iter: 44 loss: 0.00289982371
Iter: 45 loss: 0.00280374358
Iter: 46 loss: 0.00313182315
Iter: 47 loss: 0.00278221583
Iter: 48 loss: 0.00270350417
Iter: 49 loss: 0.00296514737
Iter: 50 loss: 0.00267999107
Iter: 51 loss: 0.00262147887
Iter: 52 loss: 0.00276508275
Iter: 53 loss: 0.00260473741
Iter: 54 loss: 0.00252659945
Iter: 55 loss: 0.0025166641
Iter: 56 loss: 0.0024632141
Iter: 57 loss: 0.00264896173
Iter: 58 loss: 0.00245026452
Iter: 59 loss: 0.00242298795
Iter: 60 loss: 0.00249627093
Iter: 61 loss: 0.00241448078
Iter: 62 loss: 0.0023633861
Iter: 63 loss: 0.00304319197
Iter: 64 loss: 0.00235948525
Iter: 65 loss: 0.0023226256
Iter: 66 loss: 0.00234053773
Iter: 67 loss: 0.00229829061
Iter: 68 loss: 0.00225673616
Iter: 69 loss: 0.00259126863
Iter: 70 loss: 0.00225442
Iter: 71 loss: 0.00220917165
Iter: 72 loss: 0.00232085818
Iter: 73 loss: 0.00219101016
Iter: 74 loss: 0.00215326063
Iter: 75 loss: 0.00213719299
Iter: 76 loss: 0.00212198542
Iter: 77 loss: 0.00218411768
Iter: 78 loss: 0.00209442526
Iter: 79 loss: 0.00204042764
Iter: 80 loss: 0.00239955448
Iter: 81 loss: 0.00203610677
Iter: 82 loss: 0.00197898876
Iter: 83 loss: 0.00219290424
Iter: 84 loss: 0.00196687365
Iter: 85 loss: 0.00191820622
Iter: 86 loss: 0.00193180493
Iter: 87 loss: 0.00188575033
Iter: 88 loss: 0.00185575441
Iter: 89 loss: 0.00224173348
Iter: 90 loss: 0.00185381016
Iter: 91 loss: 0.00178286666
Iter: 92 loss: 0.00198606402
Iter: 93 loss: 0.00176382111
Iter: 94 loss: 0.00171639898
Iter: 95 loss: 0.0017189139
Iter: 96 loss: 0.00168112363
Iter: 97 loss: 0.00165312144
Iter: 98 loss: 0.00162425148
Iter: 99 loss: 0.0016192738
Iter: 100 loss: 0.00159734196
Iter: 101 loss: 0.00184962875
Iter: 102 loss: 0.0015970415
Iter: 103 loss: 0.00156391528
Iter: 104 loss: 0.00195545331
Iter: 105 loss: 0.00156295276
Iter: 106 loss: 0.00153606781
Iter: 107 loss: 0.00150950858
Iter: 108 loss: 0.00150421169
Iter: 109 loss: 0.0014800292
Iter: 110 loss: 0.00147627888
Iter: 111 loss: 0.00145781296
Iter: 112 loss: 0.00156977389
Iter: 113 loss: 0.00145570724
Iter: 114 loss: 0.00143833668
Iter: 115 loss: 0.00147772161
Iter: 116 loss: 0.0014310563
Iter: 117 loss: 0.0014079602
Iter: 118 loss: 0.00140805217
Iter: 119 loss: 0.00139005668
Iter: 120 loss: 0.00136328593
Iter: 121 loss: 0.00164437923
Iter: 122 loss: 0.00136232481
Iter: 123 loss: 0.00134529057
Iter: 124 loss: 0.0013508664
Iter: 125 loss: 0.00133330934
Iter: 126 loss: 0.00130530645
Iter: 127 loss: 0.00137464236
Iter: 128 loss: 0.00129549205
Iter: 129 loss: 0.00126998534
Iter: 130 loss: 0.00129407307
Iter: 131 loss: 0.00125494052
Iter: 132 loss: 0.00122014643
Iter: 133 loss: 0.00144787715
Iter: 134 loss: 0.00121611659
Iter: 135 loss: 0.0011796843
Iter: 136 loss: 0.00140163046
Iter: 137 loss: 0.0011755689
Iter: 138 loss: 0.00113975629
Iter: 139 loss: 0.00144528248
Iter: 140 loss: 0.00113774405
Iter: 141 loss: 0.00112147641
Iter: 142 loss: 0.00113460887
Iter: 143 loss: 0.00111147831
Iter: 144 loss: 0.00109209376
Iter: 145 loss: 0.00123453536
Iter: 146 loss: 0.00109068397
Iter: 147 loss: 0.00107239804
Iter: 148 loss: 0.00117151416
Iter: 149 loss: 0.00106957532
Iter: 150 loss: 0.00105257984
Iter: 151 loss: 0.00106717413
Iter: 152 loss: 0.00104234554
Iter: 153 loss: 0.00102762342
Iter: 154 loss: 0.00112634921
Iter: 155 loss: 0.00102610723
Iter: 156 loss: 0.00101809669
Iter: 157 loss: 0.00113009731
Iter: 158 loss: 0.00101807248
Iter: 159 loss: 0.00100953318
Iter: 160 loss: 0.00100854947
Iter: 161 loss: 0.00100238202
Iter: 162 loss: 0.000991831534
Iter: 163 loss: 0.00100430252
Iter: 164 loss: 0.000986120082
Iter: 165 loss: 0.000975672971
Iter: 166 loss: 0.000962693943
Iter: 167 loss: 0.000961457088
Iter: 168 loss: 0.000940557511
Iter: 169 loss: 0.00100190029
Iter: 170 loss: 0.000933978823
Iter: 171 loss: 0.000912094256
Iter: 172 loss: 0.000891750678
Iter: 173 loss: 0.000886263966
Iter: 174 loss: 0.000858264859
Iter: 175 loss: 0.000857872888
Iter: 176 loss: 0.00083836884
Iter: 177 loss: 0.00125338882
Iter: 178 loss: 0.000838368549
Iter: 179 loss: 0.000817712862
Iter: 180 loss: 0.000823922106
Iter: 181 loss: 0.000803279167
Iter: 182 loss: 0.000779367518
Iter: 183 loss: 0.000779236085
Iter: 184 loss: 0.000754912384
Iter: 185 loss: 0.000928962196
Iter: 186 loss: 0.000753169646
Iter: 187 loss: 0.000735839596
Iter: 188 loss: 0.0008946202
Iter: 189 loss: 0.000734851114
Iter: 190 loss: 0.000716167851
Iter: 191 loss: 0.000760531868
Iter: 192 loss: 0.000707485946
Iter: 193 loss: 0.000689919572
Iter: 194 loss: 0.000689788081
Iter: 195 loss: 0.000681183825
Iter: 196 loss: 0.000675352174
Iter: 197 loss: 0.00065483636
Iter: 198 loss: 0.00113685755
Iter: 199 loss: 0.000654640316
Iter: 200 loss: 0.000636059325
Iter: 201 loss: 0.000718791212
Iter: 202 loss: 0.000632585958
Iter: 203 loss: 0.000612984644
Iter: 204 loss: 0.000982275349
Iter: 205 loss: 0.000612050178
Iter: 206 loss: 0.000591080694
Iter: 207 loss: 0.000645920052
Iter: 208 loss: 0.000582970097
Iter: 209 loss: 0.000549777702
Iter: 210 loss: 0.000658298
Iter: 211 loss: 0.000541591435
Iter: 212 loss: 0.00052039529
Iter: 213 loss: 0.000520326896
Iter: 214 loss: 0.000504653493
Iter: 215 loss: 0.000514999265
Iter: 216 loss: 0.000494834327
Iter: 217 loss: 0.000583220739
Iter: 218 loss: 0.000481305789
Iter: 219 loss: 0.000496225315
Iter: 220 loss: 0.000464719837
Iter: 221 loss: 0.000452470093
Iter: 222 loss: 0.000445500715
Iter: 223 loss: 0.000420210214
Iter: 224 loss: 0.000620983425
Iter: 225 loss: 0.000416576
Iter: 226 loss: 0.000389864319
Iter: 227 loss: 0.000767109625
Iter: 228 loss: 0.000389767607
Iter: 229 loss: 0.000367636443
Iter: 230 loss: 0.00036753685
Iter: 231 loss: 0.00035570786
Iter: 232 loss: 0.000353829615
Iter: 233 loss: 0.000344338885
Iter: 234 loss: 0.000368513342
Iter: 235 loss: 0.000340398925
Iter: 236 loss: 0.000324372202
Iter: 237 loss: 0.000388063665
Iter: 238 loss: 0.000321059139
Iter: 239 loss: 0.000296879502
Iter: 240 loss: 0.000410666282
Iter: 241 loss: 0.000290433527
Iter: 242 loss: 0.000277212705
Iter: 243 loss: 0.000319500745
Iter: 244 loss: 0.000273607264
Iter: 245 loss: 0.000282346591
Iter: 246 loss: 0.000268364267
Iter: 247 loss: 0.000257093896
Iter: 248 loss: 0.000347054302
Iter: 249 loss: 0.000256398984
Iter: 250 loss: 0.0002480619
Iter: 251 loss: 0.000369017274
Iter: 252 loss: 0.000247907126
Iter: 253 loss: 0.000245136413
Iter: 254 loss: 0.000277074
Iter: 255 loss: 0.000245105621
Iter: 256 loss: 0.000243350427
Iter: 257 loss: 0.000244686118
Iter: 258 loss: 0.00024217437
Iter: 259 loss: 0.000236709238
Iter: 260 loss: 0.000245265372
Iter: 261 loss: 0.000234122737
Iter: 262 loss: 0.00022704486
Iter: 263 loss: 0.000241292277
Iter: 264 loss: 0.000224131305
Iter: 265 loss: 0.000215657274
Iter: 266 loss: 0.000210554106
Iter: 267 loss: 0.000207005622
Iter: 268 loss: 0.00020219697
Iter: 269 loss: 0.000220352144
Iter: 270 loss: 0.000201049144
Iter: 271 loss: 0.00019629256
Iter: 272 loss: 0.000232253878
Iter: 273 loss: 0.000195454399
Iter: 274 loss: 0.000190994149
Iter: 275 loss: 0.000202010808
Iter: 276 loss: 0.000189454397
Iter: 277 loss: 0.000185417361
Iter: 278 loss: 0.000179343697
Iter: 279 loss: 0.000179253606
Iter: 280 loss: 0.000173990498
Iter: 281 loss: 0.000195802888
Iter: 282 loss: 0.000172600819
Iter: 283 loss: 0.000171144638
Iter: 284 loss: 0.000169389969
Iter: 285 loss: 0.000169212057
Iter: 286 loss: 0.000161460048
Iter: 287 loss: 0.000416453346
Iter: 288 loss: 0.000161406439
Iter: 289 loss: 0.000151813816
Iter: 290 loss: 0.00026421767
Iter: 291 loss: 0.000151704546
Iter: 292 loss: 0.000149657368
Iter: 293 loss: 0.000162692857
Iter: 294 loss: 0.000149319181
Iter: 295 loss: 0.000145741098
Iter: 296 loss: 0.00013703751
Iter: 297 loss: 0.000240918831
Iter: 298 loss: 0.000136050381
Iter: 299 loss: 0.000129849912
Iter: 300 loss: 0.000128659114
Iter: 301 loss: 0.000123037753
Iter: 302 loss: 0.000148338702
Iter: 303 loss: 0.000121995312
Iter: 304 loss: 0.000116521522
Iter: 305 loss: 0.000115560266
Iter: 306 loss: 0.00011178507
Iter: 307 loss: 0.000105003455
Iter: 308 loss: 0.000116963944
Iter: 309 loss: 0.000102132013
Iter: 310 loss: 9.8977107e-05
Iter: 311 loss: 0.000135459704
Iter: 312 loss: 9.8771874e-05
Iter: 313 loss: 9.64563151e-05
Iter: 314 loss: 0.000108514338
Iter: 315 loss: 9.6091404e-05
Iter: 316 loss: 9.42838888e-05
Iter: 317 loss: 9.27619e-05
Iter: 318 loss: 9.22371109e-05
Iter: 319 loss: 8.91216259e-05
Iter: 320 loss: 0.000129284599
Iter: 321 loss: 8.910201e-05
Iter: 322 loss: 8.40345747e-05
Iter: 323 loss: 0.000105434
Iter: 324 loss: 8.28491611e-05
Iter: 325 loss: 7.81105191e-05
Iter: 326 loss: 0.000125839579
Iter: 327 loss: 7.79543334e-05
Iter: 328 loss: 7.65590812e-05
Iter: 329 loss: 8.72712844e-05
Iter: 330 loss: 7.64791621e-05
Iter: 331 loss: 7.49159954e-05
Iter: 332 loss: 7.51709449e-05
Iter: 333 loss: 7.36869115e-05
Iter: 334 loss: 7.25312857e-05
Iter: 335 loss: 8.46747789e-05
Iter: 336 loss: 7.25287e-05
Iter: 337 loss: 7.19917807e-05
Iter: 338 loss: 7.476061e-05
Iter: 339 loss: 7.19035e-05
Iter: 340 loss: 7.16648792e-05
Iter: 341 loss: 7.11428438e-05
Iter: 342 loss: 7.91146449e-05
Iter: 343 loss: 7.11205648e-05
Iter: 344 loss: 7.02023317e-05
Iter: 345 loss: 7.34219066e-05
Iter: 346 loss: 6.99699885e-05
Iter: 347 loss: 6.89993612e-05
Iter: 348 loss: 7.14752168e-05
Iter: 349 loss: 6.8664478e-05
Iter: 350 loss: 6.72973183e-05
Iter: 351 loss: 6.72717142e-05
Iter: 352 loss: 6.65627158e-05
Iter: 353 loss: 6.77318167e-05
Iter: 354 loss: 6.62353123e-05
Iter: 355 loss: 6.58870267e-05
Iter: 356 loss: 6.59139259e-05
Iter: 357 loss: 6.56159682e-05
Iter: 358 loss: 6.51777e-05
Iter: 359 loss: 6.40494836e-05
Iter: 360 loss: 7.34255445e-05
Iter: 361 loss: 6.38517959e-05
Iter: 362 loss: 6.32459414e-05
Iter: 363 loss: 6.32288793e-05
Iter: 364 loss: 6.29715651e-05
Iter: 365 loss: 6.2940635e-05
Iter: 366 loss: 6.26131659e-05
Iter: 367 loss: 6.46266562e-05
Iter: 368 loss: 6.25615357e-05
Iter: 369 loss: 6.22151929e-05
Iter: 370 loss: 6.23327e-05
Iter: 371 loss: 6.19762723e-05
Iter: 372 loss: 6.16475518e-05
Iter: 373 loss: 6.10537463e-05
Iter: 374 loss: 7.55838e-05
Iter: 375 loss: 6.10534771e-05
Iter: 376 loss: 6.01650609e-05
Iter: 377 loss: 6.01629436e-05
Iter: 378 loss: 5.97289181e-05
Iter: 379 loss: 6.09305207e-05
Iter: 380 loss: 5.95824677e-05
Iter: 381 loss: 5.92535944e-05
Iter: 382 loss: 5.83730143e-05
Iter: 383 loss: 6.3993095e-05
Iter: 384 loss: 5.81625573e-05
Iter: 385 loss: 5.71876953e-05
Iter: 386 loss: 5.95727906e-05
Iter: 387 loss: 5.6841498e-05
Iter: 388 loss: 5.58086031e-05
Iter: 389 loss: 6.40049839e-05
Iter: 390 loss: 5.57312633e-05
Iter: 391 loss: 5.4920838e-05
Iter: 392 loss: 5.63999056e-05
Iter: 393 loss: 5.45690127e-05
Iter: 394 loss: 5.3613021e-05
Iter: 395 loss: 5.2930016e-05
Iter: 396 loss: 5.25961623e-05
Iter: 397 loss: 5.23838971e-05
Iter: 398 loss: 5.20966969e-05
Iter: 399 loss: 5.18063644e-05
Iter: 400 loss: 5.11346152e-05
Iter: 401 loss: 6.01199426e-05
Iter: 402 loss: 5.10867976e-05
Iter: 403 loss: 5.03626325e-05
Iter: 404 loss: 5.00374372e-05
Iter: 405 loss: 4.96773537e-05
Iter: 406 loss: 4.91381215e-05
Iter: 407 loss: 4.90296115e-05
Iter: 408 loss: 4.86688077e-05
Iter: 409 loss: 4.81830357e-05
Iter: 410 loss: 4.93848129e-05
Iter: 411 loss: 4.80149174e-05
Iter: 412 loss: 5.12558363e-05
Iter: 413 loss: 4.78948132e-05
Iter: 414 loss: 4.77365247e-05
Iter: 415 loss: 4.75600682e-05
Iter: 416 loss: 4.75355446e-05
Iter: 417 loss: 4.71665444e-05
Iter: 418 loss: 4.80538292e-05
Iter: 419 loss: 4.70340674e-05
Iter: 420 loss: 4.6880421e-05
Iter: 421 loss: 4.70589803e-05
Iter: 422 loss: 4.67987702e-05
Iter: 423 loss: 4.66395541e-05
Iter: 424 loss: 4.72377724e-05
Iter: 425 loss: 4.66010279e-05
Iter: 426 loss: 4.63884e-05
Iter: 427 loss: 4.6153873e-05
Iter: 428 loss: 4.61199161e-05
Iter: 429 loss: 4.6086534e-05
Iter: 430 loss: 4.60209194e-05
Iter: 431 loss: 4.58765608e-05
Iter: 432 loss: 4.6197667e-05
Iter: 433 loss: 4.5822002e-05
Iter: 434 loss: 4.57441347e-05
Iter: 435 loss: 4.57098504e-05
Iter: 436 loss: 4.56704365e-05
Iter: 437 loss: 4.55685331e-05
Iter: 438 loss: 4.60720476e-05
Iter: 439 loss: 4.55515546e-05
Iter: 440 loss: 4.54875262e-05
Iter: 441 loss: 4.53029825e-05
Iter: 442 loss: 4.61164746e-05
Iter: 443 loss: 4.52335335e-05
Iter: 444 loss: 4.50689549e-05
Iter: 445 loss: 4.55365807e-05
Iter: 446 loss: 4.50164916e-05
Iter: 447 loss: 4.61204e-05
Iter: 448 loss: 4.49584695e-05
Iter: 449 loss: 4.49050131e-05
Iter: 450 loss: 4.48316641e-05
Iter: 451 loss: 4.48284627e-05
Iter: 452 loss: 4.47495331e-05
Iter: 453 loss: 4.45284568e-05
Iter: 454 loss: 4.56663438e-05
Iter: 455 loss: 4.44572652e-05
Iter: 456 loss: 4.40493823e-05
Iter: 457 loss: 4.46617196e-05
Iter: 458 loss: 4.38539828e-05
Iter: 459 loss: 4.35745096e-05
Iter: 460 loss: 4.42478304e-05
Iter: 461 loss: 4.34748872e-05
Iter: 462 loss: 4.31091248e-05
Iter: 463 loss: 4.29362481e-05
Iter: 464 loss: 4.2758249e-05
Iter: 465 loss: 4.26545957e-05
Iter: 466 loss: 4.23910606e-05
Iter: 467 loss: 4.22616395e-05
Iter: 468 loss: 4.23248639e-05
Iter: 469 loss: 4.21737423e-05
Iter: 470 loss: 4.19763819e-05
Iter: 471 loss: 4.19990065e-05
Iter: 472 loss: 4.18236668e-05
Iter: 473 loss: 4.15476316e-05
Iter: 474 loss: 4.13090966e-05
Iter: 475 loss: 4.12356894e-05
Iter: 476 loss: 4.08181513e-05
Iter: 477 loss: 4.06577965e-05
Iter: 478 loss: 4.04311504e-05
Iter: 479 loss: 4.02972946e-05
Iter: 480 loss: 4.02498226e-05
Iter: 481 loss: 4.00395074e-05
Iter: 482 loss: 4.06493309e-05
Iter: 483 loss: 3.99739511e-05
Iter: 484 loss: 3.97448966e-05
Iter: 485 loss: 3.90948735e-05
Iter: 486 loss: 4.22224948e-05
Iter: 487 loss: 3.88686385e-05
Iter: 488 loss: 3.80647616e-05
Iter: 489 loss: 4.70037048e-05
Iter: 490 loss: 3.80482234e-05
Iter: 491 loss: 3.75082091e-05
Iter: 492 loss: 4.00512217e-05
Iter: 493 loss: 3.74103256e-05
Iter: 494 loss: 3.71303831e-05
Iter: 495 loss: 4.03027771e-05
Iter: 496 loss: 3.71252681e-05
Iter: 497 loss: 3.69589688e-05
Iter: 498 loss: 3.88932458e-05
Iter: 499 loss: 3.69563495e-05
Iter: 500 loss: 3.68374094e-05
Iter: 501 loss: 3.71656097e-05
Iter: 502 loss: 3.67983448e-05
Iter: 503 loss: 3.67481334e-05
Iter: 504 loss: 3.66757231e-05
Iter: 505 loss: 3.66738313e-05
Iter: 506 loss: 3.64866391e-05
Iter: 507 loss: 3.90081805e-05
Iter: 508 loss: 3.64858497e-05
Iter: 509 loss: 3.62072897e-05
Iter: 510 loss: 3.97079202e-05
Iter: 511 loss: 3.62049541e-05
Iter: 512 loss: 3.63106337e-05
Iter: 513 loss: 3.61093335e-05
Iter: 514 loss: 3.60396e-05
Iter: 515 loss: 3.59309197e-05
Iter: 516 loss: 3.59297046e-05
Iter: 517 loss: 3.57573808e-05
Iter: 518 loss: 3.57166791e-05
Iter: 519 loss: 3.56057644e-05
Iter: 520 loss: 3.55204102e-05
Iter: 521 loss: 3.53886571e-05
Iter: 522 loss: 3.53869473e-05
Iter: 523 loss: 3.53207288e-05
Iter: 524 loss: 3.52140705e-05
Iter: 525 loss: 3.52133939e-05
Iter: 526 loss: 3.48869835e-05
Iter: 527 loss: 3.5340021e-05
Iter: 528 loss: 3.47267705e-05
Iter: 529 loss: 3.4510791e-05
Iter: 530 loss: 3.44425025e-05
Iter: 531 loss: 3.42723652e-05
Iter: 532 loss: 3.65183769e-05
Iter: 533 loss: 3.42711974e-05
Iter: 534 loss: 3.41408449e-05
Iter: 535 loss: 3.41200066e-05
Iter: 536 loss: 3.40302067e-05
Iter: 537 loss: 3.40715706e-05
Iter: 538 loss: 3.37459278e-05
Iter: 539 loss: 3.35683544e-05
Iter: 540 loss: 3.35672339e-05
Iter: 541 loss: 3.35297882e-05
Iter: 542 loss: 3.37321617e-05
Iter: 543 loss: 3.35242839e-05
Iter: 544 loss: 3.34804754e-05
Iter: 545 loss: 3.33722855e-05
Iter: 546 loss: 3.44120417e-05
Iter: 547 loss: 3.33584576e-05
Iter: 548 loss: 3.33108328e-05
Iter: 549 loss: 3.32672e-05
Iter: 550 loss: 3.32171767e-05
Iter: 551 loss: 3.3990269e-05
Iter: 552 loss: 3.32171185e-05
Iter: 553 loss: 3.31906849e-05
Iter: 554 loss: 3.3103086e-05
Iter: 555 loss: 3.30987968e-05
Iter: 556 loss: 3.30106632e-05
Iter: 557 loss: 3.26041263e-05
Iter: 558 loss: 3.42890635e-05
Iter: 559 loss: 3.25148358e-05
Iter: 560 loss: 3.21304542e-05
Iter: 561 loss: 3.21305924e-05
Iter: 562 loss: 3.18570164e-05
Iter: 563 loss: 3.2209351e-05
Iter: 564 loss: 3.1717107e-05
Iter: 565 loss: 3.15499e-05
Iter: 566 loss: 3.15291327e-05
Iter: 567 loss: 3.14092576e-05
Iter: 568 loss: 3.12705524e-05
Iter: 569 loss: 3.13417295e-05
Iter: 570 loss: 3.11785334e-05
Iter: 571 loss: 3.10282667e-05
Iter: 572 loss: 3.10274954e-05
Iter: 573 loss: 3.08875678e-05
Iter: 574 loss: 3.18677558e-05
Iter: 575 loss: 3.08751914e-05
Iter: 576 loss: 3.07868904e-05
Iter: 577 loss: 3.07836817e-05
Iter: 578 loss: 3.07585615e-05
Iter: 579 loss: 3.08286981e-05
Iter: 580 loss: 3.07505616e-05
Iter: 581 loss: 3.06928487e-05
Iter: 582 loss: 3.06666043e-05
Iter: 583 loss: 3.06377078e-05
Iter: 584 loss: 3.0493351e-05
Iter: 585 loss: 3.05916619e-05
Iter: 586 loss: 3.04064979e-05
Iter: 587 loss: 3.02837489e-05
Iter: 588 loss: 3.01856417e-05
Iter: 589 loss: 3.01485943e-05
Iter: 590 loss: 2.99727708e-05
Iter: 591 loss: 3.00721949e-05
Iter: 592 loss: 2.98578216e-05
Iter: 593 loss: 2.97108581e-05
Iter: 594 loss: 2.97107563e-05
Iter: 595 loss: 2.96294747e-05
Iter: 596 loss: 2.96946455e-05
Iter: 597 loss: 2.95806058e-05
Iter: 598 loss: 2.94335696e-05
Iter: 599 loss: 2.94064084e-05
Iter: 600 loss: 2.93075154e-05
Iter: 601 loss: 2.91693e-05
Iter: 602 loss: 2.88727188e-05
Iter: 603 loss: 3.39358e-05
Iter: 604 loss: 2.88631218e-05
Iter: 605 loss: 2.86246814e-05
Iter: 606 loss: 2.8604265e-05
Iter: 607 loss: 3.0336887e-05
Iter: 608 loss: 2.853962e-05
Iter: 609 loss: 2.85108108e-05
Iter: 610 loss: 2.85705046e-05
Iter: 611 loss: 2.84988382e-05
Iter: 612 loss: 2.84754351e-05
Iter: 613 loss: 2.84063408e-05
Iter: 614 loss: 2.86572413e-05
Iter: 615 loss: 2.83758927e-05
Iter: 616 loss: 2.81964712e-05
Iter: 617 loss: 2.91782744e-05
Iter: 618 loss: 2.81701905e-05
Iter: 619 loss: 2.78629959e-05
Iter: 620 loss: 3.00820575e-05
Iter: 621 loss: 2.78368534e-05
Iter: 622 loss: 2.77363797e-05
Iter: 623 loss: 2.77275831e-05
Iter: 624 loss: 2.76166811e-05
Iter: 625 loss: 2.74428166e-05
Iter: 626 loss: 2.74407648e-05
Iter: 627 loss: 2.7363e-05
Iter: 628 loss: 2.86556278e-05
Iter: 629 loss: 2.73630085e-05
Iter: 630 loss: 2.73386868e-05
Iter: 631 loss: 2.73535225e-05
Iter: 632 loss: 2.73231781e-05
Iter: 633 loss: 2.72748439e-05
Iter: 634 loss: 2.71375156e-05
Iter: 635 loss: 2.77941836e-05
Iter: 636 loss: 2.70898454e-05
Iter: 637 loss: 2.70257988e-05
Iter: 638 loss: 2.69728025e-05
Iter: 639 loss: 2.68575968e-05
Iter: 640 loss: 2.70407727e-05
Iter: 641 loss: 2.68038493e-05
Iter: 642 loss: 2.75403054e-05
Iter: 643 loss: 2.67674131e-05
Iter: 644 loss: 2.67512369e-05
Iter: 645 loss: 2.67021842e-05
Iter: 646 loss: 2.68285658e-05
Iter: 647 loss: 2.66751304e-05
Iter: 648 loss: 2.65684648e-05
Iter: 649 loss: 2.6710306e-05
Iter: 650 loss: 2.65148301e-05
Iter: 651 loss: 2.64614246e-05
Iter: 652 loss: 2.63168749e-05
Iter: 653 loss: 2.71929275e-05
Iter: 654 loss: 2.62786871e-05
Iter: 655 loss: 2.61563473e-05
Iter: 656 loss: 2.6093654e-05
Iter: 657 loss: 2.60364359e-05
Iter: 658 loss: 2.58865439e-05
Iter: 659 loss: 2.60806446e-05
Iter: 660 loss: 2.58041491e-05
Iter: 661 loss: 2.56397198e-05
Iter: 662 loss: 2.62223166e-05
Iter: 663 loss: 2.55968516e-05
Iter: 664 loss: 2.54850893e-05
Iter: 665 loss: 2.53531798e-05
Iter: 666 loss: 2.53392409e-05
Iter: 667 loss: 2.52294267e-05
Iter: 668 loss: 2.52992395e-05
Iter: 669 loss: 2.51606853e-05
Iter: 670 loss: 2.50433295e-05
Iter: 671 loss: 2.49138393e-05
Iter: 672 loss: 2.48948691e-05
Iter: 673 loss: 2.47142125e-05
Iter: 674 loss: 2.68664771e-05
Iter: 675 loss: 2.47112966e-05
Iter: 676 loss: 2.46548025e-05
Iter: 677 loss: 2.463907e-05
Iter: 678 loss: 2.45706215e-05
Iter: 679 loss: 2.47379303e-05
Iter: 680 loss: 2.45463107e-05
Iter: 681 loss: 2.44680032e-05
Iter: 682 loss: 2.5117266e-05
Iter: 683 loss: 2.44632411e-05
Iter: 684 loss: 2.44088478e-05
Iter: 685 loss: 2.43116701e-05
Iter: 686 loss: 2.67344058e-05
Iter: 687 loss: 2.43117356e-05
Iter: 688 loss: 2.42622591e-05
Iter: 689 loss: 2.45213596e-05
Iter: 690 loss: 2.4254301e-05
Iter: 691 loss: 2.42436854e-05
Iter: 692 loss: 2.42091373e-05
Iter: 693 loss: 2.42366332e-05
Iter: 694 loss: 2.41801117e-05
Iter: 695 loss: 2.41086273e-05
Iter: 696 loss: 2.42387432e-05
Iter: 697 loss: 2.40776935e-05
Iter: 698 loss: 2.60079341e-05
Iter: 699 loss: 2.4059249e-05
Iter: 700 loss: 2.40501959e-05
Iter: 701 loss: 2.40451209e-05
Iter: 702 loss: 2.4041361e-05
Iter: 703 loss: 2.404939e-05
Iter: 704 loss: 2.40096015e-05
Iter: 705 loss: 2.39765795e-05
Iter: 706 loss: 2.40018271e-05
Iter: 707 loss: 2.39569035e-05
Iter: 708 loss: 2.39440742e-05
Iter: 709 loss: 2.3920591e-05
Iter: 710 loss: 2.44733237e-05
Iter: 711 loss: 2.39205619e-05
Iter: 712 loss: 2.39035253e-05
Iter: 713 loss: 2.39561268e-05
Iter: 714 loss: 2.38985176e-05
Iter: 715 loss: 2.38661123e-05
Iter: 716 loss: 2.39524597e-05
Iter: 717 loss: 2.38551074e-05
Iter: 718 loss: 2.38454722e-05
Iter: 719 loss: 2.38170978e-05
Iter: 720 loss: 2.37756904e-05
Iter: 721 loss: 2.40130903e-05
Iter: 722 loss: 2.37700951e-05
Iter: 723 loss: 2.3741195e-05
Iter: 724 loss: 2.36771975e-05
Iter: 725 loss: 2.46140844e-05
Iter: 726 loss: 2.36745345e-05
Iter: 727 loss: 2.35941152e-05
Iter: 728 loss: 2.35255702e-05
Iter: 729 loss: 2.35034731e-05
Iter: 730 loss: 2.35231364e-05
Iter: 731 loss: 2.34517338e-05
Iter: 732 loss: 2.34276886e-05
Iter: 733 loss: 2.34771887e-05
Iter: 734 loss: 2.34179952e-05
Iter: 735 loss: 2.34076251e-05
Iter: 736 loss: 2.33916981e-05
Iter: 737 loss: 2.33915925e-05
Iter: 738 loss: 2.33442152e-05
Iter: 739 loss: 2.32545754e-05
Iter: 740 loss: 2.51891579e-05
Iter: 741 loss: 2.32543207e-05
Iter: 742 loss: 2.31690228e-05
Iter: 743 loss: 2.33390656e-05
Iter: 744 loss: 2.31342765e-05
Iter: 745 loss: 2.30369114e-05
Iter: 746 loss: 2.35486841e-05
Iter: 747 loss: 2.30208461e-05
Iter: 748 loss: 2.29314646e-05
Iter: 749 loss: 2.31417216e-05
Iter: 750 loss: 2.28987556e-05
Iter: 751 loss: 2.27999481e-05
Iter: 752 loss: 2.39719593e-05
Iter: 753 loss: 2.27986238e-05
Iter: 754 loss: 2.27390665e-05
Iter: 755 loss: 2.28150584e-05
Iter: 756 loss: 2.27082091e-05
Iter: 757 loss: 2.27100645e-05
Iter: 758 loss: 2.26744105e-05
Iter: 759 loss: 2.26568409e-05
Iter: 760 loss: 2.26393604e-05
Iter: 761 loss: 2.26357624e-05
Iter: 762 loss: 2.26123957e-05
Iter: 763 loss: 2.25618933e-05
Iter: 764 loss: 2.3322893e-05
Iter: 765 loss: 2.25594304e-05
Iter: 766 loss: 2.25451604e-05
Iter: 767 loss: 2.25418426e-05
Iter: 768 loss: 2.25269e-05
Iter: 769 loss: 2.25504064e-05
Iter: 770 loss: 2.2520042e-05
Iter: 771 loss: 2.25005933e-05
Iter: 772 loss: 2.24383111e-05
Iter: 773 loss: 2.24887553e-05
Iter: 774 loss: 2.23863717e-05
Iter: 775 loss: 2.23154311e-05
Iter: 776 loss: 2.23130082e-05
Iter: 777 loss: 2.22928229e-05
Iter: 778 loss: 2.22984054e-05
Iter: 779 loss: 2.22782328e-05
Iter: 780 loss: 2.22415965e-05
Iter: 781 loss: 2.2247601e-05
Iter: 782 loss: 2.22139079e-05
Iter: 783 loss: 2.21845839e-05
Iter: 784 loss: 2.21733935e-05
Iter: 785 loss: 2.2157792e-05
Iter: 786 loss: 2.2098644e-05
Iter: 787 loss: 2.2039836e-05
Iter: 788 loss: 2.20278089e-05
Iter: 789 loss: 2.19735011e-05
Iter: 790 loss: 2.18288842e-05
Iter: 791 loss: 2.28765257e-05
Iter: 792 loss: 2.17968918e-05
Iter: 793 loss: 2.17648412e-05
Iter: 794 loss: 2.1718959e-05
Iter: 795 loss: 2.16978151e-05
Iter: 796 loss: 2.16567241e-05
Iter: 797 loss: 2.2451597e-05
Iter: 798 loss: 2.16562876e-05
Iter: 799 loss: 2.16083972e-05
Iter: 800 loss: 2.18526384e-05
Iter: 801 loss: 2.16007629e-05
Iter: 802 loss: 2.15709824e-05
Iter: 803 loss: 2.16735316e-05
Iter: 804 loss: 2.15629971e-05
Iter: 805 loss: 2.15108412e-05
Iter: 806 loss: 2.14286629e-05
Iter: 807 loss: 2.1427848e-05
Iter: 808 loss: 2.13269377e-05
Iter: 809 loss: 2.26109605e-05
Iter: 810 loss: 2.13263265e-05
Iter: 811 loss: 2.12420182e-05
Iter: 812 loss: 2.13855892e-05
Iter: 813 loss: 2.12045088e-05
Iter: 814 loss: 2.10897597e-05
Iter: 815 loss: 2.11654442e-05
Iter: 816 loss: 2.10180915e-05
Iter: 817 loss: 2.09539066e-05
Iter: 818 loss: 2.08541787e-05
Iter: 819 loss: 2.08529073e-05
Iter: 820 loss: 2.0799298e-05
Iter: 821 loss: 2.0772175e-05
Iter: 822 loss: 2.0732572e-05
Iter: 823 loss: 2.10542e-05
Iter: 824 loss: 2.07301782e-05
Iter: 825 loss: 2.11121496e-05
Iter: 826 loss: 2.07211669e-05
Iter: 827 loss: 2.07160901e-05
Iter: 828 loss: 2.07023222e-05
Iter: 829 loss: 2.07706653e-05
Iter: 830 loss: 2.06978384e-05
Iter: 831 loss: 2.06655131e-05
Iter: 832 loss: 2.05977303e-05
Iter: 833 loss: 2.1722115e-05
Iter: 834 loss: 2.05959132e-05
Iter: 835 loss: 2.06397144e-05
Iter: 836 loss: 2.05581255e-05
Iter: 837 loss: 2.05478682e-05
Iter: 838 loss: 2.05500091e-05
Iter: 839 loss: 2.0540363e-05
Iter: 840 loss: 2.0488329e-05
Iter: 841 loss: 2.07446428e-05
Iter: 842 loss: 2.04792777e-05
Iter: 843 loss: 2.04453427e-05
Iter: 844 loss: 2.04592034e-05
Iter: 845 loss: 2.04218122e-05
Iter: 846 loss: 2.03870459e-05
Iter: 847 loss: 2.06959157e-05
Iter: 848 loss: 2.03855416e-05
Iter: 849 loss: 2.03581985e-05
Iter: 850 loss: 2.04090447e-05
Iter: 851 loss: 2.03463896e-05
Iter: 852 loss: 2.03183281e-05
Iter: 853 loss: 2.02392221e-05
Iter: 854 loss: 2.06692966e-05
Iter: 855 loss: 2.02144347e-05
Iter: 856 loss: 2.01777439e-05
Iter: 857 loss: 2.03834788e-05
Iter: 858 loss: 2.01725488e-05
Iter: 859 loss: 2.01623243e-05
Iter: 860 loss: 2.01855346e-05
Iter: 861 loss: 2.0158448e-05
Iter: 862 loss: 2.01419825e-05
Iter: 863 loss: 2.00996583e-05
Iter: 864 loss: 2.04440876e-05
Iter: 865 loss: 2.00918748e-05
Iter: 866 loss: 2.00616832e-05
Iter: 867 loss: 2.0061485e-05
Iter: 868 loss: 2.00496343e-05
Iter: 869 loss: 2.0136511e-05
Iter: 870 loss: 2.00486375e-05
Iter: 871 loss: 2.00313898e-05
Iter: 872 loss: 2.00389186e-05
Iter: 873 loss: 2.001965e-05
Iter: 874 loss: 2.00031827e-05
Iter: 875 loss: 1.99511887e-05
Iter: 876 loss: 2.00023114e-05
Iter: 877 loss: 1.99092574e-05
Iter: 878 loss: 1.9821131e-05
Iter: 879 loss: 1.99854931e-05
Iter: 880 loss: 1.97836671e-05
Iter: 881 loss: 1.97230765e-05
Iter: 882 loss: 2.03089021e-05
Iter: 883 loss: 1.972071e-05
Iter: 884 loss: 1.96633737e-05
Iter: 885 loss: 1.99324149e-05
Iter: 886 loss: 1.96527108e-05
Iter: 887 loss: 1.9605819e-05
Iter: 888 loss: 1.95541252e-05
Iter: 889 loss: 1.95467492e-05
Iter: 890 loss: 1.94625391e-05
Iter: 891 loss: 2.01769162e-05
Iter: 892 loss: 1.94579079e-05
Iter: 893 loss: 1.94862732e-05
Iter: 894 loss: 1.94363129e-05
Iter: 895 loss: 1.94135573e-05
Iter: 896 loss: 1.93521955e-05
Iter: 897 loss: 1.97631707e-05
Iter: 898 loss: 1.93374181e-05
Iter: 899 loss: 1.92709122e-05
Iter: 900 loss: 1.92918669e-05
Iter: 901 loss: 1.92237239e-05
Iter: 902 loss: 1.92443695e-05
Iter: 903 loss: 1.9203424e-05
Iter: 904 loss: 1.91806448e-05
Iter: 905 loss: 1.93764135e-05
Iter: 906 loss: 1.91795043e-05
Iter: 907 loss: 1.91697291e-05
Iter: 908 loss: 1.91361651e-05
Iter: 909 loss: 1.90888277e-05
Iter: 910 loss: 1.90817773e-05
Iter: 911 loss: 1.90206374e-05
Iter: 912 loss: 1.91982217e-05
Iter: 913 loss: 1.90018254e-05
Iter: 914 loss: 1.88709273e-05
Iter: 915 loss: 1.92092048e-05
Iter: 916 loss: 1.88266513e-05
Iter: 917 loss: 1.87958976e-05
Iter: 918 loss: 1.87848254e-05
Iter: 919 loss: 1.8761184e-05
Iter: 920 loss: 1.87065634e-05
Iter: 921 loss: 1.93789783e-05
Iter: 922 loss: 1.87022197e-05
Iter: 923 loss: 1.86623038e-05
Iter: 924 loss: 1.87814767e-05
Iter: 925 loss: 1.8650233e-05
Iter: 926 loss: 1.86401667e-05
Iter: 927 loss: 1.8626557e-05
Iter: 928 loss: 1.86258876e-05
Iter: 929 loss: 1.85984809e-05
Iter: 930 loss: 1.85844183e-05
Iter: 931 loss: 1.85715089e-05
Iter: 932 loss: 1.85122863e-05
Iter: 933 loss: 1.87591395e-05
Iter: 934 loss: 1.85000063e-05
Iter: 935 loss: 1.84656092e-05
Iter: 936 loss: 1.84043784e-05
Iter: 937 loss: 1.99256501e-05
Iter: 938 loss: 1.84043565e-05
Iter: 939 loss: 1.83859447e-05
Iter: 940 loss: 1.83587108e-05
Iter: 941 loss: 1.83627926e-05
Iter: 942 loss: 1.83471238e-05
Iter: 943 loss: 1.8340208e-05
Iter: 944 loss: 1.83373231e-05
Iter: 945 loss: 1.83335469e-05
Iter: 946 loss: 1.83271495e-05
Iter: 947 loss: 1.83075063e-05
Iter: 948 loss: 1.8357252e-05
Iter: 949 loss: 1.82966596e-05
Iter: 950 loss: 1.82727908e-05
Iter: 951 loss: 1.84357959e-05
Iter: 952 loss: 1.82704989e-05
Iter: 953 loss: 1.82462572e-05
Iter: 954 loss: 1.84281052e-05
Iter: 955 loss: 1.82446693e-05
Iter: 956 loss: 1.82403073e-05
Iter: 957 loss: 1.82389576e-05
Iter: 958 loss: 1.82337517e-05
Iter: 959 loss: 1.82558942e-05
Iter: 960 loss: 1.82326694e-05
Iter: 961 loss: 1.82274471e-05
Iter: 962 loss: 1.82324547e-05
Iter: 963 loss: 1.82245822e-05
Iter: 964 loss: 1.82164295e-05
Iter: 965 loss: 1.81897958e-05
Iter: 966 loss: 1.81883242e-05
Iter: 967 loss: 1.81616451e-05
Iter: 968 loss: 1.81183459e-05
Iter: 969 loss: 1.80697753e-05
Iter: 970 loss: 1.80631323e-05
Iter: 971 loss: 1.80562965e-05
Iter: 972 loss: 1.80315365e-05
Iter: 973 loss: 1.80051029e-05
Iter: 974 loss: 1.81358828e-05
Iter: 975 loss: 1.80004281e-05
Iter: 976 loss: 1.79682047e-05
Iter: 977 loss: 1.81173291e-05
Iter: 978 loss: 1.79620583e-05
Iter: 979 loss: 1.79451436e-05
Iter: 980 loss: 1.79066265e-05
Iter: 981 loss: 1.84253622e-05
Iter: 982 loss: 1.79042763e-05
Iter: 983 loss: 1.78688297e-05
Iter: 984 loss: 1.78748669e-05
Iter: 985 loss: 1.78423925e-05
Iter: 986 loss: 1.77780021e-05
Iter: 987 loss: 1.8314071e-05
Iter: 988 loss: 1.77747206e-05
Iter: 989 loss: 1.77857255e-05
Iter: 990 loss: 1.77587463e-05
Iter: 991 loss: 1.77480106e-05
Iter: 992 loss: 1.77241236e-05
Iter: 993 loss: 1.80708048e-05
Iter: 994 loss: 1.77232068e-05
Iter: 995 loss: 1.76914673e-05
Iter: 996 loss: 1.77227248e-05
Iter: 997 loss: 1.76734684e-05
Iter: 998 loss: 1.76561589e-05
Iter: 999 loss: 1.76002322e-05
Iter: 1000 loss: 1.76296198e-05
Iter: 1001 loss: 1.75495079e-05
Iter: 1002 loss: 1.74802462e-05
Iter: 1003 loss: 1.74790948e-05
Iter: 1004 loss: 1.74540091e-05
Iter: 1005 loss: 1.75557034e-05
Iter: 1006 loss: 1.74484012e-05
Iter: 1007 loss: 1.74036832e-05
Iter: 1008 loss: 1.74552824e-05
Iter: 1009 loss: 1.73797343e-05
Iter: 1010 loss: 1.73479984e-05
Iter: 1011 loss: 1.77699603e-05
Iter: 1012 loss: 1.73478038e-05
Iter: 1013 loss: 1.73277058e-05
Iter: 1014 loss: 1.73409862e-05
Iter: 1015 loss: 1.73149492e-05
Iter: 1016 loss: 1.72973414e-05
Iter: 1017 loss: 1.72725286e-05
Iter: 1018 loss: 1.72713026e-05
Iter: 1019 loss: 1.72519358e-05
Iter: 1020 loss: 1.73228091e-05
Iter: 1021 loss: 1.72471464e-05
Iter: 1022 loss: 1.72411601e-05
Iter: 1023 loss: 1.72256441e-05
Iter: 1024 loss: 1.73562821e-05
Iter: 1025 loss: 1.72232812e-05
Iter: 1026 loss: 1.72573036e-05
Iter: 1027 loss: 1.72191303e-05
Iter: 1028 loss: 1.72162872e-05
Iter: 1029 loss: 1.72267391e-05
Iter: 1030 loss: 1.72158743e-05
Iter: 1031 loss: 1.72136242e-05
Iter: 1032 loss: 1.72065447e-05
Iter: 1033 loss: 1.72289183e-05
Iter: 1034 loss: 1.72032505e-05
Iter: 1035 loss: 1.71893771e-05
Iter: 1036 loss: 1.71892025e-05
Iter: 1037 loss: 1.71789434e-05
Iter: 1038 loss: 1.71766405e-05
Iter: 1039 loss: 1.71700358e-05
Iter: 1040 loss: 1.71590273e-05
Iter: 1041 loss: 1.71421543e-05
Iter: 1042 loss: 1.71418433e-05
Iter: 1043 loss: 1.71616975e-05
Iter: 1044 loss: 1.7134209e-05
Iter: 1045 loss: 1.71218908e-05
Iter: 1046 loss: 1.70902968e-05
Iter: 1047 loss: 1.73612225e-05
Iter: 1048 loss: 1.70849016e-05
Iter: 1049 loss: 1.70452313e-05
Iter: 1050 loss: 1.71448264e-05
Iter: 1051 loss: 1.70315234e-05
Iter: 1052 loss: 1.69985724e-05
Iter: 1053 loss: 1.72899981e-05
Iter: 1054 loss: 1.69971099e-05
Iter: 1055 loss: 1.69784034e-05
Iter: 1056 loss: 1.69302511e-05
Iter: 1057 loss: 1.73214339e-05
Iter: 1058 loss: 1.69215691e-05
Iter: 1059 loss: 1.70806306e-05
Iter: 1060 loss: 1.68906754e-05
Iter: 1061 loss: 1.6876842e-05
Iter: 1062 loss: 1.68798924e-05
Iter: 1063 loss: 1.68666047e-05
Iter: 1064 loss: 1.68506376e-05
Iter: 1065 loss: 1.68519909e-05
Iter: 1066 loss: 1.68381266e-05
Iter: 1067 loss: 1.68215593e-05
Iter: 1068 loss: 1.67670587e-05
Iter: 1069 loss: 1.67862836e-05
Iter: 1070 loss: 1.67158032e-05
Iter: 1071 loss: 1.67497037e-05
Iter: 1072 loss: 1.66524369e-05
Iter: 1073 loss: 1.65959464e-05
Iter: 1074 loss: 1.70335479e-05
Iter: 1075 loss: 1.65918173e-05
Iter: 1076 loss: 1.65784586e-05
Iter: 1077 loss: 1.66780628e-05
Iter: 1078 loss: 1.65773799e-05
Iter: 1079 loss: 1.65627098e-05
Iter: 1080 loss: 1.65311467e-05
Iter: 1081 loss: 1.70429139e-05
Iter: 1082 loss: 1.65302918e-05
Iter: 1083 loss: 1.6507689e-05
Iter: 1084 loss: 1.66804857e-05
Iter: 1085 loss: 1.65061283e-05
Iter: 1086 loss: 1.64901485e-05
Iter: 1087 loss: 1.64893518e-05
Iter: 1088 loss: 1.64767443e-05
Iter: 1089 loss: 1.6489159e-05
Iter: 1090 loss: 1.64696685e-05
Iter: 1091 loss: 1.64625271e-05
Iter: 1092 loss: 1.64689554e-05
Iter: 1093 loss: 1.64582943e-05
Iter: 1094 loss: 1.64450139e-05
Iter: 1095 loss: 1.64489084e-05
Iter: 1096 loss: 1.64355624e-05
Iter: 1097 loss: 1.64260091e-05
Iter: 1098 loss: 1.64408375e-05
Iter: 1099 loss: 1.64214071e-05
Iter: 1100 loss: 1.64056837e-05
Iter: 1101 loss: 1.63740842e-05
Iter: 1102 loss: 1.69634804e-05
Iter: 1103 loss: 1.63736931e-05
Iter: 1104 loss: 1.63541699e-05
Iter: 1105 loss: 1.63540499e-05
Iter: 1106 loss: 1.6341095e-05
Iter: 1107 loss: 1.65157526e-05
Iter: 1108 loss: 1.63410805e-05
Iter: 1109 loss: 1.63333e-05
Iter: 1110 loss: 1.63850618e-05
Iter: 1111 loss: 1.63324839e-05
Iter: 1112 loss: 1.63225122e-05
Iter: 1113 loss: 1.6301301e-05
Iter: 1114 loss: 1.66513055e-05
Iter: 1115 loss: 1.63007244e-05
Iter: 1116 loss: 1.62825017e-05
Iter: 1117 loss: 1.64112553e-05
Iter: 1118 loss: 1.62808665e-05
Iter: 1119 loss: 1.62676806e-05
Iter: 1120 loss: 1.62885208e-05
Iter: 1121 loss: 1.62615361e-05
Iter: 1122 loss: 1.62709584e-05
Iter: 1123 loss: 1.62587276e-05
Iter: 1124 loss: 1.62569213e-05
Iter: 1125 loss: 1.62661327e-05
Iter: 1126 loss: 1.62566848e-05
Iter: 1127 loss: 1.6253889e-05
Iter: 1128 loss: 1.62595934e-05
Iter: 1129 loss: 1.62527595e-05
Iter: 1130 loss: 1.62491488e-05
Iter: 1131 loss: 1.62549477e-05
Iter: 1132 loss: 1.62476e-05
Iter: 1133 loss: 1.62429169e-05
Iter: 1134 loss: 1.62276338e-05
Iter: 1135 loss: 1.62125434e-05
Iter: 1136 loss: 1.6205915e-05
Iter: 1137 loss: 1.6166141e-05
Iter: 1138 loss: 1.63175064e-05
Iter: 1139 loss: 1.61567186e-05
Iter: 1140 loss: 1.6142214e-05
Iter: 1141 loss: 1.61347671e-05
Iter: 1142 loss: 1.61352782e-05
Iter: 1143 loss: 1.61270309e-05
Iter: 1144 loss: 1.61206481e-05
Iter: 1145 loss: 1.61083826e-05
Iter: 1146 loss: 1.63834211e-05
Iter: 1147 loss: 1.61083481e-05
Iter: 1148 loss: 1.60992022e-05
Iter: 1149 loss: 1.60764648e-05
Iter: 1150 loss: 1.62920132e-05
Iter: 1151 loss: 1.60732197e-05
Iter: 1152 loss: 1.60458731e-05
Iter: 1153 loss: 1.6414886e-05
Iter: 1154 loss: 1.60458039e-05
Iter: 1155 loss: 1.60312702e-05
Iter: 1156 loss: 1.62252982e-05
Iter: 1157 loss: 1.6031101e-05
Iter: 1158 loss: 1.60132222e-05
Iter: 1159 loss: 1.6087648e-05
Iter: 1160 loss: 1.60095533e-05
Iter: 1161 loss: 1.5996935e-05
Iter: 1162 loss: 1.61015178e-05
Iter: 1163 loss: 1.59964329e-05
Iter: 1164 loss: 1.598778e-05
Iter: 1165 loss: 1.60001509e-05
Iter: 1166 loss: 1.59838492e-05
Iter: 1167 loss: 1.59684787e-05
Iter: 1168 loss: 1.5931224e-05
Iter: 1169 loss: 1.63240802e-05
Iter: 1170 loss: 1.59273022e-05
Iter: 1171 loss: 1.58912117e-05
Iter: 1172 loss: 1.58644816e-05
Iter: 1173 loss: 1.58526855e-05
Iter: 1174 loss: 1.57926988e-05
Iter: 1175 loss: 1.59412029e-05
Iter: 1176 loss: 1.57718823e-05
Iter: 1177 loss: 1.5826794e-05
Iter: 1178 loss: 1.57508366e-05
Iter: 1179 loss: 1.57347786e-05
Iter: 1180 loss: 1.57121e-05
Iter: 1181 loss: 1.57112954e-05
Iter: 1182 loss: 1.56902297e-05
Iter: 1183 loss: 1.56705537e-05
Iter: 1184 loss: 1.56657152e-05
Iter: 1185 loss: 1.56385613e-05
Iter: 1186 loss: 1.58138137e-05
Iter: 1187 loss: 1.56354417e-05
Iter: 1188 loss: 1.56105452e-05
Iter: 1189 loss: 1.57478025e-05
Iter: 1190 loss: 1.56068418e-05
Iter: 1191 loss: 1.55928246e-05
Iter: 1192 loss: 1.55918315e-05
Iter: 1193 loss: 1.55829075e-05
Iter: 1194 loss: 1.56452261e-05
Iter: 1195 loss: 1.55820908e-05
Iter: 1196 loss: 1.55769958e-05
Iter: 1197 loss: 1.55657981e-05
Iter: 1198 loss: 1.57369286e-05
Iter: 1199 loss: 1.55654889e-05
Iter: 1200 loss: 1.55421421e-05
Iter: 1201 loss: 1.55203888e-05
Iter: 1202 loss: 1.55150519e-05
Iter: 1203 loss: 1.55025373e-05
Iter: 1204 loss: 1.54702466e-05
Iter: 1205 loss: 1.57207978e-05
Iter: 1206 loss: 1.54638365e-05
Iter: 1207 loss: 1.54373756e-05
Iter: 1208 loss: 1.54435329e-05
Iter: 1209 loss: 1.54178724e-05
Iter: 1210 loss: 1.54149748e-05
Iter: 1211 loss: 1.54113641e-05
Iter: 1212 loss: 1.54090922e-05
Iter: 1213 loss: 1.54057361e-05
Iter: 1214 loss: 1.54055942e-05
Iter: 1215 loss: 1.5395779e-05
Iter: 1216 loss: 1.5374535e-05
Iter: 1217 loss: 1.56967926e-05
Iter: 1218 loss: 1.53738019e-05
Iter: 1219 loss: 1.53663877e-05
Iter: 1220 loss: 1.53584297e-05
Iter: 1221 loss: 1.53467263e-05
Iter: 1222 loss: 1.53402179e-05
Iter: 1223 loss: 1.53354049e-05
Iter: 1224 loss: 1.53604269e-05
Iter: 1225 loss: 1.53305391e-05
Iter: 1226 loss: 1.53277906e-05
Iter: 1227 loss: 1.53267065e-05
Iter: 1228 loss: 1.53255387e-05
Iter: 1229 loss: 1.53154469e-05
Iter: 1230 loss: 1.53052733e-05
Iter: 1231 loss: 1.53031287e-05
Iter: 1232 loss: 1.53009605e-05
Iter: 1233 loss: 1.52933626e-05
Iter: 1234 loss: 1.52895755e-05
Iter: 1235 loss: 1.52901175e-05
Iter: 1236 loss: 1.5286696e-05
Iter: 1237 loss: 1.5273954e-05
Iter: 1238 loss: 1.52737757e-05
Iter: 1239 loss: 1.52707435e-05
Iter: 1240 loss: 1.52684424e-05
Iter: 1241 loss: 1.52661487e-05
Iter: 1242 loss: 1.5259051e-05
Iter: 1243 loss: 1.5277059e-05
Iter: 1244 loss: 1.5255473e-05
Iter: 1245 loss: 1.52418888e-05
Iter: 1246 loss: 1.52422472e-05
Iter: 1247 loss: 1.52312559e-05
Iter: 1248 loss: 1.52115008e-05
Iter: 1249 loss: 1.5270125e-05
Iter: 1250 loss: 1.52056609e-05
Iter: 1251 loss: 1.51923332e-05
Iter: 1252 loss: 1.5292233e-05
Iter: 1253 loss: 1.51914146e-05
Iter: 1254 loss: 1.51875502e-05
Iter: 1255 loss: 1.51874792e-05
Iter: 1256 loss: 1.51834702e-05
Iter: 1257 loss: 1.51722497e-05
Iter: 1258 loss: 1.523009e-05
Iter: 1259 loss: 1.51684271e-05
Iter: 1260 loss: 1.51627173e-05
Iter: 1261 loss: 1.51596723e-05
Iter: 1262 loss: 1.51571312e-05
Iter: 1263 loss: 1.51574059e-05
Iter: 1264 loss: 1.51522072e-05
Iter: 1265 loss: 1.51499371e-05
Iter: 1266 loss: 1.51437962e-05
Iter: 1267 loss: 1.5188074e-05
Iter: 1268 loss: 1.51426011e-05
Iter: 1269 loss: 1.51233853e-05
Iter: 1270 loss: 1.50916367e-05
Iter: 1271 loss: 1.50913947e-05
Iter: 1272 loss: 1.52320554e-05
Iter: 1273 loss: 1.50870756e-05
Iter: 1274 loss: 1.50816604e-05
Iter: 1275 loss: 1.50669384e-05
Iter: 1276 loss: 1.51775921e-05
Iter: 1277 loss: 1.50639707e-05
Iter: 1278 loss: 1.50386204e-05
Iter: 1279 loss: 1.53764922e-05
Iter: 1280 loss: 1.50384221e-05
Iter: 1281 loss: 1.50184478e-05
Iter: 1282 loss: 1.50537089e-05
Iter: 1283 loss: 1.50096121e-05
Iter: 1284 loss: 1.50002325e-05
Iter: 1285 loss: 1.5003212e-05
Iter: 1286 loss: 1.49936786e-05
Iter: 1287 loss: 1.49852331e-05
Iter: 1288 loss: 1.4966311e-05
Iter: 1289 loss: 1.52407756e-05
Iter: 1290 loss: 1.49652569e-05
Iter: 1291 loss: 1.49496282e-05
Iter: 1292 loss: 1.4937913e-05
Iter: 1293 loss: 1.49326061e-05
Iter: 1294 loss: 1.49257139e-05
Iter: 1295 loss: 1.49251018e-05
Iter: 1296 loss: 1.49205189e-05
Iter: 1297 loss: 1.49205453e-05
Iter: 1298 loss: 1.49129155e-05
Iter: 1299 loss: 1.4898058e-05
Iter: 1300 loss: 1.51829227e-05
Iter: 1301 loss: 1.48980262e-05
Iter: 1302 loss: 1.48923482e-05
Iter: 1303 loss: 1.488613e-05
Iter: 1304 loss: 1.48852287e-05
Iter: 1305 loss: 1.48811487e-05
Iter: 1306 loss: 1.49152502e-05
Iter: 1307 loss: 1.4881025e-05
Iter: 1308 loss: 1.48796316e-05
Iter: 1309 loss: 1.48814834e-05
Iter: 1310 loss: 1.48789841e-05
Iter: 1311 loss: 1.48757472e-05
Iter: 1312 loss: 1.48703766e-05
Iter: 1313 loss: 1.48701893e-05
Iter: 1314 loss: 1.48639938e-05
Iter: 1315 loss: 1.49309953e-05
Iter: 1316 loss: 1.48638446e-05
Iter: 1317 loss: 1.48605759e-05
Iter: 1318 loss: 1.48674208e-05
Iter: 1319 loss: 1.48591935e-05
Iter: 1320 loss: 1.48528052e-05
Iter: 1321 loss: 1.48598756e-05
Iter: 1322 loss: 1.48492072e-05
Iter: 1323 loss: 1.48428335e-05
Iter: 1324 loss: 1.48390882e-05
Iter: 1325 loss: 1.48362305e-05
Iter: 1326 loss: 1.48211593e-05
Iter: 1327 loss: 1.48253066e-05
Iter: 1328 loss: 1.48102754e-05
Iter: 1329 loss: 1.48038107e-05
Iter: 1330 loss: 1.48037143e-05
Iter: 1331 loss: 1.47966975e-05
Iter: 1332 loss: 1.47939918e-05
Iter: 1333 loss: 1.47900746e-05
Iter: 1334 loss: 1.47858182e-05
Iter: 1335 loss: 1.47773972e-05
Iter: 1336 loss: 1.49561201e-05
Iter: 1337 loss: 1.4777188e-05
Iter: 1338 loss: 1.48016943e-05
Iter: 1339 loss: 1.4775318e-05
Iter: 1340 loss: 1.47741957e-05
Iter: 1341 loss: 1.47735791e-05
Iter: 1342 loss: 1.47730461e-05
Iter: 1343 loss: 1.47612354e-05
Iter: 1344 loss: 1.48699328e-05
Iter: 1345 loss: 1.47606916e-05
Iter: 1346 loss: 1.47494857e-05
Iter: 1347 loss: 1.47810169e-05
Iter: 1348 loss: 1.47459414e-05
Iter: 1349 loss: 1.47370256e-05
Iter: 1350 loss: 1.4735916e-05
Iter: 1351 loss: 1.47295887e-05
Iter: 1352 loss: 1.4715175e-05
Iter: 1353 loss: 1.48966155e-05
Iter: 1354 loss: 1.47151522e-05
Iter: 1355 loss: 1.47107312e-05
Iter: 1356 loss: 1.4703437e-05
Iter: 1357 loss: 1.47032442e-05
Iter: 1358 loss: 1.46908787e-05
Iter: 1359 loss: 1.47493811e-05
Iter: 1360 loss: 1.4688485e-05
Iter: 1361 loss: 1.4689318e-05
Iter: 1362 loss: 1.46848488e-05
Iter: 1363 loss: 1.46807215e-05
Iter: 1364 loss: 1.46836746e-05
Iter: 1365 loss: 1.46783059e-05
Iter: 1366 loss: 1.46741777e-05
Iter: 1367 loss: 1.46693528e-05
Iter: 1368 loss: 1.46689636e-05
Iter: 1369 loss: 1.46656093e-05
Iter: 1370 loss: 1.46651255e-05
Iter: 1371 loss: 1.46584071e-05
Iter: 1372 loss: 1.46394914e-05
Iter: 1373 loss: 1.47283363e-05
Iter: 1374 loss: 1.46325492e-05
Iter: 1375 loss: 1.4610785e-05
Iter: 1376 loss: 1.46771499e-05
Iter: 1377 loss: 1.46043258e-05
Iter: 1378 loss: 1.45906906e-05
Iter: 1379 loss: 1.4613146e-05
Iter: 1380 loss: 1.45846898e-05
Iter: 1381 loss: 1.45723825e-05
Iter: 1382 loss: 1.4551174e-05
Iter: 1383 loss: 1.45511985e-05
Iter: 1384 loss: 1.45335844e-05
Iter: 1385 loss: 1.45072781e-05
Iter: 1386 loss: 1.45066442e-05
Iter: 1387 loss: 1.44923524e-05
Iter: 1388 loss: 1.47103337e-05
Iter: 1389 loss: 1.44923179e-05
Iter: 1390 loss: 1.44709156e-05
Iter: 1391 loss: 1.45030217e-05
Iter: 1392 loss: 1.44606656e-05
Iter: 1393 loss: 1.44532387e-05
Iter: 1394 loss: 1.44879423e-05
Iter: 1395 loss: 1.44518708e-05
Iter: 1396 loss: 1.44486785e-05
Iter: 1397 loss: 1.44377373e-05
Iter: 1398 loss: 1.44334317e-05
Iter: 1399 loss: 1.44246897e-05
Iter: 1400 loss: 1.44221522e-05
Iter: 1401 loss: 1.44166352e-05
Iter: 1402 loss: 1.44360474e-05
Iter: 1403 loss: 1.44115065e-05
Iter: 1404 loss: 1.44081587e-05
Iter: 1405 loss: 1.44148926e-05
Iter: 1406 loss: 1.44067817e-05
Iter: 1407 loss: 1.43982088e-05
Iter: 1408 loss: 1.43915604e-05
Iter: 1409 loss: 1.43891248e-05
Iter: 1410 loss: 1.43753605e-05
Iter: 1411 loss: 1.45182948e-05
Iter: 1412 loss: 1.43750694e-05
Iter: 1413 loss: 1.4362533e-05
Iter: 1414 loss: 1.43577963e-05
Iter: 1415 loss: 1.43509524e-05
Iter: 1416 loss: 1.43344114e-05
Iter: 1417 loss: 1.45169479e-05
Iter: 1418 loss: 1.43341658e-05
Iter: 1419 loss: 1.43196557e-05
Iter: 1420 loss: 1.43046818e-05
Iter: 1421 loss: 1.43019515e-05
Iter: 1422 loss: 1.4287978e-05
Iter: 1423 loss: 1.44306887e-05
Iter: 1424 loss: 1.42873778e-05
Iter: 1425 loss: 1.42868703e-05
Iter: 1426 loss: 1.42795388e-05
Iter: 1427 loss: 1.42787467e-05
Iter: 1428 loss: 1.42754552e-05
Iter: 1429 loss: 1.42665995e-05
Iter: 1430 loss: 1.44051628e-05
Iter: 1431 loss: 1.42663248e-05
Iter: 1432 loss: 1.4249028e-05
Iter: 1433 loss: 1.42310055e-05
Iter: 1434 loss: 1.42277113e-05
Iter: 1435 loss: 1.42260797e-05
Iter: 1436 loss: 1.4222037e-05
Iter: 1437 loss: 1.42145918e-05
Iter: 1438 loss: 1.42329991e-05
Iter: 1439 loss: 1.42122208e-05
Iter: 1440 loss: 1.4206832e-05
Iter: 1441 loss: 1.41942173e-05
Iter: 1442 loss: 1.43542211e-05
Iter: 1443 loss: 1.41932487e-05
Iter: 1444 loss: 1.4184895e-05
Iter: 1445 loss: 1.42572335e-05
Iter: 1446 loss: 1.41843575e-05
Iter: 1447 loss: 1.41775272e-05
Iter: 1448 loss: 1.41643195e-05
Iter: 1449 loss: 1.44478508e-05
Iter: 1450 loss: 1.41643814e-05
Iter: 1451 loss: 1.41545579e-05
Iter: 1452 loss: 1.41891414e-05
Iter: 1453 loss: 1.41520686e-05
Iter: 1454 loss: 1.41490546e-05
Iter: 1455 loss: 1.41419023e-05
Iter: 1456 loss: 1.42286226e-05
Iter: 1457 loss: 1.41414457e-05
Iter: 1458 loss: 1.41391138e-05
Iter: 1459 loss: 1.41387172e-05
Iter: 1460 loss: 1.41376504e-05
Iter: 1461 loss: 1.41356968e-05
Iter: 1462 loss: 1.41356586e-05
Iter: 1463 loss: 1.41295086e-05
Iter: 1464 loss: 1.41110768e-05
Iter: 1465 loss: 1.41681721e-05
Iter: 1466 loss: 1.41017372e-05
Iter: 1467 loss: 1.40888114e-05
Iter: 1468 loss: 1.4117144e-05
Iter: 1469 loss: 1.40839838e-05
Iter: 1470 loss: 1.40601524e-05
Iter: 1471 loss: 1.40706434e-05
Iter: 1472 loss: 1.40436332e-05
Iter: 1473 loss: 1.41209412e-05
Iter: 1474 loss: 1.40381853e-05
Iter: 1475 loss: 1.40361835e-05
Iter: 1476 loss: 1.40381017e-05
Iter: 1477 loss: 1.40348984e-05
Iter: 1478 loss: 1.40218544e-05
Iter: 1479 loss: 1.40108405e-05
Iter: 1480 loss: 1.40072061e-05
Iter: 1481 loss: 1.39858e-05
Iter: 1482 loss: 1.42240315e-05
Iter: 1483 loss: 1.39854419e-05
Iter: 1484 loss: 1.39812364e-05
Iter: 1485 loss: 1.3975563e-05
Iter: 1486 loss: 1.39752483e-05
Iter: 1487 loss: 1.39715812e-05
Iter: 1488 loss: 1.39896365e-05
Iter: 1489 loss: 1.39707208e-05
Iter: 1490 loss: 1.39701324e-05
Iter: 1491 loss: 1.39691638e-05
Iter: 1492 loss: 1.39690474e-05
Iter: 1493 loss: 1.39625072e-05
Iter: 1494 loss: 1.39608128e-05
Iter: 1495 loss: 1.39569283e-05
Iter: 1496 loss: 1.39538661e-05
Iter: 1497 loss: 1.39530139e-05
Iter: 1498 loss: 1.39509848e-05
Iter: 1499 loss: 1.39458789e-05
Iter: 1500 loss: 1.39740623e-05
Iter: 1501 loss: 1.39441472e-05
Iter: 1502 loss: 1.39378881e-05
Iter: 1503 loss: 1.3941908e-05
Iter: 1504 loss: 1.39338918e-05
Iter: 1505 loss: 1.40368666e-05
Iter: 1506 loss: 1.39330332e-05
Iter: 1507 loss: 1.393206e-05
Iter: 1508 loss: 1.39339554e-05
Iter: 1509 loss: 1.39313961e-05
Iter: 1510 loss: 1.39242438e-05
Iter: 1511 loss: 1.39844506e-05
Iter: 1512 loss: 1.39237673e-05
Iter: 1513 loss: 1.39185904e-05
Iter: 1514 loss: 1.39812119e-05
Iter: 1515 loss: 1.39183667e-05
Iter: 1516 loss: 1.39157391e-05
Iter: 1517 loss: 1.39130589e-05
Iter: 1518 loss: 1.39126059e-05
Iter: 1519 loss: 1.39126678e-05
Iter: 1520 loss: 1.39103558e-05
Iter: 1521 loss: 1.39096592e-05
Iter: 1522 loss: 1.3908073e-05
Iter: 1523 loss: 1.39041258e-05
Iter: 1524 loss: 1.40045395e-05
Iter: 1525 loss: 1.39039503e-05
Iter: 1526 loss: 1.38982523e-05
Iter: 1527 loss: 1.38933965e-05
Iter: 1528 loss: 1.38916503e-05
Iter: 1529 loss: 1.38866608e-05
Iter: 1530 loss: 1.38760979e-05
Iter: 1531 loss: 1.40684533e-05
Iter: 1532 loss: 1.38760624e-05
Iter: 1533 loss: 1.38551495e-05
Iter: 1534 loss: 1.38925379e-05
Iter: 1535 loss: 1.38460282e-05
Iter: 1536 loss: 1.38337673e-05
Iter: 1537 loss: 1.3821742e-05
Iter: 1538 loss: 1.38193063e-05
Iter: 1539 loss: 1.40329603e-05
Iter: 1540 loss: 1.38159776e-05
Iter: 1541 loss: 1.3811843e-05
Iter: 1542 loss: 1.38176611e-05
Iter: 1543 loss: 1.38099495e-05
Iter: 1544 loss: 1.38059886e-05
Iter: 1545 loss: 1.38042487e-05
Iter: 1546 loss: 1.38023825e-05
Iter: 1547 loss: 1.37970037e-05
Iter: 1548 loss: 1.38116611e-05
Iter: 1549 loss: 1.37952875e-05
Iter: 1550 loss: 1.37892766e-05
Iter: 1551 loss: 1.37813231e-05
Iter: 1552 loss: 1.37807456e-05
Iter: 1553 loss: 1.3770732e-05
Iter: 1554 loss: 1.37782354e-05
Iter: 1555 loss: 1.37644674e-05
Iter: 1556 loss: 1.37777752e-05
Iter: 1557 loss: 1.37571133e-05
Iter: 1558 loss: 1.37546813e-05
Iter: 1559 loss: 1.37573406e-05
Iter: 1560 loss: 1.37532279e-05
Iter: 1561 loss: 1.37495335e-05
Iter: 1562 loss: 1.3743841e-05
Iter: 1563 loss: 1.37437037e-05
Iter: 1564 loss: 1.3740404e-05
Iter: 1565 loss: 1.37671432e-05
Iter: 1566 loss: 1.37401039e-05
Iter: 1567 loss: 1.37373427e-05
Iter: 1568 loss: 1.37362931e-05
Iter: 1569 loss: 1.37347633e-05
Iter: 1570 loss: 1.3738565e-05
Iter: 1571 loss: 1.37339048e-05
Iter: 1572 loss: 1.37333809e-05
Iter: 1573 loss: 1.37383795e-05
Iter: 1574 loss: 1.37333891e-05
Iter: 1575 loss: 1.37327643e-05
Iter: 1576 loss: 1.37313818e-05
Iter: 1577 loss: 1.37397983e-05
Iter: 1578 loss: 1.37311035e-05
Iter: 1579 loss: 1.37276475e-05
Iter: 1580 loss: 1.3718698e-05
Iter: 1581 loss: 1.37930674e-05
Iter: 1582 loss: 1.37171055e-05
Iter: 1583 loss: 1.37088209e-05
Iter: 1584 loss: 1.37670741e-05
Iter: 1585 loss: 1.37083043e-05
Iter: 1586 loss: 1.37018505e-05
Iter: 1587 loss: 1.37002226e-05
Iter: 1588 loss: 1.36961944e-05
Iter: 1589 loss: 1.37035449e-05
Iter: 1590 loss: 1.36938925e-05
Iter: 1591 loss: 1.36925455e-05
Iter: 1592 loss: 1.36882745e-05
Iter: 1593 loss: 1.37096958e-05
Iter: 1594 loss: 1.36869912e-05
Iter: 1595 loss: 1.36817944e-05
Iter: 1596 loss: 1.36811786e-05
Iter: 1597 loss: 1.3677618e-05
Iter: 1598 loss: 1.36761928e-05
Iter: 1599 loss: 1.36742692e-05
Iter: 1600 loss: 1.36688441e-05
Iter: 1601 loss: 1.36581857e-05
Iter: 1602 loss: 1.38429687e-05
Iter: 1603 loss: 1.36577801e-05
Iter: 1604 loss: 1.36494809e-05
Iter: 1605 loss: 1.36372801e-05
Iter: 1606 loss: 1.36370127e-05
Iter: 1607 loss: 1.36414919e-05
Iter: 1608 loss: 1.36347753e-05
Iter: 1609 loss: 1.36314811e-05
Iter: 1610 loss: 1.3635874e-05
Iter: 1611 loss: 1.36300823e-05
Iter: 1612 loss: 1.36275467e-05
Iter: 1613 loss: 1.36197323e-05
Iter: 1614 loss: 1.36523158e-05
Iter: 1615 loss: 1.36166364e-05
Iter: 1616 loss: 1.36076069e-05
Iter: 1617 loss: 1.36903463e-05
Iter: 1618 loss: 1.36072103e-05
Iter: 1619 loss: 1.36015024e-05
Iter: 1620 loss: 1.35890987e-05
Iter: 1621 loss: 1.37851312e-05
Iter: 1622 loss: 1.35886175e-05
Iter: 1623 loss: 1.36187946e-05
Iter: 1624 loss: 1.35854243e-05
Iter: 1625 loss: 1.3582001e-05
Iter: 1626 loss: 1.3571962e-05
Iter: 1627 loss: 1.36290473e-05
Iter: 1628 loss: 1.35692444e-05
Iter: 1629 loss: 1.3557049e-05
Iter: 1630 loss: 1.35841137e-05
Iter: 1631 loss: 1.35524915e-05
Iter: 1632 loss: 1.35448e-05
Iter: 1633 loss: 1.35290538e-05
Iter: 1634 loss: 1.37963252e-05
Iter: 1635 loss: 1.35288174e-05
Iter: 1636 loss: 1.35230612e-05
Iter: 1637 loss: 1.35514756e-05
Iter: 1638 loss: 1.35220944e-05
Iter: 1639 loss: 1.3517536e-05
Iter: 1640 loss: 1.35159262e-05
Iter: 1641 loss: 1.3513356e-05
Iter: 1642 loss: 1.35084028e-05
Iter: 1643 loss: 1.35509308e-05
Iter: 1644 loss: 1.350819e-05
Iter: 1645 loss: 1.350612e-05
Iter: 1646 loss: 1.35018972e-05
Iter: 1647 loss: 1.35606879e-05
Iter: 1648 loss: 1.35016289e-05
Iter: 1649 loss: 1.34941247e-05
Iter: 1650 loss: 1.35965656e-05
Iter: 1651 loss: 1.34940574e-05
Iter: 1652 loss: 1.34854381e-05
Iter: 1653 loss: 1.34929433e-05
Iter: 1654 loss: 1.34807105e-05
Iter: 1655 loss: 1.34768088e-05
Iter: 1656 loss: 1.34737493e-05
Iter: 1657 loss: 1.34713755e-05
Iter: 1658 loss: 1.34724887e-05
Iter: 1659 loss: 1.34699785e-05
Iter: 1660 loss: 1.34706743e-05
Iter: 1661 loss: 1.3468527e-05
Iter: 1662 loss: 1.34678603e-05
Iter: 1663 loss: 1.34649636e-05
Iter: 1664 loss: 1.34592829e-05
Iter: 1665 loss: 1.34592083e-05
Iter: 1666 loss: 1.34508264e-05
Iter: 1667 loss: 1.34523161e-05
Iter: 1668 loss: 1.34448183e-05
Iter: 1669 loss: 1.34421498e-05
Iter: 1670 loss: 1.34693046e-05
Iter: 1671 loss: 1.34418788e-05
Iter: 1672 loss: 1.34396196e-05
Iter: 1673 loss: 1.34420461e-05
Iter: 1674 loss: 1.34381717e-05
Iter: 1675 loss: 1.34467955e-05
Iter: 1676 loss: 1.34376769e-05
Iter: 1677 loss: 1.34372804e-05
Iter: 1678 loss: 1.34357488e-05
Iter: 1679 loss: 1.34380971e-05
Iter: 1680 loss: 1.34345246e-05
Iter: 1681 loss: 1.34309294e-05
Iter: 1682 loss: 1.34249476e-05
Iter: 1683 loss: 1.34249258e-05
Iter: 1684 loss: 1.34231168e-05
Iter: 1685 loss: 1.34224902e-05
Iter: 1686 loss: 1.34202464e-05
Iter: 1687 loss: 1.34155625e-05
Iter: 1688 loss: 1.34787488e-05
Iter: 1689 loss: 1.34155098e-05
Iter: 1690 loss: 1.34112342e-05
Iter: 1691 loss: 1.34260172e-05
Iter: 1692 loss: 1.34100592e-05
Iter: 1693 loss: 1.34074653e-05
Iter: 1694 loss: 1.34175943e-05
Iter: 1695 loss: 1.34068832e-05
Iter: 1696 loss: 1.34037582e-05
Iter: 1697 loss: 1.34243674e-05
Iter: 1698 loss: 1.34034344e-05
Iter: 1699 loss: 1.34017118e-05
Iter: 1700 loss: 1.34033944e-05
Iter: 1701 loss: 1.34009988e-05
Iter: 1702 loss: 1.33991352e-05
Iter: 1703 loss: 1.34070069e-05
Iter: 1704 loss: 1.33988087e-05
Iter: 1705 loss: 1.3396374e-05
Iter: 1706 loss: 1.33944013e-05
Iter: 1707 loss: 1.33939229e-05
Iter: 1708 loss: 1.33975718e-05
Iter: 1709 loss: 1.33932244e-05
Iter: 1710 loss: 1.33927269e-05
Iter: 1711 loss: 1.33908961e-05
Iter: 1712 loss: 1.33868e-05
Iter: 1713 loss: 1.34838756e-05
Iter: 1714 loss: 1.33867e-05
Iter: 1715 loss: 1.33818176e-05
Iter: 1716 loss: 1.33893873e-05
Iter: 1717 loss: 1.33793019e-05
Iter: 1718 loss: 1.33760122e-05
Iter: 1719 loss: 1.33715675e-05
Iter: 1720 loss: 1.33711237e-05
Iter: 1721 loss: 1.33636058e-05
Iter: 1722 loss: 1.34213806e-05
Iter: 1723 loss: 1.33630883e-05
Iter: 1724 loss: 1.33615886e-05
Iter: 1725 loss: 1.33781359e-05
Iter: 1726 loss: 1.33616049e-05
Iter: 1727 loss: 1.33601152e-05
Iter: 1728 loss: 1.33691901e-05
Iter: 1729 loss: 1.33600479e-05
Iter: 1730 loss: 1.33585827e-05
Iter: 1731 loss: 1.33599797e-05
Iter: 1732 loss: 1.33577969e-05
Iter: 1733 loss: 1.33561416e-05
Iter: 1734 loss: 1.3366719e-05
Iter: 1735 loss: 1.33560234e-05
Iter: 1736 loss: 1.33550557e-05
Iter: 1737 loss: 1.33528774e-05
Iter: 1738 loss: 1.33637313e-05
Iter: 1739 loss: 1.33518097e-05
Iter: 1740 loss: 1.33486155e-05
Iter: 1741 loss: 1.33894464e-05
Iter: 1742 loss: 1.33484191e-05
Iter: 1743 loss: 1.33478734e-05
Iter: 1744 loss: 1.33474605e-05
Iter: 1745 loss: 1.33472113e-05
Iter: 1746 loss: 1.33450667e-05
Iter: 1747 loss: 1.3343104e-05
Iter: 1748 loss: 1.33425128e-05
Iter: 1749 loss: 1.33413623e-05
Iter: 1750 loss: 1.33404637e-05
Iter: 1751 loss: 1.33401245e-05
Iter: 1752 loss: 1.33382555e-05
Iter: 1753 loss: 1.33328031e-05
Iter: 1754 loss: 1.33580297e-05
Iter: 1755 loss: 1.33309768e-05
Iter: 1756 loss: 1.33262556e-05
Iter: 1757 loss: 1.33658104e-05
Iter: 1758 loss: 1.33258291e-05
Iter: 1759 loss: 1.33195135e-05
Iter: 1760 loss: 1.33207932e-05
Iter: 1761 loss: 1.33149606e-05
Iter: 1762 loss: 1.33238573e-05
Iter: 1763 loss: 1.33127887e-05
Iter: 1764 loss: 1.33104086e-05
Iter: 1765 loss: 1.33274953e-05
Iter: 1766 loss: 1.33102185e-05
Iter: 1767 loss: 1.33094691e-05
Iter: 1768 loss: 1.33067751e-05
Iter: 1769 loss: 1.33072881e-05
Iter: 1770 loss: 1.33044014e-05
Iter: 1771 loss: 1.32987625e-05
Iter: 1772 loss: 1.33860021e-05
Iter: 1773 loss: 1.32988189e-05
Iter: 1774 loss: 1.32968344e-05
Iter: 1775 loss: 1.3296727e-05
Iter: 1776 loss: 1.32962341e-05
Iter: 1777 loss: 1.33040467e-05
Iter: 1778 loss: 1.32961031e-05
Iter: 1779 loss: 1.32953228e-05
Iter: 1780 loss: 1.3293984e-05
Iter: 1781 loss: 1.33263929e-05
Iter: 1782 loss: 1.32940368e-05
Iter: 1783 loss: 1.32920723e-05
Iter: 1784 loss: 1.32859604e-05
Iter: 1785 loss: 1.32891455e-05
Iter: 1786 loss: 1.32804926e-05
Iter: 1787 loss: 1.32650493e-05
Iter: 1788 loss: 1.33481481e-05
Iter: 1789 loss: 1.32628966e-05
Iter: 1790 loss: 1.32539253e-05
Iter: 1791 loss: 1.32603545e-05
Iter: 1792 loss: 1.32480891e-05
Iter: 1793 loss: 1.32390969e-05
Iter: 1794 loss: 1.33211315e-05
Iter: 1795 loss: 1.32386158e-05
Iter: 1796 loss: 1.32354935e-05
Iter: 1797 loss: 1.32542409e-05
Iter: 1798 loss: 1.32353252e-05
Iter: 1799 loss: 1.32312489e-05
Iter: 1800 loss: 1.32465175e-05
Iter: 1801 loss: 1.32308e-05
Iter: 1802 loss: 1.32273744e-05
Iter: 1803 loss: 1.32242685e-05
Iter: 1804 loss: 1.32237437e-05
Iter: 1805 loss: 1.32206005e-05
Iter: 1806 loss: 1.323385e-05
Iter: 1807 loss: 1.32197583e-05
Iter: 1808 loss: 1.32172954e-05
Iter: 1809 loss: 1.32131554e-05
Iter: 1810 loss: 1.32130926e-05
Iter: 1811 loss: 1.32042132e-05
Iter: 1812 loss: 1.32424502e-05
Iter: 1813 loss: 1.32022151e-05
Iter: 1814 loss: 1.3199573e-05
Iter: 1815 loss: 1.31994548e-05
Iter: 1816 loss: 1.31982015e-05
Iter: 1817 loss: 1.31948691e-05
Iter: 1818 loss: 1.32289306e-05
Iter: 1819 loss: 1.31945581e-05
Iter: 1820 loss: 1.31924025e-05
Iter: 1821 loss: 1.31886463e-05
Iter: 1822 loss: 1.32806108e-05
Iter: 1823 loss: 1.31887809e-05
Iter: 1824 loss: 1.31856086e-05
Iter: 1825 loss: 1.31852194e-05
Iter: 1826 loss: 1.31831457e-05
Iter: 1827 loss: 1.31808802e-05
Iter: 1828 loss: 1.31769648e-05
Iter: 1829 loss: 1.3176812e-05
Iter: 1830 loss: 1.31725556e-05
Iter: 1831 loss: 1.31794914e-05
Iter: 1832 loss: 1.31704082e-05
Iter: 1833 loss: 1.31629959e-05
Iter: 1834 loss: 1.32052637e-05
Iter: 1835 loss: 1.316198e-05
Iter: 1836 loss: 1.31500092e-05
Iter: 1837 loss: 1.3210929e-05
Iter: 1838 loss: 1.31481029e-05
Iter: 1839 loss: 1.31441702e-05
Iter: 1840 loss: 1.3155096e-05
Iter: 1841 loss: 1.31430443e-05
Iter: 1842 loss: 1.31397446e-05
Iter: 1843 loss: 1.31469105e-05
Iter: 1844 loss: 1.31386478e-05
Iter: 1845 loss: 1.31335892e-05
Iter: 1846 loss: 1.31853449e-05
Iter: 1847 loss: 1.31332363e-05
Iter: 1848 loss: 1.31311481e-05
Iter: 1849 loss: 1.31253437e-05
Iter: 1850 loss: 1.31721135e-05
Iter: 1851 loss: 1.31244251e-05
Iter: 1852 loss: 1.31209044e-05
Iter: 1853 loss: 1.31188717e-05
Iter: 1854 loss: 1.31172601e-05
Iter: 1855 loss: 1.3113111e-05
Iter: 1856 loss: 1.31070865e-05
Iter: 1857 loss: 1.31068482e-05
Iter: 1858 loss: 1.3100811e-05
Iter: 1859 loss: 1.31085271e-05
Iter: 1860 loss: 1.30978924e-05
Iter: 1861 loss: 1.30921189e-05
Iter: 1862 loss: 1.3090651e-05
Iter: 1863 loss: 1.3087023e-05
Iter: 1864 loss: 1.30766675e-05
Iter: 1865 loss: 1.31028346e-05
Iter: 1866 loss: 1.30730741e-05
Iter: 1867 loss: 1.30661847e-05
Iter: 1868 loss: 1.30661456e-05
Iter: 1869 loss: 1.30639282e-05
Iter: 1870 loss: 1.30576118e-05
Iter: 1871 loss: 1.30803382e-05
Iter: 1872 loss: 1.30546923e-05
Iter: 1873 loss: 1.30595818e-05
Iter: 1874 loss: 1.30505432e-05
Iter: 1875 loss: 1.30481358e-05
Iter: 1876 loss: 1.30480767e-05
Iter: 1877 loss: 1.30467342e-05
Iter: 1878 loss: 1.30525086e-05
Iter: 1879 loss: 1.30467561e-05
Iter: 1880 loss: 1.30451444e-05
Iter: 1881 loss: 1.30469e-05
Iter: 1882 loss: 1.30444096e-05
Iter: 1883 loss: 1.30431654e-05
Iter: 1884 loss: 1.30418548e-05
Iter: 1885 loss: 1.30417711e-05
Iter: 1886 loss: 1.30392909e-05
Iter: 1887 loss: 1.30742983e-05
Iter: 1888 loss: 1.30393528e-05
Iter: 1889 loss: 1.3038356e-05
Iter: 1890 loss: 1.30359995e-05
Iter: 1891 loss: 1.30531917e-05
Iter: 1892 loss: 1.30356148e-05
Iter: 1893 loss: 1.30325243e-05
Iter: 1894 loss: 1.30389008e-05
Iter: 1895 loss: 1.30309581e-05
Iter: 1896 loss: 1.30279814e-05
Iter: 1897 loss: 1.30275948e-05
Iter: 1898 loss: 1.30250228e-05
Iter: 1899 loss: 1.30222179e-05
Iter: 1900 loss: 1.30624121e-05
Iter: 1901 loss: 1.30222361e-05
Iter: 1902 loss: 1.30189474e-05
Iter: 1903 loss: 1.30156695e-05
Iter: 1904 loss: 1.30148164e-05
Iter: 1905 loss: 1.3012992e-05
Iter: 1906 loss: 1.30123572e-05
Iter: 1907 loss: 1.30120043e-05
Iter: 1908 loss: 1.30112458e-05
Iter: 1909 loss: 1.30101962e-05
Iter: 1910 loss: 1.30149256e-05
Iter: 1911 loss: 1.30099979e-05
Iter: 1912 loss: 1.30094386e-05
Iter: 1913 loss: 1.30082099e-05
Iter: 1914 loss: 1.30079561e-05
Iter: 1915 loss: 1.30065391e-05
Iter: 1916 loss: 1.30034696e-05
Iter: 1917 loss: 1.30371918e-05
Iter: 1918 loss: 1.30030749e-05
Iter: 1919 loss: 1.30036615e-05
Iter: 1920 loss: 1.30009739e-05
Iter: 1921 loss: 1.29997316e-05
Iter: 1922 loss: 1.29954615e-05
Iter: 1923 loss: 1.29896853e-05
Iter: 1924 loss: 1.29886912e-05
Iter: 1925 loss: 1.2975248e-05
Iter: 1926 loss: 1.29738428e-05
Iter: 1927 loss: 1.29640894e-05
Iter: 1928 loss: 1.29575747e-05
Iter: 1929 loss: 1.29471555e-05
Iter: 1930 loss: 1.294712e-05
Iter: 1931 loss: 1.29394557e-05
Iter: 1932 loss: 1.29392838e-05
Iter: 1933 loss: 1.29324781e-05
Iter: 1934 loss: 1.2947412e-05
Iter: 1935 loss: 1.29297432e-05
Iter: 1936 loss: 1.29213959e-05
Iter: 1937 loss: 1.29573464e-05
Iter: 1938 loss: 1.29195323e-05
Iter: 1939 loss: 1.29168066e-05
Iter: 1940 loss: 1.29167793e-05
Iter: 1941 loss: 1.29164227e-05
Iter: 1942 loss: 1.29153232e-05
Iter: 1943 loss: 1.2914712e-05
Iter: 1944 loss: 1.29132659e-05
Iter: 1945 loss: 1.29429227e-05
Iter: 1946 loss: 1.29132914e-05
Iter: 1947 loss: 1.29119098e-05
Iter: 1948 loss: 1.29120344e-05
Iter: 1949 loss: 1.29107621e-05
Iter: 1950 loss: 1.29096134e-05
Iter: 1951 loss: 1.29096479e-05
Iter: 1952 loss: 1.29079153e-05
Iter: 1953 loss: 1.29058944e-05
Iter: 1954 loss: 1.29059299e-05
Iter: 1955 loss: 1.29021009e-05
Iter: 1956 loss: 1.28949505e-05
Iter: 1957 loss: 1.30327926e-05
Iter: 1958 loss: 1.28949141e-05
Iter: 1959 loss: 1.28827296e-05
Iter: 1960 loss: 1.29937907e-05
Iter: 1961 loss: 1.28821084e-05
Iter: 1962 loss: 1.28757e-05
Iter: 1963 loss: 1.2883711e-05
Iter: 1964 loss: 1.28722941e-05
Iter: 1965 loss: 1.28654965e-05
Iter: 1966 loss: 1.28697366e-05
Iter: 1967 loss: 1.28608463e-05
Iter: 1968 loss: 1.2855975e-05
Iter: 1969 loss: 1.28550446e-05
Iter: 1970 loss: 1.28524907e-05
Iter: 1971 loss: 1.28523525e-05
Iter: 1972 loss: 1.28501561e-05
Iter: 1973 loss: 1.28787742e-05
Iter: 1974 loss: 1.28493766e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script72
+ '[' -r STOP.script72 ']'
+ MODEL='--load_model /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0/300_300_300_1 '
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0.4 /home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0.4
+ date
Sat Oct 31 14:23:24 EDT 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0/300_300_300_1 --function f1 --psi 0 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0.4/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 30 --learning_rate 0.001 --decay_rate 0.8 --loss_func weighted_MAPE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0e00566a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a0556950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0e00d07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a05c9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a05c9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0e00d0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a04618c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a0460598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a04606a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a04241e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a03bf840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a02e0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a02e0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a02d1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a02ad598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a02e0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a03709d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a050bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a051cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a050b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a04c9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a04741e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a04c9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a00dbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a00dbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a00dbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a00dbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a01b2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0987dc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0987dca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0987f1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0987dce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0987dcc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a016b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a0295158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa0a0081f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0045275735
test_loss: 0.0044381656
train_loss: 0.0027822363
test_loss: 0.00284156
train_loss: 0.0024062502
test_loss: 0.0024753755
train_loss: 0.0023398274
test_loss: 0.0023654136
train_loss: 0.0022473973
test_loss: 0.0023263784
train_loss: 0.002240399
test_loss: 0.002315279
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output72/f1_psi0_phi0.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output73/f1_psi0_phi0.4/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bda0ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bd9e2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bd9e3048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bd994620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bd984598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bd984840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28bd926ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28953f7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28953f7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895403158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28953f7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895403730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28953bcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28953431e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895339f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895399ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895397378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f289531f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870382d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895397510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703178c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f287034c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2895310510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870287048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870287598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870291ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702b1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702b60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702dc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702422f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702dc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702dc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870200598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702426a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870200e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870218378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.30101271e-06
Iter: 2 loss: 8.30755562e-06
Iter: 3 loss: 8.27982e-06
Iter: 4 loss: 8.26620635e-06
Iter: 5 loss: 8.28429438e-06
Iter: 6 loss: 8.2593815e-06
Iter: 7 loss: 8.25387e-06
Iter: 8 loss: 8.25631e-06
Iter: 9 loss: 8.25015468e-06
Iter: 10 loss: 8.24267136e-06
Iter: 11 loss: 8.30571e-06
Iter: 12 loss: 8.24217932e-06
Iter: 13 loss: 8.23736809e-06
Iter: 14 loss: 8.24862764e-06
Iter: 15 loss: 8.23569917e-06
Iter: 16 loss: 8.22915081e-06
Iter: 17 loss: 8.23506798e-06
Iter: 18 loss: 8.22537e-06
Iter: 19 loss: 8.21999856e-06
Iter: 20 loss: 8.23479604e-06
Iter: 21 loss: 8.21833055e-06
Iter: 22 loss: 8.20931928e-06
Iter: 23 loss: 8.20025e-06
Iter: 24 loss: 8.19847264e-06
Iter: 25 loss: 8.18615626e-06
Iter: 26 loss: 8.17953332e-06
Iter: 27 loss: 8.17399086e-06
Iter: 28 loss: 8.17091586e-06
Iter: 29 loss: 8.16566171e-06
Iter: 30 loss: 8.15837848e-06
Iter: 31 loss: 8.14336727e-06
Iter: 32 loss: 8.411831e-06
Iter: 33 loss: 8.14310624e-06
Iter: 34 loss: 8.13012139e-06
Iter: 35 loss: 8.14086e-06
Iter: 36 loss: 8.12236249e-06
Iter: 37 loss: 8.11096743e-06
Iter: 38 loss: 8.1710823e-06
Iter: 39 loss: 8.10914207e-06
Iter: 40 loss: 8.10508209e-06
Iter: 41 loss: 8.10379788e-06
Iter: 42 loss: 8.09872836e-06
Iter: 43 loss: 8.09174526e-06
Iter: 44 loss: 8.09144149e-06
Iter: 45 loss: 8.08622826e-06
Iter: 46 loss: 8.10111305e-06
Iter: 47 loss: 8.08458572e-06
Iter: 48 loss: 8.08129153e-06
Iter: 49 loss: 8.08112e-06
Iter: 50 loss: 8.07844572e-06
Iter: 51 loss: 8.07558263e-06
Iter: 52 loss: 8.07516699e-06
Iter: 53 loss: 8.06975731e-06
Iter: 54 loss: 8.0939908e-06
Iter: 55 loss: 8.06873049e-06
Iter: 56 loss: 8.06473145e-06
Iter: 57 loss: 8.07261495e-06
Iter: 58 loss: 8.06313892e-06
Iter: 59 loss: 8.05758464e-06
Iter: 60 loss: 8.06694152e-06
Iter: 61 loss: 8.05508262e-06
Iter: 62 loss: 8.05061245e-06
Iter: 63 loss: 8.04177762e-06
Iter: 64 loss: 8.21158756e-06
Iter: 65 loss: 8.04167485e-06
Iter: 66 loss: 8.03822149e-06
Iter: 67 loss: 8.03589683e-06
Iter: 68 loss: 8.03070179e-06
Iter: 69 loss: 8.01931219e-06
Iter: 70 loss: 8.19015531e-06
Iter: 71 loss: 8.01883471e-06
Iter: 72 loss: 8.00796624e-06
Iter: 73 loss: 8.00798807e-06
Iter: 74 loss: 7.99923782e-06
Iter: 75 loss: 7.9869933e-06
Iter: 76 loss: 8.12764483e-06
Iter: 77 loss: 7.98675319e-06
Iter: 78 loss: 7.97721259e-06
Iter: 79 loss: 8.10152596e-06
Iter: 80 loss: 7.97716e-06
Iter: 81 loss: 7.97312e-06
Iter: 82 loss: 7.96327549e-06
Iter: 83 loss: 8.06319804e-06
Iter: 84 loss: 7.96207e-06
Iter: 85 loss: 7.95740925e-06
Iter: 86 loss: 7.95643791e-06
Iter: 87 loss: 7.95041342e-06
Iter: 88 loss: 7.95244523e-06
Iter: 89 loss: 7.94616062e-06
Iter: 90 loss: 7.94088737e-06
Iter: 91 loss: 7.9637739e-06
Iter: 92 loss: 7.93982053e-06
Iter: 93 loss: 7.93335767e-06
Iter: 94 loss: 7.93531763e-06
Iter: 95 loss: 7.92865103e-06
Iter: 96 loss: 7.9220008e-06
Iter: 97 loss: 7.9791389e-06
Iter: 98 loss: 7.92159426e-06
Iter: 99 loss: 7.91560433e-06
Iter: 100 loss: 7.90411468e-06
Iter: 101 loss: 8.14524901e-06
Iter: 102 loss: 7.90400736e-06
Iter: 103 loss: 7.89558271e-06
Iter: 104 loss: 7.98560541e-06
Iter: 105 loss: 7.89536352e-06
Iter: 106 loss: 7.88532088e-06
Iter: 107 loss: 7.90130343e-06
Iter: 108 loss: 7.88069519e-06
Iter: 109 loss: 7.8724479e-06
Iter: 110 loss: 7.85499469e-06
Iter: 111 loss: 8.14004488e-06
Iter: 112 loss: 7.85449811e-06
Iter: 113 loss: 7.83570431e-06
Iter: 114 loss: 7.9444826e-06
Iter: 115 loss: 7.8332032e-06
Iter: 116 loss: 7.82344068e-06
Iter: 117 loss: 7.82237657e-06
Iter: 118 loss: 7.81432209e-06
Iter: 119 loss: 7.79641414e-06
Iter: 120 loss: 8.04219235e-06
Iter: 121 loss: 7.79541097e-06
Iter: 122 loss: 7.78015419e-06
Iter: 123 loss: 7.86700821e-06
Iter: 124 loss: 7.77810146e-06
Iter: 125 loss: 7.768248e-06
Iter: 126 loss: 7.76794059e-06
Iter: 127 loss: 7.76286834e-06
Iter: 128 loss: 7.75264925e-06
Iter: 129 loss: 7.94540119e-06
Iter: 130 loss: 7.75254921e-06
Iter: 131 loss: 7.74264481e-06
Iter: 132 loss: 7.7426148e-06
Iter: 133 loss: 7.73666761e-06
Iter: 134 loss: 7.73233205e-06
Iter: 135 loss: 7.73027296e-06
Iter: 136 loss: 7.71952182e-06
Iter: 137 loss: 7.76775232e-06
Iter: 138 loss: 7.71743453e-06
Iter: 139 loss: 7.71037e-06
Iter: 140 loss: 7.69951475e-06
Iter: 141 loss: 7.69935832e-06
Iter: 142 loss: 7.69143207e-06
Iter: 143 loss: 7.69000144e-06
Iter: 144 loss: 7.68302198e-06
Iter: 145 loss: 7.66625089e-06
Iter: 146 loss: 7.8483954e-06
Iter: 147 loss: 7.66455196e-06
Iter: 148 loss: 7.64512e-06
Iter: 149 loss: 7.64492e-06
Iter: 150 loss: 7.62960735e-06
Iter: 151 loss: 7.62226136e-06
Iter: 152 loss: 7.61704086e-06
Iter: 153 loss: 7.60500689e-06
Iter: 154 loss: 7.58254419e-06
Iter: 155 loss: 8.0820646e-06
Iter: 156 loss: 7.58250826e-06
Iter: 157 loss: 7.56419104e-06
Iter: 158 loss: 7.62524633e-06
Iter: 159 loss: 7.55914743e-06
Iter: 160 loss: 7.54383e-06
Iter: 161 loss: 7.5435928e-06
Iter: 162 loss: 7.53525592e-06
Iter: 163 loss: 7.52343749e-06
Iter: 164 loss: 7.52299729e-06
Iter: 165 loss: 7.51192283e-06
Iter: 166 loss: 7.51174503e-06
Iter: 167 loss: 7.50522213e-06
Iter: 168 loss: 7.49817082e-06
Iter: 169 loss: 7.49708488e-06
Iter: 170 loss: 7.48403454e-06
Iter: 171 loss: 7.54359371e-06
Iter: 172 loss: 7.48154253e-06
Iter: 173 loss: 7.47141621e-06
Iter: 174 loss: 7.47080958e-06
Iter: 175 loss: 7.46314e-06
Iter: 176 loss: 7.44708404e-06
Iter: 177 loss: 7.59569912e-06
Iter: 178 loss: 7.44640056e-06
Iter: 179 loss: 7.43879809e-06
Iter: 180 loss: 7.42169368e-06
Iter: 181 loss: 7.65396544e-06
Iter: 182 loss: 7.42066595e-06
Iter: 183 loss: 7.40262385e-06
Iter: 184 loss: 7.47797139e-06
Iter: 185 loss: 7.39878033e-06
Iter: 186 loss: 7.37967048e-06
Iter: 187 loss: 7.51634389e-06
Iter: 188 loss: 7.37799883e-06
Iter: 189 loss: 7.36630454e-06
Iter: 190 loss: 7.3510746e-06
Iter: 191 loss: 7.35005506e-06
Iter: 192 loss: 7.3352935e-06
Iter: 193 loss: 7.46669457e-06
Iter: 194 loss: 7.33461866e-06
Iter: 195 loss: 7.31805267e-06
Iter: 196 loss: 7.37337359e-06
Iter: 197 loss: 7.3135152e-06
Iter: 198 loss: 7.30285046e-06
Iter: 199 loss: 7.30619786e-06
Iter: 200 loss: 7.29516751e-06
Iter: 201 loss: 7.27694032e-06
Iter: 202 loss: 7.34768037e-06
Iter: 203 loss: 7.27271527e-06
Iter: 204 loss: 7.26124517e-06
Iter: 205 loss: 7.27693669e-06
Iter: 206 loss: 7.25554901e-06
Iter: 207 loss: 7.24037636e-06
Iter: 208 loss: 7.27103725e-06
Iter: 209 loss: 7.23425637e-06
Iter: 210 loss: 7.22298819e-06
Iter: 211 loss: 7.29551539e-06
Iter: 212 loss: 7.22179448e-06
Iter: 213 loss: 7.20935714e-06
Iter: 214 loss: 7.22259301e-06
Iter: 215 loss: 7.20252137e-06
Iter: 216 loss: 7.1940467e-06
Iter: 217 loss: 7.18100637e-06
Iter: 218 loss: 7.1808272e-06
Iter: 219 loss: 7.17370131e-06
Iter: 220 loss: 7.17222611e-06
Iter: 221 loss: 7.16259228e-06
Iter: 222 loss: 7.15160922e-06
Iter: 223 loss: 7.1502227e-06
Iter: 224 loss: 7.13613099e-06
Iter: 225 loss: 7.13482405e-06
Iter: 226 loss: 7.12446217e-06
Iter: 227 loss: 7.11256416e-06
Iter: 228 loss: 7.11192297e-06
Iter: 229 loss: 7.10048926e-06
Iter: 230 loss: 7.08749349e-06
Iter: 231 loss: 7.08585594e-06
Iter: 232 loss: 7.0731644e-06
Iter: 233 loss: 7.26167127e-06
Iter: 234 loss: 7.07317577e-06
Iter: 235 loss: 7.06281526e-06
Iter: 236 loss: 7.05710772e-06
Iter: 237 loss: 7.05256434e-06
Iter: 238 loss: 7.04137119e-06
Iter: 239 loss: 7.14479484e-06
Iter: 240 loss: 7.04088598e-06
Iter: 241 loss: 7.03243632e-06
Iter: 242 loss: 7.02605848e-06
Iter: 243 loss: 7.02329544e-06
Iter: 244 loss: 7.01354293e-06
Iter: 245 loss: 7.01340241e-06
Iter: 246 loss: 7.00776764e-06
Iter: 247 loss: 6.99564862e-06
Iter: 248 loss: 7.18471074e-06
Iter: 249 loss: 6.99523298e-06
Iter: 250 loss: 6.98265694e-06
Iter: 251 loss: 6.99857264e-06
Iter: 252 loss: 6.97618725e-06
Iter: 253 loss: 6.967231e-06
Iter: 254 loss: 6.9665507e-06
Iter: 255 loss: 6.95918106e-06
Iter: 256 loss: 6.94500341e-06
Iter: 257 loss: 7.23508401e-06
Iter: 258 loss: 6.94494747e-06
Iter: 259 loss: 6.93336642e-06
Iter: 260 loss: 7.04296508e-06
Iter: 261 loss: 6.93288757e-06
Iter: 262 loss: 6.92139929e-06
Iter: 263 loss: 6.96489224e-06
Iter: 264 loss: 6.91860669e-06
Iter: 265 loss: 6.9109833e-06
Iter: 266 loss: 6.9273392e-06
Iter: 267 loss: 6.9080088e-06
Iter: 268 loss: 6.8991535e-06
Iter: 269 loss: 6.92985441e-06
Iter: 270 loss: 6.89683611e-06
Iter: 271 loss: 6.8896552e-06
Iter: 272 loss: 6.89557191e-06
Iter: 273 loss: 6.8853883e-06
Iter: 274 loss: 6.87571264e-06
Iter: 275 loss: 6.90065053e-06
Iter: 276 loss: 6.87239481e-06
Iter: 277 loss: 6.86458679e-06
Iter: 278 loss: 6.89735634e-06
Iter: 279 loss: 6.86292469e-06
Iter: 280 loss: 6.85244231e-06
Iter: 281 loss: 6.8536965e-06
Iter: 282 loss: 6.8444715e-06
Iter: 283 loss: 6.83466806e-06
Iter: 284 loss: 6.82779591e-06
Iter: 285 loss: 6.82432164e-06
Iter: 286 loss: 6.81616712e-06
Iter: 287 loss: 6.8157683e-06
Iter: 288 loss: 6.80696485e-06
Iter: 289 loss: 6.80861513e-06
Iter: 290 loss: 6.80039193e-06
Iter: 291 loss: 6.79253299e-06
Iter: 292 loss: 6.80101039e-06
Iter: 293 loss: 6.7882379e-06
Iter: 294 loss: 6.78124798e-06
Iter: 295 loss: 6.78114611e-06
Iter: 296 loss: 6.77647085e-06
Iter: 297 loss: 6.77154367e-06
Iter: 298 loss: 6.77069056e-06
Iter: 299 loss: 6.76296122e-06
Iter: 300 loss: 6.82896871e-06
Iter: 301 loss: 6.76254513e-06
Iter: 302 loss: 6.75705451e-06
Iter: 303 loss: 6.75639421e-06
Iter: 304 loss: 6.7524943e-06
Iter: 305 loss: 6.74486409e-06
Iter: 306 loss: 6.77575645e-06
Iter: 307 loss: 6.74319836e-06
Iter: 308 loss: 6.73633e-06
Iter: 309 loss: 6.74407374e-06
Iter: 310 loss: 6.73260729e-06
Iter: 311 loss: 6.72417536e-06
Iter: 312 loss: 6.79447794e-06
Iter: 313 loss: 6.72365968e-06
Iter: 314 loss: 6.71845601e-06
Iter: 315 loss: 6.70670579e-06
Iter: 316 loss: 6.86666863e-06
Iter: 317 loss: 6.70602321e-06
Iter: 318 loss: 6.69617657e-06
Iter: 319 loss: 6.80266703e-06
Iter: 320 loss: 6.69599876e-06
Iter: 321 loss: 6.68697976e-06
Iter: 322 loss: 6.73815e-06
Iter: 323 loss: 6.6857433e-06
Iter: 324 loss: 6.67994118e-06
Iter: 325 loss: 6.67175527e-06
Iter: 326 loss: 6.67143104e-06
Iter: 327 loss: 6.66682308e-06
Iter: 328 loss: 6.66573033e-06
Iter: 329 loss: 6.66126107e-06
Iter: 330 loss: 6.66009146e-06
Iter: 331 loss: 6.65728658e-06
Iter: 332 loss: 6.65297e-06
Iter: 333 loss: 6.69758629e-06
Iter: 334 loss: 6.65286098e-06
Iter: 335 loss: 6.64926756e-06
Iter: 336 loss: 6.64628624e-06
Iter: 337 loss: 6.64521758e-06
Iter: 338 loss: 6.63927312e-06
Iter: 339 loss: 6.66343885e-06
Iter: 340 loss: 6.63799801e-06
Iter: 341 loss: 6.63243554e-06
Iter: 342 loss: 6.63729588e-06
Iter: 343 loss: 6.62919228e-06
Iter: 344 loss: 6.62380307e-06
Iter: 345 loss: 6.69651308e-06
Iter: 346 loss: 6.62379807e-06
Iter: 347 loss: 6.61963804e-06
Iter: 348 loss: 6.61106333e-06
Iter: 349 loss: 6.76111631e-06
Iter: 350 loss: 6.6108837e-06
Iter: 351 loss: 6.60189244e-06
Iter: 352 loss: 6.62025195e-06
Iter: 353 loss: 6.59829811e-06
Iter: 354 loss: 6.59011494e-06
Iter: 355 loss: 6.59009402e-06
Iter: 356 loss: 6.58485851e-06
Iter: 357 loss: 6.5770555e-06
Iter: 358 loss: 6.57688952e-06
Iter: 359 loss: 6.57133114e-06
Iter: 360 loss: 6.57131932e-06
Iter: 361 loss: 6.56560042e-06
Iter: 362 loss: 6.56585235e-06
Iter: 363 loss: 6.56117936e-06
Iter: 364 loss: 6.55506528e-06
Iter: 365 loss: 6.58917543e-06
Iter: 366 loss: 6.55421809e-06
Iter: 367 loss: 6.54800351e-06
Iter: 368 loss: 6.55378471e-06
Iter: 369 loss: 6.54442556e-06
Iter: 370 loss: 6.53880306e-06
Iter: 371 loss: 6.56287284e-06
Iter: 372 loss: 6.53763027e-06
Iter: 373 loss: 6.53230109e-06
Iter: 374 loss: 6.5352333e-06
Iter: 375 loss: 6.52881863e-06
Iter: 376 loss: 6.52373546e-06
Iter: 377 loss: 6.58874e-06
Iter: 378 loss: 6.52369818e-06
Iter: 379 loss: 6.5192171e-06
Iter: 380 loss: 6.51402115e-06
Iter: 381 loss: 6.51336813e-06
Iter: 382 loss: 6.50747324e-06
Iter: 383 loss: 6.51452137e-06
Iter: 384 loss: 6.50436505e-06
Iter: 385 loss: 6.50098264e-06
Iter: 386 loss: 6.50049469e-06
Iter: 387 loss: 6.49729827e-06
Iter: 388 loss: 6.49164849e-06
Iter: 389 loss: 6.49167805e-06
Iter: 390 loss: 6.48639434e-06
Iter: 391 loss: 6.52505605e-06
Iter: 392 loss: 6.486026e-06
Iter: 393 loss: 6.48035211e-06
Iter: 394 loss: 6.49982121e-06
Iter: 395 loss: 6.47887828e-06
Iter: 396 loss: 6.4749147e-06
Iter: 397 loss: 6.48157629e-06
Iter: 398 loss: 6.47312027e-06
Iter: 399 loss: 6.46769e-06
Iter: 400 loss: 6.47762045e-06
Iter: 401 loss: 6.46531453e-06
Iter: 402 loss: 6.45990394e-06
Iter: 403 loss: 6.46632907e-06
Iter: 404 loss: 6.45704949e-06
Iter: 405 loss: 6.4496694e-06
Iter: 406 loss: 6.46086028e-06
Iter: 407 loss: 6.44617921e-06
Iter: 408 loss: 6.44028933e-06
Iter: 409 loss: 6.49997492e-06
Iter: 410 loss: 6.44014426e-06
Iter: 411 loss: 6.43469139e-06
Iter: 412 loss: 6.4383994e-06
Iter: 413 loss: 6.43127851e-06
Iter: 414 loss: 6.42651776e-06
Iter: 415 loss: 6.42202576e-06
Iter: 416 loss: 6.42090436e-06
Iter: 417 loss: 6.41681254e-06
Iter: 418 loss: 6.41640099e-06
Iter: 419 loss: 6.41207953e-06
Iter: 420 loss: 6.40953112e-06
Iter: 421 loss: 6.40773033e-06
Iter: 422 loss: 6.40304279e-06
Iter: 423 loss: 6.4153719e-06
Iter: 424 loss: 6.40146936e-06
Iter: 425 loss: 6.39627524e-06
Iter: 426 loss: 6.44169722e-06
Iter: 427 loss: 6.3960324e-06
Iter: 428 loss: 6.39279642e-06
Iter: 429 loss: 6.39255086e-06
Iter: 430 loss: 6.39016e-06
Iter: 431 loss: 6.38521169e-06
Iter: 432 loss: 6.41119823e-06
Iter: 433 loss: 6.38446e-06
Iter: 434 loss: 6.38080473e-06
Iter: 435 loss: 6.38125221e-06
Iter: 436 loss: 6.37796029e-06
Iter: 437 loss: 6.37254334e-06
Iter: 438 loss: 6.38960137e-06
Iter: 439 loss: 6.37095036e-06
Iter: 440 loss: 6.36670393e-06
Iter: 441 loss: 6.38394431e-06
Iter: 442 loss: 6.36579261e-06
Iter: 443 loss: 6.36080131e-06
Iter: 444 loss: 6.37052835e-06
Iter: 445 loss: 6.35871947e-06
Iter: 446 loss: 6.35439665e-06
Iter: 447 loss: 6.34905382e-06
Iter: 448 loss: 6.34860453e-06
Iter: 449 loss: 6.34341086e-06
Iter: 450 loss: 6.42272425e-06
Iter: 451 loss: 6.34340631e-06
Iter: 452 loss: 6.33791115e-06
Iter: 453 loss: 6.34244725e-06
Iter: 454 loss: 6.33465515e-06
Iter: 455 loss: 6.329597e-06
Iter: 456 loss: 6.33118816e-06
Iter: 457 loss: 6.32601495e-06
Iter: 458 loss: 6.3207026e-06
Iter: 459 loss: 6.32069532e-06
Iter: 460 loss: 6.3172788e-06
Iter: 461 loss: 6.31339663e-06
Iter: 462 loss: 6.31286366e-06
Iter: 463 loss: 6.30689965e-06
Iter: 464 loss: 6.35641391e-06
Iter: 465 loss: 6.30653e-06
Iter: 466 loss: 6.30216391e-06
Iter: 467 loss: 6.30126897e-06
Iter: 468 loss: 6.29841315e-06
Iter: 469 loss: 6.29230817e-06
Iter: 470 loss: 6.3208272e-06
Iter: 471 loss: 6.2911804e-06
Iter: 472 loss: 6.28648831e-06
Iter: 473 loss: 6.29508486e-06
Iter: 474 loss: 6.2844565e-06
Iter: 475 loss: 6.27883128e-06
Iter: 476 loss: 6.31593184e-06
Iter: 477 loss: 6.27828103e-06
Iter: 478 loss: 6.27477766e-06
Iter: 479 loss: 6.26885276e-06
Iter: 480 loss: 6.26884957e-06
Iter: 481 loss: 6.26327437e-06
Iter: 482 loss: 6.31542389e-06
Iter: 483 loss: 6.26304745e-06
Iter: 484 loss: 6.25785742e-06
Iter: 485 loss: 6.28156613e-06
Iter: 486 loss: 6.25682242e-06
Iter: 487 loss: 6.25352686e-06
Iter: 488 loss: 6.25043367e-06
Iter: 489 loss: 6.24965969e-06
Iter: 490 loss: 6.24569338e-06
Iter: 491 loss: 6.24563472e-06
Iter: 492 loss: 6.24238646e-06
Iter: 493 loss: 6.23814321e-06
Iter: 494 loss: 6.2378549e-06
Iter: 495 loss: 6.23261349e-06
Iter: 496 loss: 6.28783482e-06
Iter: 497 loss: 6.23246e-06
Iter: 498 loss: 6.22836251e-06
Iter: 499 loss: 6.22517564e-06
Iter: 500 loss: 6.22387142e-06
Iter: 501 loss: 6.21744857e-06
Iter: 502 loss: 6.252204e-06
Iter: 503 loss: 6.21652725e-06
Iter: 504 loss: 6.2113877e-06
Iter: 505 loss: 6.2164454e-06
Iter: 506 loss: 6.20847322e-06
Iter: 507 loss: 6.20272567e-06
Iter: 508 loss: 6.26261544e-06
Iter: 509 loss: 6.20255287e-06
Iter: 510 loss: 6.19900356e-06
Iter: 511 loss: 6.19333832e-06
Iter: 512 loss: 6.19329921e-06
Iter: 513 loss: 6.1879673e-06
Iter: 514 loss: 6.22536754e-06
Iter: 515 loss: 6.18749118e-06
Iter: 516 loss: 6.18271224e-06
Iter: 517 loss: 6.20941864e-06
Iter: 518 loss: 6.18200329e-06
Iter: 519 loss: 6.17829346e-06
Iter: 520 loss: 6.17336855e-06
Iter: 521 loss: 6.17307614e-06
Iter: 522 loss: 6.16937086e-06
Iter: 523 loss: 6.16906118e-06
Iter: 524 loss: 6.16574607e-06
Iter: 525 loss: 6.16187754e-06
Iter: 526 loss: 6.16140824e-06
Iter: 527 loss: 6.15672434e-06
Iter: 528 loss: 6.20832589e-06
Iter: 529 loss: 6.15660747e-06
Iter: 530 loss: 6.15279896e-06
Iter: 531 loss: 6.15183581e-06
Iter: 532 loss: 6.14940745e-06
Iter: 533 loss: 6.14450346e-06
Iter: 534 loss: 6.16840134e-06
Iter: 535 loss: 6.14364217e-06
Iter: 536 loss: 6.13935345e-06
Iter: 537 loss: 6.13923385e-06
Iter: 538 loss: 6.13589054e-06
Iter: 539 loss: 6.13086831e-06
Iter: 540 loss: 6.20748415e-06
Iter: 541 loss: 6.1308383e-06
Iter: 542 loss: 6.12749363e-06
Iter: 543 loss: 6.12110853e-06
Iter: 544 loss: 6.26403e-06
Iter: 545 loss: 6.12107715e-06
Iter: 546 loss: 6.11476935e-06
Iter: 547 loss: 6.1521705e-06
Iter: 548 loss: 6.11402e-06
Iter: 549 loss: 6.10868483e-06
Iter: 550 loss: 6.1494793e-06
Iter: 551 loss: 6.10828101e-06
Iter: 552 loss: 6.10422694e-06
Iter: 553 loss: 6.09898689e-06
Iter: 554 loss: 6.09861854e-06
Iter: 555 loss: 6.09468225e-06
Iter: 556 loss: 6.09447079e-06
Iter: 557 loss: 6.09069048e-06
Iter: 558 loss: 6.0896482e-06
Iter: 559 loss: 6.08724577e-06
Iter: 560 loss: 6.08360278e-06
Iter: 561 loss: 6.11851192e-06
Iter: 562 loss: 6.08343635e-06
Iter: 563 loss: 6.08028222e-06
Iter: 564 loss: 6.0789489e-06
Iter: 565 loss: 6.07726088e-06
Iter: 566 loss: 6.07274706e-06
Iter: 567 loss: 6.09127892e-06
Iter: 568 loss: 6.07178026e-06
Iter: 569 loss: 6.06725644e-06
Iter: 570 loss: 6.06750064e-06
Iter: 571 loss: 6.06372123e-06
Iter: 572 loss: 6.05911691e-06
Iter: 573 loss: 6.05910736e-06
Iter: 574 loss: 6.05563946e-06
Iter: 575 loss: 6.05029209e-06
Iter: 576 loss: 6.05019977e-06
Iter: 577 loss: 6.04499064e-06
Iter: 578 loss: 6.069351e-06
Iter: 579 loss: 6.04406296e-06
Iter: 580 loss: 6.03949911e-06
Iter: 581 loss: 6.07331413e-06
Iter: 582 loss: 6.03910757e-06
Iter: 583 loss: 6.03527815e-06
Iter: 584 loss: 6.03089939e-06
Iter: 585 loss: 6.03038734e-06
Iter: 586 loss: 6.02646787e-06
Iter: 587 loss: 6.02640921e-06
Iter: 588 loss: 6.02264709e-06
Iter: 589 loss: 6.02257387e-06
Iter: 590 loss: 6.01958436e-06
Iter: 591 loss: 6.01549527e-06
Iter: 592 loss: 6.03845319e-06
Iter: 593 loss: 6.01496504e-06
Iter: 594 loss: 6.01047941e-06
Iter: 595 loss: 6.01067495e-06
Iter: 596 loss: 6.00696694e-06
Iter: 597 loss: 6.00132262e-06
Iter: 598 loss: 6.02024e-06
Iter: 599 loss: 5.99975192e-06
Iter: 600 loss: 5.99372834e-06
Iter: 601 loss: 5.99662371e-06
Iter: 602 loss: 5.98973838e-06
Iter: 603 loss: 5.98497536e-06
Iter: 604 loss: 5.98488896e-06
Iter: 605 loss: 5.98111455e-06
Iter: 606 loss: 5.97543658e-06
Iter: 607 loss: 5.97532289e-06
Iter: 608 loss: 5.96962673e-06
Iter: 609 loss: 5.99684518e-06
Iter: 610 loss: 5.96855216e-06
Iter: 611 loss: 5.96414066e-06
Iter: 612 loss: 6.00949807e-06
Iter: 613 loss: 5.9639915e-06
Iter: 614 loss: 5.96067e-06
Iter: 615 loss: 5.95824e-06
Iter: 616 loss: 5.95708116e-06
Iter: 617 loss: 5.95346319e-06
Iter: 618 loss: 5.98539e-06
Iter: 619 loss: 5.95327674e-06
Iter: 620 loss: 5.94922494e-06
Iter: 621 loss: 5.9541e-06
Iter: 622 loss: 5.94711855e-06
Iter: 623 loss: 5.94368612e-06
Iter: 624 loss: 5.95626352e-06
Iter: 625 loss: 5.94279209e-06
Iter: 626 loss: 5.9385975e-06
Iter: 627 loss: 5.94012363e-06
Iter: 628 loss: 5.935638e-06
Iter: 629 loss: 5.93056393e-06
Iter: 630 loss: 5.94612857e-06
Iter: 631 loss: 5.92905963e-06
Iter: 632 loss: 5.92356673e-06
Iter: 633 loss: 5.92780816e-06
Iter: 634 loss: 5.92020524e-06
Iter: 635 loss: 5.91555e-06
Iter: 636 loss: 5.9812819e-06
Iter: 637 loss: 5.91551907e-06
Iter: 638 loss: 5.91128537e-06
Iter: 639 loss: 5.90734817e-06
Iter: 640 loss: 5.90631407e-06
Iter: 641 loss: 5.90143645e-06
Iter: 642 loss: 5.91719436e-06
Iter: 643 loss: 5.9000522e-06
Iter: 644 loss: 5.89566025e-06
Iter: 645 loss: 5.93459663e-06
Iter: 646 loss: 5.89549109e-06
Iter: 647 loss: 5.89178e-06
Iter: 648 loss: 5.88963439e-06
Iter: 649 loss: 5.88807507e-06
Iter: 650 loss: 5.8839305e-06
Iter: 651 loss: 5.91191701e-06
Iter: 652 loss: 5.88354669e-06
Iter: 653 loss: 5.8789592e-06
Iter: 654 loss: 5.8887963e-06
Iter: 655 loss: 5.87718387e-06
Iter: 656 loss: 5.87342447e-06
Iter: 657 loss: 5.88166813e-06
Iter: 658 loss: 5.87196791e-06
Iter: 659 loss: 5.86702345e-06
Iter: 660 loss: 5.87514432e-06
Iter: 661 loss: 5.86471651e-06
Iter: 662 loss: 5.86004899e-06
Iter: 663 loss: 5.87062823e-06
Iter: 664 loss: 5.85827456e-06
Iter: 665 loss: 5.85269254e-06
Iter: 666 loss: 5.85739144e-06
Iter: 667 loss: 5.84938925e-06
Iter: 668 loss: 5.84482132e-06
Iter: 669 loss: 5.90743821e-06
Iter: 670 loss: 5.8447531e-06
Iter: 671 loss: 5.84061763e-06
Iter: 672 loss: 5.83860492e-06
Iter: 673 loss: 5.83669043e-06
Iter: 674 loss: 5.83237e-06
Iter: 675 loss: 5.84382178e-06
Iter: 676 loss: 5.83091605e-06
Iter: 677 loss: 5.82735356e-06
Iter: 678 loss: 5.86883652e-06
Iter: 679 loss: 5.82726e-06
Iter: 680 loss: 5.82445091e-06
Iter: 681 loss: 5.82290613e-06
Iter: 682 loss: 5.82164239e-06
Iter: 683 loss: 5.81810491e-06
Iter: 684 loss: 5.83081783e-06
Iter: 685 loss: 5.81720087e-06
Iter: 686 loss: 5.81274e-06
Iter: 687 loss: 5.83143174e-06
Iter: 688 loss: 5.81176664e-06
Iter: 689 loss: 5.80865253e-06
Iter: 690 loss: 5.81118775e-06
Iter: 691 loss: 5.80674941e-06
Iter: 692 loss: 5.80189e-06
Iter: 693 loss: 5.81193672e-06
Iter: 694 loss: 5.79989683e-06
Iter: 695 loss: 5.79544e-06
Iter: 696 loss: 5.8041669e-06
Iter: 697 loss: 5.79353855e-06
Iter: 698 loss: 5.78819e-06
Iter: 699 loss: 5.79626794e-06
Iter: 700 loss: 5.78561139e-06
Iter: 701 loss: 5.78125218e-06
Iter: 702 loss: 5.81948e-06
Iter: 703 loss: 5.78104937e-06
Iter: 704 loss: 5.77659284e-06
Iter: 705 loss: 5.77834908e-06
Iter: 706 loss: 5.77355149e-06
Iter: 707 loss: 5.76986849e-06
Iter: 708 loss: 5.77430865e-06
Iter: 709 loss: 5.76789307e-06
Iter: 710 loss: 5.76406273e-06
Iter: 711 loss: 5.80153e-06
Iter: 712 loss: 5.76389402e-06
Iter: 713 loss: 5.76050388e-06
Iter: 714 loss: 5.7597e-06
Iter: 715 loss: 5.7575071e-06
Iter: 716 loss: 5.75362128e-06
Iter: 717 loss: 5.76766342e-06
Iter: 718 loss: 5.75261674e-06
Iter: 719 loss: 5.74836349e-06
Iter: 720 loss: 5.77383435e-06
Iter: 721 loss: 5.74786873e-06
Iter: 722 loss: 5.74504975e-06
Iter: 723 loss: 5.74651085e-06
Iter: 724 loss: 5.74314799e-06
Iter: 725 loss: 5.73904163e-06
Iter: 726 loss: 5.75460581e-06
Iter: 727 loss: 5.7380621e-06
Iter: 728 loss: 5.73487796e-06
Iter: 729 loss: 5.73890247e-06
Iter: 730 loss: 5.73325406e-06
Iter: 731 loss: 5.72908402e-06
Iter: 732 loss: 5.7357347e-06
Iter: 733 loss: 5.72721547e-06
Iter: 734 loss: 5.723713e-06
Iter: 735 loss: 5.74935711e-06
Iter: 736 loss: 5.72346426e-06
Iter: 737 loss: 5.71976216e-06
Iter: 738 loss: 5.72173758e-06
Iter: 739 loss: 5.71736109e-06
Iter: 740 loss: 5.7139564e-06
Iter: 741 loss: 5.71582e-06
Iter: 742 loss: 5.71166674e-06
Iter: 743 loss: 5.70803741e-06
Iter: 744 loss: 5.75420745e-06
Iter: 745 loss: 5.70802422e-06
Iter: 746 loss: 5.70506654e-06
Iter: 747 loss: 5.70427528e-06
Iter: 748 loss: 5.70247721e-06
Iter: 749 loss: 5.69877375e-06
Iter: 750 loss: 5.7076827e-06
Iter: 751 loss: 5.69747499e-06
Iter: 752 loss: 5.69346685e-06
Iter: 753 loss: 5.73087891e-06
Iter: 754 loss: 5.69331314e-06
Iter: 755 loss: 5.69092e-06
Iter: 756 loss: 5.69022677e-06
Iter: 757 loss: 5.6887975e-06
Iter: 758 loss: 5.68481755e-06
Iter: 759 loss: 5.70252723e-06
Iter: 760 loss: 5.6840172e-06
Iter: 761 loss: 5.68089627e-06
Iter: 762 loss: 5.68336736e-06
Iter: 763 loss: 5.67903589e-06
Iter: 764 loss: 5.67484403e-06
Iter: 765 loss: 5.68470477e-06
Iter: 766 loss: 5.6732938e-06
Iter: 767 loss: 5.66987092e-06
Iter: 768 loss: 5.68646e-06
Iter: 769 loss: 5.6692852e-06
Iter: 770 loss: 5.66528615e-06
Iter: 771 loss: 5.67219786e-06
Iter: 772 loss: 5.66353447e-06
Iter: 773 loss: 5.66058861e-06
Iter: 774 loss: 5.66032031e-06
Iter: 775 loss: 5.65814526e-06
Iter: 776 loss: 5.65465825e-06
Iter: 777 loss: 5.69601889e-06
Iter: 778 loss: 5.65462e-06
Iter: 779 loss: 5.6515828e-06
Iter: 780 loss: 5.65169239e-06
Iter: 781 loss: 5.64923539e-06
Iter: 782 loss: 5.64573202e-06
Iter: 783 loss: 5.65348455e-06
Iter: 784 loss: 5.64440597e-06
Iter: 785 loss: 5.64084257e-06
Iter: 786 loss: 5.67624647e-06
Iter: 787 loss: 5.64071343e-06
Iter: 788 loss: 5.6383692e-06
Iter: 789 loss: 5.63741469e-06
Iter: 790 loss: 5.63617368e-06
Iter: 791 loss: 5.63245612e-06
Iter: 792 loss: 5.65587561e-06
Iter: 793 loss: 5.63210733e-06
Iter: 794 loss: 5.62956666e-06
Iter: 795 loss: 5.63099411e-06
Iter: 796 loss: 5.62794594e-06
Iter: 797 loss: 5.62450532e-06
Iter: 798 loss: 5.63307276e-06
Iter: 799 loss: 5.62331843e-06
Iter: 800 loss: 5.62050946e-06
Iter: 801 loss: 5.63295089e-06
Iter: 802 loss: 5.61993329e-06
Iter: 803 loss: 5.61671231e-06
Iter: 804 loss: 5.62357491e-06
Iter: 805 loss: 5.61541128e-06
Iter: 806 loss: 5.61286333e-06
Iter: 807 loss: 5.61108845e-06
Iter: 808 loss: 5.61018533e-06
Iter: 809 loss: 5.60687522e-06
Iter: 810 loss: 5.65329219e-06
Iter: 811 loss: 5.60682838e-06
Iter: 812 loss: 5.60407e-06
Iter: 813 loss: 5.60438366e-06
Iter: 814 loss: 5.60195804e-06
Iter: 815 loss: 5.59874206e-06
Iter: 816 loss: 5.60455283e-06
Iter: 817 loss: 5.59731507e-06
Iter: 818 loss: 5.59425371e-06
Iter: 819 loss: 5.6372e-06
Iter: 820 loss: 5.59423461e-06
Iter: 821 loss: 5.5922892e-06
Iter: 822 loss: 5.59107957e-06
Iter: 823 loss: 5.59031059e-06
Iter: 824 loss: 5.5872888e-06
Iter: 825 loss: 5.60863782e-06
Iter: 826 loss: 5.58702504e-06
Iter: 827 loss: 5.58486863e-06
Iter: 828 loss: 5.58503052e-06
Iter: 829 loss: 5.58318061e-06
Iter: 830 loss: 5.57995554e-06
Iter: 831 loss: 5.58933425e-06
Iter: 832 loss: 5.57896146e-06
Iter: 833 loss: 5.57619296e-06
Iter: 834 loss: 5.58419288e-06
Iter: 835 loss: 5.5753585e-06
Iter: 836 loss: 5.57186831e-06
Iter: 837 loss: 5.58301508e-06
Iter: 838 loss: 5.57088651e-06
Iter: 839 loss: 5.56839586e-06
Iter: 840 loss: 5.56626674e-06
Iter: 841 loss: 5.56562554e-06
Iter: 842 loss: 5.56249506e-06
Iter: 843 loss: 5.60809031e-06
Iter: 844 loss: 5.56245323e-06
Iter: 845 loss: 5.55984752e-06
Iter: 846 loss: 5.56104533e-06
Iter: 847 loss: 5.55805582e-06
Iter: 848 loss: 5.55522274e-06
Iter: 849 loss: 5.56015266e-06
Iter: 850 loss: 5.55398537e-06
Iter: 851 loss: 5.55135557e-06
Iter: 852 loss: 5.58701959e-06
Iter: 853 loss: 5.55136467e-06
Iter: 854 loss: 5.5495675e-06
Iter: 855 loss: 5.54811686e-06
Iter: 856 loss: 5.5475748e-06
Iter: 857 loss: 5.54469352e-06
Iter: 858 loss: 5.56707391e-06
Iter: 859 loss: 5.54451799e-06
Iter: 860 loss: 5.54241615e-06
Iter: 861 loss: 5.54215421e-06
Iter: 862 loss: 5.54069857e-06
Iter: 863 loss: 5.53746759e-06
Iter: 864 loss: 5.5473356e-06
Iter: 865 loss: 5.53649625e-06
Iter: 866 loss: 5.53377413e-06
Iter: 867 loss: 5.5416258e-06
Iter: 868 loss: 5.53291193e-06
Iter: 869 loss: 5.52969323e-06
Iter: 870 loss: 5.54309099e-06
Iter: 871 loss: 5.52900747e-06
Iter: 872 loss: 5.52677966e-06
Iter: 873 loss: 5.52461552e-06
Iter: 874 loss: 5.52418078e-06
Iter: 875 loss: 5.5214341e-06
Iter: 876 loss: 5.52145e-06
Iter: 877 loss: 5.51922039e-06
Iter: 878 loss: 5.52033134e-06
Iter: 879 loss: 5.517727e-06
Iter: 880 loss: 5.51522862e-06
Iter: 881 loss: 5.51812673e-06
Iter: 882 loss: 5.51388666e-06
Iter: 883 loss: 5.51149878e-06
Iter: 884 loss: 5.51151925e-06
Iter: 885 loss: 5.50982804e-06
Iter: 886 loss: 5.50806817e-06
Iter: 887 loss: 5.50774121e-06
Iter: 888 loss: 5.5049336e-06
Iter: 889 loss: 5.52792153e-06
Iter: 890 loss: 5.50475852e-06
Iter: 891 loss: 5.50269397e-06
Iter: 892 loss: 5.50231653e-06
Iter: 893 loss: 5.50088816e-06
Iter: 894 loss: 5.49768265e-06
Iter: 895 loss: 5.50873165e-06
Iter: 896 loss: 5.49680681e-06
Iter: 897 loss: 5.49419565e-06
Iter: 898 loss: 5.50002824e-06
Iter: 899 loss: 5.49319702e-06
Iter: 900 loss: 5.48990101e-06
Iter: 901 loss: 5.5069986e-06
Iter: 902 loss: 5.48937896e-06
Iter: 903 loss: 5.48730668e-06
Iter: 904 loss: 5.48475873e-06
Iter: 905 loss: 5.48453272e-06
Iter: 906 loss: 5.48177923e-06
Iter: 907 loss: 5.52520487e-06
Iter: 908 loss: 5.48178e-06
Iter: 909 loss: 5.47955551e-06
Iter: 910 loss: 5.48134813e-06
Iter: 911 loss: 5.47821628e-06
Iter: 912 loss: 5.47590525e-06
Iter: 913 loss: 5.47861282e-06
Iter: 914 loss: 5.47466152e-06
Iter: 915 loss: 5.47256332e-06
Iter: 916 loss: 5.50507775e-06
Iter: 917 loss: 5.47252148e-06
Iter: 918 loss: 5.47092759e-06
Iter: 919 loss: 5.46933916e-06
Iter: 920 loss: 5.46900219e-06
Iter: 921 loss: 5.46653882e-06
Iter: 922 loss: 5.48897424e-06
Iter: 923 loss: 5.46641786e-06
Iter: 924 loss: 5.46458159e-06
Iter: 925 loss: 5.46397496e-06
Iter: 926 loss: 5.46288811e-06
Iter: 927 loss: 5.45989542e-06
Iter: 928 loss: 5.46899628e-06
Iter: 929 loss: 5.45900957e-06
Iter: 930 loss: 5.4564357e-06
Iter: 931 loss: 5.46141109e-06
Iter: 932 loss: 5.45529929e-06
Iter: 933 loss: 5.45203284e-06
Iter: 934 loss: 5.47173568e-06
Iter: 935 loss: 5.45167541e-06
Iter: 936 loss: 5.44966588e-06
Iter: 937 loss: 5.44716477e-06
Iter: 938 loss: 5.44692875e-06
Iter: 939 loss: 5.4444954e-06
Iter: 940 loss: 5.44448e-06
Iter: 941 loss: 5.44243903e-06
Iter: 942 loss: 5.44437808e-06
Iter: 943 loss: 5.44128307e-06
Iter: 944 loss: 5.43919487e-06
Iter: 945 loss: 5.44085742e-06
Iter: 946 loss: 5.43791157e-06
Iter: 947 loss: 5.43593433e-06
Iter: 948 loss: 5.46727733e-06
Iter: 949 loss: 5.43593796e-06
Iter: 950 loss: 5.43441456e-06
Iter: 951 loss: 5.43278748e-06
Iter: 952 loss: 5.43249e-06
Iter: 953 loss: 5.43007172e-06
Iter: 954 loss: 5.45153307e-06
Iter: 955 loss: 5.42997259e-06
Iter: 956 loss: 5.42807129e-06
Iter: 957 loss: 5.42714315e-06
Iter: 958 loss: 5.42620728e-06
Iter: 959 loss: 5.42303042e-06
Iter: 960 loss: 5.43407441e-06
Iter: 961 loss: 5.42219868e-06
Iter: 962 loss: 5.41947384e-06
Iter: 963 loss: 5.42355156e-06
Iter: 964 loss: 5.41819827e-06
Iter: 965 loss: 5.41482586e-06
Iter: 966 loss: 5.44119712e-06
Iter: 967 loss: 5.41466034e-06
Iter: 968 loss: 5.41274e-06
Iter: 969 loss: 5.41000418e-06
Iter: 970 loss: 5.40989913e-06
Iter: 971 loss: 5.40739484e-06
Iter: 972 loss: 5.40741121e-06
Iter: 973 loss: 5.40535893e-06
Iter: 974 loss: 5.40765e-06
Iter: 975 loss: 5.40425526e-06
Iter: 976 loss: 5.40217161e-06
Iter: 977 loss: 5.40395104e-06
Iter: 978 loss: 5.40089786e-06
Iter: 979 loss: 5.39899702e-06
Iter: 980 loss: 5.42671751e-06
Iter: 981 loss: 5.39894882e-06
Iter: 982 loss: 5.39733355e-06
Iter: 983 loss: 5.39587654e-06
Iter: 984 loss: 5.39547091e-06
Iter: 985 loss: 5.3931717e-06
Iter: 986 loss: 5.41463032e-06
Iter: 987 loss: 5.39305802e-06
Iter: 988 loss: 5.39113171e-06
Iter: 989 loss: 5.39022221e-06
Iter: 990 loss: 5.3893209e-06
Iter: 991 loss: 5.38619315e-06
Iter: 992 loss: 5.39661278e-06
Iter: 993 loss: 5.38535778e-06
Iter: 994 loss: 5.3826484e-06
Iter: 995 loss: 5.38589575e-06
Iter: 996 loss: 5.3812023e-06
Iter: 997 loss: 5.37782807e-06
Iter: 998 loss: 5.40620749e-06
Iter: 999 loss: 5.37762935e-06
Iter: 1000 loss: 5.37554433e-06
Iter: 1001 loss: 5.37257256e-06
Iter: 1002 loss: 5.37249525e-06
Iter: 1003 loss: 5.3697604e-06
Iter: 1004 loss: 5.41281042e-06
Iter: 1005 loss: 5.36975722e-06
Iter: 1006 loss: 5.36748394e-06
Iter: 1007 loss: 5.37037749e-06
Iter: 1008 loss: 5.3662925e-06
Iter: 1009 loss: 5.36400239e-06
Iter: 1010 loss: 5.36606149e-06
Iter: 1011 loss: 5.36265179e-06
Iter: 1012 loss: 5.36052812e-06
Iter: 1013 loss: 5.39130087e-06
Iter: 1014 loss: 5.36052539e-06
Iter: 1015 loss: 5.35877552e-06
Iter: 1016 loss: 5.35722074e-06
Iter: 1017 loss: 5.35676372e-06
Iter: 1018 loss: 5.35430354e-06
Iter: 1019 loss: 5.37718461e-06
Iter: 1020 loss: 5.35421e-06
Iter: 1021 loss: 5.35216941e-06
Iter: 1022 loss: 5.35127174e-06
Iter: 1023 loss: 5.35029085e-06
Iter: 1024 loss: 5.3470585e-06
Iter: 1025 loss: 5.35877871e-06
Iter: 1026 loss: 5.3462195e-06
Iter: 1027 loss: 5.34332776e-06
Iter: 1028 loss: 5.34600167e-06
Iter: 1029 loss: 5.34164838e-06
Iter: 1030 loss: 5.33817183e-06
Iter: 1031 loss: 5.37457299e-06
Iter: 1032 loss: 5.33806769e-06
Iter: 1033 loss: 5.33601906e-06
Iter: 1034 loss: 5.33259072e-06
Iter: 1035 loss: 5.33256343e-06
Iter: 1036 loss: 5.32938293e-06
Iter: 1037 loss: 5.37263622e-06
Iter: 1038 loss: 5.32937611e-06
Iter: 1039 loss: 5.32670765e-06
Iter: 1040 loss: 5.3303952e-06
Iter: 1041 loss: 5.32532613e-06
Iter: 1042 loss: 5.32271315e-06
Iter: 1043 loss: 5.32510558e-06
Iter: 1044 loss: 5.32117429e-06
Iter: 1045 loss: 5.31853948e-06
Iter: 1046 loss: 5.34464971e-06
Iter: 1047 loss: 5.31846626e-06
Iter: 1048 loss: 5.31594696e-06
Iter: 1049 loss: 5.31483329e-06
Iter: 1050 loss: 5.31356091e-06
Iter: 1051 loss: 5.310706e-06
Iter: 1052 loss: 5.33866842e-06
Iter: 1053 loss: 5.31057731e-06
Iter: 1054 loss: 5.30821171e-06
Iter: 1055 loss: 5.30671696e-06
Iter: 1056 loss: 5.30580473e-06
Iter: 1057 loss: 5.30190482e-06
Iter: 1058 loss: 5.31821024e-06
Iter: 1059 loss: 5.30107172e-06
Iter: 1060 loss: 5.29782756e-06
Iter: 1061 loss: 5.30112629e-06
Iter: 1062 loss: 5.29603631e-06
Iter: 1063 loss: 5.29227282e-06
Iter: 1064 loss: 5.33022921e-06
Iter: 1065 loss: 5.29216368e-06
Iter: 1066 loss: 5.28971759e-06
Iter: 1067 loss: 5.28537385e-06
Iter: 1068 loss: 5.39219855e-06
Iter: 1069 loss: 5.28536748e-06
Iter: 1070 loss: 5.28161263e-06
Iter: 1071 loss: 5.28163673e-06
Iter: 1072 loss: 5.27864086e-06
Iter: 1073 loss: 5.28048122e-06
Iter: 1074 loss: 5.27669818e-06
Iter: 1075 loss: 5.27291e-06
Iter: 1076 loss: 5.2763744e-06
Iter: 1077 loss: 5.27078e-06
Iter: 1078 loss: 5.26724716e-06
Iter: 1079 loss: 5.31423848e-06
Iter: 1080 loss: 5.26722579e-06
Iter: 1081 loss: 5.2642954e-06
Iter: 1082 loss: 5.26332769e-06
Iter: 1083 loss: 5.26166968e-06
Iter: 1084 loss: 5.25820724e-06
Iter: 1085 loss: 5.28329747e-06
Iter: 1086 loss: 5.25791802e-06
Iter: 1087 loss: 5.25474115e-06
Iter: 1088 loss: 5.25423275e-06
Iter: 1089 loss: 5.25202358e-06
Iter: 1090 loss: 5.24770712e-06
Iter: 1091 loss: 5.2687069e-06
Iter: 1092 loss: 5.24693678e-06
Iter: 1093 loss: 5.24340248e-06
Iter: 1094 loss: 5.24411917e-06
Iter: 1095 loss: 5.24084317e-06
Iter: 1096 loss: 5.23624749e-06
Iter: 1097 loss: 5.28839701e-06
Iter: 1098 loss: 5.23619519e-06
Iter: 1099 loss: 5.23314429e-06
Iter: 1100 loss: 5.22823439e-06
Iter: 1101 loss: 5.22818709e-06
Iter: 1102 loss: 5.2236619e-06
Iter: 1103 loss: 5.28116698e-06
Iter: 1104 loss: 5.22363825e-06
Iter: 1105 loss: 5.21964921e-06
Iter: 1106 loss: 5.22403025e-06
Iter: 1107 loss: 5.21748643e-06
Iter: 1108 loss: 5.21331322e-06
Iter: 1109 loss: 5.22070059e-06
Iter: 1110 loss: 5.2114824e-06
Iter: 1111 loss: 5.20787489e-06
Iter: 1112 loss: 5.24149436e-06
Iter: 1113 loss: 5.20771209e-06
Iter: 1114 loss: 5.20423328e-06
Iter: 1115 loss: 5.20356252e-06
Iter: 1116 loss: 5.2012806e-06
Iter: 1117 loss: 5.19738387e-06
Iter: 1118 loss: 5.22759819e-06
Iter: 1119 loss: 5.19712285e-06
Iter: 1120 loss: 5.19369632e-06
Iter: 1121 loss: 5.19275454e-06
Iter: 1122 loss: 5.19068453e-06
Iter: 1123 loss: 5.18573506e-06
Iter: 1124 loss: 5.2075834e-06
Iter: 1125 loss: 5.18475827e-06
Iter: 1126 loss: 5.18061324e-06
Iter: 1127 loss: 5.18138586e-06
Iter: 1128 loss: 5.17746594e-06
Iter: 1129 loss: 5.17231956e-06
Iter: 1130 loss: 5.2417e-06
Iter: 1131 loss: 5.17230728e-06
Iter: 1132 loss: 5.16915316e-06
Iter: 1133 loss: 5.16391492e-06
Iter: 1134 loss: 5.16391583e-06
Iter: 1135 loss: 5.15971715e-06
Iter: 1136 loss: 5.15971e-06
Iter: 1137 loss: 5.15649572e-06
Iter: 1138 loss: 5.15909687e-06
Iter: 1139 loss: 5.15452393e-06
Iter: 1140 loss: 5.15065949e-06
Iter: 1141 loss: 5.15479132e-06
Iter: 1142 loss: 5.14855492e-06
Iter: 1143 loss: 5.14492331e-06
Iter: 1144 loss: 5.1825873e-06
Iter: 1145 loss: 5.144836e-06
Iter: 1146 loss: 5.14144449e-06
Iter: 1147 loss: 5.14131534e-06
Iter: 1148 loss: 5.13873601e-06
Iter: 1149 loss: 5.13497525e-06
Iter: 1150 loss: 5.15867259e-06
Iter: 1151 loss: 5.13451505e-06
Iter: 1152 loss: 5.13083796e-06
Iter: 1153 loss: 5.13083614e-06
Iter: 1154 loss: 5.12792121e-06
Iter: 1155 loss: 5.12303859e-06
Iter: 1156 loss: 5.14404201e-06
Iter: 1157 loss: 5.1221e-06
Iter: 1158 loss: 5.11780127e-06
Iter: 1159 loss: 5.11856251e-06
Iter: 1160 loss: 5.11457711e-06
Iter: 1161 loss: 5.10969585e-06
Iter: 1162 loss: 5.18648449e-06
Iter: 1163 loss: 5.10972814e-06
Iter: 1164 loss: 5.10684367e-06
Iter: 1165 loss: 5.10209247e-06
Iter: 1166 loss: 5.10202153e-06
Iter: 1167 loss: 5.09781603e-06
Iter: 1168 loss: 5.15233205e-06
Iter: 1169 loss: 5.0978233e-06
Iter: 1170 loss: 5.09433539e-06
Iter: 1171 loss: 5.09964093e-06
Iter: 1172 loss: 5.09271058e-06
Iter: 1173 loss: 5.08939229e-06
Iter: 1174 loss: 5.09529764e-06
Iter: 1175 loss: 5.08794801e-06
Iter: 1176 loss: 5.08488938e-06
Iter: 1177 loss: 5.10586779e-06
Iter: 1178 loss: 5.08460835e-06
Iter: 1179 loss: 5.08143239e-06
Iter: 1180 loss: 5.08289e-06
Iter: 1181 loss: 5.07922186e-06
