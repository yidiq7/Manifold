+ RUN=1
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ LAYERS='k4 k3 k2'
+ case $RUN in
+ PSI='-2 -1'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output70
+ for fn in f1 f2
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0
+ date
Tue Oct 27 14:42:10 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859ee8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859ec3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859ee8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f586c174ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859f541e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859f549d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859e84c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859e6f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859e52bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859e239d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859df90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859de9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859de9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859d8f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859de9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859de9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859d2c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859d2c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859d2cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859c948c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859c94840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859bfea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859c389d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859bcdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859bcdea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859b998c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859b498c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859b60d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859b71488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859b71b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859b00a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859a836a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859a94158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859a39bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859a70a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5859a107b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00252855173
Iter: 2 loss: 0.0025175577
Iter: 3 loss: 0.00247440464
Iter: 4 loss: 0.00227838289
Iter: 5 loss: 0.00179919973
Iter: 6 loss: 0.0134920012
Iter: 7 loss: 0.00179748
Iter: 8 loss: 0.00141197979
Iter: 9 loss: 0.00600162242
Iter: 10 loss: 0.00140089
Iter: 11 loss: 0.00118501671
Iter: 12 loss: 0.00150194042
Iter: 13 loss: 0.00108005805
Iter: 14 loss: 0.00091555214
Iter: 15 loss: 0.000915472105
Iter: 16 loss: 0.000799370813
Iter: 17 loss: 0.00080888276
Iter: 18 loss: 0.000708649284
Iter: 19 loss: 0.000600853935
Iter: 20 loss: 0.000852427
Iter: 21 loss: 0.000560502929
Iter: 22 loss: 0.000492478139
Iter: 23 loss: 0.00157875475
Iter: 24 loss: 0.00049247162
Iter: 25 loss: 0.000436223403
Iter: 26 loss: 0.000598017
Iter: 27 loss: 0.000418570475
Iter: 28 loss: 0.000380037294
Iter: 29 loss: 0.000379299687
Iter: 30 loss: 0.000348931
Iter: 31 loss: 0.000311760115
Iter: 32 loss: 0.000644016312
Iter: 33 loss: 0.000309919
Iter: 34 loss: 0.000282575667
Iter: 35 loss: 0.000506145298
Iter: 36 loss: 0.000280851556
Iter: 37 loss: 0.000262628513
Iter: 38 loss: 0.000254304265
Iter: 39 loss: 0.000245231378
Iter: 40 loss: 0.000226047341
Iter: 41 loss: 0.000344527
Iter: 42 loss: 0.000223730982
Iter: 43 loss: 0.000208675177
Iter: 44 loss: 0.000347875524
Iter: 45 loss: 0.000208047772
Iter: 46 loss: 0.000198524227
Iter: 47 loss: 0.000193325846
Iter: 48 loss: 0.000189096987
Iter: 49 loss: 0.000178578193
Iter: 50 loss: 0.000262129237
Iter: 51 loss: 0.000177839858
Iter: 52 loss: 0.000169259787
Iter: 53 loss: 0.000203367585
Iter: 54 loss: 0.000167349455
Iter: 55 loss: 0.000161009928
Iter: 56 loss: 0.000173673732
Iter: 57 loss: 0.000158423805
Iter: 58 loss: 0.000152460823
Iter: 59 loss: 0.000206879122
Iter: 60 loss: 0.000152185268
Iter: 61 loss: 0.000148408086
Iter: 62 loss: 0.000145041937
Iter: 63 loss: 0.000144076417
Iter: 64 loss: 0.00013908383
Iter: 65 loss: 0.000160213225
Iter: 66 loss: 0.000138034578
Iter: 67 loss: 0.00013486328
Iter: 68 loss: 0.000134847098
Iter: 69 loss: 0.000132540081
Iter: 70 loss: 0.000130674351
Iter: 71 loss: 0.000129985972
Iter: 72 loss: 0.000127009494
Iter: 73 loss: 0.000132229616
Iter: 74 loss: 0.000125696621
Iter: 75 loss: 0.000123042089
Iter: 76 loss: 0.00014144351
Iter: 77 loss: 0.000122791476
Iter: 78 loss: 0.000120767792
Iter: 79 loss: 0.000140456439
Iter: 80 loss: 0.000120695098
Iter: 81 loss: 0.000119288132
Iter: 82 loss: 0.00011826487
Iter: 83 loss: 0.000117784584
Iter: 84 loss: 0.000116023257
Iter: 85 loss: 0.000123235513
Iter: 86 loss: 0.000115636867
Iter: 87 loss: 0.000114170689
Iter: 88 loss: 0.000130910601
Iter: 89 loss: 0.000114145812
Iter: 90 loss: 0.000113163958
Iter: 91 loss: 0.000112335169
Iter: 92 loss: 0.000112060618
Iter: 93 loss: 0.000110723457
Iter: 94 loss: 0.000117155432
Iter: 95 loss: 0.000110484136
Iter: 96 loss: 0.000109314897
Iter: 97 loss: 0.000117093812
Iter: 98 loss: 0.000109196153
Iter: 99 loss: 0.000108353648
Iter: 100 loss: 0.000108983018
Iter: 101 loss: 0.00010783771
Iter: 102 loss: 0.000107005792
Iter: 103 loss: 0.000115854054
Iter: 104 loss: 0.000106984844
Iter: 105 loss: 0.000106310908
Iter: 106 loss: 0.000105998581
Iter: 107 loss: 0.000105665516
Iter: 108 loss: 0.000104813771
Iter: 109 loss: 0.000105551815
Iter: 110 loss: 0.000104312829
Iter: 111 loss: 0.000103460654
Iter: 112 loss: 0.00010938746
Iter: 113 loss: 0.000103381011
Iter: 114 loss: 0.000102696715
Iter: 115 loss: 0.00010951572
Iter: 116 loss: 0.000102674734
Iter: 117 loss: 0.000102211518
Iter: 118 loss: 0.000101643847
Iter: 119 loss: 0.000101592464
Iter: 120 loss: 0.000100858182
Iter: 121 loss: 0.000102673977
Iter: 122 loss: 0.000100598714
Iter: 123 loss: 0.000100004938
Iter: 124 loss: 0.000105601517
Iter: 125 loss: 9.99809854e-05
Iter: 126 loss: 9.94504517e-05
Iter: 127 loss: 0.000101947335
Iter: 128 loss: 9.93535941e-05
Iter: 129 loss: 9.89755863e-05
Iter: 130 loss: 9.86324158e-05
Iter: 131 loss: 9.85388e-05
Iter: 132 loss: 9.80618061e-05
Iter: 133 loss: 0.000102508799
Iter: 134 loss: 9.80419718e-05
Iter: 135 loss: 9.76085212e-05
Iter: 136 loss: 9.91295092e-05
Iter: 137 loss: 9.74957657e-05
Iter: 138 loss: 9.71671761e-05
Iter: 139 loss: 9.73632632e-05
Iter: 140 loss: 9.6955e-05
Iter: 141 loss: 9.65634099e-05
Iter: 142 loss: 9.97751777e-05
Iter: 143 loss: 9.65393192e-05
Iter: 144 loss: 9.62499616e-05
Iter: 145 loss: 9.61816e-05
Iter: 146 loss: 9.59966e-05
Iter: 147 loss: 9.56844669e-05
Iter: 148 loss: 9.91931302e-05
Iter: 149 loss: 9.56785661e-05
Iter: 150 loss: 9.54027637e-05
Iter: 151 loss: 9.557046e-05
Iter: 152 loss: 9.52254e-05
Iter: 153 loss: 9.49386886e-05
Iter: 154 loss: 9.49882815e-05
Iter: 155 loss: 9.47236113e-05
Iter: 156 loss: 9.43896739e-05
Iter: 157 loss: 9.56171e-05
Iter: 158 loss: 9.43071791e-05
Iter: 159 loss: 9.40832251e-05
Iter: 160 loss: 9.40830287e-05
Iter: 161 loss: 9.38878075e-05
Iter: 162 loss: 9.38674639e-05
Iter: 163 loss: 9.3725379e-05
Iter: 164 loss: 9.35020289e-05
Iter: 165 loss: 9.36654687e-05
Iter: 166 loss: 9.33645497e-05
Iter: 167 loss: 9.31178365e-05
Iter: 168 loss: 9.39995225e-05
Iter: 169 loss: 9.30548704e-05
Iter: 170 loss: 9.28845111e-05
Iter: 171 loss: 9.28836234e-05
Iter: 172 loss: 9.2753311e-05
Iter: 173 loss: 9.26683424e-05
Iter: 174 loss: 9.2618182e-05
Iter: 175 loss: 9.24475316e-05
Iter: 176 loss: 9.27442888e-05
Iter: 177 loss: 9.23719563e-05
Iter: 178 loss: 9.22202453e-05
Iter: 179 loss: 9.38607409e-05
Iter: 180 loss: 9.22168911e-05
Iter: 181 loss: 9.20933526e-05
Iter: 182 loss: 9.23012703e-05
Iter: 183 loss: 9.20377643e-05
Iter: 184 loss: 9.19352606e-05
Iter: 185 loss: 9.24610067e-05
Iter: 186 loss: 9.1918846e-05
Iter: 187 loss: 9.18160513e-05
Iter: 188 loss: 9.20103048e-05
Iter: 189 loss: 9.17726284e-05
Iter: 190 loss: 9.16813296e-05
Iter: 191 loss: 9.16703721e-05
Iter: 192 loss: 9.16048375e-05
Iter: 193 loss: 9.15005221e-05
Iter: 194 loss: 9.21524188e-05
Iter: 195 loss: 9.14885e-05
Iter: 196 loss: 9.14020638e-05
Iter: 197 loss: 9.21849205e-05
Iter: 198 loss: 9.13982221e-05
Iter: 199 loss: 9.13427e-05
Iter: 200 loss: 9.12921823e-05
Iter: 201 loss: 9.12785617e-05
Iter: 202 loss: 9.1203663e-05
Iter: 203 loss: 9.15962373e-05
Iter: 204 loss: 9.11919342e-05
Iter: 205 loss: 9.11342358e-05
Iter: 206 loss: 9.17993166e-05
Iter: 207 loss: 9.11334064e-05
Iter: 208 loss: 9.10930321e-05
Iter: 209 loss: 9.10623e-05
Iter: 210 loss: 9.10492381e-05
Iter: 211 loss: 9.09936862e-05
Iter: 212 loss: 9.10858071e-05
Iter: 213 loss: 9.09683e-05
Iter: 214 loss: 9.09201772e-05
Iter: 215 loss: 9.12695614e-05
Iter: 216 loss: 9.09161827e-05
Iter: 217 loss: 9.08787188e-05
Iter: 218 loss: 9.12611358e-05
Iter: 219 loss: 9.08778e-05
Iter: 220 loss: 9.0853544e-05
Iter: 221 loss: 9.08302827e-05
Iter: 222 loss: 9.08249785e-05
Iter: 223 loss: 9.07933936e-05
Iter: 224 loss: 9.0956295e-05
Iter: 225 loss: 9.07884532e-05
Iter: 226 loss: 9.0761343e-05
Iter: 227 loss: 9.09846567e-05
Iter: 228 loss: 9.07597714e-05
Iter: 229 loss: 9.07422509e-05
Iter: 230 loss: 9.07508947e-05
Iter: 231 loss: 9.07303765e-05
Iter: 232 loss: 9.0710193e-05
Iter: 233 loss: 9.0886635e-05
Iter: 234 loss: 9.07091e-05
Iter: 235 loss: 9.06947e-05
Iter: 236 loss: 9.06830683e-05
Iter: 237 loss: 9.06786881e-05
Iter: 238 loss: 9.06592468e-05
Iter: 239 loss: 9.0706948e-05
Iter: 240 loss: 9.06521454e-05
Iter: 241 loss: 9.06358255e-05
Iter: 242 loss: 9.07325739e-05
Iter: 243 loss: 9.06336354e-05
Iter: 244 loss: 9.06208224e-05
Iter: 245 loss: 9.07757785e-05
Iter: 246 loss: 9.06207861e-05
Iter: 247 loss: 9.06124478e-05
Iter: 248 loss: 9.06040805e-05
Iter: 249 loss: 9.06025525e-05
Iter: 250 loss: 9.05908819e-05
Iter: 251 loss: 9.06254136e-05
Iter: 252 loss: 9.05875277e-05
Iter: 253 loss: 9.05794222e-05
Iter: 254 loss: 9.05794368e-05
Iter: 255 loss: 9.05728302e-05
Iter: 256 loss: 9.05700217e-05
Iter: 257 loss: 9.05666e-05
Iter: 258 loss: 9.05589404e-05
Iter: 259 loss: 9.05761117e-05
Iter: 260 loss: 9.05561e-05
Iter: 261 loss: 9.05504639e-05
Iter: 262 loss: 9.06351488e-05
Iter: 263 loss: 9.0550333e-05
Iter: 264 loss: 9.05453344e-05
Iter: 265 loss: 9.05473862e-05
Iter: 266 loss: 9.05421402e-05
Iter: 267 loss: 9.05371e-05
Iter: 268 loss: 9.05430643e-05
Iter: 269 loss: 9.05344496e-05
Iter: 270 loss: 9.05300112e-05
Iter: 271 loss: 9.05808556e-05
Iter: 272 loss: 9.05299385e-05
Iter: 273 loss: 9.05262568e-05
Iter: 274 loss: 9.0529611e-05
Iter: 275 loss: 9.05241468e-05
Iter: 276 loss: 9.05208581e-05
Iter: 277 loss: 9.05420311e-05
Iter: 278 loss: 9.05205743e-05
Iter: 279 loss: 9.05174384e-05
Iter: 280 loss: 9.0522517e-05
Iter: 281 loss: 9.05160123e-05
Iter: 282 loss: 9.05133347e-05
Iter: 283 loss: 9.05140478e-05
Iter: 284 loss: 9.05113557e-05
Iter: 285 loss: 9.05082707e-05
Iter: 286 loss: 9.05173365e-05
Iter: 287 loss: 9.05073248e-05
Iter: 288 loss: 9.05050401e-05
Iter: 289 loss: 9.05290653e-05
Iter: 290 loss: 9.05049528e-05
Iter: 291 loss: 9.05029e-05
Iter: 292 loss: 9.05127235e-05
Iter: 293 loss: 9.05024644e-05
Iter: 294 loss: 9.05013e-05
Iter: 295 loss: 9.04999e-05
Iter: 296 loss: 9.0499685e-05
Iter: 297 loss: 9.04977205e-05
Iter: 298 loss: 9.05053384e-05
Iter: 299 loss: 9.04973567e-05
Iter: 300 loss: 9.04959597e-05
Iter: 301 loss: 9.05155102e-05
Iter: 302 loss: 9.04959597e-05
Iter: 303 loss: 9.04947956e-05
Iter: 304 loss: 9.04963963e-05
Iter: 305 loss: 9.04942863e-05
Iter: 306 loss: 9.04933113e-05
Iter: 307 loss: 9.04933258e-05
Iter: 308 loss: 9.04925691e-05
Iter: 309 loss: 9.04915796e-05
Iter: 310 loss: 9.05029301e-05
Iter: 311 loss: 9.04915214e-05
Iter: 312 loss: 9.04907e-05
Iter: 313 loss: 9.04929184e-05
Iter: 314 loss: 9.04904e-05
Iter: 315 loss: 9.0489877e-05
Iter: 316 loss: 9.04905683e-05
Iter: 317 loss: 9.04894e-05
Iter: 318 loss: 9.04886183e-05
Iter: 319 loss: 9.04941335e-05
Iter: 320 loss: 9.04885237e-05
Iter: 321 loss: 9.04880872e-05
Iter: 322 loss: 9.04881599e-05
Iter: 323 loss: 9.04877234e-05
Iter: 324 loss: 9.04871267e-05
Iter: 325 loss: 9.04924746e-05
Iter: 326 loss: 9.04871267e-05
Iter: 327 loss: 9.04867629e-05
Iter: 328 loss: 9.04870685e-05
Iter: 329 loss: 9.04864064e-05
Iter: 330 loss: 9.04859626e-05
Iter: 331 loss: 9.04862e-05
Iter: 332 loss: 9.04857952e-05
Iter: 333 loss: 9.0485235e-05
Iter: 334 loss: 9.04866902e-05
Iter: 335 loss: 9.04851404e-05
Iter: 336 loss: 9.04848e-05
Iter: 337 loss: 9.04847111e-05
Iter: 338 loss: 9.04844637e-05
Iter: 339 loss: 9.04845438e-05
Iter: 340 loss: 9.04843328e-05
Iter: 341 loss: 9.04840126e-05
Iter: 342 loss: 9.04841218e-05
Iter: 343 loss: 9.04838671e-05
Iter: 344 loss: 9.04835106e-05
Iter: 345 loss: 9.04855e-05
Iter: 346 loss: 9.04834887e-05
Iter: 347 loss: 9.04832559e-05
Iter: 348 loss: 9.04863045e-05
Iter: 349 loss: 9.04833214e-05
Iter: 350 loss: 9.04832123e-05
Iter: 351 loss: 9.04830595e-05
Iter: 352 loss: 9.0483e-05
Iter: 353 loss: 9.04828339e-05
Iter: 354 loss: 9.04839253e-05
Iter: 355 loss: 9.04828776e-05
Iter: 356 loss: 9.04826811e-05
Iter: 357 loss: 9.04837434e-05
Iter: 358 loss: 9.04826884e-05
Iter: 359 loss: 9.04825865e-05
Iter: 360 loss: 9.04826447e-05
Iter: 361 loss: 9.04825574e-05
Iter: 362 loss: 9.04823683e-05
Iter: 363 loss: 9.04831395e-05
Iter: 364 loss: 9.04823683e-05
Iter: 365 loss: 9.04822082e-05
Iter: 366 loss: 9.04822518e-05
Iter: 367 loss: 9.04822082e-05
Iter: 368 loss: 9.04821281e-05
Iter: 369 loss: 9.04821936e-05
Iter: 370 loss: 9.04820699e-05
Iter: 371 loss: 9.04820336e-05
Iter: 372 loss: 9.04830886e-05
Iter: 373 loss: 9.04821136e-05
Iter: 374 loss: 9.04819317e-05
Iter: 375 loss: 9.04820336e-05
Iter: 376 loss: 9.04819e-05
Iter: 377 loss: 9.04818589e-05
Iter: 378 loss: 9.04819608e-05
Iter: 379 loss: 9.0481808e-05
Iter: 380 loss: 9.04817425e-05
Iter: 381 loss: 9.04820772e-05
Iter: 382 loss: 9.0481728e-05
Iter: 383 loss: 9.0481728e-05
Iter: 384 loss: 9.04824337e-05
Iter: 385 loss: 9.04817425e-05
Iter: 386 loss: 9.04815606e-05
Iter: 387 loss: 9.0481517e-05
Iter: 388 loss: 9.04816e-05
Iter: 389 loss: 9.04815461e-05
Iter: 390 loss: 9.04816698e-05
Iter: 391 loss: 9.04815461e-05
Iter: 392 loss: 9.04815388e-05
Iter: 393 loss: 9.04819535e-05
Iter: 394 loss: 9.04814951e-05
Iter: 395 loss: 9.04814297e-05
Iter: 396 loss: 9.04815679e-05
Iter: 397 loss: 9.04815242e-05
Iter: 398 loss: 9.04814951e-05
Iter: 399 loss: 9.04814515e-05
Iter: 400 loss: 9.0481386e-05
Iter: 401 loss: 9.04813714e-05
Iter: 402 loss: 9.04816261e-05
Iter: 403 loss: 9.04813132e-05
Iter: 404 loss: 9.04814e-05
Iter: 405 loss: 9.04813714e-05
Iter: 406 loss: 9.04814078e-05
Iter: 407 loss: 9.04813787e-05
Iter: 408 loss: 9.04812769e-05
Iter: 409 loss: 9.04813496e-05
Iter: 410 loss: 9.04813642e-05
Iter: 411 loss: 9.04813642e-05
Iter: 412 loss: 9.04813205e-05
Iter: 413 loss: 9.04814224e-05
Iter: 414 loss: 9.04813496e-05
Iter: 415 loss: 9.04813423e-05
Iter: 416 loss: 9.04813787e-05
Iter: 417 loss: 9.04813787e-05
Iter: 418 loss: 9.04814369e-05
Iter: 419 loss: 9.04814078e-05
Iter: 420 loss: 9.04813933e-05
Iter: 421 loss: 9.04814e-05
Iter: 422 loss: 9.04814e-05
Iter: 423 loss: 9.04814078e-05
Iter: 424 loss: 9.04814078e-05
Iter: 425 loss: 9.04813933e-05
Iter: 426 loss: 9.04814078e-05
Iter: 427 loss: 9.04813933e-05
Iter: 428 loss: 9.04814e-05
Iter: 429 loss: 9.04814e-05
Iter: 430 loss: 9.04814078e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4
+ date
Tue Oct 27 14:48:08 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b6fa2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b685730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b690b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b65bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b5be488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b5be950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b59ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b54f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b556268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b556048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b4c4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b4d8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b4737b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b485bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b440a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b440840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b4066a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b406f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b3e6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b384f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b39a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b356598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b30d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b31fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b2b8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b2b8ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b29e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b2502f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b29e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b203a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b1b67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b1cc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b1cc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b175620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b199ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e6b155488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0249833055
Iter: 2 loss: 0.0245859772
Iter: 3 loss: 0.0230483674
Iter: 4 loss: 0.0165463649
Iter: 5 loss: 0.0111558177
Iter: 6 loss: 0.00784547813
Iter: 7 loss: 0.00414102338
Iter: 8 loss: 0.00396431936
Iter: 9 loss: 0.00242586294
Iter: 10 loss: 0.0122347958
Iter: 11 loss: 0.00212196168
Iter: 12 loss: 0.0013988734
Iter: 13 loss: 0.00539116096
Iter: 14 loss: 0.00127559854
Iter: 15 loss: 0.000856346218
Iter: 16 loss: 0.00480859866
Iter: 17 loss: 0.00083607604
Iter: 18 loss: 0.000615482044
Iter: 19 loss: 0.00308535667
Iter: 20 loss: 0.00061232358
Iter: 21 loss: 0.000495247077
Iter: 22 loss: 0.000729383901
Iter: 23 loss: 0.000446788094
Iter: 24 loss: 0.00037004787
Iter: 25 loss: 0.0010733027
Iter: 26 loss: 0.000366145978
Iter: 27 loss: 0.000319678569
Iter: 28 loss: 0.000621251529
Iter: 29 loss: 0.000314687757
Iter: 30 loss: 0.000283381494
Iter: 31 loss: 0.000367875356
Iter: 32 loss: 0.000273265934
Iter: 33 loss: 0.000247400778
Iter: 34 loss: 0.000286780793
Iter: 35 loss: 0.000234917024
Iter: 36 loss: 0.000214850967
Iter: 37 loss: 0.000272705453
Iter: 38 loss: 0.000208593206
Iter: 39 loss: 0.000191688086
Iter: 40 loss: 0.000244247
Iter: 41 loss: 0.000186752426
Iter: 42 loss: 0.00017481
Iter: 43 loss: 0.000261251553
Iter: 44 loss: 0.000173783556
Iter: 45 loss: 0.000164417259
Iter: 46 loss: 0.000208108657
Iter: 47 loss: 0.000162677956
Iter: 48 loss: 0.000156035821
Iter: 49 loss: 0.000163903373
Iter: 50 loss: 0.00015250576
Iter: 51 loss: 0.000146239327
Iter: 52 loss: 0.00017946148
Iter: 53 loss: 0.000145262136
Iter: 54 loss: 0.000140389791
Iter: 55 loss: 0.000162122495
Iter: 56 loss: 0.000139431155
Iter: 57 loss: 0.000135635404
Iter: 58 loss: 0.000145065802
Iter: 59 loss: 0.000134297225
Iter: 60 loss: 0.000131077046
Iter: 61 loss: 0.000143187484
Iter: 62 loss: 0.000130293149
Iter: 63 loss: 0.000127610518
Iter: 64 loss: 0.000142132194
Iter: 65 loss: 0.000127212465
Iter: 66 loss: 0.000125112536
Iter: 67 loss: 0.000128986911
Iter: 68 loss: 0.000124210797
Iter: 69 loss: 0.000122430458
Iter: 70 loss: 0.000141623314
Iter: 71 loss: 0.000122387923
Iter: 72 loss: 0.000121031648
Iter: 73 loss: 0.000121664321
Iter: 74 loss: 0.000120115452
Iter: 75 loss: 0.000118659402
Iter: 76 loss: 0.000120781042
Iter: 77 loss: 0.000117954187
Iter: 78 loss: 0.000116607625
Iter: 79 loss: 0.000126299608
Iter: 80 loss: 0.000116489085
Iter: 81 loss: 0.000115417686
Iter: 82 loss: 0.000119375713
Iter: 83 loss: 0.000115155206
Iter: 84 loss: 0.000114296083
Iter: 85 loss: 0.00011726089
Iter: 86 loss: 0.000114068782
Iter: 87 loss: 0.000113274684
Iter: 88 loss: 0.000114394097
Iter: 89 loss: 0.000112883397
Iter: 90 loss: 0.0001121147
Iter: 91 loss: 0.000113634916
Iter: 92 loss: 0.000111798377
Iter: 93 loss: 0.000111102403
Iter: 94 loss: 0.000114475537
Iter: 95 loss: 0.000110980312
Iter: 96 loss: 0.000110415902
Iter: 97 loss: 0.00011301128
Iter: 98 loss: 0.000110308967
Iter: 99 loss: 0.000109853208
Iter: 100 loss: 0.000111946421
Iter: 101 loss: 0.000109767192
Iter: 102 loss: 0.000109397923
Iter: 103 loss: 0.000110056775
Iter: 104 loss: 0.000109236593
Iter: 105 loss: 0.000108899432
Iter: 106 loss: 0.000111562164
Iter: 107 loss: 0.000108875909
Iter: 108 loss: 0.000108587803
Iter: 109 loss: 0.000109026209
Iter: 110 loss: 0.000108451459
Iter: 111 loss: 0.000108169523
Iter: 112 loss: 0.000108452681
Iter: 113 loss: 0.000108011162
Iter: 114 loss: 0.000107738262
Iter: 115 loss: 0.00010859764
Iter: 116 loss: 0.000107659187
Iter: 117 loss: 0.000107425105
Iter: 118 loss: 0.000109396715
Iter: 119 loss: 0.000107411717
Iter: 120 loss: 0.000107228232
Iter: 121 loss: 0.000107657557
Iter: 122 loss: 0.000107160566
Iter: 123 loss: 0.000106997199
Iter: 124 loss: 0.000107420725
Iter: 125 loss: 0.000106941632
Iter: 126 loss: 0.000106784086
Iter: 127 loss: 0.000107211104
Iter: 128 loss: 0.000106732405
Iter: 129 loss: 0.000106582294
Iter: 130 loss: 0.000106906227
Iter: 131 loss: 0.00010652405
Iter: 132 loss: 0.000106382671
Iter: 133 loss: 0.000106662919
Iter: 134 loss: 0.000106324427
Iter: 135 loss: 0.000106193977
Iter: 136 loss: 0.000106950924
Iter: 137 loss: 0.000106176754
Iter: 138 loss: 0.000106072672
Iter: 139 loss: 0.000106547552
Iter: 140 loss: 0.000106052794
Iter: 141 loss: 0.000105968233
Iter: 142 loss: 0.000106323547
Iter: 143 loss: 0.000105950181
Iter: 144 loss: 0.000105875486
Iter: 145 loss: 0.000106095264
Iter: 146 loss: 0.00010585264
Iter: 147 loss: 0.000105783183
Iter: 148 loss: 0.000105921987
Iter: 149 loss: 0.000105754749
Iter: 150 loss: 0.000105687373
Iter: 151 loss: 0.000105852982
Iter: 152 loss: 0.000105663436
Iter: 153 loss: 0.000105601073
Iter: 154 loss: 0.000105728548
Iter: 155 loss: 0.000105575855
Iter: 156 loss: 0.000105518942
Iter: 157 loss: 0.000105790816
Iter: 158 loss: 0.00010550869
Iter: 159 loss: 0.000105463158
Iter: 160 loss: 0.000105809748
Iter: 161 loss: 0.000105459592
Iter: 162 loss: 0.00010542402
Iter: 163 loss: 0.000105427927
Iter: 164 loss: 0.000105396539
Iter: 165 loss: 0.00010535503
Iter: 166 loss: 0.000105529376
Iter: 167 loss: 0.000105346262
Iter: 168 loss: 0.00010530898
Iter: 169 loss: 0.000105429834
Iter: 170 loss: 0.000105298583
Iter: 171 loss: 0.000105266445
Iter: 172 loss: 0.000105305357
Iter: 173 loss: 0.000105249455
Iter: 174 loss: 0.000105217478
Iter: 175 loss: 0.000105328319
Iter: 176 loss: 0.000105209314
Iter: 177 loss: 0.00010518403
Iter: 178 loss: 0.000105407758
Iter: 179 loss: 0.000105182815
Iter: 180 loss: 0.000105162799
Iter: 181 loss: 0.0001052187
Iter: 182 loss: 0.000105156541
Iter: 183 loss: 0.000105138468
Iter: 184 loss: 0.000105210798
Iter: 185 loss: 0.000105134422
Iter: 186 loss: 0.000105118306
Iter: 187 loss: 0.000105133324
Iter: 188 loss: 0.000105109109
Iter: 189 loss: 0.000105092244
Iter: 190 loss: 0.000105169027
Iter: 191 loss: 0.00010508894
Iter: 192 loss: 0.00010507465
Iter: 193 loss: 0.000105090854
Iter: 194 loss: 0.000105067178
Iter: 195 loss: 0.000105052524
Iter: 196 loss: 0.000105133462
Iter: 197 loss: 0.000105050407
Iter: 198 loss: 0.000105037179
Iter: 199 loss: 0.000105094732
Iter: 200 loss: 0.000105034509
Iter: 201 loss: 0.000105024897
Iter: 202 loss: 0.000105034269
Iter: 203 loss: 0.000105019099
Iter: 204 loss: 0.000105007945
Iter: 205 loss: 0.000105047395
Iter: 206 loss: 0.000105005267
Iter: 207 loss: 0.000104996041
Iter: 208 loss: 0.000105021332
Iter: 209 loss: 0.00010499308
Iter: 210 loss: 0.000104984065
Iter: 211 loss: 0.000105011946
Iter: 212 loss: 0.000104981424
Iter: 213 loss: 0.000104973064
Iter: 214 loss: 0.000104990409
Iter: 215 loss: 0.000104969717
Iter: 216 loss: 0.000104962077
Iter: 217 loss: 0.000104989071
Iter: 218 loss: 0.00010496
Iter: 219 loss: 0.00010495395
Iter: 220 loss: 0.000105025538
Iter: 221 loss: 0.00010495387
Iter: 222 loss: 0.000104949089
Iter: 223 loss: 0.000104949038
Iter: 224 loss: 0.000104945299
Iter: 225 loss: 0.000104939762
Iter: 226 loss: 0.000104961131
Iter: 227 loss: 0.00010493851
Iter: 228 loss: 0.000104933511
Iter: 229 loss: 0.000104951556
Iter: 230 loss: 0.000104932085
Iter: 231 loss: 0.00010492788
Iter: 232 loss: 0.000104934981
Iter: 233 loss: 0.000104925857
Iter: 234 loss: 0.000104921724
Iter: 235 loss: 0.000104952385
Iter: 236 loss: 0.000104921295
Iter: 237 loss: 0.000104917825
Iter: 238 loss: 0.000104921812
Iter: 239 loss: 0.000104916129
Iter: 240 loss: 0.000104912673
Iter: 241 loss: 0.000104918407
Iter: 242 loss: 0.000104911087
Iter: 243 loss: 0.000104907624
Iter: 244 loss: 0.000104925872
Iter: 245 loss: 0.000104907129
Iter: 246 loss: 0.000104904349
Iter: 247 loss: 0.000104908868
Iter: 248 loss: 0.000104903083
Iter: 249 loss: 0.000104900202
Iter: 250 loss: 0.000104911051
Iter: 251 loss: 0.000104899686
Iter: 252 loss: 0.000104897168
Iter: 253 loss: 0.000104905877
Iter: 254 loss: 0.000104896593
Iter: 255 loss: 0.000104894607
Iter: 256 loss: 0.000104902458
Iter: 257 loss: 0.000104894105
Iter: 258 loss: 0.000104892242
Iter: 259 loss: 0.000104903054
Iter: 260 loss: 0.000104892046
Iter: 261 loss: 0.000104890452
Iter: 262 loss: 0.000104890656
Iter: 263 loss: 0.000104889463
Iter: 264 loss: 0.000104887797
Iter: 265 loss: 0.000104894702
Iter: 266 loss: 0.000104887418
Iter: 267 loss: 0.000104885985
Iter: 268 loss: 0.000104893741
Iter: 269 loss: 0.000104885788
Iter: 270 loss: 0.000104884653
Iter: 271 loss: 0.000104887265
Iter: 272 loss: 0.000104884173
Iter: 273 loss: 0.000104883016
Iter: 274 loss: 0.000104886945
Iter: 275 loss: 0.000104882696
Iter: 276 loss: 0.000104881699
Iter: 277 loss: 0.000104883387
Iter: 278 loss: 0.00010488127
Iter: 279 loss: 0.000104879946
Iter: 280 loss: 0.000104882347
Iter: 281 loss: 0.000104879728
Iter: 282 loss: 0.000104878709
Iter: 283 loss: 0.000104881947
Iter: 284 loss: 0.000104878418
Iter: 285 loss: 0.000104877698
Iter: 286 loss: 0.000104881707
Iter: 287 loss: 0.000104877465
Iter: 288 loss: 0.000104876584
Iter: 289 loss: 0.000104878513
Iter: 290 loss: 0.000104876308
Iter: 291 loss: 0.000104875755
Iter: 292 loss: 0.000104878316
Iter: 293 loss: 0.000104875558
Iter: 294 loss: 0.000104874976
Iter: 295 loss: 0.000104879276
Iter: 296 loss: 0.000104874911
Iter: 297 loss: 0.000104874569
Iter: 298 loss: 0.000104874875
Iter: 299 loss: 0.000104874198
Iter: 300 loss: 0.00010487363
Iter: 301 loss: 0.000104874118
Iter: 302 loss: 0.000104873441
Iter: 303 loss: 0.000104872859
Iter: 304 loss: 0.000104876293
Iter: 305 loss: 0.000104872743
Iter: 306 loss: 0.000104872386
Iter: 307 loss: 0.000104874205
Iter: 308 loss: 0.000104872241
Iter: 309 loss: 0.000104871862
Iter: 310 loss: 0.000104872408
Iter: 311 loss: 0.000104871768
Iter: 312 loss: 0.000104871331
Iter: 313 loss: 0.000104872612
Iter: 314 loss: 0.000104871309
Iter: 315 loss: 0.00010487096
Iter: 316 loss: 0.000104871411
Iter: 317 loss: 0.0001048708
Iter: 318 loss: 0.000104870443
Iter: 319 loss: 0.000104871331
Iter: 320 loss: 0.000104870327
Iter: 321 loss: 0.000104869992
Iter: 322 loss: 0.000104871491
Iter: 323 loss: 0.000104869847
Iter: 324 loss: 0.000104869818
Iter: 325 loss: 0.000104870327
Iter: 326 loss: 0.000104869599
Iter: 327 loss: 0.000104869338
Iter: 328 loss: 0.000104870691
Iter: 329 loss: 0.000104869236
Iter: 330 loss: 0.000104869185
Iter: 331 loss: 0.00010487024
Iter: 332 loss: 0.000104869068
Iter: 333 loss: 0.000104868879
Iter: 334 loss: 0.000104869265
Iter: 335 loss: 0.00010486893
Iter: 336 loss: 0.000104868814
Iter: 337 loss: 0.000104868988
Iter: 338 loss: 0.000104868544
Iter: 339 loss: 0.000104868501
Iter: 340 loss: 0.00010486877
Iter: 341 loss: 0.000104868479
Iter: 342 loss: 0.000104868304
Iter: 343 loss: 0.000104869687
Iter: 344 loss: 0.00010486837
Iter: 345 loss: 0.000104868304
Iter: 346 loss: 0.000104868319
Iter: 347 loss: 0.000104868202
Iter: 348 loss: 0.000104868028
Iter: 349 loss: 0.000104868086
Iter: 350 loss: 0.000104868021
Iter: 351 loss: 0.000104867751
Iter: 352 loss: 0.000104868646
Iter: 353 loss: 0.000104867751
Iter: 354 loss: 0.000104867591
Iter: 355 loss: 0.000104867744
Iter: 356 loss: 0.000104867766
Iter: 357 loss: 0.000104867533
Iter: 358 loss: 0.000104867911
Iter: 359 loss: 0.000104867504
Iter: 360 loss: 0.000104867497
Iter: 361 loss: 0.000104867788
Iter: 362 loss: 0.000104867446
Iter: 363 loss: 0.000104867337
Iter: 364 loss: 0.000104867562
Iter: 365 loss: 0.000104867344
Iter: 366 loss: 0.000104867242
Iter: 367 loss: 0.000104867606
Iter: 368 loss: 0.000104867271
Iter: 369 loss: 0.000104867198
Iter: 370 loss: 0.000104867257
Iter: 371 loss: 0.000104867206
Iter: 372 loss: 0.00010486706
Iter: 373 loss: 0.000104867169
Iter: 374 loss: 0.000104867067
Iter: 375 loss: 0.00010486698
Iter: 376 loss: 0.000104867097
Iter: 377 loss: 0.000104866958
Iter: 378 loss: 0.000104866747
Iter: 379 loss: 0.000104867358
Iter: 380 loss: 0.000104866958
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8
+ date
Tue Oct 27 14:53:34 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1827455510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18273f9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18274df950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182738bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182738bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18273b82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1827303620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18273037b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182732f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18272d8b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182729db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18272a0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182723d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271ff840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271ff510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1827215840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271e0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271e77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182714d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271e09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271729d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18271258c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18270d6048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18270ec950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18270ecbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18270a5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f182706e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18270132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1827013268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826fc9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826f808c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826fa47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826fa4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826f49c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826f67d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1826f259d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0182081759
Iter: 2 loss: 0.0178430136
Iter: 3 loss: 0.0164558478
Iter: 4 loss: 0.0118401255
Iter: 5 loss: 9936.3623
Iter: 6 loss: 0.0118401255
Iter: 7 loss: 0.00768081238
Iter: 8 loss: 0.0792865083
Iter: 9 loss: 0.00742115593
Iter: 10 loss: 0.00395373441
Iter: 11 loss: 0.079913348
Iter: 12 loss: 0.00395204965
Iter: 13 loss: 0.00259293662
Iter: 14 loss: 0.0125286933
Iter: 15 loss: 0.00239617727
Iter: 16 loss: 0.00175489101
Iter: 17 loss: 0.00793351047
Iter: 18 loss: 0.00171485147
Iter: 19 loss: 0.00135329145
Iter: 20 loss: 0.00135255372
Iter: 21 loss: 0.00112742628
Iter: 22 loss: 0.00182495173
Iter: 23 loss: 0.00105838047
Iter: 24 loss: 0.000877137121
Iter: 25 loss: 0.000995664624
Iter: 26 loss: 0.000760346185
Iter: 27 loss: 0.000616348116
Iter: 28 loss: 0.0019674676
Iter: 29 loss: 0.000607098744
Iter: 30 loss: 0.00051596947
Iter: 31 loss: 0.000963563914
Iter: 32 loss: 0.000500839204
Iter: 33 loss: 0.000435856695
Iter: 34 loss: 0.00063033629
Iter: 35 loss: 0.000414710288
Iter: 36 loss: 0.000371980888
Iter: 37 loss: 0.000530302641
Iter: 38 loss: 0.000362092425
Iter: 39 loss: 0.000329779577
Iter: 40 loss: 0.000471174164
Iter: 41 loss: 0.000322549371
Iter: 42 loss: 0.00030126897
Iter: 43 loss: 0.000362556457
Iter: 44 loss: 0.000294697646
Iter: 45 loss: 0.000271331577
Iter: 46 loss: 0.000330908137
Iter: 47 loss: 0.000263219699
Iter: 48 loss: 0.000244890573
Iter: 49 loss: 0.000302694272
Iter: 50 loss: 0.000239644854
Iter: 51 loss: 0.000225762502
Iter: 52 loss: 0.000270673307
Iter: 53 loss: 0.000221845
Iter: 54 loss: 0.000210065744
Iter: 55 loss: 0.000270213903
Iter: 56 loss: 0.000208121841
Iter: 57 loss: 0.000199971866
Iter: 58 loss: 0.0002926905
Iter: 59 loss: 0.000199817441
Iter: 60 loss: 0.000193298329
Iter: 61 loss: 0.000202167736
Iter: 62 loss: 0.000190040475
Iter: 63 loss: 0.000184346893
Iter: 64 loss: 0.000194560649
Iter: 65 loss: 0.000181859767
Iter: 66 loss: 0.000176244066
Iter: 67 loss: 0.000194242748
Iter: 68 loss: 0.000174631365
Iter: 69 loss: 0.000169755673
Iter: 70 loss: 0.000181425479
Iter: 71 loss: 0.000167988619
Iter: 72 loss: 0.000163991179
Iter: 73 loss: 0.000185376572
Iter: 74 loss: 0.000163358753
Iter: 75 loss: 0.000160439668
Iter: 76 loss: 0.000198394118
Iter: 77 loss: 0.00016042612
Iter: 78 loss: 0.000158307841
Iter: 79 loss: 0.000158635434
Iter: 80 loss: 0.000156699825
Iter: 81 loss: 0.000154312685
Iter: 82 loss: 0.000159031086
Iter: 83 loss: 0.000153334433
Iter: 84 loss: 0.000151152635
Iter: 85 loss: 0.000157439077
Iter: 86 loss: 0.000150465916
Iter: 87 loss: 0.00014847875
Iter: 88 loss: 0.00015273616
Iter: 89 loss: 0.000147699349
Iter: 90 loss: 0.000145795842
Iter: 91 loss: 0.000154483976
Iter: 92 loss: 0.000145432496
Iter: 93 loss: 0.000143899219
Iter: 94 loss: 0.000150801643
Iter: 95 loss: 0.000143601239
Iter: 96 loss: 0.000142308258
Iter: 97 loss: 0.000152066525
Iter: 98 loss: 0.000142207486
Iter: 99 loss: 0.000141228375
Iter: 100 loss: 0.000142465447
Iter: 101 loss: 0.000140722288
Iter: 102 loss: 0.000139706215
Iter: 103 loss: 0.000140196382
Iter: 104 loss: 0.000139024458
Iter: 105 loss: 0.000137864612
Iter: 106 loss: 0.000140375458
Iter: 107 loss: 0.000137414419
Iter: 108 loss: 0.00013638394
Iter: 109 loss: 0.000145022495
Iter: 110 loss: 0.000136324787
Iter: 111 loss: 0.000135627095
Iter: 112 loss: 0.000142364413
Iter: 113 loss: 0.000135599679
Iter: 114 loss: 0.000135003764
Iter: 115 loss: 0.000135503768
Iter: 116 loss: 0.000134651506
Iter: 117 loss: 0.000134086222
Iter: 118 loss: 0.000134384027
Iter: 119 loss: 0.000133712136
Iter: 120 loss: 0.000133054084
Iter: 121 loss: 0.00013469081
Iter: 122 loss: 0.000132822417
Iter: 123 loss: 0.000132189016
Iter: 124 loss: 0.000134489499
Iter: 125 loss: 0.000132030036
Iter: 126 loss: 0.000131466441
Iter: 127 loss: 0.000132929214
Iter: 128 loss: 0.000131274399
Iter: 129 loss: 0.000130833956
Iter: 130 loss: 0.000135132941
Iter: 131 loss: 0.00013081792
Iter: 132 loss: 0.00013044622
Iter: 133 loss: 0.000131544963
Iter: 134 loss: 0.000130332337
Iter: 135 loss: 0.000129992055
Iter: 136 loss: 0.000130579472
Iter: 137 loss: 0.000129840599
Iter: 138 loss: 0.000129503911
Iter: 139 loss: 0.000129774387
Iter: 140 loss: 0.000129301276
Iter: 141 loss: 0.000128928485
Iter: 142 loss: 0.000130027707
Iter: 143 loss: 0.000128813932
Iter: 144 loss: 0.000128505475
Iter: 145 loss: 0.000131123379
Iter: 146 loss: 0.000128487445
Iter: 147 loss: 0.000128248066
Iter: 148 loss: 0.000130031229
Iter: 149 loss: 0.000128229265
Iter: 150 loss: 0.000128045154
Iter: 151 loss: 0.000128035608
Iter: 152 loss: 0.000127894833
Iter: 153 loss: 0.00012767312
Iter: 154 loss: 0.000127783424
Iter: 155 loss: 0.00012752488
Iter: 156 loss: 0.000127271764
Iter: 157 loss: 0.000128334315
Iter: 158 loss: 0.000127217878
Iter: 159 loss: 0.000126999221
Iter: 160 loss: 0.000127523221
Iter: 161 loss: 0.000126920044
Iter: 162 loss: 0.000126720857
Iter: 163 loss: 0.00012765557
Iter: 164 loss: 0.00012668407
Iter: 165 loss: 0.000126532541
Iter: 166 loss: 0.000127888939
Iter: 167 loss: 0.000126525149
Iter: 168 loss: 0.000126395986
Iter: 169 loss: 0.000126591403
Iter: 170 loss: 0.000126334635
Iter: 171 loss: 0.000126205239
Iter: 172 loss: 0.000126417261
Iter: 173 loss: 0.000126145926
Iter: 174 loss: 0.000126007464
Iter: 175 loss: 0.000126184474
Iter: 176 loss: 0.000125936363
Iter: 177 loss: 0.000125792954
Iter: 178 loss: 0.000126194063
Iter: 179 loss: 0.000125746927
Iter: 180 loss: 0.000125647406
Iter: 181 loss: 0.000125647086
Iter: 182 loss: 0.000125564024
Iter: 183 loss: 0.000125687919
Iter: 184 loss: 0.000125524224
Iter: 185 loss: 0.00012543911
Iter: 186 loss: 0.00012545714
Iter: 187 loss: 0.000125376187
Iter: 188 loss: 0.000125279039
Iter: 189 loss: 0.00012547044
Iter: 190 loss: 0.000125238934
Iter: 191 loss: 0.000125143459
Iter: 192 loss: 0.000125475228
Iter: 193 loss: 0.000125118459
Iter: 194 loss: 0.000125032209
Iter: 195 loss: 0.000125287945
Iter: 196 loss: 0.000125005943
Iter: 197 loss: 0.00012492828
Iter: 198 loss: 0.000125264458
Iter: 199 loss: 0.000124912607
Iter: 200 loss: 0.000124850834
Iter: 201 loss: 0.000125474
Iter: 202 loss: 0.000124848943
Iter: 203 loss: 0.000124802347
Iter: 204 loss: 0.000124814804
Iter: 205 loss: 0.0001247685
Iter: 206 loss: 0.000124712591
Iter: 207 loss: 0.000124810656
Iter: 208 loss: 0.000124687882
Iter: 209 loss: 0.000124628888
Iter: 210 loss: 0.000124794751
Iter: 211 loss: 0.000124610116
Iter: 212 loss: 0.000124557759
Iter: 213 loss: 0.000124733007
Iter: 214 loss: 0.000124543556
Iter: 215 loss: 0.000124505721
Iter: 216 loss: 0.000124505721
Iter: 217 loss: 0.000124477316
Iter: 218 loss: 0.00012446077
Iter: 219 loss: 0.000124448445
Iter: 220 loss: 0.000124409635
Iter: 221 loss: 0.000124467013
Iter: 222 loss: 0.000124390819
Iter: 223 loss: 0.000124351907
Iter: 224 loss: 0.000124450133
Iter: 225 loss: 0.000124338301
Iter: 226 loss: 0.000124300277
Iter: 227 loss: 0.000124414684
Iter: 228 loss: 0.000124288577
Iter: 229 loss: 0.000124253726
Iter: 230 loss: 0.000124353275
Iter: 231 loss: 0.000124242782
Iter: 232 loss: 0.000124213519
Iter: 233 loss: 0.000124432641
Iter: 234 loss: 0.00012421119
Iter: 235 loss: 0.00012418523
Iter: 236 loss: 0.000124292477
Iter: 237 loss: 0.000124179584
Iter: 238 loss: 0.00012415777
Iter: 239 loss: 0.000124174883
Iter: 240 loss: 0.000124144441
Iter: 241 loss: 0.000124120081
Iter: 242 loss: 0.000124160084
Iter: 243 loss: 0.000124108919
Iter: 244 loss: 0.000124084137
Iter: 245 loss: 0.00012417
Iter: 246 loss: 0.000124077691
Iter: 247 loss: 0.000124056765
Iter: 248 loss: 0.000124200888
Iter: 249 loss: 0.000124054714
Iter: 250 loss: 0.000124037178
Iter: 251 loss: 0.000124154787
Iter: 252 loss: 0.00012403552
Iter: 253 loss: 0.00012402283
Iter: 254 loss: 0.00012401228
Iter: 255 loss: 0.000124008569
Iter: 256 loss: 0.000123990292
Iter: 257 loss: 0.000124026323
Iter: 258 loss: 0.0001239829
Iter: 259 loss: 0.000123964608
Iter: 260 loss: 0.000124036349
Iter: 261 loss: 0.000123960461
Iter: 262 loss: 0.000123944395
Iter: 263 loss: 0.000123974329
Iter: 264 loss: 0.000123937469
Iter: 265 loss: 0.000123921796
Iter: 266 loss: 0.00012399102
Iter: 267 loss: 0.000123918726
Iter: 268 loss: 0.000123906822
Iter: 269 loss: 0.00012401164
Iter: 270 loss: 0.000123906095
Iter: 271 loss: 0.000123895647
Iter: 272 loss: 0.000123918697
Iter: 273 loss: 0.000123891965
Iter: 274 loss: 0.000123881749
Iter: 275 loss: 0.00012388645
Iter: 276 loss: 0.000123875041
Iter: 277 loss: 0.000123863836
Iter: 278 loss: 0.000123892751
Iter: 279 loss: 0.000123860067
Iter: 280 loss: 0.000123849764
Iter: 281 loss: 0.00012390624
Iter: 282 loss: 0.000123848207
Iter: 283 loss: 0.000123840466
Iter: 284 loss: 0.000123905629
Iter: 285 loss: 0.000123839971
Iter: 286 loss: 0.00012383287
Iter: 287 loss: 0.000123842037
Iter: 288 loss: 0.000123829377
Iter: 289 loss: 0.000123822625
Iter: 290 loss: 0.000123820399
Iter: 291 loss: 0.000123816775
Iter: 292 loss: 0.000123808073
Iter: 293 loss: 0.000123841499
Iter: 294 loss: 0.00012380608
Iter: 295 loss: 0.000123798221
Iter: 296 loss: 0.000123819656
Iter: 297 loss: 0.000123795675
Iter: 298 loss: 0.000123788195
Iter: 299 loss: 0.000123806414
Iter: 300 loss: 0.000123785576
Iter: 301 loss: 0.000123778445
Iter: 302 loss: 0.000123809092
Iter: 303 loss: 0.000123777252
Iter: 304 loss: 0.000123771664
Iter: 305 loss: 0.000123826729
Iter: 306 loss: 0.000123771606
Iter: 307 loss: 0.000123767109
Iter: 308 loss: 0.000123767939
Iter: 309 loss: 0.000123763719
Iter: 310 loss: 0.000123758335
Iter: 311 loss: 0.000123767633
Iter: 312 loss: 0.000123756035
Iter: 313 loss: 0.000123750826
Iter: 314 loss: 0.000123762569
Iter: 315 loss: 0.000123748803
Iter: 316 loss: 0.000123743768
Iter: 317 loss: 0.000123784557
Iter: 318 loss: 0.000123743448
Iter: 319 loss: 0.000123739475
Iter: 320 loss: 0.000123764403
Iter: 321 loss: 0.000123739039
Iter: 322 loss: 0.000123735867
Iter: 323 loss: 0.000123734208
Iter: 324 loss: 0.000123732752
Iter: 325 loss: 0.000123728445
Iter: 326 loss: 0.000123735925
Iter: 327 loss: 0.000123726641
Iter: 328 loss: 0.000123722406
Iter: 329 loss: 0.000123732141
Iter: 330 loss: 0.000123720703
Iter: 331 loss: 0.000123716629
Iter: 332 loss: 0.000123731152
Iter: 333 loss: 0.000123715436
Iter: 334 loss: 0.000123711477
Iter: 335 loss: 0.000123723061
Iter: 336 loss: 0.000123710255
Iter: 337 loss: 0.000123706472
Iter: 338 loss: 0.000123726146
Iter: 339 loss: 0.000123706239
Iter: 340 loss: 0.000123703212
Iter: 341 loss: 0.000123723134
Iter: 342 loss: 0.000123702775
Iter: 343 loss: 0.000123700433
Iter: 344 loss: 0.000123700112
Iter: 345 loss: 0.000123698483
Iter: 346 loss: 0.000123695587
Iter: 347 loss: 0.000123701102
Iter: 348 loss: 0.000123694219
Iter: 349 loss: 0.000123691279
Iter: 350 loss: 0.000123708363
Iter: 351 loss: 0.000123690901
Iter: 352 loss: 0.000123688573
Iter: 353 loss: 0.000123706559
Iter: 354 loss: 0.0001236885
Iter: 355 loss: 0.000123686346
Iter: 356 loss: 0.000123690785
Iter: 357 loss: 0.000123685546
Iter: 358 loss: 0.000123683974
Iter: 359 loss: 0.000123683712
Iter: 360 loss: 0.000123682636
Iter: 361 loss: 0.000123680031
Iter: 362 loss: 0.000123686506
Iter: 363 loss: 0.000123679405
Iter: 364 loss: 0.000123677266
Iter: 365 loss: 0.000123680802
Iter: 366 loss: 0.000123676029
Iter: 367 loss: 0.000123673788
Iter: 368 loss: 0.000123683421
Iter: 369 loss: 0.000123673381
Iter: 370 loss: 0.000123671343
Iter: 371 loss: 0.000123680118
Iter: 372 loss: 0.000123670907
Iter: 373 loss: 0.00012366935
Iter: 374 loss: 0.00012367923
Iter: 375 loss: 0.000123669088
Iter: 376 loss: 0.000123667676
Iter: 377 loss: 0.00012367095
Iter: 378 loss: 0.000123666978
Iter: 379 loss: 0.000123665755
Iter: 380 loss: 0.000123666017
Iter: 381 loss: 0.000123664606
Iter: 382 loss: 0.000123662889
Iter: 383 loss: 0.0001236682
Iter: 384 loss: 0.000123662438
Iter: 385 loss: 0.000123661041
Iter: 386 loss: 0.000123671009
Iter: 387 loss: 0.000123660837
Iter: 388 loss: 0.00012365976
Iter: 389 loss: 0.000123668884
Iter: 390 loss: 0.000123659614
Iter: 391 loss: 0.000123658712
Iter: 392 loss: 0.000123657926
Iter: 393 loss: 0.000123657606
Iter: 394 loss: 0.000123656355
Iter: 395 loss: 0.000123659847
Iter: 396 loss: 0.000123655875
Iter: 397 loss: 0.00012365458
Iter: 398 loss: 0.00012365765
Iter: 399 loss: 0.000123654245
Iter: 400 loss: 0.000123652964
Iter: 401 loss: 0.000123655453
Iter: 402 loss: 0.000123652513
Iter: 403 loss: 0.000123651349
Iter: 404 loss: 0.000123656355
Iter: 405 loss: 0.000123651087
Iter: 406 loss: 0.000123650316
Iter: 407 loss: 0.00012365474
Iter: 408 loss: 0.000123650025
Iter: 409 loss: 0.000123649137
Iter: 410 loss: 0.000123655263
Iter: 411 loss: 0.000123649123
Iter: 412 loss: 0.000123648177
Iter: 413 loss: 0.000123648584
Iter: 414 loss: 0.000123647784
Iter: 415 loss: 0.000123647042
Iter: 416 loss: 0.00012364774
Iter: 417 loss: 0.000123646416
Iter: 418 loss: 0.000123645616
Iter: 419 loss: 0.000123649981
Iter: 420 loss: 0.000123645354
Iter: 421 loss: 0.000123644684
Iter: 422 loss: 0.000123652426
Iter: 423 loss: 0.000123644582
Iter: 424 loss: 0.000123644044
Iter: 425 loss: 0.000123645
Iter: 426 loss: 0.000123643782
Iter: 427 loss: 0.000123643316
Iter: 428 loss: 0.000123642967
Iter: 429 loss: 0.000123642763
Iter: 430 loss: 0.000123642
Iter: 431 loss: 0.000123644815
Iter: 432 loss: 0.000123641948
Iter: 433 loss: 0.000123641221
Iter: 434 loss: 0.00012364256
Iter: 435 loss: 0.000123640915
Iter: 436 loss: 0.000123640304
Iter: 437 loss: 0.000123641876
Iter: 438 loss: 0.000123640144
Iter: 439 loss: 0.000123639329
Iter: 440 loss: 0.000123642778
Iter: 441 loss: 0.000123639373
Iter: 442 loss: 0.000123638849
Iter: 443 loss: 0.000123641745
Iter: 444 loss: 0.000123638631
Iter: 445 loss: 0.000123638383
Iter: 446 loss: 0.000123639882
Iter: 447 loss: 0.000123638223
Iter: 448 loss: 0.000123637903
Iter: 449 loss: 0.000123637757
Iter: 450 loss: 0.000123637525
Iter: 451 loss: 0.000123636943
Iter: 452 loss: 0.000123638398
Iter: 453 loss: 0.000123636768
Iter: 454 loss: 0.000123636462
Iter: 455 loss: 0.000123638456
Iter: 456 loss: 0.000123636302
Iter: 457 loss: 0.000123635982
Iter: 458 loss: 0.000123639504
Iter: 459 loss: 0.000123636011
Iter: 460 loss: 0.000123635822
Iter: 461 loss: 0.000123635662
Iter: 462 loss: 0.000123635575
Iter: 463 loss: 0.000123635022
Iter: 464 loss: 0.000123635691
Iter: 465 loss: 0.000123634993
Iter: 466 loss: 0.000123634585
Iter: 467 loss: 0.000123635953
Iter: 468 loss: 0.000123634469
Iter: 469 loss: 0.000123634105
Iter: 470 loss: 0.000123634847
Iter: 471 loss: 0.000123633974
Iter: 472 loss: 0.000123633639
Iter: 473 loss: 0.000123634527
Iter: 474 loss: 0.000123633348
Iter: 475 loss: 0.000123633072
Iter: 476 loss: 0.000123634483
Iter: 477 loss: 0.000123633174
Iter: 478 loss: 0.000123632737
Iter: 479 loss: 0.000123635546
Iter: 480 loss: 0.000123632868
Iter: 481 loss: 0.000123632664
Iter: 482 loss: 0.000123632606
Iter: 483 loss: 0.00012363249
Iter: 484 loss: 0.000123632286
Iter: 485 loss: 0.000123632635
Iter: 486 loss: 0.000123632097
Iter: 487 loss: 0.000123631689
Iter: 488 loss: 0.000123632417
Iter: 489 loss: 0.000123631777
Iter: 490 loss: 0.000123631486
Iter: 491 loss: 0.000123634527
Iter: 492 loss: 0.0001236315
Iter: 493 loss: 0.000123631296
Iter: 494 loss: 0.000123631587
Iter: 495 loss: 0.000123631267
Iter: 496 loss: 0.000123630918
Iter: 497 loss: 0.000123631093
Iter: 498 loss: 0.000123630918
Iter: 499 loss: 0.000123630598
Iter: 500 loss: 0.000123631384
Iter: 501 loss: 0.000123630525
Iter: 502 loss: 0.000123630321
Iter: 503 loss: 0.000123630918
Iter: 504 loss: 0.000123630234
Iter: 505 loss: 0.000123630089
Iter: 506 loss: 0.000123630613
Iter: 507 loss: 0.000123630103
Iter: 508 loss: 0.000123629841
Iter: 509 loss: 0.000123630511
Iter: 510 loss: 0.000123629885
Iter: 511 loss: 0.000123629638
Iter: 512 loss: 0.000123630423
Iter: 513 loss: 0.000123629594
Iter: 514 loss: 0.000123629463
Iter: 515 loss: 0.000123630613
Iter: 516 loss: 0.000123629463
Iter: 517 loss: 0.000123629274
Iter: 518 loss: 0.000123629157
Iter: 519 loss: 0.000123629317
Iter: 520 loss: 0.000123629
Iter: 521 loss: 0.000123629434
Iter: 522 loss: 0.000123629
Iter: 523 loss: 0.000123628663
Iter: 524 loss: 0.000123629608
Iter: 525 loss: 0.000123628794
Iter: 526 loss: 0.000123628794
Iter: 527 loss: 0.000123630045
Iter: 528 loss: 0.000123628648
Iter: 529 loss: 0.000123628532
Iter: 530 loss: 0.000123628619
Iter: 531 loss: 0.000123628532
Iter: 532 loss: 0.000123628328
Iter: 533 loss: 0.000123628473
Iter: 534 loss: 0.00012362827
Iter: 535 loss: 0.000123628153
Iter: 536 loss: 0.00012362875
Iter: 537 loss: 0.000123628182
Iter: 538 loss: 0.00012362795
Iter: 539 loss: 0.000123628299
Iter: 540 loss: 0.000123627964
Iter: 541 loss: 0.00012362792
Iter: 542 loss: 0.000123628095
Iter: 543 loss: 0.000123627804
Iter: 544 loss: 0.000123627717
Iter: 545 loss: 0.00012362811
Iter: 546 loss: 0.000123627528
Iter: 547 loss: 0.000123627702
Iter: 548 loss: 0.000123627498
Iter: 549 loss: 0.0001236276
Iter: 550 loss: 0.000123627615
Iter: 551 loss: 0.000123627658
Iter: 552 loss: 0.000123627673
Iter: 553 loss: 0.000123627658
Iter: 554 loss: 0.000123627688
Iter: 555 loss: 0.000123627542
Iter: 556 loss: 0.0001236276
Iter: 557 loss: 0.000123627571
Iter: 558 loss: 0.000123627542
Iter: 559 loss: 0.000123627615
Iter: 560 loss: 0.0001236276
Iter: 561 loss: 0.000123627644
Iter: 562 loss: 0.000123627702
Iter: 563 loss: 0.000123627673
Iter: 564 loss: 0.000123627658
Iter: 565 loss: 0.000123627644
Iter: 566 loss: 0.000123627644
Iter: 567 loss: 0.000123627658
Iter: 568 loss: 0.000123627658
Iter: 569 loss: 0.000123627644
Iter: 570 loss: 0.000123627658
Iter: 571 loss: 0.000123627658
Iter: 572 loss: 0.000123627644
Iter: 573 loss: 0.000123627397
Iter: 574 loss: 0.000123627877
Iter: 575 loss: 0.000123627484
Iter: 576 loss: 0.000123627338
Iter: 577 loss: 0.000123627833
Iter: 578 loss: 0.000123627236
Iter: 579 loss: 0.000123627309
Iter: 580 loss: 0.000123627586
Iter: 581 loss: 0.000123627164
Iter: 582 loss: 0.000123627076
Iter: 583 loss: 0.000123627207
Iter: 584 loss: 0.000123627076
Iter: 585 loss: 0.000123626902
Iter: 586 loss: 0.000123627382
Iter: 587 loss: 0.000123627105
Iter: 588 loss: 0.000123627076
Iter: 589 loss: 0.000123626945
Iter: 590 loss: 0.000123626756
Iter: 591 loss: 0.000123626814
Iter: 592 loss: 0.000123627062
Iter: 593 loss: 0.000123626742
Iter: 594 loss: 0.000123626669
Iter: 595 loss: 0.000123626814
Iter: 596 loss: 0.000123626756
Iter: 597 loss: 0.000123626625
Iter: 598 loss: 0.000123626829
Iter: 599 loss: 0.000123626611
Iter: 600 loss: 0.000123626553
Iter: 601 loss: 0.0001236268
Iter: 602 loss: 0.000123626465
Iter: 603 loss: 0.000123626378
Iter: 604 loss: 0.000123626611
Iter: 605 loss: 0.000123626465
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2
+ date
Tue Oct 27 15:01:49 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc846821e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdca9608bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdca9608ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc845997b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc845af950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc845be2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84510ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc845386a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84510840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc844e8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc844ad9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc8444b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc8444bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84411598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84422e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc844227b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84422510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc8439bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc8439b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84365f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84365ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84334e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc842ef730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc842966a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84296400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84296620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc842776a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84228950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc842286a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc841dcae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc841939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc84228a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc841aa8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc841aac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc8417fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdc841356a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0193256326
Iter: 2 loss: 0.0180622898
Iter: 3 loss: 0.0140968189
Iter: 4 loss: 7305.78857
Iter: 5 loss: 0.0140968217
Iter: 6 loss: 0.0115579814
Iter: 7 loss: 0.0110166855
Iter: 8 loss: 0.0083044
Iter: 9 loss: 0.12214905
Iter: 10 loss: 0.00830355752
Iter: 11 loss: 0.00611550314
Iter: 12 loss: 0.0242266972
Iter: 13 loss: 0.00590244401
Iter: 14 loss: 0.0045615593
Iter: 15 loss: 0.0097812321
Iter: 16 loss: 0.00430104602
Iter: 17 loss: 0.0034164167
Iter: 18 loss: 0.00520198047
Iter: 19 loss: 0.00293854345
Iter: 20 loss: 0.00235712482
Iter: 21 loss: 0.030675834
Iter: 22 loss: 0.00235698186
Iter: 23 loss: 0.00200908072
Iter: 24 loss: 0.00308191963
Iter: 25 loss: 0.00191442412
Iter: 26 loss: 0.00167721312
Iter: 27 loss: 0.00228231284
Iter: 28 loss: 0.00158418575
Iter: 29 loss: 0.00137468753
Iter: 30 loss: 0.00251378305
Iter: 31 loss: 0.00133617595
Iter: 32 loss: 0.00120347319
Iter: 33 loss: 0.00151114829
Iter: 34 loss: 0.00115600578
Iter: 35 loss: 0.00103360158
Iter: 36 loss: 0.00123738381
Iter: 37 loss: 0.000974294904
Iter: 38 loss: 0.000870595
Iter: 39 loss: 0.00119253492
Iter: 40 loss: 0.00083885534
Iter: 41 loss: 0.000760622788
Iter: 42 loss: 0.00155931385
Iter: 43 loss: 0.000758043781
Iter: 44 loss: 0.00069417106
Iter: 45 loss: 0.000866695133
Iter: 46 loss: 0.000672165072
Iter: 47 loss: 0.000618176069
Iter: 48 loss: 0.00081425946
Iter: 49 loss: 0.000604475266
Iter: 50 loss: 0.000555934734
Iter: 51 loss: 0.000905041874
Iter: 52 loss: 0.000550575671
Iter: 53 loss: 0.000510784623
Iter: 54 loss: 0.00055251224
Iter: 55 loss: 0.000488865306
Iter: 56 loss: 0.000447920931
Iter: 57 loss: 0.000804585055
Iter: 58 loss: 0.000445362239
Iter: 59 loss: 0.000420468219
Iter: 60 loss: 0.000572842197
Iter: 61 loss: 0.000417832838
Iter: 62 loss: 0.000398795353
Iter: 63 loss: 0.000494284264
Iter: 64 loss: 0.00039521986
Iter: 65 loss: 0.000380846555
Iter: 66 loss: 0.000387404638
Iter: 67 loss: 0.000371178205
Iter: 68 loss: 0.00035256875
Iter: 69 loss: 0.000423901336
Iter: 70 loss: 0.000347885682
Iter: 71 loss: 0.000330686569
Iter: 72 loss: 0.000420085475
Iter: 73 loss: 0.000327938818
Iter: 74 loss: 0.000313859724
Iter: 75 loss: 0.000340510363
Iter: 76 loss: 0.000307759445
Iter: 77 loss: 0.000295593461
Iter: 78 loss: 0.000319162296
Iter: 79 loss: 0.000290466618
Iter: 80 loss: 0.000279064523
Iter: 81 loss: 0.000313873228
Iter: 82 loss: 0.0002756248
Iter: 83 loss: 0.000265532115
Iter: 84 loss: 0.000333728502
Iter: 85 loss: 0.000264571339
Iter: 86 loss: 0.000256495172
Iter: 87 loss: 0.000266597024
Iter: 88 loss: 0.000252277125
Iter: 89 loss: 0.000244414899
Iter: 90 loss: 0.00028019055
Iter: 91 loss: 0.000242925424
Iter: 92 loss: 0.000236286709
Iter: 93 loss: 0.00024071493
Iter: 94 loss: 0.00023207342
Iter: 95 loss: 0.000225286232
Iter: 96 loss: 0.000249270262
Iter: 97 loss: 0.000223519863
Iter: 98 loss: 0.000217618624
Iter: 99 loss: 0.000266294461
Iter: 100 loss: 0.000217215129
Iter: 101 loss: 0.000213577892
Iter: 102 loss: 0.000213577456
Iter: 103 loss: 0.00021090568
Iter: 104 loss: 0.000209636724
Iter: 105 loss: 0.000208321231
Iter: 106 loss: 0.000204933545
Iter: 107 loss: 0.000210000668
Iter: 108 loss: 0.000203317613
Iter: 109 loss: 0.000199917398
Iter: 110 loss: 0.000229923433
Iter: 111 loss: 0.000199744696
Iter: 112 loss: 0.000197443456
Iter: 113 loss: 0.000194741762
Iter: 114 loss: 0.000194439257
Iter: 115 loss: 0.000190614839
Iter: 116 loss: 0.000213954569
Iter: 117 loss: 0.000190142207
Iter: 118 loss: 0.000187312311
Iter: 119 loss: 0.000200864044
Iter: 120 loss: 0.000186808131
Iter: 121 loss: 0.000184426928
Iter: 122 loss: 0.000190824663
Iter: 123 loss: 0.000183629832
Iter: 124 loss: 0.000181487107
Iter: 125 loss: 0.000185254408
Iter: 126 loss: 0.000180544914
Iter: 127 loss: 0.000178153045
Iter: 128 loss: 0.000187403028
Iter: 129 loss: 0.000177586582
Iter: 130 loss: 0.000175637048
Iter: 131 loss: 0.00018269071
Iter: 132 loss: 0.000175149937
Iter: 133 loss: 0.000173759065
Iter: 134 loss: 0.000192549458
Iter: 135 loss: 0.000173750552
Iter: 136 loss: 0.000172534099
Iter: 137 loss: 0.000175886264
Iter: 138 loss: 0.000172147149
Iter: 139 loss: 0.000171122301
Iter: 140 loss: 0.000170621512
Iter: 141 loss: 0.000170129322
Iter: 142 loss: 0.000168824685
Iter: 143 loss: 0.000175224588
Iter: 144 loss: 0.000168599698
Iter: 145 loss: 0.000167309729
Iter: 146 loss: 0.000170120213
Iter: 147 loss: 0.000166810598
Iter: 148 loss: 0.00016566641
Iter: 149 loss: 0.000167328792
Iter: 150 loss: 0.000165112084
Iter: 151 loss: 0.000163861492
Iter: 152 loss: 0.000166784346
Iter: 153 loss: 0.000163397752
Iter: 154 loss: 0.000162198703
Iter: 155 loss: 0.000166875761
Iter: 156 loss: 0.000161922231
Iter: 157 loss: 0.000160825
Iter: 158 loss: 0.000164323748
Iter: 159 loss: 0.000160509691
Iter: 160 loss: 0.000159519812
Iter: 161 loss: 0.000162403521
Iter: 162 loss: 0.000159214105
Iter: 163 loss: 0.000158262337
Iter: 164 loss: 0.000160203082
Iter: 165 loss: 0.000157875649
Iter: 166 loss: 0.000156940732
Iter: 167 loss: 0.00016064728
Iter: 168 loss: 0.00015673005
Iter: 169 loss: 0.00015600094
Iter: 170 loss: 0.000156000795
Iter: 171 loss: 0.000155518152
Iter: 172 loss: 0.000154944908
Iter: 173 loss: 0.000154884503
Iter: 174 loss: 0.000154133057
Iter: 175 loss: 0.000156832073
Iter: 176 loss: 0.000153941568
Iter: 177 loss: 0.000153249654
Iter: 178 loss: 0.000155519985
Iter: 179 loss: 0.00015305703
Iter: 180 loss: 0.000152392313
Iter: 181 loss: 0.000154433641
Iter: 182 loss: 0.000152194538
Iter: 183 loss: 0.000151601766
Iter: 184 loss: 0.000151934189
Iter: 185 loss: 0.000151214481
Iter: 186 loss: 0.000150553635
Iter: 187 loss: 0.00015264329
Iter: 188 loss: 0.000150362641
Iter: 189 loss: 0.000149690371
Iter: 190 loss: 0.000152747962
Iter: 191 loss: 0.000149561412
Iter: 192 loss: 0.000149037165
Iter: 193 loss: 0.000150602558
Iter: 194 loss: 0.000148877793
Iter: 195 loss: 0.000148328516
Iter: 196 loss: 0.000149420113
Iter: 197 loss: 0.00014810331
Iter: 198 loss: 0.0001475756
Iter: 199 loss: 0.000148681895
Iter: 200 loss: 0.000147365383
Iter: 201 loss: 0.000147079554
Iter: 202 loss: 0.00014704054
Iter: 203 loss: 0.000146768449
Iter: 204 loss: 0.000146667211
Iter: 205 loss: 0.000146516599
Iter: 206 loss: 0.000146159888
Iter: 207 loss: 0.000146274557
Iter: 208 loss: 0.000145906175
Iter: 209 loss: 0.000145507409
Iter: 210 loss: 0.000148177365
Iter: 211 loss: 0.000145467144
Iter: 212 loss: 0.000145131868
Iter: 213 loss: 0.000145710714
Iter: 214 loss: 0.000144982856
Iter: 215 loss: 0.00014461024
Iter: 216 loss: 0.000145534024
Iter: 217 loss: 0.000144478603
Iter: 218 loss: 0.000144142512
Iter: 219 loss: 0.000144288177
Iter: 220 loss: 0.000143912912
Iter: 221 loss: 0.000143507132
Iter: 222 loss: 0.000145425714
Iter: 223 loss: 0.000143433121
Iter: 224 loss: 0.000143078141
Iter: 225 loss: 0.000144560545
Iter: 226 loss: 0.000143002428
Iter: 227 loss: 0.000142679899
Iter: 228 loss: 0.00014332484
Iter: 229 loss: 0.000142548175
Iter: 230 loss: 0.000142231525
Iter: 231 loss: 0.000143306577
Iter: 232 loss: 0.00014214644
Iter: 233 loss: 0.000141893528
Iter: 234 loss: 0.000143902493
Iter: 235 loss: 0.000141875731
Iter: 236 loss: 0.000141645694
Iter: 237 loss: 0.000142997713
Iter: 238 loss: 0.0001416163
Iter: 239 loss: 0.000141457014
Iter: 240 loss: 0.000141257071
Iter: 241 loss: 0.000141241151
Iter: 242 loss: 0.000140978882
Iter: 243 loss: 0.000142053526
Iter: 244 loss: 0.000140921315
Iter: 245 loss: 0.000140689372
Iter: 246 loss: 0.000141638462
Iter: 247 loss: 0.000140638615
Iter: 248 loss: 0.000140416043
Iter: 249 loss: 0.000140819524
Iter: 250 loss: 0.000140319506
Iter: 251 loss: 0.000140096614
Iter: 252 loss: 0.000140469143
Iter: 253 loss: 0.000139995711
Iter: 254 loss: 0.000139771611
Iter: 255 loss: 0.000140159129
Iter: 256 loss: 0.000139671989
Iter: 257 loss: 0.000139438387
Iter: 258 loss: 0.000140582066
Iter: 259 loss: 0.00013939754
Iter: 260 loss: 0.000139192329
Iter: 261 loss: 0.000139818396
Iter: 262 loss: 0.000139131502
Iter: 263 loss: 0.000138942065
Iter: 264 loss: 0.000139383978
Iter: 265 loss: 0.000138872085
Iter: 266 loss: 0.000138687799
Iter: 267 loss: 0.000139764277
Iter: 268 loss: 0.000138664152
Iter: 269 loss: 0.000138529766
Iter: 270 loss: 0.000140003685
Iter: 271 loss: 0.000138526724
Iter: 272 loss: 0.000138420641
Iter: 273 loss: 0.000138364834
Iter: 274 loss: 0.00013831658
Iter: 275 loss: 0.000138185831
Iter: 276 loss: 0.00013825827
Iter: 277 loss: 0.000138100411
Iter: 278 loss: 0.000137940573
Iter: 279 loss: 0.000138931035
Iter: 280 loss: 0.000137921714
Iter: 281 loss: 0.000137783791
Iter: 282 loss: 0.000138171992
Iter: 283 loss: 0.000137739786
Iter: 284 loss: 0.000137616822
Iter: 285 loss: 0.000137770112
Iter: 286 loss: 0.000137553259
Iter: 287 loss: 0.000137407478
Iter: 288 loss: 0.000137653726
Iter: 289 loss: 0.00013734182
Iter: 290 loss: 0.000137194045
Iter: 291 loss: 0.000137632596
Iter: 292 loss: 0.000137148963
Iter: 293 loss: 0.000136999719
Iter: 294 loss: 0.000137537223
Iter: 295 loss: 0.000136962015
Iter: 296 loss: 0.000136834962
Iter: 297 loss: 0.000137201219
Iter: 298 loss: 0.000136795104
Iter: 299 loss: 0.000136676827
Iter: 300 loss: 0.00013740515
Iter: 301 loss: 0.000136662813
Iter: 302 loss: 0.000136586066
Iter: 303 loss: 0.000137372495
Iter: 304 loss: 0.000136583767
Iter: 305 loss: 0.000136514558
Iter: 306 loss: 0.000136545073
Iter: 307 loss: 0.000136467104
Iter: 308 loss: 0.000136390852
Iter: 309 loss: 0.000136361487
Iter: 310 loss: 0.000136320305
Iter: 311 loss: 0.000136222981
Iter: 312 loss: 0.000136711096
Iter: 313 loss: 0.000136206829
Iter: 314 loss: 0.000136115617
Iter: 315 loss: 0.000136522198
Iter: 316 loss: 0.000136098053
Iter: 317 loss: 0.000136024479
Iter: 318 loss: 0.000136135772
Iter: 319 loss: 0.00013598951
Iter: 320 loss: 0.000135904731
Iter: 321 loss: 0.000136005197
Iter: 322 loss: 0.000135859853
Iter: 323 loss: 0.00013577193
Iter: 324 loss: 0.000136094794
Iter: 325 loss: 0.000135750393
Iter: 326 loss: 0.000135666982
Iter: 327 loss: 0.00013579175
Iter: 328 loss: 0.000135627051
Iter: 329 loss: 0.000135545008
Iter: 330 loss: 0.000136064074
Iter: 331 loss: 0.000135535694
Iter: 332 loss: 0.000135466282
Iter: 333 loss: 0.000135688286
Iter: 334 loss: 0.000135446564
Iter: 335 loss: 0.000135397218
Iter: 336 loss: 0.00013598
Iter: 337 loss: 0.000135396578
Iter: 338 loss: 0.000135352631
Iter: 339 loss: 0.000135425013
Iter: 340 loss: 0.000135332666
Iter: 341 loss: 0.000135288283
Iter: 342 loss: 0.000135277078
Iter: 343 loss: 0.000135249051
Iter: 344 loss: 0.000135193783
Iter: 345 loss: 0.000135293711
Iter: 346 loss: 0.000135169859
Iter: 347 loss: 0.00013511139
Iter: 348 loss: 0.000135500231
Iter: 349 loss: 0.000135105394
Iter: 350 loss: 0.000135057082
Iter: 351 loss: 0.00013516171
Iter: 352 loss: 0.000135038426
Iter: 353 loss: 0.000134990376
Iter: 354 loss: 0.000135058988
Iter: 355 loss: 0.000134967
Iter: 356 loss: 0.000134913891
Iter: 357 loss: 0.000134994698
Iter: 358 loss: 0.00013488908
Iter: 359 loss: 0.000134832764
Iter: 360 loss: 0.000135008
Iter: 361 loss: 0.000134816204
Iter: 362 loss: 0.000134764705
Iter: 363 loss: 0.000134985981
Iter: 364 loss: 0.000134754184
Iter: 365 loss: 0.000134707487
Iter: 366 loss: 0.000134856848
Iter: 367 loss: 0.000134694128
Iter: 368 loss: 0.000134659116
Iter: 369 loss: 0.000135019407
Iter: 370 loss: 0.000134658359
Iter: 371 loss: 0.000134628935
Iter: 372 loss: 0.000134743284
Iter: 373 loss: 0.00013462198
Iter: 374 loss: 0.000134596572
Iter: 375 loss: 0.000134584319
Iter: 376 loss: 0.000134572037
Iter: 377 loss: 0.000134536182
Iter: 378 loss: 0.000134586953
Iter: 379 loss: 0.000134518632
Iter: 380 loss: 0.000134481059
Iter: 381 loss: 0.000134631366
Iter: 382 loss: 0.00013447243
Iter: 383 loss: 0.000134439528
Iter: 384 loss: 0.000134647
Iter: 385 loss: 0.000134435832
Iter: 386 loss: 0.000134408125
Iter: 387 loss: 0.000134407805
Iter: 388 loss: 0.000134385948
Iter: 389 loss: 0.00013435047
Iter: 390 loss: 0.000134436399
Iter: 391 loss: 0.000134337621
Iter: 392 loss: 0.000134301139
Iter: 393 loss: 0.000134402886
Iter: 394 loss: 0.000134289323
Iter: 395 loss: 0.00013425597
Iter: 396 loss: 0.000134369911
Iter: 397 loss: 0.00013424702
Iter: 398 loss: 0.000134216927
Iter: 399 loss: 0.000134335307
Iter: 400 loss: 0.000134209942
Iter: 401 loss: 0.000134184171
Iter: 402 loss: 0.000134320348
Iter: 403 loss: 0.000134180329
Iter: 404 loss: 0.00013415757
Iter: 405 loss: 0.000134355665
Iter: 406 loss: 0.000134156318
Iter: 407 loss: 0.000134140835
Iter: 408 loss: 0.000134139147
Iter: 409 loss: 0.00013412816
Iter: 410 loss: 0.000134107977
Iter: 411 loss: 0.000134116373
Iter: 412 loss: 0.000134094182
Iter: 413 loss: 0.000134068949
Iter: 414 loss: 0.000134131958
Iter: 415 loss: 0.000134060247
Iter: 416 loss: 0.000134037036
Iter: 417 loss: 0.000134223665
Iter: 418 loss: 0.000134035668
Iter: 419 loss: 0.000134016504
Iter: 420 loss: 0.000134036978
Iter: 421 loss: 0.000134005939
Iter: 422 loss: 0.000133984926
Iter: 423 loss: 0.000134004309
Iter: 424 loss: 0.000133972731
Iter: 425 loss: 0.000133948459
Iter: 426 loss: 0.000134032714
Iter: 427 loss: 0.000133942143
Iter: 428 loss: 0.000133920694
Iter: 429 loss: 0.000133995316
Iter: 430 loss: 0.000133915077
Iter: 431 loss: 0.000133894573
Iter: 432 loss: 0.000133927242
Iter: 433 loss: 0.000133884954
Iter: 434 loss: 0.000133866648
Iter: 435 loss: 0.000134048401
Iter: 436 loss: 0.000133866051
Iter: 437 loss: 0.000133852795
Iter: 438 loss: 0.000133970432
Iter: 439 loss: 0.00013385198
Iter: 440 loss: 0.000133841488
Iter: 441 loss: 0.000133842317
Iter: 442 loss: 0.000133833208
Iter: 443 loss: 0.000133820286
Iter: 444 loss: 0.000133823545
Iter: 445 loss: 0.000133811
Iter: 446 loss: 0.00013379431
Iter: 447 loss: 0.00013384
Iter: 448 loss: 0.000133788781
Iter: 449 loss: 0.000133773574
Iter: 450 loss: 0.000133850641
Iter: 451 loss: 0.000133771362
Iter: 452 loss: 0.000133756781
Iter: 453 loss: 0.000133799665
Iter: 454 loss: 0.000133752299
Iter: 455 loss: 0.000133739
Iter: 456 loss: 0.000133747759
Iter: 457 loss: 0.000133730427
Iter: 458 loss: 0.000133714391
Iter: 459 loss: 0.000133758
Iter: 460 loss: 0.000133709356
Iter: 461 loss: 0.000133693698
Iter: 462 loss: 0.000133737412
Iter: 463 loss: 0.000133688707
Iter: 464 loss: 0.000133674374
Iter: 465 loss: 0.000133707479
Iter: 466 loss: 0.000133668946
Iter: 467 loss: 0.000133655354
Iter: 468 loss: 0.00013372548
Iter: 469 loss: 0.000133653055
Iter: 470 loss: 0.000133643392
Iter: 471 loss: 0.000133797992
Iter: 472 loss: 0.000133643363
Iter: 473 loss: 0.00013363632
Iter: 474 loss: 0.000133641443
Iter: 475 loss: 0.000133631722
Iter: 476 loss: 0.000133623864
Iter: 477 loss: 0.000133620546
Iter: 478 loss: 0.000133616442
Iter: 479 loss: 0.000133604975
Iter: 480 loss: 0.000133636524
Iter: 481 loss: 0.000133601439
Iter: 482 loss: 0.00013359054
Iter: 483 loss: 0.000133636087
Iter: 484 loss: 0.000133588183
Iter: 485 loss: 0.000133578171
Iter: 486 loss: 0.000133621361
Iter: 487 loss: 0.000133576279
Iter: 488 loss: 0.000133567199
Iter: 489 loss: 0.00013358015
Iter: 490 loss: 0.000133562949
Iter: 491 loss: 0.000133553476
Iter: 492 loss: 0.000133566107
Iter: 493 loss: 0.000133548383
Iter: 494 loss: 0.000133538037
Iter: 495 loss: 0.000133566689
Iter: 496 loss: 0.000133534792
Iter: 497 loss: 0.000133524794
Iter: 498 loss: 0.000133550246
Iter: 499 loss: 0.000133521331
Iter: 500 loss: 0.000133511843
Iter: 501 loss: 0.000133545967
Iter: 502 loss: 0.000133509486
Iter: 503 loss: 0.000133503301
Iter: 504 loss: 0.000133503214
Iter: 505 loss: 0.000133498019
Iter: 506 loss: 0.000133503636
Iter: 507 loss: 0.000133495079
Iter: 508 loss: 0.000133489782
Iter: 509 loss: 0.000133488706
Iter: 510 loss: 0.000133485068
Iter: 511 loss: 0.000133477515
Iter: 512 loss: 0.000133490306
Iter: 513 loss: 0.000133474066
Iter: 514 loss: 0.000133466412
Iter: 515 loss: 0.000133499736
Iter: 516 loss: 0.00013346487
Iter: 517 loss: 0.000133457914
Iter: 518 loss: 0.000133487483
Iter: 519 loss: 0.000133456429
Iter: 520 loss: 0.00013345058
Iter: 521 loss: 0.000133467751
Iter: 522 loss: 0.000133448833
Iter: 523 loss: 0.000133442314
Iter: 524 loss: 0.00013344406
Iter: 525 loss: 0.000133437803
Iter: 526 loss: 0.000133430614
Iter: 527 loss: 0.000133455731
Iter: 528 loss: 0.000133428781
Iter: 529 loss: 0.000133422232
Iter: 530 loss: 0.000133434427
Iter: 531 loss: 0.000133419468
Iter: 532 loss: 0.000133412512
Iter: 533 loss: 0.000133438109
Iter: 534 loss: 0.000133410736
Iter: 535 loss: 0.000133405934
Iter: 536 loss: 0.000133478025
Iter: 537 loss: 0.000133405978
Iter: 538 loss: 0.000133401845
Iter: 539 loss: 0.000133414374
Iter: 540 loss: 0.000133400521
Iter: 541 loss: 0.000133397087
Iter: 542 loss: 0.000133395253
Iter: 543 loss: 0.000133393653
Iter: 544 loss: 0.000133388501
Iter: 545 loss: 0.000133396359
Iter: 546 loss: 0.000133386
Iter: 547 loss: 0.000133381021
Iter: 548 loss: 0.00013340103
Iter: 549 loss: 0.000133379785
Iter: 550 loss: 0.000133374982
Iter: 551 loss: 0.000133392226
Iter: 552 loss: 0.000133373673
Iter: 553 loss: 0.000133369089
Iter: 554 loss: 0.0001333853
Iter: 555 loss: 0.000133367867
Iter: 556 loss: 0.000133363443
Iter: 557 loss: 0.000133369278
Iter: 558 loss: 0.00013336126
Iter: 559 loss: 0.000133356734
Iter: 560 loss: 0.00013336548
Iter: 561 loss: 0.000133354784
Iter: 562 loss: 0.000133349822
Iter: 563 loss: 0.000133355934
Iter: 564 loss: 0.000133347348
Iter: 565 loss: 0.000133342328
Iter: 566 loss: 0.00013336855
Iter: 567 loss: 0.000133341309
Iter: 568 loss: 0.000133337366
Iter: 569 loss: 0.00013336743
Iter: 570 loss: 0.000133337
Iter: 571 loss: 0.000133333902
Iter: 572 loss: 0.000133362657
Iter: 573 loss: 0.000133333626
Iter: 574 loss: 0.000133331574
Iter: 575 loss: 0.000133329
Iter: 576 loss: 0.000133328445
Iter: 577 loss: 0.00013332488
Iter: 578 loss: 0.000133332505
Iter: 579 loss: 0.00013332325
Iter: 580 loss: 0.000133319656
Iter: 581 loss: 0.000133327907
Iter: 582 loss: 0.000133318128
Iter: 583 loss: 0.000133314228
Iter: 584 loss: 0.000133334353
Iter: 585 loss: 0.000133313733
Iter: 586 loss: 0.00013331043
Iter: 587 loss: 0.000133322086
Iter: 588 loss: 0.000133309863
Iter: 589 loss: 0.000133306734
Iter: 590 loss: 0.000133309964
Iter: 591 loss: 0.000133304915
Iter: 592 loss: 0.00013330151
Iter: 593 loss: 0.000133309222
Iter: 594 loss: 0.000133300287
Iter: 595 loss: 0.000133297071
Iter: 596 loss: 0.000133302063
Iter: 597 loss: 0.000133295252
Iter: 598 loss: 0.000133291876
Iter: 599 loss: 0.000133302747
Iter: 600 loss: 0.000133290887
Iter: 601 loss: 0.000133287598
Iter: 602 loss: 0.000133308931
Iter: 603 loss: 0.000133287307
Iter: 604 loss: 0.000133285328
Iter: 605 loss: 0.000133285197
Iter: 606 loss: 0.000133283698
Iter: 607 loss: 0.000133281937
Iter: 608 loss: 0.000133281792
Iter: 609 loss: 0.000133279333
Iter: 610 loss: 0.000133282825
Iter: 611 loss: 0.000133278096
Iter: 612 loss: 0.000133275404
Iter: 613 loss: 0.000133280846
Iter: 614 loss: 0.000133274414
Iter: 615 loss: 0.000133271838
Iter: 616 loss: 0.000133285692
Iter: 617 loss: 0.0001332713
Iter: 618 loss: 0.000133268972
Iter: 619 loss: 0.000133275869
Iter: 620 loss: 0.000133268302
Iter: 621 loss: 0.000133265901
Iter: 622 loss: 0.000133272115
Iter: 623 loss: 0.000133264926
Iter: 624 loss: 0.000133262743
Iter: 625 loss: 0.000133265494
Iter: 626 loss: 0.000133261579
Iter: 627 loss: 0.00013325928
Iter: 628 loss: 0.000133264155
Iter: 629 loss: 0.000133258145
Iter: 630 loss: 0.000133255657
Iter: 631 loss: 0.000133262438
Iter: 632 loss: 0.00013325474
Iter: 633 loss: 0.000133252397
Iter: 634 loss: 0.00013326417
Iter: 635 loss: 0.00013325183
Iter: 636 loss: 0.000133250258
Iter: 637 loss: 0.000133250316
Iter: 638 loss: 0.000133248875
Iter: 639 loss: 0.000133248715
Iter: 640 loss: 0.00013324758
Iter: 641 loss: 0.000133246009
Iter: 642 loss: 0.000133246198
Iter: 643 loss: 0.000133244641
Iter: 644 loss: 0.000133242633
Iter: 645 loss: 0.000133247464
Iter: 646 loss: 0.000133241891
Iter: 647 loss: 0.000133239853
Iter: 648 loss: 0.000133249734
Iter: 649 loss: 0.000133239446
Iter: 650 loss: 0.00013323751
Iter: 651 loss: 0.000133243084
Iter: 652 loss: 0.000133237045
Iter: 653 loss: 0.000133235211
Iter: 654 loss: 0.000133242938
Iter: 655 loss: 0.000133234658
Iter: 656 loss: 0.000133233232
Iter: 657 loss: 0.000133234425
Iter: 658 loss: 0.000133232388
Iter: 659 loss: 0.000133230351
Iter: 660 loss: 0.00013323364
Iter: 661 loss: 0.000133229711
Iter: 662 loss: 0.000133227615
Iter: 663 loss: 0.00013323233
Iter: 664 loss: 0.000133226888
Iter: 665 loss: 0.00013322501
Iter: 666 loss: 0.000133233203
Iter: 667 loss: 0.000133224705
Iter: 668 loss: 0.000133223526
Iter: 669 loss: 0.000133242458
Iter: 670 loss: 0.000133223337
Iter: 671 loss: 0.00013322226
Iter: 672 loss: 0.000133224516
Iter: 673 loss: 0.000133221649
Iter: 674 loss: 0.000133220543
Iter: 675 loss: 0.000133219859
Iter: 676 loss: 0.000133219495
Iter: 677 loss: 0.000133217851
Iter: 678 loss: 0.000133221372
Iter: 679 loss: 0.000133217254
Iter: 680 loss: 0.000133215784
Iter: 681 loss: 0.0001332213
Iter: 682 loss: 0.00013321545
Iter: 683 loss: 0.000133214096
Iter: 684 loss: 0.000133220325
Iter: 685 loss: 0.000133213747
Iter: 686 loss: 0.000133212525
Iter: 687 loss: 0.000133216658
Iter: 688 loss: 0.000133212088
Iter: 689 loss: 0.000133210837
Iter: 690 loss: 0.000133213194
Iter: 691 loss: 0.000133210357
Iter: 692 loss: 0.00013320896
Iter: 693 loss: 0.00013321024
Iter: 694 loss: 0.00013320845
Iter: 695 loss: 0.000133206762
Iter: 696 loss: 0.000133209163
Iter: 697 loss: 0.00013320634
Iter: 698 loss: 0.000133204623
Iter: 699 loss: 0.000133211928
Iter: 700 loss: 0.000133204536
Iter: 701 loss: 0.000133203212
Iter: 702 loss: 0.000133215115
Iter: 703 loss: 0.000133203197
Iter: 704 loss: 0.000133202368
Iter: 705 loss: 0.000133207344
Iter: 706 loss: 0.000133202077
Iter: 707 loss: 0.000133201451
Iter: 708 loss: 0.000133200432
Iter: 709 loss: 0.000133200447
Iter: 710 loss: 0.000133199224
Iter: 711 loss: 0.000133202149
Iter: 712 loss: 0.000133198948
Iter: 713 loss: 0.000133197755
Iter: 714 loss: 0.00013320132
Iter: 715 loss: 0.000133197231
Iter: 716 loss: 0.000133196299
Iter: 717 loss: 0.000133200112
Iter: 718 loss: 0.000133195877
Iter: 719 loss: 0.000133194873
Iter: 720 loss: 0.000133199879
Iter: 721 loss: 0.000133194437
Iter: 722 loss: 0.000133193622
Iter: 723 loss: 0.000133195586
Iter: 724 loss: 0.00013319336
Iter: 725 loss: 0.000133192283
Iter: 726 loss: 0.000133193447
Iter: 727 loss: 0.000133191905
Iter: 728 loss: 0.000133190522
Iter: 729 loss: 0.000133192167
Iter: 730 loss: 0.000133190246
Iter: 731 loss: 0.000133188849
Iter: 732 loss: 0.000133193855
Iter: 733 loss: 0.000133188485
Iter: 734 loss: 0.000133187656
Iter: 735 loss: 0.000133195106
Iter: 736 loss: 0.000133187626
Iter: 737 loss: 0.000133186841
Iter: 738 loss: 0.000133194466
Iter: 739 loss: 0.00013318671
Iter: 740 loss: 0.000133186288
Iter: 741 loss: 0.000133185691
Iter: 742 loss: 0.000133185516
Iter: 743 loss: 0.000133184774
Iter: 744 loss: 0.000133185677
Iter: 745 loss: 0.000133184338
Iter: 746 loss: 0.000133183363
Iter: 747 loss: 0.000133186186
Iter: 748 loss: 0.00013318313
Iter: 749 loss: 0.000133182039
Iter: 750 loss: 0.000133185938
Iter: 751 loss: 0.000133181893
Iter: 752 loss: 0.000133180933
Iter: 753 loss: 0.000133185094
Iter: 754 loss: 0.000133180816
Iter: 755 loss: 0.00013318003
Iter: 756 loss: 0.000133182053
Iter: 757 loss: 0.000133179681
Iter: 758 loss: 0.000133179128
Iter: 759 loss: 0.000133180161
Iter: 760 loss: 0.000133178604
Iter: 761 loss: 0.000133177615
Iter: 762 loss: 0.000133179128
Iter: 763 loss: 0.000133177367
Iter: 764 loss: 0.000133176552
Iter: 765 loss: 0.000133179099
Iter: 766 loss: 0.000133176261
Iter: 767 loss: 0.000133175403
Iter: 768 loss: 0.000133178532
Iter: 769 loss: 0.000133175185
Iter: 770 loss: 0.000133174646
Iter: 771 loss: 0.000133174675
Iter: 772 loss: 0.000133174181
Iter: 773 loss: 0.000133173773
Iter: 774 loss: 0.000133173744
Iter: 775 loss: 0.000133172958
Iter: 776 loss: 0.000133173991
Iter: 777 loss: 0.000133172813
Iter: 778 loss: 0.000133172056
Iter: 779 loss: 0.000133172609
Iter: 780 loss: 0.000133171736
Iter: 781 loss: 0.000133170732
Iter: 782 loss: 0.000133175607
Iter: 783 loss: 0.000133170863
Iter: 784 loss: 0.000133170252
Iter: 785 loss: 0.000133172813
Iter: 786 loss: 0.000133169902
Iter: 787 loss: 0.000133169364
Iter: 788 loss: 0.000133170921
Iter: 789 loss: 0.000133169146
Iter: 790 loss: 0.000133168418
Iter: 791 loss: 0.000133169873
Iter: 792 loss: 0.000133168418
Iter: 793 loss: 0.000133167603
Iter: 794 loss: 0.000133168098
Iter: 795 loss: 0.000133167166
Iter: 796 loss: 0.000133166643
Iter: 797 loss: 0.000133168549
Iter: 798 loss: 0.000133166206
Iter: 799 loss: 0.00013316577
Iter: 800 loss: 0.000133168796
Iter: 801 loss: 0.000133165537
Iter: 802 loss: 0.000133165158
Iter: 803 loss: 0.000133165115
Iter: 804 loss: 0.000133164707
Iter: 805 loss: 0.000133164605
Iter: 806 loss: 0.000133164373
Iter: 807 loss: 0.000133164
Iter: 808 loss: 0.000133164169
Iter: 809 loss: 0.000133163718
Iter: 810 loss: 0.000133163281
Iter: 811 loss: 0.000133164271
Iter: 812 loss: 0.000133162946
Iter: 813 loss: 0.000133162364
Iter: 814 loss: 0.00013316414
Iter: 815 loss: 0.00013316219
Iter: 816 loss: 0.000133161768
Iter: 817 loss: 0.000133163951
Iter: 818 loss: 0.000133161608
Iter: 819 loss: 0.000133161084
Iter: 820 loss: 0.000133162903
Iter: 821 loss: 0.000133161
Iter: 822 loss: 0.000133160487
Iter: 823 loss: 0.000133161404
Iter: 824 loss: 0.000133160371
Iter: 825 loss: 0.000133159847
Iter: 826 loss: 0.000133160327
Iter: 827 loss: 0.000133159512
Iter: 828 loss: 0.000133159265
Iter: 829 loss: 0.000133159963
Iter: 830 loss: 0.000133159148
Iter: 831 loss: 0.000133158435
Iter: 832 loss: 0.000133160604
Iter: 833 loss: 0.000133158261
Iter: 834 loss: 0.00013315797
Iter: 835 loss: 0.000133162539
Iter: 836 loss: 0.000133157795
Iter: 837 loss: 0.000133157562
Iter: 838 loss: 0.000133158566
Iter: 839 loss: 0.000133157519
Iter: 840 loss: 0.000133157213
Iter: 841 loss: 0.000133156791
Iter: 842 loss: 0.000133156806
Iter: 843 loss: 0.0001331565
Iter: 844 loss: 0.000133157213
Iter: 845 loss: 0.00013315634
Iter: 846 loss: 0.000133155801
Iter: 847 loss: 0.000133157824
Iter: 848 loss: 0.0001331557
Iter: 849 loss: 0.000133155321
Iter: 850 loss: 0.000133156369
Iter: 851 loss: 0.000133155234
Iter: 852 loss: 0.000133154768
Iter: 853 loss: 0.000133156747
Iter: 854 loss: 0.000133154826
Iter: 855 loss: 0.000133154244
Iter: 856 loss: 0.000133155263
Iter: 857 loss: 0.000133154172
Iter: 858 loss: 0.000133153924
Iter: 859 loss: 0.000133154303
Iter: 860 loss: 0.000133153939
Iter: 861 loss: 0.000133153429
Iter: 862 loss: 0.000133154113
Iter: 863 loss: 0.000133153313
Iter: 864 loss: 0.000133153022
Iter: 865 loss: 0.000133153691
Iter: 866 loss: 0.000133152702
Iter: 867 loss: 0.000133152353
Iter: 868 loss: 0.000133154332
Iter: 869 loss: 0.000133152338
Iter: 870 loss: 0.000133152033
Iter: 871 loss: 0.000133156267
Iter: 872 loss: 0.000133151945
Iter: 873 loss: 0.000133151945
Iter: 874 loss: 0.000133151771
Iter: 875 loss: 0.000133151509
Iter: 876 loss: 0.000133151305
Iter: 877 loss: 0.000133151756
Iter: 878 loss: 0.000133151247
Iter: 879 loss: 0.000133150825
Iter: 880 loss: 0.000133151276
Iter: 881 loss: 0.000133150694
Iter: 882 loss: 0.00013315049
Iter: 883 loss: 0.000133151829
Iter: 884 loss: 0.000133150286
Iter: 885 loss: 0.000133149879
Iter: 886 loss: 0.000133151829
Iter: 887 loss: 0.000133149966
Iter: 888 loss: 0.000133149806
Iter: 889 loss: 0.000133150112
Iter: 890 loss: 0.000133149486
Iter: 891 loss: 0.000133149384
Iter: 892 loss: 0.000133150243
Iter: 893 loss: 0.000133149239
Iter: 894 loss: 0.000133148947
Iter: 895 loss: 0.000133149122
Iter: 896 loss: 0.000133148773
Iter: 897 loss: 0.000133148584
Iter: 898 loss: 0.000133149559
Iter: 899 loss: 0.000133148365
Iter: 900 loss: 0.000133148162
Iter: 901 loss: 0.000133149195
Iter: 902 loss: 0.000133148278
Iter: 903 loss: 0.000133147871
Iter: 904 loss: 0.000133147696
Iter: 905 loss: 0.000133147696
Iter: 906 loss: 0.000133147652
Iter: 907 loss: 0.000133147798
Iter: 908 loss: 0.000133147536
Iter: 909 loss: 0.000133147638
Iter: 910 loss: 0.000133147347
Iter: 911 loss: 0.000133146896
Iter: 912 loss: 0.000133147725
Iter: 913 loss: 0.000133146794
Iter: 914 loss: 0.000133146634
Iter: 915 loss: 0.000133147158
Iter: 916 loss: 0.000133146736
Iter: 917 loss: 0.00013314627
Iter: 918 loss: 0.000133147551
Iter: 919 loss: 0.000133146241
Iter: 920 loss: 0.000133146095
Iter: 921 loss: 0.000133147187
Iter: 922 loss: 0.000133146183
Iter: 923 loss: 0.00013314595
Iter: 924 loss: 0.000133145979
Iter: 925 loss: 0.000133145935
Iter: 926 loss: 0.000133145484
Iter: 927 loss: 0.000133146226
Iter: 928 loss: 0.000133145644
Iter: 929 loss: 0.000133145324
Iter: 930 loss: 0.000133145702
Iter: 931 loss: 0.000133145411
Iter: 932 loss: 0.000133145135
Iter: 933 loss: 0.000133145266
Iter: 934 loss: 0.000133144931
Iter: 935 loss: 0.000133144873
Iter: 936 loss: 0.000133144757
Iter: 937 loss: 0.000133144742
Iter: 938 loss: 0.000133144742
Iter: 939 loss: 0.000133144655
Iter: 940 loss: 0.000133144407
Iter: 941 loss: 0.000133144466
Iter: 942 loss: 0.000133144291
Iter: 943 loss: 0.000133144276
Iter: 944 loss: 0.000133144626
Iter: 945 loss: 0.000133144014
Iter: 946 loss: 0.000133143825
Iter: 947 loss: 0.000133144436
Iter: 948 loss: 0.000133143883
Iter: 949 loss: 0.000133143782
Iter: 950 loss: 0.000133144364
Iter: 951 loss: 0.000133143782
Iter: 952 loss: 0.00013314352
Iter: 953 loss: 0.00013314448
Iter: 954 loss: 0.000133143563
Iter: 955 loss: 0.000133143301
Iter: 956 loss: 0.000133143563
Iter: 957 loss: 0.000133143505
Iter: 958 loss: 0.000133143156
Iter: 959 loss: 0.000133143505
Iter: 960 loss: 0.000133143098
Iter: 961 loss: 0.000133143
Iter: 962 loss: 0.000133143112
Iter: 963 loss: 0.000133143127
Iter: 964 loss: 0.000133142719
Iter: 965 loss: 0.000133143447
Iter: 966 loss: 0.000133142705
Iter: 967 loss: 0.000133142705
Iter: 968 loss: 0.000133143
Iter: 969 loss: 0.000133142719
Iter: 970 loss: 0.000133142399
Iter: 971 loss: 0.000133142559
Iter: 972 loss: 0.000133142603
Iter: 973 loss: 0.000133142195
Iter: 974 loss: 0.00013314464
Iter: 975 loss: 0.000133142225
Iter: 976 loss: 0.000133142225
Iter: 977 loss: 0.000133142414
Iter: 978 loss: 0.000133142225
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6
+ date
Tue Oct 27 15:14:48 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de86df2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e1192de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e1192d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e1192d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de860e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de85b92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de85ecd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8583ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de85837b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8583840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de851f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8523f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8523d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8480bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8480950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de844a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de846d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de846d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de83c67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de83ec158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de83ec7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8397a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de835cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de83059d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de835cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8330378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de82ee048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de82eeae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de82ab048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8250c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8206950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de82062f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8233950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de8233840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de81f2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de81f10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.027152719
Iter: 2 loss: 0.0197924078
Iter: 3 loss: 1542.42493
Iter: 4 loss: 6184.06592
Iter: 5 loss: 0.0198925529
Iter: 6 loss: 0.0205458142
Iter: 7 loss: 0.0321769714
Iter: 8 loss: 0.0194464885
Iter: 9 loss: 0.0147854593
Iter: 10 loss: 0.0142827025
Iter: 11 loss: 0.0120264497
Iter: 12 loss: 0.0814213753
Iter: 13 loss: 0.0120211281
Iter: 14 loss: 0.00970386527
Iter: 15 loss: 0.0255971104
Iter: 16 loss: 0.00944970641
Iter: 17 loss: 0.00857150462
Iter: 18 loss: 0.00978422165
Iter: 19 loss: 0.00823455676
Iter: 20 loss: 0.00747046387
Iter: 21 loss: 0.00778658828
Iter: 22 loss: 0.00684218807
Iter: 23 loss: 0.00578508805
Iter: 24 loss: 0.0218045972
Iter: 25 loss: 0.00569902454
Iter: 26 loss: 0.00476663373
Iter: 27 loss: 0.0145559292
Iter: 28 loss: 0.00470300531
Iter: 29 loss: 0.00401630765
Iter: 30 loss: 0.00711409561
Iter: 31 loss: 0.00388087146
Iter: 32 loss: 0.00341339875
Iter: 33 loss: 0.00858885422
Iter: 34 loss: 0.00337774307
Iter: 35 loss: 0.00304813404
Iter: 36 loss: 0.00373180583
Iter: 37 loss: 0.00289258966
Iter: 38 loss: 0.00249484507
Iter: 39 loss: 0.00690370239
Iter: 40 loss: 0.00247868826
Iter: 41 loss: 0.00221108226
Iter: 42 loss: 0.00405644672
Iter: 43 loss: 0.00218538032
Iter: 44 loss: 0.00199929811
Iter: 45 loss: 0.00239408226
Iter: 46 loss: 0.00192082964
Iter: 47 loss: 0.00179672253
Iter: 48 loss: 0.00178446365
Iter: 49 loss: 0.00168997992
Iter: 50 loss: 0.0021108822
Iter: 51 loss: 0.00167499459
Iter: 52 loss: 0.00159784686
Iter: 53 loss: 0.00169601385
Iter: 54 loss: 0.00155468
Iter: 55 loss: 0.00144766201
Iter: 56 loss: 0.00202396
Iter: 57 loss: 0.00143217342
Iter: 58 loss: 0.00134176994
Iter: 59 loss: 0.00190474524
Iter: 60 loss: 0.00132998242
Iter: 61 loss: 0.00125987292
Iter: 62 loss: 0.0012718729
Iter: 63 loss: 0.00120680733
Iter: 64 loss: 0.00112463988
Iter: 65 loss: 0.00166854914
Iter: 66 loss: 0.00111570209
Iter: 67 loss: 0.00104785955
Iter: 68 loss: 0.001239634
Iter: 69 loss: 0.00102490967
Iter: 70 loss: 0.0009680324
Iter: 71 loss: 0.00122999423
Iter: 72 loss: 0.000957244716
Iter: 73 loss: 0.000917368801
Iter: 74 loss: 0.00103785307
Iter: 75 loss: 0.000904388493
Iter: 76 loss: 0.000864251342
Iter: 77 loss: 0.00108472037
Iter: 78 loss: 0.00085841585
Iter: 79 loss: 0.00082730077
Iter: 80 loss: 0.000982679776
Iter: 81 loss: 0.000821122201
Iter: 82 loss: 0.000797061599
Iter: 83 loss: 0.00101222435
Iter: 84 loss: 0.000796256762
Iter: 85 loss: 0.000777467969
Iter: 86 loss: 0.000803874806
Iter: 87 loss: 0.000767755555
Iter: 88 loss: 0.000751950662
Iter: 89 loss: 0.000736772956
Iter: 90 loss: 0.000733243185
Iter: 91 loss: 0.000705313229
Iter: 92 loss: 0.00082487287
Iter: 93 loss: 0.000699221622
Iter: 94 loss: 0.000676717842
Iter: 95 loss: 0.000729079242
Iter: 96 loss: 0.000668270863
Iter: 97 loss: 0.000644216
Iter: 98 loss: 0.00066269777
Iter: 99 loss: 0.00062937726
Iter: 100 loss: 0.000601828098
Iter: 101 loss: 0.00075402332
Iter: 102 loss: 0.000597904786
Iter: 103 loss: 0.000575671147
Iter: 104 loss: 0.00061869889
Iter: 105 loss: 0.000566561706
Iter: 106 loss: 0.000546899624
Iter: 107 loss: 0.000589395466
Iter: 108 loss: 0.000539053115
Iter: 109 loss: 0.000522277667
Iter: 110 loss: 0.000650928356
Iter: 111 loss: 0.000520937843
Iter: 112 loss: 0.000508311088
Iter: 113 loss: 0.000568036514
Iter: 114 loss: 0.000506230281
Iter: 115 loss: 0.000494694454
Iter: 116 loss: 0.000564248068
Iter: 117 loss: 0.000493103755
Iter: 118 loss: 0.000485074415
Iter: 119 loss: 0.00052883249
Iter: 120 loss: 0.000484044373
Iter: 121 loss: 0.000477481139
Iter: 122 loss: 0.000470335974
Iter: 123 loss: 0.000469236664
Iter: 124 loss: 0.000459255185
Iter: 125 loss: 0.000483878248
Iter: 126 loss: 0.000455814967
Iter: 127 loss: 0.000445722369
Iter: 128 loss: 0.000465585472
Iter: 129 loss: 0.000441585435
Iter: 130 loss: 0.000432324945
Iter: 131 loss: 0.000477641937
Iter: 132 loss: 0.000430690066
Iter: 133 loss: 0.00042318576
Iter: 134 loss: 0.000417297531
Iter: 135 loss: 0.00041494827
Iter: 136 loss: 0.000405143888
Iter: 137 loss: 0.000466201833
Iter: 138 loss: 0.000404012884
Iter: 139 loss: 0.000395701471
Iter: 140 loss: 0.000430431683
Iter: 141 loss: 0.000393931812
Iter: 142 loss: 0.000386338739
Iter: 143 loss: 0.000387125649
Iter: 144 loss: 0.000380439538
Iter: 145 loss: 0.000370758
Iter: 146 loss: 0.000427800085
Iter: 147 loss: 0.000369389832
Iter: 148 loss: 0.000362554507
Iter: 149 loss: 0.000452913198
Iter: 150 loss: 0.000362536288
Iter: 151 loss: 0.000358237128
Iter: 152 loss: 0.000356652832
Iter: 153 loss: 0.000354208634
Iter: 154 loss: 0.000348126021
Iter: 155 loss: 0.000359021942
Iter: 156 loss: 0.000345544599
Iter: 157 loss: 0.000338506652
Iter: 158 loss: 0.000344928121
Iter: 159 loss: 0.000334380718
Iter: 160 loss: 0.00032747825
Iter: 161 loss: 0.000329731789
Iter: 162 loss: 0.000322545879
Iter: 163 loss: 0.000314959791
Iter: 164 loss: 0.000388284941
Iter: 165 loss: 0.000314663601
Iter: 166 loss: 0.000308427203
Iter: 167 loss: 0.000312364107
Iter: 168 loss: 0.000304408721
Iter: 169 loss: 0.000297572406
Iter: 170 loss: 0.000314787234
Iter: 171 loss: 0.000295158
Iter: 172 loss: 0.000288160227
Iter: 173 loss: 0.000317405618
Iter: 174 loss: 0.000286627881
Iter: 175 loss: 0.000281160173
Iter: 176 loss: 0.000300153857
Iter: 177 loss: 0.000279720436
Iter: 178 loss: 0.000274420076
Iter: 179 loss: 0.000293697463
Iter: 180 loss: 0.000273082667
Iter: 181 loss: 0.00026890685
Iter: 182 loss: 0.000299961423
Iter: 183 loss: 0.000268517644
Iter: 184 loss: 0.000265307521
Iter: 185 loss: 0.000306296221
Iter: 186 loss: 0.00026529032
Iter: 187 loss: 0.000263502588
Iter: 188 loss: 0.000262447109
Iter: 189 loss: 0.000261687674
Iter: 190 loss: 0.000258919172
Iter: 191 loss: 0.000266241201
Iter: 192 loss: 0.000258005864
Iter: 193 loss: 0.000255098566
Iter: 194 loss: 0.000257568463
Iter: 195 loss: 0.000253367412
Iter: 196 loss: 0.000249961711
Iter: 197 loss: 0.000252153171
Iter: 198 loss: 0.000247797318
Iter: 199 loss: 0.00024419665
Iter: 200 loss: 0.000269102864
Iter: 201 loss: 0.000243855102
Iter: 202 loss: 0.000240834765
Iter: 203 loss: 0.000249966251
Iter: 204 loss: 0.000239926492
Iter: 205 loss: 0.00023715038
Iter: 206 loss: 0.000240885958
Iter: 207 loss: 0.00023574935
Iter: 208 loss: 0.000233163504
Iter: 209 loss: 0.000242389855
Iter: 210 loss: 0.000232498744
Iter: 211 loss: 0.000229814512
Iter: 212 loss: 0.000235531683
Iter: 213 loss: 0.000228754579
Iter: 214 loss: 0.00022674611
Iter: 215 loss: 0.000248764525
Iter: 216 loss: 0.000226707896
Iter: 217 loss: 0.000225226744
Iter: 218 loss: 0.000237926972
Iter: 219 loss: 0.000225137657
Iter: 220 loss: 0.000223785668
Iter: 221 loss: 0.000225399548
Iter: 222 loss: 0.000223082869
Iter: 223 loss: 0.000221966227
Iter: 224 loss: 0.000222904549
Iter: 225 loss: 0.000221297814
Iter: 226 loss: 0.000219643072
Iter: 227 loss: 0.000221032766
Iter: 228 loss: 0.00021866466
Iter: 229 loss: 0.000216887362
Iter: 230 loss: 0.000220511502
Iter: 231 loss: 0.000216167056
Iter: 232 loss: 0.000214150685
Iter: 233 loss: 0.000217680223
Iter: 234 loss: 0.000213258376
Iter: 235 loss: 0.000211373976
Iter: 236 loss: 0.000216715707
Iter: 237 loss: 0.000210777405
Iter: 238 loss: 0.000208795827
Iter: 239 loss: 0.000218895308
Iter: 240 loss: 0.000208469166
Iter: 241 loss: 0.000206935569
Iter: 242 loss: 0.000207690609
Iter: 243 loss: 0.000205907927
Iter: 244 loss: 0.000203936215
Iter: 245 loss: 0.000210010534
Iter: 246 loss: 0.000203353062
Iter: 247 loss: 0.000201530827
Iter: 248 loss: 0.000206419412
Iter: 249 loss: 0.000200916023
Iter: 250 loss: 0.000199851667
Iter: 251 loss: 0.000199787071
Iter: 252 loss: 0.000198686263
Iter: 253 loss: 0.000200452603
Iter: 254 loss: 0.000198168447
Iter: 255 loss: 0.000197137037
Iter: 256 loss: 0.00019730514
Iter: 257 loss: 0.000196365698
Iter: 258 loss: 0.000195086526
Iter: 259 loss: 0.000199093571
Iter: 260 loss: 0.000194709035
Iter: 261 loss: 0.000193459127
Iter: 262 loss: 0.000195211964
Iter: 263 loss: 0.000192844585
Iter: 264 loss: 0.000191374667
Iter: 265 loss: 0.000193082626
Iter: 266 loss: 0.000190586579
Iter: 267 loss: 0.00018922014
Iter: 268 loss: 0.000195640183
Iter: 269 loss: 0.000188966209
Iter: 270 loss: 0.000187713958
Iter: 271 loss: 0.000192258594
Iter: 272 loss: 0.000187398458
Iter: 273 loss: 0.000186304023
Iter: 274 loss: 0.000187056808
Iter: 275 loss: 0.000185618352
Iter: 276 loss: 0.000184294709
Iter: 277 loss: 0.000193512606
Iter: 278 loss: 0.000184171979
Iter: 279 loss: 0.000183113196
Iter: 280 loss: 0.000182774034
Iter: 281 loss: 0.000182153046
Iter: 282 loss: 0.000181164214
Iter: 283 loss: 0.000194404158
Iter: 284 loss: 0.000181157
Iter: 285 loss: 0.00018023068
Iter: 286 loss: 0.000189342696
Iter: 287 loss: 0.000180202274
Iter: 288 loss: 0.000179634502
Iter: 289 loss: 0.000179226525
Iter: 290 loss: 0.00017902808
Iter: 291 loss: 0.000178309361
Iter: 292 loss: 0.000180392846
Iter: 293 loss: 0.000178088143
Iter: 294 loss: 0.000177306822
Iter: 295 loss: 0.000177887763
Iter: 296 loss: 0.000176826332
Iter: 297 loss: 0.000175919471
Iter: 298 loss: 0.000178896691
Iter: 299 loss: 0.000175668698
Iter: 300 loss: 0.000174859131
Iter: 301 loss: 0.00017622755
Iter: 302 loss: 0.000174494664
Iter: 303 loss: 0.000173692475
Iter: 304 loss: 0.000177281428
Iter: 305 loss: 0.000173535
Iter: 306 loss: 0.000172849774
Iter: 307 loss: 0.000174996938
Iter: 308 loss: 0.000172650703
Iter: 309 loss: 0.000172012369
Iter: 310 loss: 0.000173173437
Iter: 311 loss: 0.000171736712
Iter: 312 loss: 0.000171041582
Iter: 313 loss: 0.000172502594
Iter: 314 loss: 0.000170766405
Iter: 315 loss: 0.000170069688
Iter: 316 loss: 0.000174289205
Iter: 317 loss: 0.000169985142
Iter: 318 loss: 0.000169733015
Iter: 319 loss: 0.000169704086
Iter: 320 loss: 0.000169428822
Iter: 321 loss: 0.00016895718
Iter: 322 loss: 0.000168956714
Iter: 323 loss: 0.00016844942
Iter: 324 loss: 0.000169661711
Iter: 325 loss: 0.000168263839
Iter: 326 loss: 0.000167661259
Iter: 327 loss: 0.000168813189
Iter: 328 loss: 0.000167408754
Iter: 329 loss: 0.000166843558
Iter: 330 loss: 0.000168880651
Iter: 331 loss: 0.00016669961
Iter: 332 loss: 0.000166174184
Iter: 333 loss: 0.00016638574
Iter: 334 loss: 0.000165811172
Iter: 335 loss: 0.00016515702
Iter: 336 loss: 0.000167915045
Iter: 337 loss: 0.000165018049
Iter: 338 loss: 0.00016443347
Iter: 339 loss: 0.000166151818
Iter: 340 loss: 0.000164253463
Iter: 341 loss: 0.000163681805
Iter: 342 loss: 0.000165254693
Iter: 343 loss: 0.000163495744
Iter: 344 loss: 0.000162918062
Iter: 345 loss: 0.000164308731
Iter: 346 loss: 0.000162708544
Iter: 347 loss: 0.000162181153
Iter: 348 loss: 0.000163576013
Iter: 349 loss: 0.00016200266
Iter: 350 loss: 0.000161692602
Iter: 351 loss: 0.000161675795
Iter: 352 loss: 0.000161348726
Iter: 353 loss: 0.000161691249
Iter: 354 loss: 0.000161166245
Iter: 355 loss: 0.00016085431
Iter: 356 loss: 0.000160799857
Iter: 357 loss: 0.000160588126
Iter: 358 loss: 0.000160182462
Iter: 359 loss: 0.000161214179
Iter: 360 loss: 0.000160041236
Iter: 361 loss: 0.000159574818
Iter: 362 loss: 0.000160779528
Iter: 363 loss: 0.000159415693
Iter: 364 loss: 0.000159007221
Iter: 365 loss: 0.000159341493
Iter: 366 loss: 0.000158762297
Iter: 367 loss: 0.000158264389
Iter: 368 loss: 0.00016082247
Iter: 369 loss: 0.000158183509
Iter: 370 loss: 0.000157778428
Iter: 371 loss: 0.000157793911
Iter: 372 loss: 0.000157458941
Iter: 373 loss: 0.000156928203
Iter: 374 loss: 0.000161120173
Iter: 375 loss: 0.000156891474
Iter: 376 loss: 0.000156478854
Iter: 377 loss: 0.000156985509
Iter: 378 loss: 0.000156263646
Iter: 379 loss: 0.00015586392
Iter: 380 loss: 0.000157013885
Iter: 381 loss: 0.000155739224
Iter: 382 loss: 0.000155342015
Iter: 383 loss: 0.000158186478
Iter: 384 loss: 0.000155305752
Iter: 385 loss: 0.00015498366
Iter: 386 loss: 0.000159206771
Iter: 387 loss: 0.000154981841
Iter: 388 loss: 0.000154818496
Iter: 389 loss: 0.000154539914
Iter: 390 loss: 0.000154539419
Iter: 391 loss: 0.000154209585
Iter: 392 loss: 0.00015520255
Iter: 393 loss: 0.000154110836
Iter: 394 loss: 0.000153819128
Iter: 395 loss: 0.000154793
Iter: 396 loss: 0.000153739093
Iter: 397 loss: 0.000153428904
Iter: 398 loss: 0.000153632122
Iter: 399 loss: 0.000153232904
Iter: 400 loss: 0.000152889043
Iter: 401 loss: 0.000154342881
Iter: 402 loss: 0.000152816327
Iter: 403 loss: 0.000152524939
Iter: 404 loss: 0.000153312765
Iter: 405 loss: 0.000152428838
Iter: 406 loss: 0.000152127497
Iter: 407 loss: 0.000152651075
Iter: 408 loss: 0.000151994085
Iter: 409 loss: 0.00015166431
Iter: 410 loss: 0.000152857276
Iter: 411 loss: 0.000151580898
Iter: 412 loss: 0.000151283195
Iter: 413 loss: 0.000152302062
Iter: 414 loss: 0.000151203378
Iter: 415 loss: 0.000150933207
Iter: 416 loss: 0.000151269953
Iter: 417 loss: 0.00015079345
Iter: 418 loss: 0.000150664331
Iter: 419 loss: 0.000150607215
Iter: 420 loss: 0.00015049061
Iter: 421 loss: 0.000150250009
Iter: 422 loss: 0.000154484951
Iter: 423 loss: 0.000150245352
Iter: 424 loss: 0.000149952146
Iter: 425 loss: 0.000150752603
Iter: 426 loss: 0.000149855856
Iter: 427 loss: 0.000149613217
Iter: 428 loss: 0.000150669599
Iter: 429 loss: 0.000149563843
Iter: 430 loss: 0.00014930006
Iter: 431 loss: 0.000149349333
Iter: 432 loss: 0.000149102852
Iter: 433 loss: 0.000148800405
Iter: 434 loss: 0.000149949861
Iter: 435 loss: 0.000148728053
Iter: 436 loss: 0.000148438776
Iter: 437 loss: 0.000149082611
Iter: 438 loss: 0.000148328254
Iter: 439 loss: 0.000148056803
Iter: 440 loss: 0.000148851832
Iter: 441 loss: 0.000147973129
Iter: 442 loss: 0.000147685147
Iter: 443 loss: 0.000148463747
Iter: 444 loss: 0.000147590225
Iter: 445 loss: 0.000147321407
Iter: 446 loss: 0.000148228821
Iter: 447 loss: 0.000147248909
Iter: 448 loss: 0.000147012805
Iter: 449 loss: 0.000147610568
Iter: 450 loss: 0.000146930644
Iter: 451 loss: 0.000146791252
Iter: 452 loss: 0.000146779174
Iter: 453 loss: 0.000146630162
Iter: 454 loss: 0.00014650097
Iter: 455 loss: 0.000146460632
Iter: 456 loss: 0.00014626846
Iter: 457 loss: 0.000146180377
Iter: 458 loss: 0.000146084567
Iter: 459 loss: 0.000145816346
Iter: 460 loss: 0.000147756524
Iter: 461 loss: 0.000145793136
Iter: 462 loss: 0.000145575526
Iter: 463 loss: 0.000145744561
Iter: 464 loss: 0.000145443861
Iter: 465 loss: 0.000145186845
Iter: 466 loss: 0.000146367369
Iter: 467 loss: 0.000145137878
Iter: 468 loss: 0.000144907375
Iter: 469 loss: 0.00014491714
Iter: 470 loss: 0.000144726262
Iter: 471 loss: 0.00014445855
Iter: 472 loss: 0.000146296952
Iter: 473 loss: 0.000144432386
Iter: 474 loss: 0.000144212914
Iter: 475 loss: 0.00014467875
Iter: 476 loss: 0.000144126243
Iter: 477 loss: 0.000143916419
Iter: 478 loss: 0.000144692443
Iter: 479 loss: 0.000143864716
Iter: 480 loss: 0.000143662488
Iter: 481 loss: 0.000144055215
Iter: 482 loss: 0.000143578451
Iter: 483 loss: 0.00014343072
Iter: 484 loss: 0.00014343053
Iter: 485 loss: 0.000143288751
Iter: 486 loss: 0.000143724101
Iter: 487 loss: 0.000143247104
Iter: 488 loss: 0.000143149504
Iter: 489 loss: 0.000143001336
Iter: 490 loss: 0.000142998586
Iter: 491 loss: 0.000142816338
Iter: 492 loss: 0.000143426267
Iter: 493 loss: 0.000142766468
Iter: 494 loss: 0.000142578094
Iter: 495 loss: 0.000143222627
Iter: 496 loss: 0.00014252757
Iter: 497 loss: 0.000142358418
Iter: 498 loss: 0.000142673773
Iter: 499 loss: 0.00014228595
Iter: 500 loss: 0.000142104414
Iter: 501 loss: 0.000142467237
Iter: 502 loss: 0.000142030272
Iter: 503 loss: 0.000141830387
Iter: 504 loss: 0.000142407778
Iter: 505 loss: 0.00014176796
Iter: 506 loss: 0.000141589466
Iter: 507 loss: 0.000141829049
Iter: 508 loss: 0.00014149987
Iter: 509 loss: 0.000141317461
Iter: 510 loss: 0.000142850506
Iter: 511 loss: 0.000141306795
Iter: 512 loss: 0.000141162309
Iter: 513 loss: 0.000141099532
Iter: 514 loss: 0.000141025332
Iter: 515 loss: 0.000140895019
Iter: 516 loss: 0.000140892254
Iter: 517 loss: 0.000140775781
Iter: 518 loss: 0.000141367
Iter: 519 loss: 0.000140756165
Iter: 520 loss: 0.000140660632
Iter: 521 loss: 0.000140526739
Iter: 522 loss: 0.000140521559
Iter: 523 loss: 0.000140376564
Iter: 524 loss: 0.000140616728
Iter: 525 loss: 0.000140310673
Iter: 526 loss: 0.00014013442
Iter: 527 loss: 0.000141065684
Iter: 528 loss: 0.000140107455
Iter: 529 loss: 0.000139961427
Iter: 530 loss: 0.000140075645
Iter: 531 loss: 0.000139872835
Iter: 532 loss: 0.0001397054
Iter: 533 loss: 0.000140353834
Iter: 534 loss: 0.000139666197
Iter: 535 loss: 0.000139514319
Iter: 536 loss: 0.000139751894
Iter: 537 loss: 0.00013944332
Iter: 538 loss: 0.000139268348
Iter: 539 loss: 0.000139586802
Iter: 540 loss: 0.00013919262
Iter: 541 loss: 0.000139018826
Iter: 542 loss: 0.000139993092
Iter: 543 loss: 0.000138994597
Iter: 544 loss: 0.000138843723
Iter: 545 loss: 0.000139090102
Iter: 546 loss: 0.000138774878
Iter: 547 loss: 0.00013862623
Iter: 548 loss: 0.000139347103
Iter: 549 loss: 0.000138600022
Iter: 550 loss: 0.000138500603
Iter: 551 loss: 0.000138497518
Iter: 552 loss: 0.000138425123
Iter: 553 loss: 0.000138295698
Iter: 554 loss: 0.000141535682
Iter: 555 loss: 0.000138295887
Iter: 556 loss: 0.00013816994
Iter: 557 loss: 0.000138353469
Iter: 558 loss: 0.000138109
Iter: 559 loss: 0.000137958821
Iter: 560 loss: 0.000138403586
Iter: 561 loss: 0.000137912779
Iter: 562 loss: 0.000137766736
Iter: 563 loss: 0.000138339761
Iter: 564 loss: 0.000137733223
Iter: 565 loss: 0.000137590629
Iter: 566 loss: 0.000137767245
Iter: 567 loss: 0.000137516225
Iter: 568 loss: 0.000137392155
Iter: 569 loss: 0.000137804338
Iter: 570 loss: 0.000137357754
Iter: 571 loss: 0.000137213094
Iter: 572 loss: 0.000137429393
Iter: 573 loss: 0.000137143681
Iter: 574 loss: 0.000137014329
Iter: 575 loss: 0.000137383438
Iter: 576 loss: 0.000136973526
Iter: 577 loss: 0.000136850227
Iter: 578 loss: 0.00013758539
Iter: 579 loss: 0.000136834831
Iter: 580 loss: 0.000136729417
Iter: 581 loss: 0.00013683195
Iter: 582 loss: 0.000136669856
Iter: 583 loss: 0.000136616
Iter: 584 loss: 0.000136600269
Iter: 585 loss: 0.000136538947
Iter: 586 loss: 0.000136447401
Iter: 587 loss: 0.000136445247
Iter: 588 loss: 0.00013635325
Iter: 589 loss: 0.000136486633
Iter: 590 loss: 0.000136308707
Iter: 591 loss: 0.000136203322
Iter: 592 loss: 0.000136415736
Iter: 593 loss: 0.000136160321
Iter: 594 loss: 0.000136051327
Iter: 595 loss: 0.000136615301
Iter: 596 loss: 0.000136033748
Iter: 597 loss: 0.000135936774
Iter: 598 loss: 0.000136075367
Iter: 599 loss: 0.000135889277
Iter: 600 loss: 0.000135796989
Iter: 601 loss: 0.00013606064
Iter: 602 loss: 0.000135767812
Iter: 603 loss: 0.000135659531
Iter: 604 loss: 0.000135735027
Iter: 605 loss: 0.000135591661
Iter: 606 loss: 0.000135479509
Iter: 607 loss: 0.000136137547
Iter: 608 loss: 0.000135465176
Iter: 609 loss: 0.000135363443
Iter: 610 loss: 0.000135486043
Iter: 611 loss: 0.000135310082
Iter: 612 loss: 0.000135206341
Iter: 613 loss: 0.000135784168
Iter: 614 loss: 0.000135191731
Iter: 615 loss: 0.000135121911
Iter: 616 loss: 0.00013610693
Iter: 617 loss: 0.000135121809
Iter: 618 loss: 0.000135052382
Iter: 619 loss: 0.000135146358
Iter: 620 loss: 0.000135017617
Iter: 621 loss: 0.000134960923
Iter: 622 loss: 0.000134888731
Iter: 623 loss: 0.000134883478
Iter: 624 loss: 0.000134792
Iter: 625 loss: 0.000135147391
Iter: 626 loss: 0.000134770642
Iter: 627 loss: 0.000134689515
Iter: 628 loss: 0.000135140755
Iter: 629 loss: 0.00013467815
Iter: 630 loss: 0.000134608475
Iter: 631 loss: 0.000134675211
Iter: 632 loss: 0.000134568778
Iter: 633 loss: 0.000134480695
Iter: 634 loss: 0.000134748916
Iter: 635 loss: 0.000134454458
Iter: 636 loss: 0.000134370202
Iter: 637 loss: 0.000134436283
Iter: 638 loss: 0.000134319023
Iter: 639 loss: 0.000134228874
Iter: 640 loss: 0.000134754169
Iter: 641 loss: 0.000134217029
Iter: 642 loss: 0.000134131
Iter: 643 loss: 0.000134184462
Iter: 644 loss: 0.000134075788
Iter: 645 loss: 0.000133983296
Iter: 646 loss: 0.000134538219
Iter: 647 loss: 0.000133971756
Iter: 648 loss: 0.000133902795
Iter: 649 loss: 0.000134408852
Iter: 650 loss: 0.000133897178
Iter: 651 loss: 0.000133831854
Iter: 652 loss: 0.000134315254
Iter: 653 loss: 0.000133826688
Iter: 654 loss: 0.000133791575
Iter: 655 loss: 0.000133735914
Iter: 656 loss: 0.000133735361
Iter: 657 loss: 0.000133662281
Iter: 658 loss: 0.000133711874
Iter: 659 loss: 0.000133616209
Iter: 660 loss: 0.000133540248
Iter: 661 loss: 0.000133971669
Iter: 662 loss: 0.000133529771
Iter: 663 loss: 0.000133461028
Iter: 664 loss: 0.000133749214
Iter: 665 loss: 0.000133446418
Iter: 666 loss: 0.000133388399
Iter: 667 loss: 0.000133413749
Iter: 668 loss: 0.000133348643
Iter: 669 loss: 0.000133269263
Iter: 670 loss: 0.000133566049
Iter: 671 loss: 0.000133250112
Iter: 672 loss: 0.000133183436
Iter: 673 loss: 0.000133292488
Iter: 674 loss: 0.000133153415
Iter: 675 loss: 0.000133083129
Iter: 676 loss: 0.000133300418
Iter: 677 loss: 0.000133062829
Iter: 678 loss: 0.000132993169
Iter: 679 loss: 0.000133256661
Iter: 680 loss: 0.000132976653
Iter: 681 loss: 0.000132916321
Iter: 682 loss: 0.000133167836
Iter: 683 loss: 0.000132903311
Iter: 684 loss: 0.000132864152
Iter: 685 loss: 0.000132862537
Iter: 686 loss: 0.000132841116
Iter: 687 loss: 0.000132797955
Iter: 688 loss: 0.000133610069
Iter: 689 loss: 0.000132797286
Iter: 690 loss: 0.000132740126
Iter: 691 loss: 0.000132779227
Iter: 692 loss: 0.000132704212
Iter: 693 loss: 0.000132643036
Iter: 694 loss: 0.000132797402
Iter: 695 loss: 0.00013262179
Iter: 696 loss: 0.000132565663
Iter: 697 loss: 0.000133126305
Iter: 698 loss: 0.000132563961
Iter: 699 loss: 0.000132521091
Iter: 700 loss: 0.000132491783
Iter: 701 loss: 0.000132475805
Iter: 702 loss: 0.000132415211
Iter: 703 loss: 0.000132890636
Iter: 704 loss: 0.000132410816
Iter: 705 loss: 0.000132364279
Iter: 706 loss: 0.000132368019
Iter: 707 loss: 0.000132327754
Iter: 708 loss: 0.000132268848
Iter: 709 loss: 0.000132564266
Iter: 710 loss: 0.000132258836
Iter: 711 loss: 0.000132207831
Iter: 712 loss: 0.000132346031
Iter: 713 loss: 0.000132190908
Iter: 714 loss: 0.000132141431
Iter: 715 loss: 0.00013236441
Iter: 716 loss: 0.000132131769
Iter: 717 loss: 0.000132104906
Iter: 718 loss: 0.000132102781
Iter: 719 loss: 0.000132081041
Iter: 720 loss: 0.000132038898
Iter: 721 loss: 0.000132906105
Iter: 722 loss: 0.00013203852
Iter: 723 loss: 0.000131992434
Iter: 724 loss: 0.000132065674
Iter: 725 loss: 0.000131970504
Iter: 726 loss: 0.000131920882
Iter: 727 loss: 0.000132009358
Iter: 728 loss: 0.000131899054
Iter: 729 loss: 0.000131849301
Iter: 730 loss: 0.000132155663
Iter: 731 loss: 0.000131843437
Iter: 732 loss: 0.000131802051
Iter: 733 loss: 0.000131917535
Iter: 734 loss: 0.000131788634
Iter: 735 loss: 0.000131745735
Iter: 736 loss: 0.000131777
Iter: 737 loss: 0.000131719251
Iter: 738 loss: 0.000131670735
Iter: 739 loss: 0.000131815279
Iter: 740 loss: 0.000131655834
Iter: 741 loss: 0.00013160301
Iter: 742 loss: 0.000131757319
Iter: 743 loss: 0.000131586814
Iter: 744 loss: 0.000131544541
Iter: 745 loss: 0.000131627181
Iter: 746 loss: 0.000131527093
Iter: 747 loss: 0.000131481298
Iter: 748 loss: 0.00013172286
Iter: 749 loss: 0.00013147408
Iter: 750 loss: 0.000131445762
Iter: 751 loss: 0.000131445617
Iter: 752 loss: 0.000131419074
Iter: 753 loss: 0.000131405686
Iter: 754 loss: 0.000131393
Iter: 755 loss: 0.000131364504
Iter: 756 loss: 0.000131363689
Iter: 757 loss: 0.000131341279
Iter: 758 loss: 0.000131301626
Iter: 759 loss: 0.000131379478
Iter: 760 loss: 0.000131285255
Iter: 761 loss: 0.000131240973
Iter: 762 loss: 0.000131369976
Iter: 763 loss: 0.000131227134
Iter: 764 loss: 0.000131190231
Iter: 765 loss: 0.000131457782
Iter: 766 loss: 0.000131187
Iter: 767 loss: 0.000131155306
Iter: 768 loss: 0.00013116964
Iter: 769 loss: 0.000131133886
Iter: 770 loss: 0.000131095207
Iter: 771 loss: 0.000131194087
Iter: 772 loss: 0.000131081833
Iter: 773 loss: 0.000131042
Iter: 774 loss: 0.000131140667
Iter: 775 loss: 0.00013102786
Iter: 776 loss: 0.000130991728
Iter: 777 loss: 0.000131115667
Iter: 778 loss: 0.000130982051
Iter: 779 loss: 0.000130943125
Iter: 780 loss: 0.000131030218
Iter: 781 loss: 0.000130928325
Iter: 782 loss: 0.000130912682
Iter: 783 loss: 0.00013090999
Iter: 784 loss: 0.000130891087
Iter: 785 loss: 0.000130883098
Iter: 786 loss: 0.000130873246
Iter: 787 loss: 0.00013084925
Iter: 788 loss: 0.000130859684
Iter: 789 loss: 0.000130832515
Iter: 790 loss: 0.000130804081
Iter: 791 loss: 0.000130803819
Iter: 792 loss: 0.000130781118
Iter: 793 loss: 0.000130744564
Iter: 794 loss: 0.000130976434
Iter: 795 loss: 0.000130740431
Iter: 796 loss: 0.000130710119
Iter: 797 loss: 0.000130813394
Iter: 798 loss: 0.000130702174
Iter: 799 loss: 0.000130673143
Iter: 800 loss: 0.000130748755
Iter: 801 loss: 0.00013066316
Iter: 802 loss: 0.000130635221
Iter: 803 loss: 0.000130702843
Iter: 804 loss: 0.000130625034
Iter: 805 loss: 0.000130596396
Iter: 806 loss: 0.000130610395
Iter: 807 loss: 0.000130577304
Iter: 808 loss: 0.000130545086
Iter: 809 loss: 0.00013073186
Iter: 810 loss: 0.000130540982
Iter: 811 loss: 0.000130510642
Iter: 812 loss: 0.000130592482
Iter: 813 loss: 0.000130500674
Iter: 814 loss: 0.000130482047
Iter: 815 loss: 0.000130726025
Iter: 816 loss: 0.000130481843
Iter: 817 loss: 0.000130460714
Iter: 818 loss: 0.000130489439
Iter: 819 loss: 0.000130450469
Iter: 820 loss: 0.00013043129
Iter: 821 loss: 0.000130431872
Iter: 822 loss: 0.000130416156
Iter: 823 loss: 0.000130392349
Iter: 824 loss: 0.00013039785
Iter: 825 loss: 0.000130374858
Iter: 826 loss: 0.000130345899
Iter: 827 loss: 0.00013047026
Iter: 828 loss: 0.000130339788
Iter: 829 loss: 0.000130313827
Iter: 830 loss: 0.000130410088
Iter: 831 loss: 0.000130307279
Iter: 832 loss: 0.000130283341
Iter: 833 loss: 0.000130387372
Iter: 834 loss: 0.00013027867
Iter: 835 loss: 0.000130257511
Iter: 836 loss: 0.000130275992
Iter: 837 loss: 0.000130245317
Iter: 838 loss: 0.000130219923
Iter: 839 loss: 0.000130288492
Iter: 840 loss: 0.000130211323
Iter: 841 loss: 0.000130186265
Iter: 842 loss: 0.000130221844
Iter: 843 loss: 0.000130173517
Iter: 844 loss: 0.000130148139
Iter: 845 loss: 0.000130306114
Iter: 846 loss: 0.000130145039
Iter: 847 loss: 0.00013012506
Iter: 848 loss: 0.000130236556
Iter: 849 loss: 0.000130122105
Iter: 850 loss: 0.000130105182
Iter: 851 loss: 0.000130306507
Iter: 852 loss: 0.000130105022
Iter: 853 loss: 0.000130095286
Iter: 854 loss: 0.000130077606
Iter: 855 loss: 0.000130497458
Iter: 856 loss: 0.000130077751
Iter: 857 loss: 0.000130056578
Iter: 858 loss: 0.00013008673
Iter: 859 loss: 0.000130046305
Iter: 860 loss: 0.000130021479
Iter: 861 loss: 0.000130092347
Iter: 862 loss: 0.000130013854
Iter: 863 loss: 0.000129992564
Iter: 864 loss: 0.000130035769
Iter: 865 loss: 0.000129983775
Iter: 866 loss: 0.000129962878
Iter: 867 loss: 0.00013015655
Iter: 868 loss: 0.000129961816
Iter: 869 loss: 0.000129945518
Iter: 870 loss: 0.000129934255
Iter: 871 loss: 0.00012992823
Iter: 872 loss: 0.000129904831
Iter: 873 loss: 0.00013008606
Iter: 874 loss: 0.000129903288
Iter: 875 loss: 0.000129886859
Iter: 876 loss: 0.000129891967
Iter: 877 loss: 0.000129875087
Iter: 878 loss: 0.000129855
Iter: 879 loss: 0.00012994367
Iter: 880 loss: 0.000129850931
Iter: 881 loss: 0.000129832857
Iter: 882 loss: 0.000129942346
Iter: 883 loss: 0.000129830572
Iter: 884 loss: 0.000129819353
Iter: 885 loss: 0.000129819178
Iter: 886 loss: 0.000129811844
Iter: 887 loss: 0.000129797671
Iter: 888 loss: 0.000130092114
Iter: 889 loss: 0.000129797409
Iter: 890 loss: 0.000129780907
Iter: 891 loss: 0.000129797321
Iter: 892 loss: 0.000129771463
Iter: 893 loss: 0.000129750915
Iter: 894 loss: 0.000129821507
Iter: 895 loss: 0.000129745546
Iter: 896 loss: 0.000129728694
Iter: 897 loss: 0.000129759501
Iter: 898 loss: 0.00012972136
Iter: 899 loss: 0.000129704626
Iter: 900 loss: 0.000129836946
Iter: 901 loss: 0.000129703374
Iter: 902 loss: 0.000129689652
Iter: 903 loss: 0.000129703578
Iter: 904 loss: 0.000129681968
Iter: 905 loss: 0.000129665161
Iter: 906 loss: 0.000129703025
Iter: 907 loss: 0.000129658962
Iter: 908 loss: 0.00012964342
Iter: 909 loss: 0.000129674852
Iter: 910 loss: 0.000129637221
Iter: 911 loss: 0.000129620312
Iter: 912 loss: 0.000129681081
Iter: 913 loss: 0.000129616237
Iter: 914 loss: 0.000129601074
Iter: 915 loss: 0.000129655207
Iter: 916 loss: 0.000129597203
Iter: 917 loss: 0.000129587861
Iter: 918 loss: 0.00012958741
Iter: 919 loss: 0.000129579959
Iter: 920 loss: 0.000129570311
Iter: 921 loss: 0.000129569555
Iter: 922 loss: 0.000129557229
Iter: 923 loss: 0.000129561173
Iter: 924 loss: 0.000129548629
Iter: 925 loss: 0.00012953284
Iter: 926 loss: 0.000129570908
Iter: 927 loss: 0.000129527092
Iter: 928 loss: 0.000129511158
Iter: 929 loss: 0.000129561551
Iter: 930 loss: 0.000129506734
Iter: 931 loss: 0.000129492139
Iter: 932 loss: 0.000129551801
Iter: 933 loss: 0.000129488966
Iter: 934 loss: 0.000129476975
Iter: 935 loss: 0.000129530556
Iter: 936 loss: 0.000129474778
Iter: 937 loss: 0.000129462351
Iter: 938 loss: 0.000129467968
Iter: 939 loss: 0.000129453882
Iter: 940 loss: 0.000129440232
Iter: 941 loss: 0.000129471358
Iter: 942 loss: 0.00012943527
Iter: 943 loss: 0.000129421576
Iter: 944 loss: 0.000129487482
Iter: 945 loss: 0.000129418826
Iter: 946 loss: 0.000129407519
Iter: 947 loss: 0.000129435488
Iter: 948 loss: 0.000129403401
Iter: 949 loss: 0.000129395339
Iter: 950 loss: 0.000129394932
Iter: 951 loss: 0.000129387452
Iter: 952 loss: 0.000129383552
Iter: 953 loss: 0.000129380307
Iter: 954 loss: 0.000129371503
Iter: 955 loss: 0.000129369044
Iter: 956 loss: 0.000129363791
Iter: 957 loss: 0.00012935081
Iter: 958 loss: 0.000129389417
Iter: 959 loss: 0.000129346881
Iter: 960 loss: 0.000129334221
Iter: 961 loss: 0.000129347551
Iter: 962 loss: 0.000129327207
Iter: 963 loss: 0.000129315522
Iter: 964 loss: 0.000129421605
Iter: 965 loss: 0.000129314867
Iter: 966 loss: 0.000129305292
Iter: 967 loss: 0.000129318854
Iter: 968 loss: 0.000129300694
Iter: 969 loss: 0.000129288906
Iter: 970 loss: 0.000129326072
Iter: 971 loss: 0.000129285429
Iter: 972 loss: 0.000129274544
Iter: 973 loss: 0.0001292917
Iter: 974 loss: 0.000129269654
Iter: 975 loss: 0.000129259177
Iter: 976 loss: 0.000129283755
Iter: 977 loss: 0.000129255481
Iter: 978 loss: 0.000129245454
Iter: 979 loss: 0.000129298263
Iter: 980 loss: 0.000129243679
Iter: 981 loss: 0.000129236461
Iter: 982 loss: 0.000129339605
Iter: 983 loss: 0.00012923649
Iter: 984 loss: 0.000129229549
Iter: 985 loss: 0.000129238208
Iter: 986 loss: 0.000129226173
Iter: 987 loss: 0.000129220512
Iter: 988 loss: 0.00012921181
Iter: 989 loss: 0.000129211781
Iter: 990 loss: 0.000129200984
Iter: 991 loss: 0.000129260065
Iter: 992 loss: 0.000129199499
Iter: 993 loss: 0.000129189924
Iter: 994 loss: 0.000129189386
Iter: 995 loss: 0.000129182066
Iter: 996 loss: 0.000129171851
Iter: 997 loss: 0.000129258435
Iter: 998 loss: 0.000129171051
Iter: 999 loss: 0.000129161504
Iter: 1000 loss: 0.000129177104
Iter: 1001 loss: 0.000129157168
Iter: 1002 loss: 0.000129147418
Iter: 1003 loss: 0.000129197113
Iter: 1004 loss: 0.000129145672
Iter: 1005 loss: 0.000129137334
Iter: 1006 loss: 0.000129145177
Iter: 1007 loss: 0.000129132692
Iter: 1008 loss: 0.00012912348
Iter: 1009 loss: 0.000129136984
Iter: 1010 loss: 0.000129119144
Iter: 1011 loss: 0.000129108987
Iter: 1012 loss: 0.00012916133
Iter: 1013 loss: 0.000129107095
Iter: 1014 loss: 0.000129100721
Iter: 1015 loss: 0.000129100794
Iter: 1016 loss: 0.000129094988
Iter: 1017 loss: 0.00012910596
Iter: 1018 loss: 0.00012909231
Iter: 1019 loss: 0.000129087217
Iter: 1020 loss: 0.000129078748
Iter: 1021 loss: 0.000129078631
Iter: 1022 loss: 0.000129069274
Iter: 1023 loss: 0.000129121589
Iter: 1024 loss: 0.000129068285
Iter: 1025 loss: 0.000129060223
Iter: 1026 loss: 0.000129067776
Iter: 1027 loss: 0.000129055494
Iter: 1028 loss: 0.000129046792
Iter: 1029 loss: 0.000129078893
Iter: 1030 loss: 0.000129044565
Iter: 1031 loss: 0.000129035776
Iter: 1032 loss: 0.00012905823
Iter: 1033 loss: 0.000129032516
Iter: 1034 loss: 0.000129023349
Iter: 1035 loss: 0.000129073451
Iter: 1036 loss: 0.000129022024
Iter: 1037 loss: 0.00012901469
Iter: 1038 loss: 0.000129019754
Iter: 1039 loss: 0.000129010165
Iter: 1040 loss: 0.000129001535
Iter: 1041 loss: 0.000129028573
Iter: 1042 loss: 0.00012899877
Iter: 1043 loss: 0.000128990621
Iter: 1044 loss: 0.000129007429
Iter: 1045 loss: 0.000128987303
Iter: 1046 loss: 0.000128981686
Iter: 1047 loss: 0.000128981628
Iter: 1048 loss: 0.00012897636
Iter: 1049 loss: 0.000128992455
Iter: 1050 loss: 0.000128974832
Iter: 1051 loss: 0.00012897054
Iter: 1052 loss: 0.000128965941
Iter: 1053 loss: 0.000128965185
Iter: 1054 loss: 0.000128958476
Iter: 1055 loss: 0.000128968226
Iter: 1056 loss: 0.000128955231
Iter: 1057 loss: 0.000128947708
Iter: 1058 loss: 0.000128966203
Iter: 1059 loss: 0.000128944885
Iter: 1060 loss: 0.00012893739
Iter: 1061 loss: 0.000128966611
Iter: 1062 loss: 0.000128935586
Iter: 1063 loss: 0.00012892895
Iter: 1064 loss: 0.000128937696
Iter: 1065 loss: 0.000128925371
Iter: 1066 loss: 0.000128917818
Iter: 1067 loss: 0.000128977728
Iter: 1068 loss: 0.000128917294
Iter: 1069 loss: 0.000128911663
Iter: 1070 loss: 0.000128917702
Iter: 1071 loss: 0.000128908578
Iter: 1072 loss: 0.000128902102
Iter: 1073 loss: 0.000128918866
Iter: 1074 loss: 0.00012890005
Iter: 1075 loss: 0.000128894069
Iter: 1076 loss: 0.000128903193
Iter: 1077 loss: 0.000128891232
Iter: 1078 loss: 0.00012888512
Iter: 1079 loss: 0.000128949119
Iter: 1080 loss: 0.000128884916
Iter: 1081 loss: 0.000128880536
Iter: 1082 loss: 0.000128930144
Iter: 1083 loss: 0.000128880667
Iter: 1084 loss: 0.000128877902
Iter: 1085 loss: 0.000128872853
Iter: 1086 loss: 0.000128984393
Iter: 1087 loss: 0.000128872882
Iter: 1088 loss: 0.000128867599
Iter: 1089 loss: 0.000128880114
Iter: 1090 loss: 0.000128865533
Iter: 1091 loss: 0.000128859654
Iter: 1092 loss: 0.00012886888
Iter: 1093 loss: 0.000128856715
Iter: 1094 loss: 0.000128850399
Iter: 1095 loss: 0.000128870946
Iter: 1096 loss: 0.000128848711
Iter: 1097 loss: 0.000128842788
Iter: 1098 loss: 0.000128858956
Iter: 1099 loss: 0.000128840533
Iter: 1100 loss: 0.000128834392
Iter: 1101 loss: 0.000128855143
Iter: 1102 loss: 0.000128832646
Iter: 1103 loss: 0.000128826825
Iter: 1104 loss: 0.000128853877
Iter: 1105 loss: 0.00012882585
Iter: 1106 loss: 0.000128820393
Iter: 1107 loss: 0.000128822037
Iter: 1108 loss: 0.000128816464
Iter: 1109 loss: 0.000128810876
Iter: 1110 loss: 0.000128821703
Iter: 1111 loss: 0.000128808373
Iter: 1112 loss: 0.000128802916
Iter: 1113 loss: 0.000128873304
Iter: 1114 loss: 0.000128803134
Iter: 1115 loss: 0.000128799787
Iter: 1116 loss: 0.000128846499
Iter: 1117 loss: 0.000128799773
Iter: 1118 loss: 0.000128797124
Iter: 1119 loss: 0.000128792584
Iter: 1120 loss: 0.000128883737
Iter: 1121 loss: 0.000128792133
Iter: 1122 loss: 0.000128787506
Iter: 1123 loss: 0.00012880037
Iter: 1124 loss: 0.000128785789
Iter: 1125 loss: 0.000128780797
Iter: 1126 loss: 0.000128789601
Iter: 1127 loss: 0.000128778396
Iter: 1128 loss: 0.000128772808
Iter: 1129 loss: 0.000128784042
Iter: 1130 loss: 0.00012877048
Iter: 1131 loss: 0.00012876463
Iter: 1132 loss: 0.000128785061
Iter: 1133 loss: 0.000128762855
Iter: 1134 loss: 0.000128757325
Iter: 1135 loss: 0.000128779589
Iter: 1136 loss: 0.000128755986
Iter: 1137 loss: 0.000128750835
Iter: 1138 loss: 0.000128765707
Iter: 1139 loss: 0.000128749234
Iter: 1140 loss: 0.000128743821
Iter: 1141 loss: 0.00012875555
Iter: 1142 loss: 0.000128741696
Iter: 1143 loss: 0.000128736938
Iter: 1144 loss: 0.000128739543
Iter: 1145 loss: 0.000128734013
Iter: 1146 loss: 0.000128729298
Iter: 1147 loss: 0.000128788379
Iter: 1148 loss: 0.000128729371
Iter: 1149 loss: 0.000128726228
Iter: 1150 loss: 0.00012877112
Iter: 1151 loss: 0.000128726213
Iter: 1152 loss: 0.000128723768
Iter: 1153 loss: 0.000128719665
Iter: 1154 loss: 0.000128719592
Iter: 1155 loss: 0.000128715968
Iter: 1156 loss: 0.000128723099
Iter: 1157 loss: 0.00012871428
Iter: 1158 loss: 0.000128710119
Iter: 1159 loss: 0.000128714528
Iter: 1160 loss: 0.000128707499
Iter: 1161 loss: 0.000128702828
Iter: 1162 loss: 0.000128720902
Iter: 1163 loss: 0.000128701591
Iter: 1164 loss: 0.000128696556
Iter: 1165 loss: 0.000128706422
Iter: 1166 loss: 0.000128694664
Iter: 1167 loss: 0.000128690299
Iter: 1168 loss: 0.000128710613
Iter: 1169 loss: 0.000128689266
Iter: 1170 loss: 0.000128684755
Iter: 1171 loss: 0.000128698011
Iter: 1172 loss: 0.000128683634
Iter: 1173 loss: 0.000128679327
Iter: 1174 loss: 0.000128692642
Iter: 1175 loss: 0.000128678032
Iter: 1176 loss: 0.000128674481
Iter: 1177 loss: 0.000128678352
Iter: 1178 loss: 0.000128672473
Iter: 1179 loss: 0.00012866834
Iter: 1180 loss: 0.000128685249
Iter: 1181 loss: 0.000128667336
Iter: 1182 loss: 0.000128665371
Iter: 1183 loss: 0.000128665153
Iter: 1184 loss: 0.000128663174
Iter: 1185 loss: 0.000128659856
Iter: 1186 loss: 0.00012866006
Iter: 1187 loss: 0.00012865664
Iter: 1188 loss: 0.00012866492
Iter: 1189 loss: 0.000128655622
Iter: 1190 loss: 0.000128652217
Iter: 1191 loss: 0.000128651824
Iter: 1192 loss: 0.000128649161
Iter: 1193 loss: 0.000128644955
Iter: 1194 loss: 0.000128668908
Iter: 1195 loss: 0.000128644373
Iter: 1196 loss: 0.0001286404
Iter: 1197 loss: 0.00012864836
Iter: 1198 loss: 0.000128638756
Iter: 1199 loss: 0.000128634943
Iter: 1200 loss: 0.000128645188
Iter: 1201 loss: 0.000128633677
Iter: 1202 loss: 0.000128629952
Iter: 1203 loss: 0.000128649495
Iter: 1204 loss: 0.000128629064
Iter: 1205 loss: 0.00012862563
Iter: 1206 loss: 0.000128634783
Iter: 1207 loss: 0.000128624553
Iter: 1208 loss: 0.000128621279
Iter: 1209 loss: 0.000128623491
Iter: 1210 loss: 0.000128619329
Iter: 1211 loss: 0.000128615313
Iter: 1212 loss: 0.000128633503
Iter: 1213 loss: 0.000128614716
Iter: 1214 loss: 0.000128612475
Iter: 1215 loss: 0.000128612417
Iter: 1216 loss: 0.000128610409
Iter: 1217 loss: 0.00012860923
Iter: 1218 loss: 0.000128608255
Iter: 1219 loss: 0.000128605519
Iter: 1220 loss: 0.000128605665
Iter: 1221 loss: 0.000128603613
Iter: 1222 loss: 0.000128600106
Iter: 1223 loss: 0.000128607033
Iter: 1224 loss: 0.000128598476
Iter: 1225 loss: 0.000128594416
Iter: 1226 loss: 0.000128605068
Iter: 1227 loss: 0.000128593325
Iter: 1228 loss: 0.000128589571
Iter: 1229 loss: 0.000128596672
Iter: 1230 loss: 0.000128588159
Iter: 1231 loss: 0.000128584245
Iter: 1232 loss: 0.000128602434
Iter: 1233 loss: 0.000128583546
Iter: 1234 loss: 0.00012858017
Iter: 1235 loss: 0.000128586675
Iter: 1236 loss: 0.000128578511
Iter: 1237 loss: 0.000128575324
Iter: 1238 loss: 0.000128598505
Iter: 1239 loss: 0.000128575164
Iter: 1240 loss: 0.000128572312
Iter: 1241 loss: 0.000128571875
Iter: 1242 loss: 0.000128569955
Iter: 1243 loss: 0.000128566375
Iter: 1244 loss: 0.000128581072
Iter: 1245 loss: 0.000128565676
Iter: 1246 loss: 0.000128563537
Iter: 1247 loss: 0.000128563566
Iter: 1248 loss: 0.000128561282
Iter: 1249 loss: 0.000128563959
Iter: 1250 loss: 0.000128560016
Iter: 1251 loss: 0.000128558313
Iter: 1252 loss: 0.000128555926
Iter: 1253 loss: 0.000128555548
Iter: 1254 loss: 0.000128552711
Iter: 1255 loss: 0.000128560452
Iter: 1256 loss: 0.000128551488
Iter: 1257 loss: 0.000128548039
Iter: 1258 loss: 0.000128559914
Iter: 1259 loss: 0.000128547137
Iter: 1260 loss: 0.000128544169
Iter: 1261 loss: 0.000128546992
Iter: 1262 loss: 0.000128542742
Iter: 1263 loss: 0.000128539512
Iter: 1264 loss: 0.000128559856
Iter: 1265 loss: 0.000128539265
Iter: 1266 loss: 0.000128536543
Iter: 1267 loss: 0.000128540094
Iter: 1268 loss: 0.000128535205
Iter: 1269 loss: 0.000128532352
Iter: 1270 loss: 0.000128551823
Iter: 1271 loss: 0.000128532105
Iter: 1272 loss: 0.000128529646
Iter: 1273 loss: 0.000128531014
Iter: 1274 loss: 0.000128527987
Iter: 1275 loss: 0.000128525338
Iter: 1276 loss: 0.000128533109
Iter: 1277 loss: 0.000128524451
Iter: 1278 loss: 0.000128522603
Iter: 1279 loss: 0.000128548825
Iter: 1280 loss: 0.000128522617
Iter: 1281 loss: 0.000128520405
Iter: 1282 loss: 0.000128526648
Iter: 1283 loss: 0.000128519983
Iter: 1284 loss: 0.00012851863
Iter: 1285 loss: 0.000128517015
Iter: 1286 loss: 0.000128516695
Iter: 1287 loss: 0.000128514133
Iter: 1288 loss: 0.000128517582
Iter: 1289 loss: 0.000128513
Iter: 1290 loss: 0.00012851019
Iter: 1291 loss: 0.000128521802
Iter: 1292 loss: 0.000128509593
Iter: 1293 loss: 0.000128507352
Iter: 1294 loss: 0.000128510903
Iter: 1295 loss: 0.000128505955
Iter: 1296 loss: 0.000128503569
Iter: 1297 loss: 0.000128514977
Iter: 1298 loss: 0.000128503
Iter: 1299 loss: 0.00012850076
Iter: 1300 loss: 0.000128503598
Iter: 1301 loss: 0.000128499625
Iter: 1302 loss: 0.000128496875
Iter: 1303 loss: 0.000128516869
Iter: 1304 loss: 0.000128496729
Iter: 1305 loss: 0.000128494677
Iter: 1306 loss: 0.00012849638
Iter: 1307 loss: 0.000128493601
Iter: 1308 loss: 0.000128491069
Iter: 1309 loss: 0.00012850108
Iter: 1310 loss: 0.000128490647
Iter: 1311 loss: 0.000128489075
Iter: 1312 loss: 0.000128493193
Iter: 1313 loss: 0.000128488071
Iter: 1314 loss: 0.000128485961
Iter: 1315 loss: 0.000128513173
Iter: 1316 loss: 0.000128486179
Iter: 1317 loss: 0.00012848503
Iter: 1318 loss: 0.000128483036
Iter: 1319 loss: 0.000128526153
Iter: 1320 loss: 0.000128483021
Iter: 1321 loss: 0.000128480722
Iter: 1322 loss: 0.000128486048
Iter: 1323 loss: 0.00012848
Iter: 1324 loss: 0.000128477623
Iter: 1325 loss: 0.0001284842
Iter: 1326 loss: 0.000128477026
Iter: 1327 loss: 0.000128474872
Iter: 1328 loss: 0.00012847918
Iter: 1329 loss: 0.000128473795
Iter: 1330 loss: 0.00012847154
Iter: 1331 loss: 0.000128480402
Iter: 1332 loss: 0.000128470871
Iter: 1333 loss: 0.000128468819
Iter: 1334 loss: 0.000128470216
Iter: 1335 loss: 0.000128467407
Iter: 1336 loss: 0.000128465152
Iter: 1337 loss: 0.000128491811
Iter: 1338 loss: 0.000128465093
Iter: 1339 loss: 0.00012846326
Iter: 1340 loss: 0.000128463376
Iter: 1341 loss: 0.000128461863
Iter: 1342 loss: 0.00012845968
Iter: 1343 loss: 0.000128473024
Iter: 1344 loss: 0.000128459433
Iter: 1345 loss: 0.000128457788
Iter: 1346 loss: 0.000128458953
Iter: 1347 loss: 0.000128456653
Iter: 1348 loss: 0.00012845546
Iter: 1349 loss: 0.000128455358
Iter: 1350 loss: 0.000128454383
Iter: 1351 loss: 0.000128452622
Iter: 1352 loss: 0.000128477317
Iter: 1353 loss: 0.000128452331
Iter: 1354 loss: 0.000128450294
Iter: 1355 loss: 0.000128456872
Iter: 1356 loss: 0.000128449872
Iter: 1357 loss: 0.000128447937
Iter: 1358 loss: 0.000128451749
Iter: 1359 loss: 0.000128447384
Iter: 1360 loss: 0.000128445274
Iter: 1361 loss: 0.000128448271
Iter: 1362 loss: 0.000128444211
Iter: 1363 loss: 0.000128442072
Iter: 1364 loss: 0.000128453234
Iter: 1365 loss: 0.00012844181
Iter: 1366 loss: 0.00012843986
Iter: 1367 loss: 0.000128440559
Iter: 1368 loss: 0.00012843842
Iter: 1369 loss: 0.000128436455
Iter: 1370 loss: 0.000128452637
Iter: 1371 loss: 0.000128436222
Iter: 1372 loss: 0.00012843436
Iter: 1373 loss: 0.000128437736
Iter: 1374 loss: 0.000128433516
Iter: 1375 loss: 0.000128431566
Iter: 1376 loss: 0.000128438172
Iter: 1377 loss: 0.000128431129
Iter: 1378 loss: 0.000128429325
Iter: 1379 loss: 0.000128431449
Iter: 1380 loss: 0.000128428437
Iter: 1381 loss: 0.000128427608
Iter: 1382 loss: 0.000128427258
Iter: 1383 loss: 0.000128426502
Iter: 1384 loss: 0.00012842461
Iter: 1385 loss: 0.000128460044
Iter: 1386 loss: 0.000128424857
Iter: 1387 loss: 0.000128423
Iter: 1388 loss: 0.000128425178
Iter: 1389 loss: 0.000128422151
Iter: 1390 loss: 0.000128420157
Iter: 1391 loss: 0.000128426065
Iter: 1392 loss: 0.000128419575
Iter: 1393 loss: 0.000128417625
Iter: 1394 loss: 0.000128423184
Iter: 1395 loss: 0.000128416985
Iter: 1396 loss: 0.000128415224
Iter: 1397 loss: 0.000128418542
Iter: 1398 loss: 0.000128414453
Iter: 1399 loss: 0.00012841227
Iter: 1400 loss: 0.000128419299
Iter: 1401 loss: 0.000128411833
Iter: 1402 loss: 0.000128410116
Iter: 1403 loss: 0.000128416359
Iter: 1404 loss: 0.000128409476
Iter: 1405 loss: 0.000128407788
Iter: 1406 loss: 0.000128415355
Iter: 1407 loss: 0.000128407366
Iter: 1408 loss: 0.000128405896
Iter: 1409 loss: 0.000128408821
Iter: 1410 loss: 0.000128405445
Iter: 1411 loss: 0.000128403917
Iter: 1412 loss: 0.000128405343
Iter: 1413 loss: 0.000128403131
Iter: 1414 loss: 0.000128402316
Iter: 1415 loss: 0.000128401967
Iter: 1416 loss: 0.000128401
Iter: 1417 loss: 0.000128399886
Iter: 1418 loss: 0.00012839993
Iter: 1419 loss: 0.000128398329
Iter: 1420 loss: 0.0001283983
Iter: 1421 loss: 0.000128397282
Iter: 1422 loss: 0.000128395579
Iter: 1423 loss: 0.00012840156
Iter: 1424 loss: 0.000128395026
Iter: 1425 loss: 0.000128393498
Iter: 1426 loss: 0.00012839798
Iter: 1427 loss: 0.000128392901
Iter: 1428 loss: 0.000128391315
Iter: 1429 loss: 0.000128396379
Iter: 1430 loss: 0.000128390835
Iter: 1431 loss: 0.00012838922
Iter: 1432 loss: 0.000128391432
Iter: 1433 loss: 0.000128388449
Iter: 1434 loss: 0.000128386877
Iter: 1435 loss: 0.000128395783
Iter: 1436 loss: 0.000128386469
Iter: 1437 loss: 0.000128385203
Iter: 1438 loss: 0.000128390384
Iter: 1439 loss: 0.000128384607
Iter: 1440 loss: 0.000128383545
Iter: 1441 loss: 0.00012838663
Iter: 1442 loss: 0.000128383181
Iter: 1443 loss: 0.000128381973
Iter: 1444 loss: 0.000128385029
Iter: 1445 loss: 0.000128381449
Iter: 1446 loss: 0.000128380285
Iter: 1447 loss: 0.000128394648
Iter: 1448 loss: 0.000128380547
Iter: 1449 loss: 0.000128379572
Iter: 1450 loss: 0.000128379892
Iter: 1451 loss: 0.000128378801
Iter: 1452 loss: 0.000128377986
Iter: 1453 loss: 0.000128376909
Iter: 1454 loss: 0.000128376909
Iter: 1455 loss: 0.000128375497
Iter: 1456 loss: 0.000128384941
Iter: 1457 loss: 0.000128375308
Iter: 1458 loss: 0.000128374377
Iter: 1459 loss: 0.00012837445
Iter: 1460 loss: 0.000128373445
Iter: 1461 loss: 0.000128372078
Iter: 1462 loss: 0.000128381202
Iter: 1463 loss: 0.000128372165
Iter: 1464 loss: 0.000128370768
Iter: 1465 loss: 0.000128371903
Iter: 1466 loss: 0.000128370273
Iter: 1467 loss: 0.000128368993
Iter: 1468 loss: 0.000128374086
Iter: 1469 loss: 0.000128368672
Iter: 1470 loss: 0.000128367683
Iter: 1471 loss: 0.000128373853
Iter: 1472 loss: 0.00012836745
Iter: 1473 loss: 0.000128366606
Iter: 1474 loss: 0.000128368527
Iter: 1475 loss: 0.00012836617
Iter: 1476 loss: 0.000128365282
Iter: 1477 loss: 0.000128367683
Iter: 1478 loss: 0.000128365034
Iter: 1479 loss: 0.000128364249
Iter: 1480 loss: 0.000128370099
Iter: 1481 loss: 0.000128363972
Iter: 1482 loss: 0.000128363201
Iter: 1483 loss: 0.000128365966
Iter: 1484 loss: 0.000128363026
Iter: 1485 loss: 0.000128362648
Iter: 1486 loss: 0.000128361746
Iter: 1487 loss: 0.000128383443
Iter: 1488 loss: 0.000128361717
Iter: 1489 loss: 0.000128360552
Iter: 1490 loss: 0.000128367217
Iter: 1491 loss: 0.000128360436
Iter: 1492 loss: 0.000128359563
Iter: 1493 loss: 0.000128359563
Iter: 1494 loss: 0.000128359025
Iter: 1495 loss: 0.000128357875
Iter: 1496 loss: 0.000128365791
Iter: 1497 loss: 0.000128357657
Iter: 1498 loss: 0.000128356725
Iter: 1499 loss: 0.000128357773
Iter: 1500 loss: 0.000128356041
Iter: 1501 loss: 0.00012835511
Iter: 1502 loss: 0.000128357977
Iter: 1503 loss: 0.000128354528
Iter: 1504 loss: 0.000128353524
Iter: 1505 loss: 0.000128361266
Iter: 1506 loss: 0.00012835348
Iter: 1507 loss: 0.000128352694
Iter: 1508 loss: 0.000128354193
Iter: 1509 loss: 0.000128352433
Iter: 1510 loss: 0.000128351428
Iter: 1511 loss: 0.000128352869
Iter: 1512 loss: 0.000128351166
Iter: 1513 loss: 0.000128350483
Iter: 1514 loss: 0.000128356973
Iter: 1515 loss: 0.000128350366
Iter: 1516 loss: 0.000128349566
Iter: 1517 loss: 0.000128353393
Iter: 1518 loss: 0.000128349377
Iter: 1519 loss: 0.000128349
Iter: 1520 loss: 0.000128347936
Iter: 1521 loss: 0.000128366446
Iter: 1522 loss: 0.000128347951
Iter: 1523 loss: 0.000128347092
Iter: 1524 loss: 0.000128352112
Iter: 1525 loss: 0.000128346874
Iter: 1526 loss: 0.000128345928
Iter: 1527 loss: 0.000128346874
Iter: 1528 loss: 0.000128345448
Iter: 1529 loss: 0.000128344458
Iter: 1530 loss: 0.000128347514
Iter: 1531 loss: 0.00012834408
Iter: 1532 loss: 0.000128342872
Iter: 1533 loss: 0.00012834568
Iter: 1534 loss: 0.000128342683
Iter: 1535 loss: 0.000128341722
Iter: 1536 loss: 0.000128344516
Iter: 1537 loss: 0.000128341417
Iter: 1538 loss: 0.000128340529
Iter: 1539 loss: 0.000128343599
Iter: 1540 loss: 0.000128340107
Iter: 1541 loss: 0.000128339205
Iter: 1542 loss: 0.000128344473
Iter: 1543 loss: 0.000128339103
Iter: 1544 loss: 0.00012833855
Iter: 1545 loss: 0.000128338972
Iter: 1546 loss: 0.00012833791
Iter: 1547 loss: 0.000128337328
Iter: 1548 loss: 0.00012834424
Iter: 1549 loss: 0.000128337371
Iter: 1550 loss: 0.0001283366
Iter: 1551 loss: 0.000128339831
Iter: 1552 loss: 0.000128336571
Iter: 1553 loss: 0.000128335931
Iter: 1554 loss: 0.000128335174
Iter: 1555 loss: 0.000128335319
Iter: 1556 loss: 0.000128334184
Iter: 1557 loss: 0.000128336309
Iter: 1558 loss: 0.000128333893
Iter: 1559 loss: 0.000128333108
Iter: 1560 loss: 0.000128336658
Iter: 1561 loss: 0.000128332991
Iter: 1562 loss: 0.000128331987
Iter: 1563 loss: 0.000128334053
Iter: 1564 loss: 0.000128331783
Iter: 1565 loss: 0.000128330707
Iter: 1566 loss: 0.000128332627
Iter: 1567 loss: 0.000128330459
Iter: 1568 loss: 0.000128329601
Iter: 1569 loss: 0.000128333806
Iter: 1570 loss: 0.000128329324
Iter: 1571 loss: 0.000128328495
Iter: 1572 loss: 0.000128329673
Iter: 1573 loss: 0.00012832816
Iter: 1574 loss: 0.000128327243
Iter: 1575 loss: 0.000128334606
Iter: 1576 loss: 0.000128327141
Iter: 1577 loss: 0.000128326559
Iter: 1578 loss: 0.00012832717
Iter: 1579 loss: 0.000128326239
Iter: 1580 loss: 0.00012832557
Iter: 1581 loss: 0.000128329615
Iter: 1582 loss: 0.000128325395
Iter: 1583 loss: 0.000128325046
Iter: 1584 loss: 0.000128329848
Iter: 1585 loss: 0.000128325075
Iter: 1586 loss: 0.000128324609
Iter: 1587 loss: 0.000128324
Iter: 1588 loss: 0.000128323882
Iter: 1589 loss: 0.000128323198
Iter: 1590 loss: 0.000128324275
Iter: 1591 loss: 0.000128323
Iter: 1592 loss: 0.000128322106
Iter: 1593 loss: 0.000128324027
Iter: 1594 loss: 0.000128321903
Iter: 1595 loss: 0.000128321029
Iter: 1596 loss: 0.000128324493
Iter: 1597 loss: 0.000128320782
Iter: 1598 loss: 0.000128320098
Iter: 1599 loss: 0.000128321612
Iter: 1600 loss: 0.000128319865
Iter: 1601 loss: 0.00012831908
Iter: 1602 loss: 0.000128320797
Iter: 1603 loss: 0.000128318788
Iter: 1604 loss: 0.000128318206
Iter: 1605 loss: 0.000128320477
Iter: 1606 loss: 0.000128317944
Iter: 1607 loss: 0.000128317159
Iter: 1608 loss: 0.000128321859
Iter: 1609 loss: 0.000128317057
Iter: 1610 loss: 0.000128316518
Iter: 1611 loss: 0.000128317799
Iter: 1612 loss: 0.000128316402
Iter: 1613 loss: 0.00012831582
Iter: 1614 loss: 0.000128317479
Iter: 1615 loss: 0.000128315849
Iter: 1616 loss: 0.000128315485
Iter: 1617 loss: 0.000128315456
Iter: 1618 loss: 0.000128315136
Iter: 1619 loss: 0.000128314423
Iter: 1620 loss: 0.000128325264
Iter: 1621 loss: 0.000128314379
Iter: 1622 loss: 0.000128313812
Iter: 1623 loss: 0.00012831534
Iter: 1624 loss: 0.000128313608
Iter: 1625 loss: 0.00012831323
Iter: 1626 loss: 0.000128313623
Iter: 1627 loss: 0.000128312677
Iter: 1628 loss: 0.000128311891
Iter: 1629 loss: 0.000128315616
Iter: 1630 loss: 0.000128311847
Iter: 1631 loss: 0.000128311323
Iter: 1632 loss: 0.000128313084
Iter: 1633 loss: 0.000128311091
Iter: 1634 loss: 0.000128310247
Iter: 1635 loss: 0.000128311192
Iter: 1636 loss: 0.000128310174
Iter: 1637 loss: 0.000128309475
Iter: 1638 loss: 0.000128311862
Iter: 1639 loss: 0.000128309184
Iter: 1640 loss: 0.000128308704
Iter: 1641 loss: 0.000128313084
Iter: 1642 loss: 0.000128308515
Iter: 1643 loss: 0.000128308282
Iter: 1644 loss: 0.000128309519
Iter: 1645 loss: 0.000128307933
Iter: 1646 loss: 0.000128307554
Iter: 1647 loss: 0.000128308515
Iter: 1648 loss: 0.000128307409
Iter: 1649 loss: 0.000128307205
Iter: 1650 loss: 0.000128306972
Iter: 1651 loss: 0.000128306885
Iter: 1652 loss: 0.000128306463
Iter: 1653 loss: 0.000128315674
Iter: 1654 loss: 0.000128306143
Iter: 1655 loss: 0.000128305663
Iter: 1656 loss: 0.000128306754
Iter: 1657 loss: 0.00012830575
Iter: 1658 loss: 0.000128305197
Iter: 1659 loss: 0.000128305721
Iter: 1660 loss: 0.000128304906
Iter: 1661 loss: 0.00012830412
Iter: 1662 loss: 0.00012830738
Iter: 1663 loss: 0.000128304295
Iter: 1664 loss: 0.00012830364
Iter: 1665 loss: 0.000128304702
Iter: 1666 loss: 0.000128303465
Iter: 1667 loss: 0.000128302723
Iter: 1668 loss: 0.000128303771
Iter: 1669 loss: 0.00012830233
Iter: 1670 loss: 0.000128302
Iter: 1671 loss: 0.000128303567
Iter: 1672 loss: 0.000128301646
Iter: 1673 loss: 0.000128301152
Iter: 1674 loss: 0.000128304804
Iter: 1675 loss: 0.000128301152
Iter: 1676 loss: 0.000128300686
Iter: 1677 loss: 0.00012830217
Iter: 1678 loss: 0.000128300439
Iter: 1679 loss: 0.000128300104
Iter: 1680 loss: 0.000128301326
Iter: 1681 loss: 0.000128299813
Iter: 1682 loss: 0.000128299827
Iter: 1683 loss: 0.000128299784
Iter: 1684 loss: 0.000128299667
Iter: 1685 loss: 0.000128298983
Iter: 1686 loss: 0.000128298983
Iter: 1687 loss: 0.000128298561
Iter: 1688 loss: 0.000128298794
Iter: 1689 loss: 0.000128298299
Iter: 1690 loss: 0.000128297601
Iter: 1691 loss: 0.000128298867
Iter: 1692 loss: 0.000128297528
Iter: 1693 loss: 0.00012829683
Iter: 1694 loss: 0.000128299071
Iter: 1695 loss: 0.000128296742
Iter: 1696 loss: 0.000128296175
Iter: 1697 loss: 0.000128297572
Iter: 1698 loss: 0.000128296044
Iter: 1699 loss: 0.000128295549
Iter: 1700 loss: 0.000128297223
Iter: 1701 loss: 0.000128295316
Iter: 1702 loss: 0.000128294821
Iter: 1703 loss: 0.000128295331
Iter: 1704 loss: 0.000128294691
Iter: 1705 loss: 0.000128294036
Iter: 1706 loss: 0.000128297281
Iter: 1707 loss: 0.000128293701
Iter: 1708 loss: 0.000128293294
Iter: 1709 loss: 0.00012829667
Iter: 1710 loss: 0.000128293206
Iter: 1711 loss: 0.000128292973
Iter: 1712 loss: 0.000128293745
Iter: 1713 loss: 0.000128292944
Iter: 1714 loss: 0.000128292639
Iter: 1715 loss: 0.000128296393
Iter: 1716 loss: 0.00012829245
Iter: 1717 loss: 0.000128292115
Iter: 1718 loss: 0.000128292304
Iter: 1719 loss: 0.000128291984
Iter: 1720 loss: 0.000128291606
Iter: 1721 loss: 0.000128291606
Iter: 1722 loss: 0.000128291227
Iter: 1723 loss: 0.000128290849
Iter: 1724 loss: 0.0001282921
Iter: 1725 loss: 0.000128290849
Iter: 1726 loss: 0.000128290558
Iter: 1727 loss: 0.00012829146
Iter: 1728 loss: 0.00012829015
Iter: 1729 loss: 0.000128289641
Iter: 1730 loss: 0.000128291184
Iter: 1731 loss: 0.000128289292
Iter: 1732 loss: 0.000128289088
Iter: 1733 loss: 0.000128290078
Iter: 1734 loss: 0.00012828887
Iter: 1735 loss: 0.000128288244
Iter: 1736 loss: 0.000128289612
Iter: 1737 loss: 0.000128288259
Iter: 1738 loss: 0.000128287676
Iter: 1739 loss: 0.000128289423
Iter: 1740 loss: 0.000128287444
Iter: 1741 loss: 0.000128287211
Iter: 1742 loss: 0.000128290936
Iter: 1743 loss: 0.000128287094
Iter: 1744 loss: 0.000128286614
Iter: 1745 loss: 0.000128287502
Iter: 1746 loss: 0.000128286541
Iter: 1747 loss: 0.000128286338
Iter: 1748 loss: 0.000128289044
Iter: 1749 loss: 0.000128286381
Iter: 1750 loss: 0.000128286076
Iter: 1751 loss: 0.000128285974
Iter: 1752 loss: 0.000128285697
Iter: 1753 loss: 0.000128285537
Iter: 1754 loss: 0.000128285523
Iter: 1755 loss: 0.000128285217
Iter: 1756 loss: 0.000128284824
Iter: 1757 loss: 0.000128285479
Iter: 1758 loss: 0.00012828449
Iter: 1759 loss: 0.0001282843
Iter: 1760 loss: 0.000128285697
Iter: 1761 loss: 0.000128284126
Iter: 1762 loss: 0.000128283573
Iter: 1763 loss: 0.000128285494
Iter: 1764 loss: 0.00012828366
Iter: 1765 loss: 0.000128283165
Iter: 1766 loss: 0.000128283718
Iter: 1767 loss: 0.000128282758
Iter: 1768 loss: 0.000128282409
Iter: 1769 loss: 0.000128284242
Iter: 1770 loss: 0.000128282292
Iter: 1771 loss: 0.000128281798
Iter: 1772 loss: 0.000128282962
Iter: 1773 loss: 0.000128281827
Iter: 1774 loss: 0.000128281332
Iter: 1775 loss: 0.000128284679
Iter: 1776 loss: 0.000128281303
Iter: 1777 loss: 0.000128280954
Iter: 1778 loss: 0.00012828171
Iter: 1779 loss: 0.000128281012
Iter: 1780 loss: 0.000128280633
Iter: 1781 loss: 0.000128283296
Iter: 1782 loss: 0.000128280561
Iter: 1783 loss: 0.000128280401
Iter: 1784 loss: 0.000128280633
Iter: 1785 loss: 0.000128280313
Iter: 1786 loss: 0.000128280124
Iter: 1787 loss: 0.000128279964
Iter: 1788 loss: 0.000128279731
Iter: 1789 loss: 0.000128279338
Iter: 1790 loss: 0.000128280008
Iter: 1791 loss: 0.000128279135
Iter: 1792 loss: 0.000128278829
Iter: 1793 loss: 0.000128280473
Iter: 1794 loss: 0.000128278683
Iter: 1795 loss: 0.000128278392
Iter: 1796 loss: 0.000128279615
Iter: 1797 loss: 0.00012827832
Iter: 1798 loss: 0.00012827797
Iter: 1799 loss: 0.000128278203
Iter: 1800 loss: 0.000128277694
Iter: 1801 loss: 0.000128277228
Iter: 1802 loss: 0.000128279469
Iter: 1803 loss: 0.000128277286
Iter: 1804 loss: 0.000128276966
Iter: 1805 loss: 0.000128277126
Iter: 1806 loss: 0.000128276646
Iter: 1807 loss: 0.000128276253
Iter: 1808 loss: 0.00012827992
Iter: 1809 loss: 0.000128276093
Iter: 1810 loss: 0.000128275773
Iter: 1811 loss: 0.000128277257
Iter: 1812 loss: 0.000128275831
Iter: 1813 loss: 0.000128275424
Iter: 1814 loss: 0.000128277083
Iter: 1815 loss: 0.000128275642
Iter: 1816 loss: 0.000128275336
Iter: 1817 loss: 0.000128275773
Iter: 1818 loss: 0.000128275249
Iter: 1819 loss: 0.000128275133
Iter: 1820 loss: 0.000128274769
Iter: 1821 loss: 0.000128274638
Iter: 1822 loss: 0.00012827442
Iter: 1823 loss: 0.000128275045
Iter: 1824 loss: 0.000128274172
Iter: 1825 loss: 0.000128273983
Iter: 1826 loss: 0.000128274987
Iter: 1827 loss: 0.000128273678
Iter: 1828 loss: 0.000128273328
Iter: 1829 loss: 0.000128274332
Iter: 1830 loss: 0.000128273154
Iter: 1831 loss: 0.000128273023
Iter: 1832 loss: 0.000128273707
Iter: 1833 loss: 0.000128272688
Iter: 1834 loss: 0.000128272455
Iter: 1835 loss: 0.00012827359
Iter: 1836 loss: 0.000128272339
Iter: 1837 loss: 0.000128271698
Iter: 1838 loss: 0.000128272484
Iter: 1839 loss: 0.000128271742
Iter: 1840 loss: 0.000128271233
Iter: 1841 loss: 0.000128273823
Iter: 1842 loss: 0.000128271204
Iter: 1843 loss: 0.000128270753
Iter: 1844 loss: 0.000128273095
Iter: 1845 loss: 0.000128270796
Iter: 1846 loss: 0.000128270505
Iter: 1847 loss: 0.000128271786
Iter: 1848 loss: 0.000128270767
Iter: 1849 loss: 0.00012827036
Iter: 1850 loss: 0.000128270913
Iter: 1851 loss: 0.000128270389
Iter: 1852 loss: 0.000128270025
Iter: 1853 loss: 0.000128269807
Iter: 1854 loss: 0.000128270054
Iter: 1855 loss: 0.000128269603
Iter: 1856 loss: 0.000128270098
Iter: 1857 loss: 0.000128269225
Iter: 1858 loss: 0.000128268977
Iter: 1859 loss: 0.000128269981
Iter: 1860 loss: 0.000128268948
Iter: 1861 loss: 0.000128268628
Iter: 1862 loss: 0.000128269428
Iter: 1863 loss: 0.000128268366
Iter: 1864 loss: 0.000128268148
Iter: 1865 loss: 0.000128268861
Iter: 1866 loss: 0.000128267959
Iter: 1867 loss: 0.000128267566
Iter: 1868 loss: 0.000128268352
Iter: 1869 loss: 0.00012826742
Iter: 1870 loss: 0.000128266838
Iter: 1871 loss: 0.000128268322
Iter: 1872 loss: 0.000128266925
Iter: 1873 loss: 0.000128266489
Iter: 1874 loss: 0.000128268322
Iter: 1875 loss: 0.000128266242
Iter: 1876 loss: 0.000128266125
Iter: 1877 loss: 0.000128267857
Iter: 1878 loss: 0.000128266052
Iter: 1879 loss: 0.000128265645
Iter: 1880 loss: 0.000128266751
Iter: 1881 loss: 0.000128265805
Iter: 1882 loss: 0.000128265514
Iter: 1883 loss: 0.000128265921
Iter: 1884 loss: 0.000128265587
Iter: 1885 loss: 0.000128265427
Iter: 1886 loss: 0.000128265106
Iter: 1887 loss: 0.000128265034
Iter: 1888 loss: 0.00012826467
Iter: 1889 loss: 0.000128265034
Iter: 1890 loss: 0.000128264568
Iter: 1891 loss: 0.000128264117
Iter: 1892 loss: 0.000128265267
Iter: 1893 loss: 0.000128264102
Iter: 1894 loss: 0.000128263666
Iter: 1895 loss: 0.000128264728
Iter: 1896 loss: 0.000128263433
Iter: 1897 loss: 0.000128263287
Iter: 1898 loss: 0.000128264059
Iter: 1899 loss: 0.000128263186
Iter: 1900 loss: 0.000128262735
Iter: 1901 loss: 0.000128263491
Iter: 1902 loss: 0.000128262502
Iter: 1903 loss: 0.000128262414
Iter: 1904 loss: 0.000128263389
Iter: 1905 loss: 0.000128262123
Iter: 1906 loss: 0.000128261963
Iter: 1907 loss: 0.000128263433
Iter: 1908 loss: 0.000128261803
Iter: 1909 loss: 0.000128261338
Iter: 1910 loss: 0.000128262967
Iter: 1911 loss: 0.000128261294
Iter: 1912 loss: 0.00012826125
Iter: 1913 loss: 0.000128262473
Iter: 1914 loss: 0.000128261207
Iter: 1915 loss: 0.000128261061
Iter: 1916 loss: 0.000128261701
Iter: 1917 loss: 0.000128261076
Iter: 1918 loss: 0.000128260974
Iter: 1919 loss: 0.000128260668
Iter: 1920 loss: 0.000128260755
Iter: 1921 loss: 0.000128260392
Iter: 1922 loss: 0.000128260901
Iter: 1923 loss: 0.000128260202
Iter: 1924 loss: 0.000128260202
Iter: 1925 loss: 0.000128260523
Iter: 1926 loss: 0.00012826
Iter: 1927 loss: 0.000128259635
Iter: 1928 loss: 0.000128260566
Iter: 1929 loss: 0.00012825962
Iter: 1930 loss: 0.000128259097
Iter: 1931 loss: 0.000128260232
Iter: 1932 loss: 0.000128258893
Iter: 1933 loss: 0.000128258776
Iter: 1934 loss: 0.000128259373
Iter: 1935 loss: 0.000128258675
Iter: 1936 loss: 0.0001282585
Iter: 1937 loss: 0.000128259358
Iter: 1938 loss: 0.000128258325
Iter: 1939 loss: 0.000128258063
Iter: 1940 loss: 0.000128259533
Iter: 1941 loss: 0.000128258107
Iter: 1942 loss: 0.000128257758
Iter: 1943 loss: 0.000128258936
Iter: 1944 loss: 0.00012825767
Iter: 1945 loss: 0.000128257423
Iter: 1946 loss: 0.000128258704
Iter: 1947 loss: 0.000128257467
Iter: 1948 loss: 0.000128257365
Iter: 1949 loss: 0.000128257991
Iter: 1950 loss: 0.00012825735
Iter: 1951 loss: 0.000128257074
Iter: 1952 loss: 0.000128256856
Iter: 1953 loss: 0.000128256914
Iter: 1954 loss: 0.000128256681
Iter: 1955 loss: 0.000128257
Iter: 1956 loss: 0.000128256535
Iter: 1957 loss: 0.000128256186
Iter: 1958 loss: 0.000128256652
Iter: 1959 loss: 0.00012825607
Iter: 1960 loss: 0.000128255837
Iter: 1961 loss: 0.000128257088
Iter: 1962 loss: 0.000128255837
Iter: 1963 loss: 0.000128255517
Iter: 1964 loss: 0.000128256535
Iter: 1965 loss: 0.000128255284
Iter: 1966 loss: 0.000128255066
Iter: 1967 loss: 0.000128255604
Iter: 1968 loss: 0.000128254935
Iter: 1969 loss: 0.000128254615
Iter: 1970 loss: 0.000128255619
Iter: 1971 loss: 0.000128254615
Iter: 1972 loss: 0.000128254353
Iter: 1973 loss: 0.000128255546
Iter: 1974 loss: 0.000128254265
Iter: 1975 loss: 0.000128254091
Iter: 1976 loss: 0.000128255415
Iter: 1977 loss: 0.000128254207
Iter: 1978 loss: 0.00012825396
Iter: 1979 loss: 0.000128254833
Iter: 1980 loss: 0.000128253974
Iter: 1981 loss: 0.000128253669
Iter: 1982 loss: 0.000128254716
Iter: 1983 loss: 0.000128253829
Iter: 1984 loss: 0.000128253465
Iter: 1985 loss: 0.000128253494
Iter: 1986 loss: 0.000128253407
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2
+ date
Tue Oct 27 15:40:38 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fabafca0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fabafccfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fabafcfbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fabafcfb048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab881eeb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab8820f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab881747b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab88174ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab88192378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab8814aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab8810aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab880b1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab880b1e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab880d76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab880d7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab88043510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab88043400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab88053c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab88043840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab7021cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab7021cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab701ea378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab701a1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab701a1488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab701af0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab701af620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab70135510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab700dd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab700dd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab7008e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab700c3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab700c3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab70060a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab7000b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab70039510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab700396a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0478937849
Iter: 2 loss: 5221.41162
Iter: 3 loss: 0.04789377
Iter: 4 loss: 1011.14435
Iter: 5 loss: 0.0478937402
Iter: 6 loss: 7446.9585
Iter: 7 loss: 0.0478937179
Iter: 8 loss: 0.0400942229
Iter: 9 loss: 1309.60913
Iter: 10 loss: 0.0400940403
Iter: 11 loss: 2806.56543
Iter: 12 loss: 0.0808582455
Iter: 13 loss: 0.0394437686
Iter: 14 loss: 0.0354208499
Iter: 15 loss: 0.0354773253
Iter: 16 loss: 0.0313589
Iter: 17 loss: 8267.83691
Iter: 18 loss: 0.0313589
Iter: 19 loss: 0.0726825073
Iter: 20 loss: 0.0296537541
Iter: 21 loss: 0.0243018307
Iter: 22 loss: 0.0237057563
Iter: 23 loss: 0.0201928131
Iter: 24 loss: 0.0200949423
Iter: 25 loss: 0.018738376
Iter: 26 loss: 0.0231083445
Iter: 27 loss: 0.0187269207
Iter: 28 loss: 0.0179123525
Iter: 29 loss: 0.0227460451
Iter: 30 loss: 0.0177325383
Iter: 31 loss: 0.0164502859
Iter: 32 loss: 0.0231440533
Iter: 33 loss: 0.0160957389
Iter: 34 loss: 0.014691974
Iter: 35 loss: 0.0490583405
Iter: 36 loss: 0.0146556711
Iter: 37 loss: 0.0134898936
Iter: 38 loss: 0.0239350609
Iter: 39 loss: 0.0134337246
Iter: 40 loss: 0.0126239099
Iter: 41 loss: 0.0126500288
Iter: 42 loss: 0.0119236186
Iter: 43 loss: 0.0108693484
Iter: 44 loss: 0.0232296884
Iter: 45 loss: 0.0107639879
Iter: 46 loss: 0.00977412052
Iter: 47 loss: 0.0171200186
Iter: 48 loss: 0.00961765
Iter: 49 loss: 0.00874237
Iter: 50 loss: 0.0141223483
Iter: 51 loss: 0.00863214489
Iter: 52 loss: 0.0080551682
Iter: 53 loss: 0.0151112908
Iter: 54 loss: 0.00801677443
Iter: 55 loss: 0.00766064646
Iter: 56 loss: 0.0097371256
Iter: 57 loss: 0.00762832491
Iter: 58 loss: 0.00730620325
Iter: 59 loss: 0.0116208075
Iter: 60 loss: 0.007283099
Iter: 61 loss: 0.00706683565
Iter: 62 loss: 0.00772134587
Iter: 63 loss: 0.00700994115
Iter: 64 loss: 0.00672320789
Iter: 65 loss: 0.00768662849
Iter: 66 loss: 0.00662548142
Iter: 67 loss: 0.0063021658
Iter: 68 loss: 0.00629201066
Iter: 69 loss: 0.00607117265
Iter: 70 loss: 0.00670514535
Iter: 71 loss: 0.00598805957
Iter: 72 loss: 0.00581716839
Iter: 73 loss: 0.00584496558
Iter: 74 loss: 0.00569198653
Iter: 75 loss: 0.0054155
Iter: 76 loss: 0.00713353511
Iter: 77 loss: 0.00536509277
Iter: 78 loss: 0.00512775872
Iter: 79 loss: 0.00681345258
Iter: 80 loss: 0.00510567706
Iter: 81 loss: 0.00488835759
Iter: 82 loss: 0.00541161466
Iter: 83 loss: 0.00479997322
Iter: 84 loss: 0.00459464965
Iter: 85 loss: 0.00639044773
Iter: 86 loss: 0.00458458206
Iter: 87 loss: 0.00443176227
Iter: 88 loss: 0.00577529799
Iter: 89 loss: 0.00441598333
Iter: 90 loss: 0.00426263735
Iter: 91 loss: 0.005063802
Iter: 92 loss: 0.00424096454
Iter: 93 loss: 0.00410305057
Iter: 94 loss: 0.00444165152
Iter: 95 loss: 0.00404405175
Iter: 96 loss: 0.00391856814
Iter: 97 loss: 0.00384355453
Iter: 98 loss: 0.00379047217
Iter: 99 loss: 0.00360030634
Iter: 100 loss: 0.00445389701
Iter: 101 loss: 0.00356464577
Iter: 102 loss: 0.00341349095
Iter: 103 loss: 0.00440187054
Iter: 104 loss: 0.00339146191
Iter: 105 loss: 0.00328457542
Iter: 106 loss: 0.00399380783
Iter: 107 loss: 0.0032765884
Iter: 108 loss: 0.00318557257
Iter: 109 loss: 0.00346173369
Iter: 110 loss: 0.00315329107
Iter: 111 loss: 0.00309712859
Iter: 112 loss: 0.00310621061
Iter: 113 loss: 0.00305555668
Iter: 114 loss: 0.00295484392
Iter: 115 loss: 0.00311684632
Iter: 116 loss: 0.00290761329
Iter: 117 loss: 0.00280809123
Iter: 118 loss: 0.0032864965
Iter: 119 loss: 0.00279001473
Iter: 120 loss: 0.00269686244
Iter: 121 loss: 0.00281568896
Iter: 122 loss: 0.00264596962
Iter: 123 loss: 0.00258685555
Iter: 124 loss: 0.00258521968
Iter: 125 loss: 0.00253032194
Iter: 126 loss: 0.00273350533
Iter: 127 loss: 0.00251534884
Iter: 128 loss: 0.00246483064
Iter: 129 loss: 0.00247123837
Iter: 130 loss: 0.00242719776
Iter: 131 loss: 0.00236823433
Iter: 132 loss: 0.00244334107
Iter: 133 loss: 0.00233603967
Iter: 134 loss: 0.00227652467
Iter: 135 loss: 0.00239070226
Iter: 136 loss: 0.0022518374
Iter: 137 loss: 0.00219660741
Iter: 138 loss: 0.00232020905
Iter: 139 loss: 0.00217514765
Iter: 140 loss: 0.00215669395
Iter: 141 loss: 0.00214181421
Iter: 142 loss: 0.00212047109
Iter: 143 loss: 0.00209503295
Iter: 144 loss: 0.00209220522
Iter: 145 loss: 0.0020478447
Iter: 146 loss: 0.00205842871
Iter: 147 loss: 0.00201530359
Iter: 148 loss: 0.00195954
Iter: 149 loss: 0.0020883726
Iter: 150 loss: 0.00193811231
Iter: 151 loss: 0.00189232314
Iter: 152 loss: 0.00228648074
Iter: 153 loss: 0.0018897478
Iter: 154 loss: 0.00185349199
Iter: 155 loss: 0.00189298647
Iter: 156 loss: 0.00183264818
Iter: 157 loss: 0.00180199405
Iter: 158 loss: 0.00180174212
Iter: 159 loss: 0.00178679975
Iter: 160 loss: 0.00175355689
Iter: 161 loss: 0.00223971042
Iter: 162 loss: 0.00175189623
Iter: 163 loss: 0.00171008869
Iter: 164 loss: 0.00229232153
Iter: 165 loss: 0.00171006878
Iter: 166 loss: 0.00166898
Iter: 167 loss: 0.00203326112
Iter: 168 loss: 0.00166583399
Iter: 169 loss: 0.00163939502
Iter: 170 loss: 0.00161610497
Iter: 171 loss: 0.00160904054
Iter: 172 loss: 0.00157230312
Iter: 173 loss: 0.00205795281
Iter: 174 loss: 0.00157180475
Iter: 175 loss: 0.0015473183
Iter: 176 loss: 0.00187222182
Iter: 177 loss: 0.00154730072
Iter: 178 loss: 0.00152900279
Iter: 179 loss: 0.00151012896
Iter: 180 loss: 0.00150656048
Iter: 181 loss: 0.00148858631
Iter: 182 loss: 0.00147291471
Iter: 183 loss: 0.00146808941
Iter: 184 loss: 0.0014399261
Iter: 185 loss: 0.00151155307
Iter: 186 loss: 0.00142989354
Iter: 187 loss: 0.0014056341
Iter: 188 loss: 0.00167500949
Iter: 189 loss: 0.00140528893
Iter: 190 loss: 0.00139067764
Iter: 191 loss: 0.00151230628
Iter: 192 loss: 0.00138954562
Iter: 193 loss: 0.0013735
Iter: 194 loss: 0.00135369401
Iter: 195 loss: 0.00135192112
Iter: 196 loss: 0.00132700987
Iter: 197 loss: 0.00139217661
Iter: 198 loss: 0.00131867221
Iter: 199 loss: 0.00129894633
Iter: 200 loss: 0.00131082907
Iter: 201 loss: 0.00128595834
Iter: 202 loss: 0.00125537417
Iter: 203 loss: 0.00149098551
Iter: 204 loss: 0.0012529064
Iter: 205 loss: 0.00123160332
Iter: 206 loss: 0.00127111981
Iter: 207 loss: 0.00122269639
Iter: 208 loss: 0.001208812
Iter: 209 loss: 0.0012077851
Iter: 210 loss: 0.00119398988
Iter: 211 loss: 0.00119996595
Iter: 212 loss: 0.0011845727
Iter: 213 loss: 0.00117100927
Iter: 214 loss: 0.0011550216
Iter: 215 loss: 0.00115335186
Iter: 216 loss: 0.00112989009
Iter: 217 loss: 0.00116488663
Iter: 218 loss: 0.00111837883
Iter: 219 loss: 0.0010955492
Iter: 220 loss: 0.00130847236
Iter: 221 loss: 0.00109440181
Iter: 222 loss: 0.00107756979
Iter: 223 loss: 0.00120994565
Iter: 224 loss: 0.00107652228
Iter: 225 loss: 0.00105883449
Iter: 226 loss: 0.00113448198
Iter: 227 loss: 0.00105486717
Iter: 228 loss: 0.00104635383
Iter: 229 loss: 0.00104103226
Iter: 230 loss: 0.00103765307
Iter: 231 loss: 0.00102097378
Iter: 232 loss: 0.00102202105
Iter: 233 loss: 0.00100800919
Iter: 234 loss: 0.000987743726
Iter: 235 loss: 0.00100450334
Iter: 236 loss: 0.000975409232
Iter: 237 loss: 0.000965653453
Iter: 238 loss: 0.000963174389
Iter: 239 loss: 0.000952423085
Iter: 240 loss: 0.000992485206
Iter: 241 loss: 0.000949599
Iter: 242 loss: 0.000942196813
Iter: 243 loss: 0.00103548844
Iter: 244 loss: 0.00094216672
Iter: 245 loss: 0.000938142766
Iter: 246 loss: 0.000930995448
Iter: 247 loss: 0.000930994865
Iter: 248 loss: 0.000919221435
Iter: 249 loss: 0.000921457249
Iter: 250 loss: 0.00091032387
Iter: 251 loss: 0.000898427214
Iter: 252 loss: 0.000913731579
Iter: 253 loss: 0.000892261858
Iter: 254 loss: 0.000878867402
Iter: 255 loss: 0.000951443391
Iter: 256 loss: 0.000876868609
Iter: 257 loss: 0.000866364338
Iter: 258 loss: 0.000900208717
Iter: 259 loss: 0.00086331612
Iter: 260 loss: 0.000855540042
Iter: 261 loss: 0.000855367631
Iter: 262 loss: 0.000849703676
Iter: 263 loss: 0.000840744586
Iter: 264 loss: 0.000840636611
Iter: 265 loss: 0.000831660116
Iter: 266 loss: 0.000832636259
Iter: 267 loss: 0.000824735034
Iter: 268 loss: 0.000812440587
Iter: 269 loss: 0.000854484388
Iter: 270 loss: 0.000809101737
Iter: 271 loss: 0.000796315202
Iter: 272 loss: 0.000823887938
Iter: 273 loss: 0.000791349798
Iter: 274 loss: 0.00077796675
Iter: 275 loss: 0.00083085947
Iter: 276 loss: 0.000774909626
Iter: 277 loss: 0.000770585029
Iter: 278 loss: 0.000768280355
Iter: 279 loss: 0.000763425
Iter: 280 loss: 0.0007631029
Iter: 281 loss: 0.0007594786
Iter: 282 loss: 0.000752255
Iter: 283 loss: 0.000739617506
Iter: 284 loss: 0.000739614246
Iter: 285 loss: 0.000727270904
Iter: 286 loss: 0.000737976108
Iter: 287 loss: 0.00072001724
Iter: 288 loss: 0.000706920924
Iter: 289 loss: 0.000762361509
Iter: 290 loss: 0.000704076898
Iter: 291 loss: 0.000696689123
Iter: 292 loss: 0.000696685398
Iter: 293 loss: 0.0006901
Iter: 294 loss: 0.000748461811
Iter: 295 loss: 0.00068982644
Iter: 296 loss: 0.000686803949
Iter: 297 loss: 0.000681803445
Iter: 298 loss: 0.000681779813
Iter: 299 loss: 0.000677222095
Iter: 300 loss: 0.000673682312
Iter: 301 loss: 0.000672265422
Iter: 302 loss: 0.000667727203
Iter: 303 loss: 0.000667487271
Iter: 304 loss: 0.000663984683
Iter: 305 loss: 0.000659819
Iter: 306 loss: 0.000655487413
Iter: 307 loss: 0.000654723844
Iter: 308 loss: 0.000648893125
Iter: 309 loss: 0.000689004315
Iter: 310 loss: 0.000648329093
Iter: 311 loss: 0.00064346788
Iter: 312 loss: 0.00065284688
Iter: 313 loss: 0.00064139755
Iter: 314 loss: 0.000635637087
Iter: 315 loss: 0.000662911334
Iter: 316 loss: 0.000634596217
Iter: 317 loss: 0.000628298381
Iter: 318 loss: 0.000642278814
Iter: 319 loss: 0.00062582636
Iter: 320 loss: 0.000621509738
Iter: 321 loss: 0.000614154851
Iter: 322 loss: 0.00061414612
Iter: 323 loss: 0.000606576097
Iter: 324 loss: 0.000671903137
Iter: 325 loss: 0.000606146525
Iter: 326 loss: 0.000600770116
Iter: 327 loss: 0.000614740537
Iter: 328 loss: 0.000598875456
Iter: 329 loss: 0.000595016405
Iter: 330 loss: 0.000594944926
Iter: 331 loss: 0.000592497876
Iter: 332 loss: 0.000589783187
Iter: 333 loss: 0.000589393545
Iter: 334 loss: 0.000583638786
Iter: 335 loss: 0.000599107472
Iter: 336 loss: 0.00058175216
Iter: 337 loss: 0.000577845669
Iter: 338 loss: 0.000577845145
Iter: 339 loss: 0.000574362581
Iter: 340 loss: 0.000572992139
Iter: 341 loss: 0.000571118318
Iter: 342 loss: 0.000566862815
Iter: 343 loss: 0.000566203147
Iter: 344 loss: 0.000563271227
Iter: 345 loss: 0.000557860185
Iter: 346 loss: 0.000616344565
Iter: 347 loss: 0.000557737891
Iter: 348 loss: 0.00055413309
Iter: 349 loss: 0.000562480767
Iter: 350 loss: 0.00055280386
Iter: 351 loss: 0.000548416283
Iter: 352 loss: 0.000562175468
Iter: 353 loss: 0.00054712093
Iter: 354 loss: 0.000544208684
Iter: 355 loss: 0.000540305744
Iter: 356 loss: 0.00054009
Iter: 357 loss: 0.000533689163
Iter: 358 loss: 0.000564007
Iter: 359 loss: 0.000532532635
Iter: 360 loss: 0.000530080055
Iter: 361 loss: 0.000529729412
Iter: 362 loss: 0.000526684
Iter: 363 loss: 0.000526306278
Iter: 364 loss: 0.000524146075
Iter: 365 loss: 0.000520743488
Iter: 366 loss: 0.000518138637
Iter: 367 loss: 0.000517042
Iter: 368 loss: 0.000513379
Iter: 369 loss: 0.000562065281
Iter: 370 loss: 0.000513365434
Iter: 371 loss: 0.000509741891
Iter: 372 loss: 0.000517257256
Iter: 373 loss: 0.000508258876
Iter: 374 loss: 0.000504861877
Iter: 375 loss: 0.00050213089
Iter: 376 loss: 0.000501101662
Iter: 377 loss: 0.000496914552
Iter: 378 loss: 0.00050973281
Iter: 379 loss: 0.000495687476
Iter: 380 loss: 0.000490852515
Iter: 381 loss: 0.000510292593
Iter: 382 loss: 0.00048977806
Iter: 383 loss: 0.000486766919
Iter: 384 loss: 0.000518325192
Iter: 385 loss: 0.00048669448
Iter: 386 loss: 0.000484176213
Iter: 387 loss: 0.000481286668
Iter: 388 loss: 0.000480927556
Iter: 389 loss: 0.000476742716
Iter: 390 loss: 0.000490098493
Iter: 391 loss: 0.000475518696
Iter: 392 loss: 0.000471272186
Iter: 393 loss: 0.000474918401
Iter: 394 loss: 0.000468776445
Iter: 395 loss: 0.000473019783
Iter: 396 loss: 0.000467714213
Iter: 397 loss: 0.000466608471
Iter: 398 loss: 0.000465204444
Iter: 399 loss: 0.000465099787
Iter: 400 loss: 0.000461691961
Iter: 401 loss: 0.000469723396
Iter: 402 loss: 0.000460442505
Iter: 403 loss: 0.000464620185
Iter: 404 loss: 0.000458654249
Iter: 405 loss: 0.000457717717
Iter: 406 loss: 0.000455245143
Iter: 407 loss: 0.000473786873
Iter: 408 loss: 0.000454729481
Iter: 409 loss: 0.000451690285
Iter: 410 loss: 0.000459704665
Iter: 411 loss: 0.000450660445
Iter: 412 loss: 0.000447829952
Iter: 413 loss: 0.000459392613
Iter: 414 loss: 0.00044719677
Iter: 415 loss: 0.000444505626
Iter: 416 loss: 0.000460312818
Iter: 417 loss: 0.000444137026
Iter: 418 loss: 0.000441400742
Iter: 419 loss: 0.000446038699
Iter: 420 loss: 0.000440180389
Iter: 421 loss: 0.000437412644
Iter: 422 loss: 0.000444317557
Iter: 423 loss: 0.000436438189
Iter: 424 loss: 0.000433402485
Iter: 425 loss: 0.000438313175
Iter: 426 loss: 0.000432001631
Iter: 427 loss: 0.000429886044
Iter: 428 loss: 0.00045818428
Iter: 429 loss: 0.000429880456
Iter: 430 loss: 0.000427013059
Iter: 431 loss: 0.000433018169
Iter: 432 loss: 0.000425840874
Iter: 433 loss: 0.000424495054
Iter: 434 loss: 0.000423726218
Iter: 435 loss: 0.000423148071
Iter: 436 loss: 0.000420887198
Iter: 437 loss: 0.000427820429
Iter: 438 loss: 0.000420206867
Iter: 439 loss: 0.000418065203
Iter: 440 loss: 0.000415949908
Iter: 441 loss: 0.000415501767
Iter: 442 loss: 0.000412363326
Iter: 443 loss: 0.000412659603
Iter: 444 loss: 0.000409915869
Iter: 445 loss: 0.00040595734
Iter: 446 loss: 0.000409565982
Iter: 447 loss: 0.000403671671
Iter: 448 loss: 0.000400123623
Iter: 449 loss: 0.000430826854
Iter: 450 loss: 0.000399931218
Iter: 451 loss: 0.000397150114
Iter: 452 loss: 0.000396993331
Iter: 453 loss: 0.000394874049
Iter: 454 loss: 0.000392153859
Iter: 455 loss: 0.000392081798
Iter: 456 loss: 0.000390246627
Iter: 457 loss: 0.000387873792
Iter: 458 loss: 0.000387712324
Iter: 459 loss: 0.000385208
Iter: 460 loss: 0.00039723597
Iter: 461 loss: 0.000384736748
Iter: 462 loss: 0.000382927916
Iter: 463 loss: 0.000382908329
Iter: 464 loss: 0.000381721708
Iter: 465 loss: 0.000382209371
Iter: 466 loss: 0.000380897895
Iter: 467 loss: 0.000379813107
Iter: 468 loss: 0.000379173871
Iter: 469 loss: 0.000378723518
Iter: 470 loss: 0.000376812
Iter: 471 loss: 0.000377491524
Iter: 472 loss: 0.000375465665
Iter: 473 loss: 0.00037301259
Iter: 474 loss: 0.000375498639
Iter: 475 loss: 0.000371632981
Iter: 476 loss: 0.0003684283
Iter: 477 loss: 0.000380226527
Iter: 478 loss: 0.000367618981
Iter: 479 loss: 0.000364734093
Iter: 480 loss: 0.000369519868
Iter: 481 loss: 0.000363431842
Iter: 482 loss: 0.000360500067
Iter: 483 loss: 0.000383670122
Iter: 484 loss: 0.000360293721
Iter: 485 loss: 0.000357696554
Iter: 486 loss: 0.000362074061
Iter: 487 loss: 0.000356516452
Iter: 488 loss: 0.000354308984
Iter: 489 loss: 0.000354296644
Iter: 490 loss: 0.00035288895
Iter: 491 loss: 0.000355269352
Iter: 492 loss: 0.000352262956
Iter: 493 loss: 0.000351190974
Iter: 494 loss: 0.000367384084
Iter: 495 loss: 0.000351188879
Iter: 496 loss: 0.000350523129
Iter: 497 loss: 0.000349887589
Iter: 498 loss: 0.00034973945
Iter: 499 loss: 0.000348438451
Iter: 500 loss: 0.000349520793
Iter: 501 loss: 0.000347661087
Iter: 502 loss: 0.000345936132
Iter: 503 loss: 0.000347972556
Iter: 504 loss: 0.000345021428
Iter: 505 loss: 0.000342880579
Iter: 506 loss: 0.000343517895
Iter: 507 loss: 0.000341337756
Iter: 508 loss: 0.000339215738
Iter: 509 loss: 0.00035057668
Iter: 510 loss: 0.000338897924
Iter: 511 loss: 0.000336673285
Iter: 512 loss: 0.000338731188
Iter: 513 loss: 0.000335379154
Iter: 514 loss: 0.000332938536
Iter: 515 loss: 0.000340622675
Iter: 516 loss: 0.000332223077
Iter: 517 loss: 0.00032978761
Iter: 518 loss: 0.000344858767
Iter: 519 loss: 0.000329488568
Iter: 520 loss: 0.000327860966
Iter: 521 loss: 0.000339390477
Iter: 522 loss: 0.000327720307
Iter: 523 loss: 0.000326709676
Iter: 524 loss: 0.000336628756
Iter: 525 loss: 0.000326671434
Iter: 526 loss: 0.000326028327
Iter: 527 loss: 0.000329976698
Iter: 528 loss: 0.000325954927
Iter: 529 loss: 0.000325262459
Iter: 530 loss: 0.000324629131
Iter: 531 loss: 0.000324458553
Iter: 532 loss: 0.000323399407
Iter: 533 loss: 0.000324902503
Iter: 534 loss: 0.000322878768
Iter: 535 loss: 0.000321651576
Iter: 536 loss: 0.000323205313
Iter: 537 loss: 0.000321017927
Iter: 538 loss: 0.000319651968
Iter: 539 loss: 0.000320508552
Iter: 540 loss: 0.000318778824
Iter: 541 loss: 0.000317187427
Iter: 542 loss: 0.000322347565
Iter: 543 loss: 0.000316732621
Iter: 544 loss: 0.000314958859
Iter: 545 loss: 0.000317696511
Iter: 546 loss: 0.000314122124
Iter: 547 loss: 0.000312228658
Iter: 548 loss: 0.00031460062
Iter: 549 loss: 0.000311242795
Iter: 550 loss: 0.000309236406
Iter: 551 loss: 0.000334658835
Iter: 552 loss: 0.000309216935
Iter: 553 loss: 0.000307874463
Iter: 554 loss: 0.000312729593
Iter: 555 loss: 0.000307526789
Iter: 556 loss: 0.000306325324
Iter: 557 loss: 0.000317836937
Iter: 558 loss: 0.000306283298
Iter: 559 loss: 0.000305448077
Iter: 560 loss: 0.000310839474
Iter: 561 loss: 0.000305349065
Iter: 562 loss: 0.000304585381
Iter: 563 loss: 0.000304497138
Iter: 564 loss: 0.000303947425
Iter: 565 loss: 0.000302992819
Iter: 566 loss: 0.000303882145
Iter: 567 loss: 0.00030244168
Iter: 568 loss: 0.00030126411
Iter: 569 loss: 0.000304011
Iter: 570 loss: 0.000300831685
Iter: 571 loss: 0.000299605541
Iter: 572 loss: 0.000300158077
Iter: 573 loss: 0.000298770668
Iter: 574 loss: 0.000297382881
Iter: 575 loss: 0.000297423685
Iter: 576 loss: 0.000296287209
Iter: 577 loss: 0.000294241472
Iter: 578 loss: 0.000308055722
Iter: 579 loss: 0.000294029946
Iter: 580 loss: 0.000292485754
Iter: 581 loss: 0.000292365905
Iter: 582 loss: 0.000291212869
Iter: 583 loss: 0.000289251155
Iter: 584 loss: 0.000311065814
Iter: 585 loss: 0.000289210642
Iter: 586 loss: 0.000287848408
Iter: 587 loss: 0.000291735283
Iter: 588 loss: 0.000287420233
Iter: 589 loss: 0.000286156661
Iter: 590 loss: 0.000295826059
Iter: 591 loss: 0.000286056951
Iter: 592 loss: 0.000285270944
Iter: 593 loss: 0.000293021381
Iter: 594 loss: 0.000285248592
Iter: 595 loss: 0.000284618262
Iter: 596 loss: 0.000284491834
Iter: 597 loss: 0.000284072245
Iter: 598 loss: 0.000283332629
Iter: 599 loss: 0.000283095171
Iter: 600 loss: 0.000282663852
Iter: 601 loss: 0.000281608838
Iter: 602 loss: 0.000285365095
Iter: 603 loss: 0.000281333225
Iter: 604 loss: 0.000280431734
Iter: 605 loss: 0.000280972105
Iter: 606 loss: 0.000279849395
Iter: 607 loss: 0.000278692663
Iter: 608 loss: 0.000280124397
Iter: 609 loss: 0.000278086052
Iter: 610 loss: 0.000276786857
Iter: 611 loss: 0.000284612441
Iter: 612 loss: 0.000276628241
Iter: 613 loss: 0.000275531842
Iter: 614 loss: 0.000274801831
Iter: 615 loss: 0.000274387072
Iter: 616 loss: 0.000273090729
Iter: 617 loss: 0.00029131255
Iter: 618 loss: 0.00027308779
Iter: 619 loss: 0.000271976198
Iter: 620 loss: 0.000273466751
Iter: 621 loss: 0.000271412457
Iter: 622 loss: 0.0002704215
Iter: 623 loss: 0.000285303046
Iter: 624 loss: 0.000270421442
Iter: 625 loss: 0.000269914221
Iter: 626 loss: 0.000276214385
Iter: 627 loss: 0.000269908516
Iter: 628 loss: 0.000269470853
Iter: 629 loss: 0.000269229116
Iter: 630 loss: 0.000269037
Iter: 631 loss: 0.000268347096
Iter: 632 loss: 0.000268590346
Iter: 633 loss: 0.000267859432
Iter: 634 loss: 0.000267062744
Iter: 635 loss: 0.000270043791
Iter: 636 loss: 0.000266871299
Iter: 637 loss: 0.00026612432
Iter: 638 loss: 0.000265801849
Iter: 639 loss: 0.000265416456
Iter: 640 loss: 0.000264350791
Iter: 641 loss: 0.00026644551
Iter: 642 loss: 0.000263913709
Iter: 643 loss: 0.000262808433
Iter: 644 loss: 0.000266745075
Iter: 645 loss: 0.000262523536
Iter: 646 loss: 0.000261360547
Iter: 647 loss: 0.000261511159
Iter: 648 loss: 0.000260474742
Iter: 649 loss: 0.000259353459
Iter: 650 loss: 0.000270120683
Iter: 651 loss: 0.000259309512
Iter: 652 loss: 0.000258162123
Iter: 653 loss: 0.000259562948
Iter: 654 loss: 0.000257565
Iter: 655 loss: 0.000256828
Iter: 656 loss: 0.000256770873
Iter: 657 loss: 0.000256342872
Iter: 658 loss: 0.000259931927
Iter: 659 loss: 0.000256319647
Iter: 660 loss: 0.000255915453
Iter: 661 loss: 0.000255601713
Iter: 662 loss: 0.000255473598
Iter: 663 loss: 0.000254856539
Iter: 664 loss: 0.000254869781
Iter: 665 loss: 0.000254367769
Iter: 666 loss: 0.000253598671
Iter: 667 loss: 0.000256073254
Iter: 668 loss: 0.000253376929
Iter: 669 loss: 0.000252563623
Iter: 670 loss: 0.000252872967
Iter: 671 loss: 0.000251997553
Iter: 672 loss: 0.000250952435
Iter: 673 loss: 0.000253465318
Iter: 674 loss: 0.000250572
Iter: 675 loss: 0.000249543984
Iter: 676 loss: 0.000254058366
Iter: 677 loss: 0.000249338307
Iter: 678 loss: 0.000248300319
Iter: 679 loss: 0.000249167031
Iter: 680 loss: 0.000247680902
Iter: 681 loss: 0.00024666806
Iter: 682 loss: 0.000249673059
Iter: 683 loss: 0.000246359443
Iter: 684 loss: 0.000245154602
Iter: 685 loss: 0.00025206618
Iter: 686 loss: 0.000244987168
Iter: 687 loss: 0.00024440288
Iter: 688 loss: 0.00024440253
Iter: 689 loss: 0.000244021328
Iter: 690 loss: 0.000246531214
Iter: 691 loss: 0.00024397987
Iter: 692 loss: 0.000243576564
Iter: 693 loss: 0.00024364503
Iter: 694 loss: 0.000243275761
Iter: 695 loss: 0.000242787908
Iter: 696 loss: 0.000243035523
Iter: 697 loss: 0.000242462294
Iter: 698 loss: 0.000241889633
Iter: 699 loss: 0.000243198301
Iter: 700 loss: 0.000241677655
Iter: 701 loss: 0.000241021655
Iter: 702 loss: 0.000240857451
Iter: 703 loss: 0.000240442765
Iter: 704 loss: 0.000239578687
Iter: 705 loss: 0.000241603033
Iter: 706 loss: 0.000239263652
Iter: 707 loss: 0.000238486566
Iter: 708 loss: 0.000240657915
Iter: 709 loss: 0.000238235691
Iter: 710 loss: 0.000237333821
Iter: 711 loss: 0.000238658889
Iter: 712 loss: 0.000236896944
Iter: 713 loss: 0.000236048043
Iter: 714 loss: 0.000237723812
Iter: 715 loss: 0.000235697546
Iter: 716 loss: 0.000234791805
Iter: 717 loss: 0.000243393297
Iter: 718 loss: 0.000234757987
Iter: 719 loss: 0.000234245977
Iter: 720 loss: 0.00023964257
Iter: 721 loss: 0.000234231571
Iter: 722 loss: 0.000233875
Iter: 723 loss: 0.000237373257
Iter: 724 loss: 0.000233863815
Iter: 725 loss: 0.000233553772
Iter: 726 loss: 0.000233670376
Iter: 727 loss: 0.000233335784
Iter: 728 loss: 0.00023298696
Iter: 729 loss: 0.000232766557
Iter: 730 loss: 0.000232629347
Iter: 731 loss: 0.000232091174
Iter: 732 loss: 0.000233721701
Iter: 733 loss: 0.00023192825
Iter: 734 loss: 0.000231373691
Iter: 735 loss: 0.000231407786
Iter: 736 loss: 0.000230940554
Iter: 737 loss: 0.000230176636
Iter: 738 loss: 0.000232783932
Iter: 739 loss: 0.000229970916
Iter: 740 loss: 0.000229372294
Iter: 741 loss: 0.00023008899
Iter: 742 loss: 0.000229056895
Iter: 743 loss: 0.000228287943
Iter: 744 loss: 0.000232461985
Iter: 745 loss: 0.000228174875
Iter: 746 loss: 0.000227612531
Iter: 747 loss: 0.000227497367
Iter: 748 loss: 0.0002271267
Iter: 749 loss: 0.000226376607
Iter: 750 loss: 0.000234419029
Iter: 751 loss: 0.000226358025
Iter: 752 loss: 0.000225847311
Iter: 753 loss: 0.000229948695
Iter: 754 loss: 0.000225815107
Iter: 755 loss: 0.000225504336
Iter: 756 loss: 0.00022977512
Iter: 757 loss: 0.000225502969
Iter: 758 loss: 0.000225241791
Iter: 759 loss: 0.000225375377
Iter: 760 loss: 0.000225069656
Iter: 761 loss: 0.000224743737
Iter: 762 loss: 0.000224360847
Iter: 763 loss: 0.000224318035
Iter: 764 loss: 0.000223768788
Iter: 765 loss: 0.000226306147
Iter: 766 loss: 0.000223666604
Iter: 767 loss: 0.000223113471
Iter: 768 loss: 0.000222825809
Iter: 769 loss: 0.000222571
Iter: 770 loss: 0.0002219077
Iter: 771 loss: 0.00022564111
Iter: 772 loss: 0.000221815251
Iter: 773 loss: 0.000221304232
Iter: 774 loss: 0.000221063063
Iter: 775 loss: 0.000220812901
Iter: 776 loss: 0.000220081129
Iter: 777 loss: 0.000226782038
Iter: 778 loss: 0.000220048969
Iter: 779 loss: 0.0002195087
Iter: 780 loss: 0.000219566355
Iter: 781 loss: 0.000219093
Iter: 782 loss: 0.000218356479
Iter: 783 loss: 0.000221124355
Iter: 784 loss: 0.000218180532
Iter: 785 loss: 0.000217610635
Iter: 786 loss: 0.000223445124
Iter: 787 loss: 0.000217592722
Iter: 788 loss: 0.000217263296
Iter: 789 loss: 0.000221660623
Iter: 790 loss: 0.000217262015
Iter: 791 loss: 0.000216984612
Iter: 792 loss: 0.000217029039
Iter: 793 loss: 0.000216774235
Iter: 794 loss: 0.000216424669
Iter: 795 loss: 0.000216159286
Iter: 796 loss: 0.00021604597
Iter: 797 loss: 0.000215530177
Iter: 798 loss: 0.000217221
Iter: 799 loss: 0.000215385429
Iter: 800 loss: 0.000214831176
Iter: 801 loss: 0.000215083986
Iter: 802 loss: 0.000214455955
Iter: 803 loss: 0.000213907493
Iter: 804 loss: 0.000216378583
Iter: 805 loss: 0.000213800522
Iter: 806 loss: 0.000213308493
Iter: 807 loss: 0.000213207662
Iter: 808 loss: 0.000212882864
Iter: 809 loss: 0.000212143364
Iter: 810 loss: 0.000216170403
Iter: 811 loss: 0.000212033294
Iter: 812 loss: 0.000211455656
Iter: 813 loss: 0.000212498941
Iter: 814 loss: 0.000211205144
Iter: 815 loss: 0.000210466969
Iter: 816 loss: 0.000212535611
Iter: 817 loss: 0.000210229977
Iter: 818 loss: 0.000209831182
Iter: 819 loss: 0.000209825725
Iter: 820 loss: 0.000209549849
Iter: 821 loss: 0.000211787337
Iter: 822 loss: 0.000209531485
Iter: 823 loss: 0.000209257749
Iter: 824 loss: 0.000209495673
Iter: 825 loss: 0.00020909743
Iter: 826 loss: 0.000208817306
Iter: 827 loss: 0.000208824276
Iter: 828 loss: 0.000208595156
Iter: 829 loss: 0.000208253987
Iter: 830 loss: 0.000208696016
Iter: 831 loss: 0.000208079844
Iter: 832 loss: 0.000207626377
Iter: 833 loss: 0.000208196347
Iter: 834 loss: 0.000207391306
Iter: 835 loss: 0.000206973491
Iter: 836 loss: 0.000207743869
Iter: 837 loss: 0.000206794823
Iter: 838 loss: 0.000206321914
Iter: 839 loss: 0.000206836034
Iter: 840 loss: 0.000206063516
Iter: 841 loss: 0.000205464865
Iter: 842 loss: 0.000207305537
Iter: 843 loss: 0.00020528803
Iter: 844 loss: 0.000204706419
Iter: 845 loss: 0.000206350218
Iter: 846 loss: 0.000204520824
Iter: 847 loss: 0.000203894422
Iter: 848 loss: 0.000205765187
Iter: 849 loss: 0.000203704287
Iter: 850 loss: 0.000203380187
Iter: 851 loss: 0.000203378411
Iter: 852 loss: 0.000203124757
Iter: 853 loss: 0.000204857744
Iter: 854 loss: 0.000203100848
Iter: 855 loss: 0.000202839394
Iter: 856 loss: 0.00020325699
Iter: 857 loss: 0.000202716896
Iter: 858 loss: 0.000202495125
Iter: 859 loss: 0.00020240029
Iter: 860 loss: 0.000202285577
Iter: 861 loss: 0.000201955932
Iter: 862 loss: 0.000202380936
Iter: 863 loss: 0.000201786868
Iter: 864 loss: 0.000201354473
Iter: 865 loss: 0.00020247369
Iter: 866 loss: 0.000201208008
Iter: 867 loss: 0.000200870694
Iter: 868 loss: 0.000201209128
Iter: 869 loss: 0.000200681316
Iter: 870 loss: 0.000200260372
Iter: 871 loss: 0.000200687165
Iter: 872 loss: 0.000200023933
Iter: 873 loss: 0.000199505797
Iter: 874 loss: 0.000201246585
Iter: 875 loss: 0.000199364877
Iter: 876 loss: 0.000198858528
Iter: 877 loss: 0.000200149167
Iter: 878 loss: 0.000198683832
Iter: 879 loss: 0.000198163179
Iter: 880 loss: 0.000200570968
Iter: 881 loss: 0.000198064852
Iter: 882 loss: 0.000197764617
Iter: 883 loss: 0.00020044
Iter: 884 loss: 0.000197750342
Iter: 885 loss: 0.000197500951
Iter: 886 loss: 0.000199627451
Iter: 887 loss: 0.000197486253
Iter: 888 loss: 0.000197254325
Iter: 889 loss: 0.000197884452
Iter: 890 loss: 0.000197178888
Iter: 891 loss: 0.000197002068
Iter: 892 loss: 0.000196880326
Iter: 893 loss: 0.000196816283
Iter: 894 loss: 0.000196537178
Iter: 895 loss: 0.000196756533
Iter: 896 loss: 0.000196368041
Iter: 897 loss: 0.000196002889
Iter: 898 loss: 0.000197328336
Iter: 899 loss: 0.000195910558
Iter: 900 loss: 0.000195639834
Iter: 901 loss: 0.000195877728
Iter: 902 loss: 0.000195481523
Iter: 903 loss: 0.00019513462
Iter: 904 loss: 0.000195412504
Iter: 905 loss: 0.000194924985
Iter: 906 loss: 0.000194478343
Iter: 907 loss: 0.000196000576
Iter: 908 loss: 0.000194358407
Iter: 909 loss: 0.000193936197
Iter: 910 loss: 0.000194861321
Iter: 911 loss: 0.000193772939
Iter: 912 loss: 0.000193359301
Iter: 913 loss: 0.00019579276
Iter: 914 loss: 0.00019330607
Iter: 915 loss: 0.000193014013
Iter: 916 loss: 0.000194360837
Iter: 917 loss: 0.000192958774
Iter: 918 loss: 0.000192705731
Iter: 919 loss: 0.000196020177
Iter: 920 loss: 0.000192704916
Iter: 921 loss: 0.000192516425
Iter: 922 loss: 0.000193262851
Iter: 923 loss: 0.000192472653
Iter: 924 loss: 0.000192345833
Iter: 925 loss: 0.000192166903
Iter: 926 loss: 0.000192160151
Iter: 927 loss: 0.000191891188
Iter: 928 loss: 0.000191976156
Iter: 929 loss: 0.000191699131
Iter: 930 loss: 0.000191331012
Iter: 931 loss: 0.000193082698
Iter: 932 loss: 0.000191264204
Iter: 933 loss: 0.000190990686
Iter: 934 loss: 0.000191155312
Iter: 935 loss: 0.000190813211
Iter: 936 loss: 0.000190475839
Iter: 937 loss: 0.000190588675
Iter: 938 loss: 0.000190237057
Iter: 939 loss: 0.000189751547
Iter: 940 loss: 0.000191828891
Iter: 941 loss: 0.000189650542
Iter: 942 loss: 0.000189198705
Iter: 943 loss: 0.000189847255
Iter: 944 loss: 0.00018897868
Iter: 945 loss: 0.000188535909
Iter: 946 loss: 0.000192411506
Iter: 947 loss: 0.000188512655
Iter: 948 loss: 0.000188215883
Iter: 949 loss: 0.000188852573
Iter: 950 loss: 0.000188099948
Iter: 951 loss: 0.000187832105
Iter: 952 loss: 0.000187830286
Iter: 953 loss: 0.000187636266
Iter: 954 loss: 0.000188623177
Iter: 955 loss: 0.000187605707
Iter: 956 loss: 0.000187480153
Iter: 957 loss: 0.000187274316
Iter: 958 loss: 0.000187273516
Iter: 959 loss: 0.000186993755
Iter: 960 loss: 0.000187256606
Iter: 961 loss: 0.000186833495
Iter: 962 loss: 0.000186522462
Iter: 963 loss: 0.000188413222
Iter: 964 loss: 0.000186484307
Iter: 965 loss: 0.000186248508
Iter: 966 loss: 0.000186282414
Iter: 967 loss: 0.000186070683
Iter: 968 loss: 0.000185739991
Iter: 969 loss: 0.000186143792
Iter: 970 loss: 0.000185566925
Iter: 971 loss: 0.000185184152
Iter: 972 loss: 0.000186780147
Iter: 973 loss: 0.000185102515
Iter: 974 loss: 0.000184730932
Iter: 975 loss: 0.000185015175
Iter: 976 loss: 0.000184504548
Iter: 977 loss: 0.000184132688
Iter: 978 loss: 0.00018774801
Iter: 979 loss: 0.000184118966
Iter: 980 loss: 0.000183862896
Iter: 981 loss: 0.000184375065
Iter: 982 loss: 0.000183758166
Iter: 983 loss: 0.000183548269
Iter: 984 loss: 0.000183542958
Iter: 985 loss: 0.000183397176
Iter: 986 loss: 0.000184042336
Iter: 987 loss: 0.000183367491
Iter: 988 loss: 0.000183256605
Iter: 989 loss: 0.000183059397
Iter: 990 loss: 0.000187967744
Iter: 991 loss: 0.000183059077
Iter: 992 loss: 0.000182800432
Iter: 993 loss: 0.000183348195
Iter: 994 loss: 0.000182698277
Iter: 995 loss: 0.000182468371
Iter: 996 loss: 0.000183548575
Iter: 997 loss: 0.000182426273
Iter: 998 loss: 0.000182223928
Iter: 999 loss: 0.000182134419
Iter: 1000 loss: 0.000182031188
Iter: 1001 loss: 0.00018170994
Iter: 1002 loss: 0.000182069809
Iter: 1003 loss: 0.000181536365
Iter: 1004 loss: 0.000181206138
Iter: 1005 loss: 0.000182989112
Iter: 1006 loss: 0.000181156502
Iter: 1007 loss: 0.000180837786
Iter: 1008 loss: 0.000181092662
Iter: 1009 loss: 0.000180645948
Iter: 1010 loss: 0.000180340634
Iter: 1011 loss: 0.000183087017
Iter: 1012 loss: 0.000180325267
Iter: 1013 loss: 0.000180085597
Iter: 1014 loss: 0.000180518779
Iter: 1015 loss: 0.000179981638
Iter: 1016 loss: 0.000179841532
Iter: 1017 loss: 0.000179816969
Iter: 1018 loss: 0.00017969805
Iter: 1019 loss: 0.000180136951
Iter: 1020 loss: 0.000179669543
Iter: 1021 loss: 0.000179567724
Iter: 1022 loss: 0.000179367955
Iter: 1023 loss: 0.000183364333
Iter: 1024 loss: 0.000179366412
Iter: 1025 loss: 0.000179124792
Iter: 1026 loss: 0.000179638038
Iter: 1027 loss: 0.000179029506
Iter: 1028 loss: 0.000178792267
Iter: 1029 loss: 0.000179633396
Iter: 1030 loss: 0.000178730785
Iter: 1031 loss: 0.000178502509
Iter: 1032 loss: 0.000178679096
Iter: 1033 loss: 0.000178363669
Iter: 1034 loss: 0.000178062415
Iter: 1035 loss: 0.00017807493
Iter: 1036 loss: 0.000177824666
Iter: 1037 loss: 0.000177499474
Iter: 1038 loss: 0.000180157105
Iter: 1039 loss: 0.00017747932
Iter: 1040 loss: 0.000177182446
Iter: 1041 loss: 0.000177433612
Iter: 1042 loss: 0.000177007081
Iter: 1043 loss: 0.00017672102
Iter: 1044 loss: 0.000178252492
Iter: 1045 loss: 0.000176677422
Iter: 1046 loss: 0.000176392103
Iter: 1047 loss: 0.000176877526
Iter: 1048 loss: 0.000176263682
Iter: 1049 loss: 0.000176184127
Iter: 1050 loss: 0.000176116708
Iter: 1051 loss: 0.000176011526
Iter: 1052 loss: 0.000176302681
Iter: 1053 loss: 0.000175977184
Iter: 1054 loss: 0.000175865658
Iter: 1055 loss: 0.000175637266
Iter: 1056 loss: 0.000179683964
Iter: 1057 loss: 0.000175633118
Iter: 1058 loss: 0.000175374516
Iter: 1059 loss: 0.000176316418
Iter: 1060 loss: 0.000175310386
Iter: 1061 loss: 0.000175089546
Iter: 1062 loss: 0.000175886293
Iter: 1063 loss: 0.000175034074
Iter: 1064 loss: 0.000174825022
Iter: 1065 loss: 0.00017500027
Iter: 1066 loss: 0.000174700705
Iter: 1067 loss: 0.000174428438
Iter: 1068 loss: 0.00017438145
Iter: 1069 loss: 0.000174194953
Iter: 1070 loss: 0.000173870416
Iter: 1071 loss: 0.000175787223
Iter: 1072 loss: 0.000173828041
Iter: 1073 loss: 0.000173497479
Iter: 1074 loss: 0.000173931854
Iter: 1075 loss: 0.000173329099
Iter: 1076 loss: 0.000173018881
Iter: 1077 loss: 0.000174410554
Iter: 1078 loss: 0.000172958447
Iter: 1079 loss: 0.000172627086
Iter: 1080 loss: 0.000173525666
Iter: 1081 loss: 0.000172518674
Iter: 1082 loss: 0.000172410015
Iter: 1083 loss: 0.000172363332
Iter: 1084 loss: 0.000172239277
Iter: 1085 loss: 0.000172750617
Iter: 1086 loss: 0.000172212138
Iter: 1087 loss: 0.000172102082
Iter: 1088 loss: 0.000171878986
Iter: 1089 loss: 0.0001760257
Iter: 1090 loss: 0.000171875115
Iter: 1091 loss: 0.000171637279
Iter: 1092 loss: 0.000172653788
Iter: 1093 loss: 0.000171587933
Iter: 1094 loss: 0.000171398933
Iter: 1095 loss: 0.000171854976
Iter: 1096 loss: 0.000171331078
Iter: 1097 loss: 0.000171122374
Iter: 1098 loss: 0.000171238746
Iter: 1099 loss: 0.000170985571
Iter: 1100 loss: 0.000170700339
Iter: 1101 loss: 0.000170816784
Iter: 1102 loss: 0.000170503481
Iter: 1103 loss: 0.000170203421
Iter: 1104 loss: 0.000171577791
Iter: 1105 loss: 0.000170146726
Iter: 1106 loss: 0.000169828563
Iter: 1107 loss: 0.000170602289
Iter: 1108 loss: 0.000169714796
Iter: 1109 loss: 0.000169440638
Iter: 1110 loss: 0.000170037267
Iter: 1111 loss: 0.000169334235
Iter: 1112 loss: 0.000169006322
Iter: 1113 loss: 0.000170278683
Iter: 1114 loss: 0.000168929284
Iter: 1115 loss: 0.000168817467
Iter: 1116 loss: 0.000168789426
Iter: 1117 loss: 0.000168676808
Iter: 1118 loss: 0.000169040984
Iter: 1119 loss: 0.000168644125
Iter: 1120 loss: 0.000168529688
Iter: 1121 loss: 0.000168318846
Iter: 1122 loss: 0.000173191482
Iter: 1123 loss: 0.000168318555
Iter: 1124 loss: 0.000168093553
Iter: 1125 loss: 0.000168926941
Iter: 1126 loss: 0.000168038649
Iter: 1127 loss: 0.000167842431
Iter: 1128 loss: 0.000168435334
Iter: 1129 loss: 0.000167783699
Iter: 1130 loss: 0.000167581951
Iter: 1131 loss: 0.000167711201
Iter: 1132 loss: 0.00016745305
Iter: 1133 loss: 0.000167185921
Iter: 1134 loss: 0.000167502119
Iter: 1135 loss: 0.000167045218
Iter: 1136 loss: 0.000166774465
Iter: 1137 loss: 0.000167216596
Iter: 1138 loss: 0.00016665009
Iter: 1139 loss: 0.00016635668
Iter: 1140 loss: 0.000168508443
Iter: 1141 loss: 0.000166332044
Iter: 1142 loss: 0.000166108
Iter: 1143 loss: 0.000166224549
Iter: 1144 loss: 0.000165959398
Iter: 1145 loss: 0.0001656721
Iter: 1146 loss: 0.000167347171
Iter: 1147 loss: 0.00016563473
Iter: 1148 loss: 0.000165490623
Iter: 1149 loss: 0.000165486796
Iter: 1150 loss: 0.000165368023
Iter: 1151 loss: 0.000166187179
Iter: 1152 loss: 0.000165356963
Iter: 1153 loss: 0.00016526955
Iter: 1154 loss: 0.000165123769
Iter: 1155 loss: 0.000165123187
Iter: 1156 loss: 0.000164952857
Iter: 1157 loss: 0.000165061938
Iter: 1158 loss: 0.000164844736
Iter: 1159 loss: 0.000164653655
Iter: 1160 loss: 0.000165798701
Iter: 1161 loss: 0.000164629659
Iter: 1162 loss: 0.000164470955
Iter: 1163 loss: 0.000164469209
Iter: 1164 loss: 0.000164344208
Iter: 1165 loss: 0.000164111698
Iter: 1166 loss: 0.000164714147
Iter: 1167 loss: 0.000164032099
Iter: 1168 loss: 0.000163821242
Iter: 1169 loss: 0.000163757417
Iter: 1170 loss: 0.000163631979
Iter: 1171 loss: 0.000163400546
Iter: 1172 loss: 0.000166853017
Iter: 1173 loss: 0.000163400386
Iter: 1174 loss: 0.000163215562
Iter: 1175 loss: 0.000163201476
Iter: 1176 loss: 0.000163063742
Iter: 1177 loss: 0.000162820274
Iter: 1178 loss: 0.000164311554
Iter: 1179 loss: 0.000162791024
Iter: 1180 loss: 0.000162654615
Iter: 1181 loss: 0.000164674944
Iter: 1182 loss: 0.000162654935
Iter: 1183 loss: 0.000162550743
Iter: 1184 loss: 0.000163441684
Iter: 1185 loss: 0.000162544573
Iter: 1186 loss: 0.000162469965
Iter: 1187 loss: 0.000162346842
Iter: 1188 loss: 0.000162346085
Iter: 1189 loss: 0.000162189812
Iter: 1190 loss: 0.000162306722
Iter: 1191 loss: 0.000162093784
Iter: 1192 loss: 0.000161925884
Iter: 1193 loss: 0.000163160497
Iter: 1194 loss: 0.000161912438
Iter: 1195 loss: 0.000161766628
Iter: 1196 loss: 0.000161718053
Iter: 1197 loss: 0.000161633594
Iter: 1198 loss: 0.000161438773
Iter: 1199 loss: 0.000162223863
Iter: 1200 loss: 0.000161395292
Iter: 1201 loss: 0.000161212418
Iter: 1202 loss: 0.000161006086
Iter: 1203 loss: 0.000160978889
Iter: 1204 loss: 0.00016073852
Iter: 1205 loss: 0.00016405918
Iter: 1206 loss: 0.000160738069
Iter: 1207 loss: 0.00016053248
Iter: 1208 loss: 0.000160673007
Iter: 1209 loss: 0.000160403564
Iter: 1210 loss: 0.000160171941
Iter: 1211 loss: 0.000161170363
Iter: 1212 loss: 0.000160124284
Iter: 1213 loss: 0.000159965741
Iter: 1214 loss: 0.000162201381
Iter: 1215 loss: 0.00015996529
Iter: 1216 loss: 0.000159853
Iter: 1217 loss: 0.000161301476
Iter: 1218 loss: 0.000159852236
Iter: 1219 loss: 0.000159778254
Iter: 1220 loss: 0.000159648553
Iter: 1221 loss: 0.000159648625
Iter: 1222 loss: 0.00015950235
Iter: 1223 loss: 0.000159589516
Iter: 1224 loss: 0.0001594075
Iter: 1225 loss: 0.000159240095
Iter: 1226 loss: 0.000160033305
Iter: 1227 loss: 0.000159209449
Iter: 1228 loss: 0.000159036455
Iter: 1229 loss: 0.00015914152
Iter: 1230 loss: 0.000158925177
Iter: 1231 loss: 0.000158744573
Iter: 1232 loss: 0.000159463147
Iter: 1233 loss: 0.000158703275
Iter: 1234 loss: 0.000158520474
Iter: 1235 loss: 0.000158393916
Iter: 1236 loss: 0.00015832785
Iter: 1237 loss: 0.000158071678
Iter: 1238 loss: 0.000159558462
Iter: 1239 loss: 0.000158037627
Iter: 1240 loss: 0.000157809118
Iter: 1241 loss: 0.000158689887
Iter: 1242 loss: 0.000157754519
Iter: 1243 loss: 0.000157546718
Iter: 1244 loss: 0.000158471899
Iter: 1245 loss: 0.000157505245
Iter: 1246 loss: 0.000157377479
Iter: 1247 loss: 0.000158781273
Iter: 1248 loss: 0.00015737486
Iter: 1249 loss: 0.000157272952
Iter: 1250 loss: 0.000158422685
Iter: 1251 loss: 0.000157270959
Iter: 1252 loss: 0.000157193179
Iter: 1253 loss: 0.000157079427
Iter: 1254 loss: 0.000157076487
Iter: 1255 loss: 0.000156954251
Iter: 1256 loss: 0.000157062474
Iter: 1257 loss: 0.000156882656
Iter: 1258 loss: 0.00015672775
Iter: 1259 loss: 0.000157053641
Iter: 1260 loss: 0.000156666167
Iter: 1261 loss: 0.000156488095
Iter: 1262 loss: 0.000157102797
Iter: 1263 loss: 0.000156440714
Iter: 1264 loss: 0.000156312235
Iter: 1265 loss: 0.00015637734
Iter: 1266 loss: 0.000156226379
Iter: 1267 loss: 0.000156034395
Iter: 1268 loss: 0.000156252587
Iter: 1269 loss: 0.00015593064
Iter: 1270 loss: 0.000155718444
Iter: 1271 loss: 0.0001564126
Iter: 1272 loss: 0.000155658781
Iter: 1273 loss: 0.000155470378
Iter: 1274 loss: 0.000155971415
Iter: 1275 loss: 0.000155406655
Iter: 1276 loss: 0.00015521259
Iter: 1277 loss: 0.000156663271
Iter: 1278 loss: 0.000155196831
Iter: 1279 loss: 0.00015509066
Iter: 1280 loss: 0.000155703106
Iter: 1281 loss: 0.000155076428
Iter: 1282 loss: 0.000154981506
Iter: 1283 loss: 0.000156196751
Iter: 1284 loss: 0.000154980749
Iter: 1285 loss: 0.000154911046
Iter: 1286 loss: 0.000154836336
Iter: 1287 loss: 0.00015482468
Iter: 1288 loss: 0.000154732843
Iter: 1289 loss: 0.000154694819
Iter: 1290 loss: 0.000154646768
Iter: 1291 loss: 0.000154498382
Iter: 1292 loss: 0.000154936788
Iter: 1293 loss: 0.000154452544
Iter: 1294 loss: 0.000154308073
Iter: 1295 loss: 0.000155142421
Iter: 1296 loss: 0.0001542885
Iter: 1297 loss: 0.000154184556
Iter: 1298 loss: 0.00015410973
Iter: 1299 loss: 0.000154073859
Iter: 1300 loss: 0.000153885427
Iter: 1301 loss: 0.000154369394
Iter: 1302 loss: 0.000153820409
Iter: 1303 loss: 0.000153645291
Iter: 1304 loss: 0.000154200505
Iter: 1305 loss: 0.000153595087
Iter: 1306 loss: 0.000153419445
Iter: 1307 loss: 0.000153526169
Iter: 1308 loss: 0.000153307046
Iter: 1309 loss: 0.000153124274
Iter: 1310 loss: 0.0001531241
Iter: 1311 loss: 0.000153025059
Iter: 1312 loss: 0.000153386442
Iter: 1313 loss: 0.000153000219
Iter: 1314 loss: 0.00015291819
Iter: 1315 loss: 0.000152917681
Iter: 1316 loss: 0.00015285975
Iter: 1317 loss: 0.00015280323
Iter: 1318 loss: 0.000152790846
Iter: 1319 loss: 0.000152708468
Iter: 1320 loss: 0.000152638546
Iter: 1321 loss: 0.000152615918
Iter: 1322 loss: 0.000152481603
Iter: 1323 loss: 0.00015299338
Iter: 1324 loss: 0.000152449546
Iter: 1325 loss: 0.000152324166
Iter: 1326 loss: 0.000152812674
Iter: 1327 loss: 0.000152294597
Iter: 1328 loss: 0.000152194596
Iter: 1329 loss: 0.000152200359
Iter: 1330 loss: 0.000152116234
Iter: 1331 loss: 0.000151960616
Iter: 1332 loss: 0.000152100838
Iter: 1333 loss: 0.000151869477
Iter: 1334 loss: 0.000151702028
Iter: 1335 loss: 0.000152427077
Iter: 1336 loss: 0.000151667613
Iter: 1337 loss: 0.000151494794
Iter: 1338 loss: 0.000151652857
Iter: 1339 loss: 0.000151394663
Iter: 1340 loss: 0.000151231536
Iter: 1341 loss: 0.000152989785
Iter: 1342 loss: 0.000151227432
Iter: 1343 loss: 0.000151124041
Iter: 1344 loss: 0.00015179714
Iter: 1345 loss: 0.000151112545
Iter: 1346 loss: 0.0001510562
Iter: 1347 loss: 0.000151054381
Iter: 1348 loss: 0.000151009517
Iter: 1349 loss: 0.000150953216
Iter: 1350 loss: 0.000150949083
Iter: 1351 loss: 0.000150877284
Iter: 1352 loss: 0.000150829263
Iter: 1353 loss: 0.00015080224
Iter: 1354 loss: 0.000150691718
Iter: 1355 loss: 0.000150853797
Iter: 1356 loss: 0.000150637774
Iter: 1357 loss: 0.000150496533
Iter: 1358 loss: 0.000151447079
Iter: 1359 loss: 0.00015048249
Iter: 1360 loss: 0.00015039742
Iter: 1361 loss: 0.000150401407
Iter: 1362 loss: 0.000150330452
Iter: 1363 loss: 0.000150184336
Iter: 1364 loss: 0.000150258726
Iter: 1365 loss: 0.000150087813
Iter: 1366 loss: 0.000149920466
Iter: 1367 loss: 0.000150367196
Iter: 1368 loss: 0.000149865009
Iter: 1369 loss: 0.000149672764
Iter: 1370 loss: 0.000150361768
Iter: 1371 loss: 0.000149623957
Iter: 1372 loss: 0.000149471976
Iter: 1373 loss: 0.000150381107
Iter: 1374 loss: 0.000149452564
Iter: 1375 loss: 0.000149351414
Iter: 1376 loss: 0.000150289838
Iter: 1377 loss: 0.000149347266
Iter: 1378 loss: 0.000149297091
Iter: 1379 loss: 0.000149295316
Iter: 1380 loss: 0.000149252606
Iter: 1381 loss: 0.00014919095
Iter: 1382 loss: 0.000149189465
Iter: 1383 loss: 0.000149110827
Iter: 1384 loss: 0.000149130981
Iter: 1385 loss: 0.000149053812
Iter: 1386 loss: 0.000148951658
Iter: 1387 loss: 0.000148962456
Iter: 1388 loss: 0.000148873136
Iter: 1389 loss: 0.000148746767
Iter: 1390 loss: 0.000150122229
Iter: 1391 loss: 0.000148743784
Iter: 1392 loss: 0.000148669322
Iter: 1393 loss: 0.000148604
Iter: 1394 loss: 0.000148585081
Iter: 1395 loss: 0.000148440362
Iter: 1396 loss: 0.00014873936
Iter: 1397 loss: 0.000148382838
Iter: 1398 loss: 0.000148234103
Iter: 1399 loss: 0.00014849416
Iter: 1400 loss: 0.000148169143
Iter: 1401 loss: 0.000147997052
Iter: 1402 loss: 0.000148532476
Iter: 1403 loss: 0.000147946383
Iter: 1404 loss: 0.000147815575
Iter: 1405 loss: 0.000148837513
Iter: 1406 loss: 0.000147806175
Iter: 1407 loss: 0.000147717539
Iter: 1408 loss: 0.000148336519
Iter: 1409 loss: 0.000147709128
Iter: 1410 loss: 0.00014765808
Iter: 1411 loss: 0.00014765677
Iter: 1412 loss: 0.000147613129
Iter: 1413 loss: 0.00014757851
Iter: 1414 loss: 0.00014756438
Iter: 1415 loss: 0.000147504848
Iter: 1416 loss: 0.000147465631
Iter: 1417 loss: 0.000147442814
Iter: 1418 loss: 0.000147340819
Iter: 1419 loss: 0.000147394399
Iter: 1420 loss: 0.00014727308
Iter: 1421 loss: 0.000147164537
Iter: 1422 loss: 0.000148377061
Iter: 1423 loss: 0.000147162078
Iter: 1424 loss: 0.000147086277
Iter: 1425 loss: 0.000147077662
Iter: 1426 loss: 0.0001470227
Iter: 1427 loss: 0.000146915234
Iter: 1428 loss: 0.000146923907
Iter: 1429 loss: 0.000146831619
Iter: 1430 loss: 0.000146693288
Iter: 1431 loss: 0.000147417959
Iter: 1432 loss: 0.000146671693
Iter: 1433 loss: 0.000146533435
Iter: 1434 loss: 0.000146647362
Iter: 1435 loss: 0.000146451493
Iter: 1436 loss: 0.000146333274
Iter: 1437 loss: 0.000147460203
Iter: 1438 loss: 0.000146328632
Iter: 1439 loss: 0.000146236474
Iter: 1440 loss: 0.00014685838
Iter: 1441 loss: 0.000146227248
Iter: 1442 loss: 0.000146189675
Iter: 1443 loss: 0.000146184422
Iter: 1444 loss: 0.000146149658
Iter: 1445 loss: 0.000146115955
Iter: 1446 loss: 0.000146108679
Iter: 1447 loss: 0.000146051825
Iter: 1448 loss: 0.000145994258
Iter: 1449 loss: 0.00014598298
Iter: 1450 loss: 0.000145883154
Iter: 1451 loss: 0.000146039412
Iter: 1452 loss: 0.000145836777
Iter: 1453 loss: 0.000145735015
Iter: 1454 loss: 0.000146634207
Iter: 1455 loss: 0.000145729718
Iter: 1456 loss: 0.000145656915
Iter: 1457 loss: 0.000145733109
Iter: 1458 loss: 0.000145616199
Iter: 1459 loss: 0.000145531725
Iter: 1460 loss: 0.00014548414
Iter: 1461 loss: 0.000145447382
Iter: 1462 loss: 0.00014532113
Iter: 1463 loss: 0.000145669823
Iter: 1464 loss: 0.000145280384
Iter: 1465 loss: 0.000145131722
Iter: 1466 loss: 0.000145616359
Iter: 1467 loss: 0.000145089798
Iter: 1468 loss: 0.000144979509
Iter: 1469 loss: 0.000145445199
Iter: 1470 loss: 0.000144955979
Iter: 1471 loss: 0.000144859834
Iter: 1472 loss: 0.000145604819
Iter: 1473 loss: 0.000144853315
Iter: 1474 loss: 0.00014480167
Iter: 1475 loss: 0.000144800229
Iter: 1476 loss: 0.000144754245
Iter: 1477 loss: 0.000144747493
Iter: 1478 loss: 0.000144714606
Iter: 1479 loss: 0.000144665697
Iter: 1480 loss: 0.000144607024
Iter: 1481 loss: 0.000144600432
Iter: 1482 loss: 0.000144502817
Iter: 1483 loss: 0.000144506543
Iter: 1484 loss: 0.000144425663
Iter: 1485 loss: 0.000144327088
Iter: 1486 loss: 0.00014579916
Iter: 1487 loss: 0.000144327088
Iter: 1488 loss: 0.000144250807
Iter: 1489 loss: 0.000144306949
Iter: 1490 loss: 0.000144203586
Iter: 1491 loss: 0.000144116231
Iter: 1492 loss: 0.00014412569
Iter: 1493 loss: 0.000144049263
Iter: 1494 loss: 0.000143925718
Iter: 1495 loss: 0.000144198319
Iter: 1496 loss: 0.000143878613
Iter: 1497 loss: 0.000143737474
Iter: 1498 loss: 0.000143988058
Iter: 1499 loss: 0.000143675788
Iter: 1500 loss: 0.000143555983
Iter: 1501 loss: 0.000144432386
Iter: 1502 loss: 0.000143545898
Iter: 1503 loss: 0.000143438185
Iter: 1504 loss: 0.000144002901
Iter: 1505 loss: 0.00014342129
Iter: 1506 loss: 0.000143373516
Iter: 1507 loss: 0.0001433664
Iter: 1508 loss: 0.000143323705
Iter: 1509 loss: 0.000143343641
Iter: 1510 loss: 0.000143294921
Iter: 1511 loss: 0.000143247948
Iter: 1512 loss: 0.00014318421
Iter: 1513 loss: 0.00014318066
Iter: 1514 loss: 0.000143091689
Iter: 1515 loss: 0.000143241108
Iter: 1516 loss: 0.000143051133
Iter: 1517 loss: 0.000142968507
Iter: 1518 loss: 0.000143524958
Iter: 1519 loss: 0.000142959645
Iter: 1520 loss: 0.000142885605
Iter: 1521 loss: 0.000143007448
Iter: 1522 loss: 0.000142851728
Iter: 1523 loss: 0.000142776305
Iter: 1524 loss: 0.000142763718
Iter: 1525 loss: 0.000142711637
Iter: 1526 loss: 0.000142608202
Iter: 1527 loss: 0.000142806908
Iter: 1528 loss: 0.000142564517
Iter: 1529 loss: 0.000142439356
Iter: 1530 loss: 0.000142778081
Iter: 1531 loss: 0.000142397737
Iter: 1532 loss: 0.000142294361
Iter: 1533 loss: 0.000142732446
Iter: 1534 loss: 0.000142272722
Iter: 1535 loss: 0.000142182049
Iter: 1536 loss: 0.000142837394
Iter: 1537 loss: 0.000142174336
Iter: 1538 loss: 0.000142130273
Iter: 1539 loss: 0.000142126926
Iter: 1540 loss: 0.000142089
Iter: 1541 loss: 0.000142122517
Iter: 1542 loss: 0.000142066521
Iter: 1543 loss: 0.000142030069
Iter: 1544 loss: 0.000141984536
Iter: 1545 loss: 0.000141981262
Iter: 1546 loss: 0.000141913173
Iter: 1547 loss: 0.000141969
Iter: 1548 loss: 0.000141872821
Iter: 1549 loss: 0.000141802884
Iter: 1550 loss: 0.000142218953
Iter: 1551 loss: 0.000141793731
Iter: 1552 loss: 0.000141720593
Iter: 1553 loss: 0.000141845449
Iter: 1554 loss: 0.000141687633
Iter: 1555 loss: 0.000141616329
Iter: 1556 loss: 0.000141646393
Iter: 1557 loss: 0.000141567987
Iter: 1558 loss: 0.000141478027
Iter: 1559 loss: 0.000141626573
Iter: 1560 loss: 0.000141437165
Iter: 1561 loss: 0.000141326687
Iter: 1562 loss: 0.00014152276
Iter: 1563 loss: 0.000141278841
Iter: 1564 loss: 0.000141182274
Iter: 1565 loss: 0.000141723431
Iter: 1566 loss: 0.000141168872
Iter: 1567 loss: 0.000141092634
Iter: 1568 loss: 0.000141722732
Iter: 1569 loss: 0.000141088094
Iter: 1570 loss: 0.000141055847
Iter: 1571 loss: 0.000141052486
Iter: 1572 loss: 0.000141022741
Iter: 1573 loss: 0.000141041979
Iter: 1574 loss: 0.000141003839
Iter: 1575 loss: 0.000140971097
Iter: 1576 loss: 0.000140924676
Iter: 1577 loss: 0.000140923134
Iter: 1578 loss: 0.000140859658
Iter: 1579 loss: 0.00014092795
Iter: 1580 loss: 0.000140825083
Iter: 1581 loss: 0.000140760225
Iter: 1582 loss: 0.000141071272
Iter: 1583 loss: 0.000140748962
Iter: 1584 loss: 0.000140676784
Iter: 1585 loss: 0.000140816992
Iter: 1586 loss: 0.000140647287
Iter: 1587 loss: 0.000140576012
Iter: 1588 loss: 0.000140628879
Iter: 1589 loss: 0.000140532109
Iter: 1590 loss: 0.000140450706
Iter: 1591 loss: 0.000140552642
Iter: 1592 loss: 0.000140408505
Iter: 1593 loss: 0.000140313423
Iter: 1594 loss: 0.000140567368
Iter: 1595 loss: 0.000140281569
Iter: 1596 loss: 0.000140201664
Iter: 1597 loss: 0.00014055043
Iter: 1598 loss: 0.00014018509
Iter: 1599 loss: 0.000140114367
Iter: 1600 loss: 0.000140615331
Iter: 1601 loss: 0.000140107819
Iter: 1602 loss: 0.000140079355
Iter: 1603 loss: 0.000140074582
Iter: 1604 loss: 0.000140046846
Iter: 1605 loss: 0.000140056232
Iter: 1606 loss: 0.000140027187
Iter: 1607 loss: 0.000139991665
Iter: 1608 loss: 0.000139945303
Iter: 1609 loss: 0.000139942218
Iter: 1610 loss: 0.000139882177
Iter: 1611 loss: 0.000139982149
Iter: 1612 loss: 0.000139854732
Iter: 1613 loss: 0.000139793046
Iter: 1614 loss: 0.000139946467
Iter: 1615 loss: 0.000139771393
Iter: 1616 loss: 0.000139691765
Iter: 1617 loss: 0.00014001214
Iter: 1618 loss: 0.000139673444
Iter: 1619 loss: 0.000139607495
Iter: 1620 loss: 0.000139650816
Iter: 1621 loss: 0.0001395656
Iter: 1622 loss: 0.000139492491
Iter: 1623 loss: 0.000139576965
Iter: 1624 loss: 0.000139453419
Iter: 1625 loss: 0.000139368
Iter: 1626 loss: 0.000139606767
Iter: 1627 loss: 0.000139340715
Iter: 1628 loss: 0.000139259238
Iter: 1629 loss: 0.000139484764
Iter: 1630 loss: 0.000139232987
Iter: 1631 loss: 0.000139154188
Iter: 1632 loss: 0.000139744239
Iter: 1633 loss: 0.000139148
Iter: 1634 loss: 0.000139117314
Iter: 1635 loss: 0.000139111246
Iter: 1636 loss: 0.000139080948
Iter: 1637 loss: 0.000139109732
Iter: 1638 loss: 0.000139064126
Iter: 1639 loss: 0.000139030628
Iter: 1640 loss: 0.00013898786
Iter: 1641 loss: 0.000138984877
Iter: 1642 loss: 0.000138929143
Iter: 1643 loss: 0.000139013689
Iter: 1644 loss: 0.000138902848
Iter: 1645 loss: 0.00013884154
Iter: 1646 loss: 0.000138927819
Iter: 1647 loss: 0.000138811389
Iter: 1648 loss: 0.000138731251
Iter: 1649 loss: 0.000139182754
Iter: 1650 loss: 0.000138719974
Iter: 1651 loss: 0.000138662479
Iter: 1652 loss: 0.000138694566
Iter: 1653 loss: 0.000138625241
Iter: 1654 loss: 0.000138558084
Iter: 1655 loss: 0.00013859605
Iter: 1656 loss: 0.000138514384
Iter: 1657 loss: 0.000138428441
Iter: 1658 loss: 0.000138694042
Iter: 1659 loss: 0.000138402625
Iter: 1660 loss: 0.000138320393
Iter: 1661 loss: 0.000138484
Iter: 1662 loss: 0.000138287156
Iter: 1663 loss: 0.000138207732
Iter: 1664 loss: 0.000138938572
Iter: 1665 loss: 0.000138204021
Iter: 1666 loss: 0.000138178424
Iter: 1667 loss: 0.000138171206
Iter: 1668 loss: 0.000138144576
Iter: 1669 loss: 0.000138161326
Iter: 1670 loss: 0.000138127638
Iter: 1671 loss: 0.000138094882
Iter: 1672 loss: 0.000138059186
Iter: 1673 loss: 0.000138053816
Iter: 1674 loss: 0.000138002972
Iter: 1675 loss: 0.000138064177
Iter: 1676 loss: 0.000137976152
Iter: 1677 loss: 0.000137918221
Iter: 1678 loss: 0.000137976283
Iter: 1679 loss: 0.000137885247
Iter: 1680 loss: 0.000137810741
Iter: 1681 loss: 0.000138407195
Iter: 1682 loss: 0.000137805648
Iter: 1683 loss: 0.000137756346
Iter: 1684 loss: 0.000137763956
Iter: 1685 loss: 0.000137719529
Iter: 1686 loss: 0.000137654162
Iter: 1687 loss: 0.000137700205
Iter: 1688 loss: 0.000137613097
Iter: 1689 loss: 0.000137531257
Iter: 1690 loss: 0.000137771363
Iter: 1691 loss: 0.000137506358
Iter: 1692 loss: 0.000137426119
Iter: 1693 loss: 0.000137598821
Iter: 1694 loss: 0.000137395051
Iter: 1695 loss: 0.000137322204
Iter: 1696 loss: 0.000138008196
Iter: 1697 loss: 0.000137319134
Iter: 1698 loss: 0.000137293289
Iter: 1699 loss: 0.0001372876
Iter: 1700 loss: 0.000137259922
Iter: 1701 loss: 0.000137283801
Iter: 1702 loss: 0.00013724358
Iter: 1703 loss: 0.000137211056
Iter: 1704 loss: 0.000137180905
Iter: 1705 loss: 0.000137173163
Iter: 1706 loss: 0.000137125273
Iter: 1707 loss: 0.000137180759
Iter: 1708 loss: 0.000137100156
Iter: 1709 loss: 0.000137043
Iter: 1710 loss: 0.000137079289
Iter: 1711 loss: 0.000137007184
Iter: 1712 loss: 0.000136934163
Iter: 1713 loss: 0.000137556257
Iter: 1714 loss: 0.000136929972
Iter: 1715 loss: 0.000136883435
Iter: 1716 loss: 0.000136875344
Iter: 1717 loss: 0.000136843737
Iter: 1718 loss: 0.000136776813
Iter: 1719 loss: 0.000136818286
Iter: 1720 loss: 0.000136733812
Iter: 1721 loss: 0.000136649964
Iter: 1722 loss: 0.000136909221
Iter: 1723 loss: 0.000136624847
Iter: 1724 loss: 0.00013654519
Iter: 1725 loss: 0.000136725692
Iter: 1726 loss: 0.00013651514
Iter: 1727 loss: 0.000136441697
Iter: 1728 loss: 0.000137021576
Iter: 1729 loss: 0.0001364364
Iter: 1730 loss: 0.000136412244
Iter: 1731 loss: 0.000136405055
Iter: 1732 loss: 0.000136377246
Iter: 1733 loss: 0.000136394709
Iter: 1734 loss: 0.000136359493
Iter: 1735 loss: 0.000136325863
Iter: 1736 loss: 0.000136292147
Iter: 1737 loss: 0.000136285016
Iter: 1738 loss: 0.000136235685
Iter: 1739 loss: 0.000136287563
Iter: 1740 loss: 0.000136208168
Iter: 1741 loss: 0.000136148679
Iter: 1742 loss: 0.000136192524
Iter: 1743 loss: 0.00013611262
Iter: 1744 loss: 0.000136043425
Iter: 1745 loss: 0.000136828399
Iter: 1746 loss: 0.000136042436
Iter: 1747 loss: 0.000135997761
Iter: 1748 loss: 0.000135980663
Iter: 1749 loss: 0.00013595639
Iter: 1750 loss: 0.000135888855
Iter: 1751 loss: 0.00013594667
Iter: 1752 loss: 0.000135849521
Iter: 1753 loss: 0.000135770315
Iter: 1754 loss: 0.000135992756
Iter: 1755 loss: 0.000135745649
Iter: 1756 loss: 0.000135667258
Iter: 1757 loss: 0.000135857234
Iter: 1758 loss: 0.000135639624
Iter: 1759 loss: 0.0001355696
Iter: 1760 loss: 0.000136170507
Iter: 1761 loss: 0.000135565613
Iter: 1762 loss: 0.000135540642
Iter: 1763 loss: 0.000135535287
Iter: 1764 loss: 0.000135507435
Iter: 1765 loss: 0.00013553536
Iter: 1766 loss: 0.000135492199
Iter: 1767 loss: 0.000135460054
Iter: 1768 loss: 0.000135438837
Iter: 1769 loss: 0.000135426366
Iter: 1770 loss: 0.000135384907
Iter: 1771 loss: 0.000135424343
Iter: 1772 loss: 0.000135361042
Iter: 1773 loss: 0.000135308932
Iter: 1774 loss: 0.000135354639
Iter: 1775 loss: 0.000135278256
Iter: 1776 loss: 0.000135223832
Iter: 1777 loss: 0.000135904964
Iter: 1778 loss: 0.000135223381
Iter: 1779 loss: 0.000135188631
Iter: 1780 loss: 0.000135166847
Iter: 1781 loss: 0.000135153037
Iter: 1782 loss: 0.000135097012
Iter: 1783 loss: 0.000135137787
Iter: 1784 loss: 0.000135062015
Iter: 1785 loss: 0.000134993868
Iter: 1786 loss: 0.000135173861
Iter: 1787 loss: 0.000134970964
Iter: 1788 loss: 0.0001349019
Iter: 1789 loss: 0.000135077367
Iter: 1790 loss: 0.000134878108
Iter: 1791 loss: 0.000134815957
Iter: 1792 loss: 0.000135245122
Iter: 1793 loss: 0.000134810296
Iter: 1794 loss: 0.000134786213
Iter: 1795 loss: 0.000134781643
Iter: 1796 loss: 0.000134755275
Iter: 1797 loss: 0.000134792732
Iter: 1798 loss: 0.000134742178
Iter: 1799 loss: 0.000134715126
Iter: 1800 loss: 0.000134691189
Iter: 1801 loss: 0.000134684655
Iter: 1802 loss: 0.000134645452
Iter: 1803 loss: 0.000134661008
Iter: 1804 loss: 0.000134618676
Iter: 1805 loss: 0.000134564209
Iter: 1806 loss: 0.000134618866
Iter: 1807 loss: 0.000134534115
Iter: 1808 loss: 0.000134483562
Iter: 1809 loss: 0.000134483504
Iter: 1810 loss: 0.000134449656
Iter: 1811 loss: 0.000134412694
Iter: 1812 loss: 0.000134407412
Iter: 1813 loss: 0.000134343645
Iter: 1814 loss: 0.000134416
Iter: 1815 loss: 0.000134309565
Iter: 1816 loss: 0.000134236456
Iter: 1817 loss: 0.0001343896
Iter: 1818 loss: 0.000134207774
Iter: 1819 loss: 0.000134130358
Iter: 1820 loss: 0.000134402275
Iter: 1821 loss: 0.000134109723
Iter: 1822 loss: 0.000134045651
Iter: 1823 loss: 0.000134438189
Iter: 1824 loss: 0.000134037677
Iter: 1825 loss: 0.000134013098
Iter: 1826 loss: 0.000134007729
Iter: 1827 loss: 0.000133979949
Iter: 1828 loss: 0.000134013593
Iter: 1829 loss: 0.000133965805
Iter: 1830 loss: 0.000133935071
Iter: 1831 loss: 0.000133919864
Iter: 1832 loss: 0.000133904978
Iter: 1833 loss: 0.000133865295
Iter: 1834 loss: 0.000133875583
Iter: 1835 loss: 0.000133836555
Iter: 1836 loss: 0.000133779133
Iter: 1837 loss: 0.000133827096
Iter: 1838 loss: 0.000133745285
Iter: 1839 loss: 0.000133690613
Iter: 1840 loss: 0.000134527072
Iter: 1841 loss: 0.00013369057
Iter: 1842 loss: 0.000133653113
Iter: 1843 loss: 0.000133613474
Iter: 1844 loss: 0.000133606693
Iter: 1845 loss: 0.000133539841
Iter: 1846 loss: 0.00013361749
Iter: 1847 loss: 0.000133504145
Iter: 1848 loss: 0.000133427748
Iter: 1849 loss: 0.000133589201
Iter: 1850 loss: 0.000133397582
Iter: 1851 loss: 0.000133320427
Iter: 1852 loss: 0.000133646419
Iter: 1853 loss: 0.000133304216
Iter: 1854 loss: 0.00013324499
Iter: 1855 loss: 0.000133599708
Iter: 1856 loss: 0.000133237685
Iter: 1857 loss: 0.000133211521
Iter: 1858 loss: 0.000133208378
Iter: 1859 loss: 0.000133180409
Iter: 1860 loss: 0.000133219437
Iter: 1861 loss: 0.000133166861
Iter: 1862 loss: 0.000133138354
Iter: 1863 loss: 0.000133123249
Iter: 1864 loss: 0.000133110545
Iter: 1865 loss: 0.000133072739
Iter: 1866 loss: 0.000133080423
Iter: 1867 loss: 0.000133044741
Iter: 1868 loss: 0.000132990885
Iter: 1869 loss: 0.00013304493
Iter: 1870 loss: 0.000132960529
Iter: 1871 loss: 0.000132911242
Iter: 1872 loss: 0.00013291114
Iter: 1873 loss: 0.000132875517
Iter: 1874 loss: 0.000132835732
Iter: 1875 loss: 0.000132830231
Iter: 1876 loss: 0.000132768269
Iter: 1877 loss: 0.000132884306
Iter: 1878 loss: 0.000132741872
Iter: 1879 loss: 0.000132676651
Iter: 1880 loss: 0.000132760208
Iter: 1881 loss: 0.000132643647
Iter: 1882 loss: 0.000132571033
Iter: 1883 loss: 0.000132959976
Iter: 1884 loss: 0.000132559711
Iter: 1885 loss: 0.000132507514
Iter: 1886 loss: 0.000132751389
Iter: 1887 loss: 0.000132497807
Iter: 1888 loss: 0.00013247483
Iter: 1889 loss: 0.000132470275
Iter: 1890 loss: 0.000132444256
Iter: 1891 loss: 0.000132478686
Iter: 1892 loss: 0.00013243068
Iter: 1893 loss: 0.000132401154
Iter: 1894 loss: 0.000132392393
Iter: 1895 loss: 0.00013237448
Iter: 1896 loss: 0.000132338246
Iter: 1897 loss: 0.000132344867
Iter: 1898 loss: 0.000132311339
Iter: 1899 loss: 0.00013226032
Iter: 1900 loss: 0.000132332352
Iter: 1901 loss: 0.000132235422
Iter: 1902 loss: 0.000132190879
Iter: 1903 loss: 0.00013280868
Iter: 1904 loss: 0.000132190922
Iter: 1905 loss: 0.000132157729
Iter: 1906 loss: 0.000132115849
Iter: 1907 loss: 0.000132112647
Iter: 1908 loss: 0.000132053974
Iter: 1909 loss: 0.000132200599
Iter: 1910 loss: 0.000132034096
Iter: 1911 loss: 0.000131976296
Iter: 1912 loss: 0.00013203
Iter: 1913 loss: 0.000131943088
Iter: 1914 loss: 0.000131875306
Iter: 1915 loss: 0.00013219926
Iter: 1916 loss: 0.000131862966
Iter: 1917 loss: 0.000131812762
Iter: 1918 loss: 0.00013204795
Iter: 1919 loss: 0.000131803419
Iter: 1920 loss: 0.000131778041
Iter: 1921 loss: 0.000131775654
Iter: 1922 loss: 0.00013174754
Iter: 1923 loss: 0.000131794644
Iter: 1924 loss: 0.000131735258
Iter: 1925 loss: 0.000131707318
Iter: 1926 loss: 0.000131688124
Iter: 1927 loss: 0.000131678054
Iter: 1928 loss: 0.000131640845
Iter: 1929 loss: 0.000131652603
Iter: 1930 loss: 0.000131613851
Iter: 1931 loss: 0.000131564535
Iter: 1932 loss: 0.000131653607
Iter: 1933 loss: 0.000131543231
Iter: 1934 loss: 0.000131500259
Iter: 1935 loss: 0.00013205671
Iter: 1936 loss: 0.000131500012
Iter: 1937 loss: 0.000131463166
Iter: 1938 loss: 0.000131416309
Iter: 1939 loss: 0.000131412584
Iter: 1940 loss: 0.000131351975
Iter: 1941 loss: 0.000131544424
Iter: 1942 loss: 0.000131334295
Iter: 1943 loss: 0.000131278503
Iter: 1944 loss: 0.000131295485
Iter: 1945 loss: 0.000131238296
Iter: 1946 loss: 0.000131169203
Iter: 1947 loss: 0.000131659515
Iter: 1948 loss: 0.000131163222
Iter: 1949 loss: 0.000131114561
Iter: 1950 loss: 0.000131268083
Iter: 1951 loss: 0.000131100358
Iter: 1952 loss: 0.000131073262
Iter: 1953 loss: 0.000131070425
Iter: 1954 loss: 0.000131040841
Iter: 1955 loss: 0.000131111476
Iter: 1956 loss: 0.000131030043
Iter: 1957 loss: 0.00013100302
Iter: 1958 loss: 0.000130984408
Iter: 1959 loss: 0.000130975182
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4
+ date
Tue Oct 27 16:06:09 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcef9da1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcef9ea730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcef9eaea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcab536e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcab48c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcab48c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcab46ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcab420048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbcab46fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc843742f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc8433c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84353f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc842f97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84386950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc842c0ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc842c0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84284488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc842c0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc841fe840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84202f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84214598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc841d4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc8418d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc8419b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc841366a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84136268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84117840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc840cb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc840cb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc8407b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc84031840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc840506a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc840509d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc707cc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc707fcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc707ad730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.126325458
Iter: 2 loss: 3729.40137
Iter: 3 loss: 0.126132324
Iter: 4 loss: 7129.11328
Iter: 5 loss: 0.126131
Iter: 6 loss: 3775.07031
Iter: 7 loss: 4638.62598
Iter: 8 loss: 0.126130164
Iter: 9 loss: 2261.9043
Iter: 10 loss: 813.278931
Iter: 11 loss: 0.126129642
Iter: 12 loss: 418.252197
Iter: 13 loss: 0.126128972
Iter: 14 loss: 369.622162
Iter: 15 loss: 0.126127794
Iter: 16 loss: 0.0894901
Iter: 17 loss: 0.0894900858
Iter: 18 loss: 7.36454725
Iter: 19 loss: 0.089489527
Iter: 20 loss: 0.135671169
Iter: 21 loss: 0.0894227
Iter: 22 loss: 0.103417873
Iter: 23 loss: 0.087828733
Iter: 24 loss: 0.0878277272
Iter: 25 loss: 235.823151
Iter: 26 loss: 0.0864250958
Iter: 27 loss: 0.0809839144
Iter: 28 loss: 0.0725082457
Iter: 29 loss: 0.172477856
Iter: 30 loss: 0.0717269555
Iter: 31 loss: 0.0691537261
Iter: 32 loss: 0.0760601535
Iter: 33 loss: 0.0694078729
Iter: 34 loss: 0.0674167
Iter: 35 loss: 0.0672701076
Iter: 36 loss: 0.0649384856
Iter: 37 loss: 0.141974
Iter: 38 loss: 0.0647999048
Iter: 39 loss: 0.0647170097
Iter: 40 loss: 0.0633498
Iter: 41 loss: 0.0607775897
Iter: 42 loss: 0.113887116
Iter: 43 loss: 0.0607168935
Iter: 44 loss: 0.0565640777
Iter: 45 loss: 0.107106626
Iter: 46 loss: 0.0560805574
Iter: 47 loss: 0.0529156886
Iter: 48 loss: 0.0528471768
Iter: 49 loss: 0.0507994
Iter: 50 loss: 0.0627624243
Iter: 51 loss: 0.0505180731
Iter: 52 loss: 0.0479111373
Iter: 53 loss: 0.0534887612
Iter: 54 loss: 0.0464359894
Iter: 55 loss: 0.0455445163
Iter: 56 loss: 0.0442853719
Iter: 57 loss: 0.0425974354
Iter: 58 loss: 0.0807364136
Iter: 59 loss: 0.0425532348
Iter: 60 loss: 0.0410336219
Iter: 61 loss: 0.0592761487
Iter: 62 loss: 0.0409159288
Iter: 63 loss: 0.0402750224
Iter: 64 loss: 0.0437308773
Iter: 65 loss: 0.0401281342
Iter: 66 loss: 0.0390797518
Iter: 67 loss: 0.0472299978
Iter: 68 loss: 0.0390067026
Iter: 69 loss: 0.0383582413
Iter: 70 loss: 0.0383093171
Iter: 71 loss: 0.0377657525
Iter: 72 loss: 0.041214861
Iter: 73 loss: 0.0376792
Iter: 74 loss: 0.0371466652
Iter: 75 loss: 0.0380896665
Iter: 76 loss: 0.0368987322
Iter: 77 loss: 0.036393851
Iter: 78 loss: 0.03889402
Iter: 79 loss: 0.0362985469
Iter: 80 loss: 0.035816554
Iter: 81 loss: 0.0440879203
Iter: 82 loss: 0.0358062536
Iter: 83 loss: 0.035163857
Iter: 84 loss: 0.0352554135
Iter: 85 loss: 0.0346842259
Iter: 86 loss: 0.0340279415
Iter: 87 loss: 0.0377432331
Iter: 88 loss: 0.0339595713
Iter: 89 loss: 0.039947208
Iter: 90 loss: 0.0338930525
Iter: 91 loss: 0.0336725712
Iter: 92 loss: 0.0349428505
Iter: 93 loss: 0.0336418785
Iter: 94 loss: 0.0334968455
Iter: 95 loss: 0.0334803797
Iter: 96 loss: 0.0333826616
Iter: 97 loss: 0.0332090221
Iter: 98 loss: 0.0329287648
Iter: 99 loss: 0.0329279155
Iter: 100 loss: 0.0320513174
Iter: 101 loss: 0.043473497
Iter: 102 loss: 0.0320022404
Iter: 103 loss: 0.03160768
Iter: 104 loss: 0.0333688185
Iter: 105 loss: 0.0315102786
Iter: 106 loss: 0.0308820773
Iter: 107 loss: 0.034027189
Iter: 108 loss: 0.03073081
Iter: 109 loss: 0.0302445777
Iter: 110 loss: 0.0310017802
Iter: 111 loss: 0.0300212353
Iter: 112 loss: 0.0294447374
Iter: 113 loss: 0.0306282602
Iter: 114 loss: 0.0291863903
Iter: 115 loss: 0.0282341614
Iter: 116 loss: 0.0489754677
Iter: 117 loss: 0.0281787328
Iter: 118 loss: 0.0275169294
Iter: 119 loss: 0.0273443498
Iter: 120 loss: 0.0270066932
Iter: 121 loss: 0.0270044226
Iter: 122 loss: 0.0268998072
Iter: 123 loss: 0.0276119225
Iter: 124 loss: 0.0268908143
Iter: 125 loss: 0.0268852487
Iter: 126 loss: 0.0267788619
Iter: 127 loss: 0.0265781377
Iter: 128 loss: 0.0267597213
Iter: 129 loss: 0.0264632106
Iter: 130 loss: 0.026218418
Iter: 131 loss: 0.0258931108
Iter: 132 loss: 0.0258798115
Iter: 133 loss: 0.0257111862
Iter: 134 loss: 0.0255052894
Iter: 135 loss: 0.025080815
Iter: 136 loss: 0.0260498151
Iter: 137 loss: 0.0249343403
Iter: 138 loss: 0.0246093497
Iter: 139 loss: 0.0239613727
Iter: 140 loss: 0.0400844663
Iter: 141 loss: 0.0239559915
Iter: 142 loss: 0.0232134685
Iter: 143 loss: 0.0253126305
Iter: 144 loss: 0.0229750238
Iter: 145 loss: 0.0227280892
Iter: 146 loss: 0.0237186
Iter: 147 loss: 0.022657508
Iter: 148 loss: 0.0223829
Iter: 149 loss: 0.0222121365
Iter: 150 loss: 0.0221024081
Iter: 151 loss: 0.0217315294
Iter: 152 loss: 0.0224679261
Iter: 153 loss: 0.0215999708
Iter: 154 loss: 0.0213257093
Iter: 155 loss: 0.0222863201
Iter: 156 loss: 0.0212428924
Iter: 157 loss: 0.0210829638
Iter: 158 loss: 0.0213761516
Iter: 159 loss: 0.0210224744
Iter: 160 loss: 0.0207309127
Iter: 161 loss: 0.0260165744
Iter: 162 loss: 0.0207292587
Iter: 163 loss: 0.0204595383
Iter: 164 loss: 0.0205973573
Iter: 165 loss: 0.0202756822
Iter: 166 loss: 0.0199653693
Iter: 167 loss: 0.0207954347
Iter: 168 loss: 0.0198856741
Iter: 169 loss: 0.0197290853
Iter: 170 loss: 0.019560378
Iter: 171 loss: 0.0195291191
Iter: 172 loss: 0.019416783
Iter: 173 loss: 0.0196286961
Iter: 174 loss: 0.0193748549
Iter: 175 loss: 0.0193145256
Iter: 176 loss: 0.019254813
Iter: 177 loss: 0.0192441456
Iter: 178 loss: 0.019078359
Iter: 179 loss: 0.0206218064
Iter: 180 loss: 0.0190641806
Iter: 181 loss: 0.0188499466
Iter: 182 loss: 0.018849967
Iter: 183 loss: 0.0190796629
Iter: 184 loss: 0.0187129099
Iter: 185 loss: 0.0185659956
Iter: 186 loss: 0.0185998194
Iter: 187 loss: 0.0184548926
Iter: 188 loss: 0.0180711
Iter: 189 loss: 0.0180512741
Iter: 190 loss: 0.0182058327
Iter: 191 loss: 0.0177611932
Iter: 192 loss: 0.0174592845
Iter: 193 loss: 0.0178570077
Iter: 194 loss: 0.0172992051
Iter: 195 loss: 0.0169754885
Iter: 196 loss: 0.0169754494
Iter: 197 loss: 0.0168652236
Iter: 198 loss: 0.0167996213
Iter: 199 loss: 0.0166575145
Iter: 200 loss: 0.0170676112
Iter: 201 loss: 0.0166155919
Iter: 202 loss: 0.0163499601
Iter: 203 loss: 0.0167038366
Iter: 204 loss: 0.0162301753
Iter: 205 loss: 0.0159683302
Iter: 206 loss: 0.0172458254
Iter: 207 loss: 0.0159170032
Iter: 208 loss: 0.0157663859
Iter: 209 loss: 0.0159836933
Iter: 210 loss: 0.0157000609
Iter: 211 loss: 0.0155533049
Iter: 212 loss: 0.017088078
Iter: 213 loss: 0.0155477962
Iter: 214 loss: 0.0155012701
Iter: 215 loss: 0.0154006826
Iter: 216 loss: 0.0171713904
Iter: 217 loss: 0.0153973531
Iter: 218 loss: 0.0151142683
Iter: 219 loss: 0.015223572
Iter: 220 loss: 0.0149148824
Iter: 221 loss: 0.0156147787
Iter: 222 loss: 0.0148556884
Iter: 223 loss: 0.0147408154
Iter: 224 loss: 0.0146408528
Iter: 225 loss: 0.0146127883
Iter: 226 loss: 0.0144906621
Iter: 227 loss: 0.0144647062
Iter: 228 loss: 0.0143820196
Iter: 229 loss: 0.0142419348
Iter: 230 loss: 0.0142268464
Iter: 231 loss: 0.0141233215
Iter: 232 loss: 0.0138813891
Iter: 233 loss: 0.0182481855
Iter: 234 loss: 0.0138798561
Iter: 235 loss: 0.0138324471
Iter: 236 loss: 0.0138924103
Iter: 237 loss: 0.0138088865
Iter: 238 loss: 0.013651574
Iter: 239 loss: 0.0139851207
Iter: 240 loss: 0.0135933897
Iter: 241 loss: 0.0134009225
Iter: 242 loss: 0.0154401641
Iter: 243 loss: 0.0133954808
Iter: 244 loss: 0.0131514035
Iter: 245 loss: 0.0138980802
Iter: 246 loss: 0.0130863367
Iter: 247 loss: 0.0129642691
Iter: 248 loss: 0.0129037723
Iter: 249 loss: 0.0128323566
Iter: 250 loss: 0.0129988063
Iter: 251 loss: 0.0128037129
Iter: 252 loss: 0.0124925114
Iter: 253 loss: 0.0124696316
Iter: 254 loss: 0.0122570544
Iter: 255 loss: 0.0121846413
Iter: 256 loss: 0.0120507926
Iter: 257 loss: 0.0119530335
Iter: 258 loss: 0.0119065437
Iter: 259 loss: 0.0117761111
Iter: 260 loss: 0.0131024597
Iter: 261 loss: 0.0117701991
Iter: 262 loss: 0.0117350454
Iter: 263 loss: 0.0117320567
Iter: 264 loss: 0.0116886031
Iter: 265 loss: 0.0116645843
Iter: 266 loss: 0.0116447359
Iter: 267 loss: 0.0115734898
Iter: 268 loss: 0.0115201548
Iter: 269 loss: 0.0114974333
Iter: 270 loss: 0.0114304665
Iter: 271 loss: 0.0114531741
Iter: 272 loss: 0.0113820732
Iter: 273 loss: 0.0113319661
Iter: 274 loss: 0.0113297962
Iter: 275 loss: 0.0112633426
Iter: 276 loss: 0.0121031813
Iter: 277 loss: 0.0112622036
Iter: 278 loss: 0.0112022962
Iter: 279 loss: 0.0112123331
Iter: 280 loss: 0.0111582791
Iter: 281 loss: 0.0110925427
Iter: 282 loss: 0.0110816136
Iter: 283 loss: 0.0110350484
Iter: 284 loss: 0.0109771499
Iter: 285 loss: 0.0109552611
Iter: 286 loss: 0.0109233577
Iter: 287 loss: 0.0107970778
Iter: 288 loss: 0.0106863128
Iter: 289 loss: 0.0106549282
Iter: 290 loss: 0.0104709696
Iter: 291 loss: 0.0116412882
Iter: 292 loss: 0.0104470346
Iter: 293 loss: 0.0103413379
Iter: 294 loss: 0.0103345579
Iter: 295 loss: 0.0102814753
Iter: 296 loss: 0.0102742072
Iter: 297 loss: 0.0102107096
Iter: 298 loss: 0.0103260353
Iter: 299 loss: 0.0101813953
Iter: 300 loss: 0.0101449536
Iter: 301 loss: 0.0100856815
Iter: 302 loss: 0.0100853071
Iter: 303 loss: 0.00993923098
Iter: 304 loss: 0.0106749916
Iter: 305 loss: 0.00991031
Iter: 306 loss: 0.009823245
Iter: 307 loss: 0.00981636532
Iter: 308 loss: 0.00974628143
Iter: 309 loss: 0.0101761976
Iter: 310 loss: 0.00973789208
Iter: 311 loss: 0.00970595703
Iter: 312 loss: 0.00970317144
Iter: 313 loss: 0.00968034193
Iter: 314 loss: 0.00963659398
Iter: 315 loss: 0.0105336336
Iter: 316 loss: 0.00963643566
Iter: 317 loss: 0.00955156516
Iter: 318 loss: 0.00952438824
Iter: 319 loss: 0.00947412848
Iter: 320 loss: 0.00939097814
Iter: 321 loss: 0.0093022855
Iter: 322 loss: 0.00928720459
Iter: 323 loss: 0.00915168598
Iter: 324 loss: 0.00912912469
Iter: 325 loss: 0.00914524309
Iter: 326 loss: 0.00906942599
Iter: 327 loss: 0.00904245488
Iter: 328 loss: 0.00908393227
Iter: 329 loss: 0.00902919564
Iter: 330 loss: 0.00897846371
Iter: 331 loss: 0.00884689763
Iter: 332 loss: 0.00986149
Iter: 333 loss: 0.0088221021
Iter: 334 loss: 0.0086875353
Iter: 335 loss: 0.01005923
Iter: 336 loss: 0.00868537929
Iter: 337 loss: 0.00863012299
Iter: 338 loss: 0.00862761214
Iter: 339 loss: 0.00858483929
Iter: 340 loss: 0.00855009351
Iter: 341 loss: 0.00852753222
Iter: 342 loss: 0.00851357356
Iter: 343 loss: 0.00845753402
Iter: 344 loss: 0.00869691744
Iter: 345 loss: 0.00844660588
Iter: 346 loss: 0.00841676
Iter: 347 loss: 0.00860820059
Iter: 348 loss: 0.00841337
Iter: 349 loss: 0.00838778075
Iter: 350 loss: 0.0083993338
Iter: 351 loss: 0.00837033056
Iter: 352 loss: 0.00831287634
Iter: 353 loss: 0.0084833568
Iter: 354 loss: 0.00829401612
Iter: 355 loss: 0.00826790277
Iter: 356 loss: 0.00831991807
Iter: 357 loss: 0.00825733878
Iter: 358 loss: 0.00823817775
Iter: 359 loss: 0.00820227154
Iter: 360 loss: 0.00901197642
Iter: 361 loss: 0.00820220262
Iter: 362 loss: 0.00816134643
Iter: 363 loss: 0.008512
Iter: 364 loss: 0.00815926678
Iter: 365 loss: 0.00814192742
Iter: 366 loss: 0.00813502911
Iter: 367 loss: 0.00812156685
Iter: 368 loss: 0.00808868743
Iter: 369 loss: 0.00845375285
Iter: 370 loss: 0.00808498822
Iter: 371 loss: 0.00800962374
Iter: 372 loss: 0.00802575052
Iter: 373 loss: 0.00795453
Iter: 374 loss: 0.00791512802
Iter: 375 loss: 0.00791443512
Iter: 376 loss: 0.00789653137
Iter: 377 loss: 0.0078929374
Iter: 378 loss: 0.00787508301
Iter: 379 loss: 0.00783588924
Iter: 380 loss: 0.00849870872
Iter: 381 loss: 0.00783432089
Iter: 382 loss: 0.00776365306
Iter: 383 loss: 0.00838143285
Iter: 384 loss: 0.00775973545
Iter: 385 loss: 0.00767970551
Iter: 386 loss: 0.00781043433
Iter: 387 loss: 0.00764362188
Iter: 388 loss: 0.00774745503
Iter: 389 loss: 0.00763175823
Iter: 390 loss: 0.00762096234
Iter: 391 loss: 0.00762699544
Iter: 392 loss: 0.00761380326
Iter: 393 loss: 0.00758103561
Iter: 394 loss: 0.00756302476
Iter: 395 loss: 0.00754907308
Iter: 396 loss: 0.00756200496
Iter: 397 loss: 0.00753021287
Iter: 398 loss: 0.00751499785
Iter: 399 loss: 0.00750779
Iter: 400 loss: 0.00750028528
Iter: 401 loss: 0.00746255
Iter: 402 loss: 0.00743837375
Iter: 403 loss: 0.00742344
Iter: 404 loss: 0.00737474114
Iter: 405 loss: 0.00766295288
Iter: 406 loss: 0.00736951036
Iter: 407 loss: 0.00739192963
Iter: 408 loss: 0.00735818921
Iter: 409 loss: 0.00734586269
Iter: 410 loss: 0.00731766038
Iter: 411 loss: 0.00771134347
Iter: 412 loss: 0.00731584616
Iter: 413 loss: 0.00727456203
Iter: 414 loss: 0.0072544571
Iter: 415 loss: 0.0072351
Iter: 416 loss: 0.00719572045
Iter: 417 loss: 0.00722163543
Iter: 418 loss: 0.00717021478
Iter: 419 loss: 0.0071372455
Iter: 420 loss: 0.00723195
Iter: 421 loss: 0.00712717138
Iter: 422 loss: 0.00712851807
Iter: 423 loss: 0.00709770527
Iter: 424 loss: 0.00707541034
Iter: 425 loss: 0.00704819616
Iter: 426 loss: 0.00704568624
Iter: 427 loss: 0.00700383028
Iter: 428 loss: 0.00696360972
Iter: 429 loss: 0.00695424899
Iter: 430 loss: 0.0072219111
Iter: 431 loss: 0.00693303207
Iter: 432 loss: 0.00691908365
Iter: 433 loss: 0.00694102794
Iter: 434 loss: 0.00691252761
Iter: 435 loss: 0.00688002352
Iter: 436 loss: 0.00687117362
Iter: 437 loss: 0.00685128197
Iter: 438 loss: 0.00679319166
Iter: 439 loss: 0.00702178897
Iter: 440 loss: 0.00677991239
Iter: 441 loss: 0.00678978208
Iter: 442 loss: 0.00676517049
Iter: 443 loss: 0.00675375
Iter: 444 loss: 0.00674680062
Iter: 445 loss: 0.00674225483
Iter: 446 loss: 0.0067157615
Iter: 447 loss: 0.00665360736
Iter: 448 loss: 0.00742037315
Iter: 449 loss: 0.00664849114
Iter: 450 loss: 0.00658366224
Iter: 451 loss: 0.00699242
Iter: 452 loss: 0.00657635462
Iter: 453 loss: 0.00655740034
Iter: 454 loss: 0.00655479822
Iter: 455 loss: 0.00654821191
Iter: 456 loss: 0.00654051732
Iter: 457 loss: 0.00653965957
Iter: 458 loss: 0.00650433637
Iter: 459 loss: 0.00655649323
Iter: 460 loss: 0.00648751436
Iter: 461 loss: 0.00645218696
Iter: 462 loss: 0.00651183305
Iter: 463 loss: 0.00643652957
Iter: 464 loss: 0.00640659966
Iter: 465 loss: 0.00633944198
Iter: 466 loss: 0.00728813
Iter: 467 loss: 0.00633578701
Iter: 468 loss: 0.00625681737
Iter: 469 loss: 0.00676379167
Iter: 470 loss: 0.00624822406
Iter: 471 loss: 0.00620753178
Iter: 472 loss: 0.00662831916
Iter: 473 loss: 0.00620648405
Iter: 474 loss: 0.00619035121
Iter: 475 loss: 0.00618929928
Iter: 476 loss: 0.00617978
Iter: 477 loss: 0.00616305601
Iter: 478 loss: 0.00616306
Iter: 479 loss: 0.00613421
Iter: 480 loss: 0.00619377615
Iter: 481 loss: 0.00612321962
Iter: 482 loss: 0.00610428257
Iter: 483 loss: 0.0060861758
Iter: 484 loss: 0.00608178694
Iter: 485 loss: 0.00608548708
Iter: 486 loss: 0.00606756285
Iter: 487 loss: 0.00604277616
Iter: 488 loss: 0.00609317096
Iter: 489 loss: 0.00603234302
Iter: 490 loss: 0.00602231175
Iter: 491 loss: 0.00600715075
Iter: 492 loss: 0.00600687135
Iter: 493 loss: 0.00596597139
Iter: 494 loss: 0.00594263943
Iter: 495 loss: 0.00592506165
Iter: 496 loss: 0.00587943103
Iter: 497 loss: 0.00597285759
Iter: 498 loss: 0.00586049818
Iter: 499 loss: 0.00581085216
Iter: 500 loss: 0.00586234033
Iter: 501 loss: 0.00578284496
Iter: 502 loss: 0.00577123649
Iter: 503 loss: 0.00575051829
Iter: 504 loss: 0.00574601861
Iter: 505 loss: 0.00574377272
Iter: 506 loss: 0.00573662668
Iter: 507 loss: 0.00573985279
Iter: 508 loss: 0.00573176704
Iter: 509 loss: 0.00572185637
Iter: 510 loss: 0.0057149
Iter: 511 loss: 0.00571126491
Iter: 512 loss: 0.00568914833
Iter: 513 loss: 0.00567914359
Iter: 514 loss: 0.00566806458
Iter: 515 loss: 0.00564134028
Iter: 516 loss: 0.00564101
Iter: 517 loss: 0.00561894383
Iter: 518 loss: 0.00561890332
Iter: 519 loss: 0.00561192958
Iter: 520 loss: 0.00559302745
Iter: 521 loss: 0.00570805371
Iter: 522 loss: 0.00558813103
Iter: 523 loss: 0.00556196366
Iter: 524 loss: 0.0055484008
Iter: 525 loss: 0.0055365013
Iter: 526 loss: 0.00548282359
Iter: 527 loss: 0.0059073288
Iter: 528 loss: 0.00547900936
Iter: 529 loss: 0.00545119587
Iter: 530 loss: 0.00547603238
Iter: 531 loss: 0.00543463416
Iter: 532 loss: 0.00540884119
Iter: 533 loss: 0.00555508863
Iter: 534 loss: 0.00540518854
Iter: 535 loss: 0.0053928243
Iter: 536 loss: 0.00539144035
Iter: 537 loss: 0.00537642278
Iter: 538 loss: 0.0054010977
Iter: 539 loss: 0.00536946533
Iter: 540 loss: 0.00534864189
Iter: 541 loss: 0.00534131937
Iter: 542 loss: 0.0053297407
Iter: 543 loss: 0.00530894333
Iter: 544 loss: 0.00544273108
Iter: 545 loss: 0.00530654239
Iter: 546 loss: 0.0052839648
Iter: 547 loss: 0.0053709466
Iter: 548 loss: 0.00527897198
Iter: 549 loss: 0.00526019093
Iter: 550 loss: 0.00542410277
Iter: 551 loss: 0.00525889779
Iter: 552 loss: 0.00524499081
Iter: 553 loss: 0.00522303674
Iter: 554 loss: 0.00522279181
Iter: 555 loss: 0.00520184496
Iter: 556 loss: 0.00518283248
Iter: 557 loss: 0.00517780334
Iter: 558 loss: 0.00514199166
Iter: 559 loss: 0.00509466231
Iter: 560 loss: 0.00509205274
Iter: 561 loss: 0.00504304934
Iter: 562 loss: 0.00508477073
Iter: 563 loss: 0.00501458906
Iter: 564 loss: 0.00498188706
Iter: 565 loss: 0.00521868188
Iter: 566 loss: 0.00497953082
Iter: 567 loss: 0.00496282103
Iter: 568 loss: 0.00495761447
Iter: 569 loss: 0.00494772522
Iter: 570 loss: 0.00508150086
Iter: 571 loss: 0.00493686
Iter: 572 loss: 0.00492415251
Iter: 573 loss: 0.00490709767
Iter: 574 loss: 0.00490618171
Iter: 575 loss: 0.00489332806
Iter: 576 loss: 0.00490545342
Iter: 577 loss: 0.0048858556
Iter: 578 loss: 0.00487102382
Iter: 579 loss: 0.00486145914
Iter: 580 loss: 0.00485567469
Iter: 581 loss: 0.00493327389
Iter: 582 loss: 0.0048450632
Iter: 583 loss: 0.00483833347
Iter: 584 loss: 0.00482623558
Iter: 585 loss: 0.00482624583
Iter: 586 loss: 0.00481441757
Iter: 587 loss: 0.00481247343
Iter: 588 loss: 0.00480435323
Iter: 589 loss: 0.00478235306
Iter: 590 loss: 0.00484356517
Iter: 591 loss: 0.00477497466
Iter: 592 loss: 0.0047506853
Iter: 593 loss: 0.0047632223
Iter: 594 loss: 0.00473435409
Iter: 595 loss: 0.00471434183
Iter: 596 loss: 0.00475662109
Iter: 597 loss: 0.00470643304
Iter: 598 loss: 0.00467242487
Iter: 599 loss: 0.00468457444
Iter: 600 loss: 0.00464867149
Iter: 601 loss: 0.00460882904
Iter: 602 loss: 0.00492496043
Iter: 603 loss: 0.00460552471
Iter: 604 loss: 0.00459817285
Iter: 605 loss: 0.00459244661
Iter: 606 loss: 0.00464794878
Iter: 607 loss: 0.00456913607
Iter: 608 loss: 0.00455094781
Iter: 609 loss: 0.00452028774
Iter: 610 loss: 0.00452018157
Iter: 611 loss: 0.00450852048
Iter: 612 loss: 0.00450839568
Iter: 613 loss: 0.00450395606
Iter: 614 loss: 0.00450016093
Iter: 615 loss: 0.00449891621
Iter: 616 loss: 0.00448459573
Iter: 617 loss: 0.00448381808
Iter: 618 loss: 0.00446042465
Iter: 619 loss: 0.004459769
Iter: 620 loss: 0.0044411
Iter: 621 loss: 0.00442902371
Iter: 622 loss: 0.0045189904
Iter: 623 loss: 0.0044281329
Iter: 624 loss: 0.00441400055
Iter: 625 loss: 0.00440541888
Iter: 626 loss: 0.00439970428
Iter: 627 loss: 0.00437214226
Iter: 628 loss: 0.00435003499
Iter: 629 loss: 0.00434154365
Iter: 630 loss: 0.0043292949
Iter: 631 loss: 0.00434615323
Iter: 632 loss: 0.00432320405
Iter: 633 loss: 0.00431550154
Iter: 634 loss: 0.00430044904
Iter: 635 loss: 0.00459036883
Iter: 636 loss: 0.00430029444
Iter: 637 loss: 0.00428594183
Iter: 638 loss: 0.00434242235
Iter: 639 loss: 0.00428254344
Iter: 640 loss: 0.0042894166
Iter: 641 loss: 0.00427619321
Iter: 642 loss: 0.00427058898
Iter: 643 loss: 0.00429065153
Iter: 644 loss: 0.00426921714
Iter: 645 loss: 0.00426228065
Iter: 646 loss: 0.00426443
Iter: 647 loss: 0.00425735908
Iter: 648 loss: 0.0042457087
Iter: 649 loss: 0.00442003272
Iter: 650 loss: 0.00424568076
Iter: 651 loss: 0.00423587
Iter: 652 loss: 0.00423946558
Iter: 653 loss: 0.00422898354
Iter: 654 loss: 0.00421860907
Iter: 655 loss: 0.00421362463
Iter: 656 loss: 0.00420858245
Iter: 657 loss: 0.00419603894
Iter: 658 loss: 0.00425462052
Iter: 659 loss: 0.00419370644
Iter: 660 loss: 0.00418371707
Iter: 661 loss: 0.00425438117
Iter: 662 loss: 0.00418273732
Iter: 663 loss: 0.00417851657
Iter: 664 loss: 0.0041781459
Iter: 665 loss: 0.00417282898
Iter: 666 loss: 0.00416602939
Iter: 667 loss: 0.00416553952
Iter: 668 loss: 0.00415713154
Iter: 669 loss: 0.00415097
Iter: 670 loss: 0.0041481792
Iter: 671 loss: 0.00413912768
Iter: 672 loss: 0.00412321
Iter: 673 loss: 0.00412320951
Iter: 674 loss: 0.00410630368
Iter: 675 loss: 0.00414015818
Iter: 676 loss: 0.00409906311
Iter: 677 loss: 0.004087626
Iter: 678 loss: 0.00408326415
Iter: 679 loss: 0.00407518959
Iter: 680 loss: 0.00405838899
Iter: 681 loss: 0.00437432807
Iter: 682 loss: 0.00405804394
Iter: 683 loss: 0.00408104202
Iter: 684 loss: 0.00405082
Iter: 685 loss: 0.00404035719
Iter: 686 loss: 0.0040700445
Iter: 687 loss: 0.00403698953
Iter: 688 loss: 0.00403155
Iter: 689 loss: 0.00406747
Iter: 690 loss: 0.00403095782
Iter: 691 loss: 0.00402473
Iter: 692 loss: 0.00401717145
Iter: 693 loss: 0.00401647296
Iter: 694 loss: 0.00400076434
Iter: 695 loss: 0.00404572906
Iter: 696 loss: 0.00399575243
Iter: 697 loss: 0.00398859382
Iter: 698 loss: 0.00398709811
Iter: 699 loss: 0.00398130203
Iter: 700 loss: 0.00398196932
Iter: 701 loss: 0.00397675112
Iter: 702 loss: 0.00397083536
Iter: 703 loss: 0.00395810604
Iter: 704 loss: 0.00415333686
Iter: 705 loss: 0.00395762967
Iter: 706 loss: 0.00394311408
Iter: 707 loss: 0.00402074121
Iter: 708 loss: 0.00394090405
Iter: 709 loss: 0.0039316644
Iter: 710 loss: 0.0039039324
Iter: 711 loss: 0.00399109907
Iter: 712 loss: 0.00389009179
Iter: 713 loss: 0.00388434925
Iter: 714 loss: 0.00386548834
Iter: 715 loss: 0.00385336485
Iter: 716 loss: 0.00389331602
Iter: 717 loss: 0.00384993874
Iter: 718 loss: 0.00384110981
Iter: 719 loss: 0.00382177928
Iter: 720 loss: 0.00410169736
Iter: 721 loss: 0.00382089755
Iter: 722 loss: 0.00377795286
Iter: 723 loss: 0.00383412791
Iter: 724 loss: 0.00375592965
Iter: 725 loss: 0.00373502355
Iter: 726 loss: 0.00382307102
Iter: 727 loss: 0.00373082398
Iter: 728 loss: 0.00369361439
Iter: 729 loss: 0.00390406186
Iter: 730 loss: 0.00368832797
Iter: 731 loss: 0.0036871545
Iter: 732 loss: 0.00368010742
Iter: 733 loss: 0.00368291838
Iter: 734 loss: 0.0036738459
Iter: 735 loss: 0.00367254252
Iter: 736 loss: 0.00366887427
Iter: 737 loss: 0.00368778058
Iter: 738 loss: 0.00366765191
Iter: 739 loss: 0.0036614642
Iter: 740 loss: 0.00365306367
Iter: 741 loss: 0.00365267647
Iter: 742 loss: 0.00364480587
Iter: 743 loss: 0.00363784
Iter: 744 loss: 0.00363573
Iter: 745 loss: 0.00362991821
Iter: 746 loss: 0.00361666363
Iter: 747 loss: 0.00379677839
Iter: 748 loss: 0.0036157982
Iter: 749 loss: 0.00361054693
Iter: 750 loss: 0.00360516761
Iter: 751 loss: 0.00358819729
Iter: 752 loss: 0.00361780776
Iter: 753 loss: 0.00358078349
Iter: 754 loss: 0.00356170023
Iter: 755 loss: 0.00354335317
Iter: 756 loss: 0.00353909377
Iter: 757 loss: 0.00350250117
Iter: 758 loss: 0.00363466
Iter: 759 loss: 0.00349279027
Iter: 760 loss: 0.00347472611
Iter: 761 loss: 0.00348637486
Iter: 762 loss: 0.00346339028
Iter: 763 loss: 0.00344554801
Iter: 764 loss: 0.00357598043
Iter: 765 loss: 0.00344390655
Iter: 766 loss: 0.00346623128
Iter: 767 loss: 0.00343842246
Iter: 768 loss: 0.00343564851
Iter: 769 loss: 0.00343430601
Iter: 770 loss: 0.00343295513
Iter: 771 loss: 0.00341712893
Iter: 772 loss: 0.00347292959
Iter: 773 loss: 0.0034131431
Iter: 774 loss: 0.00340531114
Iter: 775 loss: 0.00340489112
Iter: 776 loss: 0.00340291858
Iter: 777 loss: 0.00339812785
Iter: 778 loss: 0.00344748958
Iter: 779 loss: 0.00339757884
Iter: 780 loss: 0.0033925646
Iter: 781 loss: 0.003379256
Iter: 782 loss: 0.00348139927
Iter: 783 loss: 0.00337643968
Iter: 784 loss: 0.00335552287
Iter: 785 loss: 0.00363081461
Iter: 786 loss: 0.00335542206
Iter: 787 loss: 0.00333752064
Iter: 788 loss: 0.00345714646
Iter: 789 loss: 0.00333566987
Iter: 790 loss: 0.00333139044
Iter: 791 loss: 0.00332741253
Iter: 792 loss: 0.00332204578
Iter: 793 loss: 0.00331152347
Iter: 794 loss: 0.00353399082
Iter: 795 loss: 0.00331143243
Iter: 796 loss: 0.00329854
Iter: 797 loss: 0.00328843761
Iter: 798 loss: 0.00328446366
Iter: 799 loss: 0.00328633655
Iter: 800 loss: 0.00327724358
Iter: 801 loss: 0.00327130477
Iter: 802 loss: 0.00327906478
Iter: 803 loss: 0.00326831453
Iter: 804 loss: 0.00326517131
Iter: 805 loss: 0.00326611055
Iter: 806 loss: 0.00326288352
Iter: 807 loss: 0.0032709362
Iter: 808 loss: 0.00325613469
Iter: 809 loss: 0.00324769458
Iter: 810 loss: 0.00327194459
Iter: 811 loss: 0.0032450147
Iter: 812 loss: 0.00323229656
Iter: 813 loss: 0.00322790258
Iter: 814 loss: 0.00322064664
Iter: 815 loss: 0.00320699741
Iter: 816 loss: 0.00339176273
Iter: 817 loss: 0.00320696458
Iter: 818 loss: 0.00319649139
Iter: 819 loss: 0.0032514527
Iter: 820 loss: 0.00319486787
Iter: 821 loss: 0.00318735046
Iter: 822 loss: 0.00318642
Iter: 823 loss: 0.00318106147
Iter: 824 loss: 0.00316782901
Iter: 825 loss: 0.00331307296
Iter: 826 loss: 0.00316750351
Iter: 827 loss: 0.00315644639
Iter: 828 loss: 0.00315433019
Iter: 829 loss: 0.00314689986
Iter: 830 loss: 0.00313697383
Iter: 831 loss: 0.00312757771
Iter: 832 loss: 0.0031253004
Iter: 833 loss: 0.00328448904
Iter: 834 loss: 0.00312400772
Iter: 835 loss: 0.00312129431
Iter: 836 loss: 0.00313112885
Iter: 837 loss: 0.00312062795
Iter: 838 loss: 0.00311479252
Iter: 839 loss: 0.00312868832
Iter: 840 loss: 0.00311270868
Iter: 841 loss: 0.00310675474
Iter: 842 loss: 0.00310292956
Iter: 843 loss: 0.00310060033
Iter: 844 loss: 0.00309255347
Iter: 845 loss: 0.00308938068
Iter: 846 loss: 0.00308510684
Iter: 847 loss: 0.00307567674
Iter: 848 loss: 0.00309342844
Iter: 849 loss: 0.00307154353
Iter: 850 loss: 0.00306367967
Iter: 851 loss: 0.0030584652
Iter: 852 loss: 0.00305544538
Iter: 853 loss: 0.00304420898
Iter: 854 loss: 0.0031160803
Iter: 855 loss: 0.00304296799
Iter: 856 loss: 0.00303687318
Iter: 857 loss: 0.00311566191
Iter: 858 loss: 0.00303684361
Iter: 859 loss: 0.00303217955
Iter: 860 loss: 0.0030291318
Iter: 861 loss: 0.00302733853
Iter: 862 loss: 0.00301938201
Iter: 863 loss: 0.00304777361
Iter: 864 loss: 0.00301728258
Iter: 865 loss: 0.00300475396
Iter: 866 loss: 0.00300304918
Iter: 867 loss: 0.0029942845
Iter: 868 loss: 0.00322433235
Iter: 869 loss: 0.00299265841
Iter: 870 loss: 0.00299091078
Iter: 871 loss: 0.00299139833
Iter: 872 loss: 0.00298965047
Iter: 873 loss: 0.00297081
Iter: 874 loss: 0.00307577103
Iter: 875 loss: 0.00296814879
Iter: 876 loss: 0.0029608293
Iter: 877 loss: 0.00297443359
Iter: 878 loss: 0.00295759388
Iter: 879 loss: 0.0029515326
Iter: 880 loss: 0.00294199283
Iter: 881 loss: 0.00294186198
Iter: 882 loss: 0.00293748034
Iter: 883 loss: 0.00294699939
Iter: 884 loss: 0.00293575809
Iter: 885 loss: 0.00293328939
Iter: 886 loss: 0.00292857108
Iter: 887 loss: 0.00303997542
Iter: 888 loss: 0.00292854477
Iter: 889 loss: 0.00292098429
Iter: 890 loss: 0.00290478882
Iter: 891 loss: 0.00318349944
Iter: 892 loss: 0.00290432619
Iter: 893 loss: 0.00288440264
Iter: 894 loss: 0.00302488962
Iter: 895 loss: 0.00288271671
Iter: 896 loss: 0.00289350143
Iter: 897 loss: 0.00287513528
Iter: 898 loss: 0.0028679641
Iter: 899 loss: 0.00286218012
Iter: 900 loss: 0.0028599631
Iter: 901 loss: 0.00285270344
Iter: 902 loss: 0.00284791598
Iter: 903 loss: 0.00284513738
Iter: 904 loss: 0.00283389282
Iter: 905 loss: 0.00281852577
Iter: 906 loss: 0.00281783
Iter: 907 loss: 0.00280836597
Iter: 908 loss: 0.00293490873
Iter: 909 loss: 0.00280832825
Iter: 910 loss: 0.00280137081
Iter: 911 loss: 0.00279152393
Iter: 912 loss: 0.00279118586
Iter: 913 loss: 0.00284855207
Iter: 914 loss: 0.00278890436
Iter: 915 loss: 0.00278737373
Iter: 916 loss: 0.00279705646
Iter: 917 loss: 0.00278719561
Iter: 918 loss: 0.00278192433
Iter: 919 loss: 0.00278280443
Iter: 920 loss: 0.00277800066
Iter: 921 loss: 0.00276588835
Iter: 922 loss: 0.00279018283
Iter: 923 loss: 0.00276092743
Iter: 924 loss: 0.00275239581
Iter: 925 loss: 0.00276007107
Iter: 926 loss: 0.00274744816
Iter: 927 loss: 0.00273708021
Iter: 928 loss: 0.00271997438
Iter: 929 loss: 0.00271989964
Iter: 930 loss: 0.00270299381
Iter: 931 loss: 0.00285025337
Iter: 932 loss: 0.00270213489
Iter: 933 loss: 0.00269539608
Iter: 934 loss: 0.00269293343
Iter: 935 loss: 0.00268867
Iter: 936 loss: 0.00267850072
Iter: 937 loss: 0.00279596774
Iter: 938 loss: 0.00267751352
Iter: 939 loss: 0.00267097913
Iter: 940 loss: 0.00271133101
Iter: 941 loss: 0.00267024897
Iter: 942 loss: 0.00266884896
Iter: 943 loss: 0.0026649693
Iter: 944 loss: 0.00268648099
Iter: 945 loss: 0.00266384287
Iter: 946 loss: 0.00267613959
Iter: 947 loss: 0.00265913224
Iter: 948 loss: 0.00265008816
Iter: 949 loss: 0.002662668
Iter: 950 loss: 0.00264558755
Iter: 951 loss: 0.0026310375
Iter: 952 loss: 0.00266702
Iter: 953 loss: 0.00262589427
Iter: 954 loss: 0.00261882553
Iter: 955 loss: 0.00261879968
Iter: 956 loss: 0.00261492888
Iter: 957 loss: 0.00260459236
Iter: 958 loss: 0.00268044602
Iter: 959 loss: 0.00260232063
Iter: 960 loss: 0.00259406283
Iter: 961 loss: 0.00262455409
Iter: 962 loss: 0.00259205373
Iter: 963 loss: 0.00258708652
Iter: 964 loss: 0.00257725036
Iter: 965 loss: 0.00277335639
Iter: 966 loss: 0.00257716165
Iter: 967 loss: 0.0025637853
Iter: 968 loss: 0.00261305552
Iter: 969 loss: 0.00256052753
Iter: 970 loss: 0.00255397521
Iter: 971 loss: 0.00255232211
Iter: 972 loss: 0.00255213748
Iter: 973 loss: 0.00255064853
Iter: 974 loss: 0.00254903478
Iter: 975 loss: 0.00254394859
Iter: 976 loss: 0.00255157519
Iter: 977 loss: 0.0025403616
Iter: 978 loss: 0.0025350689
Iter: 979 loss: 0.00256892759
Iter: 980 loss: 0.0025344356
Iter: 981 loss: 0.00252685742
Iter: 982 loss: 0.002544221
Iter: 983 loss: 0.00252409885
Iter: 984 loss: 0.00252148788
Iter: 985 loss: 0.00252427766
Iter: 986 loss: 0.00252007367
Iter: 987 loss: 0.00251429551
Iter: 988 loss: 0.00251775235
Iter: 989 loss: 0.00251055975
Iter: 990 loss: 0.00250449358
Iter: 991 loss: 0.00250368565
Iter: 992 loss: 0.00250185793
Iter: 993 loss: 0.00249604974
Iter: 994 loss: 0.00250431662
Iter: 995 loss: 0.002491761
Iter: 996 loss: 0.00248579727
Iter: 997 loss: 0.00249639433
Iter: 998 loss: 0.00248320145
Iter: 999 loss: 0.00248181261
Iter: 1000 loss: 0.00247745821
Iter: 1001 loss: 0.00248424802
Iter: 1002 loss: 0.0024744207
Iter: 1003 loss: 0.00246401364
Iter: 1004 loss: 0.00246211584
Iter: 1005 loss: 0.00245498377
Iter: 1006 loss: 0.00244999235
Iter: 1007 loss: 0.00244982913
Iter: 1008 loss: 0.00244483864
Iter: 1009 loss: 0.00243462762
Iter: 1010 loss: 0.00260910299
Iter: 1011 loss: 0.00243441807
Iter: 1012 loss: 0.00242722128
Iter: 1013 loss: 0.00249949656
Iter: 1014 loss: 0.0024270094
Iter: 1015 loss: 0.0024281037
Iter: 1016 loss: 0.00242582452
Iter: 1017 loss: 0.002424506
Iter: 1018 loss: 0.00242108898
Iter: 1019 loss: 0.00244810479
Iter: 1020 loss: 0.00242045522
Iter: 1021 loss: 0.00241646427
Iter: 1022 loss: 0.00241349661
Iter: 1023 loss: 0.00241215643
Iter: 1024 loss: 0.00241214735
Iter: 1025 loss: 0.00240949471
Iter: 1026 loss: 0.00240604207
Iter: 1027 loss: 0.00240719877
Iter: 1028 loss: 0.0024036339
Iter: 1029 loss: 0.00239964062
Iter: 1030 loss: 0.00239882548
Iter: 1031 loss: 0.00239618821
Iter: 1032 loss: 0.00239343289
Iter: 1033 loss: 0.00238747685
Iter: 1034 loss: 0.0024793772
Iter: 1035 loss: 0.00238723354
Iter: 1036 loss: 0.0023836582
Iter: 1037 loss: 0.00239244057
Iter: 1038 loss: 0.00238233199
Iter: 1039 loss: 0.00238076
Iter: 1040 loss: 0.00237561599
Iter: 1041 loss: 0.00237801392
Iter: 1042 loss: 0.00237088092
Iter: 1043 loss: 0.00236440799
Iter: 1044 loss: 0.00236387784
Iter: 1045 loss: 0.00236013276
Iter: 1046 loss: 0.00235638488
Iter: 1047 loss: 0.00235565566
Iter: 1048 loss: 0.00234999787
Iter: 1049 loss: 0.00236078282
Iter: 1050 loss: 0.00234763254
Iter: 1051 loss: 0.00234999368
Iter: 1052 loss: 0.0023431906
Iter: 1053 loss: 0.00233821711
Iter: 1054 loss: 0.00234194635
Iter: 1055 loss: 0.00233520567
Iter: 1056 loss: 0.00233396282
Iter: 1057 loss: 0.00233377377
Iter: 1058 loss: 0.00233290764
Iter: 1059 loss: 0.0023305933
Iter: 1060 loss: 0.00232346915
Iter: 1061 loss: 0.00233976101
Iter: 1062 loss: 0.00231924816
Iter: 1063 loss: 0.00231207162
Iter: 1064 loss: 0.00240335148
Iter: 1065 loss: 0.00231199549
Iter: 1066 loss: 0.00230653211
Iter: 1067 loss: 0.00236177351
Iter: 1068 loss: 0.00230636983
Iter: 1069 loss: 0.00230500381
Iter: 1070 loss: 0.00230133859
Iter: 1071 loss: 0.0023251411
Iter: 1072 loss: 0.0023004408
Iter: 1073 loss: 0.00229512015
Iter: 1074 loss: 0.00229404634
Iter: 1075 loss: 0.00229055109
Iter: 1076 loss: 0.00228593382
Iter: 1077 loss: 0.00227814261
Iter: 1078 loss: 0.00227811839
Iter: 1079 loss: 0.00226819515
Iter: 1080 loss: 0.00231689401
Iter: 1081 loss: 0.0022665998
Iter: 1082 loss: 0.00226036366
Iter: 1083 loss: 0.00224361802
Iter: 1084 loss: 0.0023646967
Iter: 1085 loss: 0.00223981473
Iter: 1086 loss: 0.00223235413
Iter: 1087 loss: 0.00227169413
Iter: 1088 loss: 0.00223124726
Iter: 1089 loss: 0.00222805561
Iter: 1090 loss: 0.00222005323
Iter: 1091 loss: 0.00229603215
Iter: 1092 loss: 0.00221891678
Iter: 1093 loss: 0.00221596239
Iter: 1094 loss: 0.0022141973
Iter: 1095 loss: 0.00220729341
Iter: 1096 loss: 0.00229013851
Iter: 1097 loss: 0.00220718584
Iter: 1098 loss: 0.00220264145
Iter: 1099 loss: 0.00220375601
Iter: 1100 loss: 0.00219932268
Iter: 1101 loss: 0.00219426304
Iter: 1102 loss: 0.00224480801
Iter: 1103 loss: 0.00219408749
Iter: 1104 loss: 0.00219053985
Iter: 1105 loss: 0.00219236803
Iter: 1106 loss: 0.00218819012
Iter: 1107 loss: 0.00218232721
Iter: 1108 loss: 0.00226418488
Iter: 1109 loss: 0.00218230532
Iter: 1110 loss: 0.00217874581
Iter: 1111 loss: 0.0021824406
Iter: 1112 loss: 0.00217676093
Iter: 1113 loss: 0.00217389711
Iter: 1114 loss: 0.00219537178
Iter: 1115 loss: 0.00217366777
Iter: 1116 loss: 0.0021720035
Iter: 1117 loss: 0.00217256066
Iter: 1118 loss: 0.0021708135
Iter: 1119 loss: 0.00216943
Iter: 1120 loss: 0.0021689767
Iter: 1121 loss: 0.00216732733
Iter: 1122 loss: 0.0021625529
Iter: 1123 loss: 0.00218376284
Iter: 1124 loss: 0.00216075266
Iter: 1125 loss: 0.00215770514
Iter: 1126 loss: 0.00217426103
Iter: 1127 loss: 0.00215725019
Iter: 1128 loss: 0.00216150284
Iter: 1129 loss: 0.00215479149
Iter: 1130 loss: 0.00215349765
Iter: 1131 loss: 0.00215019193
Iter: 1132 loss: 0.00217849412
Iter: 1133 loss: 0.00214962428
Iter: 1134 loss: 0.00214653602
Iter: 1135 loss: 0.0021550504
Iter: 1136 loss: 0.00214552623
Iter: 1137 loss: 0.0021429169
Iter: 1138 loss: 0.00214250362
Iter: 1139 loss: 0.00214069127
Iter: 1140 loss: 0.00213811453
Iter: 1141 loss: 0.00216129422
Iter: 1142 loss: 0.00213799742
Iter: 1143 loss: 0.00213524047
Iter: 1144 loss: 0.00213796715
Iter: 1145 loss: 0.00213369261
Iter: 1146 loss: 0.00213075988
Iter: 1147 loss: 0.00213057804
Iter: 1148 loss: 0.00212725485
Iter: 1149 loss: 0.00212519499
Iter: 1150 loss: 0.00212382409
Iter: 1151 loss: 0.00212131045
Iter: 1152 loss: 0.00212112395
Iter: 1153 loss: 0.00211649435
Iter: 1154 loss: 0.00214229
Iter: 1155 loss: 0.00211580587
Iter: 1156 loss: 0.00211362215
Iter: 1157 loss: 0.00210640091
Iter: 1158 loss: 0.00210781908
Iter: 1159 loss: 0.00209924113
Iter: 1160 loss: 0.00209587137
Iter: 1161 loss: 0.00209423574
Iter: 1162 loss: 0.00208896957
Iter: 1163 loss: 0.00208781473
Iter: 1164 loss: 0.00208664569
Iter: 1165 loss: 0.00208325381
Iter: 1166 loss: 0.00209815684
Iter: 1167 loss: 0.0020819949
Iter: 1168 loss: 0.00207504421
Iter: 1169 loss: 0.00213299552
Iter: 1170 loss: 0.00207464164
Iter: 1171 loss: 0.00207274035
Iter: 1172 loss: 0.00207101274
Iter: 1173 loss: 0.00207055197
Iter: 1174 loss: 0.00206797849
Iter: 1175 loss: 0.00206696521
Iter: 1176 loss: 0.0020655829
Iter: 1177 loss: 0.00206318405
Iter: 1178 loss: 0.0020583109
Iter: 1179 loss: 0.00214081025
Iter: 1180 loss: 0.00205821777
Iter: 1181 loss: 0.002054838
Iter: 1182 loss: 0.00206052884
Iter: 1183 loss: 0.00205328921
Iter: 1184 loss: 0.00205250434
Iter: 1185 loss: 0.00205034437
Iter: 1186 loss: 0.00206319778
Iter: 1187 loss: 0.00204974692
Iter: 1188 loss: 0.00204352639
Iter: 1189 loss: 0.00204281951
Iter: 1190 loss: 0.00203833147
Iter: 1191 loss: 0.00203796499
Iter: 1192 loss: 0.00203546695
Iter: 1193 loss: 0.00203233957
Iter: 1194 loss: 0.00205003168
Iter: 1195 loss: 0.00203190604
Iter: 1196 loss: 0.00202833582
Iter: 1197 loss: 0.00205520657
Iter: 1198 loss: 0.00202803756
Iter: 1199 loss: 0.0020240664
Iter: 1200 loss: 0.00202075485
Iter: 1201 loss: 0.00201962795
Iter: 1202 loss: 0.00201581535
Iter: 1203 loss: 0.00201579067
Iter: 1204 loss: 0.00201178715
Iter: 1205 loss: 0.00201090286
Iter: 1206 loss: 0.0020082877
Iter: 1207 loss: 0.00200526975
Iter: 1208 loss: 0.00201851549
Iter: 1209 loss: 0.00200467021
Iter: 1210 loss: 0.00200395612
Iter: 1211 loss: 0.00200171117
Iter: 1212 loss: 0.00200642319
Iter: 1213 loss: 0.00200033979
Iter: 1214 loss: 0.00200039
Iter: 1215 loss: 0.00199746294
Iter: 1216 loss: 0.00199486525
Iter: 1217 loss: 0.00199242029
Iter: 1218 loss: 0.00199182238
Iter: 1219 loss: 0.00198780233
Iter: 1220 loss: 0.00199077697
Iter: 1221 loss: 0.00198533083
Iter: 1222 loss: 0.00198320672
Iter: 1223 loss: 0.00197898946
Iter: 1224 loss: 0.00206169672
Iter: 1225 loss: 0.00197895477
Iter: 1226 loss: 0.00197336893
Iter: 1227 loss: 0.00202177605
Iter: 1228 loss: 0.00197309
Iter: 1229 loss: 0.00196947204
Iter: 1230 loss: 0.00197506021
Iter: 1231 loss: 0.00196777703
Iter: 1232 loss: 0.00196275208
Iter: 1233 loss: 0.00195651269
Iter: 1234 loss: 0.00195596647
Iter: 1235 loss: 0.001951118
Iter: 1236 loss: 0.00195085595
Iter: 1237 loss: 0.00194803858
Iter: 1238 loss: 0.00194682332
Iter: 1239 loss: 0.00194535
Iter: 1240 loss: 0.00194189628
Iter: 1241 loss: 0.00193920068
Iter: 1242 loss: 0.00193811138
Iter: 1243 loss: 0.00194864091
Iter: 1244 loss: 0.00193645817
Iter: 1245 loss: 0.00193430122
Iter: 1246 loss: 0.00194925745
Iter: 1247 loss: 0.00193410146
Iter: 1248 loss: 0.00193301053
Iter: 1249 loss: 0.00192955078
Iter: 1250 loss: 0.00193378795
Iter: 1251 loss: 0.00192694657
Iter: 1252 loss: 0.001922403
Iter: 1253 loss: 0.00192744564
Iter: 1254 loss: 0.00191994384
Iter: 1255 loss: 0.00191552576
Iter: 1256 loss: 0.00191698887
Iter: 1257 loss: 0.00191246101
Iter: 1258 loss: 0.00190637796
Iter: 1259 loss: 0.00191377418
Iter: 1260 loss: 0.0019031734
Iter: 1261 loss: 0.00189984485
Iter: 1262 loss: 0.00189385051
Iter: 1263 loss: 0.00203690818
Iter: 1264 loss: 0.00189386541
Iter: 1265 loss: 0.00188633148
Iter: 1266 loss: 0.00199520937
Iter: 1267 loss: 0.00188631087
Iter: 1268 loss: 0.00188257289
Iter: 1269 loss: 0.00189147075
Iter: 1270 loss: 0.00188121491
Iter: 1271 loss: 0.00187839731
Iter: 1272 loss: 0.00190867833
Iter: 1273 loss: 0.00187832094
Iter: 1274 loss: 0.00187568937
Iter: 1275 loss: 0.00187576481
Iter: 1276 loss: 0.00187360158
Iter: 1277 loss: 0.00186985312
Iter: 1278 loss: 0.00189561176
Iter: 1279 loss: 0.00186950504
Iter: 1280 loss: 0.00186683261
Iter: 1281 loss: 0.00186922215
Iter: 1282 loss: 0.00186525541
Iter: 1283 loss: 0.00186287437
Iter: 1284 loss: 0.00187273812
Iter: 1285 loss: 0.00186238938
Iter: 1286 loss: 0.00186065095
Iter: 1287 loss: 0.00186437403
Iter: 1288 loss: 0.00185997586
Iter: 1289 loss: 0.00185644394
Iter: 1290 loss: 0.00185281073
Iter: 1291 loss: 0.00185211631
Iter: 1292 loss: 0.00184906553
Iter: 1293 loss: 0.00184835494
Iter: 1294 loss: 0.00184476608
Iter: 1295 loss: 0.00183969876
Iter: 1296 loss: 0.00183950725
Iter: 1297 loss: 0.00183510571
Iter: 1298 loss: 0.00183838815
Iter: 1299 loss: 0.0018323909
Iter: 1300 loss: 0.00182840077
Iter: 1301 loss: 0.00186738686
Iter: 1302 loss: 0.00182825769
Iter: 1303 loss: 0.00182542251
Iter: 1304 loss: 0.00183258089
Iter: 1305 loss: 0.00182444393
Iter: 1306 loss: 0.00182194519
Iter: 1307 loss: 0.00183057552
Iter: 1308 loss: 0.00182128279
Iter: 1309 loss: 0.00181956845
Iter: 1310 loss: 0.00181948917
Iter: 1311 loss: 0.00181850418
Iter: 1312 loss: 0.00181775051
Iter: 1313 loss: 0.00181743363
Iter: 1314 loss: 0.00181637367
Iter: 1315 loss: 0.00181630603
Iter: 1316 loss: 0.00181542488
Iter: 1317 loss: 0.00181339844
Iter: 1318 loss: 0.00183889631
Iter: 1319 loss: 0.00181326631
Iter: 1320 loss: 0.00181091717
Iter: 1321 loss: 0.00180602469
Iter: 1322 loss: 0.00189405924
Iter: 1323 loss: 0.00180592411
Iter: 1324 loss: 0.00180250057
Iter: 1325 loss: 0.00180567603
Iter: 1326 loss: 0.00180054386
Iter: 1327 loss: 0.0017968358
Iter: 1328 loss: 0.0018341234
Iter: 1329 loss: 0.00179670088
Iter: 1330 loss: 0.00179277151
Iter: 1331 loss: 0.00179383252
Iter: 1332 loss: 0.00178990909
Iter: 1333 loss: 0.00178600138
Iter: 1334 loss: 0.00178875821
Iter: 1335 loss: 0.00178355619
Iter: 1336 loss: 0.00177866779
Iter: 1337 loss: 0.00179543486
Iter: 1338 loss: 0.00177735835
Iter: 1339 loss: 0.00177268393
Iter: 1340 loss: 0.00178001181
Iter: 1341 loss: 0.00177050778
Iter: 1342 loss: 0.00177226914
Iter: 1343 loss: 0.00176942174
Iter: 1344 loss: 0.00176809658
Iter: 1345 loss: 0.00176715502
Iter: 1346 loss: 0.00176666991
Iter: 1347 loss: 0.00176442193
Iter: 1348 loss: 0.00176707364
Iter: 1349 loss: 0.00176325161
Iter: 1350 loss: 0.00176020339
Iter: 1351 loss: 0.00178487471
Iter: 1352 loss: 0.00176000455
Iter: 1353 loss: 0.00175918883
Iter: 1354 loss: 0.00175867265
Iter: 1355 loss: 0.00175836158
Iter: 1356 loss: 0.00175653584
Iter: 1357 loss: 0.00175674632
Iter: 1358 loss: 0.00175514352
Iter: 1359 loss: 0.00175237632
Iter: 1360 loss: 0.00174915115
Iter: 1361 loss: 0.00174878864
Iter: 1362 loss: 0.0017454566
Iter: 1363 loss: 0.00177902263
Iter: 1364 loss: 0.00174533366
Iter: 1365 loss: 0.00174373598
Iter: 1366 loss: 0.00174175028
Iter: 1367 loss: 0.00174157636
Iter: 1368 loss: 0.00173906935
Iter: 1369 loss: 0.00173312286
Iter: 1370 loss: 0.00180389592
Iter: 1371 loss: 0.0017325792
Iter: 1372 loss: 0.00172948395
Iter: 1373 loss: 0.00172817474
Iter: 1374 loss: 0.0017396803
Iter: 1375 loss: 0.00172719685
Iter: 1376 loss: 0.00172661606
Iter: 1377 loss: 0.00172722701
Iter: 1378 loss: 0.00172627368
Iter: 1379 loss: 0.00172557204
Iter: 1380 loss: 0.00172317179
Iter: 1381 loss: 0.00172202569
Iter: 1382 loss: 0.00172033987
Iter: 1383 loss: 0.00175958744
Iter: 1384 loss: 0.00171677559
Iter: 1385 loss: 0.00171290315
Iter: 1386 loss: 0.00172462873
Iter: 1387 loss: 0.00171176693
Iter: 1388 loss: 0.00170812185
Iter: 1389 loss: 0.00170151319
Iter: 1390 loss: 0.00185685989
Iter: 1391 loss: 0.00170150946
Iter: 1392 loss: 0.001700597
Iter: 1393 loss: 0.00169885706
Iter: 1394 loss: 0.00169653818
Iter: 1395 loss: 0.00169383246
Iter: 1396 loss: 0.00169352721
Iter: 1397 loss: 0.00168816885
Iter: 1398 loss: 0.00168811413
Iter: 1399 loss: 0.00168385159
Iter: 1400 loss: 0.00167673547
Iter: 1401 loss: 0.00167656713
Iter: 1402 loss: 0.00167477503
Iter: 1403 loss: 0.00167040213
Iter: 1404 loss: 0.00171715161
Iter: 1405 loss: 0.00166987185
Iter: 1406 loss: 0.00166721491
Iter: 1407 loss: 0.00167315803
Iter: 1408 loss: 0.00166623225
Iter: 1409 loss: 0.00166548917
Iter: 1410 loss: 0.00166383921
Iter: 1411 loss: 0.00168749678
Iter: 1412 loss: 0.0016637498
Iter: 1413 loss: 0.00165995758
Iter: 1414 loss: 0.0016684155
Iter: 1415 loss: 0.00165851659
Iter: 1416 loss: 0.00165408966
Iter: 1417 loss: 0.00166069623
Iter: 1418 loss: 0.00165194622
Iter: 1419 loss: 0.00164801977
Iter: 1420 loss: 0.00164954877
Iter: 1421 loss: 0.00164532603
Iter: 1422 loss: 0.00163861865
Iter: 1423 loss: 0.00163861329
Iter: 1424 loss: 0.00163621688
Iter: 1425 loss: 0.00164449716
Iter: 1426 loss: 0.00163558475
Iter: 1427 loss: 0.00163368252
Iter: 1428 loss: 0.00163158
Iter: 1429 loss: 0.00163126993
Iter: 1430 loss: 0.00162724406
Iter: 1431 loss: 0.00168249593
Iter: 1432 loss: 0.0016272366
Iter: 1433 loss: 0.00162500655
Iter: 1434 loss: 0.00162931369
Iter: 1435 loss: 0.00162409968
Iter: 1436 loss: 0.00162250048
Iter: 1437 loss: 0.00162246777
Iter: 1438 loss: 0.00162158837
Iter: 1439 loss: 0.0016229644
Iter: 1440 loss: 0.00162118813
Iter: 1441 loss: 0.00162039266
Iter: 1442 loss: 0.00161967799
Iter: 1443 loss: 0.00161948241
Iter: 1444 loss: 0.00161804573
Iter: 1445 loss: 0.00161461346
Iter: 1446 loss: 0.00165315229
Iter: 1447 loss: 0.00161427539
Iter: 1448 loss: 0.00160972483
Iter: 1449 loss: 0.00162693276
Iter: 1450 loss: 0.00160863483
Iter: 1451 loss: 0.00160332932
Iter: 1452 loss: 0.00164463266
Iter: 1453 loss: 0.00160292455
Iter: 1454 loss: 0.00159994466
Iter: 1455 loss: 0.00159857934
Iter: 1456 loss: 0.00159596663
Iter: 1457 loss: 0.0016040398
Iter: 1458 loss: 0.0015952317
Iter: 1459 loss: 0.00159259955
Iter: 1460 loss: 0.001585469
Iter: 1461 loss: 0.00163119636
Iter: 1462 loss: 0.00158364046
Iter: 1463 loss: 0.00157854124
Iter: 1464 loss: 0.00157823903
Iter: 1465 loss: 0.0015740121
Iter: 1466 loss: 0.00158088095
Iter: 1467 loss: 0.00157206459
Iter: 1468 loss: 0.00156855886
Iter: 1469 loss: 0.00158751686
Iter: 1470 loss: 0.00156807236
Iter: 1471 loss: 0.00157034269
Iter: 1472 loss: 0.00156660983
Iter: 1473 loss: 0.00156613754
Iter: 1474 loss: 0.00156468421
Iter: 1475 loss: 0.00156665104
Iter: 1476 loss: 0.00156360539
Iter: 1477 loss: 0.00156169548
Iter: 1478 loss: 0.00156130875
Iter: 1479 loss: 0.00155951676
Iter: 1480 loss: 0.00156100909
Iter: 1481 loss: 0.00155845913
Iter: 1482 loss: 0.00155718985
Iter: 1483 loss: 0.00155697321
Iter: 1484 loss: 0.00155611488
Iter: 1485 loss: 0.00155510125
Iter: 1486 loss: 0.00155248446
Iter: 1487 loss: 0.00157320965
Iter: 1488 loss: 0.0015519989
Iter: 1489 loss: 0.00155204954
Iter: 1490 loss: 0.00155004091
Iter: 1491 loss: 0.00154848094
Iter: 1492 loss: 0.00154737732
Iter: 1493 loss: 0.00154680666
Iter: 1494 loss: 0.00154525856
Iter: 1495 loss: 0.00154690351
Iter: 1496 loss: 0.00154439849
Iter: 1497 loss: 0.00154200394
Iter: 1498 loss: 0.00154694577
Iter: 1499 loss: 0.00154103548
Iter: 1500 loss: 0.00153839681
Iter: 1501 loss: 0.00155380019
Iter: 1502 loss: 0.0015380549
Iter: 1503 loss: 0.00153914012
Iter: 1504 loss: 0.00153728994
Iter: 1505 loss: 0.00153627526
Iter: 1506 loss: 0.00153432856
Iter: 1507 loss: 0.00157490815
Iter: 1508 loss: 0.00153431483
Iter: 1509 loss: 0.00153193239
Iter: 1510 loss: 0.00155665516
Iter: 1511 loss: 0.00153185194
Iter: 1512 loss: 0.0015307318
Iter: 1513 loss: 0.00152773561
Iter: 1514 loss: 0.00154904381
Iter: 1515 loss: 0.00152707403
Iter: 1516 loss: 0.00152451801
Iter: 1517 loss: 0.00152436201
Iter: 1518 loss: 0.00152210833
Iter: 1519 loss: 0.00152094825
Iter: 1520 loss: 0.00151988538
Iter: 1521 loss: 0.001516046
Iter: 1522 loss: 0.00151502085
Iter: 1523 loss: 0.00151235471
Iter: 1524 loss: 0.00151152909
Iter: 1525 loss: 0.00151029555
Iter: 1526 loss: 0.00150928041
Iter: 1527 loss: 0.00150892232
Iter: 1528 loss: 0.00150686968
Iter: 1529 loss: 0.00150430622
Iter: 1530 loss: 0.00150410656
Iter: 1531 loss: 0.00150235265
Iter: 1532 loss: 0.00150096277
Iter: 1533 loss: 0.00150044099
Iter: 1534 loss: 0.00149910199
Iter: 1535 loss: 0.00151079381
Iter: 1536 loss: 0.00149902701
Iter: 1537 loss: 0.00149800722
Iter: 1538 loss: 0.00149963307
Iter: 1539 loss: 0.00149754179
Iter: 1540 loss: 0.0014952824
Iter: 1541 loss: 0.00150859985
Iter: 1542 loss: 0.00149499555
Iter: 1543 loss: 0.0014933605
Iter: 1544 loss: 0.00149274583
Iter: 1545 loss: 0.00149184023
Iter: 1546 loss: 0.00151993823
Iter: 1547 loss: 0.00148947793
Iter: 1548 loss: 0.00148659036
Iter: 1549 loss: 0.00148974638
Iter: 1550 loss: 0.00148501107
Iter: 1551 loss: 0.00148391596
Iter: 1552 loss: 0.00148127554
Iter: 1553 loss: 0.00151003501
Iter: 1554 loss: 0.00148100802
Iter: 1555 loss: 0.00147897401
Iter: 1556 loss: 0.00148071093
Iter: 1557 loss: 0.00147777912
Iter: 1558 loss: 0.0014760117
Iter: 1559 loss: 0.00148371607
Iter: 1560 loss: 0.00147566246
Iter: 1561 loss: 0.00147427525
Iter: 1562 loss: 0.00147426827
Iter: 1563 loss: 0.00147334195
Iter: 1564 loss: 0.00147293229
Iter: 1565 loss: 0.00147246756
Iter: 1566 loss: 0.00147083891
Iter: 1567 loss: 0.00146936555
Iter: 1568 loss: 0.00146896672
Iter: 1569 loss: 0.00147310516
Iter: 1570 loss: 0.00146811502
Iter: 1571 loss: 0.00146737415
Iter: 1572 loss: 0.00146656879
Iter: 1573 loss: 0.00146645808
Iter: 1574 loss: 0.00146568147
Iter: 1575 loss: 0.0014640888
Iter: 1576 loss: 0.00149376807
Iter: 1577 loss: 0.00146406807
Iter: 1578 loss: 0.00146175502
Iter: 1579 loss: 0.00145785464
Iter: 1580 loss: 0.00145786314
Iter: 1581 loss: 0.00145923975
Iter: 1582 loss: 0.00145652797
Iter: 1583 loss: 0.00145574892
Iter: 1584 loss: 0.00145575544
Iter: 1585 loss: 0.00145512016
Iter: 1586 loss: 0.0014539042
Iter: 1587 loss: 0.00145110069
Iter: 1588 loss: 0.00148740818
Iter: 1589 loss: 0.00145090953
Iter: 1590 loss: 0.00144903688
Iter: 1591 loss: 0.00145593495
Iter: 1592 loss: 0.00144857098
Iter: 1593 loss: 0.0014467627
Iter: 1594 loss: 0.00147251203
Iter: 1595 loss: 0.00144677027
Iter: 1596 loss: 0.00144503021
Iter: 1597 loss: 0.00146966253
Iter: 1598 loss: 0.00144502427
Iter: 1599 loss: 0.0014441153
Iter: 1600 loss: 0.0014420175
Iter: 1601 loss: 0.00146710756
Iter: 1602 loss: 0.00144185568
Iter: 1603 loss: 0.0014394226
Iter: 1604 loss: 0.00146985974
Iter: 1605 loss: 0.00143938581
Iter: 1606 loss: 0.00143672724
Iter: 1607 loss: 0.00145971763
Iter: 1608 loss: 0.00143660209
Iter: 1609 loss: 0.00143580488
Iter: 1610 loss: 0.00143406319
Iter: 1611 loss: 0.00145988038
Iter: 1612 loss: 0.00143398298
Iter: 1613 loss: 0.00142994488
Iter: 1614 loss: 0.00143498252
Iter: 1615 loss: 0.00142786512
Iter: 1616 loss: 0.00142676989
Iter: 1617 loss: 0.00142647279
Iter: 1618 loss: 0.0014254027
Iter: 1619 loss: 0.00142910518
Iter: 1620 loss: 0.00142512342
Iter: 1621 loss: 0.00142396521
Iter: 1622 loss: 0.00142633286
Iter: 1623 loss: 0.00142349675
Iter: 1624 loss: 0.00142235984
Iter: 1625 loss: 0.0014192044
Iter: 1626 loss: 0.00143646449
Iter: 1627 loss: 0.0014182434
Iter: 1628 loss: 0.00141547958
Iter: 1629 loss: 0.00142510305
Iter: 1630 loss: 0.00141473964
Iter: 1631 loss: 0.00141293113
Iter: 1632 loss: 0.00142503495
Iter: 1633 loss: 0.0014127593
Iter: 1634 loss: 0.00141032506
Iter: 1635 loss: 0.00140702119
Iter: 1636 loss: 0.00140687393
Iter: 1637 loss: 0.00140581094
Iter: 1638 loss: 0.00140469708
Iter: 1639 loss: 0.00140315923
Iter: 1640 loss: 0.00140748825
Iter: 1641 loss: 0.00140266691
Iter: 1642 loss: 0.00140117644
Iter: 1643 loss: 0.00139695336
Iter: 1644 loss: 0.00141742639
Iter: 1645 loss: 0.00139551191
Iter: 1646 loss: 0.00139175938
Iter: 1647 loss: 0.00139304006
Iter: 1648 loss: 0.00138913468
Iter: 1649 loss: 0.00138584431
Iter: 1650 loss: 0.00139798131
Iter: 1651 loss: 0.00138502615
Iter: 1652 loss: 0.00138341985
Iter: 1653 loss: 0.00138320914
Iter: 1654 loss: 0.00138204126
Iter: 1655 loss: 0.00138542708
Iter: 1656 loss: 0.00138166873
Iter: 1657 loss: 0.00138017908
Iter: 1658 loss: 0.0013801048
Iter: 1659 loss: 0.00137895369
Iter: 1660 loss: 0.00137723843
Iter: 1661 loss: 0.00137347099
Iter: 1662 loss: 0.00142907794
Iter: 1663 loss: 0.00137327542
Iter: 1664 loss: 0.00136845326
Iter: 1665 loss: 0.00138320145
Iter: 1666 loss: 0.00136702741
Iter: 1667 loss: 0.00136241654
Iter: 1668 loss: 0.00139338209
Iter: 1669 loss: 0.00136196753
Iter: 1670 loss: 0.00136044784
Iter: 1671 loss: 0.00136554695
Iter: 1672 loss: 0.00136002898
Iter: 1673 loss: 0.00135878427
Iter: 1674 loss: 0.00137191056
Iter: 1675 loss: 0.00135875796
Iter: 1676 loss: 0.00135812315
Iter: 1677 loss: 0.00135637308
Iter: 1678 loss: 0.00136677304
Iter: 1679 loss: 0.00135591102
Iter: 1680 loss: 0.00135315198
Iter: 1681 loss: 0.00136522658
Iter: 1682 loss: 0.00135259272
Iter: 1683 loss: 0.00135163451
Iter: 1684 loss: 0.0013506161
Iter: 1685 loss: 0.00134911505
Iter: 1686 loss: 0.00135801442
Iter: 1687 loss: 0.00134892529
Iter: 1688 loss: 0.00134800444
Iter: 1689 loss: 0.00134702655
Iter: 1690 loss: 0.00134685822
Iter: 1691 loss: 0.00134415959
Iter: 1692 loss: 0.00134957256
Iter: 1693 loss: 0.00134305225
Iter: 1694 loss: 0.00134156086
Iter: 1695 loss: 0.00134136993
Iter: 1696 loss: 0.00134030893
Iter: 1697 loss: 0.00133832858
Iter: 1698 loss: 0.00134126365
Iter: 1699 loss: 0.00133739086
Iter: 1700 loss: 0.00133530376
Iter: 1701 loss: 0.0013359841
Iter: 1702 loss: 0.00133380271
Iter: 1703 loss: 0.00133020384
Iter: 1704 loss: 0.00133279781
Iter: 1705 loss: 0.00132797053
Iter: 1706 loss: 0.00132760697
Iter: 1707 loss: 0.00132709555
Iter: 1708 loss: 0.00132568902
Iter: 1709 loss: 0.00132253242
Iter: 1710 loss: 0.00136461144
Iter: 1711 loss: 0.00132233964
Iter: 1712 loss: 0.00131872855
Iter: 1713 loss: 0.0013196168
Iter: 1714 loss: 0.00131608988
Iter: 1715 loss: 0.00132035417
Iter: 1716 loss: 0.00131432875
Iter: 1717 loss: 0.0013131249
Iter: 1718 loss: 0.00131514203
Iter: 1719 loss: 0.00131256972
Iter: 1720 loss: 0.00131158938
Iter: 1721 loss: 0.00130956958
Iter: 1722 loss: 0.00134439324
Iter: 1723 loss: 0.00130953989
Iter: 1724 loss: 0.00130759133
Iter: 1725 loss: 0.00130550656
Iter: 1726 loss: 0.00130516128
Iter: 1727 loss: 0.00130268733
Iter: 1728 loss: 0.00131115294
Iter: 1729 loss: 0.0013020339
Iter: 1730 loss: 0.00129945658
Iter: 1731 loss: 0.00129988696
Iter: 1732 loss: 0.00129749649
Iter: 1733 loss: 0.00129343546
Iter: 1734 loss: 0.00129192788
Iter: 1735 loss: 0.0012896643
Iter: 1736 loss: 0.00129434827
Iter: 1737 loss: 0.00128775067
Iter: 1738 loss: 0.0012865226
Iter: 1739 loss: 0.00128638209
Iter: 1740 loss: 0.001285495
Iter: 1741 loss: 0.00128389266
Iter: 1742 loss: 0.00128326006
Iter: 1743 loss: 0.00128224795
Iter: 1744 loss: 0.00128327683
Iter: 1745 loss: 0.00128168333
Iter: 1746 loss: 0.00128033245
Iter: 1747 loss: 0.00127702137
Iter: 1748 loss: 0.00131208193
Iter: 1749 loss: 0.00127663347
Iter: 1750 loss: 0.00127670309
Iter: 1751 loss: 0.00127501809
Iter: 1752 loss: 0.0012733686
Iter: 1753 loss: 0.00127636222
Iter: 1754 loss: 0.00127265649
Iter: 1755 loss: 0.00127183762
Iter: 1756 loss: 0.00127060665
Iter: 1757 loss: 0.00127058476
Iter: 1758 loss: 0.00126880803
Iter: 1759 loss: 0.0012684667
Iter: 1760 loss: 0.00126730325
Iter: 1761 loss: 0.00126421987
Iter: 1762 loss: 0.00126191764
Iter: 1763 loss: 0.00126089714
Iter: 1764 loss: 0.00125658652
Iter: 1765 loss: 0.00131361349
Iter: 1766 loss: 0.00125656056
Iter: 1767 loss: 0.00125489954
Iter: 1768 loss: 0.00125328056
Iter: 1769 loss: 0.0012529213
Iter: 1770 loss: 0.00125025818
Iter: 1771 loss: 0.00126912107
Iter: 1772 loss: 0.00125003117
Iter: 1773 loss: 0.0012506
Iter: 1774 loss: 0.00124935643
Iter: 1775 loss: 0.00124874711
Iter: 1776 loss: 0.00124813628
Iter: 1777 loss: 0.00124801707
Iter: 1778 loss: 0.00124672626
Iter: 1779 loss: 0.00124406419
Iter: 1780 loss: 0.00128950179
Iter: 1781 loss: 0.00124399969
Iter: 1782 loss: 0.00124428119
Iter: 1783 loss: 0.00124306697
Iter: 1784 loss: 0.00124221505
Iter: 1785 loss: 0.00124680903
Iter: 1786 loss: 0.00124209
Iter: 1787 loss: 0.00124139222
Iter: 1788 loss: 0.00123939058
Iter: 1789 loss: 0.0012476031
Iter: 1790 loss: 0.00123856706
Iter: 1791 loss: 0.00123489753
Iter: 1792 loss: 0.00124404486
Iter: 1793 loss: 0.00123359892
Iter: 1794 loss: 0.00123138865
Iter: 1795 loss: 0.00123693142
Iter: 1796 loss: 0.00123060192
Iter: 1797 loss: 0.00122837257
Iter: 1798 loss: 0.00123572606
Iter: 1799 loss: 0.00122775696
Iter: 1800 loss: 0.00122519024
Iter: 1801 loss: 0.00123015034
Iter: 1802 loss: 0.00122412224
Iter: 1803 loss: 0.00122285262
Iter: 1804 loss: 0.00122469827
Iter: 1805 loss: 0.00122224481
Iter: 1806 loss: 0.00122127053
Iter: 1807 loss: 0.00122083107
Iter: 1808 loss: 0.00122021814
Iter: 1809 loss: 0.00122120872
Iter: 1810 loss: 0.00121992547
Iter: 1811 loss: 0.00121949823
Iter: 1812 loss: 0.00121889659
Iter: 1813 loss: 0.0012188768
Iter: 1814 loss: 0.00121730566
Iter: 1815 loss: 0.00123213464
Iter: 1816 loss: 0.00121723651
Iter: 1817 loss: 0.00121495803
Iter: 1818 loss: 0.00122575485
Iter: 1819 loss: 0.00121453544
Iter: 1820 loss: 0.00121280248
Iter: 1821 loss: 0.00122398511
Iter: 1822 loss: 0.00121261517
Iter: 1823 loss: 0.00121152541
Iter: 1824 loss: 0.00121353054
Iter: 1825 loss: 0.00121104612
Iter: 1826 loss: 0.00120989524
Iter: 1827 loss: 0.00120989955
Iter: 1828 loss: 0.00120897125
Iter: 1829 loss: 0.00120789
Iter: 1830 loss: 0.00120769418
Iter: 1831 loss: 0.00120696565
Iter: 1832 loss: 0.00120478799
Iter: 1833 loss: 0.00121240458
Iter: 1834 loss: 0.00120424561
Iter: 1835 loss: 0.00120208249
Iter: 1836 loss: 0.00122298591
Iter: 1837 loss: 0.00120200845
Iter: 1838 loss: 0.00120259251
Iter: 1839 loss: 0.00120154745
Iter: 1840 loss: 0.00120128877
Iter: 1841 loss: 0.00120252185
Iter: 1842 loss: 0.00120124314
Iter: 1843 loss: 0.00120096642
Iter: 1844 loss: 0.0012000585
Iter: 1845 loss: 0.0011999954
Iter: 1846 loss: 0.00119908503
Iter: 1847 loss: 0.00119736593
Iter: 1848 loss: 0.00119686173
Iter: 1849 loss: 0.00119581108
Iter: 1850 loss: 0.00119439792
Iter: 1851 loss: 0.0011976622
Iter: 1852 loss: 0.00119386928
Iter: 1853 loss: 0.00119294459
Iter: 1854 loss: 0.00119293644
Iter: 1855 loss: 0.00119244365
Iter: 1856 loss: 0.0011919213
Iter: 1857 loss: 0.0011918291
Iter: 1858 loss: 0.00119026727
Iter: 1859 loss: 0.00119406858
Iter: 1860 loss: 0.00118971127
Iter: 1861 loss: 0.00118789368
Iter: 1862 loss: 0.00118457805
Iter: 1863 loss: 0.00126223767
Iter: 1864 loss: 0.00118457247
Iter: 1865 loss: 0.00118254405
Iter: 1866 loss: 0.00118457817
Iter: 1867 loss: 0.00118141063
Iter: 1868 loss: 0.00118002831
Iter: 1869 loss: 0.00117748755
Iter: 1870 loss: 0.00123360718
Iter: 1871 loss: 0.00117748731
Iter: 1872 loss: 0.00119005062
Iter: 1873 loss: 0.00117711956
Iter: 1874 loss: 0.00117683772
Iter: 1875 loss: 0.00117657916
Iter: 1876 loss: 0.00117651606
Iter: 1877 loss: 0.0011758412
Iter: 1878 loss: 0.00117394794
Iter: 1879 loss: 0.00118391274
Iter: 1880 loss: 0.00117335131
Iter: 1881 loss: 0.00117027352
Iter: 1882 loss: 0.00118525419
Iter: 1883 loss: 0.00116973405
Iter: 1884 loss: 0.00117291417
Iter: 1885 loss: 0.00116865942
Iter: 1886 loss: 0.00116768316
Iter: 1887 loss: 0.00116587477
Iter: 1888 loss: 0.00120787346
Iter: 1889 loss: 0.00116587302
Iter: 1890 loss: 0.00116631272
Iter: 1891 loss: 0.0011633297
Iter: 1892 loss: 0.00116129243
Iter: 1893 loss: 0.00116937875
Iter: 1894 loss: 0.00116081676
Iter: 1895 loss: 0.00116003829
Iter: 1896 loss: 0.00115790125
Iter: 1897 loss: 0.00117130403
Iter: 1898 loss: 0.00115734979
Iter: 1899 loss: 0.00115544058
Iter: 1900 loss: 0.0011554237
Iter: 1901 loss: 0.00115373405
Iter: 1902 loss: 0.00115250098
Iter: 1903 loss: 0.0011519175
Iter: 1904 loss: 0.00115159596
Iter: 1905 loss: 0.00115097058
Iter: 1906 loss: 0.00114996056
Iter: 1907 loss: 0.00114992412
Iter: 1908 loss: 0.00114959502
Iter: 1909 loss: 0.00114853086
Iter: 1910 loss: 0.00114907755
Iter: 1911 loss: 0.00114756101
Iter: 1912 loss: 0.00114571035
Iter: 1913 loss: 0.00114830164
Iter: 1914 loss: 0.00114479824
Iter: 1915 loss: 0.00114412
Iter: 1916 loss: 0.00114545261
Iter: 1917 loss: 0.00114384154
Iter: 1918 loss: 0.00114272512
Iter: 1919 loss: 0.00114054151
Iter: 1920 loss: 0.00118377479
Iter: 1921 loss: 0.00114052114
Iter: 1922 loss: 0.00113848667
Iter: 1923 loss: 0.00114136492
Iter: 1924 loss: 0.00113748293
Iter: 1925 loss: 0.00113649399
Iter: 1926 loss: 0.00113803055
Iter: 1927 loss: 0.00113603822
Iter: 1928 loss: 0.00113535183
Iter: 1929 loss: 0.00113507546
Iter: 1930 loss: 0.00113471271
Iter: 1931 loss: 0.00113415183
Iter: 1932 loss: 0.00113308185
Iter: 1933 loss: 0.00115656503
Iter: 1934 loss: 0.00113307685
Iter: 1935 loss: 0.00113243889
Iter: 1936 loss: 0.0011314326
Iter: 1937 loss: 0.00113142
Iter: 1938 loss: 0.00113060407
Iter: 1939 loss: 0.00113131979
Iter: 1940 loss: 0.00113012549
Iter: 1941 loss: 0.00113792415
Iter: 1942 loss: 0.00112881581
Iter: 1943 loss: 0.00112728868
Iter: 1944 loss: 0.00112772814
Iter: 1945 loss: 0.0011261903
Iter: 1946 loss: 0.00112401461
Iter: 1947 loss: 0.00112614851
Iter: 1948 loss: 0.00112277456
Iter: 1949 loss: 0.00112069841
Iter: 1950 loss: 0.00115165324
Iter: 1951 loss: 0.00112069782
Iter: 1952 loss: 0.00111761643
Iter: 1953 loss: 0.00113372935
Iter: 1954 loss: 0.00111715565
Iter: 1955 loss: 0.00111593457
Iter: 1956 loss: 0.00112296711
Iter: 1957 loss: 0.00111576053
Iter: 1958 loss: 0.00111522665
Iter: 1959 loss: 0.00111341861
Iter: 1960 loss: 0.00111245853
Iter: 1961 loss: 0.00111122592
Iter: 1962 loss: 0.00110505288
Iter: 1963 loss: 0.00116181758
Iter: 1964 loss: 0.00110477721
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8
+ date
Tue Oct 27 16:31:39 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a4a2551e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a8df73730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a8df73ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a4a178f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a4a17d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a4a178488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a240766a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a240a77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a240301e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a24030730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a107e69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a107868c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a10786840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a107b2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a107b2e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a10760598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a1071d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a107609d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a106907b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a10698f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a106b4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a1065dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a106286a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a105cb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a105d7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a105ec2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a105b1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a105b19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a105b12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a10512b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a104c9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a104e31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a104e3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a1047eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a104b4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0a104b4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.109158441
Iter: 2 loss: 5.79836702
Iter: 3 loss: 5.79659605
Iter: 4 loss: 3.85313511
Iter: 5 loss: 3.85188746
Iter: 6 loss: 2.65938282
Iter: 7 loss: 2.65835762
Iter: 8 loss: 1.88086498
Iter: 9 loss: 1.87998247
Iter: 10 loss: 1.36914206
Iter: 11 loss: 1.36835837
Iter: 12 loss: 1.01654387
Iter: 13 loss: 1.01573431
Iter: 14 loss: 0.754814446
Iter: 15 loss: 0.753867507
Iter: 16 loss: 0.550425887
Iter: 17 loss: 0.54923588
Iter: 18 loss: 0.389306694
Iter: 19 loss: 0.387888134
Iter: 20 loss: 0.267784059
Iter: 21 loss: 0.266248524
Iter: 22 loss: 0.179167941
Iter: 23 loss: 0.17757228
Iter: 24 loss: 0.116001852
Iter: 25 loss: 0.114471912
Iter: 26 loss: 0.0749275163
Iter: 27 loss: 0.0739002675
Iter: 28 loss: 0.0726622865
Iter: 29 loss: 0.0677435845
Iter: 30 loss: 0.0498621762
Iter: 31 loss: 1219.35901
Iter: 32 loss: 0.0498621762
Iter: 33 loss: 0.0504351705
Iter: 34 loss: 0.0478502512
Iter: 35 loss: 541.76532
Iter: 36 loss: 1402.28662
Iter: 37 loss: 0.0449517891
Iter: 38 loss: 0.0441366434
Iter: 39 loss: 749.955505
Iter: 40 loss: 0.04413528
Iter: 41 loss: 201.850967
Iter: 42 loss: 0.0484067909
Iter: 43 loss: 0.0429289564
Iter: 44 loss: 0.0407337472
Iter: 45 loss: 0.0407332331
Iter: 46 loss: 0.036812596
Iter: 47 loss: 0.049628783
Iter: 48 loss: 0.0369650163
Iter: 49 loss: 0.0353973918
Iter: 50 loss: 0.0333522111
Iter: 51 loss: 0.0331883617
Iter: 52 loss: 0.0306551941
Iter: 53 loss: 0.0453357473
Iter: 54 loss: 0.0297980793
Iter: 55 loss: 0.0279158093
Iter: 56 loss: 0.0278973393
Iter: 57 loss: 0.026789695
Iter: 58 loss: 0.0281847697
Iter: 59 loss: 0.0263538212
Iter: 60 loss: 0.0248573814
Iter: 61 loss: 0.0245774388
Iter: 62 loss: 0.0233973712
Iter: 63 loss: 0.0217996277
Iter: 64 loss: 0.0252388455
Iter: 65 loss: 0.0212397985
Iter: 66 loss: 0.019961955
Iter: 67 loss: 0.0244682208
Iter: 68 loss: 0.0198448263
Iter: 69 loss: 0.0189121477
Iter: 70 loss: 0.0260288175
Iter: 71 loss: 0.0187098756
Iter: 72 loss: 0.0180504359
Iter: 73 loss: 0.0380963
Iter: 74 loss: 0.0180392172
Iter: 75 loss: 0.0174606852
Iter: 76 loss: 0.0187740233
Iter: 77 loss: 0.0172426421
Iter: 78 loss: 0.0165983923
Iter: 79 loss: 0.0173061267
Iter: 80 loss: 0.016417291
Iter: 81 loss: 0.0160300098
Iter: 82 loss: 0.0164130479
Iter: 83 loss: 0.015783865
Iter: 84 loss: 0.0154229747
Iter: 85 loss: 0.015531525
Iter: 86 loss: 0.0151479309
Iter: 87 loss: 0.0146422274
Iter: 88 loss: 0.0148242451
Iter: 89 loss: 0.0143286288
Iter: 90 loss: 0.0139689734
Iter: 91 loss: 0.0144767063
Iter: 92 loss: 0.0137749333
Iter: 93 loss: 0.0132937962
Iter: 94 loss: 0.0151462834
Iter: 95 loss: 0.0131582422
Iter: 96 loss: 0.0124404337
Iter: 97 loss: 0.0180842131
Iter: 98 loss: 0.0124232471
Iter: 99 loss: 0.0120263994
Iter: 100 loss: 0.0283263642
Iter: 101 loss: 0.0120241875
Iter: 102 loss: 0.0114863543
Iter: 103 loss: 0.011808686
Iter: 104 loss: 0.0111688338
Iter: 105 loss: 0.0109204585
Iter: 106 loss: 0.0108785937
Iter: 107 loss: 0.0107226083
Iter: 108 loss: 0.0110671697
Iter: 109 loss: 0.0106621282
Iter: 110 loss: 0.0103230588
Iter: 111 loss: 0.0103562335
Iter: 112 loss: 0.0100622429
Iter: 113 loss: 0.00978958793
Iter: 114 loss: 0.0117735937
Iter: 115 loss: 0.00974742137
Iter: 116 loss: 0.00959431566
Iter: 117 loss: 0.00963653438
Iter: 118 loss: 0.009489852
Iter: 119 loss: 0.00921452604
Iter: 120 loss: 0.0103956964
Iter: 121 loss: 0.00914756
Iter: 122 loss: 0.0088213291
Iter: 123 loss: 0.0118957963
Iter: 124 loss: 0.00879456382
Iter: 125 loss: 0.00852741208
Iter: 126 loss: 0.00930236839
Iter: 127 loss: 0.00842645
Iter: 128 loss: 0.00820725132
Iter: 129 loss: 0.00884798728
Iter: 130 loss: 0.00815073773
Iter: 131 loss: 0.00791831873
Iter: 132 loss: 0.00859847292
Iter: 133 loss: 0.00783687178
Iter: 134 loss: 0.00765652908
Iter: 135 loss: 0.0075197937
Iter: 136 loss: 0.00746293366
Iter: 137 loss: 0.00723797362
Iter: 138 loss: 0.00965586118
Iter: 139 loss: 0.00722427294
Iter: 140 loss: 0.00703875441
Iter: 141 loss: 0.00826599821
Iter: 142 loss: 0.00703142304
Iter: 143 loss: 0.00690890756
Iter: 144 loss: 0.00672862493
Iter: 145 loss: 0.00672424212
Iter: 146 loss: 0.00659307
Iter: 147 loss: 0.00741345249
Iter: 148 loss: 0.00657439604
Iter: 149 loss: 0.0064777704
Iter: 150 loss: 0.00683424342
Iter: 151 loss: 0.0064546694
Iter: 152 loss: 0.0063390024
Iter: 153 loss: 0.00649852958
Iter: 154 loss: 0.00627694279
Iter: 155 loss: 0.00616749655
Iter: 156 loss: 0.00622830354
Iter: 157 loss: 0.00610104389
Iter: 158 loss: 0.00599365681
Iter: 159 loss: 0.0058736
Iter: 160 loss: 0.00585595332
Iter: 161 loss: 0.00572647061
Iter: 162 loss: 0.00703608245
Iter: 163 loss: 0.00572336372
Iter: 164 loss: 0.00562069472
Iter: 165 loss: 0.0056807436
Iter: 166 loss: 0.00555643952
Iter: 167 loss: 0.00543925259
Iter: 168 loss: 0.00562136434
Iter: 169 loss: 0.00538419094
Iter: 170 loss: 0.00528935529
Iter: 171 loss: 0.00528381811
Iter: 172 loss: 0.00522468
Iter: 173 loss: 0.00550355576
Iter: 174 loss: 0.00521657523
Iter: 175 loss: 0.00515706744
Iter: 176 loss: 0.00501325727
Iter: 177 loss: 0.00672781793
Iter: 178 loss: 0.00499851
Iter: 179 loss: 0.00491427351
Iter: 180 loss: 0.00557045732
Iter: 181 loss: 0.0049095084
Iter: 182 loss: 0.00484618
Iter: 183 loss: 0.00505114719
Iter: 184 loss: 0.00482811453
Iter: 185 loss: 0.00475607067
Iter: 186 loss: 0.00541754533
Iter: 187 loss: 0.00475432631
Iter: 188 loss: 0.00470481254
Iter: 189 loss: 0.00487900618
Iter: 190 loss: 0.00469007157
Iter: 191 loss: 0.00466071116
Iter: 192 loss: 0.00460215751
Iter: 193 loss: 0.00570570212
Iter: 194 loss: 0.00460140593
Iter: 195 loss: 0.00452044746
Iter: 196 loss: 0.00480800588
Iter: 197 loss: 0.00450039376
Iter: 198 loss: 0.00442329282
Iter: 199 loss: 0.00461445656
Iter: 200 loss: 0.00439369865
Iter: 201 loss: 0.00430431217
Iter: 202 loss: 0.00545067666
Iter: 203 loss: 0.00430410542
Iter: 204 loss: 0.00423788792
Iter: 205 loss: 0.00463123899
Iter: 206 loss: 0.00422741147
Iter: 207 loss: 0.00418569893
Iter: 208 loss: 0.00477924803
Iter: 209 loss: 0.00418568216
Iter: 210 loss: 0.00415568473
Iter: 211 loss: 0.00415223651
Iter: 212 loss: 0.00413048454
Iter: 213 loss: 0.00409146538
Iter: 214 loss: 0.00435129972
Iter: 215 loss: 0.00408858946
Iter: 216 loss: 0.00405838899
Iter: 217 loss: 0.00402001943
Iter: 218 loss: 0.00401682686
Iter: 219 loss: 0.00396778807
Iter: 220 loss: 0.00398784317
Iter: 221 loss: 0.00393493101
Iter: 222 loss: 0.00390917156
Iter: 223 loss: 0.00385760237
Iter: 224 loss: 0.00491383
Iter: 225 loss: 0.00385698932
Iter: 226 loss: 0.00387510704
Iter: 227 loss: 0.00382909155
Iter: 228 loss: 0.00378444535
Iter: 229 loss: 0.00398108643
Iter: 230 loss: 0.00377607904
Iter: 231 loss: 0.00375013915
Iter: 232 loss: 0.00370642054
Iter: 233 loss: 0.00370632578
Iter: 234 loss: 0.00365805975
Iter: 235 loss: 0.00385271618
Iter: 236 loss: 0.00364726945
Iter: 237 loss: 0.00360785774
Iter: 238 loss: 0.00397031941
Iter: 239 loss: 0.00360613968
Iter: 240 loss: 0.00358070224
Iter: 241 loss: 0.00366340438
Iter: 242 loss: 0.0035732016
Iter: 243 loss: 0.00353494869
Iter: 244 loss: 0.00359604624
Iter: 245 loss: 0.00351806311
Iter: 246 loss: 0.00349237095
Iter: 247 loss: 0.00353402132
Iter: 248 loss: 0.00348012941
Iter: 249 loss: 0.00346655957
Iter: 250 loss: 0.00354031986
Iter: 251 loss: 0.00346478494
Iter: 252 loss: 0.00345186377
Iter: 253 loss: 0.00348032359
Iter: 254 loss: 0.00344681484
Iter: 255 loss: 0.00341886468
Iter: 256 loss: 0.00339406962
Iter: 257 loss: 0.00338705909
Iter: 258 loss: 0.00335562578
Iter: 259 loss: 0.00369712
Iter: 260 loss: 0.00335456571
Iter: 261 loss: 0.00333214272
Iter: 262 loss: 0.00338978739
Iter: 263 loss: 0.00332469121
Iter: 264 loss: 0.0032990172
Iter: 265 loss: 0.00330260815
Iter: 266 loss: 0.00327908108
Iter: 267 loss: 0.00325837219
Iter: 268 loss: 0.00331070507
Iter: 269 loss: 0.00325129973
Iter: 270 loss: 0.00323179364
Iter: 271 loss: 0.00324153365
Iter: 272 loss: 0.00321875117
Iter: 273 loss: 0.0031841849
Iter: 274 loss: 0.00321003655
Iter: 275 loss: 0.00316321198
Iter: 276 loss: 0.0031564855
Iter: 277 loss: 0.00314503163
Iter: 278 loss: 0.00313007459
Iter: 279 loss: 0.00314787729
Iter: 280 loss: 0.00312208477
Iter: 281 loss: 0.0030973861
Iter: 282 loss: 0.00342956069
Iter: 283 loss: 0.00309737539
Iter: 284 loss: 0.00308279227
Iter: 285 loss: 0.00312632066
Iter: 286 loss: 0.00307810679
Iter: 287 loss: 0.0030689449
Iter: 288 loss: 0.003051301
Iter: 289 loss: 0.00341486721
Iter: 290 loss: 0.00305120321
Iter: 291 loss: 0.00303282589
Iter: 292 loss: 0.00305609358
Iter: 293 loss: 0.00302318181
Iter: 294 loss: 0.00300156791
Iter: 295 loss: 0.00312919309
Iter: 296 loss: 0.00299899466
Iter: 297 loss: 0.00298485393
Iter: 298 loss: 0.00304562715
Iter: 299 loss: 0.00298173586
Iter: 300 loss: 0.00296738255
Iter: 301 loss: 0.00294543267
Iter: 302 loss: 0.00294508366
Iter: 303 loss: 0.0029245133
Iter: 304 loss: 0.00296605588
Iter: 305 loss: 0.00291587412
Iter: 306 loss: 0.00289973803
Iter: 307 loss: 0.00294550252
Iter: 308 loss: 0.00289458944
Iter: 309 loss: 0.00288027106
Iter: 310 loss: 0.00288023497
Iter: 311 loss: 0.00286792056
Iter: 312 loss: 0.00285194372
Iter: 313 loss: 0.00285081472
Iter: 314 loss: 0.00284079881
Iter: 315 loss: 0.00284072524
Iter: 316 loss: 0.00283761928
Iter: 317 loss: 0.00283722067
Iter: 318 loss: 0.0028350018
Iter: 319 loss: 0.00282093603
Iter: 320 loss: 0.0028897915
Iter: 321 loss: 0.00281855883
Iter: 322 loss: 0.00280426024
Iter: 323 loss: 0.00282100914
Iter: 324 loss: 0.00279650046
Iter: 325 loss: 0.00278662145
Iter: 326 loss: 0.00276689697
Iter: 327 loss: 0.00314525585
Iter: 328 loss: 0.00276665972
Iter: 329 loss: 0.00275309943
Iter: 330 loss: 0.00275029405
Iter: 331 loss: 0.00273959804
Iter: 332 loss: 0.00272579538
Iter: 333 loss: 0.00272487709
Iter: 334 loss: 0.00270864484
Iter: 335 loss: 0.00270970608
Iter: 336 loss: 0.00269574625
Iter: 337 loss: 0.00268646027
Iter: 338 loss: 0.00267865555
Iter: 339 loss: 0.0026760255
Iter: 340 loss: 0.00266106543
Iter: 341 loss: 0.0027308492
Iter: 342 loss: 0.00265834294
Iter: 343 loss: 0.00264792843
Iter: 344 loss: 0.00268222624
Iter: 345 loss: 0.00264499895
Iter: 346 loss: 0.00263873092
Iter: 347 loss: 0.0027305712
Iter: 348 loss: 0.00263873
Iter: 349 loss: 0.00263186195
Iter: 350 loss: 0.00265538041
Iter: 351 loss: 0.00262994552
Iter: 352 loss: 0.00262332265
Iter: 353 loss: 0.00260919053
Iter: 354 loss: 0.00284277275
Iter: 355 loss: 0.00260875141
Iter: 356 loss: 0.00259520672
Iter: 357 loss: 0.00278235646
Iter: 358 loss: 0.00259519415
Iter: 359 loss: 0.00258295168
Iter: 360 loss: 0.00269595301
Iter: 361 loss: 0.00258232607
Iter: 362 loss: 0.00257543707
Iter: 363 loss: 0.00256005256
Iter: 364 loss: 0.00277958205
Iter: 365 loss: 0.00255923346
Iter: 366 loss: 0.00254201889
Iter: 367 loss: 0.00252852449
Iter: 368 loss: 0.0025231503
Iter: 369 loss: 0.00255586463
Iter: 370 loss: 0.00251488062
Iter: 371 loss: 0.00250852201
Iter: 372 loss: 0.00250618951
Iter: 373 loss: 0.00250268332
Iter: 374 loss: 0.0024877449
Iter: 375 loss: 0.00254358863
Iter: 376 loss: 0.00248409971
Iter: 377 loss: 0.00246532401
Iter: 378 loss: 0.0025245985
Iter: 379 loss: 0.00246016588
Iter: 380 loss: 0.0024519763
Iter: 381 loss: 0.00251377677
Iter: 382 loss: 0.00245127128
Iter: 383 loss: 0.0024433122
Iter: 384 loss: 0.00246979669
Iter: 385 loss: 0.00244124513
Iter: 386 loss: 0.00243365252
Iter: 387 loss: 0.00243846234
Iter: 388 loss: 0.00242876261
Iter: 389 loss: 0.00241930177
Iter: 390 loss: 0.00245795259
Iter: 391 loss: 0.00241714949
Iter: 392 loss: 0.0024096414
Iter: 393 loss: 0.00241583469
Iter: 394 loss: 0.00240519876
Iter: 395 loss: 0.00239438401
Iter: 396 loss: 0.00239433954
Iter: 397 loss: 0.00238784449
Iter: 398 loss: 0.00238378346
Iter: 399 loss: 0.00238119625
Iter: 400 loss: 0.00236987881
Iter: 401 loss: 0.0023795478
Iter: 402 loss: 0.00236312789
Iter: 403 loss: 0.00235180208
Iter: 404 loss: 0.00244126
Iter: 405 loss: 0.00235107215
Iter: 406 loss: 0.00234195869
Iter: 407 loss: 0.00232689455
Iter: 408 loss: 0.00232682889
Iter: 409 loss: 0.00231405348
Iter: 410 loss: 0.00231846049
Iter: 411 loss: 0.00230506854
Iter: 412 loss: 0.00228925282
Iter: 413 loss: 0.00254086079
Iter: 414 loss: 0.00228924141
Iter: 415 loss: 0.00228283578
Iter: 416 loss: 0.0022825303
Iter: 417 loss: 0.00227430835
Iter: 418 loss: 0.00226948829
Iter: 419 loss: 0.00226594671
Iter: 420 loss: 0.0022594675
Iter: 421 loss: 0.00225308491
Iter: 422 loss: 0.00225172308
Iter: 423 loss: 0.00223736046
Iter: 424 loss: 0.00227001053
Iter: 425 loss: 0.00223193294
Iter: 426 loss: 0.00221934612
Iter: 427 loss: 0.00221933099
Iter: 428 loss: 0.00221375329
Iter: 429 loss: 0.00221365294
Iter: 430 loss: 0.00221023
Iter: 431 loss: 0.00220239977
Iter: 432 loss: 0.00230530649
Iter: 433 loss: 0.00220187567
Iter: 434 loss: 0.00218798686
Iter: 435 loss: 0.00219598296
Iter: 436 loss: 0.00217884337
Iter: 437 loss: 0.00216517
Iter: 438 loss: 0.00216488354
Iter: 439 loss: 0.00215508556
Iter: 440 loss: 0.0021574276
Iter: 441 loss: 0.00214786688
Iter: 442 loss: 0.00213521626
Iter: 443 loss: 0.00217317371
Iter: 444 loss: 0.00213139551
Iter: 445 loss: 0.0021232469
Iter: 446 loss: 0.0022392855
Iter: 447 loss: 0.00212321384
Iter: 448 loss: 0.00212094327
Iter: 449 loss: 0.0021184911
Iter: 450 loss: 0.0021163309
Iter: 451 loss: 0.00211096206
Iter: 452 loss: 0.00216411799
Iter: 453 loss: 0.00211025611
Iter: 454 loss: 0.0021056612
Iter: 455 loss: 0.00209971657
Iter: 456 loss: 0.00209934358
Iter: 457 loss: 0.00209282432
Iter: 458 loss: 0.00208372017
Iter: 459 loss: 0.00208332157
Iter: 460 loss: 0.00207698136
Iter: 461 loss: 0.00207737274
Iter: 462 loss: 0.00207205163
Iter: 463 loss: 0.0020670665
Iter: 464 loss: 0.00207289541
Iter: 465 loss: 0.00206440547
Iter: 466 loss: 0.00205754489
Iter: 467 loss: 0.00206281338
Iter: 468 loss: 0.00205331203
Iter: 469 loss: 0.00204985775
Iter: 470 loss: 0.00204644236
Iter: 471 loss: 0.00203899806
Iter: 472 loss: 0.00202726386
Iter: 473 loss: 0.0020271386
Iter: 474 loss: 0.00201501558
Iter: 475 loss: 0.00203927467
Iter: 476 loss: 0.00201000087
Iter: 477 loss: 0.00199918495
Iter: 478 loss: 0.00200179499
Iter: 479 loss: 0.00199128687
Iter: 480 loss: 0.00198265677
Iter: 481 loss: 0.0019826456
Iter: 482 loss: 0.00197846908
Iter: 483 loss: 0.00197693985
Iter: 484 loss: 0.00197457895
Iter: 485 loss: 0.00197206647
Iter: 486 loss: 0.00197166298
Iter: 487 loss: 0.00196665549
Iter: 488 loss: 0.00198583445
Iter: 489 loss: 0.00196539401
Iter: 490 loss: 0.00196131528
Iter: 491 loss: 0.00195993902
Iter: 492 loss: 0.00195760932
Iter: 493 loss: 0.0019504599
Iter: 494 loss: 0.00194668316
Iter: 495 loss: 0.00194342295
Iter: 496 loss: 0.0019347677
Iter: 497 loss: 0.00201320671
Iter: 498 loss: 0.00193430088
Iter: 499 loss: 0.00192551943
Iter: 500 loss: 0.00191529351
Iter: 501 loss: 0.00191409956
Iter: 502 loss: 0.00190725783
Iter: 503 loss: 0.00190629624
Iter: 504 loss: 0.00190068095
Iter: 505 loss: 0.0018995686
Iter: 506 loss: 0.00189581735
Iter: 507 loss: 0.00188799948
Iter: 508 loss: 0.00187379
Iter: 509 loss: 0.00220630364
Iter: 510 loss: 0.00187378144
Iter: 511 loss: 0.0018668354
Iter: 512 loss: 0.0018744187
Iter: 513 loss: 0.00186296692
Iter: 514 loss: 0.00185730262
Iter: 515 loss: 0.00184706191
Iter: 516 loss: 0.00207857508
Iter: 517 loss: 0.00184705947
Iter: 518 loss: 0.00183614809
Iter: 519 loss: 0.00182592566
Iter: 520 loss: 0.00182334846
Iter: 521 loss: 0.00182448886
Iter: 522 loss: 0.00181806786
Iter: 523 loss: 0.00181323942
Iter: 524 loss: 0.00180485542
Iter: 525 loss: 0.00180485076
Iter: 526 loss: 0.00179730006
Iter: 527 loss: 0.00181165827
Iter: 528 loss: 0.00179422356
Iter: 529 loss: 0.00179002015
Iter: 530 loss: 0.00178078318
Iter: 531 loss: 0.00192275969
Iter: 532 loss: 0.00178037467
Iter: 533 loss: 0.00176642765
Iter: 534 loss: 0.0017944742
Iter: 535 loss: 0.0017607169
Iter: 536 loss: 0.00175176491
Iter: 537 loss: 0.00176830916
Iter: 538 loss: 0.00174792379
Iter: 539 loss: 0.00173984468
Iter: 540 loss: 0.00185382389
Iter: 541 loss: 0.00173983257
Iter: 542 loss: 0.00173343241
Iter: 543 loss: 0.00173804455
Iter: 544 loss: 0.00172940968
Iter: 545 loss: 0.00172200357
Iter: 546 loss: 0.00172024686
Iter: 547 loss: 0.00171552435
Iter: 548 loss: 0.00171036692
Iter: 549 loss: 0.00171018299
Iter: 550 loss: 0.00170312659
Iter: 551 loss: 0.00174320966
Iter: 552 loss: 0.00170220877
Iter: 553 loss: 0.00169711956
Iter: 554 loss: 0.00171651621
Iter: 555 loss: 0.00169581058
Iter: 556 loss: 0.00169031566
Iter: 557 loss: 0.00174406799
Iter: 558 loss: 0.00169015559
Iter: 559 loss: 0.00168808422
Iter: 560 loss: 0.00168288732
Iter: 561 loss: 0.00173449
Iter: 562 loss: 0.00168217649
Iter: 563 loss: 0.0016769527
Iter: 564 loss: 0.00167895504
Iter: 565 loss: 0.00167336513
Iter: 566 loss: 0.00166884321
Iter: 567 loss: 0.00166421849
Iter: 568 loss: 0.00166333339
Iter: 569 loss: 0.001655792
Iter: 570 loss: 0.00165004097
Iter: 571 loss: 0.00164761604
Iter: 572 loss: 0.00163955486
Iter: 573 loss: 0.00163953495
Iter: 574 loss: 0.00163267856
Iter: 575 loss: 0.00164789695
Iter: 576 loss: 0.00163012464
Iter: 577 loss: 0.00162395905
Iter: 578 loss: 0.00163610815
Iter: 579 loss: 0.0016214163
Iter: 580 loss: 0.00161236885
Iter: 581 loss: 0.00162439037
Iter: 582 loss: 0.00160778582
Iter: 583 loss: 0.00159945688
Iter: 584 loss: 0.00166490953
Iter: 585 loss: 0.0015988166
Iter: 586 loss: 0.00159460551
Iter: 587 loss: 0.00159335951
Iter: 588 loss: 0.00159000186
Iter: 589 loss: 0.00159355311
Iter: 590 loss: 0.00158810976
Iter: 591 loss: 0.00158373732
Iter: 592 loss: 0.00159474614
Iter: 593 loss: 0.00158227189
Iter: 594 loss: 0.0015793402
Iter: 595 loss: 0.00157626718
Iter: 596 loss: 0.00157572189
Iter: 597 loss: 0.00157074898
Iter: 598 loss: 0.00164766016
Iter: 599 loss: 0.00157074665
Iter: 600 loss: 0.00156717328
Iter: 601 loss: 0.00156476488
Iter: 602 loss: 0.00156344683
Iter: 603 loss: 0.00155941187
Iter: 604 loss: 0.00157412724
Iter: 605 loss: 0.00155841862
Iter: 606 loss: 0.00155478448
Iter: 607 loss: 0.00155794679
Iter: 608 loss: 0.00155262905
Iter: 609 loss: 0.00154857815
Iter: 610 loss: 0.00154443423
Iter: 611 loss: 0.00154365459
Iter: 612 loss: 0.00153714418
Iter: 613 loss: 0.00154198008
Iter: 614 loss: 0.00153317954
Iter: 615 loss: 0.00152758625
Iter: 616 loss: 0.00153911859
Iter: 617 loss: 0.00152532244
Iter: 618 loss: 0.00152025896
Iter: 619 loss: 0.00153066986
Iter: 620 loss: 0.0015181948
Iter: 621 loss: 0.00151438022
Iter: 622 loss: 0.00151392294
Iter: 623 loss: 0.00151205179
Iter: 624 loss: 0.00150903221
Iter: 625 loss: 0.00150900823
Iter: 626 loss: 0.00150560378
Iter: 627 loss: 0.00150873186
Iter: 628 loss: 0.00150365243
Iter: 629 loss: 0.00149947056
Iter: 630 loss: 0.00150722032
Iter: 631 loss: 0.00149770139
Iter: 632 loss: 0.00149340462
Iter: 633 loss: 0.00152787869
Iter: 634 loss: 0.00149313174
Iter: 635 loss: 0.00148993637
Iter: 636 loss: 0.00149403594
Iter: 637 loss: 0.00148828304
Iter: 638 loss: 0.001483917
Iter: 639 loss: 0.00149352232
Iter: 640 loss: 0.00148228265
Iter: 641 loss: 0.00147898588
Iter: 642 loss: 0.00147318316
Iter: 643 loss: 0.00147317932
Iter: 644 loss: 0.00146594131
Iter: 645 loss: 0.00147138094
Iter: 646 loss: 0.00146149029
Iter: 647 loss: 0.00145350187
Iter: 648 loss: 0.00146056036
Iter: 649 loss: 0.00144889252
Iter: 650 loss: 0.00144085661
Iter: 651 loss: 0.00151283725
Iter: 652 loss: 0.00144044508
Iter: 653 loss: 0.0014530624
Iter: 654 loss: 0.001438885
Iter: 655 loss: 0.00143766555
Iter: 656 loss: 0.0014352306
Iter: 657 loss: 0.00148470164
Iter: 658 loss: 0.00143521186
Iter: 659 loss: 0.00143243046
Iter: 660 loss: 0.00142591749
Iter: 661 loss: 0.00150034192
Iter: 662 loss: 0.00142534904
Iter: 663 loss: 0.00142112549
Iter: 664 loss: 0.00143422629
Iter: 665 loss: 0.00141986099
Iter: 666 loss: 0.0014156939
Iter: 667 loss: 0.00143130042
Iter: 668 loss: 0.00141467678
Iter: 669 loss: 0.00140959583
Iter: 670 loss: 0.00141857855
Iter: 671 loss: 0.00140743423
Iter: 672 loss: 0.00140533922
Iter: 673 loss: 0.00141414837
Iter: 674 loss: 0.00140487798
Iter: 675 loss: 0.00140377868
Iter: 676 loss: 0.00140057621
Iter: 677 loss: 0.00141328829
Iter: 678 loss: 0.00139923557
Iter: 679 loss: 0.00139473332
Iter: 680 loss: 0.00139388989
Iter: 681 loss: 0.00139090011
Iter: 682 loss: 0.00138738588
Iter: 683 loss: 0.00138145196
Iter: 684 loss: 0.00138144265
Iter: 685 loss: 0.00137577904
Iter: 686 loss: 0.00137293653
Iter: 687 loss: 0.00137026818
Iter: 688 loss: 0.00136244157
Iter: 689 loss: 0.00136675802
Iter: 690 loss: 0.00135733117
Iter: 691 loss: 0.00134786777
Iter: 692 loss: 0.00145743496
Iter: 693 loss: 0.00134764437
Iter: 694 loss: 0.00134552526
Iter: 695 loss: 0.00134523329
Iter: 696 loss: 0.00134229427
Iter: 697 loss: 0.00134176633
Iter: 698 loss: 0.00133976189
Iter: 699 loss: 0.00133463461
Iter: 700 loss: 0.00133413146
Iter: 701 loss: 0.00133040664
Iter: 702 loss: 0.00132603548
Iter: 703 loss: 0.00132765807
Iter: 704 loss: 0.00132297887
Iter: 705 loss: 0.00132119691
Iter: 706 loss: 0.00132042798
Iter: 707 loss: 0.00131779234
Iter: 708 loss: 0.00132010528
Iter: 709 loss: 0.00131626916
Iter: 710 loss: 0.00131437485
Iter: 711 loss: 0.00131030614
Iter: 712 loss: 0.00137765286
Iter: 713 loss: 0.00131017377
Iter: 714 loss: 0.00130561087
Iter: 715 loss: 0.00135699438
Iter: 716 loss: 0.00130553008
Iter: 717 loss: 0.00130332541
Iter: 718 loss: 0.00130287884
Iter: 719 loss: 0.001301412
Iter: 720 loss: 0.00129780034
Iter: 721 loss: 0.00129473221
Iter: 722 loss: 0.00129374256
Iter: 723 loss: 0.00128726196
Iter: 724 loss: 0.00128804543
Iter: 725 loss: 0.00128227414
Iter: 726 loss: 0.00127133261
Iter: 727 loss: 0.00129792094
Iter: 728 loss: 0.00126737601
Iter: 729 loss: 0.0012559935
Iter: 730 loss: 0.0012738565
Iter: 731 loss: 0.00125068333
Iter: 732 loss: 0.00125804474
Iter: 733 loss: 0.00124782
Iter: 734 loss: 0.00124526094
Iter: 735 loss: 0.00124276674
Iter: 736 loss: 0.00124220783
Iter: 737 loss: 0.00124022749
Iter: 738 loss: 0.00123974623
Iter: 739 loss: 0.00123668101
Iter: 740 loss: 0.00126627251
Iter: 741 loss: 0.00123658136
Iter: 742 loss: 0.00123512163
Iter: 743 loss: 0.00123099
Iter: 744 loss: 0.00125210383
Iter: 745 loss: 0.00122959993
Iter: 746 loss: 0.00122707768
Iter: 747 loss: 0.00122705754
Iter: 748 loss: 0.00122475205
Iter: 749 loss: 0.00122194597
Iter: 750 loss: 0.00122167927
Iter: 751 loss: 0.0012179059
Iter: 752 loss: 0.00121756212
Iter: 753 loss: 0.0012141692
Iter: 754 loss: 0.001218096
Iter: 755 loss: 0.00121232355
Iter: 756 loss: 0.00121041527
Iter: 757 loss: 0.00120872445
Iter: 758 loss: 0.00120824017
Iter: 759 loss: 0.00120608625
Iter: 760 loss: 0.00120294082
Iter: 761 loss: 0.00120284862
Iter: 762 loss: 0.00120034686
Iter: 763 loss: 0.00119731866
Iter: 764 loss: 0.00119701843
Iter: 765 loss: 0.0011919504
Iter: 766 loss: 0.00122196856
Iter: 767 loss: 0.00119128451
Iter: 768 loss: 0.00118496083
Iter: 769 loss: 0.0011895377
Iter: 770 loss: 0.00118108036
Iter: 771 loss: 0.00117411045
Iter: 772 loss: 0.00124779297
Iter: 773 loss: 0.00117394107
Iter: 774 loss: 0.00116967713
Iter: 775 loss: 0.00119532854
Iter: 776 loss: 0.00116911414
Iter: 777 loss: 0.00116594241
Iter: 778 loss: 0.00119117124
Iter: 779 loss: 0.00116575067
Iter: 780 loss: 0.00116358907
Iter: 781 loss: 0.00116108474
Iter: 782 loss: 0.00116078835
Iter: 783 loss: 0.00115803862
Iter: 784 loss: 0.00115464209
Iter: 785 loss: 0.00115433778
Iter: 786 loss: 0.00114917359
Iter: 787 loss: 0.00115050934
Iter: 788 loss: 0.00114538963
Iter: 789 loss: 0.00115796726
Iter: 790 loss: 0.00114316377
Iter: 791 loss: 0.00114228716
Iter: 792 loss: 0.0011403081
Iter: 793 loss: 0.00116818934
Iter: 794 loss: 0.0011401932
Iter: 795 loss: 0.00113761262
Iter: 796 loss: 0.00113364961
Iter: 797 loss: 0.00113358581
Iter: 798 loss: 0.00112826773
Iter: 799 loss: 0.00113660702
Iter: 800 loss: 0.00112576829
Iter: 801 loss: 0.00112136081
Iter: 802 loss: 0.0011213
Iter: 803 loss: 0.00111778802
Iter: 804 loss: 0.00111698802
Iter: 805 loss: 0.00111474365
Iter: 806 loss: 0.00110868551
Iter: 807 loss: 0.00116678979
Iter: 808 loss: 0.0011084266
Iter: 809 loss: 0.00110809912
Iter: 810 loss: 0.00110660354
Iter: 811 loss: 0.00110434799
Iter: 812 loss: 0.00110478746
Iter: 813 loss: 0.00110265054
Iter: 814 loss: 0.00110081944
Iter: 815 loss: 0.0011012638
Iter: 816 loss: 0.00109949254
Iter: 817 loss: 0.00109809882
Iter: 818 loss: 0.00109617354
Iter: 819 loss: 0.00109608658
Iter: 820 loss: 0.00109280134
Iter: 821 loss: 0.00109217828
Iter: 822 loss: 0.00108998537
Iter: 823 loss: 0.00109550718
Iter: 824 loss: 0.00108903809
Iter: 825 loss: 0.00108826486
Iter: 826 loss: 0.00108584482
Iter: 827 loss: 0.00109020167
Iter: 828 loss: 0.00108424388
Iter: 829 loss: 0.00107852067
Iter: 830 loss: 0.00109603698
Iter: 831 loss: 0.00107681961
Iter: 832 loss: 0.00107598573
Iter: 833 loss: 0.0010737991
Iter: 834 loss: 0.00107171992
Iter: 835 loss: 0.00106924912
Iter: 836 loss: 0.00106899091
Iter: 837 loss: 0.0010665775
Iter: 838 loss: 0.00106392219
Iter: 839 loss: 0.00106352591
Iter: 840 loss: 0.00106137071
Iter: 841 loss: 0.0010636159
Iter: 842 loss: 0.00106019317
Iter: 843 loss: 0.00105932925
Iter: 844 loss: 0.00105758011
Iter: 845 loss: 0.00108974287
Iter: 846 loss: 0.00105755206
Iter: 847 loss: 0.00105507404
Iter: 848 loss: 0.00108366739
Iter: 849 loss: 0.0010550383
Iter: 850 loss: 0.00104939798
Iter: 851 loss: 0.00107315765
Iter: 852 loss: 0.00104815431
Iter: 853 loss: 0.0010458203
Iter: 854 loss: 0.00104303646
Iter: 855 loss: 0.00104275462
Iter: 856 loss: 0.00104002713
Iter: 857 loss: 0.00103821326
Iter: 858 loss: 0.00103719404
Iter: 859 loss: 0.00103351916
Iter: 860 loss: 0.00103315385
Iter: 861 loss: 0.0010304742
Iter: 862 loss: 0.00102324295
Iter: 863 loss: 0.00106160319
Iter: 864 loss: 0.00102213188
Iter: 865 loss: 0.00101853767
Iter: 866 loss: 0.00104271667
Iter: 867 loss: 0.00101817679
Iter: 868 loss: 0.00101539167
Iter: 869 loss: 0.00101907132
Iter: 870 loss: 0.00101399189
Iter: 871 loss: 0.00101142353
Iter: 872 loss: 0.00101228687
Iter: 873 loss: 0.0010095964
Iter: 874 loss: 0.00101611204
Iter: 875 loss: 0.00100816693
Iter: 876 loss: 0.0010075816
Iter: 877 loss: 0.00100570242
Iter: 878 loss: 0.00100791734
Iter: 879 loss: 0.00100425049
Iter: 880 loss: 0.00100149168
Iter: 881 loss: 0.00100135303
Iter: 882 loss: 0.000999249169
Iter: 883 loss: 0.000996988732
Iter: 884 loss: 0.00100176479
Iter: 885 loss: 0.000996089308
Iter: 886 loss: 0.000994252
Iter: 887 loss: 0.00100664643
Iter: 888 loss: 0.000994077
Iter: 889 loss: 0.000990399
Iter: 890 loss: 0.000994270784
Iter: 891 loss: 0.000988337
Iter: 892 loss: 0.000984364771
Iter: 893 loss: 0.00099378929
Iter: 894 loss: 0.000982916914
Iter: 895 loss: 0.000978931785
Iter: 896 loss: 0.000986228
Iter: 897 loss: 0.000977215706
Iter: 898 loss: 0.00097522384
Iter: 899 loss: 0.000993631314
Iter: 900 loss: 0.00097512966
Iter: 901 loss: 0.000973806833
Iter: 902 loss: 0.000972318405
Iter: 903 loss: 0.000972116599
Iter: 904 loss: 0.000969564659
Iter: 905 loss: 0.000970047549
Iter: 906 loss: 0.000967658358
Iter: 907 loss: 0.000965987681
Iter: 908 loss: 0.000984255923
Iter: 909 loss: 0.000965949
Iter: 910 loss: 0.000964317296
Iter: 911 loss: 0.000972617534
Iter: 912 loss: 0.000964048959
Iter: 913 loss: 0.00096301391
Iter: 914 loss: 0.000961719896
Iter: 915 loss: 0.000961614307
Iter: 916 loss: 0.000960200676
Iter: 917 loss: 0.000976918149
Iter: 918 loss: 0.000960184319
Iter: 919 loss: 0.000959198282
Iter: 920 loss: 0.000957350247
Iter: 921 loss: 0.00099900784
Iter: 922 loss: 0.000957344193
Iter: 923 loss: 0.00095467444
Iter: 924 loss: 0.000961928745
Iter: 925 loss: 0.000953793759
Iter: 926 loss: 0.000951206894
Iter: 927 loss: 0.00096415251
Iter: 928 loss: 0.000950758345
Iter: 929 loss: 0.000948109
Iter: 930 loss: 0.000945437
Iter: 931 loss: 0.000944903877
Iter: 932 loss: 0.000945428386
Iter: 933 loss: 0.000943508814
Iter: 934 loss: 0.000942278595
Iter: 935 loss: 0.000940214668
Iter: 936 loss: 0.000940210419
Iter: 937 loss: 0.000937728677
Iter: 938 loss: 0.000943551073
Iter: 939 loss: 0.000936805562
Iter: 940 loss: 0.000935057
Iter: 941 loss: 0.000936335593
Iter: 942 loss: 0.000933979929
Iter: 943 loss: 0.000932569965
Iter: 944 loss: 0.000932410709
Iter: 945 loss: 0.000931246381
Iter: 946 loss: 0.000933793373
Iter: 947 loss: 0.000930803129
Iter: 948 loss: 0.000930063194
Iter: 949 loss: 0.000929965521
Iter: 950 loss: 0.00092943979
Iter: 951 loss: 0.000928361376
Iter: 952 loss: 0.000926313282
Iter: 953 loss: 0.000970643
Iter: 954 loss: 0.000926306588
Iter: 955 loss: 0.000924134685
Iter: 956 loss: 0.000929446192
Iter: 957 loss: 0.000923367857
Iter: 958 loss: 0.000920857128
Iter: 959 loss: 0.000915207318
Iter: 960 loss: 0.000993003137
Iter: 961 loss: 0.000914887874
Iter: 962 loss: 0.000909328694
Iter: 963 loss: 0.000973351882
Iter: 964 loss: 0.000909231137
Iter: 965 loss: 0.000905460794
Iter: 966 loss: 0.000915793818
Iter: 967 loss: 0.000904231216
Iter: 968 loss: 0.000902492146
Iter: 969 loss: 0.000901547435
Iter: 970 loss: 0.000900029903
Iter: 971 loss: 0.000896625919
Iter: 972 loss: 0.000946657558
Iter: 973 loss: 0.00089644629
Iter: 974 loss: 0.000893992197
Iter: 975 loss: 0.000904561835
Iter: 976 loss: 0.000893489632
Iter: 977 loss: 0.000892744341
Iter: 978 loss: 0.000897337
Iter: 979 loss: 0.000892649288
Iter: 980 loss: 0.000892073032
Iter: 981 loss: 0.000891350268
Iter: 982 loss: 0.000891290663
Iter: 983 loss: 0.000889599381
Iter: 984 loss: 0.00088776747
Iter: 985 loss: 0.000887478818
Iter: 986 loss: 0.000885968
Iter: 987 loss: 0.000882777444
Iter: 988 loss: 0.00093528966
Iter: 989 loss: 0.00088268437
Iter: 990 loss: 0.000878663734
Iter: 991 loss: 0.000887794187
Iter: 992 loss: 0.000877130835
Iter: 993 loss: 0.000872415956
Iter: 994 loss: 0.000879433122
Iter: 995 loss: 0.000870122
Iter: 996 loss: 0.000865903217
Iter: 997 loss: 0.000869783456
Iter: 998 loss: 0.000863491732
Iter: 999 loss: 0.000860313186
Iter: 1000 loss: 0.000858123065
Iter: 1001 loss: 0.00085697067
Iter: 1002 loss: 0.000852727215
Iter: 1003 loss: 0.000862611283
Iter: 1004 loss: 0.000851125573
Iter: 1005 loss: 0.000846513081
Iter: 1006 loss: 0.000907239737
Iter: 1007 loss: 0.000846491836
Iter: 1008 loss: 0.000844541879
Iter: 1009 loss: 0.000854289625
Iter: 1010 loss: 0.000844202121
Iter: 1011 loss: 0.000842221
Iter: 1012 loss: 0.000854121288
Iter: 1013 loss: 0.000841987203
Iter: 1014 loss: 0.000840157969
Iter: 1015 loss: 0.000843723305
Iter: 1016 loss: 0.000839385204
Iter: 1017 loss: 0.000837438856
Iter: 1018 loss: 0.000848052
Iter: 1019 loss: 0.000837173196
Iter: 1020 loss: 0.00083645666
Iter: 1021 loss: 0.000834674167
Iter: 1022 loss: 0.000851854857
Iter: 1023 loss: 0.000834427134
Iter: 1024 loss: 0.000832045509
Iter: 1025 loss: 0.000833997154
Iter: 1026 loss: 0.000830611272
Iter: 1027 loss: 0.000827531563
Iter: 1028 loss: 0.000849187141
Iter: 1029 loss: 0.000827238895
Iter: 1030 loss: 0.000825480907
Iter: 1031 loss: 0.000844455
Iter: 1032 loss: 0.000825434923
Iter: 1033 loss: 0.000824027753
Iter: 1034 loss: 0.000823451
Iter: 1035 loss: 0.00082270382
Iter: 1036 loss: 0.00082044414
Iter: 1037 loss: 0.000821773661
Iter: 1038 loss: 0.000818987
Iter: 1039 loss: 0.000818773755
Iter: 1040 loss: 0.000818043482
Iter: 1041 loss: 0.000817330321
Iter: 1042 loss: 0.000816275482
Iter: 1043 loss: 0.000816249172
Iter: 1044 loss: 0.000814546831
Iter: 1045 loss: 0.000829995959
Iter: 1046 loss: 0.000814462663
Iter: 1047 loss: 0.000813469756
Iter: 1048 loss: 0.000818226486
Iter: 1049 loss: 0.000813293969
Iter: 1050 loss: 0.000812678947
Iter: 1051 loss: 0.000812775
Iter: 1052 loss: 0.000812216196
Iter: 1053 loss: 0.000811486738
Iter: 1054 loss: 0.000810321653
Iter: 1055 loss: 0.000810313795
Iter: 1056 loss: 0.000808632525
Iter: 1057 loss: 0.000811610604
Iter: 1058 loss: 0.000807898
Iter: 1059 loss: 0.000805508462
Iter: 1060 loss: 0.000817870721
Iter: 1061 loss: 0.000805128948
Iter: 1062 loss: 0.000803399365
Iter: 1063 loss: 0.000815834617
Iter: 1064 loss: 0.000803247676
Iter: 1065 loss: 0.000801931426
Iter: 1066 loss: 0.000812073413
Iter: 1067 loss: 0.000801828515
Iter: 1068 loss: 0.000800753129
Iter: 1069 loss: 0.000797804561
Iter: 1070 loss: 0.000815704232
Iter: 1071 loss: 0.000796997745
Iter: 1072 loss: 0.000794362044
Iter: 1073 loss: 0.000823211274
Iter: 1074 loss: 0.000794301566
Iter: 1075 loss: 0.000794324616
Iter: 1076 loss: 0.000793495
Iter: 1077 loss: 0.000792825944
Iter: 1078 loss: 0.000792393927
Iter: 1079 loss: 0.000792135834
Iter: 1080 loss: 0.000791161205
Iter: 1081 loss: 0.000800063484
Iter: 1082 loss: 0.000791119644
Iter: 1083 loss: 0.00079063978
Iter: 1084 loss: 0.000791256898
Iter: 1085 loss: 0.000790393446
Iter: 1086 loss: 0.000789758691
Iter: 1087 loss: 0.000789156533
Iter: 1088 loss: 0.000789011712
Iter: 1089 loss: 0.000788120844
Iter: 1090 loss: 0.000786055345
Iter: 1091 loss: 0.000812022539
Iter: 1092 loss: 0.000785902957
Iter: 1093 loss: 0.000782953051
Iter: 1094 loss: 0.000794683
Iter: 1095 loss: 0.000782270858
Iter: 1096 loss: 0.000778886722
Iter: 1097 loss: 0.000789172424
Iter: 1098 loss: 0.000777876412
Iter: 1099 loss: 0.000774903165
Iter: 1100 loss: 0.00079168356
Iter: 1101 loss: 0.000774479064
Iter: 1102 loss: 0.000771542545
Iter: 1103 loss: 0.000766455079
Iter: 1104 loss: 0.000766452053
Iter: 1105 loss: 0.000762361742
Iter: 1106 loss: 0.000794204767
Iter: 1107 loss: 0.000762050273
Iter: 1108 loss: 0.000757979811
Iter: 1109 loss: 0.00076015864
Iter: 1110 loss: 0.0007553061
Iter: 1111 loss: 0.000753278728
Iter: 1112 loss: 0.000752795255
Iter: 1113 loss: 0.000750316191
Iter: 1114 loss: 0.000771482941
Iter: 1115 loss: 0.000750187086
Iter: 1116 loss: 0.000749278115
Iter: 1117 loss: 0.000748313847
Iter: 1118 loss: 0.000748147897
Iter: 1119 loss: 0.000746567675
Iter: 1120 loss: 0.000746753183
Iter: 1121 loss: 0.000745362835
Iter: 1122 loss: 0.000743605895
Iter: 1123 loss: 0.000747216283
Iter: 1124 loss: 0.000742893666
Iter: 1125 loss: 0.000741119846
Iter: 1126 loss: 0.000737691124
Iter: 1127 loss: 0.000810795231
Iter: 1128 loss: 0.000737672439
Iter: 1129 loss: 0.000735009671
Iter: 1130 loss: 0.00074685656
Iter: 1131 loss: 0.000734487257
Iter: 1132 loss: 0.000733938708
Iter: 1133 loss: 0.000733631372
Iter: 1134 loss: 0.000732655288
Iter: 1135 loss: 0.000730872969
Iter: 1136 loss: 0.000772835221
Iter: 1137 loss: 0.000730869826
Iter: 1138 loss: 0.000729155319
Iter: 1139 loss: 0.000739728101
Iter: 1140 loss: 0.00072894874
Iter: 1141 loss: 0.000727363396
Iter: 1142 loss: 0.000732020941
Iter: 1143 loss: 0.000726878119
Iter: 1144 loss: 0.000725740334
Iter: 1145 loss: 0.000741087366
Iter: 1146 loss: 0.000725735328
Iter: 1147 loss: 0.000724935904
Iter: 1148 loss: 0.000724938116
Iter: 1149 loss: 0.000724570942
Iter: 1150 loss: 0.000723783
Iter: 1151 loss: 0.000736381742
Iter: 1152 loss: 0.000723755744
Iter: 1153 loss: 0.000722641358
Iter: 1154 loss: 0.000724855578
Iter: 1155 loss: 0.00072219118
Iter: 1156 loss: 0.000721273595
Iter: 1157 loss: 0.000723345322
Iter: 1158 loss: 0.000720924465
Iter: 1159 loss: 0.000719782314
Iter: 1160 loss: 0.00071711262
Iter: 1161 loss: 0.000749682134
Iter: 1162 loss: 0.00071689277
Iter: 1163 loss: 0.000713973073
Iter: 1164 loss: 0.000715712551
Iter: 1165 loss: 0.000712079112
Iter: 1166 loss: 0.000710852793
Iter: 1167 loss: 0.000710594119
Iter: 1168 loss: 0.000708867679
Iter: 1169 loss: 0.000707721862
Iter: 1170 loss: 0.000707075931
Iter: 1171 loss: 0.000705033774
Iter: 1172 loss: 0.000707253232
Iter: 1173 loss: 0.000703920727
Iter: 1174 loss: 0.00070183404
Iter: 1175 loss: 0.000710614608
Iter: 1176 loss: 0.000701393699
Iter: 1177 loss: 0.000699037337
Iter: 1178 loss: 0.00070691423
Iter: 1179 loss: 0.000698384945
Iter: 1180 loss: 0.000698847289
Iter: 1181 loss: 0.000697519281
Iter: 1182 loss: 0.000697102747
Iter: 1183 loss: 0.000696155941
Iter: 1184 loss: 0.000709468848
Iter: 1185 loss: 0.000696103554
Iter: 1186 loss: 0.000694962218
Iter: 1187 loss: 0.000696916948
Iter: 1188 loss: 0.000694462389
Iter: 1189 loss: 0.000693354756
Iter: 1190 loss: 0.000695376715
Iter: 1191 loss: 0.000692875939
Iter: 1192 loss: 0.000691179885
Iter: 1193 loss: 0.000689177192
Iter: 1194 loss: 0.000688958797
Iter: 1195 loss: 0.000686047599
Iter: 1196 loss: 0.000687578926
Iter: 1197 loss: 0.000684113
Iter: 1198 loss: 0.000683564809
Iter: 1199 loss: 0.000682352169
Iter: 1200 loss: 0.000680511585
Iter: 1201 loss: 0.00068163767
Iter: 1202 loss: 0.000679332181
Iter: 1203 loss: 0.000678331417
Iter: 1204 loss: 0.00067679293
Iter: 1205 loss: 0.00067677
Iter: 1206 loss: 0.000675388263
Iter: 1207 loss: 0.000676194089
Iter: 1208 loss: 0.000674502342
Iter: 1209 loss: 0.000673849951
Iter: 1210 loss: 0.000672217575
Iter: 1211 loss: 0.000687807566
Iter: 1212 loss: 0.000671990914
Iter: 1213 loss: 0.000670341833
Iter: 1214 loss: 0.000668728142
Iter: 1215 loss: 0.000668376044
Iter: 1216 loss: 0.000667155953
Iter: 1217 loss: 0.000667078188
Iter: 1218 loss: 0.000666476088
Iter: 1219 loss: 0.000666448614
Iter: 1220 loss: 0.000665987085
Iter: 1221 loss: 0.000665432541
Iter: 1222 loss: 0.000665380678
Iter: 1223 loss: 0.000664569845
Iter: 1224 loss: 0.000663119135
Iter: 1225 loss: 0.000697709271
Iter: 1226 loss: 0.0006631203
Iter: 1227 loss: 0.000662247301
Iter: 1228 loss: 0.00066457229
Iter: 1229 loss: 0.000661953178
Iter: 1230 loss: 0.00066131528
Iter: 1231 loss: 0.000659445242
Iter: 1232 loss: 0.000666521
Iter: 1233 loss: 0.000658653444
Iter: 1234 loss: 0.000655829674
Iter: 1235 loss: 0.000671479153
Iter: 1236 loss: 0.000655436597
Iter: 1237 loss: 0.00065555633
Iter: 1238 loss: 0.000654966687
Iter: 1239 loss: 0.000654503645
Iter: 1240 loss: 0.000655863609
Iter: 1241 loss: 0.000654364645
Iter: 1242 loss: 0.000653849915
Iter: 1243 loss: 0.000652721443
Iter: 1244 loss: 0.000669405796
Iter: 1245 loss: 0.000652672083
Iter: 1246 loss: 0.00065199472
Iter: 1247 loss: 0.00065090612
Iter: 1248 loss: 0.00065089768
Iter: 1249 loss: 0.000649807
Iter: 1250 loss: 0.000653550087
Iter: 1251 loss: 0.000649510534
Iter: 1252 loss: 0.000648923917
Iter: 1253 loss: 0.000648924557
Iter: 1254 loss: 0.000648278336
Iter: 1255 loss: 0.000650876784
Iter: 1256 loss: 0.000648130663
Iter: 1257 loss: 0.000647496781
Iter: 1258 loss: 0.000647194451
Iter: 1259 loss: 0.000646888278
Iter: 1260 loss: 0.000646295841
Iter: 1261 loss: 0.000651343784
Iter: 1262 loss: 0.00064626208
Iter: 1263 loss: 0.000645774067
Iter: 1264 loss: 0.000644376036
Iter: 1265 loss: 0.000650715432
Iter: 1266 loss: 0.000643866602
Iter: 1267 loss: 0.000642247382
Iter: 1268 loss: 0.000654293
Iter: 1269 loss: 0.000642120489
Iter: 1270 loss: 0.00064161577
Iter: 1271 loss: 0.000641614
Iter: 1272 loss: 0.000641143415
Iter: 1273 loss: 0.000646190369
Iter: 1274 loss: 0.000641134277
Iter: 1275 loss: 0.000640648883
Iter: 1276 loss: 0.000640008482
Iter: 1277 loss: 0.00063997024
Iter: 1278 loss: 0.000639432808
Iter: 1279 loss: 0.000638457888
Iter: 1280 loss: 0.000661724596
Iter: 1281 loss: 0.000638458179
Iter: 1282 loss: 0.000637330697
Iter: 1283 loss: 0.000645555323
Iter: 1284 loss: 0.000637229532
Iter: 1285 loss: 0.000636213
Iter: 1286 loss: 0.000635702861
Iter: 1287 loss: 0.00063522585
Iter: 1288 loss: 0.000634701457
Iter: 1289 loss: 0.000634127704
Iter: 1290 loss: 0.000633638934
Iter: 1291 loss: 0.000633826945
Iter: 1292 loss: 0.000633299234
Iter: 1293 loss: 0.000632731244
Iter: 1294 loss: 0.00063239364
Iter: 1295 loss: 0.000632153242
Iter: 1296 loss: 0.000631261617
Iter: 1297 loss: 0.000630325871
Iter: 1298 loss: 0.000630161201
Iter: 1299 loss: 0.000629035349
Iter: 1300 loss: 0.000627653033
Iter: 1301 loss: 0.000627530622
Iter: 1302 loss: 0.000625966757
Iter: 1303 loss: 0.000626564841
Iter: 1304 loss: 0.000624870881
Iter: 1305 loss: 0.000623321394
Iter: 1306 loss: 0.000622503227
Iter: 1307 loss: 0.000621799962
Iter: 1308 loss: 0.000619817234
Iter: 1309 loss: 0.000624651846
Iter: 1310 loss: 0.000619108207
Iter: 1311 loss: 0.000620741746
Iter: 1312 loss: 0.000618514838
Iter: 1313 loss: 0.00061805005
Iter: 1314 loss: 0.000617460173
Iter: 1315 loss: 0.000617414538
Iter: 1316 loss: 0.000616703415
Iter: 1317 loss: 0.000615421915
Iter: 1318 loss: 0.000646505505
Iter: 1319 loss: 0.000615422032
Iter: 1320 loss: 0.000615237514
Iter: 1321 loss: 0.000614754739
Iter: 1322 loss: 0.000614278775
Iter: 1323 loss: 0.000614483317
Iter: 1324 loss: 0.000613954267
Iter: 1325 loss: 0.000613115961
Iter: 1326 loss: 0.000615248224
Iter: 1327 loss: 0.000612820382
Iter: 1328 loss: 0.000611923169
Iter: 1329 loss: 0.00061221025
Iter: 1330 loss: 0.000611286494
Iter: 1331 loss: 0.000610562856
Iter: 1332 loss: 0.000609977113
Iter: 1333 loss: 0.000609762094
Iter: 1334 loss: 0.000608937466
Iter: 1335 loss: 0.000611204305
Iter: 1336 loss: 0.000608666916
Iter: 1337 loss: 0.000607542344
Iter: 1338 loss: 0.000623802305
Iter: 1339 loss: 0.000607541413
Iter: 1340 loss: 0.000607066
Iter: 1341 loss: 0.000606579357
Iter: 1342 loss: 0.000606484769
Iter: 1343 loss: 0.000605667243
Iter: 1344 loss: 0.000604739063
Iter: 1345 loss: 0.00060462032
Iter: 1346 loss: 0.000603875145
Iter: 1347 loss: 0.000603647029
Iter: 1348 loss: 0.000603204593
Iter: 1349 loss: 0.000602025248
Iter: 1350 loss: 0.000612816541
Iter: 1351 loss: 0.000601973035
Iter: 1352 loss: 0.000601524778
Iter: 1353 loss: 0.000601524545
Iter: 1354 loss: 0.000601113541
Iter: 1355 loss: 0.000600774
Iter: 1356 loss: 0.000600656844
Iter: 1357 loss: 0.000599732564
Iter: 1358 loss: 0.000601347594
Iter: 1359 loss: 0.000599320163
Iter: 1360 loss: 0.000598686456
Iter: 1361 loss: 0.000603897963
Iter: 1362 loss: 0.00059865
Iter: 1363 loss: 0.000598230516
Iter: 1364 loss: 0.000597893319
Iter: 1365 loss: 0.000597763865
Iter: 1366 loss: 0.00059706968
Iter: 1367 loss: 0.000596937432
Iter: 1368 loss: 0.000596471
Iter: 1369 loss: 0.000595784746
Iter: 1370 loss: 0.000600578554
Iter: 1371 loss: 0.000595721
Iter: 1372 loss: 0.000595496909
Iter: 1373 loss: 0.000595380552
Iter: 1374 loss: 0.000595161633
Iter: 1375 loss: 0.000594725425
Iter: 1376 loss: 0.000603008317
Iter: 1377 loss: 0.000594720128
Iter: 1378 loss: 0.000594156736
Iter: 1379 loss: 0.000593977631
Iter: 1380 loss: 0.000593650562
Iter: 1381 loss: 0.000592622848
Iter: 1382 loss: 0.000599892
Iter: 1383 loss: 0.000592533732
Iter: 1384 loss: 0.000591950375
Iter: 1385 loss: 0.000599431456
Iter: 1386 loss: 0.000591944787
Iter: 1387 loss: 0.000591389136
Iter: 1388 loss: 0.000591253105
Iter: 1389 loss: 0.000590903219
Iter: 1390 loss: 0.000590076
Iter: 1391 loss: 0.0005933629
Iter: 1392 loss: 0.000589885633
Iter: 1393 loss: 0.000589309609
Iter: 1394 loss: 0.000591234537
Iter: 1395 loss: 0.000589154661
Iter: 1396 loss: 0.000588520546
Iter: 1397 loss: 0.000588127761
Iter: 1398 loss: 0.000587869727
Iter: 1399 loss: 0.000587053539
Iter: 1400 loss: 0.000587527815
Iter: 1401 loss: 0.000586522277
Iter: 1402 loss: 0.000585515227
Iter: 1403 loss: 0.000584478781
Iter: 1404 loss: 0.000584288908
Iter: 1405 loss: 0.000586208305
Iter: 1406 loss: 0.000583796471
Iter: 1407 loss: 0.000583388144
Iter: 1408 loss: 0.000582542503
Iter: 1409 loss: 0.000597078761
Iter: 1410 loss: 0.000582525157
Iter: 1411 loss: 0.000581508211
Iter: 1412 loss: 0.000581352855
Iter: 1413 loss: 0.000580644351
Iter: 1414 loss: 0.000579705462
Iter: 1415 loss: 0.00057968148
Iter: 1416 loss: 0.00057904172
Iter: 1417 loss: 0.0005804908
Iter: 1418 loss: 0.000578793348
Iter: 1419 loss: 0.000577981467
Iter: 1420 loss: 0.000577686878
Iter: 1421 loss: 0.000577232218
Iter: 1422 loss: 0.000576538616
Iter: 1423 loss: 0.000578449923
Iter: 1424 loss: 0.00057631376
Iter: 1425 loss: 0.000575597573
Iter: 1426 loss: 0.000576956605
Iter: 1427 loss: 0.000575298
Iter: 1428 loss: 0.000574205071
Iter: 1429 loss: 0.000575667364
Iter: 1430 loss: 0.000573653844
Iter: 1431 loss: 0.000572394172
Iter: 1432 loss: 0.000574551872
Iter: 1433 loss: 0.000571831828
Iter: 1434 loss: 0.000570172211
Iter: 1435 loss: 0.000568937219
Iter: 1436 loss: 0.000568383
Iter: 1437 loss: 0.000567932846
Iter: 1438 loss: 0.000567414798
Iter: 1439 loss: 0.00056619395
Iter: 1440 loss: 0.00056516839
Iter: 1441 loss: 0.000564827642
Iter: 1442 loss: 0.000563711626
Iter: 1443 loss: 0.000562038214
Iter: 1444 loss: 0.000562003523
Iter: 1445 loss: 0.000560445944
Iter: 1446 loss: 0.000578934385
Iter: 1447 loss: 0.000560427667
Iter: 1448 loss: 0.000559187087
Iter: 1449 loss: 0.000564208545
Iter: 1450 loss: 0.00055890216
Iter: 1451 loss: 0.000557777938
Iter: 1452 loss: 0.000566481031
Iter: 1453 loss: 0.000557698484
Iter: 1454 loss: 0.000557370833
Iter: 1455 loss: 0.000556619721
Iter: 1456 loss: 0.000566269096
Iter: 1457 loss: 0.000556565297
Iter: 1458 loss: 0.000555482286
Iter: 1459 loss: 0.000556249404
Iter: 1460 loss: 0.000554808124
Iter: 1461 loss: 0.000553993043
Iter: 1462 loss: 0.00055388012
Iter: 1463 loss: 0.000553365273
Iter: 1464 loss: 0.000552294
Iter: 1465 loss: 0.000570625416
Iter: 1466 loss: 0.000552270561
Iter: 1467 loss: 0.000550936093
Iter: 1468 loss: 0.000566598435
Iter: 1469 loss: 0.000550915312
Iter: 1470 loss: 0.00055028405
Iter: 1471 loss: 0.000549645163
Iter: 1472 loss: 0.000549522054
Iter: 1473 loss: 0.000550709665
Iter: 1474 loss: 0.000549132121
Iter: 1475 loss: 0.000548762153
Iter: 1476 loss: 0.000547993579
Iter: 1477 loss: 0.000561662368
Iter: 1478 loss: 0.000547976
Iter: 1479 loss: 0.000547402771
Iter: 1480 loss: 0.000548710581
Iter: 1481 loss: 0.000547189615
Iter: 1482 loss: 0.000546860159
Iter: 1483 loss: 0.000545821
Iter: 1484 loss: 0.000547421048
Iter: 1485 loss: 0.000545090472
Iter: 1486 loss: 0.000544353155
Iter: 1487 loss: 0.000544287439
Iter: 1488 loss: 0.000543374219
Iter: 1489 loss: 0.000545166375
Iter: 1490 loss: 0.000542993948
Iter: 1491 loss: 0.000542225083
Iter: 1492 loss: 0.00054530846
Iter: 1493 loss: 0.000542053371
Iter: 1494 loss: 0.000541419839
Iter: 1495 loss: 0.000540465931
Iter: 1496 loss: 0.000540450274
Iter: 1497 loss: 0.000539111206
Iter: 1498 loss: 0.000541318732
Iter: 1499 loss: 0.000538496766
Iter: 1500 loss: 0.00053699041
Iter: 1501 loss: 0.000536522362
Iter: 1502 loss: 0.000535631378
Iter: 1503 loss: 0.000532835838
Iter: 1504 loss: 0.000545783085
Iter: 1505 loss: 0.000532312901
Iter: 1506 loss: 0.000530347694
Iter: 1507 loss: 0.000538644905
Iter: 1508 loss: 0.000529938727
Iter: 1509 loss: 0.000530817488
Iter: 1510 loss: 0.000529338373
Iter: 1511 loss: 0.000528837787
Iter: 1512 loss: 0.000528713455
Iter: 1513 loss: 0.000528403674
Iter: 1514 loss: 0.000527625671
Iter: 1515 loss: 0.000527136901
Iter: 1516 loss: 0.000526829506
Iter: 1517 loss: 0.000525696727
Iter: 1518 loss: 0.000525216223
Iter: 1519 loss: 0.000524633215
Iter: 1520 loss: 0.000523040537
Iter: 1521 loss: 0.000534730847
Iter: 1522 loss: 0.000522904273
Iter: 1523 loss: 0.000521947921
Iter: 1524 loss: 0.000524282921
Iter: 1525 loss: 0.000521605951
Iter: 1526 loss: 0.000520768343
Iter: 1527 loss: 0.000521109789
Iter: 1528 loss: 0.00052018906
Iter: 1529 loss: 0.000518706394
Iter: 1530 loss: 0.000524975
Iter: 1531 loss: 0.000518398592
Iter: 1532 loss: 0.00051743642
Iter: 1533 loss: 0.000518646
Iter: 1534 loss: 0.000516937813
Iter: 1535 loss: 0.00051599904
Iter: 1536 loss: 0.000516465399
Iter: 1537 loss: 0.000515373889
Iter: 1538 loss: 0.000514704734
Iter: 1539 loss: 0.000513709325
Iter: 1540 loss: 0.000513687904
Iter: 1541 loss: 0.00051515759
Iter: 1542 loss: 0.000513441744
Iter: 1543 loss: 0.000513257575
Iter: 1544 loss: 0.000513244071
Iter: 1545 loss: 0.000513104955
Iter: 1546 loss: 0.000512877479
Iter: 1547 loss: 0.000512439525
Iter: 1548 loss: 0.000521708862
Iter: 1549 loss: 0.000512437196
Iter: 1550 loss: 0.000511971652
Iter: 1551 loss: 0.000511155755
Iter: 1552 loss: 0.000511156279
Iter: 1553 loss: 0.000510478392
Iter: 1554 loss: 0.000517712091
Iter: 1555 loss: 0.000510464422
Iter: 1556 loss: 0.000509912847
Iter: 1557 loss: 0.000511251739
Iter: 1558 loss: 0.000509716338
Iter: 1559 loss: 0.000508862198
Iter: 1560 loss: 0.00051025115
Iter: 1561 loss: 0.00050847244
Iter: 1562 loss: 0.000507506833
Iter: 1563 loss: 0.000522273709
Iter: 1564 loss: 0.00050750724
Iter: 1565 loss: 0.000506910903
Iter: 1566 loss: 0.000506219745
Iter: 1567 loss: 0.000506137614
Iter: 1568 loss: 0.00050504494
Iter: 1569 loss: 0.000518602901
Iter: 1570 loss: 0.000505032
Iter: 1571 loss: 0.000504206633
Iter: 1572 loss: 0.000503336836
Iter: 1573 loss: 0.000503186253
Iter: 1574 loss: 0.000502579729
Iter: 1575 loss: 0.00050239393
Iter: 1576 loss: 0.00050186587
Iter: 1577 loss: 0.000501849339
Iter: 1578 loss: 0.000501629896
Iter: 1579 loss: 0.000501009519
Iter: 1580 loss: 0.000504283293
Iter: 1581 loss: 0.000500812079
Iter: 1582 loss: 0.000499852234
Iter: 1583 loss: 0.000502034556
Iter: 1584 loss: 0.000499492
Iter: 1585 loss: 0.000498514855
Iter: 1586 loss: 0.000499824062
Iter: 1587 loss: 0.000498028
Iter: 1588 loss: 0.000497009722
Iter: 1589 loss: 0.000501678674
Iter: 1590 loss: 0.000496815541
Iter: 1591 loss: 0.000496075838
Iter: 1592 loss: 0.000495148182
Iter: 1593 loss: 0.000495073735
Iter: 1594 loss: 0.000493653235
Iter: 1595 loss: 0.000493687403
Iter: 1596 loss: 0.00049252843
Iter: 1597 loss: 0.00049048342
Iter: 1598 loss: 0.000497817
Iter: 1599 loss: 0.00048996089
Iter: 1600 loss: 0.000488766236
Iter: 1601 loss: 0.000497647212
Iter: 1602 loss: 0.000488667865
Iter: 1603 loss: 0.000487953832
Iter: 1604 loss: 0.000487946323
Iter: 1605 loss: 0.000487352401
Iter: 1606 loss: 0.000487572455
Iter: 1607 loss: 0.000486937555
Iter: 1608 loss: 0.000487241166
Iter: 1609 loss: 0.000486627629
Iter: 1610 loss: 0.000486473786
Iter: 1611 loss: 0.000486001896
Iter: 1612 loss: 0.000487121346
Iter: 1613 loss: 0.000485730823
Iter: 1614 loss: 0.000484996854
Iter: 1615 loss: 0.000489275088
Iter: 1616 loss: 0.000484901277
Iter: 1617 loss: 0.00048398404
Iter: 1618 loss: 0.000489537837
Iter: 1619 loss: 0.000483873184
Iter: 1620 loss: 0.000483387295
Iter: 1621 loss: 0.000485188502
Iter: 1622 loss: 0.000483264419
Iter: 1623 loss: 0.000482857606
Iter: 1624 loss: 0.000482363976
Iter: 1625 loss: 0.000482314499
Iter: 1626 loss: 0.000481683936
Iter: 1627 loss: 0.000482369622
Iter: 1628 loss: 0.00048133856
Iter: 1629 loss: 0.000480620685
Iter: 1630 loss: 0.000481787254
Iter: 1631 loss: 0.000480287243
Iter: 1632 loss: 0.000479567912
Iter: 1633 loss: 0.00047992036
Iter: 1634 loss: 0.000479082577
Iter: 1635 loss: 0.00047816048
Iter: 1636 loss: 0.000478439382
Iter: 1637 loss: 0.00047749767
Iter: 1638 loss: 0.000476989109
Iter: 1639 loss: 0.000476871588
Iter: 1640 loss: 0.000476739922
Iter: 1641 loss: 0.000476658228
Iter: 1642 loss: 0.000476386747
Iter: 1643 loss: 0.000475882116
Iter: 1644 loss: 0.000487241952
Iter: 1645 loss: 0.00047588133
Iter: 1646 loss: 0.000475593726
Iter: 1647 loss: 0.000474786561
Iter: 1648 loss: 0.000478977221
Iter: 1649 loss: 0.000474529195
Iter: 1650 loss: 0.000473860768
Iter: 1651 loss: 0.000473847758
Iter: 1652 loss: 0.000473244261
Iter: 1653 loss: 0.000473718508
Iter: 1654 loss: 0.000472882268
Iter: 1655 loss: 0.000471937179
Iter: 1656 loss: 0.00047789485
Iter: 1657 loss: 0.00047182382
Iter: 1658 loss: 0.000470660976
Iter: 1659 loss: 0.000471033563
Iter: 1660 loss: 0.000469830353
Iter: 1661 loss: 0.000469031249
Iter: 1662 loss: 0.000469714694
Iter: 1663 loss: 0.000468560669
Iter: 1664 loss: 0.000467652804
Iter: 1665 loss: 0.000472065498
Iter: 1666 loss: 0.000467491103
Iter: 1667 loss: 0.000466679
Iter: 1668 loss: 0.000469821214
Iter: 1669 loss: 0.000466490339
Iter: 1670 loss: 0.000466037163
Iter: 1671 loss: 0.000465431192
Iter: 1672 loss: 0.000465396937
Iter: 1673 loss: 0.000465491117
Iter: 1674 loss: 0.00046516335
Iter: 1675 loss: 0.00046492464
Iter: 1676 loss: 0.000464570709
Iter: 1677 loss: 0.000464561192
Iter: 1678 loss: 0.000464200653
Iter: 1679 loss: 0.000463562843
Iter: 1680 loss: 0.000463561941
Iter: 1681 loss: 0.000462974276
Iter: 1682 loss: 0.00046460802
Iter: 1683 loss: 0.000462784054
Iter: 1684 loss: 0.000462348165
Iter: 1685 loss: 0.000462894386
Iter: 1686 loss: 0.000462119642
Iter: 1687 loss: 0.000461473741
Iter: 1688 loss: 0.000462693948
Iter: 1689 loss: 0.000461198302
Iter: 1690 loss: 0.000460449839
Iter: 1691 loss: 0.000466416124
Iter: 1692 loss: 0.000460400915
Iter: 1693 loss: 0.000459612755
Iter: 1694 loss: 0.000458527822
Iter: 1695 loss: 0.000458478287
Iter: 1696 loss: 0.000457439775
Iter: 1697 loss: 0.000466405239
Iter: 1698 loss: 0.000457382877
Iter: 1699 loss: 0.00045666
Iter: 1700 loss: 0.000457360933
Iter: 1701 loss: 0.000456246868
Iter: 1702 loss: 0.000455569301
Iter: 1703 loss: 0.000462752476
Iter: 1704 loss: 0.000455554458
Iter: 1705 loss: 0.000455314934
Iter: 1706 loss: 0.000455291593
Iter: 1707 loss: 0.000455051835
Iter: 1708 loss: 0.000455095724
Iter: 1709 loss: 0.000454872177
Iter: 1710 loss: 0.00045456161
Iter: 1711 loss: 0.000454041758
Iter: 1712 loss: 0.000454040972
Iter: 1713 loss: 0.000453473622
Iter: 1714 loss: 0.000459660747
Iter: 1715 loss: 0.000453461951
Iter: 1716 loss: 0.000453045272
Iter: 1717 loss: 0.000452894776
Iter: 1718 loss: 0.000452662149
Iter: 1719 loss: 0.00045207981
Iter: 1720 loss: 0.000453328976
Iter: 1721 loss: 0.000451852247
Iter: 1722 loss: 0.000451235304
Iter: 1723 loss: 0.000451380765
Iter: 1724 loss: 0.000450783118
Iter: 1725 loss: 0.000449640705
Iter: 1726 loss: 0.000455165515
Iter: 1727 loss: 0.000449437386
Iter: 1728 loss: 0.0004487111
Iter: 1729 loss: 0.000449510291
Iter: 1730 loss: 0.000448314357
Iter: 1731 loss: 0.000447564642
Iter: 1732 loss: 0.000449197716
Iter: 1733 loss: 0.000447274768
Iter: 1734 loss: 0.00044654269
Iter: 1735 loss: 0.000448503182
Iter: 1736 loss: 0.000446295715
Iter: 1737 loss: 0.000446334016
Iter: 1738 loss: 0.000446016726
Iter: 1739 loss: 0.00044573471
Iter: 1740 loss: 0.000445888087
Iter: 1741 loss: 0.000445547514
Iter: 1742 loss: 0.000445297861
Iter: 1743 loss: 0.000444804231
Iter: 1744 loss: 0.000454614783
Iter: 1745 loss: 0.000444798672
Iter: 1746 loss: 0.000444245466
Iter: 1747 loss: 0.000446961436
Iter: 1748 loss: 0.000444147532
Iter: 1749 loss: 0.000443684985
Iter: 1750 loss: 0.000444075733
Iter: 1751 loss: 0.000443410361
Iter: 1752 loss: 0.000442910619
Iter: 1753 loss: 0.000445806741
Iter: 1754 loss: 0.000442844117
Iter: 1755 loss: 0.00044235558
Iter: 1756 loss: 0.000442101038
Iter: 1757 loss: 0.000441874086
Iter: 1758 loss: 0.000441151438
Iter: 1759 loss: 0.000446505379
Iter: 1760 loss: 0.000441093202
Iter: 1761 loss: 0.000440540462
Iter: 1762 loss: 0.000441626587
Iter: 1763 loss: 0.000440314936
Iter: 1764 loss: 0.000439734111
Iter: 1765 loss: 0.000440676813
Iter: 1766 loss: 0.000439469761
Iter: 1767 loss: 0.000438701361
Iter: 1768 loss: 0.000443772733
Iter: 1769 loss: 0.000438624702
Iter: 1770 loss: 0.000438499381
Iter: 1771 loss: 0.00043839257
Iter: 1772 loss: 0.000438139716
Iter: 1773 loss: 0.000438570452
Iter: 1774 loss: 0.000438026851
Iter: 1775 loss: 0.000437779
Iter: 1776 loss: 0.000437458861
Iter: 1777 loss: 0.000437439245
Iter: 1778 loss: 0.000437032199
Iter: 1779 loss: 0.000438674237
Iter: 1780 loss: 0.000436942442
Iter: 1781 loss: 0.000436564093
Iter: 1782 loss: 0.000436737551
Iter: 1783 loss: 0.000436308648
Iter: 1784 loss: 0.00043591336
Iter: 1785 loss: 0.000436725502
Iter: 1786 loss: 0.000435755413
Iter: 1787 loss: 0.000435252732
Iter: 1788 loss: 0.00043521676
Iter: 1789 loss: 0.000434839516
Iter: 1790 loss: 0.000434273155
Iter: 1791 loss: 0.00044046095
Iter: 1792 loss: 0.000434262416
Iter: 1793 loss: 0.000433897
Iter: 1794 loss: 0.000433899229
Iter: 1795 loss: 0.000433604961
Iter: 1796 loss: 0.000433066831
Iter: 1797 loss: 0.00043229945
Iter: 1798 loss: 0.000432274071
Iter: 1799 loss: 0.000431317
Iter: 1800 loss: 0.000438758492
Iter: 1801 loss: 0.000431243097
Iter: 1802 loss: 0.000430633285
Iter: 1803 loss: 0.000429096
Iter: 1804 loss: 0.000443119148
Iter: 1805 loss: 0.00042886287
Iter: 1806 loss: 0.000441645563
Iter: 1807 loss: 0.000428629
Iter: 1808 loss: 0.000428551924
Iter: 1809 loss: 0.000428691041
Iter: 1810 loss: 0.000428519445
Iter: 1811 loss: 0.000428245112
Iter: 1812 loss: 0.000427774881
Iter: 1813 loss: 0.000427774386
Iter: 1814 loss: 0.000427278341
Iter: 1815 loss: 0.000433414389
Iter: 1816 loss: 0.000427274732
Iter: 1817 loss: 0.000426893122
Iter: 1818 loss: 0.000427314488
Iter: 1819 loss: 0.000426685961
Iter: 1820 loss: 0.000426373648
Iter: 1821 loss: 0.00042608747
Iter: 1822 loss: 0.000426009414
Iter: 1823 loss: 0.000425446051
Iter: 1824 loss: 0.00042726894
Iter: 1825 loss: 0.000425286
Iter: 1826 loss: 0.000424584
Iter: 1827 loss: 0.000425897073
Iter: 1828 loss: 0.000424282509
Iter: 1829 loss: 0.000423729798
Iter: 1830 loss: 0.000425147708
Iter: 1831 loss: 0.000423538324
Iter: 1832 loss: 0.000422882964
Iter: 1833 loss: 0.000430781511
Iter: 1834 loss: 0.000422875368
Iter: 1835 loss: 0.00042243558
Iter: 1836 loss: 0.000422056386
Iter: 1837 loss: 0.000421937846
Iter: 1838 loss: 0.00042156683
Iter: 1839 loss: 0.000421555655
Iter: 1840 loss: 0.000421388
Iter: 1841 loss: 0.000421014178
Iter: 1842 loss: 0.000426366139
Iter: 1843 loss: 0.000420996133
Iter: 1844 loss: 0.000420369412
Iter: 1845 loss: 0.000419288524
Iter: 1846 loss: 0.000419286516
Iter: 1847 loss: 0.000418595853
Iter: 1848 loss: 0.000418545329
Iter: 1849 loss: 0.000417974661
Iter: 1850 loss: 0.000427449064
Iter: 1851 loss: 0.000417974807
Iter: 1852 loss: 0.000417649571
Iter: 1853 loss: 0.000416949682
Iter: 1854 loss: 0.000427886145
Iter: 1855 loss: 0.000416926108
Iter: 1856 loss: 0.000416081923
Iter: 1857 loss: 0.000415518763
Iter: 1858 loss: 0.00041520028
Iter: 1859 loss: 0.000414270587
Iter: 1860 loss: 0.000425841892
Iter: 1861 loss: 0.000414260401
Iter: 1862 loss: 0.000413926027
Iter: 1863 loss: 0.000413879985
Iter: 1864 loss: 0.000413592468
Iter: 1865 loss: 0.000413
Iter: 1866 loss: 0.000423433376
Iter: 1867 loss: 0.00041298705
Iter: 1868 loss: 0.00041240771
Iter: 1869 loss: 0.000413568341
Iter: 1870 loss: 0.000412171241
Iter: 1871 loss: 0.000412412803
Iter: 1872 loss: 0.000411942659
Iter: 1873 loss: 0.000411821849
Iter: 1874 loss: 0.00041150325
Iter: 1875 loss: 0.0004139
Iter: 1876 loss: 0.000411438756
Iter: 1877 loss: 0.000411047251
Iter: 1878 loss: 0.000410321809
Iter: 1879 loss: 0.000426904415
Iter: 1880 loss: 0.000410319655
Iter: 1881 loss: 0.000409634289
Iter: 1882 loss: 0.000418942393
Iter: 1883 loss: 0.000409632
Iter: 1884 loss: 0.000409270433
Iter: 1885 loss: 0.000409270491
Iter: 1886 loss: 0.000409022672
Iter: 1887 loss: 0.00040863466
Iter: 1888 loss: 0.000408630091
Iter: 1889 loss: 0.000408233842
Iter: 1890 loss: 0.000407646119
Iter: 1891 loss: 0.000407632557
Iter: 1892 loss: 0.000406964158
Iter: 1893 loss: 0.000410297624
Iter: 1894 loss: 0.000406853505
Iter: 1895 loss: 0.000406547828
Iter: 1896 loss: 0.000405988481
Iter: 1897 loss: 0.000419167976
Iter: 1898 loss: 0.000405991683
Iter: 1899 loss: 0.000405666709
Iter: 1900 loss: 0.000406653737
Iter: 1901 loss: 0.000405570405
Iter: 1902 loss: 0.000405504456
Iter: 1903 loss: 0.000405318337
Iter: 1904 loss: 0.000406293169
Iter: 1905 loss: 0.000405257859
Iter: 1906 loss: 0.00040507692
Iter: 1907 loss: 0.000405297236
Iter: 1908 loss: 0.000404981081
Iter: 1909 loss: 0.000404583698
Iter: 1910 loss: 0.000408557709
Iter: 1911 loss: 0.000404572522
Iter: 1912 loss: 0.000404393417
Iter: 1913 loss: 0.000404214341
Iter: 1914 loss: 0.000404176826
Iter: 1915 loss: 0.000404019404
Iter: 1916 loss: 0.000404036604
Iter: 1917 loss: 0.000403897575
Iter: 1918 loss: 0.000403782702
Iter: 1919 loss: 0.000403586921
Iter: 1920 loss: 0.000403586659
Iter: 1921 loss: 0.000403388462
Iter: 1922 loss: 0.000403384445
Iter: 1923 loss: 0.000403136713
Iter: 1924 loss: 0.000402938342
Iter: 1925 loss: 0.000402862846
Iter: 1926 loss: 0.0004022262
Iter: 1927 loss: 0.00040379382
Iter: 1928 loss: 0.000402000413
Iter: 1929 loss: 0.000401354977
Iter: 1930 loss: 0.000404438411
Iter: 1931 loss: 0.000401239027
Iter: 1932 loss: 0.000400940597
Iter: 1933 loss: 0.00040074531
Iter: 1934 loss: 0.000400307064
Iter: 1935 loss: 0.000401249446
Iter: 1936 loss: 0.000400137331
Iter: 1937 loss: 0.000399661425
Iter: 1938 loss: 0.000399516721
Iter: 1939 loss: 0.000399235141
Iter: 1940 loss: 0.000398799137
Iter: 1941 loss: 0.000398785778
Iter: 1942 loss: 0.000398571108
Iter: 1943 loss: 0.000398566073
Iter: 1944 loss: 0.000398421427
Iter: 1945 loss: 0.000398983015
Iter: 1946 loss: 0.000398387201
Iter: 1947 loss: 0.000398245698
Iter: 1948 loss: 0.000397883297
Iter: 1949 loss: 0.000400811725
Iter: 1950 loss: 0.000397817465
Iter: 1951 loss: 0.000397215394
Iter: 1952 loss: 0.000397167343
Iter: 1953 loss: 0.000396720832
Iter: 1954 loss: 0.000396046235
Iter: 1955 loss: 0.000395404029
Iter: 1956 loss: 0.000395250623
Iter: 1957 loss: 0.000394469651
Iter: 1958 loss: 0.000394469098
Iter: 1959 loss: 0.000393685827
Iter: 1960 loss: 0.000395926065
Iter: 1961 loss: 0.000393438473
Iter: 1962 loss: 0.000393034017
Iter: 1963 loss: 0.000393975817
Iter: 1964 loss: 0.000392884365
Iter: 1965 loss: 0.000392273068
Iter: 1966 loss: 0.000394490606
Iter: 1967 loss: 0.000392119226
Iter: 1968 loss: 0.00039164492
Iter: 1969 loss: 0.000391579175
Iter: 1970 loss: 0.000391244976
Iter: 1971 loss: 0.000390858913
Iter: 1972 loss: 0.000390854897
Iter: 1973 loss: 0.000390665082
Iter: 1974 loss: 0.000390659668
Iter: 1975 loss: 0.000390529138
Iter: 1976 loss: 0.000390358153
Iter: 1977 loss: 0.000390348345
Iter: 1978 loss: 0.00038996723
Iter: 1979 loss: 0.000389039924
Iter: 1980 loss: 0.000398680801
Iter: 1981 loss: 0.000388934568
Iter: 1982 loss: 0.000388096349
Iter: 1983 loss: 0.000393064547
Iter: 1984 loss: 0.000387990091
Iter: 1985 loss: 0.000387258857
Iter: 1986 loss: 0.000387503067
Iter: 1987 loss: 0.000386742031
Iter: 1988 loss: 0.000385921274
Iter: 1989 loss: 0.000385917607
Iter: 1990 loss: 0.000385262974
Iter: 1991 loss: 0.000384769693
Iter: 1992 loss: 0.000384715619
Iter: 1993 loss: 0.000384207553
Iter: 1994 loss: 0.00038356072
Iter: 1995 loss: 0.000383512699
Iter: 1996 loss: 0.000382841798
Iter: 1997 loss: 0.000390802568
Iter: 1998 loss: 0.00038283132
Iter: 1999 loss: 0.000382140512
Iter: 2000 loss: 0.000385318097
Iter: 2001 loss: 0.000382006809
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3
+ date
Tue Oct 27 16:57:40 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -2 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fca1801b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fca3c7b5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fca3c7b5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fca3c7b5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fca000542f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fca0006df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b46268c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b464f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4626378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b45ddb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b45bbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b45648c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4564378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b451af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b451aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b453ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b44f5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b44f5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4507840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b446bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4486840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4436c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b43ff730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b43a36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b43a31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b43ca2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4388510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4339510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b43467b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b4346950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b429e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b42bd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b42bd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b429e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b429e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9b42496a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0274160542
Iter: 2 loss: 1.7989037
Iter: 3 loss: 1.79001021
Iter: 4 loss: 1.26603103
Iter: 5 loss: 1.25788546
Iter: 6 loss: 0.896434963
Iter: 7 loss: 0.888221741
Iter: 8 loss: 0.628543079
Iter: 9 loss: 0.619672656
Iter: 10 loss: 0.428569734
Iter: 11 loss: 0.418497205
Iter: 12 loss: 0.275117517
Iter: 13 loss: 0.263530731
Iter: 14 loss: 0.160318658
Iter: 15 loss: 0.14873381
Iter: 16 loss: 0.0815656707
Iter: 17 loss: 0.0721160099
Iter: 18 loss: 0.034694884
Iter: 19 loss: 0.0295075253
Iter: 20 loss: 0.0148694078
Iter: 21 loss: 0.0139263934
Iter: 22 loss: 0.0131390216
Iter: 23 loss: 0.0113034155
Iter: 24 loss: 1338.71558
Iter: 25 loss: 0.0287036952
Iter: 26 loss: 0.0131494328
Iter: 27 loss: 0.0130501539
Iter: 28 loss: 0.0113248462
Iter: 29 loss: 0.010866804
Iter: 30 loss: 0.0102215577
Iter: 31 loss: 0.00937581714
Iter: 32 loss: 0.00937063247
Iter: 33 loss: 0.00835075695
Iter: 34 loss: 0.00734625384
Iter: 35 loss: 0.00711129606
Iter: 36 loss: 0.00642729644
Iter: 37 loss: 0.0061738845
Iter: 38 loss: 0.00601385767
Iter: 39 loss: 0.00617330382
Iter: 40 loss: 0.00590136182
Iter: 41 loss: 0.00578555465
Iter: 42 loss: 0.00574326562
Iter: 43 loss: 0.0056723617
Iter: 44 loss: 0.00531862583
Iter: 45 loss: 0.00514587201
Iter: 46 loss: 0.00499910675
Iter: 47 loss: 0.00467055757
Iter: 48 loss: 0.00452402188
Iter: 49 loss: 0.00435855845
Iter: 50 loss: 0.00397586916
Iter: 51 loss: 0.00535364635
Iter: 52 loss: 0.00387985725
Iter: 53 loss: 0.00354788173
Iter: 54 loss: 0.00494879764
Iter: 55 loss: 0.00348412711
Iter: 56 loss: 0.00316596637
Iter: 57 loss: 0.00481452048
Iter: 58 loss: 0.00309956213
Iter: 59 loss: 0.00287967734
Iter: 60 loss: 0.00362287508
Iter: 61 loss: 0.00281444
Iter: 62 loss: 0.00262615224
Iter: 63 loss: 0.0042987871
Iter: 64 loss: 0.00260855979
Iter: 65 loss: 0.00242951675
Iter: 66 loss: 0.00332734501
Iter: 67 loss: 0.00240188045
Iter: 68 loss: 0.00223768339
Iter: 69 loss: 0.00219197758
Iter: 70 loss: 0.00209023105
Iter: 71 loss: 0.00195462443
Iter: 72 loss: 0.00195376202
Iter: 73 loss: 0.00200456684
Iter: 74 loss: 0.00190711394
Iter: 75 loss: 0.00186981051
Iter: 76 loss: 0.00187329378
Iter: 77 loss: 0.0018404501
Iter: 78 loss: 0.0017415341
Iter: 79 loss: 0.00192349439
Iter: 80 loss: 0.00170390285
Iter: 81 loss: 0.00162782788
Iter: 82 loss: 0.00163345202
Iter: 83 loss: 0.00156746665
Iter: 84 loss: 0.0014883246
Iter: 85 loss: 0.00181752176
Iter: 86 loss: 0.00147463451
Iter: 87 loss: 0.00139219477
Iter: 88 loss: 0.00157904974
Iter: 89 loss: 0.00136093993
Iter: 90 loss: 0.00131318101
Iter: 91 loss: 0.00130673533
Iter: 92 loss: 0.0012740806
Iter: 93 loss: 0.00121194357
Iter: 94 loss: 0.00171343063
Iter: 95 loss: 0.00120804564
Iter: 96 loss: 0.00117242325
Iter: 97 loss: 0.00121000083
Iter: 98 loss: 0.00115226186
Iter: 99 loss: 0.00110962382
Iter: 100 loss: 0.00130376185
Iter: 101 loss: 0.00110045029
Iter: 102 loss: 0.00106229284
Iter: 103 loss: 0.00140080682
Iter: 104 loss: 0.00106105045
Iter: 105 loss: 0.00104888156
Iter: 106 loss: 0.00104742986
Iter: 107 loss: 0.00103925238
Iter: 108 loss: 0.0010146891
Iter: 109 loss: 0.00108542363
Iter: 110 loss: 0.00100209482
Iter: 111 loss: 0.000966239255
Iter: 112 loss: 0.000984975602
Iter: 113 loss: 0.000942969869
Iter: 114 loss: 0.000916087709
Iter: 115 loss: 0.00103893201
Iter: 116 loss: 0.000910995645
Iter: 117 loss: 0.00088052178
Iter: 118 loss: 0.000949583657
Iter: 119 loss: 0.000868553
Iter: 120 loss: 0.000850728131
Iter: 121 loss: 0.000880849955
Iter: 122 loss: 0.000842672889
Iter: 123 loss: 0.000826365082
Iter: 124 loss: 0.000922547246
Iter: 125 loss: 0.00082433119
Iter: 126 loss: 0.000809151679
Iter: 127 loss: 0.000789363
Iter: 128 loss: 0.000788113335
Iter: 129 loss: 0.000768247759
Iter: 130 loss: 0.000875677506
Iter: 131 loss: 0.000765014789
Iter: 132 loss: 0.000750274281
Iter: 133 loss: 0.000766976736
Iter: 134 loss: 0.000742442848
Iter: 135 loss: 0.000726647268
Iter: 136 loss: 0.000848104653
Iter: 137 loss: 0.000725321122
Iter: 138 loss: 0.000729154679
Iter: 139 loss: 0.000720972195
Iter: 140 loss: 0.000717702089
Iter: 141 loss: 0.000707964296
Iter: 142 loss: 0.000741412863
Iter: 143 loss: 0.000703402911
Iter: 144 loss: 0.000693198293
Iter: 145 loss: 0.000720638433
Iter: 146 loss: 0.000689848035
Iter: 147 loss: 0.000681253383
Iter: 148 loss: 0.000686300918
Iter: 149 loss: 0.000675724354
Iter: 150 loss: 0.000665447908
Iter: 151 loss: 0.000809432298
Iter: 152 loss: 0.00066542963
Iter: 153 loss: 0.000658731326
Iter: 154 loss: 0.000672287541
Iter: 155 loss: 0.000655940268
Iter: 156 loss: 0.000650412461
Iter: 157 loss: 0.000642532948
Iter: 158 loss: 0.000642286381
Iter: 159 loss: 0.000632396957
Iter: 160 loss: 0.000649560359
Iter: 161 loss: 0.000628001522
Iter: 162 loss: 0.000619926839
Iter: 163 loss: 0.00064599287
Iter: 164 loss: 0.000617649755
Iter: 165 loss: 0.000610430725
Iter: 166 loss: 0.000658660836
Iter: 167 loss: 0.000609760405
Iter: 168 loss: 0.000606324815
Iter: 169 loss: 0.000605184818
Iter: 170 loss: 0.000603196444
Iter: 171 loss: 0.000597281847
Iter: 172 loss: 0.000600638567
Iter: 173 loss: 0.000593469245
Iter: 174 loss: 0.000594630954
Iter: 175 loss: 0.000591260963
Iter: 176 loss: 0.000589725038
Iter: 177 loss: 0.000585205504
Iter: 178 loss: 0.000601394917
Iter: 179 loss: 0.000583209912
Iter: 180 loss: 0.000576731225
Iter: 181 loss: 0.000611895637
Iter: 182 loss: 0.000575788959
Iter: 183 loss: 0.00057063892
Iter: 184 loss: 0.000583543791
Iter: 185 loss: 0.000568866089
Iter: 186 loss: 0.00056416844
Iter: 187 loss: 0.000583945424
Iter: 188 loss: 0.000563129433
Iter: 189 loss: 0.000560127082
Iter: 190 loss: 0.000560036569
Iter: 191 loss: 0.000557795225
Iter: 192 loss: 0.000553896884
Iter: 193 loss: 0.000553894322
Iter: 194 loss: 0.000549809076
Iter: 195 loss: 0.000559227949
Iter: 196 loss: 0.000548303884
Iter: 197 loss: 0.000542948663
Iter: 198 loss: 0.000561706373
Iter: 199 loss: 0.000541595509
Iter: 200 loss: 0.000538289431
Iter: 201 loss: 0.000542872876
Iter: 202 loss: 0.000536615727
Iter: 203 loss: 0.00053423841
Iter: 204 loss: 0.000533632818
Iter: 205 loss: 0.000532156788
Iter: 206 loss: 0.000530276448
Iter: 207 loss: 0.000527427648
Iter: 208 loss: 0.000527372933
Iter: 209 loss: 0.000524680421
Iter: 210 loss: 0.00052454567
Iter: 211 loss: 0.000522131217
Iter: 212 loss: 0.000519565772
Iter: 213 loss: 0.000519137073
Iter: 214 loss: 0.000516257714
Iter: 215 loss: 0.000517438632
Iter: 216 loss: 0.00051427813
Iter: 217 loss: 0.000511505525
Iter: 218 loss: 0.000507684308
Iter: 219 loss: 0.0005075105
Iter: 220 loss: 0.000505278644
Iter: 221 loss: 0.000505030155
Iter: 222 loss: 0.000502949115
Iter: 223 loss: 0.00051277614
Iter: 224 loss: 0.00050258392
Iter: 225 loss: 0.000500096
Iter: 226 loss: 0.000499531394
Iter: 227 loss: 0.00049793144
Iter: 228 loss: 0.000495117391
Iter: 229 loss: 0.000504268741
Iter: 230 loss: 0.000494323089
Iter: 231 loss: 0.000491743966
Iter: 232 loss: 0.000505671836
Iter: 233 loss: 0.000491371204
Iter: 234 loss: 0.000490148552
Iter: 235 loss: 0.000490060484
Iter: 236 loss: 0.000489229744
Iter: 237 loss: 0.000487404934
Iter: 238 loss: 0.000514053856
Iter: 239 loss: 0.00048732094
Iter: 240 loss: 0.000484788034
Iter: 241 loss: 0.000488464197
Iter: 242 loss: 0.00048355374
Iter: 243 loss: 0.000481117168
Iter: 244 loss: 0.000481088267
Iter: 245 loss: 0.000479798415
Iter: 246 loss: 0.000478576694
Iter: 247 loss: 0.000478278671
Iter: 248 loss: 0.000476235262
Iter: 249 loss: 0.000480284129
Iter: 250 loss: 0.000475397275
Iter: 251 loss: 0.000473493594
Iter: 252 loss: 0.000471933396
Iter: 253 loss: 0.00047138051
Iter: 254 loss: 0.000469803461
Iter: 255 loss: 0.000469698745
Iter: 256 loss: 0.000467889477
Iter: 257 loss: 0.000467766891
Iter: 258 loss: 0.000466410187
Iter: 259 loss: 0.000464306155
Iter: 260 loss: 0.000475831039
Iter: 261 loss: 0.000463999517
Iter: 262 loss: 0.000462267926
Iter: 263 loss: 0.000463023374
Iter: 264 loss: 0.000461087096
Iter: 265 loss: 0.000459331291
Iter: 266 loss: 0.000482510921
Iter: 267 loss: 0.000459325354
Iter: 268 loss: 0.000457802846
Iter: 269 loss: 0.000470974745
Iter: 270 loss: 0.000457714894
Iter: 271 loss: 0.000456924172
Iter: 272 loss: 0.0004554427
Iter: 273 loss: 0.000487870915
Iter: 274 loss: 0.00045543845
Iter: 275 loss: 0.00045385657
Iter: 276 loss: 0.000456512236
Iter: 277 loss: 0.000453131623
Iter: 278 loss: 0.000450807856
Iter: 279 loss: 0.00046208073
Iter: 280 loss: 0.000450412103
Iter: 281 loss: 0.000449183339
Iter: 282 loss: 0.000451185246
Iter: 283 loss: 0.000448613719
Iter: 284 loss: 0.000447153754
Iter: 285 loss: 0.000444349047
Iter: 286 loss: 0.000503035379
Iter: 287 loss: 0.000444333971
Iter: 288 loss: 0.000441804
Iter: 289 loss: 0.000456762442
Iter: 290 loss: 0.000441482756
Iter: 291 loss: 0.000439719181
Iter: 292 loss: 0.000465339283
Iter: 293 loss: 0.000439718395
Iter: 294 loss: 0.000438160816
Iter: 295 loss: 0.000443672878
Iter: 296 loss: 0.000437751383
Iter: 297 loss: 0.000436961709
Iter: 298 loss: 0.000435091322
Iter: 299 loss: 0.000456182635
Iter: 300 loss: 0.000434917281
Iter: 301 loss: 0.000433656154
Iter: 302 loss: 0.00043343805
Iter: 303 loss: 0.000432900153
Iter: 304 loss: 0.000432831293
Iter: 305 loss: 0.00043233714
Iter: 306 loss: 0.000431191758
Iter: 307 loss: 0.000445570331
Iter: 308 loss: 0.000431108114
Iter: 309 loss: 0.000429617212
Iter: 310 loss: 0.000434303103
Iter: 311 loss: 0.000429190579
Iter: 312 loss: 0.000427788036
Iter: 313 loss: 0.000440213
Iter: 314 loss: 0.00042771321
Iter: 315 loss: 0.000426458166
Iter: 316 loss: 0.000428165658
Iter: 317 loss: 0.000425835664
Iter: 318 loss: 0.000424836937
Iter: 319 loss: 0.000424272264
Iter: 320 loss: 0.000423838152
Iter: 321 loss: 0.000422034587
Iter: 322 loss: 0.00042824744
Iter: 323 loss: 0.000421562931
Iter: 324 loss: 0.000420201832
Iter: 325 loss: 0.000423692109
Iter: 326 loss: 0.00041972968
Iter: 327 loss: 0.000418986223
Iter: 328 loss: 0.000418937
Iter: 329 loss: 0.000418245385
Iter: 330 loss: 0.000416440045
Iter: 331 loss: 0.000430297252
Iter: 332 loss: 0.000416087627
Iter: 333 loss: 0.000414426962
Iter: 334 loss: 0.000421132543
Iter: 335 loss: 0.000414061098
Iter: 336 loss: 0.000412966823
Iter: 337 loss: 0.000428232539
Iter: 338 loss: 0.000412962632
Iter: 339 loss: 0.000412086869
Iter: 340 loss: 0.000423953228
Iter: 341 loss: 0.000412084803
Iter: 342 loss: 0.000411577697
Iter: 343 loss: 0.00041093849
Iter: 344 loss: 0.000410886511
Iter: 345 loss: 0.000410062552
Iter: 346 loss: 0.000409653585
Iter: 347 loss: 0.000409265602
Iter: 348 loss: 0.000408098218
Iter: 349 loss: 0.000419882243
Iter: 350 loss: 0.000408057414
Iter: 351 loss: 0.000407475018
Iter: 352 loss: 0.000406976178
Iter: 353 loss: 0.000406817184
Iter: 354 loss: 0.000405770028
Iter: 355 loss: 0.00040887
Iter: 356 loss: 0.000405446859
Iter: 357 loss: 0.000404384511
Iter: 358 loss: 0.000404076331
Iter: 359 loss: 0.000403436425
Iter: 360 loss: 0.000402069389
Iter: 361 loss: 0.00040816862
Iter: 362 loss: 0.000401798345
Iter: 363 loss: 0.000400692341
Iter: 364 loss: 0.00041608006
Iter: 365 loss: 0.000400689692
Iter: 366 loss: 0.000399729353
Iter: 367 loss: 0.000401090889
Iter: 368 loss: 0.000399256358
Iter: 369 loss: 0.00039870452
Iter: 370 loss: 0.000398162
Iter: 371 loss: 0.000398046
Iter: 372 loss: 0.000398057629
Iter: 373 loss: 0.000397600059
Iter: 374 loss: 0.000397299824
Iter: 375 loss: 0.000396790274
Iter: 376 loss: 0.000396789634
Iter: 377 loss: 0.000396051444
Iter: 378 loss: 0.000397136144
Iter: 379 loss: 0.000395692507
Iter: 380 loss: 0.000395173556
Iter: 381 loss: 0.000395173061
Iter: 382 loss: 0.000394804869
Iter: 383 loss: 0.000394137227
Iter: 384 loss: 0.000410259963
Iter: 385 loss: 0.000394137518
Iter: 386 loss: 0.000393423543
Iter: 387 loss: 0.000395215233
Iter: 388 loss: 0.000393175
Iter: 389 loss: 0.000392337941
Iter: 390 loss: 0.000393543974
Iter: 391 loss: 0.000391928916
Iter: 392 loss: 0.000391066918
Iter: 393 loss: 0.000393468566
Iter: 394 loss: 0.000390791916
Iter: 395 loss: 0.000390014116
Iter: 396 loss: 0.000394372561
Iter: 397 loss: 0.000389901747
Iter: 398 loss: 0.000389076566
Iter: 399 loss: 0.000392548216
Iter: 400 loss: 0.000388903514
Iter: 401 loss: 0.000388355926
Iter: 402 loss: 0.00038799888
Iter: 403 loss: 0.000387786946
Iter: 404 loss: 0.000387589
Iter: 405 loss: 0.000387422042
Iter: 406 loss: 0.000387020438
Iter: 407 loss: 0.000386221043
Iter: 408 loss: 0.00040173973
Iter: 409 loss: 0.000386211323
Iter: 410 loss: 0.000385511375
Iter: 411 loss: 0.00039038423
Iter: 412 loss: 0.000385447813
Iter: 413 loss: 0.000385043444
Iter: 414 loss: 0.000385950494
Iter: 415 loss: 0.000384888903
Iter: 416 loss: 0.000384310057
Iter: 417 loss: 0.000384499086
Iter: 418 loss: 0.000383900246
Iter: 419 loss: 0.000383306062
Iter: 420 loss: 0.000382658181
Iter: 421 loss: 0.000382560422
Iter: 422 loss: 0.000381612277
Iter: 423 loss: 0.000391204754
Iter: 424 loss: 0.000381583872
Iter: 425 loss: 0.000380903541
Iter: 426 loss: 0.000380201353
Iter: 427 loss: 0.000380071084
Iter: 428 loss: 0.000379062345
Iter: 429 loss: 0.000388931076
Iter: 430 loss: 0.000379027362
Iter: 431 loss: 0.000378261146
Iter: 432 loss: 0.000384540646
Iter: 433 loss: 0.000378210214
Iter: 434 loss: 0.000377620338
Iter: 435 loss: 0.000377010438
Iter: 436 loss: 0.000376899668
Iter: 437 loss: 0.000376431737
Iter: 438 loss: 0.000376429904
Iter: 439 loss: 0.000375891163
Iter: 440 loss: 0.000376108452
Iter: 441 loss: 0.000375520729
Iter: 442 loss: 0.000375117583
Iter: 443 loss: 0.000375911681
Iter: 444 loss: 0.000374951109
Iter: 445 loss: 0.000374487485
Iter: 446 loss: 0.000375097385
Iter: 447 loss: 0.000374253606
Iter: 448 loss: 0.000373640913
Iter: 449 loss: 0.0003761478
Iter: 450 loss: 0.000373504125
Iter: 451 loss: 0.000373044109
Iter: 452 loss: 0.000372291659
Iter: 453 loss: 0.000372287934
Iter: 454 loss: 0.000371504226
Iter: 455 loss: 0.000378766446
Iter: 456 loss: 0.000371468719
Iter: 457 loss: 0.000370821566
Iter: 458 loss: 0.000372230978
Iter: 459 loss: 0.000370570691
Iter: 460 loss: 0.000369943969
Iter: 461 loss: 0.000369478512
Iter: 462 loss: 0.000369267887
Iter: 463 loss: 0.000368888141
Iter: 464 loss: 0.000368689129
Iter: 465 loss: 0.000368335
Iter: 466 loss: 0.000368514739
Iter: 467 loss: 0.00036809931
Iter: 468 loss: 0.00036768784
Iter: 469 loss: 0.000368516194
Iter: 470 loss: 0.000367520552
Iter: 471 loss: 0.000366914843
Iter: 472 loss: 0.000371353352
Iter: 473 loss: 0.000366862805
Iter: 474 loss: 0.000366613036
Iter: 475 loss: 0.000366471
Iter: 476 loss: 0.000366364
Iter: 477 loss: 0.000365913846
Iter: 478 loss: 0.000367083645
Iter: 479 loss: 0.000365759188
Iter: 480 loss: 0.000365294516
Iter: 481 loss: 0.000367483648
Iter: 482 loss: 0.00036521093
Iter: 483 loss: 0.000364807376
Iter: 484 loss: 0.000363943749
Iter: 485 loss: 0.00037772904
Iter: 486 loss: 0.000363914936
Iter: 487 loss: 0.000363160332
Iter: 488 loss: 0.000367998524
Iter: 489 loss: 0.000363078376
Iter: 490 loss: 0.000362325925
Iter: 491 loss: 0.000363887521
Iter: 492 loss: 0.000362024875
Iter: 493 loss: 0.000361203682
Iter: 494 loss: 0.000361280283
Iter: 495 loss: 0.000360569335
Iter: 496 loss: 0.000360237173
Iter: 497 loss: 0.000360075413
Iter: 498 loss: 0.000359587924
Iter: 499 loss: 0.000359344762
Iter: 500 loss: 0.000359114463
Iter: 501 loss: 0.000358571036
Iter: 502 loss: 0.000362190593
Iter: 503 loss: 0.000358513818
Iter: 504 loss: 0.000358103949
Iter: 505 loss: 0.000363600295
Iter: 506 loss: 0.000358102756
Iter: 507 loss: 0.000357887882
Iter: 508 loss: 0.000357418554
Iter: 509 loss: 0.000364479551
Iter: 510 loss: 0.000357397308
Iter: 511 loss: 0.000356805453
Iter: 512 loss: 0.000359418744
Iter: 513 loss: 0.000356688164
Iter: 514 loss: 0.000356215984
Iter: 515 loss: 0.000358652294
Iter: 516 loss: 0.000356137694
Iter: 517 loss: 0.00035570265
Iter: 518 loss: 0.000354993128
Iter: 519 loss: 0.000354989694
Iter: 520 loss: 0.000354349148
Iter: 521 loss: 0.000357632933
Iter: 522 loss: 0.000354243733
Iter: 523 loss: 0.00035363069
Iter: 524 loss: 0.000356014119
Iter: 525 loss: 0.000353488402
Iter: 526 loss: 0.000352877949
Iter: 527 loss: 0.00035263953
Iter: 528 loss: 0.00035230958
Iter: 529 loss: 0.00035165454
Iter: 530 loss: 0.000359601137
Iter: 531 loss: 0.000351647264
Iter: 532 loss: 0.000351004855
Iter: 533 loss: 0.000353513635
Iter: 534 loss: 0.000350852089
Iter: 535 loss: 0.00035040587
Iter: 536 loss: 0.000350907911
Iter: 537 loss: 0.000350164424
Iter: 538 loss: 0.000349773094
Iter: 539 loss: 0.000349764305
Iter: 540 loss: 0.000349545502
Iter: 541 loss: 0.000349204114
Iter: 542 loss: 0.000349199836
Iter: 543 loss: 0.000348813599
Iter: 544 loss: 0.000350657065
Iter: 545 loss: 0.000348743197
Iter: 546 loss: 0.000348382775
Iter: 547 loss: 0.000348934322
Iter: 548 loss: 0.000348212081
Iter: 549 loss: 0.000347717083
Iter: 550 loss: 0.000348205387
Iter: 551 loss: 0.000347435882
Iter: 552 loss: 0.000346989429
Iter: 553 loss: 0.000346337387
Iter: 554 loss: 0.00034631975
Iter: 555 loss: 0.000345546578
Iter: 556 loss: 0.000353231735
Iter: 557 loss: 0.00034552018
Iter: 558 loss: 0.000344749249
Iter: 559 loss: 0.000345023844
Iter: 560 loss: 0.000344206463
Iter: 561 loss: 0.000343479624
Iter: 562 loss: 0.000346296962
Iter: 563 loss: 0.000343308842
Iter: 564 loss: 0.000342769752
Iter: 565 loss: 0.00034270715
Iter: 566 loss: 0.000342427229
Iter: 567 loss: 0.000342751388
Iter: 568 loss: 0.000342278247
Iter: 569 loss: 0.00034202094
Iter: 570 loss: 0.000345175416
Iter: 571 loss: 0.000342018204
Iter: 572 loss: 0.000341791601
Iter: 573 loss: 0.00034134218
Iter: 574 loss: 0.000350109534
Iter: 575 loss: 0.000341337
Iter: 576 loss: 0.000340796134
Iter: 577 loss: 0.000342970859
Iter: 578 loss: 0.000340676343
Iter: 579 loss: 0.000340085826
Iter: 580 loss: 0.000342590502
Iter: 581 loss: 0.000339959108
Iter: 582 loss: 0.000339475868
Iter: 583 loss: 0.000339783408
Iter: 584 loss: 0.000339169317
Iter: 585 loss: 0.000338594284
Iter: 586 loss: 0.000337979058
Iter: 587 loss: 0.000337880192
Iter: 588 loss: 0.000336905
Iter: 589 loss: 0.000340846396
Iter: 590 loss: 0.000336688769
Iter: 591 loss: 0.000335587159
Iter: 592 loss: 0.000340741302
Iter: 593 loss: 0.000335382065
Iter: 594 loss: 0.000334644
Iter: 595 loss: 0.000333951088
Iter: 596 loss: 0.000333779841
Iter: 597 loss: 0.000333528384
Iter: 598 loss: 0.000333179953
Iter: 599 loss: 0.00033276988
Iter: 600 loss: 0.000332663825
Iter: 601 loss: 0.000332408177
Iter: 602 loss: 0.000332040538
Iter: 603 loss: 0.000332019234
Iter: 604 loss: 0.000331698
Iter: 605 loss: 0.000331446383
Iter: 606 loss: 0.000331346935
Iter: 607 loss: 0.000330928946
Iter: 608 loss: 0.000331342162
Iter: 609 loss: 0.000330691691
Iter: 610 loss: 0.000330193667
Iter: 611 loss: 0.000332035415
Iter: 612 loss: 0.00033007242
Iter: 613 loss: 0.000329607399
Iter: 614 loss: 0.000330865383
Iter: 615 loss: 0.000329452159
Iter: 616 loss: 0.000329033413
Iter: 617 loss: 0.000328482944
Iter: 618 loss: 0.000328448601
Iter: 619 loss: 0.000327692193
Iter: 620 loss: 0.000330684794
Iter: 621 loss: 0.00032751984
Iter: 622 loss: 0.000326786831
Iter: 623 loss: 0.000331681
Iter: 624 loss: 0.00032671314
Iter: 625 loss: 0.000326072943
Iter: 626 loss: 0.000326167094
Iter: 627 loss: 0.000325585308
Iter: 628 loss: 0.00032489837
Iter: 629 loss: 0.000329712726
Iter: 630 loss: 0.000324838038
Iter: 631 loss: 0.000324135442
Iter: 632 loss: 0.000328389084
Iter: 633 loss: 0.000324047171
Iter: 634 loss: 0.000323680695
Iter: 635 loss: 0.000325728877
Iter: 636 loss: 0.000323630928
Iter: 637 loss: 0.000323178625
Iter: 638 loss: 0.000323186978
Iter: 639 loss: 0.000322818727
Iter: 640 loss: 0.000322309759
Iter: 641 loss: 0.000322896813
Iter: 642 loss: 0.000322038017
Iter: 643 loss: 0.000321557629
Iter: 644 loss: 0.000324327295
Iter: 645 loss: 0.000321491942
Iter: 646 loss: 0.000321050291
Iter: 647 loss: 0.000321328465
Iter: 648 loss: 0.000320770137
Iter: 649 loss: 0.000320160063
Iter: 650 loss: 0.000320525258
Iter: 651 loss: 0.000319765648
Iter: 652 loss: 0.000319078506
Iter: 653 loss: 0.000318693463
Iter: 654 loss: 0.00031839413
Iter: 655 loss: 0.000317762606
Iter: 656 loss: 0.000317742582
Iter: 657 loss: 0.000317240367
Iter: 658 loss: 0.000317325292
Iter: 659 loss: 0.00031686353
Iter: 660 loss: 0.000316316378
Iter: 661 loss: 0.000319484563
Iter: 662 loss: 0.000316242629
Iter: 663 loss: 0.0003158607
Iter: 664 loss: 0.00031584606
Iter: 665 loss: 0.000315658806
Iter: 666 loss: 0.000316105958
Iter: 667 loss: 0.000315589481
Iter: 668 loss: 0.000315337209
Iter: 669 loss: 0.000315561512
Iter: 670 loss: 0.000315189303
Iter: 671 loss: 0.000314901758
Iter: 672 loss: 0.000315143086
Iter: 673 loss: 0.000314730511
Iter: 674 loss: 0.000314371195
Iter: 675 loss: 0.00031485912
Iter: 676 loss: 0.000314190518
Iter: 677 loss: 0.000313704775
Iter: 678 loss: 0.000314526929
Iter: 679 loss: 0.000313484663
Iter: 680 loss: 0.000312994845
Iter: 681 loss: 0.000313130324
Iter: 682 loss: 0.000312642253
Iter: 683 loss: 0.000311928743
Iter: 684 loss: 0.00031159108
Iter: 685 loss: 0.000311241252
Iter: 686 loss: 0.00031045184
Iter: 687 loss: 0.000317484024
Iter: 688 loss: 0.00031041319
Iter: 689 loss: 0.000309634546
Iter: 690 loss: 0.000311794574
Iter: 691 loss: 0.000309381867
Iter: 692 loss: 0.00030860526
Iter: 693 loss: 0.000308313145
Iter: 694 loss: 0.000307886046
Iter: 695 loss: 0.000307605223
Iter: 696 loss: 0.000307306647
Iter: 697 loss: 0.000306961476
Iter: 698 loss: 0.000307574664
Iter: 699 loss: 0.000306811853
Iter: 700 loss: 0.00030635274
Iter: 701 loss: 0.000307020324
Iter: 702 loss: 0.000306126662
Iter: 703 loss: 0.000305677357
Iter: 704 loss: 0.000306422065
Iter: 705 loss: 0.000305473426
Iter: 706 loss: 0.000305052905
Iter: 707 loss: 0.000305699534
Iter: 708 loss: 0.000304852467
Iter: 709 loss: 0.00030431003
Iter: 710 loss: 0.000306137779
Iter: 711 loss: 0.000304164976
Iter: 712 loss: 0.00030366928
Iter: 713 loss: 0.000303892
Iter: 714 loss: 0.000303331937
Iter: 715 loss: 0.00030274794
Iter: 716 loss: 0.00030327955
Iter: 717 loss: 0.000302409637
Iter: 718 loss: 0.000301739667
Iter: 719 loss: 0.000302773522
Iter: 720 loss: 0.00030142389
Iter: 721 loss: 0.000300729473
Iter: 722 loss: 0.000307591894
Iter: 723 loss: 0.000300705084
Iter: 724 loss: 0.000300196611
Iter: 725 loss: 0.000299978303
Iter: 726 loss: 0.000299714797
Iter: 727 loss: 0.000299365318
Iter: 728 loss: 0.000299322157
Iter: 729 loss: 0.000298975385
Iter: 730 loss: 0.000300957967
Iter: 731 loss: 0.000298927393
Iter: 732 loss: 0.000298626081
Iter: 733 loss: 0.00029871377
Iter: 734 loss: 0.000298409723
Iter: 735 loss: 0.000297968683
Iter: 736 loss: 0.000298784813
Iter: 737 loss: 0.000297779567
Iter: 738 loss: 0.000297295453
Iter: 739 loss: 0.000296894985
Iter: 740 loss: 0.000296755985
Iter: 741 loss: 0.000295964768
Iter: 742 loss: 0.000301601365
Iter: 743 loss: 0.000295892678
Iter: 744 loss: 0.000295368169
Iter: 745 loss: 0.000295543286
Iter: 746 loss: 0.000294998317
Iter: 747 loss: 0.000294289493
Iter: 748 loss: 0.000294644531
Iter: 749 loss: 0.000293815858
Iter: 750 loss: 0.000292998622
Iter: 751 loss: 0.000294898113
Iter: 752 loss: 0.000292696175
Iter: 753 loss: 0.000292001176
Iter: 754 loss: 0.000299368403
Iter: 755 loss: 0.000291983248
Iter: 756 loss: 0.000291414472
Iter: 757 loss: 0.000291889126
Iter: 758 loss: 0.000291076809
Iter: 759 loss: 0.000290628057
Iter: 760 loss: 0.000292936864
Iter: 761 loss: 0.000290554453
Iter: 762 loss: 0.000290115364
Iter: 763 loss: 0.000296360871
Iter: 764 loss: 0.000290114956
Iter: 765 loss: 0.000289827469
Iter: 766 loss: 0.000289878197
Iter: 767 loss: 0.000289610936
Iter: 768 loss: 0.000289265823
Iter: 769 loss: 0.000290554279
Iter: 770 loss: 0.000289182964
Iter: 771 loss: 0.000288892188
Iter: 772 loss: 0.000289009069
Iter: 773 loss: 0.000288690848
Iter: 774 loss: 0.000288342795
Iter: 775 loss: 0.000289760384
Iter: 776 loss: 0.000288265961
Iter: 777 loss: 0.000287899224
Iter: 778 loss: 0.000287765812
Iter: 779 loss: 0.000287559698
Iter: 780 loss: 0.000287048577
Iter: 781 loss: 0.0002876863
Iter: 782 loss: 0.000286782422
Iter: 783 loss: 0.00028617194
Iter: 784 loss: 0.000286157156
Iter: 785 loss: 0.000285679125
Iter: 786 loss: 0.000285011192
Iter: 787 loss: 0.00029412
Iter: 788 loss: 0.000285008224
Iter: 789 loss: 0.000284482696
Iter: 790 loss: 0.000285658374
Iter: 791 loss: 0.000284283364
Iter: 792 loss: 0.000283762056
Iter: 793 loss: 0.000283803791
Iter: 794 loss: 0.000283357804
Iter: 795 loss: 0.000283050875
Iter: 796 loss: 0.000282910798
Iter: 797 loss: 0.000282647146
Iter: 798 loss: 0.000282788329
Iter: 799 loss: 0.000282474095
Iter: 800 loss: 0.000282166031
Iter: 801 loss: 0.00028244534
Iter: 802 loss: 0.00028198678
Iter: 803 loss: 0.000281580607
Iter: 804 loss: 0.000282306399
Iter: 805 loss: 0.000281403132
Iter: 806 loss: 0.000281048298
Iter: 807 loss: 0.000282291934
Iter: 808 loss: 0.000280955777
Iter: 809 loss: 0.000280584907
Iter: 810 loss: 0.000280977605
Iter: 811 loss: 0.000280381151
Iter: 812 loss: 0.000279973145
Iter: 813 loss: 0.000280298758
Iter: 814 loss: 0.000279727974
Iter: 815 loss: 0.000279246597
Iter: 816 loss: 0.000279652
Iter: 817 loss: 0.00027896103
Iter: 818 loss: 0.000278459018
Iter: 819 loss: 0.000280667155
Iter: 820 loss: 0.000278358406
Iter: 821 loss: 0.000277819112
Iter: 822 loss: 0.000279973698
Iter: 823 loss: 0.000277697924
Iter: 824 loss: 0.000277270941
Iter: 825 loss: 0.000278053194
Iter: 826 loss: 0.000277086277
Iter: 827 loss: 0.000277014216
Iter: 828 loss: 0.000276881503
Iter: 829 loss: 0.000276728882
Iter: 830 loss: 0.000276723236
Iter: 831 loss: 0.000276604609
Iter: 832 loss: 0.000276387262
Iter: 833 loss: 0.000276218023
Iter: 834 loss: 0.000276150822
Iter: 835 loss: 0.000275770493
Iter: 836 loss: 0.00027798384
Iter: 837 loss: 0.000275719271
Iter: 838 loss: 0.000275449886
Iter: 839 loss: 0.000275204802
Iter: 840 loss: 0.000275138707
Iter: 841 loss: 0.000274589373
Iter: 842 loss: 0.000276584178
Iter: 843 loss: 0.000274449878
Iter: 844 loss: 0.000274056103
Iter: 845 loss: 0.000274737424
Iter: 846 loss: 0.000273881364
Iter: 847 loss: 0.00027345898
Iter: 848 loss: 0.000273417099
Iter: 849 loss: 0.000273107202
Iter: 850 loss: 0.000272544683
Iter: 851 loss: 0.000274582766
Iter: 852 loss: 0.000272403471
Iter: 853 loss: 0.000271887926
Iter: 854 loss: 0.000275873666
Iter: 855 loss: 0.00027184916
Iter: 856 loss: 0.000271426776
Iter: 857 loss: 0.000271833123
Iter: 858 loss: 0.000271186931
Iter: 859 loss: 0.000271142024
Iter: 860 loss: 0.000270998571
Iter: 861 loss: 0.000270820747
Iter: 862 loss: 0.000270945544
Iter: 863 loss: 0.000270710938
Iter: 864 loss: 0.000270489894
Iter: 865 loss: 0.00027012013
Iter: 866 loss: 0.000270118937
Iter: 867 loss: 0.000269712706
Iter: 868 loss: 0.000275117112
Iter: 869 loss: 0.000269711483
Iter: 870 loss: 0.000269441924
Iter: 871 loss: 0.000269166718
Iter: 872 loss: 0.000269114273
Iter: 873 loss: 0.000268690463
Iter: 874 loss: 0.000271688332
Iter: 875 loss: 0.000268653035
Iter: 876 loss: 0.000268326956
Iter: 877 loss: 0.000268085249
Iter: 878 loss: 0.00026797608
Iter: 879 loss: 0.000267433119
Iter: 880 loss: 0.000268308853
Iter: 881 loss: 0.000267183204
Iter: 882 loss: 0.000266639312
Iter: 883 loss: 0.00026750454
Iter: 884 loss: 0.00026638672
Iter: 885 loss: 0.000265854294
Iter: 886 loss: 0.000271215395
Iter: 887 loss: 0.000265837298
Iter: 888 loss: 0.000265392155
Iter: 889 loss: 0.000266140501
Iter: 890 loss: 0.000265190523
Iter: 891 loss: 0.000264929899
Iter: 892 loss: 0.000264927919
Iter: 893 loss: 0.000264657021
Iter: 894 loss: 0.000264802482
Iter: 895 loss: 0.000264476868
Iter: 896 loss: 0.000264136412
Iter: 897 loss: 0.000263912894
Iter: 898 loss: 0.000263783324
Iter: 899 loss: 0.000263460912
Iter: 900 loss: 0.00026346033
Iter: 901 loss: 0.000263206573
Iter: 902 loss: 0.000262903108
Iter: 903 loss: 0.000262872432
Iter: 904 loss: 0.000262509682
Iter: 905 loss: 0.000264755567
Iter: 906 loss: 0.000262466958
Iter: 907 loss: 0.000262177229
Iter: 908 loss: 0.000262166461
Iter: 909 loss: 0.000261943293
Iter: 910 loss: 0.000261477864
Iter: 911 loss: 0.000261716312
Iter: 912 loss: 0.000261167
Iter: 913 loss: 0.000260509725
Iter: 914 loss: 0.000261985406
Iter: 915 loss: 0.000260260102
Iter: 916 loss: 0.00025974086
Iter: 917 loss: 0.000262832036
Iter: 918 loss: 0.000259674562
Iter: 919 loss: 0.000259136839
Iter: 920 loss: 0.000260055938
Iter: 921 loss: 0.000258895743
Iter: 922 loss: 0.000258520304
Iter: 923 loss: 0.000263775146
Iter: 924 loss: 0.000258518674
Iter: 925 loss: 0.000258131127
Iter: 926 loss: 0.000260902
Iter: 927 loss: 0.000258097658
Iter: 928 loss: 0.000257892912
Iter: 929 loss: 0.000257612817
Iter: 930 loss: 0.000257599808
Iter: 931 loss: 0.000257266569
Iter: 932 loss: 0.000258553133
Iter: 933 loss: 0.000257189793
Iter: 934 loss: 0.000256777916
Iter: 935 loss: 0.000257322361
Iter: 936 loss: 0.000256568426
Iter: 937 loss: 0.000256259751
Iter: 938 loss: 0.00025738508
Iter: 939 loss: 0.000256182626
Iter: 940 loss: 0.000255818886
Iter: 941 loss: 0.000255662977
Iter: 942 loss: 0.000255473773
Iter: 943 loss: 0.000254955754
Iter: 944 loss: 0.000256109459
Iter: 945 loss: 0.000254758401
Iter: 946 loss: 0.00025428785
Iter: 947 loss: 0.000255324354
Iter: 948 loss: 0.00025410665
Iter: 949 loss: 0.000253663544
Iter: 950 loss: 0.000255606603
Iter: 951 loss: 0.000253574253
Iter: 952 loss: 0.000253115169
Iter: 953 loss: 0.000255245162
Iter: 954 loss: 0.000253029284
Iter: 955 loss: 0.000252654834
Iter: 956 loss: 0.000253197271
Iter: 957 loss: 0.000252474158
Iter: 958 loss: 0.000252116093
Iter: 959 loss: 0.000252103753
Iter: 960 loss: 0.0002519314
Iter: 961 loss: 0.000251612219
Iter: 962 loss: 0.000258776796
Iter: 963 loss: 0.000251611695
Iter: 964 loss: 0.000251244288
Iter: 965 loss: 0.00025232535
Iter: 966 loss: 0.000251130405
Iter: 967 loss: 0.000250730867
Iter: 968 loss: 0.000253482081
Iter: 969 loss: 0.000250694051
Iter: 970 loss: 0.000250471174
Iter: 971 loss: 0.000250366807
Iter: 972 loss: 0.000250257319
Iter: 973 loss: 0.000249893841
Iter: 974 loss: 0.000250882353
Iter: 975 loss: 0.000249774428
Iter: 976 loss: 0.000249462057
Iter: 977 loss: 0.000249421893
Iter: 978 loss: 0.000249199657
Iter: 979 loss: 0.000248716213
Iter: 980 loss: 0.000249862875
Iter: 981 loss: 0.000248540484
Iter: 982 loss: 0.000248154945
Iter: 983 loss: 0.000249787641
Iter: 984 loss: 0.0002480736
Iter: 985 loss: 0.000247753167
Iter: 986 loss: 0.000250153651
Iter: 987 loss: 0.00024772808
Iter: 988 loss: 0.00024747962
Iter: 989 loss: 0.000247589196
Iter: 990 loss: 0.000247310643
Iter: 991 loss: 0.000247308111
Iter: 992 loss: 0.000247166667
Iter: 993 loss: 0.000247073971
Iter: 994 loss: 0.000246838725
Iter: 995 loss: 0.00024896994
Iter: 996 loss: 0.000246803043
Iter: 997 loss: 0.000246493611
Iter: 998 loss: 0.000246782234
Iter: 999 loss: 0.000246315321
Iter: 1000 loss: 0.000246060255
Iter: 1001 loss: 0.000246059091
Iter: 1002 loss: 0.000245873525
Iter: 1003 loss: 0.000245510688
Iter: 1004 loss: 0.000252803904
Iter: 1005 loss: 0.000245507632
Iter: 1006 loss: 0.000245154981
Iter: 1007 loss: 0.000250442041
Iter: 1008 loss: 0.000245154835
Iter: 1009 loss: 0.000244911527
Iter: 1010 loss: 0.000245026866
Iter: 1011 loss: 0.000244746741
Iter: 1012 loss: 0.000244494178
Iter: 1013 loss: 0.000244477851
Iter: 1014 loss: 0.000244286726
Iter: 1015 loss: 0.000243882736
Iter: 1016 loss: 0.000244443945
Iter: 1017 loss: 0.000243682633
Iter: 1018 loss: 0.000243318529
Iter: 1019 loss: 0.000246277312
Iter: 1020 loss: 0.000243294606
Iter: 1021 loss: 0.000242909882
Iter: 1022 loss: 0.000244085357
Iter: 1023 loss: 0.000242795504
Iter: 1024 loss: 0.00024265275
Iter: 1025 loss: 0.000242609487
Iter: 1026 loss: 0.000242451613
Iter: 1027 loss: 0.000242246475
Iter: 1028 loss: 0.000242232869
Iter: 1029 loss: 0.000242015405
Iter: 1030 loss: 0.000242194408
Iter: 1031 loss: 0.000241885296
Iter: 1032 loss: 0.000241657792
Iter: 1033 loss: 0.000244492199
Iter: 1034 loss: 0.000241654794
Iter: 1035 loss: 0.000241440517
Iter: 1036 loss: 0.000241082627
Iter: 1037 loss: 0.000241080837
Iter: 1038 loss: 0.000240717694
Iter: 1039 loss: 0.00024226286
Iter: 1040 loss: 0.000240642432
Iter: 1041 loss: 0.000240260269
Iter: 1042 loss: 0.000240739
Iter: 1043 loss: 0.000240061461
Iter: 1044 loss: 0.000239691813
Iter: 1045 loss: 0.00024065857
Iter: 1046 loss: 0.000239566463
Iter: 1047 loss: 0.000239179455
Iter: 1048 loss: 0.000239464309
Iter: 1049 loss: 0.000238939974
Iter: 1050 loss: 0.00023842536
Iter: 1051 loss: 0.000239060988
Iter: 1052 loss: 0.000238158798
Iter: 1053 loss: 0.000237736313
Iter: 1054 loss: 0.000237731409
Iter: 1055 loss: 0.000237556742
Iter: 1056 loss: 0.000237556378
Iter: 1057 loss: 0.000237368105
Iter: 1058 loss: 0.000237153217
Iter: 1059 loss: 0.000237126776
Iter: 1060 loss: 0.000236884618
Iter: 1061 loss: 0.000237020548
Iter: 1062 loss: 0.000236726744
Iter: 1063 loss: 0.000236483887
Iter: 1064 loss: 0.000237909815
Iter: 1065 loss: 0.000236451713
Iter: 1066 loss: 0.000236162799
Iter: 1067 loss: 0.000236296939
Iter: 1068 loss: 0.000235967978
Iter: 1069 loss: 0.000235668442
Iter: 1070 loss: 0.000235721178
Iter: 1071 loss: 0.000235443236
Iter: 1072 loss: 0.000235073123
Iter: 1073 loss: 0.000238572306
Iter: 1074 loss: 0.000235057552
Iter: 1075 loss: 0.000234792824
Iter: 1076 loss: 0.000234486157
Iter: 1077 loss: 0.00023444921
Iter: 1078 loss: 0.000233964718
Iter: 1079 loss: 0.00023622546
Iter: 1080 loss: 0.00023387486
Iter: 1081 loss: 0.000233510975
Iter: 1082 loss: 0.000234020234
Iter: 1083 loss: 0.000233331361
Iter: 1084 loss: 0.000232995837
Iter: 1085 loss: 0.000236431239
Iter: 1086 loss: 0.000232986189
Iter: 1087 loss: 0.00023276094
Iter: 1088 loss: 0.000235269021
Iter: 1089 loss: 0.000232755556
Iter: 1090 loss: 0.00023254205
Iter: 1091 loss: 0.00023309511
Iter: 1092 loss: 0.000232469654
Iter: 1093 loss: 0.00023234071
Iter: 1094 loss: 0.000232082733
Iter: 1095 loss: 0.000237095737
Iter: 1096 loss: 0.000232080172
Iter: 1097 loss: 0.000231745478
Iter: 1098 loss: 0.00023330198
Iter: 1099 loss: 0.0002316842
Iter: 1100 loss: 0.000231402373
Iter: 1101 loss: 0.000235374668
Iter: 1102 loss: 0.000231402693
Iter: 1103 loss: 0.000231259502
Iter: 1104 loss: 0.000230911071
Iter: 1105 loss: 0.000234472653
Iter: 1106 loss: 0.000230869307
Iter: 1107 loss: 0.00023049544
Iter: 1108 loss: 0.000234781357
Iter: 1109 loss: 0.00023048924
Iter: 1110 loss: 0.000230171281
Iter: 1111 loss: 0.000230439953
Iter: 1112 loss: 0.000229983008
Iter: 1113 loss: 0.000229672223
Iter: 1114 loss: 0.000229880694
Iter: 1115 loss: 0.000229476384
Iter: 1116 loss: 0.000229067751
Iter: 1117 loss: 0.000229986821
Iter: 1118 loss: 0.000228912395
Iter: 1119 loss: 0.000228551638
Iter: 1120 loss: 0.00022981799
Iter: 1121 loss: 0.00022845692
Iter: 1122 loss: 0.000228196
Iter: 1123 loss: 0.000228191537
Iter: 1124 loss: 0.000227969402
Iter: 1125 loss: 0.000229309808
Iter: 1126 loss: 0.000227941448
Iter: 1127 loss: 0.000227801938
Iter: 1128 loss: 0.000227448603
Iter: 1129 loss: 0.000230534264
Iter: 1130 loss: 0.000227391181
Iter: 1131 loss: 0.000227022072
Iter: 1132 loss: 0.000228943667
Iter: 1133 loss: 0.000226962889
Iter: 1134 loss: 0.000226696924
Iter: 1135 loss: 0.000226696502
Iter: 1136 loss: 0.000226470045
Iter: 1137 loss: 0.000226395714
Iter: 1138 loss: 0.000226263772
Iter: 1139 loss: 0.00022605728
Iter: 1140 loss: 0.000226049538
Iter: 1141 loss: 0.000225889758
Iter: 1142 loss: 0.000225623022
Iter: 1143 loss: 0.000228503457
Iter: 1144 loss: 0.000225616503
Iter: 1145 loss: 0.00022545112
Iter: 1146 loss: 0.000225451964
Iter: 1147 loss: 0.000225318654
Iter: 1148 loss: 0.000225071941
Iter: 1149 loss: 0.000225485972
Iter: 1150 loss: 0.000224958974
Iter: 1151 loss: 0.000224676391
Iter: 1152 loss: 0.000225249751
Iter: 1153 loss: 0.00022456194
Iter: 1154 loss: 0.000224358955
Iter: 1155 loss: 0.000224359086
Iter: 1156 loss: 0.000224214222
Iter: 1157 loss: 0.000226447868
Iter: 1158 loss: 0.000224213931
Iter: 1159 loss: 0.000224116637
Iter: 1160 loss: 0.000223906856
Iter: 1161 loss: 0.000227197976
Iter: 1162 loss: 0.000223899289
Iter: 1163 loss: 0.000223691153
Iter: 1164 loss: 0.000223616109
Iter: 1165 loss: 0.000223499024
Iter: 1166 loss: 0.000223288371
Iter: 1167 loss: 0.000223287367
Iter: 1168 loss: 0.00022309937
Iter: 1169 loss: 0.000223732903
Iter: 1170 loss: 0.000223048861
Iter: 1171 loss: 0.000222879011
Iter: 1172 loss: 0.000222656206
Iter: 1173 loss: 0.000222642557
Iter: 1174 loss: 0.000222413946
Iter: 1175 loss: 0.000223608862
Iter: 1176 loss: 0.000222377508
Iter: 1177 loss: 0.000222098941
Iter: 1178 loss: 0.000222548231
Iter: 1179 loss: 0.000221970287
Iter: 1180 loss: 0.000221760813
Iter: 1181 loss: 0.000221997572
Iter: 1182 loss: 0.000221648137
Iter: 1183 loss: 0.000221353723
Iter: 1184 loss: 0.000221568072
Iter: 1185 loss: 0.000221171198
Iter: 1186 loss: 0.000220907939
Iter: 1187 loss: 0.000223357929
Iter: 1188 loss: 0.000220896269
Iter: 1189 loss: 0.000220845133
Iter: 1190 loss: 0.000220794551
Iter: 1191 loss: 0.000220702772
Iter: 1192 loss: 0.000220544796
Iter: 1193 loss: 0.000220544302
Iter: 1194 loss: 0.000220339512
Iter: 1195 loss: 0.000220041315
Iter: 1196 loss: 0.000220032874
Iter: 1197 loss: 0.000219742709
Iter: 1198 loss: 0.000220170972
Iter: 1199 loss: 0.000219603593
Iter: 1200 loss: 0.000219509893
Iter: 1201 loss: 0.000219425274
Iter: 1202 loss: 0.000219286929
Iter: 1203 loss: 0.000219316775
Iter: 1204 loss: 0.000219184541
Iter: 1205 loss: 0.000219019377
Iter: 1206 loss: 0.000218848101
Iter: 1207 loss: 0.000218816916
Iter: 1208 loss: 0.000218528163
Iter: 1209 loss: 0.000219049602
Iter: 1210 loss: 0.000218403657
Iter: 1211 loss: 0.000218179281
Iter: 1212 loss: 0.000218177433
Iter: 1213 loss: 0.000218038665
Iter: 1214 loss: 0.000217775785
Iter: 1215 loss: 0.000223442301
Iter: 1216 loss: 0.000217774679
Iter: 1217 loss: 0.000217505527
Iter: 1218 loss: 0.000220344984
Iter: 1219 loss: 0.000217498397
Iter: 1220 loss: 0.00021733476
Iter: 1221 loss: 0.000218841422
Iter: 1222 loss: 0.00021732715
Iter: 1223 loss: 0.000217176537
Iter: 1224 loss: 0.000218458
Iter: 1225 loss: 0.000217167631
Iter: 1226 loss: 0.000217084089
Iter: 1227 loss: 0.000216917382
Iter: 1228 loss: 0.000220084825
Iter: 1229 loss: 0.000216914734
Iter: 1230 loss: 0.000216688233
Iter: 1231 loss: 0.00021656591
Iter: 1232 loss: 0.000216463552
Iter: 1233 loss: 0.000216159417
Iter: 1234 loss: 0.000216315791
Iter: 1235 loss: 0.000215956738
Iter: 1236 loss: 0.000216030807
Iter: 1237 loss: 0.00021579524
Iter: 1238 loss: 0.00021567072
Iter: 1239 loss: 0.000215396751
Iter: 1240 loss: 0.000219409674
Iter: 1241 loss: 0.00021538377
Iter: 1242 loss: 0.000215142558
Iter: 1243 loss: 0.000215688677
Iter: 1244 loss: 0.000215051
Iter: 1245 loss: 0.000214765765
Iter: 1246 loss: 0.000215078762
Iter: 1247 loss: 0.000214609754
Iter: 1248 loss: 0.000214285712
Iter: 1249 loss: 0.000214731539
Iter: 1250 loss: 0.000214123836
Iter: 1251 loss: 0.000213892461
Iter: 1252 loss: 0.000213873485
Iter: 1253 loss: 0.000213705294
Iter: 1254 loss: 0.000213529071
Iter: 1255 loss: 0.000213498584
Iter: 1256 loss: 0.00021349515
Iter: 1257 loss: 0.000213386447
Iter: 1258 loss: 0.000213323889
Iter: 1259 loss: 0.000213195526
Iter: 1260 loss: 0.000215534368
Iter: 1261 loss: 0.000213192528
Iter: 1262 loss: 0.000213008432
Iter: 1263 loss: 0.000212977873
Iter: 1264 loss: 0.000212852072
Iter: 1265 loss: 0.00021268893
Iter: 1266 loss: 0.00021232455
Iter: 1267 loss: 0.000217336477
Iter: 1268 loss: 0.000212303086
Iter: 1269 loss: 0.000211968552
Iter: 1270 loss: 0.000215243082
Iter: 1271 loss: 0.000211956474
Iter: 1272 loss: 0.000211717415
Iter: 1273 loss: 0.000213757565
Iter: 1274 loss: 0.000211704391
Iter: 1275 loss: 0.000211507606
Iter: 1276 loss: 0.000212492378
Iter: 1277 loss: 0.000211474136
Iter: 1278 loss: 0.000211282197
Iter: 1279 loss: 0.000210860686
Iter: 1280 loss: 0.000217090826
Iter: 1281 loss: 0.000210842438
Iter: 1282 loss: 0.000210574086
Iter: 1283 loss: 0.000210571248
Iter: 1284 loss: 0.000210367187
Iter: 1285 loss: 0.00021028136
Iter: 1286 loss: 0.000210174912
Iter: 1287 loss: 0.000209988095
Iter: 1288 loss: 0.000211816354
Iter: 1289 loss: 0.000209981052
Iter: 1290 loss: 0.000209846505
Iter: 1291 loss: 0.000210586
Iter: 1292 loss: 0.000209826583
Iter: 1293 loss: 0.000209671372
Iter: 1294 loss: 0.000209678939
Iter: 1295 loss: 0.000209548045
Iter: 1296 loss: 0.000209440273
Iter: 1297 loss: 0.000209197722
Iter: 1298 loss: 0.000212510437
Iter: 1299 loss: 0.000209184029
Iter: 1300 loss: 0.000208865284
Iter: 1301 loss: 0.000209401333
Iter: 1302 loss: 0.000208720856
Iter: 1303 loss: 0.000208355967
Iter: 1304 loss: 0.000213536536
Iter: 1305 loss: 0.000208354875
Iter: 1306 loss: 0.000208229147
Iter: 1307 loss: 0.000208045763
Iter: 1308 loss: 0.000208040117
Iter: 1309 loss: 0.000207826262
Iter: 1310 loss: 0.000207825098
Iter: 1311 loss: 0.000207657897
Iter: 1312 loss: 0.000207391742
Iter: 1313 loss: 0.000207389268
Iter: 1314 loss: 0.000207118748
Iter: 1315 loss: 0.000207870544
Iter: 1316 loss: 0.000207032106
Iter: 1317 loss: 0.000206741155
Iter: 1318 loss: 0.000206917961
Iter: 1319 loss: 0.00020655377
Iter: 1320 loss: 0.00020629332
Iter: 1321 loss: 0.000207369943
Iter: 1322 loss: 0.000206237484
Iter: 1323 loss: 0.000206251701
Iter: 1324 loss: 0.000206113677
Iter: 1325 loss: 0.000206007782
Iter: 1326 loss: 0.000205877674
Iter: 1327 loss: 0.000205866454
Iter: 1328 loss: 0.000205703749
Iter: 1329 loss: 0.000205758843
Iter: 1330 loss: 0.000205589546
Iter: 1331 loss: 0.000205406628
Iter: 1332 loss: 0.00020576235
Iter: 1333 loss: 0.000205331045
Iter: 1334 loss: 0.000205116725
Iter: 1335 loss: 0.000205612901
Iter: 1336 loss: 0.000205037039
Iter: 1337 loss: 0.000204858196
Iter: 1338 loss: 0.000207297315
Iter: 1339 loss: 0.000204856624
Iter: 1340 loss: 0.000204742086
Iter: 1341 loss: 0.000204851807
Iter: 1342 loss: 0.000204676122
Iter: 1343 loss: 0.00020451576
Iter: 1344 loss: 0.000205135628
Iter: 1345 loss: 0.000204478274
Iter: 1346 loss: 0.000204391123
Iter: 1347 loss: 0.000204184442
Iter: 1348 loss: 0.000206551747
Iter: 1349 loss: 0.000204164884
Iter: 1350 loss: 0.000203910575
Iter: 1351 loss: 0.000205264863
Iter: 1352 loss: 0.000203871445
Iter: 1353 loss: 0.000203638687
Iter: 1354 loss: 0.000203882359
Iter: 1355 loss: 0.000203510121
Iter: 1356 loss: 0.00020331837
Iter: 1357 loss: 0.00020460994
Iter: 1358 loss: 0.0002033
Iter: 1359 loss: 0.000203088071
Iter: 1360 loss: 0.00020512045
Iter: 1361 loss: 0.000203079107
Iter: 1362 loss: 0.000203012372
Iter: 1363 loss: 0.000202854339
Iter: 1364 loss: 0.000204695563
Iter: 1365 loss: 0.000202839758
Iter: 1366 loss: 0.000202600495
Iter: 1367 loss: 0.00020291713
Iter: 1368 loss: 0.000202479205
Iter: 1369 loss: 0.000202265204
Iter: 1370 loss: 0.000203893258
Iter: 1371 loss: 0.000202249066
Iter: 1372 loss: 0.000202099443
Iter: 1373 loss: 0.000202989409
Iter: 1374 loss: 0.000202079274
Iter: 1375 loss: 0.000201951858
Iter: 1376 loss: 0.000202302879
Iter: 1377 loss: 0.00020191056
Iter: 1378 loss: 0.000201780756
Iter: 1379 loss: 0.000202178941
Iter: 1380 loss: 0.000201742136
Iter: 1381 loss: 0.00020162572
Iter: 1382 loss: 0.00020155996
Iter: 1383 loss: 0.000201509829
Iter: 1384 loss: 0.00020131965
Iter: 1385 loss: 0.000201283241
Iter: 1386 loss: 0.000201155781
Iter: 1387 loss: 0.000200893075
Iter: 1388 loss: 0.000201995164
Iter: 1389 loss: 0.000200836716
Iter: 1390 loss: 0.000200588212
Iter: 1391 loss: 0.000202436699
Iter: 1392 loss: 0.00020056896
Iter: 1393 loss: 0.000200527546
Iter: 1394 loss: 0.000200463488
Iter: 1395 loss: 0.000200422597
Iter: 1396 loss: 0.000200288123
Iter: 1397 loss: 0.000200258015
Iter: 1398 loss: 0.000200138689
Iter: 1399 loss: 0.000199921
Iter: 1400 loss: 0.000202371244
Iter: 1401 loss: 0.000199916423
Iter: 1402 loss: 0.000199772025
Iter: 1403 loss: 0.000199798902
Iter: 1404 loss: 0.000199664311
Iter: 1405 loss: 0.000199531263
Iter: 1406 loss: 0.000201508956
Iter: 1407 loss: 0.000199531496
Iter: 1408 loss: 0.000199404254
Iter: 1409 loss: 0.000199606468
Iter: 1410 loss: 0.000199345319
Iter: 1411 loss: 0.00019923746
Iter: 1412 loss: 0.000199717382
Iter: 1413 loss: 0.000199216534
Iter: 1414 loss: 0.000199146278
Iter: 1415 loss: 0.000199011323
Iter: 1416 loss: 0.000201856237
Iter: 1417 loss: 0.000199010843
Iter: 1418 loss: 0.00019875943
Iter: 1419 loss: 0.000199160306
Iter: 1420 loss: 0.00019864249
Iter: 1421 loss: 0.000198415379
Iter: 1422 loss: 0.000199022659
Iter: 1423 loss: 0.000198339054
Iter: 1424 loss: 0.000198138034
Iter: 1425 loss: 0.000198432579
Iter: 1426 loss: 0.000198041322
Iter: 1427 loss: 0.00019790337
Iter: 1428 loss: 0.000197903049
Iter: 1429 loss: 0.000197764
Iter: 1430 loss: 0.000197444708
Iter: 1431 loss: 0.000201544433
Iter: 1432 loss: 0.00019742272
Iter: 1433 loss: 0.000197213725
Iter: 1434 loss: 0.000197785455
Iter: 1435 loss: 0.000197145418
Iter: 1436 loss: 0.000196924957
Iter: 1437 loss: 0.000197866757
Iter: 1438 loss: 0.000196879468
Iter: 1439 loss: 0.00019672139
Iter: 1440 loss: 0.00019683619
Iter: 1441 loss: 0.00019662347
Iter: 1442 loss: 0.000196426307
Iter: 1443 loss: 0.0001995005
Iter: 1444 loss: 0.000196426408
Iter: 1445 loss: 0.000196317662
Iter: 1446 loss: 0.000196912297
Iter: 1447 loss: 0.000196301786
Iter: 1448 loss: 0.00019621478
Iter: 1449 loss: 0.000195971166
Iter: 1450 loss: 0.000197196059
Iter: 1451 loss: 0.00019589033
Iter: 1452 loss: 0.000195640576
Iter: 1453 loss: 0.00019809205
Iter: 1454 loss: 0.000195632107
Iter: 1455 loss: 0.000195430606
Iter: 1456 loss: 0.00019561121
Iter: 1457 loss: 0.000195314526
Iter: 1458 loss: 0.00019516368
Iter: 1459 loss: 0.000195156332
Iter: 1460 loss: 0.000195064917
Iter: 1461 loss: 0.000196168985
Iter: 1462 loss: 0.000195064102
Iter: 1463 loss: 0.000194976572
Iter: 1464 loss: 0.00019486848
Iter: 1465 loss: 0.0001948594
Iter: 1466 loss: 0.000194748485
Iter: 1467 loss: 0.000194694381
Iter: 1468 loss: 0.000194641063
Iter: 1469 loss: 0.000194487147
Iter: 1470 loss: 0.000195934146
Iter: 1471 loss: 0.000194480803
Iter: 1472 loss: 0.000194357635
Iter: 1473 loss: 0.000194340042
Iter: 1474 loss: 0.000194253284
Iter: 1475 loss: 0.000194109307
Iter: 1476 loss: 0.000194109074
Iter: 1477 loss: 0.000194016611
Iter: 1478 loss: 0.000194562235
Iter: 1479 loss: 0.000194004853
Iter: 1480 loss: 0.000193925618
Iter: 1481 loss: 0.000193736661
Iter: 1482 loss: 0.000195897766
Iter: 1483 loss: 0.000193718821
Iter: 1484 loss: 0.000193557935
Iter: 1485 loss: 0.000193914922
Iter: 1486 loss: 0.000193496831
Iter: 1487 loss: 0.000193306449
Iter: 1488 loss: 0.000193800297
Iter: 1489 loss: 0.000193241111
Iter: 1490 loss: 0.000193116051
Iter: 1491 loss: 0.000193116197
Iter: 1492 loss: 0.000193038286
Iter: 1493 loss: 0.000193037878
Iter: 1494 loss: 0.00019296963
Iter: 1495 loss: 0.000192904641
Iter: 1496 loss: 0.000192889056
Iter: 1497 loss: 0.000192804684
Iter: 1498 loss: 0.000192691368
Iter: 1499 loss: 0.000192685169
Iter: 1500 loss: 0.000192538748
Iter: 1501 loss: 0.000193712098
Iter: 1502 loss: 0.000192529347
Iter: 1503 loss: 0.000192397769
Iter: 1504 loss: 0.00019245327
Iter: 1505 loss: 0.000192307343
Iter: 1506 loss: 0.000192179054
Iter: 1507 loss: 0.000192178966
Iter: 1508 loss: 0.000192085587
Iter: 1509 loss: 0.000192348743
Iter: 1510 loss: 0.000192055886
Iter: 1511 loss: 0.000191942905
Iter: 1512 loss: 0.000191767176
Iter: 1513 loss: 0.000191764819
Iter: 1514 loss: 0.000191577739
Iter: 1515 loss: 0.000191605941
Iter: 1516 loss: 0.000191436353
Iter: 1517 loss: 0.000191198356
Iter: 1518 loss: 0.000192696039
Iter: 1519 loss: 0.000191171246
Iter: 1520 loss: 0.000191019499
Iter: 1521 loss: 0.000192389241
Iter: 1522 loss: 0.000191012499
Iter: 1523 loss: 0.000190944833
Iter: 1524 loss: 0.000190937193
Iter: 1525 loss: 0.000190877312
Iter: 1526 loss: 0.000190811581
Iter: 1527 loss: 0.000190801278
Iter: 1528 loss: 0.000190709194
Iter: 1529 loss: 0.000190531864
Iter: 1530 loss: 0.000194235123
Iter: 1531 loss: 0.000190531078
Iter: 1532 loss: 0.000190380117
Iter: 1533 loss: 0.000190380291
Iter: 1534 loss: 0.000190259278
Iter: 1535 loss: 0.000190277991
Iter: 1536 loss: 0.000190168357
Iter: 1537 loss: 0.000190051127
Iter: 1538 loss: 0.000190051098
Iter: 1539 loss: 0.000189960992
Iter: 1540 loss: 0.000190217499
Iter: 1541 loss: 0.000189933402
Iter: 1542 loss: 0.000189838189
Iter: 1543 loss: 0.000189783168
Iter: 1544 loss: 0.000189742335
Iter: 1545 loss: 0.00018962445
Iter: 1546 loss: 0.000189476705
Iter: 1547 loss: 0.000189464903
Iter: 1548 loss: 0.000189287326
Iter: 1549 loss: 0.000191072628
Iter: 1550 loss: 0.000189281782
Iter: 1551 loss: 0.000189163344
Iter: 1552 loss: 0.000189886327
Iter: 1553 loss: 0.000189148821
Iter: 1554 loss: 0.000189099257
Iter: 1555 loss: 0.000189088372
Iter: 1556 loss: 0.000189037426
Iter: 1557 loss: 0.000188970414
Iter: 1558 loss: 0.000188966093
Iter: 1559 loss: 0.000188873906
Iter: 1560 loss: 0.000188711332
Iter: 1561 loss: 0.000188711041
Iter: 1562 loss: 0.00018857629
Iter: 1563 loss: 0.000190256673
Iter: 1564 loss: 0.000188574966
Iter: 1565 loss: 0.000188453501
Iter: 1566 loss: 0.000188597638
Iter: 1567 loss: 0.000188389589
Iter: 1568 loss: 0.000188294973
Iter: 1569 loss: 0.000189715167
Iter: 1570 loss: 0.000188295264
Iter: 1571 loss: 0.000188215621
Iter: 1572 loss: 0.000188337421
Iter: 1573 loss: 0.000188177888
Iter: 1574 loss: 0.00018807748
Iter: 1575 loss: 0.000188093079
Iter: 1576 loss: 0.000188001359
Iter: 1577 loss: 0.00018788359
Iter: 1578 loss: 0.000187666141
Iter: 1579 loss: 0.000192691965
Iter: 1580 loss: 0.000187666054
Iter: 1581 loss: 0.000187448779
Iter: 1582 loss: 0.000189498154
Iter: 1583 loss: 0.000187440746
Iter: 1584 loss: 0.000187284881
Iter: 1585 loss: 0.000187984668
Iter: 1586 loss: 0.00018725406
Iter: 1587 loss: 0.000187198748
Iter: 1588 loss: 0.000187174504
Iter: 1589 loss: 0.000187102705
Iter: 1590 loss: 0.000187026424
Iter: 1591 loss: 0.000187013895
Iter: 1592 loss: 0.000186903
Iter: 1593 loss: 0.000186694117
Iter: 1594 loss: 0.000191271567
Iter: 1595 loss: 0.000186693302
Iter: 1596 loss: 0.00018652156
Iter: 1597 loss: 0.00018833307
Iter: 1598 loss: 0.000186517515
Iter: 1599 loss: 0.000186353864
Iter: 1600 loss: 0.000186560981
Iter: 1601 loss: 0.000186270539
Iter: 1602 loss: 0.00018614321
Iter: 1603 loss: 0.000188184233
Iter: 1604 loss: 0.000186143501
Iter: 1605 loss: 0.000186025907
Iter: 1606 loss: 0.000186130375
Iter: 1607 loss: 0.000185957877
Iter: 1608 loss: 0.00018580677
Iter: 1609 loss: 0.000185902638
Iter: 1610 loss: 0.000185710305
Iter: 1611 loss: 0.000185566751
Iter: 1612 loss: 0.000185301207
Iter: 1613 loss: 0.000191370316
Iter: 1614 loss: 0.000185300567
Iter: 1615 loss: 0.00018506241
Iter: 1616 loss: 0.000187715224
Iter: 1617 loss: 0.000185057914
Iter: 1618 loss: 0.00018487795
Iter: 1619 loss: 0.0001858045
Iter: 1620 loss: 0.000184848846
Iter: 1621 loss: 0.000184802062
Iter: 1622 loss: 0.000184772332
Iter: 1623 loss: 0.000184709
Iter: 1624 loss: 0.000184651988
Iter: 1625 loss: 0.000184635413
Iter: 1626 loss: 0.000184531498
Iter: 1627 loss: 0.000184355653
Iter: 1628 loss: 0.000184355056
Iter: 1629 loss: 0.000184204604
Iter: 1630 loss: 0.000185269324
Iter: 1631 loss: 0.000184191245
Iter: 1632 loss: 0.000184038858
Iter: 1633 loss: 0.000184506323
Iter: 1634 loss: 0.000183993892
Iter: 1635 loss: 0.000183883472
Iter: 1636 loss: 0.000184651377
Iter: 1637 loss: 0.000183872922
Iter: 1638 loss: 0.000183754746
Iter: 1639 loss: 0.000184098753
Iter: 1640 loss: 0.000183718075
Iter: 1641 loss: 0.000183609198
Iter: 1642 loss: 0.000183820026
Iter: 1643 loss: 0.000183564698
Iter: 1644 loss: 0.000183469048
Iter: 1645 loss: 0.000183285243
Iter: 1646 loss: 0.00018713584
Iter: 1647 loss: 0.000183284224
Iter: 1648 loss: 0.000183108365
Iter: 1649 loss: 0.000183913
Iter: 1650 loss: 0.000183074531
Iter: 1651 loss: 0.000182915741
Iter: 1652 loss: 0.000183590688
Iter: 1653 loss: 0.00018288166
Iter: 1654 loss: 0.000182847492
Iter: 1655 loss: 0.000182811797
Iter: 1656 loss: 0.000182749354
Iter: 1657 loss: 0.000182701056
Iter: 1658 loss: 0.000182680873
Iter: 1659 loss: 0.000182594769
Iter: 1660 loss: 0.000182453252
Iter: 1661 loss: 0.000182452757
Iter: 1662 loss: 0.000182322314
Iter: 1663 loss: 0.000182656979
Iter: 1664 loss: 0.000182278091
Iter: 1665 loss: 0.000182111136
Iter: 1666 loss: 0.000182939868
Iter: 1667 loss: 0.000182082964
Iter: 1668 loss: 0.000181970201
Iter: 1669 loss: 0.000182666263
Iter: 1670 loss: 0.000181956566
Iter: 1671 loss: 0.00018184277
Iter: 1672 loss: 0.000182402408
Iter: 1673 loss: 0.000181823591
Iter: 1674 loss: 0.000181740441
Iter: 1675 loss: 0.000181863114
Iter: 1676 loss: 0.000181700758
Iter: 1677 loss: 0.000181622163
Iter: 1678 loss: 0.000181452779
Iter: 1679 loss: 0.000184126809
Iter: 1680 loss: 0.000181447307
Iter: 1681 loss: 0.000181273324
Iter: 1682 loss: 0.000182237331
Iter: 1683 loss: 0.000181248353
Iter: 1684 loss: 0.000181094249
Iter: 1685 loss: 0.000182044052
Iter: 1686 loss: 0.000181076088
Iter: 1687 loss: 0.000181063981
Iter: 1688 loss: 0.000181024341
Iter: 1689 loss: 0.000180980423
Iter: 1690 loss: 0.000180940027
Iter: 1691 loss: 0.000180929666
Iter: 1692 loss: 0.000180850184
Iter: 1693 loss: 0.000180765113
Iter: 1694 loss: 0.000180750911
Iter: 1695 loss: 0.000180635048
Iter: 1696 loss: 0.000180777133
Iter: 1697 loss: 0.000180573887
Iter: 1698 loss: 0.000180423405
Iter: 1699 loss: 0.000181628711
Iter: 1700 loss: 0.000180413466
Iter: 1701 loss: 0.000180315837
Iter: 1702 loss: 0.000180567207
Iter: 1703 loss: 0.000180282
Iter: 1704 loss: 0.000180175106
Iter: 1705 loss: 0.000181196883
Iter: 1706 loss: 0.000180171148
Iter: 1707 loss: 0.000180099974
Iter: 1708 loss: 0.000180142379
Iter: 1709 loss: 0.000180053641
Iter: 1710 loss: 0.000179973737
Iter: 1711 loss: 0.00017980831
Iter: 1712 loss: 0.000182698757
Iter: 1713 loss: 0.000179805327
Iter: 1714 loss: 0.000179641967
Iter: 1715 loss: 0.000179897135
Iter: 1716 loss: 0.000179566065
Iter: 1717 loss: 0.000179388328
Iter: 1718 loss: 0.000180768824
Iter: 1719 loss: 0.000179375347
Iter: 1720 loss: 0.000179349445
Iter: 1721 loss: 0.000179319279
Iter: 1722 loss: 0.000179261027
Iter: 1723 loss: 0.000179198396
Iter: 1724 loss: 0.000179188
Iter: 1725 loss: 0.000179081137
Iter: 1726 loss: 0.000178975111
Iter: 1727 loss: 0.000178953051
Iter: 1728 loss: 0.000178806222
Iter: 1729 loss: 0.000178948656
Iter: 1730 loss: 0.00017872281
Iter: 1731 loss: 0.000178561
Iter: 1732 loss: 0.00018062524
Iter: 1733 loss: 0.00017855945
Iter: 1734 loss: 0.000178451359
Iter: 1735 loss: 0.000178596631
Iter: 1736 loss: 0.000178396906
Iter: 1737 loss: 0.000178278657
Iter: 1738 loss: 0.000179617156
Iter: 1739 loss: 0.000178276779
Iter: 1740 loss: 0.000178193732
Iter: 1741 loss: 0.000178266928
Iter: 1742 loss: 0.000178145463
Iter: 1743 loss: 0.000178049027
Iter: 1744 loss: 0.000177898022
Iter: 1745 loss: 0.000177896203
Iter: 1746 loss: 0.000177735768
Iter: 1747 loss: 0.000177857088
Iter: 1748 loss: 0.000177637528
Iter: 1749 loss: 0.000177455222
Iter: 1750 loss: 0.000179198163
Iter: 1751 loss: 0.000177448703
Iter: 1752 loss: 0.000177393274
Iter: 1753 loss: 0.000177381327
Iter: 1754 loss: 0.000177305657
Iter: 1755 loss: 0.000177276772
Iter: 1756 loss: 0.000177235896
Iter: 1757 loss: 0.000177143549
Iter: 1758 loss: 0.000177065711
Iter: 1759 loss: 0.000177040652
Iter: 1760 loss: 0.000176917223
Iter: 1761 loss: 0.000176948553
Iter: 1762 loss: 0.000176827729
Iter: 1763 loss: 0.000176707137
Iter: 1764 loss: 0.000176706701
Iter: 1765 loss: 0.000176619898
Iter: 1766 loss: 0.000176693167
Iter: 1767 loss: 0.000176569214
Iter: 1768 loss: 0.000176473244
Iter: 1769 loss: 0.000177793903
Iter: 1770 loss: 0.000176472429
Iter: 1771 loss: 0.000176401009
Iter: 1772 loss: 0.000176451984
Iter: 1773 loss: 0.00017635664
Iter: 1774 loss: 0.000176273534
Iter: 1775 loss: 0.000176170157
Iter: 1776 loss: 0.00017616144
Iter: 1777 loss: 0.000176036687
Iter: 1778 loss: 0.00017595345
Iter: 1779 loss: 0.000175906913
Iter: 1780 loss: 0.000175738256
Iter: 1781 loss: 0.000177711045
Iter: 1782 loss: 0.000175735811
Iter: 1783 loss: 0.000175663736
Iter: 1784 loss: 0.000175661669
Iter: 1785 loss: 0.000175575056
Iter: 1786 loss: 0.000175603927
Iter: 1787 loss: 0.000175514229
Iter: 1788 loss: 0.000175425739
Iter: 1789 loss: 0.000175364927
Iter: 1790 loss: 0.000175333058
Iter: 1791 loss: 0.000175211899
Iter: 1792 loss: 0.000175167283
Iter: 1793 loss: 0.000175100256
Iter: 1794 loss: 0.000174973393
Iter: 1795 loss: 0.00017497153
Iter: 1796 loss: 0.00017486744
Iter: 1797 loss: 0.000174902088
Iter: 1798 loss: 0.000174794375
Iter: 1799 loss: 0.000174677349
Iter: 1800 loss: 0.000176182948
Iter: 1801 loss: 0.000174676345
Iter: 1802 loss: 0.000174585686
Iter: 1803 loss: 0.000174675428
Iter: 1804 loss: 0.000174534158
Iter: 1805 loss: 0.000174422777
Iter: 1806 loss: 0.000174349756
Iter: 1807 loss: 0.000174307163
Iter: 1808 loss: 0.000174154324
Iter: 1809 loss: 0.000174078057
Iter: 1810 loss: 0.000174005487
Iter: 1811 loss: 0.000173816137
Iter: 1812 loss: 0.000175484325
Iter: 1813 loss: 0.000173806897
Iter: 1814 loss: 0.000173700668
Iter: 1815 loss: 0.000174978341
Iter: 1816 loss: 0.00017369882
Iter: 1817 loss: 0.000173576991
Iter: 1818 loss: 0.000173972105
Iter: 1819 loss: 0.000173543303
Iter: 1820 loss: 0.00017346887
Iter: 1821 loss: 0.000173359585
Iter: 1822 loss: 0.000173356777
Iter: 1823 loss: 0.000173213892
Iter: 1824 loss: 0.000173127919
Iter: 1825 loss: 0.0001730691
Iter: 1826 loss: 0.000172916276
Iter: 1827 loss: 0.000172916087
Iter: 1828 loss: 0.000172784188
Iter: 1829 loss: 0.000172950764
Iter: 1830 loss: 0.00017271527
Iter: 1831 loss: 0.000172598171
Iter: 1832 loss: 0.000174487766
Iter: 1833 loss: 0.000172598462
Iter: 1834 loss: 0.000172502405
Iter: 1835 loss: 0.000172506101
Iter: 1836 loss: 0.00017242672
Iter: 1837 loss: 0.00017229715
Iter: 1838 loss: 0.000172278291
Iter: 1839 loss: 0.000172187589
Iter: 1840 loss: 0.000172058048
Iter: 1841 loss: 0.000171962965
Iter: 1842 loss: 0.000171919281
Iter: 1843 loss: 0.000171758613
Iter: 1844 loss: 0.000173960143
Iter: 1845 loss: 0.000171757827
Iter: 1846 loss: 0.00017166778
Iter: 1847 loss: 0.000172664237
Iter: 1848 loss: 0.000171665713
Iter: 1849 loss: 0.000171574677
Iter: 1850 loss: 0.00017206918
Iter: 1851 loss: 0.000171560794
Iter: 1852 loss: 0.000171509542
Iter: 1853 loss: 0.000171409949
Iter: 1854 loss: 0.0001734494
Iter: 1855 loss: 0.000171409338
Iter: 1856 loss: 0.000171280088
Iter: 1857 loss: 0.000171316031
Iter: 1858 loss: 0.000171187261
Iter: 1859 loss: 0.000171072839
Iter: 1860 loss: 0.00017280117
Iter: 1861 loss: 0.000171072679
Iter: 1862 loss: 0.000170972533
Iter: 1863 loss: 0.000171109248
Iter: 1864 loss: 0.00017092294
Iter: 1865 loss: 0.000170836021
Iter: 1866 loss: 0.000171848456
Iter: 1867 loss: 0.000170834741
Iter: 1868 loss: 0.000170751562
Iter: 1869 loss: 0.000170779414
Iter: 1870 loss: 0.000170692816
Iter: 1871 loss: 0.000170589163
Iter: 1872 loss: 0.000170636165
Iter: 1873 loss: 0.000170518571
Iter: 1874 loss: 0.000170426298
Iter: 1875 loss: 0.000170314
Iter: 1876 loss: 0.000170303349
Iter: 1877 loss: 0.000170160929
Iter: 1878 loss: 0.000171160704
Iter: 1879 loss: 0.000170147861
Iter: 1880 loss: 0.000170057145
Iter: 1881 loss: 0.000171333493
Iter: 1882 loss: 0.000170056184
Iter: 1883 loss: 0.000169971347
Iter: 1884 loss: 0.000170621512
Iter: 1885 loss: 0.000169965351
Iter: 1886 loss: 0.000169915438
Iter: 1887 loss: 0.00016980154
Iter: 1888 loss: 0.000171219523
Iter: 1889 loss: 0.000169792926
Iter: 1890 loss: 0.000169651816
Iter: 1891 loss: 0.000169853898
Iter: 1892 loss: 0.000169582796
Iter: 1893 loss: 0.000169455656
Iter: 1894 loss: 0.00017002516
Iter: 1895 loss: 0.000169430918
Iter: 1896 loss: 0.000169289138
Iter: 1897 loss: 0.00016994102
Iter: 1898 loss: 0.000169262319
Iter: 1899 loss: 0.000169169623
Iter: 1900 loss: 0.000169922423
Iter: 1901 loss: 0.000169164283
Iter: 1902 loss: 0.000169069157
Iter: 1903 loss: 0.000169172
Iter: 1904 loss: 0.000169016843
Iter: 1905 loss: 0.000168912637
Iter: 1906 loss: 0.000169056206
Iter: 1907 loss: 0.000168860075
Iter: 1908 loss: 0.00016877579
Iter: 1909 loss: 0.000168614366
Iter: 1910 loss: 0.000172005617
Iter: 1911 loss: 0.000168613478
Iter: 1912 loss: 0.00016843871
Iter: 1913 loss: 0.00016977459
Iter: 1914 loss: 0.00016842538
Iter: 1915 loss: 0.000168319209
Iter: 1916 loss: 0.000169438892
Iter: 1917 loss: 0.000168316183
Iter: 1918 loss: 0.000168228144
Iter: 1919 loss: 0.000169303763
Iter: 1920 loss: 0.000168226979
Iter: 1921 loss: 0.000168180763
Iter: 1922 loss: 0.000168060098
Iter: 1923 loss: 0.000169016072
Iter: 1924 loss: 0.000168037368
Iter: 1925 loss: 0.000167892198
Iter: 1926 loss: 0.000168351224
Iter: 1927 loss: 0.000167850056
Iter: 1928 loss: 0.000167723658
Iter: 1929 loss: 0.000168102706
Iter: 1930 loss: 0.000167685022
Iter: 1931 loss: 0.000167556602
Iter: 1932 loss: 0.000168772764
Iter: 1933 loss: 0.000167551683
Iter: 1934 loss: 0.000167475417
Iter: 1935 loss: 0.00016789457
Iter: 1936 loss: 0.000167464517
Iter: 1937 loss: 0.000167378981
Iter: 1938 loss: 0.000167481718
Iter: 1939 loss: 0.000167333637
Iter: 1940 loss: 0.00016725024
Iter: 1941 loss: 0.000167387159
Iter: 1942 loss: 0.00016721143
Iter: 1943 loss: 0.000167140795
Iter: 1944 loss: 0.00016701853
Iter: 1945 loss: 0.000167018865
Iter: 1946 loss: 0.000166898666
Iter: 1947 loss: 0.000167708815
Iter: 1948 loss: 0.000166886981
Iter: 1949 loss: 0.000166806305
Iter: 1950 loss: 0.000167670732
Iter: 1951 loss: 0.000166805185
Iter: 1952 loss: 0.000166743281
Iter: 1953 loss: 0.000167668244
Iter: 1954 loss: 0.000166743092
Iter: 1955 loss: 0.00016670613
Iter: 1956 loss: 0.000166613
Iter: 1957 loss: 0.000167445454
Iter: 1958 loss: 0.000166599086
Iter: 1959 loss: 0.000166490645
Iter: 1960 loss: 0.000166713478
Iter: 1961 loss: 0.000166447062
Iter: 1962 loss: 0.000166327562
Iter: 1963 loss: 0.000166432932
Iter: 1964 loss: 0.000166257509
Iter: 1965 loss: 0.000166146026
Iter: 1966 loss: 0.000166145212
Iter: 1967 loss: 0.000166080747
Iter: 1968 loss: 0.000166220154
Iter: 1969 loss: 0.000166055892
Iter: 1970 loss: 0.000165970268
Iter: 1971 loss: 0.000166304773
Iter: 1972 loss: 0.000165950507
Iter: 1973 loss: 0.000165881196
Iter: 1974 loss: 0.00016598776
Iter: 1975 loss: 0.000165848411
Iter: 1976 loss: 0.000165785794
Iter: 1977 loss: 0.000165663441
Iter: 1978 loss: 0.000168104336
Iter: 1979 loss: 0.000165662321
Iter: 1980 loss: 0.000165534875
Iter: 1981 loss: 0.000166191836
Iter: 1982 loss: 0.000165514444
Iter: 1983 loss: 0.000165415506
Iter: 1984 loss: 0.000166312355
Iter: 1985 loss: 0.000165411213
Iter: 1986 loss: 0.000165347301
Iter: 1987 loss: 0.000165346253
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/k4
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0
+ date
Tue Oct 27 17:23:31 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5a83a5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5a83b59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5a83f5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566ee2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566ee2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566e276a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566e019d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566dd06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566dd09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc566dd0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540523840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5404ebc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5404eb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540490d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540490a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540490ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540428158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540428ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5403cd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540391f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540353378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540304f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5402b9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5402c8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5402e3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540285b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540247ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540247840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc54025f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5402470d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5401fcd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5401cbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540185378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540139c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc540167598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc5400f8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00473071169
Iter: 2 loss: 0.00471463241
Iter: 3 loss: 0.00465348409
Iter: 4 loss: 0.00442413427
Iter: 5 loss: 0.00523186848
Iter: 6 loss: 0.00431798585
Iter: 7 loss: 0.0041865455
Iter: 8 loss: 0.0041863583
Iter: 9 loss: 0.00411083
Iter: 10 loss: 0.00437393691
Iter: 11 loss: 0.00409130892
Iter: 12 loss: 0.0040523354
Iter: 13 loss: 0.00410179421
Iter: 14 loss: 0.00403221557
Iter: 15 loss: 0.00400926
Iter: 16 loss: 0.00415791478
Iter: 17 loss: 0.00400678907
Iter: 18 loss: 0.00399767235
Iter: 19 loss: 0.00399706932
Iter: 20 loss: 0.00399149489
Iter: 21 loss: 0.00398916192
Iter: 22 loss: 0.00398625154
Iter: 23 loss: 0.00398228783
Iter: 24 loss: 0.00401828624
Iter: 25 loss: 0.00398210855
Iter: 26 loss: 0.00397969037
Iter: 27 loss: 0.00400710385
Iter: 28 loss: 0.0039796466
Iter: 29 loss: 0.00397858582
Iter: 30 loss: 0.00397804193
Iter: 31 loss: 0.00397754973
Iter: 32 loss: 0.00397691363
Iter: 33 loss: 0.00397691363
Iter: 34 loss: 0.00397649407
Iter: 35 loss: 0.00398009736
Iter: 36 loss: 0.00397647
Iter: 37 loss: 0.00397631526
Iter: 38 loss: 0.00397622306
Iter: 39 loss: 0.00397615787
Iter: 40 loss: 0.00397602562
Iter: 41 loss: 0.00397710595
Iter: 42 loss: 0.00397601817
Iter: 43 loss: 0.00397597719
Iter: 44 loss: 0.00397597253
Iter: 45 loss: 0.0039759432
Iter: 46 loss: 0.00397596322
Iter: 47 loss: 0.00397592317
Iter: 48 loss: 0.00397590501
Iter: 49 loss: 0.00397593947
Iter: 50 loss: 0.00397589616
Iter: 51 loss: 0.00397588639
Iter: 52 loss: 0.00397598
Iter: 53 loss: 0.00397588778
Iter: 54 loss: 0.00397588313
Iter: 55 loss: 0.00397588219
Iter: 56 loss: 0.0039758794
Iter: 57 loss: 0.00397587847
Iter: 58 loss: 0.003975878
Iter: 59 loss: 0.00397587661
Iter: 60 loss: 0.00397589803
Iter: 61 loss: 0.00397587661
Iter: 62 loss: 0.00397587521
Iter: 63 loss: 0.00397588219
Iter: 64 loss: 0.00397587474
Iter: 65 loss: 0.00397587474
Iter: 66 loss: 0.00397587381
Iter: 67 loss: 0.00397587428
Iter: 68 loss: 0.00397587428
Iter: 69 loss: 0.00397587428
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4
+ date
Tue Oct 27 17:24:15 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d870f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8634f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8750d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d85f2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d85f2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d85f2e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d856c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8593840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8593268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8541d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d85079d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d84ae8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d84ae840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8469378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8469840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d843e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d843e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d83ef1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d841ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d83bdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d83d89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d838e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8342598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8354400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d82f77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d83182f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d82d9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8287510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8287378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d8234620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d81ec9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d820e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d820e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d81a7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d81debf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46d818f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0294769164
Iter: 2 loss: 0.0284185782
Iter: 3 loss: 0.0245018713
Iter: 4 loss: 0.0117825037
Iter: 5 loss: 0.156138271
Iter: 6 loss: 0.00996803306
Iter: 7 loss: 0.00587531412
Iter: 8 loss: 0.00586515479
Iter: 9 loss: 0.00511583034
Iter: 10 loss: 0.00495616766
Iter: 11 loss: 0.00468356954
Iter: 12 loss: 0.00528398
Iter: 13 loss: 0.00458018063
Iter: 14 loss: 0.0044556167
Iter: 15 loss: 0.00566940755
Iter: 16 loss: 0.00445070351
Iter: 17 loss: 0.00438316446
Iter: 18 loss: 0.00497641694
Iter: 19 loss: 0.00437980285
Iter: 20 loss: 0.00434993673
Iter: 21 loss: 0.00440842286
Iter: 22 loss: 0.00433747657
Iter: 23 loss: 0.00431756582
Iter: 24 loss: 0.00451799342
Iter: 25 loss: 0.00431694742
Iter: 26 loss: 0.00430565234
Iter: 27 loss: 0.00432036677
Iter: 28 loss: 0.00429991446
Iter: 29 loss: 0.0042933505
Iter: 30 loss: 0.00430663768
Iter: 31 loss: 0.00429067062
Iter: 32 loss: 0.00428696536
Iter: 33 loss: 0.00433838507
Iter: 34 loss: 0.00428695418
Iter: 35 loss: 0.00428439351
Iter: 36 loss: 0.00429124245
Iter: 37 loss: 0.00428354647
Iter: 38 loss: 0.00428191945
Iter: 39 loss: 0.00428486615
Iter: 40 loss: 0.00428121164
Iter: 41 loss: 0.00428014528
Iter: 42 loss: 0.00428612763
Iter: 43 loss: 0.00427999487
Iter: 44 loss: 0.0042794589
Iter: 45 loss: 0.00428458489
Iter: 46 loss: 0.00427943794
Iter: 47 loss: 0.00427914737
Iter: 48 loss: 0.00428243959
Iter: 49 loss: 0.00427914271
Iter: 50 loss: 0.00427896529
Iter: 51 loss: 0.00427908218
Iter: 52 loss: 0.00427885447
Iter: 53 loss: 0.00427874
Iter: 54 loss: 0.0042800568
Iter: 55 loss: 0.00427873759
Iter: 56 loss: 0.00427865749
Iter: 57 loss: 0.00427912455
Iter: 58 loss: 0.00427864632
Iter: 59 loss: 0.00427860301
Iter: 60 loss: 0.00427867239
Iter: 61 loss: 0.00427858345
Iter: 62 loss: 0.00427855458
Iter: 63 loss: 0.00427889824
Iter: 64 loss: 0.00427855365
Iter: 65 loss: 0.00427853456
Iter: 66 loss: 0.00427855086
Iter: 67 loss: 0.00427852198
Iter: 68 loss: 0.00427850801
Iter: 69 loss: 0.00427859556
Iter: 70 loss: 0.00427850615
Iter: 71 loss: 0.00427849917
Iter: 72 loss: 0.00427854573
Iter: 73 loss: 0.00427849684
Iter: 74 loss: 0.00427849218
Iter: 75 loss: 0.00427851966
Iter: 76 loss: 0.00427849218
Iter: 77 loss: 0.00427848846
Iter: 78 loss: 0.00427850522
Iter: 79 loss: 0.00427848846
Iter: 80 loss: 0.00427848566
Iter: 81 loss: 0.00427849218
Iter: 82 loss: 0.00427848753
Iter: 83 loss: 0.00427848566
Iter: 84 loss: 0.00427849824
Iter: 85 loss: 0.0042784852
Iter: 86 loss: 0.00427848473
Iter: 87 loss: 0.00427848473
Iter: 88 loss: 0.00427848473
Iter: 89 loss: 0.00427848333
Iter: 90 loss: 0.00427848799
Iter: 91 loss: 0.00427848333
Iter: 92 loss: 0.00427848287
Iter: 93 loss: 0.00427848473
Iter: 94 loss: 0.00427848287
Iter: 95 loss: 0.0042784838
Iter: 96 loss: 0.0042784838
Iter: 97 loss: 0.0042784838
Iter: 98 loss: 0.00427848333
Iter: 99 loss: 0.00427848427
Iter: 100 loss: 0.0042784838
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8
+ date
Tue Oct 27 17:25:06 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff84542e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8454af7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8454b1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8454b1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820453730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8204536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82043ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8203e5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820402400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8203aebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820370510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82037af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82031f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8202d4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8202e18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820299b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8202ad510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8202adf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82028ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820228f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820244840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8201fa620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8201ae510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8201bfae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820158620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8201588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8201458c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8200eebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820145950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8200a0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8200537b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82007b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82007b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff82006f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820041ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff820041b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.023100704
Iter: 2 loss: 0.0222062729
Iter: 3 loss: 0.018995814
Iter: 4 loss: 0.0164302792
Iter: 5 loss: 0.0142165441
Iter: 6 loss: 0.00941892341
Iter: 7 loss: 0.0743102729
Iter: 8 loss: 0.0090526
Iter: 9 loss: 0.0062648356
Iter: 10 loss: 0.00619604066
Iter: 11 loss: 0.00560714398
Iter: 12 loss: 0.00887200329
Iter: 13 loss: 0.00548901223
Iter: 14 loss: 0.00524128042
Iter: 15 loss: 0.00524093164
Iter: 16 loss: 0.00510122627
Iter: 17 loss: 0.00524016842
Iter: 18 loss: 0.00502432091
Iter: 19 loss: 0.00490847509
Iter: 20 loss: 0.00530264061
Iter: 21 loss: 0.00487537868
Iter: 22 loss: 0.00481341733
Iter: 23 loss: 0.00508441869
Iter: 24 loss: 0.00480046682
Iter: 25 loss: 0.00476104813
Iter: 26 loss: 0.00507199578
Iter: 27 loss: 0.00475834683
Iter: 28 loss: 0.00473732967
Iter: 29 loss: 0.00481859967
Iter: 30 loss: 0.00473234616
Iter: 31 loss: 0.00472072
Iter: 32 loss: 0.00478054211
Iter: 33 loss: 0.00471882103
Iter: 34 loss: 0.00471149478
Iter: 35 loss: 0.00474549178
Iter: 36 loss: 0.00471014204
Iter: 37 loss: 0.00470550917
Iter: 38 loss: 0.00472394
Iter: 39 loss: 0.00470445
Iter: 40 loss: 0.00470153056
Iter: 41 loss: 0.004719235
Iter: 42 loss: 0.00470117154
Iter: 43 loss: 0.00469912775
Iter: 44 loss: 0.00470562465
Iter: 45 loss: 0.00469854102
Iter: 46 loss: 0.00469713891
Iter: 47 loss: 0.00471379515
Iter: 48 loss: 0.00469712168
Iter: 49 loss: 0.0046961247
Iter: 50 loss: 0.00469668675
Iter: 51 loss: 0.00469547277
Iter: 52 loss: 0.00469439849
Iter: 53 loss: 0.00469878176
Iter: 54 loss: 0.0046941624
Iter: 55 loss: 0.0046934383
Iter: 56 loss: 0.00469710119
Iter: 57 loss: 0.00469331816
Iter: 58 loss: 0.0046926979
Iter: 59 loss: 0.00469628675
Iter: 60 loss: 0.00469261501
Iter: 61 loss: 0.00469219917
Iter: 62 loss: 0.00469250139
Iter: 63 loss: 0.00469194353
Iter: 64 loss: 0.00469153374
Iter: 65 loss: 0.00469228905
Iter: 66 loss: 0.00469135819
Iter: 67 loss: 0.00469100242
Iter: 68 loss: 0.0046922
Iter: 69 loss: 0.0046909065
Iter: 70 loss: 0.00469065364
Iter: 71 loss: 0.00469242921
Iter: 72 loss: 0.00469062943
Iter: 73 loss: 0.00469046133
Iter: 74 loss: 0.00469124643
Iter: 75 loss: 0.00469043152
Iter: 76 loss: 0.00469032489
Iter: 77 loss: 0.0046907505
Iter: 78 loss: 0.00469029928
Iter: 79 loss: 0.00469022337
Iter: 80 loss: 0.00469092932
Iter: 81 loss: 0.00469022
Iter: 82 loss: 0.00469017029
Iter: 83 loss: 0.00469046924
Iter: 84 loss: 0.0046901647
Iter: 85 loss: 0.00469013
Iter: 86 loss: 0.00469019217
Iter: 87 loss: 0.00469011301
Iter: 88 loss: 0.00469008693
Iter: 89 loss: 0.00469016656
Iter: 90 loss: 0.00469007855
Iter: 91 loss: 0.00469006132
Iter: 92 loss: 0.00469026808
Iter: 93 loss: 0.00469006086
Iter: 94 loss: 0.00469004828
Iter: 95 loss: 0.00469007855
Iter: 96 loss: 0.0046900427
Iter: 97 loss: 0.00469003245
Iter: 98 loss: 0.00469005061
Iter: 99 loss: 0.00469002873
Iter: 100 loss: 0.00469002035
Iter: 101 loss: 0.00469004
Iter: 102 loss: 0.00469001848
Iter: 103 loss: 0.0046900115
Iter: 104 loss: 0.00469004083
Iter: 105 loss: 0.00469001103
Iter: 106 loss: 0.00469000591
Iter: 107 loss: 0.0046900264
Iter: 108 loss: 0.00469000544
Iter: 109 loss: 0.00469000312
Iter: 110 loss: 0.00469001848
Iter: 111 loss: 0.00469000358
Iter: 112 loss: 0.00469000172
Iter: 113 loss: 0.00469001
Iter: 114 loss: 0.00469000032
Iter: 115 loss: 0.00469
Iter: 116 loss: 0.00469000591
Iter: 117 loss: 0.00469
Iter: 118 loss: 0.00469
Iter: 119 loss: 0.00469000731
Iter: 120 loss: 0.00468999846
Iter: 121 loss: 0.00468999892
Iter: 122 loss: 0.00468999892
Iter: 123 loss: 0.00468999799
Iter: 124 loss: 0.00468999706
Iter: 125 loss: 0.00469000172
Iter: 126 loss: 0.00468999706
Iter: 127 loss: 0.00468999706
Iter: 128 loss: 0.00469000172
Iter: 129 loss: 0.00468999753
Iter: 130 loss: 0.00468999753
Iter: 131 loss: 0.00468999892
Iter: 132 loss: 0.00468999799
Iter: 133 loss: 0.00468999706
Iter: 134 loss: 0.00468999706
Iter: 135 loss: 0.00468999753
Iter: 136 loss: 0.00468999799
Iter: 137 loss: 0.00468999753
Iter: 138 loss: 0.00468999706
Iter: 139 loss: 0.00468999706
Iter: 140 loss: 0.00468999799
Iter: 141 loss: 0.00468999706
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2
+ date
Tue Oct 27 17:26:09 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66b5135378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66b50a87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66b50a3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66b50a3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66900ca730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669007b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66900a7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669004c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6690076378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670741f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670706598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667070af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66706b29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670667620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667069b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667069b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670630400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66706539d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66705ac9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670630d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66705cd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670584c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670584b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66704ebf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66704eb730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667050d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66704da620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6670481598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667048b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667042fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66703e4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667040d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667040d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66703bc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667036c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f667036c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0245599505
Iter: 2 loss: 0.0222642981
Iter: 3 loss: 0.0160002727
Iter: 4 loss: 6665.11426
Iter: 5 loss: 0.0160002708
Iter: 6 loss: 0.0127953254
Iter: 7 loss: 10160.1318
Iter: 8 loss: 0.0127953254
Iter: 9 loss: 0.00947783235
Iter: 10 loss: 0.035628438
Iter: 11 loss: 0.00910146721
Iter: 12 loss: 0.00757118454
Iter: 13 loss: 0.0166419223
Iter: 14 loss: 0.00737914722
Iter: 15 loss: 0.00664422847
Iter: 16 loss: 0.00943334121
Iter: 17 loss: 0.00641158642
Iter: 18 loss: 0.00606349
Iter: 19 loss: 0.00605531083
Iter: 20 loss: 0.0058848979
Iter: 21 loss: 0.00589907728
Iter: 22 loss: 0.00575241866
Iter: 23 loss: 0.00560495071
Iter: 24 loss: 0.00642674975
Iter: 25 loss: 0.00558090024
Iter: 26 loss: 0.00549454289
Iter: 27 loss: 0.00571090076
Iter: 28 loss: 0.00546399038
Iter: 29 loss: 0.00537932524
Iter: 30 loss: 0.00586812943
Iter: 31 loss: 0.00536739454
Iter: 32 loss: 0.00531644793
Iter: 33 loss: 0.00578121282
Iter: 34 loss: 0.00531362463
Iter: 35 loss: 0.00528214918
Iter: 36 loss: 0.00535451807
Iter: 37 loss: 0.00527030043
Iter: 38 loss: 0.00524331257
Iter: 39 loss: 0.0053533488
Iter: 40 loss: 0.00523742381
Iter: 41 loss: 0.00521932822
Iter: 42 loss: 0.0053219907
Iter: 43 loss: 0.00521669
Iter: 44 loss: 0.00520640193
Iter: 45 loss: 0.0053124954
Iter: 46 loss: 0.00520613231
Iter: 47 loss: 0.00519887172
Iter: 48 loss: 0.00523269549
Iter: 49 loss: 0.00519746
Iter: 50 loss: 0.00519323256
Iter: 51 loss: 0.00520574348
Iter: 52 loss: 0.0051919492
Iter: 53 loss: 0.00518814567
Iter: 54 loss: 0.00519458391
Iter: 55 loss: 0.00518643763
Iter: 56 loss: 0.00518331816
Iter: 57 loss: 0.00520533882
Iter: 58 loss: 0.00518303271
Iter: 59 loss: 0.00518060382
Iter: 60 loss: 0.00518985
Iter: 61 loss: 0.00518003106
Iter: 62 loss: 0.00517829694
Iter: 63 loss: 0.00517892
Iter: 64 loss: 0.0051770797
Iter: 65 loss: 0.00517501449
Iter: 66 loss: 0.00518167205
Iter: 67 loss: 0.00517443195
Iter: 68 loss: 0.00517264195
Iter: 69 loss: 0.0051779449
Iter: 70 loss: 0.0051720934
Iter: 71 loss: 0.00517050736
Iter: 72 loss: 0.00517389551
Iter: 73 loss: 0.00516988477
Iter: 74 loss: 0.0051685432
Iter: 75 loss: 0.0051756748
Iter: 76 loss: 0.00516833644
Iter: 77 loss: 0.00516725425
Iter: 78 loss: 0.00517146289
Iter: 79 loss: 0.00516700093
Iter: 80 loss: 0.00516608544
Iter: 81 loss: 0.00516937627
Iter: 82 loss: 0.00516584888
Iter: 83 loss: 0.00516518811
Iter: 84 loss: 0.00517555606
Iter: 85 loss: 0.00516518811
Iter: 86 loss: 0.00516467914
Iter: 87 loss: 0.00516472
Iter: 88 loss: 0.00516428426
Iter: 89 loss: 0.00516373478
Iter: 90 loss: 0.00516436389
Iter: 91 loss: 0.00516343955
Iter: 92 loss: 0.00516289845
Iter: 93 loss: 0.00516807
Iter: 94 loss: 0.0051628761
Iter: 95 loss: 0.005162457
Iter: 96 loss: 0.00516317273
Iter: 97 loss: 0.00516226655
Iter: 98 loss: 0.00516182836
Iter: 99 loss: 0.00516262092
Iter: 100 loss: 0.0051616393
Iter: 101 loss: 0.00516123697
Iter: 102 loss: 0.00516198
Iter: 103 loss: 0.00516106468
Iter: 104 loss: 0.0051606847
Iter: 105 loss: 0.00516179577
Iter: 106 loss: 0.00516056642
Iter: 107 loss: 0.00516021531
Iter: 108 loss: 0.00516115036
Iter: 109 loss: 0.0051600989
Iter: 110 loss: 0.00515980739
Iter: 111 loss: 0.00516083976
Iter: 112 loss: 0.00515973242
Iter: 113 loss: 0.00515949
Iter: 114 loss: 0.00516059343
Iter: 115 loss: 0.00515944324
Iter: 116 loss: 0.00515928026
Iter: 117 loss: 0.00516048819
Iter: 118 loss: 0.00515926629
Iter: 119 loss: 0.00515915919
Iter: 120 loss: 0.00516043603
Iter: 121 loss: 0.00515915733
Iter: 122 loss: 0.00515907304
Iter: 123 loss: 0.00515910937
Iter: 124 loss: 0.00515901623
Iter: 125 loss: 0.00515893707
Iter: 126 loss: 0.00515905162
Iter: 127 loss: 0.00515889842
Iter: 128 loss: 0.00515883137
Iter: 129 loss: 0.00515936548
Iter: 130 loss: 0.00515882671
Iter: 131 loss: 0.00515877
Iter: 132 loss: 0.00515897945
Iter: 133 loss: 0.00515875546
Iter: 134 loss: 0.00515871262
Iter: 135 loss: 0.00515873916
Iter: 136 loss: 0.00515868515
Iter: 137 loss: 0.00515864277
Iter: 138 loss: 0.00515886489
Iter: 139 loss: 0.00515863579
Iter: 140 loss: 0.00515860412
Iter: 141 loss: 0.00515867
Iter: 142 loss: 0.00515859108
Iter: 143 loss: 0.00515856408
Iter: 144 loss: 0.00515864603
Iter: 145 loss: 0.00515855663
Iter: 146 loss: 0.0051585352
Iter: 147 loss: 0.00515862927
Iter: 148 loss: 0.00515853055
Iter: 149 loss: 0.00515851378
Iter: 150 loss: 0.00515857339
Iter: 151 loss: 0.00515850913
Iter: 152 loss: 0.00515849888
Iter: 153 loss: 0.00515859853
Iter: 154 loss: 0.00515849795
Iter: 155 loss: 0.00515848957
Iter: 156 loss: 0.00515857153
Iter: 157 loss: 0.00515849143
Iter: 158 loss: 0.00515848584
Iter: 159 loss: 0.00515848864
Iter: 160 loss: 0.00515848212
Iter: 161 loss: 0.00515847653
Iter: 162 loss: 0.00515847933
Iter: 163 loss: 0.0051584742
Iter: 164 loss: 0.00515846908
Iter: 165 loss: 0.00515849702
Iter: 166 loss: 0.00515846815
Iter: 167 loss: 0.00515846442
Iter: 168 loss: 0.00515850633
Iter: 169 loss: 0.00515846536
Iter: 170 loss: 0.00515846256
Iter: 171 loss: 0.00515846256
Iter: 172 loss: 0.0051584607
Iter: 173 loss: 0.00515845791
Iter: 174 loss: 0.00515847374
Iter: 175 loss: 0.00515845791
Iter: 176 loss: 0.00515845511
Iter: 177 loss: 0.00515846163
Iter: 178 loss: 0.00515845418
Iter: 179 loss: 0.00515845371
Iter: 180 loss: 0.00515845511
Iter: 181 loss: 0.00515845278
Iter: 182 loss: 0.00515845092
Iter: 183 loss: 0.0051584593
Iter: 184 loss: 0.00515845139
Iter: 185 loss: 0.00515845092
Iter: 186 loss: 0.00515845511
Iter: 187 loss: 0.00515845
Iter: 188 loss: 0.00515844859
Iter: 189 loss: 0.00515845418
Iter: 190 loss: 0.00515844952
Iter: 191 loss: 0.00515844859
Iter: 192 loss: 0.00515844673
Iter: 193 loss: 0.00515844766
Iter: 194 loss: 0.00515844766
Iter: 195 loss: 0.00515844673
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6
+ date
Tue Oct 27 17:27:23 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004336158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004362a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004362d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fafc2557c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fafc2557840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fafc258d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c457620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c4577b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c48b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c435bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c3fa510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c3f7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c3f7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c3597b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c386a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c31ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c31fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c2db268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c29a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c33e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c2c9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c278bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c22e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c1e09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c1e0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c207510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c1cd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c17a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c17d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c11eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c0dd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c0dd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c0f4048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c0ad378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c0ad840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faf9c07f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0328155346
Iter: 2 loss: 0.0228722766
Iter: 3 loss: 1085.02246
Iter: 4 loss: 0.0228720456
Iter: 5 loss: 0.0399648584
Iter: 6 loss: 0.0212955624
Iter: 7 loss: 0.0174281094
Iter: 8 loss: 0.0165919121
Iter: 9 loss: 0.0139077045
Iter: 10 loss: 0.0677724779
Iter: 11 loss: 0.0138008753
Iter: 12 loss: 0.0113386121
Iter: 13 loss: 0.0273096599
Iter: 14 loss: 0.0110193212
Iter: 15 loss: 0.0100659914
Iter: 16 loss: 0.0111339381
Iter: 17 loss: 0.00959723
Iter: 18 loss: 0.00875832886
Iter: 19 loss: 0.00900813
Iter: 20 loss: 0.00806415919
Iter: 21 loss: 0.00746793
Iter: 22 loss: 0.0164293
Iter: 23 loss: 0.00744047575
Iter: 24 loss: 0.00711433496
Iter: 25 loss: 0.00867936946
Iter: 26 loss: 0.0070575974
Iter: 27 loss: 0.0068980339
Iter: 28 loss: 0.00687747728
Iter: 29 loss: 0.00675788196
Iter: 30 loss: 0.00651217671
Iter: 31 loss: 0.00800205953
Iter: 32 loss: 0.00648096623
Iter: 33 loss: 0.00634473749
Iter: 34 loss: 0.00855038408
Iter: 35 loss: 0.00634462759
Iter: 36 loss: 0.00627267174
Iter: 37 loss: 0.00638039
Iter: 38 loss: 0.00623729
Iter: 39 loss: 0.00617957
Iter: 40 loss: 0.00630070269
Iter: 41 loss: 0.00615646783
Iter: 42 loss: 0.00610390911
Iter: 43 loss: 0.00623291964
Iter: 44 loss: 0.00608455436
Iter: 45 loss: 0.00603459636
Iter: 46 loss: 0.00643851515
Iter: 47 loss: 0.00603080308
Iter: 48 loss: 0.00600033952
Iter: 49 loss: 0.00615775958
Iter: 50 loss: 0.00599555951
Iter: 51 loss: 0.00597550347
Iter: 52 loss: 0.00602353271
Iter: 53 loss: 0.00596786663
Iter: 54 loss: 0.00594799686
Iter: 55 loss: 0.00595838157
Iter: 56 loss: 0.00593491551
Iter: 57 loss: 0.00590915792
Iter: 58 loss: 0.00598617177
Iter: 59 loss: 0.00590125564
Iter: 60 loss: 0.00587758794
Iter: 61 loss: 0.0059064785
Iter: 62 loss: 0.00586519344
Iter: 63 loss: 0.00584511971
Iter: 64 loss: 0.00598985
Iter: 65 loss: 0.00584324077
Iter: 66 loss: 0.00582754845
Iter: 67 loss: 0.00591569953
Iter: 68 loss: 0.00582548603
Iter: 69 loss: 0.00581262913
Iter: 70 loss: 0.00592607539
Iter: 71 loss: 0.00581179326
Iter: 72 loss: 0.00580362417
Iter: 73 loss: 0.005800399
Iter: 74 loss: 0.00579601061
Iter: 75 loss: 0.00578499213
Iter: 76 loss: 0.00582217285
Iter: 77 loss: 0.00578193786
Iter: 78 loss: 0.00577386282
Iter: 79 loss: 0.00581110921
Iter: 80 loss: 0.00577233452
Iter: 81 loss: 0.00576635823
Iter: 82 loss: 0.00581959449
Iter: 83 loss: 0.00576605834
Iter: 84 loss: 0.00576180127
Iter: 85 loss: 0.00576743716
Iter: 86 loss: 0.00575965689
Iter: 87 loss: 0.00575588783
Iter: 88 loss: 0.00580968056
Iter: 89 loss: 0.00575587433
Iter: 90 loss: 0.00575317349
Iter: 91 loss: 0.00575376768
Iter: 92 loss: 0.00575118791
Iter: 93 loss: 0.00574832316
Iter: 94 loss: 0.00575208198
Iter: 95 loss: 0.00574686285
Iter: 96 loss: 0.00574452477
Iter: 97 loss: 0.00574918464
Iter: 98 loss: 0.00574356597
Iter: 99 loss: 0.00574104767
Iter: 100 loss: 0.0057514878
Iter: 101 loss: 0.00574050657
Iter: 102 loss: 0.00573867
Iter: 103 loss: 0.00574241858
Iter: 104 loss: 0.00573792867
Iter: 105 loss: 0.0057363743
Iter: 106 loss: 0.00574098853
Iter: 107 loss: 0.00573589467
Iter: 108 loss: 0.00573474495
Iter: 109 loss: 0.00573472166
Iter: 110 loss: 0.00573392445
Iter: 111 loss: 0.00573383225
Iter: 112 loss: 0.0057332553
Iter: 113 loss: 0.00573231233
Iter: 114 loss: 0.00573412841
Iter: 115 loss: 0.00573191885
Iter: 116 loss: 0.00573107786
Iter: 117 loss: 0.00573491398
Iter: 118 loss: 0.00573091675
Iter: 119 loss: 0.00573008042
Iter: 120 loss: 0.00573286135
Iter: 121 loss: 0.00572984898
Iter: 122 loss: 0.00572924921
Iter: 123 loss: 0.00573253352
Iter: 124 loss: 0.00572915934
Iter: 125 loss: 0.00572849903
Iter: 126 loss: 0.00572955515
Iter: 127 loss: 0.00572819449
Iter: 128 loss: 0.00572773442
Iter: 129 loss: 0.0057278797
Iter: 130 loss: 0.00572740845
Iter: 131 loss: 0.00572676118
Iter: 132 loss: 0.00572895166
Iter: 133 loss: 0.00572658703
Iter: 134 loss: 0.00572603382
Iter: 135 loss: 0.00572677841
Iter: 136 loss: 0.00572575675
Iter: 137 loss: 0.00572516676
Iter: 138 loss: 0.00572747458
Iter: 139 loss: 0.00572503312
Iter: 140 loss: 0.00572445896
Iter: 141 loss: 0.00572632952
Iter: 142 loss: 0.00572429923
Iter: 143 loss: 0.00572387921
Iter: 144 loss: 0.00572457165
Iter: 145 loss: 0.00572368782
Iter: 146 loss: 0.00572329
Iter: 147 loss: 0.00572733115
Iter: 148 loss: 0.00572327711
Iter: 149 loss: 0.00572296744
Iter: 150 loss: 0.00572536374
Iter: 151 loss: 0.00572294416
Iter: 152 loss: 0.00572271831
Iter: 153 loss: 0.00572267734
Iter: 154 loss: 0.0057225246
Iter: 155 loss: 0.0057222629
Iter: 156 loss: 0.00572370365
Iter: 157 loss: 0.00572222332
Iter: 158 loss: 0.00572200445
Iter: 159 loss: 0.00572237372
Iter: 160 loss: 0.00572190713
Iter: 161 loss: 0.00572166964
Iter: 162 loss: 0.00572320679
Iter: 163 loss: 0.0057216445
Iter: 164 loss: 0.00572146801
Iter: 165 loss: 0.00572147965
Iter: 166 loss: 0.00572133111
Iter: 167 loss: 0.00572110154
Iter: 168 loss: 0.00572121935
Iter: 169 loss: 0.00572094833
Iter: 170 loss: 0.00572069921
Iter: 171 loss: 0.00572145451
Iter: 172 loss: 0.00572062517
Iter: 173 loss: 0.00572035275
Iter: 174 loss: 0.00572123146
Iter: 175 loss: 0.00572027359
Iter: 176 loss: 0.00572004449
Iter: 177 loss: 0.00572107919
Iter: 178 loss: 0.00572000025
Iter: 179 loss: 0.00571979396
Iter: 180 loss: 0.00572014041
Iter: 181 loss: 0.00571970362
Iter: 182 loss: 0.00571949594
Iter: 183 loss: 0.00572082214
Iter: 184 loss: 0.00571947079
Iter: 185 loss: 0.00571930222
Iter: 186 loss: 0.00572092738
Iter: 187 loss: 0.00571929663
Iter: 188 loss: 0.00571917463
Iter: 189 loss: 0.0057191588
Iter: 190 loss: 0.00571907545
Iter: 191 loss: 0.00571891945
Iter: 192 loss: 0.0057192794
Iter: 193 loss: 0.00571886031
Iter: 194 loss: 0.00571869779
Iter: 195 loss: 0.00571925472
Iter: 196 loss: 0.00571865216
Iter: 197 loss: 0.00571850128
Iter: 198 loss: 0.00571929337
Iter: 199 loss: 0.00571847707
Iter: 200 loss: 0.00571835274
Iter: 201 loss: 0.00571832247
Iter: 202 loss: 0.00571824331
Iter: 203 loss: 0.00571807567
Iter: 204 loss: 0.00571839046
Iter: 205 loss: 0.00571800396
Iter: 206 loss: 0.00571784191
Iter: 207 loss: 0.00571832294
Iter: 208 loss: 0.00571779348
Iter: 209 loss: 0.00571763702
Iter: 210 loss: 0.00571802631
Iter: 211 loss: 0.00571758207
Iter: 212 loss: 0.00571744051
Iter: 213 loss: 0.00571791874
Iter: 214 loss: 0.00571740139
Iter: 215 loss: 0.00571726635
Iter: 216 loss: 0.00571787544
Iter: 217 loss: 0.00571724
Iter: 218 loss: 0.00571714109
Iter: 219 loss: 0.00571778184
Iter: 220 loss: 0.00571713177
Iter: 221 loss: 0.00571703399
Iter: 222 loss: 0.00571759604
Iter: 223 loss: 0.00571702048
Iter: 224 loss: 0.00571696134
Iter: 225 loss: 0.00571697811
Iter: 226 loss: 0.00571691664
Iter: 227 loss: 0.00571683468
Iter: 228 loss: 0.00571696414
Iter: 229 loss: 0.00571679324
Iter: 230 loss: 0.00571672339
Iter: 231 loss: 0.0057173958
Iter: 232 loss: 0.00571672292
Iter: 233 loss: 0.00571666192
Iter: 234 loss: 0.00571668521
Iter: 235 loss: 0.00571662234
Iter: 236 loss: 0.00571655715
Iter: 237 loss: 0.00571677228
Iter: 238 loss: 0.00571653806
Iter: 239 loss: 0.00571647612
Iter: 240 loss: 0.00571643654
Iter: 241 loss: 0.00571641186
Iter: 242 loss: 0.00571633969
Iter: 243 loss: 0.00571695156
Iter: 244 loss: 0.00571633596
Iter: 245 loss: 0.00571628194
Iter: 246 loss: 0.00571642211
Iter: 247 loss: 0.00571626285
Iter: 248 loss: 0.00571621303
Iter: 249 loss: 0.00571632106
Iter: 250 loss: 0.00571619533
Iter: 251 loss: 0.00571615063
Iter: 252 loss: 0.00571649568
Iter: 253 loss: 0.0057161469
Iter: 254 loss: 0.00571612
Iter: 255 loss: 0.00571646355
Iter: 256 loss: 0.00571612176
Iter: 257 loss: 0.00571609894
Iter: 258 loss: 0.00571612967
Iter: 259 loss: 0.0057160873
Iter: 260 loss: 0.00571606774
Iter: 261 loss: 0.00571608543
Iter: 262 loss: 0.00571605423
Iter: 263 loss: 0.00571603188
Iter: 264 loss: 0.00571609382
Iter: 265 loss: 0.0057160249
Iter: 266 loss: 0.00571600255
Iter: 267 loss: 0.00571616692
Iter: 268 loss: 0.00571600161
Iter: 269 loss: 0.00571598578
Iter: 270 loss: 0.00571599277
Iter: 271 loss: 0.00571597461
Iter: 272 loss: 0.00571595691
Iter: 273 loss: 0.00571597833
Iter: 274 loss: 0.00571594713
Iter: 275 loss: 0.00571592897
Iter: 276 loss: 0.00571601558
Iter: 277 loss: 0.00571592432
Iter: 278 loss: 0.00571591081
Iter: 279 loss: 0.00571592152
Iter: 280 loss: 0.00571590196
Iter: 281 loss: 0.00571588427
Iter: 282 loss: 0.00571594946
Iter: 283 loss: 0.00571588194
Iter: 284 loss: 0.00571586937
Iter: 285 loss: 0.00571592571
Iter: 286 loss: 0.00571586471
Iter: 287 loss: 0.00571585447
Iter: 288 loss: 0.00571591966
Iter: 289 loss: 0.0057158526
Iter: 290 loss: 0.00571584795
Iter: 291 loss: 0.00571596064
Iter: 292 loss: 0.00571584655
Iter: 293 loss: 0.0057158405
Iter: 294 loss: 0.00571583491
Iter: 295 loss: 0.00571583398
Iter: 296 loss: 0.00571583025
Iter: 297 loss: 0.00571586518
Iter: 298 loss: 0.00571582559
Iter: 299 loss: 0.00571582094
Iter: 300 loss: 0.00571583305
Iter: 301 loss: 0.00571581908
Iter: 302 loss: 0.00571581163
Iter: 303 loss: 0.00571585726
Iter: 304 loss: 0.00571581256
Iter: 305 loss: 0.0057158079
Iter: 306 loss: 0.00571580604
Iter: 307 loss: 0.00571580324
Iter: 308 loss: 0.00571579952
Iter: 309 loss: 0.00571582094
Iter: 310 loss: 0.00571579766
Iter: 311 loss: 0.005715793
Iter: 312 loss: 0.00571579579
Iter: 313 loss: 0.00571578927
Iter: 314 loss: 0.00571578508
Iter: 315 loss: 0.00571581814
Iter: 316 loss: 0.00571578275
Iter: 317 loss: 0.00571578089
Iter: 318 loss: 0.00571578555
Iter: 319 loss: 0.00571577577
Iter: 320 loss: 0.00571577251
Iter: 321 loss: 0.00571578
Iter: 322 loss: 0.00571577065
Iter: 323 loss: 0.00571576878
Iter: 324 loss: 0.00571576646
Iter: 325 loss: 0.00571576506
Iter: 326 loss: 0.00571576925
Iter: 327 loss: 0.00571576506
Iter: 328 loss: 0.00571576133
Iter: 329 loss: 0.00571576087
Iter: 330 loss: 0.00571575807
Iter: 331 loss: 0.00571575575
Iter: 332 loss: 0.00571578
Iter: 333 loss: 0.00571575621
Iter: 334 loss: 0.00571575342
Iter: 335 loss: 0.00571576227
Iter: 336 loss: 0.00571575528
Iter: 337 loss: 0.00571575342
Iter: 338 loss: 0.00571575575
Iter: 339 loss: 0.00571575109
Iter: 340 loss: 0.00571574783
Iter: 341 loss: 0.00571575249
Iter: 342 loss: 0.00571574923
Iter: 343 loss: 0.00571574736
Iter: 344 loss: 0.0057157483
Iter: 345 loss: 0.0057157455
Iter: 346 loss: 0.00571574271
Iter: 347 loss: 0.00571575575
Iter: 348 loss: 0.00571574364
Iter: 349 loss: 0.00571574084
Iter: 350 loss: 0.0057157455
Iter: 351 loss: 0.00571574271
Iter: 352 loss: 0.00571573805
Iter: 353 loss: 0.00571574178
Iter: 354 loss: 0.00571573712
Iter: 355 loss: 0.00571573805
Iter: 356 loss: 0.00571574643
Iter: 357 loss: 0.00571573852
Iter: 358 loss: 0.00571573712
Iter: 359 loss: 0.00571574736
Iter: 360 loss: 0.00571573619
Iter: 361 loss: 0.00571573619
Iter: 362 loss: 0.00571573619
Iter: 363 loss: 0.00571573526
Iter: 364 loss: 0.00571573526
Iter: 365 loss: 0.00571573619
Iter: 366 loss: 0.00571573386
Iter: 367 loss: 0.00571573479
Iter: 368 loss: 0.00571573526
Iter: 369 loss: 0.00571573386
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2
+ date
Tue Oct 27 17:29:15 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f282d46d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27eb73dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27eb73dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27eb70ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27eb6692f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27eb669c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c456b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c456b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4596b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4539840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4500510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c44a9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c44a9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c445e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4472950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c44330d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c44359d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4435f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c43ae8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c43c7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c43c7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4388510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4333048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4349840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c42e4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4307620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c42d0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c427a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c427a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c4229620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c425a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c425a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c41e8b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c420f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c41cd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27c41cd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0542850122
Iter: 2 loss: 1456.38831
Iter: 3 loss: 8975.71191
Iter: 4 loss: 0.0344723761
Iter: 5 loss: 0.0634814501
Iter: 6 loss: 0.0344118699
Iter: 7 loss: 0.0322652124
Iter: 8 loss: 0.0320216715
Iter: 9 loss: 0.0253746361
Iter: 10 loss: 0.0252262857
Iter: 11 loss: 0.0204394981
Iter: 12 loss: 0.162577271
Iter: 13 loss: 0.0204243064
Iter: 14 loss: 0.0188811813
Iter: 15 loss: 0.0260687135
Iter: 16 loss: 0.0187829845
Iter: 17 loss: 0.018114863
Iter: 18 loss: 0.0181638561
Iter: 19 loss: 0.017522987
Iter: 20 loss: 0.0162400045
Iter: 21 loss: 0.0234615915
Iter: 22 loss: 0.0159635171
Iter: 23 loss: 0.0146102086
Iter: 24 loss: 0.0180176385
Iter: 25 loss: 0.0141461091
Iter: 26 loss: 0.0131844543
Iter: 27 loss: 0.0125869662
Iter: 28 loss: 0.0121421777
Iter: 29 loss: 0.0111303888
Iter: 30 loss: 0.0269548241
Iter: 31 loss: 0.011108987
Iter: 32 loss: 0.0102840895
Iter: 33 loss: 0.017638471
Iter: 34 loss: 0.010213349
Iter: 35 loss: 0.00969775766
Iter: 36 loss: 0.0130815795
Iter: 37 loss: 0.00963040069
Iter: 38 loss: 0.0092920037
Iter: 39 loss: 0.0113772564
Iter: 40 loss: 0.00925620273
Iter: 41 loss: 0.00909105316
Iter: 42 loss: 0.00909102242
Iter: 43 loss: 0.0090086963
Iter: 44 loss: 0.00894810352
Iter: 45 loss: 0.00892059319
Iter: 46 loss: 0.00872143
Iter: 47 loss: 0.00878158305
Iter: 48 loss: 0.00857349485
Iter: 49 loss: 0.00836166367
Iter: 50 loss: 0.0100682788
Iter: 51 loss: 0.00834421255
Iter: 52 loss: 0.00813385285
Iter: 53 loss: 0.00915049668
Iter: 54 loss: 0.0080952961
Iter: 55 loss: 0.00795241259
Iter: 56 loss: 0.00903514214
Iter: 57 loss: 0.0079373084
Iter: 58 loss: 0.00782995485
Iter: 59 loss: 0.00806112681
Iter: 60 loss: 0.0077872551
Iter: 61 loss: 0.00766811194
Iter: 62 loss: 0.008481659
Iter: 63 loss: 0.00765304454
Iter: 64 loss: 0.00756688649
Iter: 65 loss: 0.00773407798
Iter: 66 loss: 0.00753098959
Iter: 67 loss: 0.00742761604
Iter: 68 loss: 0.00882071257
Iter: 69 loss: 0.00742663816
Iter: 70 loss: 0.00736651476
Iter: 71 loss: 0.00772091094
Iter: 72 loss: 0.00735995686
Iter: 73 loss: 0.00732278
Iter: 74 loss: 0.00767473411
Iter: 75 loss: 0.00732047483
Iter: 76 loss: 0.00729618
Iter: 77 loss: 0.00731710205
Iter: 78 loss: 0.00728200097
Iter: 79 loss: 0.00723325927
Iter: 80 loss: 0.00735796941
Iter: 81 loss: 0.0072165411
Iter: 82 loss: 0.00717409421
Iter: 83 loss: 0.00736555224
Iter: 84 loss: 0.00716637587
Iter: 85 loss: 0.00713548809
Iter: 86 loss: 0.00720358
Iter: 87 loss: 0.00712349825
Iter: 88 loss: 0.00709768059
Iter: 89 loss: 0.00714547746
Iter: 90 loss: 0.00708632031
Iter: 91 loss: 0.00706893485
Iter: 92 loss: 0.00706893066
Iter: 93 loss: 0.00705420226
Iter: 94 loss: 0.0070740832
Iter: 95 loss: 0.00704690767
Iter: 96 loss: 0.00703468546
Iter: 97 loss: 0.00703546964
Iter: 98 loss: 0.00702500483
Iter: 99 loss: 0.00701360358
Iter: 100 loss: 0.0069984477
Iter: 101 loss: 0.00699759461
Iter: 102 loss: 0.00697974116
Iter: 103 loss: 0.00704147061
Iter: 104 loss: 0.00697506964
Iter: 105 loss: 0.00695859455
Iter: 106 loss: 0.00705569843
Iter: 107 loss: 0.00695635937
Iter: 108 loss: 0.00695309322
Iter: 109 loss: 0.00694948481
Iter: 110 loss: 0.00694364123
Iter: 111 loss: 0.00692669256
Iter: 112 loss: 0.00700333202
Iter: 113 loss: 0.00692012347
Iter: 114 loss: 0.00690685539
Iter: 115 loss: 0.00692170626
Iter: 116 loss: 0.00689974707
Iter: 117 loss: 0.00689146947
Iter: 118 loss: 0.0068780873
Iter: 119 loss: 0.00687798
Iter: 120 loss: 0.00686540734
Iter: 121 loss: 0.00687751221
Iter: 122 loss: 0.00685817283
Iter: 123 loss: 0.00684728101
Iter: 124 loss: 0.00685590412
Iter: 125 loss: 0.00684071099
Iter: 126 loss: 0.00682919752
Iter: 127 loss: 0.00696114544
Iter: 128 loss: 0.0068289605
Iter: 129 loss: 0.00681942282
Iter: 130 loss: 0.00686504971
Iter: 131 loss: 0.00681774132
Iter: 132 loss: 0.00680866744
Iter: 133 loss: 0.00680443505
Iter: 134 loss: 0.00679991301
Iter: 135 loss: 0.00678644795
Iter: 136 loss: 0.00683434773
Iter: 137 loss: 0.00678291
Iter: 138 loss: 0.00677201338
Iter: 139 loss: 0.00683929352
Iter: 140 loss: 0.00677068345
Iter: 141 loss: 0.00676239654
Iter: 142 loss: 0.00683957525
Iter: 143 loss: 0.0067620948
Iter: 144 loss: 0.00675704423
Iter: 145 loss: 0.00675685471
Iter: 146 loss: 0.00675425865
Iter: 147 loss: 0.00675234152
Iter: 148 loss: 0.00675148051
Iter: 149 loss: 0.00674666092
Iter: 150 loss: 0.00675089657
Iter: 151 loss: 0.00674381293
Iter: 152 loss: 0.00673830649
Iter: 153 loss: 0.00675663911
Iter: 154 loss: 0.00673679076
Iter: 155 loss: 0.00673164427
Iter: 156 loss: 0.00673890114
Iter: 157 loss: 0.006729085
Iter: 158 loss: 0.0067234165
Iter: 159 loss: 0.00672597252
Iter: 160 loss: 0.00671955105
Iter: 161 loss: 0.00671266299
Iter: 162 loss: 0.00678900164
Iter: 163 loss: 0.00671254
Iter: 164 loss: 0.00670628063
Iter: 165 loss: 0.00669764029
Iter: 166 loss: 0.00669724774
Iter: 167 loss: 0.0066865785
Iter: 168 loss: 0.0067113284
Iter: 169 loss: 0.0066826418
Iter: 170 loss: 0.00667434745
Iter: 171 loss: 0.00671448745
Iter: 172 loss: 0.00667291135
Iter: 173 loss: 0.00666626589
Iter: 174 loss: 0.00668671
Iter: 175 loss: 0.00666433712
Iter: 176 loss: 0.00666073523
Iter: 177 loss: 0.00666029844
Iter: 178 loss: 0.00665700203
Iter: 179 loss: 0.0066657858
Iter: 180 loss: 0.00665592449
Iter: 181 loss: 0.00665363
Iter: 182 loss: 0.00664999615
Iter: 183 loss: 0.00664995704
Iter: 184 loss: 0.0066456385
Iter: 185 loss: 0.00666044839
Iter: 186 loss: 0.00664449437
Iter: 187 loss: 0.00664078258
Iter: 188 loss: 0.00665302202
Iter: 189 loss: 0.00663974416
Iter: 190 loss: 0.00663583819
Iter: 191 loss: 0.00663337437
Iter: 192 loss: 0.00663182791
Iter: 193 loss: 0.00662772916
Iter: 194 loss: 0.0066795256
Iter: 195 loss: 0.00662769843
Iter: 196 loss: 0.00662430841
Iter: 197 loss: 0.00664075138
Iter: 198 loss: 0.00662370212
Iter: 199 loss: 0.00662111863
Iter: 200 loss: 0.0066218162
Iter: 201 loss: 0.00661925087
Iter: 202 loss: 0.00661621243
Iter: 203 loss: 0.00662199175
Iter: 204 loss: 0.00661493745
Iter: 205 loss: 0.00661219796
Iter: 206 loss: 0.0066289
Iter: 207 loss: 0.00661186548
Iter: 208 loss: 0.00660994602
Iter: 209 loss: 0.00661926717
Iter: 210 loss: 0.00660960097
Iter: 211 loss: 0.00660821795
Iter: 212 loss: 0.00660815742
Iter: 213 loss: 0.00660749059
Iter: 214 loss: 0.00660644751
Iter: 215 loss: 0.0066064354
Iter: 216 loss: 0.0066050617
Iter: 217 loss: 0.00660547381
Iter: 218 loss: 0.00660407916
Iter: 219 loss: 0.00660260394
Iter: 220 loss: 0.00660822
Iter: 221 loss: 0.00660225702
Iter: 222 loss: 0.00660073105
Iter: 223 loss: 0.00660300534
Iter: 224 loss: 0.00659999717
Iter: 225 loss: 0.00659834407
Iter: 226 loss: 0.0066002314
Iter: 227 loss: 0.00659746211
Iter: 228 loss: 0.00659635896
Iter: 229 loss: 0.00661320379
Iter: 230 loss: 0.00659635663
Iter: 231 loss: 0.00659539178
Iter: 232 loss: 0.00659824908
Iter: 233 loss: 0.00659509748
Iter: 234 loss: 0.00659435801
Iter: 235 loss: 0.00659349374
Iter: 236 loss: 0.00659339642
Iter: 237 loss: 0.00659208186
Iter: 238 loss: 0.00659685582
Iter: 239 loss: 0.00659175031
Iter: 240 loss: 0.00659069046
Iter: 241 loss: 0.00659358036
Iter: 242 loss: 0.00659034587
Iter: 243 loss: 0.00659031048
Iter: 244 loss: 0.00658989511
Iter: 245 loss: 0.00658944761
Iter: 246 loss: 0.006589178
Iter: 247 loss: 0.00658899499
Iter: 248 loss: 0.00658843294
Iter: 249 loss: 0.00658774655
Iter: 250 loss: 0.00658768462
Iter: 251 loss: 0.00658670068
Iter: 252 loss: 0.00659123575
Iter: 253 loss: 0.00658651907
Iter: 254 loss: 0.00658582104
Iter: 255 loss: 0.00658744527
Iter: 256 loss: 0.00658556633
Iter: 257 loss: 0.00658477191
Iter: 258 loss: 0.00658639753
Iter: 259 loss: 0.00658445153
Iter: 260 loss: 0.00658368
Iter: 261 loss: 0.00658682967
Iter: 262 loss: 0.0065835081
Iter: 263 loss: 0.00658283848
Iter: 264 loss: 0.00658306
Iter: 265 loss: 0.00658236537
Iter: 266 loss: 0.00658201
Iter: 267 loss: 0.0065819337
Iter: 268 loss: 0.00658158353
Iter: 269 loss: 0.00658140518
Iter: 270 loss: 0.00658124406
Iter: 271 loss: 0.00658074487
Iter: 272 loss: 0.00658083707
Iter: 273 loss: 0.00658037048
Iter: 274 loss: 0.00657978514
Iter: 275 loss: 0.00658170693
Iter: 276 loss: 0.00657962495
Iter: 277 loss: 0.00657975208
Iter: 278 loss: 0.00657940516
Iter: 279 loss: 0.00657925848
Iter: 280 loss: 0.00657900423
Iter: 281 loss: 0.00657900423
Iter: 282 loss: 0.0065787374
Iter: 283 loss: 0.00657873508
Iter: 284 loss: 0.00657852367
Iter: 285 loss: 0.00657818094
Iter: 286 loss: 0.0065792026
Iter: 287 loss: 0.00657808036
Iter: 288 loss: 0.00657779956
Iter: 289 loss: 0.00657858793
Iter: 290 loss: 0.00657770876
Iter: 291 loss: 0.00657741493
Iter: 292 loss: 0.0065785069
Iter: 293 loss: 0.00657734741
Iter: 294 loss: 0.00657709269
Iter: 295 loss: 0.00657755556
Iter: 296 loss: 0.00657698559
Iter: 297 loss: 0.0065766708
Iter: 298 loss: 0.0065770885
Iter: 299 loss: 0.00657651201
Iter: 300 loss: 0.00657634949
Iter: 301 loss: 0.00657633692
Iter: 302 loss: 0.00657617114
Iter: 303 loss: 0.00657591084
Iter: 304 loss: 0.00657590572
Iter: 305 loss: 0.00657565193
Iter: 306 loss: 0.00657693762
Iter: 307 loss: 0.00657560863
Iter: 308 loss: 0.00657552248
Iter: 309 loss: 0.00657552
Iter: 310 loss: 0.00657542236
Iter: 311 loss: 0.00657541864
Iter: 312 loss: 0.00657534041
Iter: 313 loss: 0.00657523144
Iter: 314 loss: 0.0065752184
Iter: 315 loss: 0.00657514296
Iter: 316 loss: 0.00657501258
Iter: 317 loss: 0.00657538325
Iter: 318 loss: 0.00657497393
Iter: 319 loss: 0.00657484401
Iter: 320 loss: 0.00657491665
Iter: 321 loss: 0.00657476205
Iter: 322 loss: 0.0065746028
Iter: 323 loss: 0.0065750191
Iter: 324 loss: 0.00657455344
Iter: 325 loss: 0.00657439418
Iter: 326 loss: 0.00657526311
Iter: 327 loss: 0.00657437183
Iter: 328 loss: 0.00657425076
Iter: 329 loss: 0.00657434575
Iter: 330 loss: 0.00657417532
Iter: 331 loss: 0.00657400116
Iter: 332 loss: 0.00657475647
Iter: 333 loss: 0.00657397136
Iter: 334 loss: 0.00657386892
Iter: 335 loss: 0.00657532318
Iter: 336 loss: 0.00657386798
Iter: 337 loss: 0.00657378696
Iter: 338 loss: 0.00657365
Iter: 339 loss: 0.00657365099
Iter: 340 loss: 0.00657364447
Iter: 341 loss: 0.0065736
Iter: 342 loss: 0.00657355553
Iter: 343 loss: 0.00657363422
Iter: 344 loss: 0.0065735383
Iter: 345 loss: 0.00657349546
Iter: 346 loss: 0.00657340838
Iter: 347 loss: 0.00657511549
Iter: 348 loss: 0.00657340651
Iter: 349 loss: 0.00657330547
Iter: 350 loss: 0.00657376088
Iter: 351 loss: 0.0065732915
Iter: 352 loss: 0.00657320488
Iter: 353 loss: 0.00657328404
Iter: 354 loss: 0.00657315785
Iter: 355 loss: 0.00657305587
Iter: 356 loss: 0.00657326821
Iter: 357 loss: 0.0065730121
Iter: 358 loss: 0.00657289848
Iter: 359 loss: 0.00657320209
Iter: 360 loss: 0.00657286076
Iter: 361 loss: 0.00657272572
Iter: 362 loss: 0.00657296088
Iter: 363 loss: 0.00657266518
Iter: 364 loss: 0.00657253619
Iter: 365 loss: 0.00657328032
Iter: 366 loss: 0.0065725185
Iter: 367 loss: 0.00657241791
Iter: 368 loss: 0.00657301536
Iter: 369 loss: 0.00657240395
Iter: 370 loss: 0.00657231407
Iter: 371 loss: 0.0065725
Iter: 372 loss: 0.00657227729
Iter: 373 loss: 0.00657220325
Iter: 374 loss: 0.006572349
Iter: 375 loss: 0.00657217437
Iter: 376 loss: 0.00657210778
Iter: 377 loss: 0.00657210778
Iter: 378 loss: 0.00657207426
Iter: 379 loss: 0.00657199509
Iter: 380 loss: 0.00657304144
Iter: 381 loss: 0.00657198858
Iter: 382 loss: 0.00657188939
Iter: 383 loss: 0.00657198345
Iter: 384 loss: 0.00657183025
Iter: 385 loss: 0.0065717278
Iter: 386 loss: 0.00657232106
Iter: 387 loss: 0.00657171523
Iter: 388 loss: 0.00657162257
Iter: 389 loss: 0.00657156948
Iter: 390 loss: 0.00657153549
Iter: 391 loss: 0.00657138322
Iter: 392 loss: 0.00657207565
Iter: 393 loss: 0.00657135341
Iter: 394 loss: 0.00657122722
Iter: 395 loss: 0.00657165563
Iter: 396 loss: 0.00657119323
Iter: 397 loss: 0.00657107122
Iter: 398 loss: 0.00657153595
Iter: 399 loss: 0.00657104328
Iter: 400 loss: 0.0065709562
Iter: 401 loss: 0.00657151639
Iter: 402 loss: 0.00657094829
Iter: 403 loss: 0.00657086
Iter: 404 loss: 0.00657099858
Iter: 405 loss: 0.00657081883
Iter: 406 loss: 0.00657073641
Iter: 407 loss: 0.00657098088
Iter: 408 loss: 0.00657070847
Iter: 409 loss: 0.0065706782
Iter: 410 loss: 0.00657066843
Iter: 411 loss: 0.00657063676
Iter: 412 loss: 0.00657055341
Iter: 413 loss: 0.00657118578
Iter: 414 loss: 0.00657054037
Iter: 415 loss: 0.00657045608
Iter: 416 loss: 0.00657092221
Iter: 417 loss: 0.00657044258
Iter: 418 loss: 0.00657037739
Iter: 419 loss: 0.00657041743
Iter: 420 loss: 0.00657033455
Iter: 421 loss: 0.006570247
Iter: 422 loss: 0.00657045655
Iter: 423 loss: 0.00657021394
Iter: 424 loss: 0.00657012593
Iter: 425 loss: 0.00657029357
Iter: 426 loss: 0.00657008868
Iter: 427 loss: 0.00656998623
Iter: 428 loss: 0.00657029636
Iter: 429 loss: 0.00656995364
Iter: 430 loss: 0.00656987121
Iter: 431 loss: 0.00657045422
Iter: 432 loss: 0.00656986
Iter: 433 loss: 0.0065698009
Iter: 434 loss: 0.00656999741
Iter: 435 loss: 0.00656978227
Iter: 436 loss: 0.00656972686
Iter: 437 loss: 0.00657012081
Iter: 438 loss: 0.00656971801
Iter: 439 loss: 0.00656968309
Iter: 440 loss: 0.0065697087
Iter: 441 loss: 0.00656965468
Iter: 442 loss: 0.00656963326
Iter: 443 loss: 0.00656962628
Iter: 444 loss: 0.00656960392
Iter: 445 loss: 0.00656956
Iter: 446 loss: 0.00656955969
Iter: 447 loss: 0.0065695243
Iter: 448 loss: 0.00656952104
Iter: 449 loss: 0.00656949356
Iter: 450 loss: 0.00656943116
Iter: 451 loss: 0.00656959228
Iter: 452 loss: 0.00656941347
Iter: 453 loss: 0.00656935712
Iter: 454 loss: 0.0065694456
Iter: 455 loss: 0.00656933198
Iter: 456 loss: 0.00656926539
Iter: 457 loss: 0.00656940835
Iter: 458 loss: 0.00656923838
Iter: 459 loss: 0.00656918157
Iter: 460 loss: 0.00656937528
Iter: 461 loss: 0.00656916341
Iter: 462 loss: 0.0065691
Iter: 463 loss: 0.00656932406
Iter: 464 loss: 0.00656908378
Iter: 465 loss: 0.00656903628
Iter: 466 loss: 0.00656930311
Iter: 467 loss: 0.00656902883
Iter: 468 loss: 0.00656898972
Iter: 469 loss: 0.0065692
Iter: 470 loss: 0.00656898133
Iter: 471 loss: 0.00656894781
Iter: 472 loss: 0.0065689953
Iter: 473 loss: 0.00656893058
Iter: 474 loss: 0.00656891149
Iter: 475 loss: 0.00656890962
Iter: 476 loss: 0.00656889146
Iter: 477 loss: 0.00656887237
Iter: 478 loss: 0.00656886678
Iter: 479 loss: 0.00656884024
Iter: 480 loss: 0.00656881044
Iter: 481 loss: 0.00656880857
Iter: 482 loss: 0.00656875921
Iter: 483 loss: 0.00656898506
Iter: 484 loss: 0.0065687513
Iter: 485 loss: 0.00656870566
Iter: 486 loss: 0.00656871917
Iter: 487 loss: 0.00656867586
Iter: 488 loss: 0.00656861905
Iter: 489 loss: 0.00656888168
Iter: 490 loss: 0.00656860974
Iter: 491 loss: 0.00656855758
Iter: 492 loss: 0.00656863
Iter: 493 loss: 0.00656853104
Iter: 494 loss: 0.00656848215
Iter: 495 loss: 0.00656877924
Iter: 496 loss: 0.00656847656
Iter: 497 loss: 0.00656843092
Iter: 498 loss: 0.00656856131
Iter: 499 loss: 0.00656841928
Iter: 500 loss: 0.00656838482
Iter: 501 loss: 0.00656870101
Iter: 502 loss: 0.00656838482
Iter: 503 loss: 0.00656835735
Iter: 504 loss: 0.00656837877
Iter: 505 loss: 0.00656834384
Iter: 506 loss: 0.0065683173
Iter: 507 loss: 0.00656863581
Iter: 508 loss: 0.00656831451
Iter: 509 loss: 0.00656829029
Iter: 510 loss: 0.00656830613
Iter: 511 loss: 0.00656827167
Iter: 512 loss: 0.00656825304
Iter: 513 loss: 0.00656822044
Iter: 514 loss: 0.00656821858
Iter: 515 loss: 0.00656817295
Iter: 516 loss: 0.00656827679
Iter: 517 loss: 0.00656815618
Iter: 518 loss: 0.00656810775
Iter: 519 loss: 0.00656828377
Iter: 520 loss: 0.00656809472
Iter: 521 loss: 0.00656804955
Iter: 522 loss: 0.00656807562
Iter: 523 loss: 0.00656802114
Iter: 524 loss: 0.00656796666
Iter: 525 loss: 0.00656825257
Iter: 526 loss: 0.00656795828
Iter: 527 loss: 0.00656790938
Iter: 528 loss: 0.00656796899
Iter: 529 loss: 0.0065678875
Iter: 530 loss: 0.00656783488
Iter: 531 loss: 0.00656822231
Iter: 532 loss: 0.00656782975
Iter: 533 loss: 0.00656779855
Iter: 534 loss: 0.00656800438
Iter: 535 loss: 0.00656779483
Iter: 536 loss: 0.00656776596
Iter: 537 loss: 0.0065678088
Iter: 538 loss: 0.00656775478
Iter: 539 loss: 0.00656772777
Iter: 540 loss: 0.00656797551
Iter: 541 loss: 0.00656772684
Iter: 542 loss: 0.00656770216
Iter: 543 loss: 0.0065677627
Iter: 544 loss: 0.00656769238
Iter: 545 loss: 0.00656767795
Iter: 546 loss: 0.00656764349
Iter: 547 loss: 0.00656823302
Iter: 548 loss: 0.00656764442
Iter: 549 loss: 0.00656759785
Iter: 550 loss: 0.00656772172
Iter: 551 loss: 0.00656758249
Iter: 552 loss: 0.00656754617
Iter: 553 loss: 0.00656771846
Iter: 554 loss: 0.0065675322
Iter: 555 loss: 0.00656749541
Iter: 556 loss: 0.00656749494
Iter: 557 loss: 0.00656746421
Iter: 558 loss: 0.00656741485
Iter: 559 loss: 0.00656770589
Iter: 560 loss: 0.00656740926
Iter: 561 loss: 0.00656737
Iter: 562 loss: 0.00656745117
Iter: 563 loss: 0.00656735105
Iter: 564 loss: 0.00656731706
Iter: 565 loss: 0.00656757783
Iter: 566 loss: 0.0065673124
Iter: 567 loss: 0.00656728679
Iter: 568 loss: 0.00656741345
Iter: 569 loss: 0.00656728074
Iter: 570 loss: 0.00656725559
Iter: 571 loss: 0.0065673627
Iter: 572 loss: 0.00656725094
Iter: 573 loss: 0.00656723464
Iter: 574 loss: 0.00656733662
Iter: 575 loss: 0.00656723324
Iter: 576 loss: 0.00656721555
Iter: 577 loss: 0.00656727329
Iter: 578 loss: 0.00656721182
Iter: 579 loss: 0.00656719692
Iter: 580 loss: 0.00656716898
Iter: 581 loss: 0.00656757271
Iter: 582 loss: 0.00656716898
Iter: 583 loss: 0.00656713545
Iter: 584 loss: 0.00656726351
Iter: 585 loss: 0.00656712893
Iter: 586 loss: 0.0065671
Iter: 587 loss: 0.00656720251
Iter: 588 loss: 0.00656709354
Iter: 589 loss: 0.00656706467
Iter: 590 loss: 0.00656709028
Iter: 591 loss: 0.00656704605
Iter: 592 loss: 0.00656701112
Iter: 593 loss: 0.00656707
Iter: 594 loss: 0.00656700041
Iter: 595 loss: 0.00656696083
Iter: 596 loss: 0.00656720623
Iter: 597 loss: 0.0065669585
Iter: 598 loss: 0.00656693056
Iter: 599 loss: 0.00656698924
Iter: 600 loss: 0.00656691846
Iter: 601 loss: 0.00656689052
Iter: 602 loss: 0.00656713825
Iter: 603 loss: 0.00656689098
Iter: 604 loss: 0.00656687748
Iter: 605 loss: 0.0065669613
Iter: 606 loss: 0.00656687049
Iter: 607 loss: 0.00656686071
Iter: 608 loss: 0.00656690076
Iter: 609 loss: 0.00656685885
Iter: 610 loss: 0.00656684581
Iter: 611 loss: 0.00656691752
Iter: 612 loss: 0.00656684441
Iter: 613 loss: 0.0065668365
Iter: 614 loss: 0.00656681741
Iter: 615 loss: 0.00656707305
Iter: 616 loss: 0.00656681508
Iter: 617 loss: 0.00656679226
Iter: 618 loss: 0.00656683231
Iter: 619 loss: 0.00656677969
Iter: 620 loss: 0.00656675501
Iter: 621 loss: 0.00656688353
Iter: 622 loss: 0.00656675315
Iter: 623 loss: 0.0065667294
Iter: 624 loss: 0.00656674244
Iter: 625 loss: 0.00656671356
Iter: 626 loss: 0.00656668283
Iter: 627 loss: 0.00656674337
Iter: 628 loss: 0.00656666793
Iter: 629 loss: 0.00656664232
Iter: 630 loss: 0.00656683557
Iter: 631 loss: 0.00656663952
Iter: 632 loss: 0.00656661484
Iter: 633 loss: 0.00656666048
Iter: 634 loss: 0.00656660413
Iter: 635 loss: 0.00656658597
Iter: 636 loss: 0.00656681508
Iter: 637 loss: 0.0065665869
Iter: 638 loss: 0.00656657573
Iter: 639 loss: 0.00656660926
Iter: 640 loss: 0.00656656967
Iter: 641 loss: 0.00656656
Iter: 642 loss: 0.00656660739
Iter: 643 loss: 0.00656655896
Iter: 644 loss: 0.00656654499
Iter: 645 loss: 0.00656663161
Iter: 646 loss: 0.0065665436
Iter: 647 loss: 0.00656653941
Iter: 648 loss: 0.00656651799
Iter: 649 loss: 0.00656669494
Iter: 650 loss: 0.00656651659
Iter: 651 loss: 0.0065664961
Iter: 652 loss: 0.00656655757
Iter: 653 loss: 0.00656649
Iter: 654 loss: 0.0065664663
Iter: 655 loss: 0.00656654406
Iter: 656 loss: 0.00656646444
Iter: 657 loss: 0.00656643882
Iter: 658 loss: 0.00656646863
Iter: 659 loss: 0.00656642672
Iter: 660 loss: 0.00656640157
Iter: 661 loss: 0.00656645
Iter: 662 loss: 0.00656639226
Iter: 663 loss: 0.00656636711
Iter: 664 loss: 0.00656646304
Iter: 665 loss: 0.00656636199
Iter: 666 loss: 0.00656633824
Iter: 667 loss: 0.00656645885
Iter: 668 loss: 0.00656633172
Iter: 669 loss: 0.00656631682
Iter: 670 loss: 0.00656643976
Iter: 671 loss: 0.00656631356
Iter: 672 loss: 0.00656630285
Iter: 673 loss: 0.00656633917
Iter: 674 loss: 0.0065663
Iter: 675 loss: 0.00656628935
Iter: 676 loss: 0.00656635873
Iter: 677 loss: 0.00656628702
Iter: 678 loss: 0.0065662805
Iter: 679 loss: 0.00656634755
Iter: 680 loss: 0.0065662805
Iter: 681 loss: 0.00656627165
Iter: 682 loss: 0.00656625722
Iter: 683 loss: 0.00656637
Iter: 684 loss: 0.00656625442
Iter: 685 loss: 0.0065662358
Iter: 686 loss: 0.00656629
Iter: 687 loss: 0.0065662316
Iter: 688 loss: 0.00656621158
Iter: 689 loss: 0.00656626374
Iter: 690 loss: 0.00656620692
Iter: 691 loss: 0.00656618923
Iter: 692 loss: 0.00656623673
Iter: 693 loss: 0.00656618131
Iter: 694 loss: 0.00656616129
Iter: 695 loss: 0.00656618504
Iter: 696 loss: 0.00656615105
Iter: 697 loss: 0.00656612776
Iter: 698 loss: 0.00656622136
Iter: 699 loss: 0.00656612078
Iter: 700 loss: 0.00656610494
Iter: 701 loss: 0.00656619
Iter: 702 loss: 0.00656610494
Iter: 703 loss: 0.00656609144
Iter: 704 loss: 0.00656617293
Iter: 705 loss: 0.00656608865
Iter: 706 loss: 0.00656607747
Iter: 707 loss: 0.00656612497
Iter: 708 loss: 0.00656607281
Iter: 709 loss: 0.00656606723
Iter: 710 loss: 0.00656610774
Iter: 711 loss: 0.0065660649
Iter: 712 loss: 0.00656605605
Iter: 713 loss: 0.00656610588
Iter: 714 loss: 0.00656605512
Iter: 715 loss: 0.00656604953
Iter: 716 loss: 0.00656603742
Iter: 717 loss: 0.00656622881
Iter: 718 loss: 0.00656603742
Iter: 719 loss: 0.00656602485
Iter: 720 loss: 0.00656605605
Iter: 721 loss: 0.00656601926
Iter: 722 loss: 0.00656601
Iter: 723 loss: 0.00656604907
Iter: 724 loss: 0.00656600296
Iter: 725 loss: 0.00656599086
Iter: 726 loss: 0.00656602066
Iter: 727 loss: 0.00656598806
Iter: 728 loss: 0.00656597316
Iter: 729 loss: 0.00656598341
Iter: 730 loss: 0.00656596664
Iter: 731 loss: 0.00656594802
Iter: 732 loss: 0.00656602858
Iter: 733 loss: 0.00656594709
Iter: 734 loss: 0.00656593312
Iter: 735 loss: 0.0065659713
Iter: 736 loss: 0.00656593
Iter: 737 loss: 0.00656591868
Iter: 738 loss: 0.00656600436
Iter: 739 loss: 0.00656591915
Iter: 740 loss: 0.00656591402
Iter: 741 loss: 0.00656595174
Iter: 742 loss: 0.0065659117
Iter: 743 loss: 0.00656590424
Iter: 744 loss: 0.00656592567
Iter: 745 loss: 0.00656590611
Iter: 746 loss: 0.00656590052
Iter: 747 loss: 0.00656594941
Iter: 748 loss: 0.00656590238
Iter: 749 loss: 0.0065658954
Iter: 750 loss: 0.00656588608
Iter: 751 loss: 0.00656604953
Iter: 752 loss: 0.00656588655
Iter: 753 loss: 0.00656588236
Iter: 754 loss: 0.00656588422
Iter: 755 loss: 0.00656587491
Iter: 756 loss: 0.00656586839
Iter: 757 loss: 0.00656589586
Iter: 758 loss: 0.0065658642
Iter: 759 loss: 0.00656585721
Iter: 760 loss: 0.0065658805
Iter: 761 loss: 0.00656585256
Iter: 762 loss: 0.00656584464
Iter: 763 loss: 0.00656585488
Iter: 764 loss: 0.00656584
Iter: 765 loss: 0.00656582881
Iter: 766 loss: 0.00656588655
Iter: 767 loss: 0.00656582695
Iter: 768 loss: 0.00656582
Iter: 769 loss: 0.00656583626
Iter: 770 loss: 0.00656582
Iter: 771 loss: 0.00656580925
Iter: 772 loss: 0.00656588
Iter: 773 loss: 0.00656581111
Iter: 774 loss: 0.00656580506
Iter: 775 loss: 0.00656582136
Iter: 776 loss: 0.00656580459
Iter: 777 loss: 0.00656579761
Iter: 778 loss: 0.00656582089
Iter: 779 loss: 0.00656579807
Iter: 780 loss: 0.00656579295
Iter: 781 loss: 0.00656583486
Iter: 782 loss: 0.00656579342
Iter: 783 loss: 0.00656579155
Iter: 784 loss: 0.00656578969
Iter: 785 loss: 0.00656589027
Iter: 786 loss: 0.00656578783
Iter: 787 loss: 0.00656578224
Iter: 788 loss: 0.00656578597
Iter: 789 loss: 0.00656577852
Iter: 790 loss: 0.00656577386
Iter: 791 loss: 0.00656578923
Iter: 792 loss: 0.00656577246
Iter: 793 loss: 0.00656576641
Iter: 794 loss: 0.0065657869
Iter: 795 loss: 0.00656576362
Iter: 796 loss: 0.0065657571
Iter: 797 loss: 0.00656576222
Iter: 798 loss: 0.00656575337
Iter: 799 loss: 0.00656574592
Iter: 800 loss: 0.00656578038
Iter: 801 loss: 0.00656574406
Iter: 802 loss: 0.00656573661
Iter: 803 loss: 0.00656576082
Iter: 804 loss: 0.00656573568
Iter: 805 loss: 0.00656573102
Iter: 806 loss: 0.00656576548
Iter: 807 loss: 0.00656572636
Iter: 808 loss: 0.00656572264
Iter: 809 loss: 0.0065657394
Iter: 810 loss: 0.0065657231
Iter: 811 loss: 0.00656572
Iter: 812 loss: 0.00656574126
Iter: 813 loss: 0.00656572
Iter: 814 loss: 0.00656571565
Iter: 815 loss: 0.00656574685
Iter: 816 loss: 0.00656571705
Iter: 817 loss: 0.00656571332
Iter: 818 loss: 0.00656571286
Iter: 819 loss: 0.00656578317
Iter: 820 loss: 0.00656571286
Iter: 821 loss: 0.0065657068
Iter: 822 loss: 0.0065657096
Iter: 823 loss: 0.00656570401
Iter: 824 loss: 0.00656570029
Iter: 825 loss: 0.00656571519
Iter: 826 loss: 0.00656569609
Iter: 827 loss: 0.00656569283
Iter: 828 loss: 0.00656571053
Iter: 829 loss: 0.00656568725
Iter: 830 loss: 0.00656568585
Iter: 831 loss: 0.00656568771
Iter: 832 loss: 0.00656567886
Iter: 833 loss: 0.00656567328
Iter: 834 loss: 0.00656569377
Iter: 835 loss: 0.00656567141
Iter: 836 loss: 0.00656566629
Iter: 837 loss: 0.00656569516
Iter: 838 loss: 0.00656566489
Iter: 839 loss: 0.00656565791
Iter: 840 loss: 0.00656568073
Iter: 841 loss: 0.00656565651
Iter: 842 loss: 0.00656565325
Iter: 843 loss: 0.006565677
Iter: 844 loss: 0.00656565232
Iter: 845 loss: 0.00656564953
Iter: 846 loss: 0.0065656621
Iter: 847 loss: 0.00656565
Iter: 848 loss: 0.00656564627
Iter: 849 loss: 0.00656566909
Iter: 850 loss: 0.00656564487
Iter: 851 loss: 0.00656564161
Iter: 852 loss: 0.00656564161
Iter: 853 loss: 0.00656571239
Iter: 854 loss: 0.00656564254
Iter: 855 loss: 0.00656563789
Iter: 856 loss: 0.00656563835
Iter: 857 loss: 0.00656563789
Iter: 858 loss: 0.00656563044
Iter: 859 loss: 0.0065656458
Iter: 860 loss: 0.00656562857
Iter: 861 loss: 0.00656562205
Iter: 862 loss: 0.00656564673
Iter: 863 loss: 0.00656562205
Iter: 864 loss: 0.006565616
Iter: 865 loss: 0.00656561879
Iter: 866 loss: 0.00656561274
Iter: 867 loss: 0.00656560529
Iter: 868 loss: 0.0065656295
Iter: 869 loss: 0.00656560669
Iter: 870 loss: 0.00656560156
Iter: 871 loss: 0.00656562066
Iter: 872 loss: 0.00656559831
Iter: 873 loss: 0.00656559505
Iter: 874 loss: 0.00656562159
Iter: 875 loss: 0.00656559691
Iter: 876 loss: 0.00656559039
Iter: 877 loss: 0.00656560762
Iter: 878 loss: 0.00656559039
Iter: 879 loss: 0.00656558806
Iter: 880 loss: 0.00656560156
Iter: 881 loss: 0.00656558666
Iter: 882 loss: 0.0065655876
Iter: 883 loss: 0.00656560715
Iter: 884 loss: 0.00656558527
Iter: 885 loss: 0.00656558666
Iter: 886 loss: 0.00656558154
Iter: 887 loss: 0.0065656323
Iter: 888 loss: 0.00656558294
Iter: 889 loss: 0.00656558
Iter: 890 loss: 0.00656558
Iter: 891 loss: 0.00656557735
Iter: 892 loss: 0.00656557269
Iter: 893 loss: 0.00656558201
Iter: 894 loss: 0.0065655713
Iter: 895 loss: 0.00656556897
Iter: 896 loss: 0.00656559831
Iter: 897 loss: 0.00656556617
Iter: 898 loss: 0.00656556431
Iter: 899 loss: 0.00656556524
Iter: 900 loss: 0.00656556105
Iter: 901 loss: 0.00656555919
Iter: 902 loss: 0.00656557316
Iter: 903 loss: 0.00656555779
Iter: 904 loss: 0.00656555314
Iter: 905 loss: 0.00656556943
Iter: 906 loss: 0.0065655522
Iter: 907 loss: 0.00656555
Iter: 908 loss: 0.00656556897
Iter: 909 loss: 0.00656555127
Iter: 910 loss: 0.00656555127
Iter: 911 loss: 0.00656555686
Iter: 912 loss: 0.00656554848
Iter: 913 loss: 0.00656554941
Iter: 914 loss: 0.00656555407
Iter: 915 loss: 0.00656554615
Iter: 916 loss: 0.00656554755
Iter: 917 loss: 0.00656555872
Iter: 918 loss: 0.00656554615
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4
+ date
Tue Oct 27 17:33:08 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6c019268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6bf71730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6bf77268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6beb1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6beb1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6beb1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68c88730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68cba840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68c88378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68c68f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68c276a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68bc98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68bc9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68b87378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68b87840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68b9d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68b62c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68b62400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68b76730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68ae0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68aef598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68aae598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68a6b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68a0f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68a1a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68a378c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb689fbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb689a27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb689fb158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb689fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb6890c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb689291e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb68929400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb688d7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb688ffbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb688ba598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.126846775
Iter: 2 loss: 8425.22
Iter: 3 loss: 0.126845539
Iter: 4 loss: 13265.6543
Iter: 5 loss: 0.126767293
Iter: 6 loss: 4096.78125
Iter: 7 loss: 0.126765937
Iter: 8 loss: 988.980591
Iter: 9 loss: 414.582642
Iter: 10 loss: 0.124756858
Iter: 11 loss: 139.644806
Iter: 12 loss: 0.0834191293
Iter: 13 loss: 0.0724869892
Iter: 14 loss: 0.0732433349
Iter: 15 loss: 2043.73926
Iter: 16 loss: 0.0732432827
Iter: 17 loss: 112.034988
Iter: 18 loss: 0.0732425675
Iter: 19 loss: 0.0754703
Iter: 20 loss: 0.0706299692
Iter: 21 loss: 0.0691365
Iter: 22 loss: 0.0690411329
Iter: 23 loss: 0.0673387125
Iter: 24 loss: 0.0673256516
Iter: 25 loss: 0.0656351298
Iter: 26 loss: 0.0628317595
Iter: 27 loss: 0.0624557
Iter: 28 loss: 0.057843931
Iter: 29 loss: 0.0622007921
Iter: 30 loss: 0.0570650399
Iter: 31 loss: 0.0543431938
Iter: 32 loss: 0.0615864806
Iter: 33 loss: 0.0528065823
Iter: 34 loss: 0.0574466437
Iter: 35 loss: 0.0513368323
Iter: 36 loss: 0.0491923839
Iter: 37 loss: 0.0489333868
Iter: 38 loss: 0.0465745851
Iter: 39 loss: 0.0565735139
Iter: 40 loss: 0.0458317772
Iter: 41 loss: 0.0455928147
Iter: 42 loss: 0.0418945327
Iter: 43 loss: 0.0395120755
Iter: 44 loss: 0.063851878
Iter: 45 loss: 0.0395119712
Iter: 46 loss: 0.037773747
Iter: 47 loss: 0.0641097128
Iter: 48 loss: 0.0376601368
Iter: 49 loss: 0.0359149203
Iter: 50 loss: 0.0664014
Iter: 51 loss: 0.0357961357
Iter: 52 loss: 0.0340266116
Iter: 53 loss: 0.108937152
Iter: 54 loss: 0.0340188332
Iter: 55 loss: 0.0326005071
Iter: 56 loss: 0.0429656059
Iter: 57 loss: 0.0325252824
Iter: 58 loss: 0.0315230563
Iter: 59 loss: 0.0334258974
Iter: 60 loss: 0.031220438
Iter: 61 loss: 0.0296319127
Iter: 62 loss: 0.042229183
Iter: 63 loss: 0.0294101443
Iter: 64 loss: 0.0276772231
Iter: 65 loss: 0.056234058
Iter: 66 loss: 0.027638793
Iter: 67 loss: 0.0266806576
Iter: 68 loss: 0.0320634693
Iter: 69 loss: 0.026539173
Iter: 70 loss: 0.0254814588
Iter: 71 loss: 0.0254810341
Iter: 72 loss: 0.0248067565
Iter: 73 loss: 0.0317461267
Iter: 74 loss: 0.0247644354
Iter: 75 loss: 0.0253412202
Iter: 76 loss: 0.0246251
Iter: 77 loss: 0.0244644117
Iter: 78 loss: 0.024822386
Iter: 79 loss: 0.0244111195
Iter: 80 loss: 0.0238903463
Iter: 81 loss: 0.0239546858
Iter: 82 loss: 0.0235115811
Iter: 83 loss: 0.0230205283
Iter: 84 loss: 0.0306571499
Iter: 85 loss: 0.0230094865
Iter: 86 loss: 0.0227732286
Iter: 87 loss: 0.0243635252
Iter: 88 loss: 0.0227644183
Iter: 89 loss: 0.0225388687
Iter: 90 loss: 0.0238506831
Iter: 91 loss: 0.0224937182
Iter: 92 loss: 0.0223089419
Iter: 93 loss: 0.0225245804
Iter: 94 loss: 0.0222083349
Iter: 95 loss: 0.0218691733
Iter: 96 loss: 0.0220412333
Iter: 97 loss: 0.0216400363
Iter: 98 loss: 0.0209669787
Iter: 99 loss: 0.0244134367
Iter: 100 loss: 0.0208065845
Iter: 101 loss: 0.0198893771
Iter: 102 loss: 0.0248005874
Iter: 103 loss: 0.0197808743
Iter: 104 loss: 0.0193926822
Iter: 105 loss: 0.0204009712
Iter: 106 loss: 0.019230783
Iter: 107 loss: 0.0190764293
Iter: 108 loss: 0.0196315758
Iter: 109 loss: 0.0190350618
Iter: 110 loss: 0.0188308712
Iter: 111 loss: 0.0188305564
Iter: 112 loss: 0.0186577737
Iter: 113 loss: 0.0186686181
Iter: 114 loss: 0.0185296293
Iter: 115 loss: 0.018062517
Iter: 116 loss: 0.017884383
Iter: 117 loss: 0.0176080074
Iter: 118 loss: 0.0171913765
Iter: 119 loss: 0.0171744395
Iter: 120 loss: 0.0167204197
Iter: 121 loss: 0.0233897027
Iter: 122 loss: 0.016715033
Iter: 123 loss: 0.016425278
Iter: 124 loss: 0.0170598514
Iter: 125 loss: 0.0163442511
Iter: 126 loss: 0.016215967
Iter: 127 loss: 0.0163825
Iter: 128 loss: 0.0161444526
Iter: 129 loss: 0.0158653967
Iter: 130 loss: 0.0158729404
Iter: 131 loss: 0.0156441182
Iter: 132 loss: 0.0152302813
Iter: 133 loss: 0.0171217471
Iter: 134 loss: 0.0151351597
Iter: 135 loss: 0.0148261189
Iter: 136 loss: 0.0146736884
Iter: 137 loss: 0.0145268794
Iter: 138 loss: 0.0141706588
Iter: 139 loss: 0.0143909575
Iter: 140 loss: 0.0139321871
Iter: 141 loss: 0.0152648743
Iter: 142 loss: 0.0138780847
Iter: 143 loss: 0.0137310559
Iter: 144 loss: 0.0140695386
Iter: 145 loss: 0.0136763547
Iter: 146 loss: 0.0132153183
Iter: 147 loss: 0.0166409854
Iter: 148 loss: 0.0131799364
Iter: 149 loss: 0.0128251947
Iter: 150 loss: 0.0157159977
Iter: 151 loss: 0.012792062
Iter: 152 loss: 0.0126437731
Iter: 153 loss: 0.0129751768
Iter: 154 loss: 0.0125905415
Iter: 155 loss: 0.0124927703
Iter: 156 loss: 0.0123820538
Iter: 157 loss: 0.0123653337
Iter: 158 loss: 0.0122628883
Iter: 159 loss: 0.0124682561
Iter: 160 loss: 0.0122225601
Iter: 161 loss: 0.0119554615
Iter: 162 loss: 0.0129160117
Iter: 163 loss: 0.0118811177
Iter: 164 loss: 0.0121369269
Iter: 165 loss: 0.0117267435
Iter: 166 loss: 0.0116097918
Iter: 167 loss: 0.0117022069
Iter: 168 loss: 0.0115369232
Iter: 169 loss: 0.0114084007
Iter: 170 loss: 0.0113107841
Iter: 171 loss: 0.0112672057
Iter: 172 loss: 0.0111768991
Iter: 173 loss: 0.0111567834
Iter: 174 loss: 0.011085174
Iter: 175 loss: 0.0109904744
Iter: 176 loss: 0.0109846517
Iter: 177 loss: 0.0136801656
Iter: 178 loss: 0.010922214
Iter: 179 loss: 0.0108300559
Iter: 180 loss: 0.0113119148
Iter: 181 loss: 0.0108138816
Iter: 182 loss: 0.0107295346
Iter: 183 loss: 0.0109369727
Iter: 184 loss: 0.0107008694
Iter: 185 loss: 0.0105829593
Iter: 186 loss: 0.0106256157
Iter: 187 loss: 0.0104976483
Iter: 188 loss: 0.0104099521
Iter: 189 loss: 0.0104570286
Iter: 190 loss: 0.0103515591
Iter: 191 loss: 0.0102753704
Iter: 192 loss: 0.0102695171
Iter: 193 loss: 0.0102120582
Iter: 194 loss: 0.0101774018
Iter: 195 loss: 0.0101908129
Iter: 196 loss: 0.0101525225
Iter: 197 loss: 0.0101223085
Iter: 198 loss: 0.0100934468
Iter: 199 loss: 0.0100865159
Iter: 200 loss: 0.00993678719
Iter: 201 loss: 0.0100388797
Iter: 202 loss: 0.00984112173
Iter: 203 loss: 0.00964863412
Iter: 204 loss: 0.0112835411
Iter: 205 loss: 0.00964002684
Iter: 206 loss: 0.00951936
Iter: 207 loss: 0.00977755524
Iter: 208 loss: 0.00947141275
Iter: 209 loss: 0.00936945528
Iter: 210 loss: 0.0102870874
Iter: 211 loss: 0.00936143845
Iter: 212 loss: 0.00931180548
Iter: 213 loss: 0.00927885529
Iter: 214 loss: 0.00925983768
Iter: 215 loss: 0.00916890893
Iter: 216 loss: 0.009310605
Iter: 217 loss: 0.00912521221
Iter: 218 loss: 0.00903337
Iter: 219 loss: 0.009422075
Iter: 220 loss: 0.00901157502
Iter: 221 loss: 0.0089673847
Iter: 222 loss: 0.00911454856
Iter: 223 loss: 0.00895557087
Iter: 224 loss: 0.00888350606
Iter: 225 loss: 0.00889723
Iter: 226 loss: 0.00883167
Iter: 227 loss: 0.00877500512
Iter: 228 loss: 0.00901773199
Iter: 229 loss: 0.00876581
Iter: 230 loss: 0.00873864535
Iter: 231 loss: 0.00876925699
Iter: 232 loss: 0.00872348435
Iter: 233 loss: 0.00869605504
Iter: 234 loss: 0.00868256576
Iter: 235 loss: 0.00866939873
Iter: 236 loss: 0.00860025175
Iter: 237 loss: 0.00853740238
Iter: 238 loss: 0.00851946697
Iter: 239 loss: 0.00847146567
Iter: 240 loss: 0.00846566
Iter: 241 loss: 0.00842971914
Iter: 242 loss: 0.00841219
Iter: 243 loss: 0.00839462411
Iter: 244 loss: 0.00833167508
Iter: 245 loss: 0.00856886245
Iter: 246 loss: 0.00831583701
Iter: 247 loss: 0.00827236846
Iter: 248 loss: 0.00844295695
Iter: 249 loss: 0.00826179143
Iter: 250 loss: 0.00823371205
Iter: 251 loss: 0.00819811691
Iter: 252 loss: 0.00819533877
Iter: 253 loss: 0.00814551767
Iter: 254 loss: 0.00869150087
Iter: 255 loss: 0.008144
Iter: 256 loss: 0.00805387087
Iter: 257 loss: 0.00889544282
Iter: 258 loss: 0.00804933906
Iter: 259 loss: 0.0080059
Iter: 260 loss: 0.008260414
Iter: 261 loss: 0.00799868815
Iter: 262 loss: 0.00795808621
Iter: 263 loss: 0.00797731057
Iter: 264 loss: 0.00793112256
Iter: 265 loss: 0.00789325871
Iter: 266 loss: 0.00790017284
Iter: 267 loss: 0.00786449295
Iter: 268 loss: 0.00780292368
Iter: 269 loss: 0.0078986045
Iter: 270 loss: 0.00777438516
Iter: 271 loss: 0.00771090202
Iter: 272 loss: 0.00781966932
Iter: 273 loss: 0.00768175256
Iter: 274 loss: 0.00763175031
Iter: 275 loss: 0.00768160634
Iter: 276 loss: 0.00760285091
Iter: 277 loss: 0.00755996
Iter: 278 loss: 0.00792016368
Iter: 279 loss: 0.00755705312
Iter: 280 loss: 0.00751111703
Iter: 281 loss: 0.00778124575
Iter: 282 loss: 0.00750589
Iter: 283 loss: 0.00748886
Iter: 284 loss: 0.00749501307
Iter: 285 loss: 0.00747682666
Iter: 286 loss: 0.00746400096
Iter: 287 loss: 0.00744151371
Iter: 288 loss: 0.00744151045
Iter: 289 loss: 0.0073846858
Iter: 290 loss: 0.00758466404
Iter: 291 loss: 0.00737008359
Iter: 292 loss: 0.00731852558
Iter: 293 loss: 0.00731457956
Iter: 294 loss: 0.00727664866
Iter: 295 loss: 0.00726282923
Iter: 296 loss: 0.00724833924
Iter: 297 loss: 0.00722334906
Iter: 298 loss: 0.00723056123
Iter: 299 loss: 0.00720546581
Iter: 300 loss: 0.00717729703
Iter: 301 loss: 0.00710583106
Iter: 302 loss: 0.0077779023
Iter: 303 loss: 0.00709491316
Iter: 304 loss: 0.00702767447
Iter: 305 loss: 0.00724337343
Iter: 306 loss: 0.00700684544
Iter: 307 loss: 0.00696832966
Iter: 308 loss: 0.00751411
Iter: 309 loss: 0.00696812384
Iter: 310 loss: 0.00692532491
Iter: 311 loss: 0.00689046
Iter: 312 loss: 0.00687840674
Iter: 313 loss: 0.00687971804
Iter: 314 loss: 0.00685975282
Iter: 315 loss: 0.00684317
Iter: 316 loss: 0.00698336866
Iter: 317 loss: 0.00684229
Iter: 318 loss: 0.0068344865
Iter: 319 loss: 0.006811528
Iter: 320 loss: 0.00690102763
Iter: 321 loss: 0.00680158474
Iter: 322 loss: 0.00673584733
Iter: 323 loss: 0.00768050179
Iter: 324 loss: 0.00673565269
Iter: 325 loss: 0.0066865366
Iter: 326 loss: 0.00675833598
Iter: 327 loss: 0.0066630356
Iter: 328 loss: 0.0066454378
Iter: 329 loss: 0.00664623547
Iter: 330 loss: 0.00663168589
Iter: 331 loss: 0.00661569927
Iter: 332 loss: 0.00658470392
Iter: 333 loss: 0.00730549172
Iter: 334 loss: 0.0065845442
Iter: 335 loss: 0.00655834842
Iter: 336 loss: 0.00667050481
Iter: 337 loss: 0.00655305712
Iter: 338 loss: 0.0065037217
Iter: 339 loss: 0.0068698572
Iter: 340 loss: 0.00649881549
Iter: 341 loss: 0.00646244688
Iter: 342 loss: 0.00646235887
Iter: 343 loss: 0.0064384453
Iter: 344 loss: 0.00645279046
Iter: 345 loss: 0.00642331224
Iter: 346 loss: 0.00640569162
Iter: 347 loss: 0.00638945401
Iter: 348 loss: 0.00638506329
Iter: 349 loss: 0.0063603255
Iter: 350 loss: 0.00629203906
Iter: 351 loss: 0.00671568513
Iter: 352 loss: 0.00627307221
Iter: 353 loss: 0.00621971209
Iter: 354 loss: 0.00674382132
Iter: 355 loss: 0.00621793699
Iter: 356 loss: 0.00660372153
Iter: 357 loss: 0.00619721739
Iter: 358 loss: 0.00618993584
Iter: 359 loss: 0.00618132856
Iter: 360 loss: 0.00618037814
Iter: 361 loss: 0.00615524501
Iter: 362 loss: 0.00615034392
Iter: 363 loss: 0.00611336716
Iter: 364 loss: 0.00618674513
Iter: 365 loss: 0.00609875936
Iter: 366 loss: 0.00608849153
Iter: 367 loss: 0.00606360193
Iter: 368 loss: 0.00632320344
Iter: 369 loss: 0.00606079679
Iter: 370 loss: 0.00603721477
Iter: 371 loss: 0.00603905506
Iter: 372 loss: 0.0060187215
Iter: 373 loss: 0.00599902868
Iter: 374 loss: 0.00598762464
Iter: 375 loss: 0.00595589634
Iter: 376 loss: 0.00595585536
Iter: 377 loss: 0.00594224874
Iter: 378 loss: 0.00611344632
Iter: 379 loss: 0.00594215561
Iter: 380 loss: 0.00593101792
Iter: 381 loss: 0.00590758957
Iter: 382 loss: 0.00632147491
Iter: 383 loss: 0.00590700144
Iter: 384 loss: 0.0058834739
Iter: 385 loss: 0.00586412475
Iter: 386 loss: 0.00585737079
Iter: 387 loss: 0.00583614
Iter: 388 loss: 0.00593790365
Iter: 389 loss: 0.00583239272
Iter: 390 loss: 0.00583072845
Iter: 391 loss: 0.00581443403
Iter: 392 loss: 0.00580923632
Iter: 393 loss: 0.00580029469
Iter: 394 loss: 0.00580029
Iter: 395 loss: 0.00578616187
Iter: 396 loss: 0.00581630226
Iter: 397 loss: 0.00578071456
Iter: 398 loss: 0.00575361541
Iter: 399 loss: 0.00587753905
Iter: 400 loss: 0.00574820768
Iter: 401 loss: 0.00572787644
Iter: 402 loss: 0.00579892285
Iter: 403 loss: 0.00572287
Iter: 404 loss: 0.00570774544
Iter: 405 loss: 0.0057027177
Iter: 406 loss: 0.00569408666
Iter: 407 loss: 0.0056657
Iter: 408 loss: 0.00569341891
Iter: 409 loss: 0.00564961554
Iter: 410 loss: 0.00562265
Iter: 411 loss: 0.00589858554
Iter: 412 loss: 0.00562190963
Iter: 413 loss: 0.00560975494
Iter: 414 loss: 0.00560502894
Iter: 415 loss: 0.00559434248
Iter: 416 loss: 0.0055849785
Iter: 417 loss: 0.00558223203
Iter: 418 loss: 0.00557307433
Iter: 419 loss: 0.00555780577
Iter: 420 loss: 0.00555774756
Iter: 421 loss: 0.00554790441
Iter: 422 loss: 0.00555607025
Iter: 423 loss: 0.00554194953
Iter: 424 loss: 0.00551986601
Iter: 425 loss: 0.00555930333
Iter: 426 loss: 0.00550999539
Iter: 427 loss: 0.00548857916
Iter: 428 loss: 0.00568347424
Iter: 429 loss: 0.00548757147
Iter: 430 loss: 0.00548093487
Iter: 431 loss: 0.00548123941
Iter: 432 loss: 0.00547564216
Iter: 433 loss: 0.00546579156
Iter: 434 loss: 0.00544944964
Iter: 435 loss: 0.00544936117
Iter: 436 loss: 0.00541123
Iter: 437 loss: 0.00539870467
Iter: 438 loss: 0.00537637854
Iter: 439 loss: 0.00534663117
Iter: 440 loss: 0.00549517944
Iter: 441 loss: 0.0053413203
Iter: 442 loss: 0.00530620664
Iter: 443 loss: 0.0055277627
Iter: 444 loss: 0.00530217774
Iter: 445 loss: 0.00529197
Iter: 446 loss: 0.00529197184
Iter: 447 loss: 0.00528754247
Iter: 448 loss: 0.00528205186
Iter: 449 loss: 0.00528159179
Iter: 450 loss: 0.00527773844
Iter: 451 loss: 0.00527654774
Iter: 452 loss: 0.00527165
Iter: 453 loss: 0.00525961397
Iter: 454 loss: 0.00538824731
Iter: 455 loss: 0.00525818579
Iter: 456 loss: 0.0052416604
Iter: 457 loss: 0.00547810271
Iter: 458 loss: 0.00524161104
Iter: 459 loss: 0.00523358537
Iter: 460 loss: 0.00523356488
Iter: 461 loss: 0.00522578135
Iter: 462 loss: 0.00522254966
Iter: 463 loss: 0.00521849608
Iter: 464 loss: 0.00520866597
Iter: 465 loss: 0.00520845968
Iter: 466 loss: 0.00520060444
Iter: 467 loss: 0.0051831021
Iter: 468 loss: 0.00520330481
Iter: 469 loss: 0.00517364778
Iter: 470 loss: 0.005161935
Iter: 471 loss: 0.00535292272
Iter: 472 loss: 0.00516192429
Iter: 473 loss: 0.00514996564
Iter: 474 loss: 0.00515421
Iter: 475 loss: 0.00514162425
Iter: 476 loss: 0.00512604788
Iter: 477 loss: 0.00513412245
Iter: 478 loss: 0.00511559471
Iter: 479 loss: 0.00510982331
Iter: 480 loss: 0.0051065213
Iter: 481 loss: 0.00510428
Iter: 482 loss: 0.00509711914
Iter: 483 loss: 0.00510510243
Iter: 484 loss: 0.00509148138
Iter: 485 loss: 0.00507595763
Iter: 486 loss: 0.00508718146
Iter: 487 loss: 0.00506638456
Iter: 488 loss: 0.00506291073
Iter: 489 loss: 0.00506289909
Iter: 490 loss: 0.00505980663
Iter: 491 loss: 0.00507426402
Iter: 492 loss: 0.00505923945
Iter: 493 loss: 0.00505558
Iter: 494 loss: 0.00506162271
Iter: 495 loss: 0.0050538918
Iter: 496 loss: 0.00504929293
Iter: 497 loss: 0.00503815152
Iter: 498 loss: 0.00516112149
Iter: 499 loss: 0.00503694732
Iter: 500 loss: 0.00502204429
Iter: 501 loss: 0.00502214488
Iter: 502 loss: 0.00501013314
Iter: 503 loss: 0.00499640219
Iter: 504 loss: 0.00518999249
Iter: 505 loss: 0.00499636307
Iter: 506 loss: 0.00498404307
Iter: 507 loss: 0.00496362336
Iter: 508 loss: 0.00496354513
Iter: 509 loss: 0.00495090941
Iter: 510 loss: 0.00494920369
Iter: 511 loss: 0.00494034402
Iter: 512 loss: 0.0049247914
Iter: 513 loss: 0.00505113695
Iter: 514 loss: 0.00492367893
Iter: 515 loss: 0.00492152479
Iter: 516 loss: 0.00491425209
Iter: 517 loss: 0.00491165416
Iter: 518 loss: 0.00490902
Iter: 519 loss: 0.0049085049
Iter: 520 loss: 0.00490321638
Iter: 521 loss: 0.00497781904
Iter: 522 loss: 0.00490320101
Iter: 523 loss: 0.00489937654
Iter: 524 loss: 0.00490078516
Iter: 525 loss: 0.00489671156
Iter: 526 loss: 0.00489031943
Iter: 527 loss: 0.00488531496
Iter: 528 loss: 0.00488332473
Iter: 529 loss: 0.00487547461
Iter: 530 loss: 0.00487022148
Iter: 531 loss: 0.00486725
Iter: 532 loss: 0.0048578158
Iter: 533 loss: 0.00495017692
Iter: 534 loss: 0.00485748425
Iter: 535 loss: 0.00484729465
Iter: 536 loss: 0.00483076461
Iter: 537 loss: 0.00483066263
Iter: 538 loss: 0.00482075568
Iter: 539 loss: 0.00482072961
Iter: 540 loss: 0.00481635751
Iter: 541 loss: 0.00481341127
Iter: 542 loss: 0.00481178612
Iter: 543 loss: 0.00480431784
Iter: 544 loss: 0.00480424892
Iter: 545 loss: 0.00480157323
Iter: 546 loss: 0.00483136717
Iter: 547 loss: 0.00480152247
Iter: 548 loss: 0.00479963236
Iter: 549 loss: 0.00479391217
Iter: 550 loss: 0.00480976049
Iter: 551 loss: 0.00479086256
Iter: 552 loss: 0.00478272885
Iter: 553 loss: 0.00480203377
Iter: 554 loss: 0.00477974536
Iter: 555 loss: 0.00477853511
Iter: 556 loss: 0.00477632415
Iter: 557 loss: 0.00477230782
Iter: 558 loss: 0.00477537885
Iter: 559 loss: 0.00476985797
Iter: 560 loss: 0.00476567633
Iter: 561 loss: 0.00475947931
Iter: 562 loss: 0.00475932378
Iter: 563 loss: 0.00475240871
Iter: 564 loss: 0.00478689186
Iter: 565 loss: 0.00475128181
Iter: 566 loss: 0.00474530552
Iter: 567 loss: 0.00474712625
Iter: 568 loss: 0.00474095903
Iter: 569 loss: 0.00473663537
Iter: 570 loss: 0.00480013434
Iter: 571 loss: 0.00473663
Iter: 572 loss: 0.00473259436
Iter: 573 loss: 0.00472007319
Iter: 574 loss: 0.00474596722
Iter: 575 loss: 0.00471222028
Iter: 576 loss: 0.00470083766
Iter: 577 loss: 0.00472905394
Iter: 578 loss: 0.00469681155
Iter: 579 loss: 0.00469474448
Iter: 580 loss: 0.004694
Iter: 581 loss: 0.00469285203
Iter: 582 loss: 0.00469103735
Iter: 583 loss: 0.00469477475
Iter: 584 loss: 0.00469029881
Iter: 585 loss: 0.00468719518
Iter: 586 loss: 0.00470216945
Iter: 587 loss: 0.00468666758
Iter: 588 loss: 0.00468305778
Iter: 589 loss: 0.00467570871
Iter: 590 loss: 0.00481065689
Iter: 591 loss: 0.0046755881
Iter: 592 loss: 0.00466943439
Iter: 593 loss: 0.00476037664
Iter: 594 loss: 0.00466942973
Iter: 595 loss: 0.00466632051
Iter: 596 loss: 0.00466434751
Iter: 597 loss: 0.00466310699
Iter: 598 loss: 0.00465709111
Iter: 599 loss: 0.00464785052
Iter: 600 loss: 0.00464770943
Iter: 601 loss: 0.00464571267
Iter: 602 loss: 0.00464370847
Iter: 603 loss: 0.00464202929
Iter: 604 loss: 0.0046395706
Iter: 605 loss: 0.00463951472
Iter: 606 loss: 0.00463443343
Iter: 607 loss: 0.00462410273
Iter: 608 loss: 0.00481088459
Iter: 609 loss: 0.00462393556
Iter: 610 loss: 0.00461652828
Iter: 611 loss: 0.00470259506
Iter: 612 loss: 0.00461641606
Iter: 613 loss: 0.00462270621
Iter: 614 loss: 0.00461364258
Iter: 615 loss: 0.00461223116
Iter: 616 loss: 0.00460891
Iter: 617 loss: 0.00464902
Iter: 618 loss: 0.00460862834
Iter: 619 loss: 0.00467093335
Iter: 620 loss: 0.00460677408
Iter: 621 loss: 0.00460494962
Iter: 622 loss: 0.00460753124
Iter: 623 loss: 0.00460405415
Iter: 624 loss: 0.00460226974
Iter: 625 loss: 0.00459865527
Iter: 626 loss: 0.00466488441
Iter: 627 loss: 0.00459860358
Iter: 628 loss: 0.00459258026
Iter: 629 loss: 0.00463469047
Iter: 630 loss: 0.00459200097
Iter: 631 loss: 0.0045880829
Iter: 632 loss: 0.00460045086
Iter: 633 loss: 0.00458692573
Iter: 634 loss: 0.00458219
Iter: 635 loss: 0.00459772535
Iter: 636 loss: 0.00458084792
Iter: 637 loss: 0.00457618525
Iter: 638 loss: 0.00459561637
Iter: 639 loss: 0.00457520597
Iter: 640 loss: 0.00457268
Iter: 641 loss: 0.00457865139
Iter: 642 loss: 0.00457176613
Iter: 643 loss: 0.00456958637
Iter: 644 loss: 0.0045687845
Iter: 645 loss: 0.00456756866
Iter: 646 loss: 0.00456546666
Iter: 647 loss: 0.00456512906
Iter: 648 loss: 0.00456367806
Iter: 649 loss: 0.00456197234
Iter: 650 loss: 0.00455800164
Iter: 651 loss: 0.00460587395
Iter: 652 loss: 0.00455768313
Iter: 653 loss: 0.00455387868
Iter: 654 loss: 0.00455891155
Iter: 655 loss: 0.00455192477
Iter: 656 loss: 0.00454630284
Iter: 657 loss: 0.00455552619
Iter: 658 loss: 0.0045437431
Iter: 659 loss: 0.00453893235
Iter: 660 loss: 0.00453859428
Iter: 661 loss: 0.00453688204
Iter: 662 loss: 0.0045337989
Iter: 663 loss: 0.00461023161
Iter: 664 loss: 0.00453380216
Iter: 665 loss: 0.00453228317
Iter: 666 loss: 0.00453041261
Iter: 667 loss: 0.00452748686
Iter: 668 loss: 0.00456131436
Iter: 669 loss: 0.00452743657
Iter: 670 loss: 0.0045265751
Iter: 671 loss: 0.00452620676
Iter: 672 loss: 0.00452576112
Iter: 673 loss: 0.00452379091
Iter: 674 loss: 0.00451987749
Iter: 675 loss: 0.00459723
Iter: 676 loss: 0.00451983092
Iter: 677 loss: 0.00451830169
Iter: 678 loss: 0.00451811729
Iter: 679 loss: 0.00451649027
Iter: 680 loss: 0.00452159857
Iter: 681 loss: 0.00451600878
Iter: 682 loss: 0.00451459736
Iter: 683 loss: 0.00451211724
Iter: 684 loss: 0.00451211818
Iter: 685 loss: 0.00450685248
Iter: 686 loss: 0.00449530222
Iter: 687 loss: 0.00467207422
Iter: 688 loss: 0.00449480209
Iter: 689 loss: 0.00448807841
Iter: 690 loss: 0.00453021284
Iter: 691 loss: 0.00448731473
Iter: 692 loss: 0.00448399549
Iter: 693 loss: 0.00449706893
Iter: 694 loss: 0.00448323088
Iter: 695 loss: 0.0044807
Iter: 696 loss: 0.00447481
Iter: 697 loss: 0.00454607513
Iter: 698 loss: 0.00447434559
Iter: 699 loss: 0.00446851272
Iter: 700 loss: 0.00447373372
Iter: 701 loss: 0.00446513
Iter: 702 loss: 0.00446388684
Iter: 703 loss: 0.0044613569
Iter: 704 loss: 0.00450732838
Iter: 705 loss: 0.00446132291
Iter: 706 loss: 0.00446005026
Iter: 707 loss: 0.00445954548
Iter: 708 loss: 0.00445887167
Iter: 709 loss: 0.00445684232
Iter: 710 loss: 0.00445400365
Iter: 711 loss: 0.00445388304
Iter: 712 loss: 0.00445000594
Iter: 713 loss: 0.00448445836
Iter: 714 loss: 0.00444983132
Iter: 715 loss: 0.00444667926
Iter: 716 loss: 0.0044415663
Iter: 717 loss: 0.00444152392
Iter: 718 loss: 0.00443653483
Iter: 719 loss: 0.00443639932
Iter: 720 loss: 0.00443478115
Iter: 721 loss: 0.00443456601
Iter: 722 loss: 0.00443342794
Iter: 723 loss: 0.00443197927
Iter: 724 loss: 0.0044309604
Iter: 725 loss: 0.00443045236
Iter: 726 loss: 0.00442835363
Iter: 727 loss: 0.00444267178
Iter: 728 loss: 0.0044281492
Iter: 729 loss: 0.00442565512
Iter: 730 loss: 0.00444349274
Iter: 731 loss: 0.00442542974
Iter: 732 loss: 0.0044215396
Iter: 733 loss: 0.00444507925
Iter: 734 loss: 0.00442104414
Iter: 735 loss: 0.00441846205
Iter: 736 loss: 0.00442731194
Iter: 737 loss: 0.00441777613
Iter: 738 loss: 0.00441626
Iter: 739 loss: 0.00441237
Iter: 740 loss: 0.00444513746
Iter: 741 loss: 0.0044117053
Iter: 742 loss: 0.00440891786
Iter: 743 loss: 0.00440933928
Iter: 744 loss: 0.00440681167
Iter: 745 loss: 0.00440448849
Iter: 746 loss: 0.00440828083
Iter: 747 loss: 0.00440341607
Iter: 748 loss: 0.00440217648
Iter: 749 loss: 0.00439874362
Iter: 750 loss: 0.00441845041
Iter: 751 loss: 0.00439776946
Iter: 752 loss: 0.00439499272
Iter: 753 loss: 0.00439490518
Iter: 754 loss: 0.00439077476
Iter: 755 loss: 0.00441418309
Iter: 756 loss: 0.00439020898
Iter: 757 loss: 0.00438838731
Iter: 758 loss: 0.0043891184
Iter: 759 loss: 0.00438712444
Iter: 760 loss: 0.00438576471
Iter: 761 loss: 0.00438453816
Iter: 762 loss: 0.00438418426
Iter: 763 loss: 0.00438125245
Iter: 764 loss: 0.00438628951
Iter: 765 loss: 0.00437995279
Iter: 766 loss: 0.00437667035
Iter: 767 loss: 0.00438844832
Iter: 768 loss: 0.00437584519
Iter: 769 loss: 0.00437621912
Iter: 770 loss: 0.00437415438
Iter: 771 loss: 0.00437328313
Iter: 772 loss: 0.0043715192
Iter: 773 loss: 0.00440378627
Iter: 774 loss: 0.00437148847
Iter: 775 loss: 0.0043691406
Iter: 776 loss: 0.00436898647
Iter: 777 loss: 0.00436599646
Iter: 778 loss: 0.00436599227
Iter: 779 loss: 0.0043653124
Iter: 780 loss: 0.00436332682
Iter: 781 loss: 0.00437119231
Iter: 782 loss: 0.00436249422
Iter: 783 loss: 0.00436029769
Iter: 784 loss: 0.00436060783
Iter: 785 loss: 0.00435862411
Iter: 786 loss: 0.00435538171
Iter: 787 loss: 0.004379516
Iter: 788 loss: 0.00435511954
Iter: 789 loss: 0.00435238378
Iter: 790 loss: 0.00439121434
Iter: 791 loss: 0.00435237586
Iter: 792 loss: 0.0043510478
Iter: 793 loss: 0.00434717722
Iter: 794 loss: 0.0043627019
Iter: 795 loss: 0.00434558373
Iter: 796 loss: 0.0043382179
Iter: 797 loss: 0.00437454
Iter: 798 loss: 0.00433693454
Iter: 799 loss: 0.00433375873
Iter: 800 loss: 0.00433433
Iter: 801 loss: 0.00433136662
Iter: 802 loss: 0.00433295593
Iter: 803 loss: 0.00432997523
Iter: 804 loss: 0.00432774611
Iter: 805 loss: 0.00432970934
Iter: 806 loss: 0.00432643294
Iter: 807 loss: 0.00432550069
Iter: 808 loss: 0.00432678126
Iter: 809 loss: 0.00432504527
Iter: 810 loss: 0.00432253629
Iter: 811 loss: 0.004320201
Iter: 812 loss: 0.00431959797
Iter: 813 loss: 0.00431594299
Iter: 814 loss: 0.00431589363
Iter: 815 loss: 0.00431459397
Iter: 816 loss: 0.00431063771
Iter: 817 loss: 0.0043209
Iter: 818 loss: 0.00430847285
Iter: 819 loss: 0.00430607563
Iter: 820 loss: 0.0043304353
Iter: 821 loss: 0.00430600159
Iter: 822 loss: 0.00430459809
Iter: 823 loss: 0.00430486305
Iter: 824 loss: 0.00430354383
Iter: 825 loss: 0.00430201646
Iter: 826 loss: 0.00430455059
Iter: 827 loss: 0.0043013203
Iter: 828 loss: 0.00429858
Iter: 829 loss: 0.00429562293
Iter: 830 loss: 0.0042951582
Iter: 831 loss: 0.00429085
Iter: 832 loss: 0.00432541594
Iter: 833 loss: 0.00429057516
Iter: 834 loss: 0.00428905478
Iter: 835 loss: 0.00429072417
Iter: 836 loss: 0.00428823475
Iter: 837 loss: 0.00428698491
Iter: 838 loss: 0.00428667478
Iter: 839 loss: 0.00428617047
Iter: 840 loss: 0.00428576302
Iter: 841 loss: 0.00428560609
Iter: 842 loss: 0.00428420305
Iter: 843 loss: 0.0042805
Iter: 844 loss: 0.00430804398
Iter: 845 loss: 0.00427974295
Iter: 846 loss: 0.00427602511
Iter: 847 loss: 0.0042945738
Iter: 848 loss: 0.00427539367
Iter: 849 loss: 0.00427373219
Iter: 850 loss: 0.00429356843
Iter: 851 loss: 0.00427370891
Iter: 852 loss: 0.00427255034
Iter: 853 loss: 0.00427376106
Iter: 854 loss: 0.00427191518
Iter: 855 loss: 0.00427040458
Iter: 856 loss: 0.00426815962
Iter: 857 loss: 0.004268107
Iter: 858 loss: 0.00426321477
Iter: 859 loss: 0.00428220071
Iter: 860 loss: 0.00426204968
Iter: 861 loss: 0.00425862521
Iter: 862 loss: 0.00429203548
Iter: 863 loss: 0.00425851298
Iter: 864 loss: 0.00425687619
Iter: 865 loss: 0.00425765663
Iter: 866 loss: 0.00425578468
Iter: 867 loss: 0.00425290084
Iter: 868 loss: 0.00425774045
Iter: 869 loss: 0.00425162073
Iter: 870 loss: 0.00425249804
Iter: 871 loss: 0.00425093807
Iter: 872 loss: 0.00425029639
Iter: 873 loss: 0.00425156
Iter: 874 loss: 0.0042500291
Iter: 875 loss: 0.00424921606
Iter: 876 loss: 0.00424678065
Iter: 877 loss: 0.00425403193
Iter: 878 loss: 0.00424555782
Iter: 879 loss: 0.00424186047
Iter: 880 loss: 0.00424546143
Iter: 881 loss: 0.00423976174
Iter: 882 loss: 0.00424099294
Iter: 883 loss: 0.00423871
Iter: 884 loss: 0.00423733797
Iter: 885 loss: 0.00424040295
Iter: 886 loss: 0.00423681038
Iter: 887 loss: 0.00423520431
Iter: 888 loss: 0.00423214538
Iter: 889 loss: 0.00429926813
Iter: 890 loss: 0.00423213281
Iter: 891 loss: 0.00422919
Iter: 892 loss: 0.00424997555
Iter: 893 loss: 0.00422893418
Iter: 894 loss: 0.00422676792
Iter: 895 loss: 0.00423540873
Iter: 896 loss: 0.00422627199
Iter: 897 loss: 0.00422437768
Iter: 898 loss: 0.00421964237
Iter: 899 loss: 0.00426541502
Iter: 900 loss: 0.00421898905
Iter: 901 loss: 0.00421375129
Iter: 902 loss: 0.00421375176
Iter: 903 loss: 0.00421213638
Iter: 904 loss: 0.00421204325
Iter: 905 loss: 0.00421057455
Iter: 906 loss: 0.00421607494
Iter: 907 loss: 0.00421021553
Iter: 908 loss: 0.00420893263
Iter: 909 loss: 0.00420975033
Iter: 910 loss: 0.00420810655
Iter: 911 loss: 0.00420699315
Iter: 912 loss: 0.00420422852
Iter: 913 loss: 0.00423089927
Iter: 914 loss: 0.00420385506
Iter: 915 loss: 0.00420103921
Iter: 916 loss: 0.00420545274
Iter: 917 loss: 0.00419972884
Iter: 918 loss: 0.00419664895
Iter: 919 loss: 0.00419514347
Iter: 920 loss: 0.00419367338
Iter: 921 loss: 0.00420211814
Iter: 922 loss: 0.0041921204
Iter: 923 loss: 0.00418982
Iter: 924 loss: 0.00419562
Iter: 925 loss: 0.00418901304
Iter: 926 loss: 0.00418802258
Iter: 927 loss: 0.00418695295
Iter: 928 loss: 0.00418678718
Iter: 929 loss: 0.00418457342
Iter: 930 loss: 0.00418807939
Iter: 931 loss: 0.00418353
Iter: 932 loss: 0.00418032054
Iter: 933 loss: 0.00418968033
Iter: 934 loss: 0.00417932356
Iter: 935 loss: 0.00417693099
Iter: 936 loss: 0.00420782389
Iter: 937 loss: 0.00417691097
Iter: 938 loss: 0.0041762162
Iter: 939 loss: 0.00417611515
Iter: 940 loss: 0.00417548418
Iter: 941 loss: 0.00417681923
Iter: 942 loss: 0.00417523
Iter: 943 loss: 0.0041744113
Iter: 944 loss: 0.00417322386
Iter: 945 loss: 0.00417318847
Iter: 946 loss: 0.00417140871
Iter: 947 loss: 0.0041695619
Iter: 948 loss: 0.00416921917
Iter: 949 loss: 0.00416691136
Iter: 950 loss: 0.0041693151
Iter: 951 loss: 0.00416563731
Iter: 952 loss: 0.00416269898
Iter: 953 loss: 0.00417204434
Iter: 954 loss: 0.00416184589
Iter: 955 loss: 0.00416223751
Iter: 956 loss: 0.00416121678
Iter: 957 loss: 0.00416035671
Iter: 958 loss: 0.00416080095
Iter: 959 loss: 0.00415978581
Iter: 960 loss: 0.0041590347
Iter: 961 loss: 0.00415661326
Iter: 962 loss: 0.00415828358
Iter: 963 loss: 0.0041545
Iter: 964 loss: 0.00415127259
Iter: 965 loss: 0.00415126095
Iter: 966 loss: 0.00414969306
Iter: 967 loss: 0.00415557344
Iter: 968 loss: 0.00414931122
Iter: 969 loss: 0.00414798316
Iter: 970 loss: 0.00415635295
Iter: 971 loss: 0.00414783694
Iter: 972 loss: 0.00414588396
Iter: 973 loss: 0.00415160041
Iter: 974 loss: 0.00414528325
Iter: 975 loss: 0.00414347835
Iter: 976 loss: 0.00416052295
Iter: 977 loss: 0.0041434071
Iter: 978 loss: 0.00414270256
Iter: 979 loss: 0.00414176937
Iter: 980 loss: 0.00414171629
Iter: 981 loss: 0.00413986202
Iter: 982 loss: 0.00413530925
Iter: 983 loss: 0.00418194383
Iter: 984 loss: 0.00413475418
Iter: 985 loss: 0.00413087243
Iter: 986 loss: 0.00416526617
Iter: 987 loss: 0.0041306694
Iter: 988 loss: 0.004127956
Iter: 989 loss: 0.00414559571
Iter: 990 loss: 0.00412766263
Iter: 991 loss: 0.00412781676
Iter: 992 loss: 0.00412642956
Iter: 993 loss: 0.00412613153
Iter: 994 loss: 0.00412500929
Iter: 995 loss: 0.00412182743
Iter: 996 loss: 0.004166428
Iter: 997 loss: 0.00412165606
Iter: 998 loss: 0.00411814125
Iter: 999 loss: 0.00412946334
Iter: 1000 loss: 0.00411715731
Iter: 1001 loss: 0.00411575846
Iter: 1002 loss: 0.00411437266
Iter: 1003 loss: 0.00411408907
Iter: 1004 loss: 0.00411092
Iter: 1005 loss: 0.004128817
Iter: 1006 loss: 0.00411047833
Iter: 1007 loss: 0.00410989346
Iter: 1008 loss: 0.00410974491
Iter: 1009 loss: 0.00410940778
Iter: 1010 loss: 0.00410877634
Iter: 1011 loss: 0.00412212079
Iter: 1012 loss: 0.00410877634
Iter: 1013 loss: 0.00410805177
Iter: 1014 loss: 0.00410778914
Iter: 1015 loss: 0.00410664221
Iter: 1016 loss: 0.00410514511
Iter: 1017 loss: 0.00410504825
Iter: 1018 loss: 0.00410347711
Iter: 1019 loss: 0.00410442
Iter: 1020 loss: 0.00410247408
Iter: 1021 loss: 0.00410173088
Iter: 1022 loss: 0.00410070037
Iter: 1023 loss: 0.00410065334
Iter: 1024 loss: 0.00409918372
Iter: 1025 loss: 0.00409912504
Iter: 1026 loss: 0.00409799
Iter: 1027 loss: 0.00409695
Iter: 1028 loss: 0.00409949711
Iter: 1029 loss: 0.00409657508
Iter: 1030 loss: 0.00409599394
Iter: 1031 loss: 0.00409595855
Iter: 1032 loss: 0.00409575459
Iter: 1033 loss: 0.00409502909
Iter: 1034 loss: 0.00409338763
Iter: 1035 loss: 0.00409339182
Iter: 1036 loss: 0.00409135129
Iter: 1037 loss: 0.00410273299
Iter: 1038 loss: 0.00409106398
Iter: 1039 loss: 0.00408986118
Iter: 1040 loss: 0.00408964511
Iter: 1041 loss: 0.00408904254
Iter: 1042 loss: 0.0040874742
Iter: 1043 loss: 0.00410083868
Iter: 1044 loss: 0.0040872097
Iter: 1045 loss: 0.00408607442
Iter: 1046 loss: 0.00408729631
Iter: 1047 loss: 0.00408544298
Iter: 1048 loss: 0.00408434775
Iter: 1049 loss: 0.00408427045
Iter: 1050 loss: 0.00408361293
Iter: 1051 loss: 0.00408284692
Iter: 1052 loss: 0.00408276822
Iter: 1053 loss: 0.00407991186
Iter: 1054 loss: 0.00408220477
Iter: 1055 loss: 0.00407818891
Iter: 1056 loss: 0.0040775775
Iter: 1057 loss: 0.0040765414
Iter: 1058 loss: 0.0040755854
Iter: 1059 loss: 0.00408004643
Iter: 1060 loss: 0.0040754131
Iter: 1061 loss: 0.00407469738
Iter: 1062 loss: 0.00408221083
Iter: 1063 loss: 0.00407467317
Iter: 1064 loss: 0.00407431833
Iter: 1065 loss: 0.00407316256
Iter: 1066 loss: 0.00407445617
Iter: 1067 loss: 0.00407226337
Iter: 1068 loss: 0.00406504888
Iter: 1069 loss: 0.00408794731
Iter: 1070 loss: 0.00406296458
Iter: 1071 loss: 0.00409187609
Iter: 1072 loss: 0.00406254269
Iter: 1073 loss: 0.0040621208
Iter: 1074 loss: 0.00406289054
Iter: 1075 loss: 0.00406193407
Iter: 1076 loss: 0.00406147959
Iter: 1077 loss: 0.00406064233
Iter: 1078 loss: 0.00408005575
Iter: 1079 loss: 0.00406064466
Iter: 1080 loss: 0.00405912241
Iter: 1081 loss: 0.00405663345
Iter: 1082 loss: 0.00405662
Iter: 1083 loss: 0.00405508699
Iter: 1084 loss: 0.00405507581
Iter: 1085 loss: 0.00405338593
Iter: 1086 loss: 0.0040554
Iter: 1087 loss: 0.00405249558
Iter: 1088 loss: 0.00405112887
Iter: 1089 loss: 0.0040511461
Iter: 1090 loss: 0.00405003736
Iter: 1091 loss: 0.00404793862
Iter: 1092 loss: 0.00405711588
Iter: 1093 loss: 0.00404750835
Iter: 1094 loss: 0.00404699659
Iter: 1095 loss: 0.00404684
Iter: 1096 loss: 0.00404575514
Iter: 1097 loss: 0.00404334
Iter: 1098 loss: 0.00407624384
Iter: 1099 loss: 0.00404319866
Iter: 1100 loss: 0.00404189341
Iter: 1101 loss: 0.00404706504
Iter: 1102 loss: 0.00404159911
Iter: 1103 loss: 0.00404130388
Iter: 1104 loss: 0.00404031947
Iter: 1105 loss: 0.00404051971
Iter: 1106 loss: 0.00403936254
Iter: 1107 loss: 0.0040387651
Iter: 1108 loss: 0.00403856952
Iter: 1109 loss: 0.00403798837
Iter: 1110 loss: 0.00403883401
Iter: 1111 loss: 0.00403770525
Iter: 1112 loss: 0.00403613597
Iter: 1113 loss: 0.00403643493
Iter: 1114 loss: 0.00403497089
Iter: 1115 loss: 0.0040333122
Iter: 1116 loss: 0.00403331
Iter: 1117 loss: 0.00403204933
Iter: 1118 loss: 0.00403949525
Iter: 1119 loss: 0.00403189
Iter: 1120 loss: 0.00403084746
Iter: 1121 loss: 0.00403163303
Iter: 1122 loss: 0.00403020717
Iter: 1123 loss: 0.00402934197
Iter: 1124 loss: 0.00403757859
Iter: 1125 loss: 0.00402931124
Iter: 1126 loss: 0.00402844884
Iter: 1127 loss: 0.00402767444
Iter: 1128 loss: 0.00402745511
Iter: 1129 loss: 0.00402613729
Iter: 1130 loss: 0.00402592868
Iter: 1131 loss: 0.00402540062
Iter: 1132 loss: 0.00403042696
Iter: 1133 loss: 0.00402537687
Iter: 1134 loss: 0.00402501225
Iter: 1135 loss: 0.00402381411
Iter: 1136 loss: 0.00402440643
Iter: 1137 loss: 0.00402272306
Iter: 1138 loss: 0.00402065925
Iter: 1139 loss: 0.00402049441
Iter: 1140 loss: 0.0040189568
Iter: 1141 loss: 0.00402795943
Iter: 1142 loss: 0.0040184469
Iter: 1143 loss: 0.00401812419
Iter: 1144 loss: 0.00401719566
Iter: 1145 loss: 0.00402119849
Iter: 1146 loss: 0.0040168385
Iter: 1147 loss: 0.00401477609
Iter: 1148 loss: 0.0040159463
Iter: 1149 loss: 0.00401343033
Iter: 1150 loss: 0.00401167385
Iter: 1151 loss: 0.00401167292
Iter: 1152 loss: 0.00401002821
Iter: 1153 loss: 0.00401479751
Iter: 1154 loss: 0.00400952389
Iter: 1155 loss: 0.00400792807
Iter: 1156 loss: 0.00401096186
Iter: 1157 loss: 0.00400725426
Iter: 1158 loss: 0.00400713971
Iter: 1159 loss: 0.00400607288
Iter: 1160 loss: 0.00400539488
Iter: 1161 loss: 0.00400661491
Iter: 1162 loss: 0.00400509778
Iter: 1163 loss: 0.00400405331
Iter: 1164 loss: 0.00400597509
Iter: 1165 loss: 0.00400360906
Iter: 1166 loss: 0.0040023718
Iter: 1167 loss: 0.00400530221
Iter: 1168 loss: 0.00400191639
Iter: 1169 loss: 0.00400130823
Iter: 1170 loss: 0.00399981905
Iter: 1171 loss: 0.00401472067
Iter: 1172 loss: 0.00399962952
Iter: 1173 loss: 0.00400041742
Iter: 1174 loss: 0.00399888074
Iter: 1175 loss: 0.00399835641
Iter: 1176 loss: 0.00399907725
Iter: 1177 loss: 0.00399809564
Iter: 1178 loss: 0.0039968146
Iter: 1179 loss: 0.00399420504
Iter: 1180 loss: 0.00404321169
Iter: 1181 loss: 0.00399416126
Iter: 1182 loss: 0.00399106
Iter: 1183 loss: 0.00400832342
Iter: 1184 loss: 0.00399062689
Iter: 1185 loss: 0.00398867298
Iter: 1186 loss: 0.0040191384
Iter: 1187 loss: 0.00398866739
Iter: 1188 loss: 0.00398682617
Iter: 1189 loss: 0.00398862502
Iter: 1190 loss: 0.00398578122
Iter: 1191 loss: 0.00398467481
Iter: 1192 loss: 0.00399262458
Iter: 1193 loss: 0.00398457702
Iter: 1194 loss: 0.00398325687
Iter: 1195 loss: 0.00399671914
Iter: 1196 loss: 0.00398322055
Iter: 1197 loss: 0.00398265896
Iter: 1198 loss: 0.00398669066
Iter: 1199 loss: 0.00398261193
Iter: 1200 loss: 0.00398223102
Iter: 1201 loss: 0.00398190506
Iter: 1202 loss: 0.00398180494
Iter: 1203 loss: 0.00398085779
Iter: 1204 loss: 0.00397882517
Iter: 1205 loss: 0.00401104055
Iter: 1206 loss: 0.00397875113
Iter: 1207 loss: 0.00397724891
Iter: 1208 loss: 0.00398547389
Iter: 1209 loss: 0.00397702958
Iter: 1210 loss: 0.00397452712
Iter: 1211 loss: 0.00397651736
Iter: 1212 loss: 0.00397301838
Iter: 1213 loss: 0.00397228356
Iter: 1214 loss: 0.00397187099
Iter: 1215 loss: 0.00397155
Iter: 1216 loss: 0.00397019694
Iter: 1217 loss: 0.00396763673
Iter: 1218 loss: 0.00402287254
Iter: 1219 loss: 0.00396762975
Iter: 1220 loss: 0.00396574847
Iter: 1221 loss: 0.00396798411
Iter: 1222 loss: 0.00396475941
Iter: 1223 loss: 0.003962046
Iter: 1224 loss: 0.00397937931
Iter: 1225 loss: 0.00396173913
Iter: 1226 loss: 0.0039601326
Iter: 1227 loss: 0.00397692388
Iter: 1228 loss: 0.00396009209
Iter: 1229 loss: 0.00395893957
Iter: 1230 loss: 0.00395893957
Iter: 1231 loss: 0.00395841617
Iter: 1232 loss: 0.00396006834
Iter: 1233 loss: 0.00395826809
Iter: 1234 loss: 0.00395792397
Iter: 1235 loss: 0.00395687111
Iter: 1236 loss: 0.00395923574
Iter: 1237 loss: 0.00395624898
Iter: 1238 loss: 0.00395497726
Iter: 1239 loss: 0.00396607164
Iter: 1240 loss: 0.00395491347
Iter: 1241 loss: 0.00395408692
Iter: 1242 loss: 0.0039529386
Iter: 1243 loss: 0.00395289203
Iter: 1244 loss: 0.00395384757
Iter: 1245 loss: 0.00395192113
Iter: 1246 loss: 0.00395151135
Iter: 1247 loss: 0.00395293813
Iter: 1248 loss: 0.00395140843
Iter: 1249 loss: 0.00395093672
Iter: 1250 loss: 0.00394965243
Iter: 1251 loss: 0.0039574597
Iter: 1252 loss: 0.00394931063
Iter: 1253 loss: 0.00394713599
Iter: 1254 loss: 0.00397977
Iter: 1255 loss: 0.00394713
Iter: 1256 loss: 0.00394625869
Iter: 1257 loss: 0.00394645426
Iter: 1258 loss: 0.00394561328
Iter: 1259 loss: 0.00394486543
Iter: 1260 loss: 0.00394828897
Iter: 1261 loss: 0.0039447248
Iter: 1262 loss: 0.00394411758
Iter: 1263 loss: 0.00394306332
Iter: 1264 loss: 0.00394305913
Iter: 1265 loss: 0.00394403934
Iter: 1266 loss: 0.00394271268
Iter: 1267 loss: 0.00394250639
Iter: 1268 loss: 0.00394195504
Iter: 1269 loss: 0.00394571433
Iter: 1270 loss: 0.00394182885
Iter: 1271 loss: 0.00394038204
Iter: 1272 loss: 0.00394312199
Iter: 1273 loss: 0.00393977
Iter: 1274 loss: 0.00393920485
Iter: 1275 loss: 0.00393913593
Iter: 1276 loss: 0.00393872755
Iter: 1277 loss: 0.00393824093
Iter: 1278 loss: 0.00393823581
Iter: 1279 loss: 0.00393779483
Iter: 1280 loss: 0.00393784931
Iter: 1281 loss: 0.00393746048
Iter: 1282 loss: 0.00393676572
Iter: 1283 loss: 0.00393569656
Iter: 1284 loss: 0.00393567793
Iter: 1285 loss: 0.00393411517
Iter: 1286 loss: 0.00393544231
Iter: 1287 loss: 0.00393320154
Iter: 1288 loss: 0.00393111
Iter: 1289 loss: 0.00394717744
Iter: 1290 loss: 0.00393093843
Iter: 1291 loss: 0.00393508514
Iter: 1292 loss: 0.00393007277
Iter: 1293 loss: 0.00392938592
Iter: 1294 loss: 0.0039311978
Iter: 1295 loss: 0.00392915029
Iter: 1296 loss: 0.0039286823
Iter: 1297 loss: 0.00392866833
Iter: 1298 loss: 0.00392794656
Iter: 1299 loss: 0.00392837357
Iter: 1300 loss: 0.00392746925
Iter: 1301 loss: 0.00392704736
Iter: 1302 loss: 0.00392573886
Iter: 1303 loss: 0.0039285603
Iter: 1304 loss: 0.00392494071
Iter: 1305 loss: 0.0039217649
Iter: 1306 loss: 0.00393131096
Iter: 1307 loss: 0.00392081123
Iter: 1308 loss: 0.00392093696
Iter: 1309 loss: 0.00391976349
Iter: 1310 loss: 0.00391912367
Iter: 1311 loss: 0.00392714189
Iter: 1312 loss: 0.00391911808
Iter: 1313 loss: 0.00391861191
Iter: 1314 loss: 0.00391861331
Iter: 1315 loss: 0.00391821284
Iter: 1316 loss: 0.00391763169
Iter: 1317 loss: 0.00391581841
Iter: 1318 loss: 0.00391822588
Iter: 1319 loss: 0.00391448941
Iter: 1320 loss: 0.00391265051
Iter: 1321 loss: 0.00391914602
Iter: 1322 loss: 0.00391215552
Iter: 1323 loss: 0.00391129404
Iter: 1324 loss: 0.00391011359
Iter: 1325 loss: 0.00391006097
Iter: 1326 loss: 0.00391100487
Iter: 1327 loss: 0.00390945561
Iter: 1328 loss: 0.0039091385
Iter: 1329 loss: 0.00390906
Iter: 1330 loss: 0.00390885118
Iter: 1331 loss: 0.00390845072
Iter: 1332 loss: 0.00390845258
Iter: 1333 loss: 0.00390821043
Iter: 1334 loss: 0.00390802603
Iter: 1335 loss: 0.00390794827
Iter: 1336 loss: 0.00390627701
Iter: 1337 loss: 0.00390866818
Iter: 1338 loss: 0.00390546606
Iter: 1339 loss: 0.0039046437
Iter: 1340 loss: 0.00390547491
Iter: 1341 loss: 0.00390417804
Iter: 1342 loss: 0.0039039012
Iter: 1343 loss: 0.00390355708
Iter: 1344 loss: 0.00390315382
Iter: 1345 loss: 0.00390284602
Iter: 1346 loss: 0.00390272448
Iter: 1347 loss: 0.00390177662
Iter: 1348 loss: 0.00390520226
Iter: 1349 loss: 0.00390153518
Iter: 1350 loss: 0.00390070141
Iter: 1351 loss: 0.00390081108
Iter: 1352 loss: 0.00390007021
Iter: 1353 loss: 0.00389941456
Iter: 1354 loss: 0.00389895984
Iter: 1355 loss: 0.00389872305
Iter: 1356 loss: 0.00389823876
Iter: 1357 loss: 0.00389755331
Iter: 1358 loss: 0.00389752956
Iter: 1359 loss: 0.00389654702
Iter: 1360 loss: 0.0038970944
Iter: 1361 loss: 0.00389590277
Iter: 1362 loss: 0.00389521453
Iter: 1363 loss: 0.0038952129
Iter: 1364 loss: 0.00389444595
Iter: 1365 loss: 0.00390135031
Iter: 1366 loss: 0.00389441056
Iter: 1367 loss: 0.00389416912
Iter: 1368 loss: 0.00389423594
Iter: 1369 loss: 0.00389399449
Iter: 1370 loss: 0.00389371812
Iter: 1371 loss: 0.00389347924
Iter: 1372 loss: 0.00389340799
Iter: 1373 loss: 0.00389270042
Iter: 1374 loss: 0.00389176933
Iter: 1375 loss: 0.00389171019
Iter: 1376 loss: 0.00389079493
Iter: 1377 loss: 0.0038907486
Iter: 1378 loss: 0.00389014161
Iter: 1379 loss: 0.00388931343
Iter: 1380 loss: 0.00388927083
Iter: 1381 loss: 0.00388805615
Iter: 1382 loss: 0.00389091205
Iter: 1383 loss: 0.00388760446
Iter: 1384 loss: 0.0038871367
Iter: 1385 loss: 0.00388711551
Iter: 1386 loss: 0.0038865197
Iter: 1387 loss: 0.00388837792
Iter: 1388 loss: 0.00388635788
Iter: 1389 loss: 0.00388594624
Iter: 1390 loss: 0.00388512202
Iter: 1391 loss: 0.00390060851
Iter: 1392 loss: 0.00388511177
Iter: 1393 loss: 0.00388397393
Iter: 1394 loss: 0.00388683565
Iter: 1395 loss: 0.00388358068
Iter: 1396 loss: 0.00388498744
Iter: 1397 loss: 0.0038832468
Iter: 1398 loss: 0.00388300791
Iter: 1399 loss: 0.00388298254
Iter: 1400 loss: 0.0038828114
Iter: 1401 loss: 0.00388239813
Iter: 1402 loss: 0.0038828298
Iter: 1403 loss: 0.00388217065
Iter: 1404 loss: 0.00388153084
Iter: 1405 loss: 0.00388236879
Iter: 1406 loss: 0.00388120511
Iter: 1407 loss: 0.00388058182
Iter: 1408 loss: 0.00388289336
Iter: 1409 loss: 0.00388042605
Iter: 1410 loss: 0.00387977
Iter: 1411 loss: 0.00387808774
Iter: 1412 loss: 0.00389260449
Iter: 1413 loss: 0.00387780368
Iter: 1414 loss: 0.003876128
Iter: 1415 loss: 0.00387620577
Iter: 1416 loss: 0.00387482066
Iter: 1417 loss: 0.00387318735
Iter: 1418 loss: 0.00389227178
Iter: 1419 loss: 0.00387315126
Iter: 1420 loss: 0.00387694081
Iter: 1421 loss: 0.00387281855
Iter: 1422 loss: 0.0038726565
Iter: 1423 loss: 0.00387212634
Iter: 1424 loss: 0.00387263251
Iter: 1425 loss: 0.0038716984
Iter: 1426 loss: 0.00387050188
Iter: 1427 loss: 0.00388064981
Iter: 1428 loss: 0.00387042621
Iter: 1429 loss: 0.00387691287
Iter: 1430 loss: 0.00387012679
Iter: 1431 loss: 0.00386990304
Iter: 1432 loss: 0.00387007976
Iter: 1433 loss: 0.00386976101
Iter: 1434 loss: 0.0038694297
Iter: 1435 loss: 0.0038687815
Iter: 1436 loss: 0.00388191408
Iter: 1437 loss: 0.00386877381
Iter: 1438 loss: 0.00386778195
Iter: 1439 loss: 0.00387025881
Iter: 1440 loss: 0.00386743504
Iter: 1441 loss: 0.00386678195
Iter: 1442 loss: 0.00386658218
Iter: 1443 loss: 0.00386608345
Iter: 1444 loss: 0.00387144648
Iter: 1445 loss: 0.00386606948
Iter: 1446 loss: 0.0038657249
Iter: 1447 loss: 0.00386495
Iter: 1448 loss: 0.00387656735
Iter: 1449 loss: 0.00386491604
Iter: 1450 loss: 0.00386401266
Iter: 1451 loss: 0.00386253372
Iter: 1452 loss: 0.00386252534
Iter: 1453 loss: 0.00386416633
Iter: 1454 loss: 0.00386208808
Iter: 1455 loss: 0.00386161543
Iter: 1456 loss: 0.00386117
Iter: 1457 loss: 0.0038610585
Iter: 1458 loss: 0.0038605812
Iter: 1459 loss: 0.0038598266
Iter: 1460 loss: 0.00385982
Iter: 1461 loss: 0.00385924638
Iter: 1462 loss: 0.00386450114
Iter: 1463 loss: 0.00385922589
Iter: 1464 loss: 0.00385897118
Iter: 1465 loss: 0.00386007829
Iter: 1466 loss: 0.00385891926
Iter: 1467 loss: 0.00385858421
Iter: 1468 loss: 0.00385877956
Iter: 1469 loss: 0.00385836395
Iter: 1470 loss: 0.00385792088
Iter: 1471 loss: 0.00385845941
Iter: 1472 loss: 0.00385768688
Iter: 1473 loss: 0.003857292
Iter: 1474 loss: 0.003862062
Iter: 1475 loss: 0.00385729107
Iter: 1476 loss: 0.00385703472
Iter: 1477 loss: 0.00385710178
Iter: 1478 loss: 0.00385684916
Iter: 1479 loss: 0.00385637861
Iter: 1480 loss: 0.00385755021
Iter: 1481 loss: 0.00385621074
Iter: 1482 loss: 0.00385592435
Iter: 1483 loss: 0.00385554135
Iter: 1484 loss: 0.00385552272
Iter: 1485 loss: 0.00385489478
Iter: 1486 loss: 0.0038551467
Iter: 1487 loss: 0.00385445426
Iter: 1488 loss: 0.00385538628
Iter: 1489 loss: 0.00385428034
Iter: 1490 loss: 0.0038541297
Iter: 1491 loss: 0.0038544382
Iter: 1492 loss: 0.00385407149
Iter: 1493 loss: 0.00385396322
Iter: 1494 loss: 0.00385490828
Iter: 1495 loss: 0.00385395717
Iter: 1496 loss: 0.00385384494
Iter: 1497 loss: 0.00385423983
Iter: 1498 loss: 0.00385381677
Iter: 1499 loss: 0.00385373482
Iter: 1500 loss: 0.00385352
Iter: 1501 loss: 0.00385500258
Iter: 1502 loss: 0.00385346729
Iter: 1503 loss: 0.003853095
Iter: 1504 loss: 0.00385272549
Iter: 1505 loss: 0.00385264773
Iter: 1506 loss: 0.00385203026
Iter: 1507 loss: 0.00385236228
Iter: 1508 loss: 0.00385163166
Iter: 1509 loss: 0.00385054876
Iter: 1510 loss: 0.00385669363
Iter: 1511 loss: 0.00385040557
Iter: 1512 loss: 0.00384988612
Iter: 1513 loss: 0.00385161629
Iter: 1514 loss: 0.00384974829
Iter: 1515 loss: 0.00384919392
Iter: 1516 loss: 0.00384859182
Iter: 1517 loss: 0.00384849939
Iter: 1518 loss: 0.00384799624
Iter: 1519 loss: 0.00384917716
Iter: 1520 loss: 0.00384780369
Iter: 1521 loss: 0.00384751055
Iter: 1522 loss: 0.00384709239
Iter: 1523 loss: 0.00384707819
Iter: 1524 loss: 0.00384753291
Iter: 1525 loss: 0.00384685956
Iter: 1526 loss: 0.00384675199
Iter: 1527 loss: 0.00384667935
Iter: 1528 loss: 0.00384663953
Iter: 1529 loss: 0.003846345
Iter: 1530 loss: 0.00384680461
Iter: 1531 loss: 0.00384620763
Iter: 1532 loss: 0.00384594733
Iter: 1533 loss: 0.00384766
Iter: 1534 loss: 0.0038459166
Iter: 1535 loss: 0.00384565
Iter: 1536 loss: 0.00384485046
Iter: 1537 loss: 0.00384703884
Iter: 1538 loss: 0.00384441251
Iter: 1539 loss: 0.00384371285
Iter: 1540 loss: 0.00384554779
Iter: 1541 loss: 0.00384347513
Iter: 1542 loss: 0.00384267955
Iter: 1543 loss: 0.00385051663
Iter: 1544 loss: 0.00384265278
Iter: 1545 loss: 0.00384223
Iter: 1546 loss: 0.00384502253
Iter: 1547 loss: 0.00384218246
Iter: 1548 loss: 0.00384194148
Iter: 1549 loss: 0.00384140899
Iter: 1550 loss: 0.00384895806
Iter: 1551 loss: 0.00384138338
Iter: 1552 loss: 0.0038404474
Iter: 1553 loss: 0.00384376477
Iter: 1554 loss: 0.00384020805
Iter: 1555 loss: 0.00383968954
Iter: 1556 loss: 0.00384761696
Iter: 1557 loss: 0.00383969303
Iter: 1558 loss: 0.00383962272
Iter: 1559 loss: 0.00383953098
Iter: 1560 loss: 0.00383937871
Iter: 1561 loss: 0.00383962179
Iter: 1562 loss: 0.00383930746
Iter: 1563 loss: 0.00383912935
Iter: 1564 loss: 0.003840141
Iter: 1565 loss: 0.00383910351
Iter: 1566 loss: 0.00383895449
Iter: 1567 loss: 0.003840002
Iter: 1568 loss: 0.00383894076
Iter: 1569 loss: 0.00383881526
Iter: 1570 loss: 0.0038385042
Iter: 1571 loss: 0.0038410686
Iter: 1572 loss: 0.00383844459
Iter: 1573 loss: 0.00383817218
Iter: 1574 loss: 0.00383859174
Iter: 1575 loss: 0.00383803924
Iter: 1576 loss: 0.00383775239
Iter: 1577 loss: 0.00383775332
Iter: 1578 loss: 0.00383756473
Iter: 1579 loss: 0.00383751839
Iter: 1580 loss: 0.00383740361
Iter: 1581 loss: 0.00383702572
Iter: 1582 loss: 0.00383646507
Iter: 1583 loss: 0.00383645017
Iter: 1584 loss: 0.00383586669
Iter: 1585 loss: 0.0038358653
Iter: 1586 loss: 0.0038355384
Iter: 1587 loss: 0.00383582432
Iter: 1588 loss: 0.00383534166
Iter: 1589 loss: 0.00383499684
Iter: 1590 loss: 0.00383648
Iter: 1591 loss: 0.00383492373
Iter: 1592 loss: 0.00383460755
Iter: 1593 loss: 0.00383459963
Iter: 1594 loss: 0.003834442
Iter: 1595 loss: 0.00383492978
Iter: 1596 loss: 0.003834398
Iter: 1597 loss: 0.00383425085
Iter: 1598 loss: 0.00383522338
Iter: 1599 loss: 0.00383423222
Iter: 1600 loss: 0.00383409183
Iter: 1601 loss: 0.00383376773
Iter: 1602 loss: 0.00383812329
Iter: 1603 loss: 0.0038337498
Iter: 1604 loss: 0.00383333932
Iter: 1605 loss: 0.00383351138
Iter: 1606 loss: 0.00383305456
Iter: 1607 loss: 0.00383278565
Iter: 1608 loss: 0.00383242057
Iter: 1609 loss: 0.00383240241
Iter: 1610 loss: 0.00383207458
Iter: 1611 loss: 0.00383604947
Iter: 1612 loss: 0.00383207
Iter: 1613 loss: 0.00383177749
Iter: 1614 loss: 0.00383283617
Iter: 1615 loss: 0.00383170834
Iter: 1616 loss: 0.00383154163
Iter: 1617 loss: 0.00383107224
Iter: 1618 loss: 0.00383327017
Iter: 1619 loss: 0.00383090414
Iter: 1620 loss: 0.00383025594
Iter: 1621 loss: 0.00383339636
Iter: 1622 loss: 0.0038301372
Iter: 1623 loss: 0.00382989319
Iter: 1624 loss: 0.00382986292
Iter: 1625 loss: 0.00382966502
Iter: 1626 loss: 0.0038326194
Iter: 1627 loss: 0.00382966315
Iter: 1628 loss: 0.00382945128
Iter: 1629 loss: 0.00382905733
Iter: 1630 loss: 0.00383776566
Iter: 1631 loss: 0.00382905127
Iter: 1632 loss: 0.0038289139
Iter: 1633 loss: 0.0038288869
Iter: 1634 loss: 0.00382867409
Iter: 1635 loss: 0.00382829132
Iter: 1636 loss: 0.00383718871
Iter: 1637 loss: 0.00382828689
Iter: 1638 loss: 0.00382807245
Iter: 1639 loss: 0.00382796256
Iter: 1640 loss: 0.00382785732
Iter: 1641 loss: 0.00382756698
Iter: 1642 loss: 0.00382754114
Iter: 1643 loss: 0.00382732693
Iter: 1644 loss: 0.00382717652
Iter: 1645 loss: 0.00382736558
Iter: 1646 loss: 0.00382710318
Iter: 1647 loss: 0.0038269111
Iter: 1648 loss: 0.00382962218
Iter: 1649 loss: 0.00382691529
Iter: 1650 loss: 0.00382675114
Iter: 1651 loss: 0.00382643309
Iter: 1652 loss: 0.00383306714
Iter: 1653 loss: 0.00382643053
Iter: 1654 loss: 0.0038260289
Iter: 1655 loss: 0.0038271239
Iter: 1656 loss: 0.00382589642
Iter: 1657 loss: 0.00382568361
Iter: 1658 loss: 0.00382815115
Iter: 1659 loss: 0.00382567872
Iter: 1660 loss: 0.00382551597
Iter: 1661 loss: 0.0038252864
Iter: 1662 loss: 0.00382527965
Iter: 1663 loss: 0.00382513274
Iter: 1664 loss: 0.0038251048
Iter: 1665 loss: 0.00382503355
Iter: 1666 loss: 0.0038250403
Iter: 1667 loss: 0.00382497744
Iter: 1668 loss: 0.00382482028
Iter: 1669 loss: 0.00382482423
Iter: 1670 loss: 0.00382469781
Iter: 1671 loss: 0.00382462027
Iter: 1672 loss: 0.00382443308
Iter: 1673 loss: 0.0038262629
Iter: 1674 loss: 0.00382441049
Iter: 1675 loss: 0.00382417161
Iter: 1676 loss: 0.00382389827
Iter: 1677 loss: 0.00382386311
Iter: 1678 loss: 0.00382379536
Iter: 1679 loss: 0.00382370595
Iter: 1680 loss: 0.00382362725
Iter: 1681 loss: 0.00382362469
Iter: 1682 loss: 0.00382356578
Iter: 1683 loss: 0.00382333319
Iter: 1684 loss: 0.00382340746
Iter: 1685 loss: 0.00382317277
Iter: 1686 loss: 0.00382328616
Iter: 1687 loss: 0.00382304355
Iter: 1688 loss: 0.00382294133
Iter: 1689 loss: 0.00382278766
Iter: 1690 loss: 0.00382278697
Iter: 1691 loss: 0.00382269151
Iter: 1692 loss: 0.00382267823
Iter: 1693 loss: 0.00382261327
Iter: 1694 loss: 0.0038224759
Iter: 1695 loss: 0.00382226193
Iter: 1696 loss: 0.00382225704
Iter: 1697 loss: 0.00382181699
Iter: 1698 loss: 0.0038266487
Iter: 1699 loss: 0.00382180908
Iter: 1700 loss: 0.00382159417
Iter: 1701 loss: 0.00382291549
Iter: 1702 loss: 0.00382156763
Iter: 1703 loss: 0.00382147962
Iter: 1704 loss: 0.00382130733
Iter: 1705 loss: 0.00382518419
Iter: 1706 loss: 0.00382130709
Iter: 1707 loss: 0.00382112036
Iter: 1708 loss: 0.00382123073
Iter: 1709 loss: 0.00382100604
Iter: 1710 loss: 0.00382077531
Iter: 1711 loss: 0.0038218582
Iter: 1712 loss: 0.00382073969
Iter: 1713 loss: 0.00382049032
Iter: 1714 loss: 0.00382115273
Iter: 1715 loss: 0.00382040581
Iter: 1716 loss: 0.00382021023
Iter: 1717 loss: 0.00381973572
Iter: 1718 loss: 0.00382492039
Iter: 1719 loss: 0.00381968915
Iter: 1720 loss: 0.00381935947
Iter: 1721 loss: 0.00381935923
Iter: 1722 loss: 0.00381912058
Iter: 1723 loss: 0.00381957646
Iter: 1724 loss: 0.0038190207
Iter: 1725 loss: 0.00381879322
Iter: 1726 loss: 0.00381849101
Iter: 1727 loss: 0.0038184796
Iter: 1728 loss: 0.00381825329
Iter: 1729 loss: 0.00381822931
Iter: 1730 loss: 0.00381809194
Iter: 1731 loss: 0.00381784583
Iter: 1732 loss: 0.00381784886
Iter: 1733 loss: 0.00381778041
Iter: 1734 loss: 0.0038177385
Iter: 1735 loss: 0.00381763838
Iter: 1736 loss: 0.00381810963
Iter: 1737 loss: 0.00381761836
Iter: 1738 loss: 0.00381755736
Iter: 1739 loss: 0.00381750241
Iter: 1740 loss: 0.00381748099
Iter: 1741 loss: 0.00381730683
Iter: 1742 loss: 0.00381691242
Iter: 1743 loss: 0.003822339
Iter: 1744 loss: 0.00381688843
Iter: 1745 loss: 0.00381664047
Iter: 1746 loss: 0.0038174605
Iter: 1747 loss: 0.00381657341
Iter: 1748 loss: 0.00381623232
Iter: 1749 loss: 0.00381677574
Iter: 1750 loss: 0.00381607702
Iter: 1751 loss: 0.00381582323
Iter: 1752 loss: 0.00381581439
Iter: 1753 loss: 0.00381558319
Iter: 1754 loss: 0.00381615269
Iter: 1755 loss: 0.00381549401
Iter: 1756 loss: 0.00381532637
Iter: 1757 loss: 0.00381495128
Iter: 1758 loss: 0.00382007123
Iter: 1759 loss: 0.00381492404
Iter: 1760 loss: 0.00381454336
Iter: 1761 loss: 0.00381947495
Iter: 1762 loss: 0.00381454406
Iter: 1763 loss: 0.00381442439
Iter: 1764 loss: 0.00381442439
Iter: 1765 loss: 0.00381432706
Iter: 1766 loss: 0.0038141706
Iter: 1767 loss: 0.00381443021
Iter: 1768 loss: 0.00381409796
Iter: 1769 loss: 0.0038138309
Iter: 1770 loss: 0.00381518435
Iter: 1771 loss: 0.00381379249
Iter: 1772 loss: 0.00381370215
Iter: 1773 loss: 0.00381346652
Iter: 1774 loss: 0.00381514826
Iter: 1775 loss: 0.00381341763
Iter: 1776 loss: 0.00381332124
Iter: 1777 loss: 0.00381328887
Iter: 1778 loss: 0.00381322578
Iter: 1779 loss: 0.00381316873
Iter: 1780 loss: 0.00381315057
Iter: 1781 loss: 0.00381300412
Iter: 1782 loss: 0.00381274102
Iter: 1783 loss: 0.00381274149
Iter: 1784 loss: 0.00381256407
Iter: 1785 loss: 0.0038127969
Iter: 1786 loss: 0.00381247699
Iter: 1787 loss: 0.00381234917
Iter: 1788 loss: 0.00381234661
Iter: 1789 loss: 0.00381225208
Iter: 1790 loss: 0.00381209794
Iter: 1791 loss: 0.00381209748
Iter: 1792 loss: 0.00381188723
Iter: 1793 loss: 0.00381165417
Iter: 1794 loss: 0.00381161924
Iter: 1795 loss: 0.00381118711
Iter: 1796 loss: 0.00381355383
Iter: 1797 loss: 0.00381111749
Iter: 1798 loss: 0.00381092564
Iter: 1799 loss: 0.00381198153
Iter: 1800 loss: 0.003810897
Iter: 1801 loss: 0.00381069
Iter: 1802 loss: 0.00381201552
Iter: 1803 loss: 0.00381066371
Iter: 1804 loss: 0.00381056638
Iter: 1805 loss: 0.00381034892
Iter: 1806 loss: 0.00381318247
Iter: 1807 loss: 0.00381033728
Iter: 1808 loss: 0.00381018221
Iter: 1809 loss: 0.00381064741
Iter: 1810 loss: 0.00381013565
Iter: 1811 loss: 0.00381001551
Iter: 1812 loss: 0.00381161552
Iter: 1813 loss: 0.00381001085
Iter: 1814 loss: 0.00380993378
Iter: 1815 loss: 0.0038098339
Iter: 1816 loss: 0.00380983064
Iter: 1817 loss: 0.00380965322
Iter: 1818 loss: 0.00380958966
Iter: 1819 loss: 0.00380949466
Iter: 1820 loss: 0.00380923669
Iter: 1821 loss: 0.0038099098
Iter: 1822 loss: 0.00380915124
Iter: 1823 loss: 0.003809
Iter: 1824 loss: 0.00380904553
Iter: 1825 loss: 0.00380888698
Iter: 1826 loss: 0.00380876195
Iter: 1827 loss: 0.00380876404
Iter: 1828 loss: 0.00380866555
Iter: 1829 loss: 0.00380852958
Iter: 1830 loss: 0.00380889955
Iter: 1831 loss: 0.00380848558
Iter: 1832 loss: 0.0038083843
Iter: 1833 loss: 0.00380848441
Iter: 1834 loss: 0.00380832609
Iter: 1835 loss: 0.00380814774
Iter: 1836 loss: 0.00380911189
Iter: 1837 loss: 0.00380812609
Iter: 1838 loss: 0.00380806415
Iter: 1839 loss: 0.00380792236
Iter: 1840 loss: 0.00380943948
Iter: 1841 loss: 0.00380790373
Iter: 1842 loss: 0.00380771398
Iter: 1843 loss: 0.0038083063
Iter: 1844 loss: 0.00380766019
Iter: 1845 loss: 0.00380753702
Iter: 1846 loss: 0.00380752655
Iter: 1847 loss: 0.00380742364
Iter: 1848 loss: 0.00380725297
Iter: 1849 loss: 0.00381162646
Iter: 1850 loss: 0.00380725204
Iter: 1851 loss: 0.00380712165
Iter: 1852 loss: 0.00380796846
Iter: 1853 loss: 0.0038071028
Iter: 1854 loss: 0.0038069794
Iter: 1855 loss: 0.00380817032
Iter: 1856 loss: 0.00380697194
Iter: 1857 loss: 0.00380690582
Iter: 1858 loss: 0.00380673283
Iter: 1859 loss: 0.00380827207
Iter: 1860 loss: 0.00380670768
Iter: 1861 loss: 0.00380649581
Iter: 1862 loss: 0.00380856125
Iter: 1863 loss: 0.00380648463
Iter: 1864 loss: 0.0038063922
Iter: 1865 loss: 0.00380632933
Iter: 1866 loss: 0.00380629068
Iter: 1867 loss: 0.00380604574
Iter: 1868 loss: 0.00380598567
Iter: 1869 loss: 0.00380583177
Iter: 1870 loss: 0.00380635494
Iter: 1871 loss: 0.00380574306
Iter: 1872 loss: 0.00380569673
Iter: 1873 loss: 0.00380553468
Iter: 1874 loss: 0.00380563969
Iter: 1875 loss: 0.0038054015
Iter: 1876 loss: 0.00380515913
Iter: 1877 loss: 0.00380546739
Iter: 1878 loss: 0.00380503363
Iter: 1879 loss: 0.00380488951
Iter: 1880 loss: 0.00380479731
Iter: 1881 loss: 0.00380474422
Iter: 1882 loss: 0.0038044604
Iter: 1883 loss: 0.00380526949
Iter: 1884 loss: 0.00380437239
Iter: 1885 loss: 0.00380418496
Iter: 1886 loss: 0.00380375539
Iter: 1887 loss: 0.00380898779
Iter: 1888 loss: 0.00380371767
Iter: 1889 loss: 0.00380446343
Iter: 1890 loss: 0.00380358123
Iter: 1891 loss: 0.00380345201
Iter: 1892 loss: 0.00380329788
Iter: 1893 loss: 0.00380328065
Iter: 1894 loss: 0.00380311208
Iter: 1895 loss: 0.00380319287
Iter: 1896 loss: 0.00380300148
Iter: 1897 loss: 0.00380277657
Iter: 1898 loss: 0.00380273303
Iter: 1899 loss: 0.00380258588
Iter: 1900 loss: 0.00380257284
Iter: 1901 loss: 0.00380238798
Iter: 1902 loss: 0.00380230159
Iter: 1903 loss: 0.00380292558
Iter: 1904 loss: 0.0038022974
Iter: 1905 loss: 0.00380223338
Iter: 1906 loss: 0.00380209484
Iter: 1907 loss: 0.00380446925
Iter: 1908 loss: 0.00380209181
Iter: 1909 loss: 0.00380194234
Iter: 1910 loss: 0.0038020534
Iter: 1911 loss: 0.00380185619
Iter: 1912 loss: 0.0038017896
Iter: 1913 loss: 0.00380164082
Iter: 1914 loss: 0.00380349928
Iter: 1915 loss: 0.00380162452
Iter: 1916 loss: 0.00380141288
Iter: 1917 loss: 0.00380221941
Iter: 1918 loss: 0.00380136375
Iter: 1919 loss: 0.00380113744
Iter: 1920 loss: 0.00380125735
Iter: 1921 loss: 0.00380098843
Iter: 1922 loss: 0.00380072766
Iter: 1923 loss: 0.00380118797
Iter: 1924 loss: 0.00380061055
Iter: 1925 loss: 0.00380036328
Iter: 1926 loss: 0.00380165176
Iter: 1927 loss: 0.00380032416
Iter: 1928 loss: 0.0038001854
Iter: 1929 loss: 0.00380138913
Iter: 1930 loss: 0.00380017189
Iter: 1931 loss: 0.00380002591
Iter: 1932 loss: 0.0037996748
Iter: 1933 loss: 0.00380381965
Iter: 1934 loss: 0.00379964523
Iter: 1935 loss: 0.00379932881
Iter: 1936 loss: 0.00380345806
Iter: 1937 loss: 0.00379932649
Iter: 1938 loss: 0.00379982335
Iter: 1939 loss: 0.0037992713
Iter: 1940 loss: 0.00379923172
Iter: 1941 loss: 0.00379914371
Iter: 1942 loss: 0.00380005315
Iter: 1943 loss: 0.00379913254
Iter: 1944 loss: 0.00379904057
Iter: 1945 loss: 0.00379913952
Iter: 1946 loss: 0.00379899307
Iter: 1947 loss: 0.00379883405
Iter: 1948 loss: 0.00379949692
Iter: 1949 loss: 0.00379879749
Iter: 1950 loss: 0.00379872089
Iter: 1951 loss: 0.0037986564
Iter: 1952 loss: 0.00379863521
Iter: 1953 loss: 0.00379849272
Iter: 1954 loss: 0.00379826059
Iter: 1955 loss: 0.00379825803
Iter: 1956 loss: 0.00379798701
Iter: 1957 loss: 0.00379860541
Iter: 1958 loss: 0.00379788061
Iter: 1959 loss: 0.00379773811
Iter: 1960 loss: 0.00379917864
Iter: 1961 loss: 0.00379773485
Iter: 1962 loss: 0.00379765593
Iter: 1963 loss: 0.00379748596
Iter: 1964 loss: 0.00380001822
Iter: 1965 loss: 0.00379747944
Iter: 1966 loss: 0.00379748829
Iter: 1967 loss: 0.00379739702
Iter: 1968 loss: 0.00379732368
Iter: 1969 loss: 0.00379725406
Iter: 1970 loss: 0.00379723986
Iter: 1971 loss: 0.00379713881
Iter: 1972 loss: 0.00379824685
Iter: 1973 loss: 0.00379713601
Iter: 1974 loss: 0.00379709154
Iter: 1975 loss: 0.00379709527
Iter: 1976 loss: 0.00379705871
Iter: 1977 loss: 0.00379698072
Iter: 1978 loss: 0.00379689201
Iter: 1979 loss: 0.0037968813
Iter: 1980 loss: 0.00379678514
Iter: 1981 loss: 0.00379819539
Iter: 1982 loss: 0.00379678514
Iter: 1983 loss: 0.00379672414
Iter: 1984 loss: 0.0037967558
Iter: 1985 loss: 0.0037966813
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8
+ date
Tue Oct 27 17:40:57 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e419ec510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e83727400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e83727e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e83727840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e419401e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e41940d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e1c099f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e1c06a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e1c06a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e0009d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e000789d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e00022840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e00022ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7e00046d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da87d3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da87d3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da87946a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8794510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8743a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8714f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da87258c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da86c4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da86a16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8648620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8649620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da86611e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da862f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da85dd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da85e60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da85e69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da85e6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8565158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da85667b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8566f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da8509a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7da84e2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0960000381
Iter: 2 loss: 6479.33594
Iter: 3 loss: 0.0865705311
Iter: 4 loss: 0.0690406561
Iter: 5 loss: 0.0597552657
Iter: 6 loss: 0.0594975576
Iter: 7 loss: 0.0578036159
Iter: 8 loss: 0.0516858362
Iter: 9 loss: 60.7657623
Iter: 10 loss: 0.0516854674
Iter: 11 loss: 854.678
Iter: 12 loss: 278.365173
Iter: 13 loss: 0.051685445
Iter: 14 loss: 0.0427118465
Iter: 15 loss: 0.0427118503
Iter: 16 loss: 0.0393857881
Iter: 17 loss: 0.0427059531
Iter: 18 loss: 0.039710056
Iter: 19 loss: 0.0404405035
Iter: 20 loss: 0.0368054211
Iter: 21 loss: 0.034054473
Iter: 22 loss: 0.0716583505
Iter: 23 loss: 0.0339805074
Iter: 24 loss: 0.0329112522
Iter: 25 loss: 0.0318998247
Iter: 26 loss: 0.0305231214
Iter: 27 loss: 0.0341649316
Iter: 28 loss: 0.0299686901
Iter: 29 loss: 0.0273563974
Iter: 30 loss: 0.0271146409
Iter: 31 loss: 0.0258560404
Iter: 32 loss: 0.0245866627
Iter: 33 loss: 0.0241485238
Iter: 34 loss: 0.0232628062
Iter: 35 loss: 0.0215654969
Iter: 36 loss: 0.0220512114
Iter: 37 loss: 0.0203705337
Iter: 38 loss: 0.0176878907
Iter: 39 loss: 0.0285307691
Iter: 40 loss: 0.0174403396
Iter: 41 loss: 0.0159956701
Iter: 42 loss: 0.0196242481
Iter: 43 loss: 0.0154354721
Iter: 44 loss: 0.014399495
Iter: 45 loss: 0.0178350769
Iter: 46 loss: 0.0139933666
Iter: 47 loss: 0.0126284566
Iter: 48 loss: 0.0222327076
Iter: 49 loss: 0.012500043
Iter: 50 loss: 0.011787856
Iter: 51 loss: 0.0157296509
Iter: 52 loss: 0.0116537372
Iter: 53 loss: 0.0110442871
Iter: 54 loss: 0.0105119981
Iter: 55 loss: 0.0103477472
Iter: 56 loss: 0.00958905742
Iter: 57 loss: 0.0146376453
Iter: 58 loss: 0.00954525918
Iter: 59 loss: 0.00936215185
Iter: 60 loss: 0.00915417075
Iter: 61 loss: 0.00905027
Iter: 62 loss: 0.00885559805
Iter: 63 loss: 0.0086467471
Iter: 64 loss: 0.00859543681
Iter: 65 loss: 0.00846309308
Iter: 66 loss: 0.00783080887
Iter: 67 loss: 0.0110037616
Iter: 68 loss: 0.00772518059
Iter: 69 loss: 0.00741811562
Iter: 70 loss: 0.00749872345
Iter: 71 loss: 0.00718997512
Iter: 72 loss: 0.0068775434
Iter: 73 loss: 0.00750040775
Iter: 74 loss: 0.00674501108
Iter: 75 loss: 0.00645984244
Iter: 76 loss: 0.0089546442
Iter: 77 loss: 0.00644877087
Iter: 78 loss: 0.00623085629
Iter: 79 loss: 0.00816889759
Iter: 80 loss: 0.0062099155
Iter: 81 loss: 0.00612368807
Iter: 82 loss: 0.00617455924
Iter: 83 loss: 0.00606882
Iter: 84 loss: 0.00584512111
Iter: 85 loss: 0.00674913451
Iter: 86 loss: 0.00579219963
Iter: 87 loss: 0.00566024426
Iter: 88 loss: 0.00671748165
Iter: 89 loss: 0.00565484865
Iter: 90 loss: 0.0055563231
Iter: 91 loss: 0.00566016138
Iter: 92 loss: 0.00550042605
Iter: 93 loss: 0.00542370137
Iter: 94 loss: 0.00625671633
Iter: 95 loss: 0.00542297401
Iter: 96 loss: 0.00537494197
Iter: 97 loss: 0.0053902017
Iter: 98 loss: 0.00533978269
Iter: 99 loss: 0.00526490435
Iter: 100 loss: 0.00523768831
Iter: 101 loss: 0.00519684842
Iter: 102 loss: 0.00509912381
Iter: 103 loss: 0.00577756437
Iter: 104 loss: 0.00508927833
Iter: 105 loss: 0.00503765326
Iter: 106 loss: 0.00528130447
Iter: 107 loss: 0.00502724759
Iter: 108 loss: 0.00499735354
Iter: 109 loss: 0.00492947502
Iter: 110 loss: 0.00587694719
Iter: 111 loss: 0.00492536929
Iter: 112 loss: 0.00487992633
Iter: 113 loss: 0.0054391576
Iter: 114 loss: 0.00487910118
Iter: 115 loss: 0.00483362516
Iter: 116 loss: 0.00498662284
Iter: 117 loss: 0.00482223928
Iter: 118 loss: 0.00479407422
Iter: 119 loss: 0.00477419794
Iter: 120 loss: 0.0047640386
Iter: 121 loss: 0.00472109951
Iter: 122 loss: 0.00475631095
Iter: 123 loss: 0.00469566789
Iter: 124 loss: 0.00464591291
Iter: 125 loss: 0.00507247262
Iter: 126 loss: 0.00464325957
Iter: 127 loss: 0.00461566169
Iter: 128 loss: 0.00458471384
Iter: 129 loss: 0.00458032638
Iter: 130 loss: 0.00453550555
Iter: 131 loss: 0.00456489623
Iter: 132 loss: 0.00450693257
Iter: 133 loss: 0.00453909812
Iter: 134 loss: 0.00448999926
Iter: 135 loss: 0.00447189901
Iter: 136 loss: 0.00450028619
Iter: 137 loss: 0.00446306914
Iter: 138 loss: 0.00445417687
Iter: 139 loss: 0.0044474341
Iter: 140 loss: 0.00444459962
Iter: 141 loss: 0.00442923512
Iter: 142 loss: 0.00444872305
Iter: 143 loss: 0.00442107581
Iter: 144 loss: 0.00440911669
Iter: 145 loss: 0.00454133144
Iter: 146 loss: 0.00440886803
Iter: 147 loss: 0.00439647958
Iter: 148 loss: 0.00450325
Iter: 149 loss: 0.00439574
Iter: 150 loss: 0.00438551512
Iter: 151 loss: 0.00439265603
Iter: 152 loss: 0.0043792529
Iter: 153 loss: 0.00436686212
Iter: 154 loss: 0.00435534026
Iter: 155 loss: 0.00435245689
Iter: 156 loss: 0.00433402229
Iter: 157 loss: 0.00443490129
Iter: 158 loss: 0.004331287
Iter: 159 loss: 0.00431540655
Iter: 160 loss: 0.00429692725
Iter: 161 loss: 0.00429481175
Iter: 162 loss: 0.00426948
Iter: 163 loss: 0.00438247435
Iter: 164 loss: 0.00426459778
Iter: 165 loss: 0.00425862428
Iter: 166 loss: 0.00425435137
Iter: 167 loss: 0.00424549
Iter: 168 loss: 0.00434900355
Iter: 169 loss: 0.00424539577
Iter: 170 loss: 0.00424075406
Iter: 171 loss: 0.00424831919
Iter: 172 loss: 0.00423859432
Iter: 173 loss: 0.00423359405
Iter: 174 loss: 0.00423894171
Iter: 175 loss: 0.0042308867
Iter: 176 loss: 0.00422506686
Iter: 177 loss: 0.00421573268
Iter: 178 loss: 0.00421565585
Iter: 179 loss: 0.00420475518
Iter: 180 loss: 0.00428114831
Iter: 181 loss: 0.004203788
Iter: 182 loss: 0.00419440959
Iter: 183 loss: 0.00419277744
Iter: 184 loss: 0.0041863583
Iter: 185 loss: 0.00417429628
Iter: 186 loss: 0.00423406623
Iter: 187 loss: 0.00417222641
Iter: 188 loss: 0.00416346081
Iter: 189 loss: 0.00417489652
Iter: 190 loss: 0.00415901095
Iter: 191 loss: 0.00415044278
Iter: 192 loss: 0.00423049135
Iter: 193 loss: 0.00415009866
Iter: 194 loss: 0.0041433638
Iter: 195 loss: 0.0041322615
Iter: 196 loss: 0.00413221307
Iter: 197 loss: 0.00412515784
Iter: 198 loss: 0.0041249413
Iter: 199 loss: 0.00411955174
Iter: 200 loss: 0.00418121554
Iter: 201 loss: 0.0041194777
Iter: 202 loss: 0.00411426229
Iter: 203 loss: 0.00411750516
Iter: 204 loss: 0.00411086669
Iter: 205 loss: 0.00410356838
Iter: 206 loss: 0.00413376279
Iter: 207 loss: 0.00410207175
Iter: 208 loss: 0.0040974319
Iter: 209 loss: 0.00409535691
Iter: 210 loss: 0.00409299228
Iter: 211 loss: 0.00408779923
Iter: 212 loss: 0.00410809834
Iter: 213 loss: 0.00408660248
Iter: 214 loss: 0.00408126507
Iter: 215 loss: 0.00409567915
Iter: 216 loss: 0.00407948857
Iter: 217 loss: 0.00407548202
Iter: 218 loss: 0.00407815352
Iter: 219 loss: 0.00407296699
Iter: 220 loss: 0.00406776741
Iter: 221 loss: 0.00408066297
Iter: 222 loss: 0.00406592619
Iter: 223 loss: 0.00406125234
Iter: 224 loss: 0.00407285
Iter: 225 loss: 0.00405961461
Iter: 226 loss: 0.00405482668
Iter: 227 loss: 0.00407083426
Iter: 228 loss: 0.00405351818
Iter: 229 loss: 0.00405016495
Iter: 230 loss: 0.00409676787
Iter: 231 loss: 0.00405015098
Iter: 232 loss: 0.00404757
Iter: 233 loss: 0.00405991077
Iter: 234 loss: 0.00404711487
Iter: 235 loss: 0.0040443684
Iter: 236 loss: 0.00404563453
Iter: 237 loss: 0.00404248247
Iter: 238 loss: 0.00403953623
Iter: 239 loss: 0.00403953064
Iter: 240 loss: 0.00403801445
Iter: 241 loss: 0.00403622631
Iter: 242 loss: 0.00403603166
Iter: 243 loss: 0.00403351802
Iter: 244 loss: 0.00404038839
Iter: 245 loss: 0.00403270591
Iter: 246 loss: 0.00403033104
Iter: 247 loss: 0.00403153617
Iter: 248 loss: 0.00402874313
Iter: 249 loss: 0.00402535126
Iter: 250 loss: 0.00402303319
Iter: 251 loss: 0.0040218
Iter: 252 loss: 0.00401509274
Iter: 253 loss: 0.0040235566
Iter: 254 loss: 0.00401164079
Iter: 255 loss: 0.00400445564
Iter: 256 loss: 0.0040200958
Iter: 257 loss: 0.00400169473
Iter: 258 loss: 0.00399515
Iter: 259 loss: 0.00403136062
Iter: 260 loss: 0.00399420783
Iter: 261 loss: 0.00399089372
Iter: 262 loss: 0.00399084901
Iter: 263 loss: 0.0039881859
Iter: 264 loss: 0.00399627443
Iter: 265 loss: 0.00398740126
Iter: 266 loss: 0.00398440752
Iter: 267 loss: 0.00398692535
Iter: 268 loss: 0.00398259796
Iter: 269 loss: 0.00398048386
Iter: 270 loss: 0.00398041215
Iter: 271 loss: 0.00397914648
Iter: 272 loss: 0.00397749571
Iter: 273 loss: 0.00397738628
Iter: 274 loss: 0.00397502212
Iter: 275 loss: 0.00398068456
Iter: 276 loss: 0.00397417089
Iter: 277 loss: 0.0039719278
Iter: 278 loss: 0.00397185655
Iter: 279 loss: 0.00397010753
Iter: 280 loss: 0.00396635802
Iter: 281 loss: 0.00397157
Iter: 282 loss: 0.00396451354
Iter: 283 loss: 0.00396050466
Iter: 284 loss: 0.00397305
Iter: 285 loss: 0.00395933958
Iter: 286 loss: 0.00395553745
Iter: 287 loss: 0.00396641437
Iter: 288 loss: 0.00395433698
Iter: 289 loss: 0.00395132415
Iter: 290 loss: 0.0039622169
Iter: 291 loss: 0.00395055767
Iter: 292 loss: 0.00394848268
Iter: 293 loss: 0.00397629105
Iter: 294 loss: 0.00394846592
Iter: 295 loss: 0.00394681748
Iter: 296 loss: 0.00395556632
Iter: 297 loss: 0.00394657161
Iter: 298 loss: 0.00394502236
Iter: 299 loss: 0.0039449269
Iter: 300 loss: 0.00394374738
Iter: 301 loss: 0.00394218881
Iter: 302 loss: 0.00394214
Iter: 303 loss: 0.00394099578
Iter: 304 loss: 0.00393947959
Iter: 305 loss: 0.00393938553
Iter: 306 loss: 0.00393692916
Iter: 307 loss: 0.0039403392
Iter: 308 loss: 0.00393571798
Iter: 309 loss: 0.0039330041
Iter: 310 loss: 0.00392950047
Iter: 311 loss: 0.00392926
Iter: 312 loss: 0.00392305385
Iter: 313 loss: 0.00395261636
Iter: 314 loss: 0.0039219521
Iter: 315 loss: 0.00391792087
Iter: 316 loss: 0.00392366853
Iter: 317 loss: 0.00391594972
Iter: 318 loss: 0.00391188916
Iter: 319 loss: 0.0039370656
Iter: 320 loss: 0.00391141744
Iter: 321 loss: 0.00390863931
Iter: 322 loss: 0.00391403958
Iter: 323 loss: 0.003907484
Iter: 324 loss: 0.00390530284
Iter: 325 loss: 0.00393023202
Iter: 326 loss: 0.00390526
Iter: 327 loss: 0.0039033629
Iter: 328 loss: 0.00391209545
Iter: 329 loss: 0.00390301319
Iter: 330 loss: 0.00390118314
Iter: 331 loss: 0.00390142831
Iter: 332 loss: 0.00389978848
Iter: 333 loss: 0.00389830163
Iter: 334 loss: 0.00389815704
Iter: 335 loss: 0.0038969405
Iter: 336 loss: 0.00389661267
Iter: 337 loss: 0.00389585528
Iter: 338 loss: 0.00389418891
Iter: 339 loss: 0.00389699172
Iter: 340 loss: 0.00389344245
Iter: 341 loss: 0.00389196258
Iter: 342 loss: 0.00389030227
Iter: 343 loss: 0.00389008038
Iter: 344 loss: 0.00388753088
Iter: 345 loss: 0.00390861835
Iter: 346 loss: 0.00388737535
Iter: 347 loss: 0.00388572272
Iter: 348 loss: 0.00388591737
Iter: 349 loss: 0.00388445961
Iter: 350 loss: 0.00388235203
Iter: 351 loss: 0.00389577611
Iter: 352 loss: 0.00388211943
Iter: 353 loss: 0.00388017436
Iter: 354 loss: 0.00388025772
Iter: 355 loss: 0.00387863978
Iter: 356 loss: 0.00387645
Iter: 357 loss: 0.00390675571
Iter: 358 loss: 0.00387644162
Iter: 359 loss: 0.00387458643
Iter: 360 loss: 0.00388670759
Iter: 361 loss: 0.0038743983
Iter: 362 loss: 0.00387299201
Iter: 363 loss: 0.00387447351
Iter: 364 loss: 0.00387221552
Iter: 365 loss: 0.00387122435
Iter: 366 loss: 0.00387114799
Iter: 367 loss: 0.00387024647
Iter: 368 loss: 0.00387110258
Iter: 369 loss: 0.00386972609
Iter: 370 loss: 0.00386874704
Iter: 371 loss: 0.00386889465
Iter: 372 loss: 0.00386800757
Iter: 373 loss: 0.00386670791
Iter: 374 loss: 0.00386531255
Iter: 375 loss: 0.0038650881
Iter: 376 loss: 0.00386306806
Iter: 377 loss: 0.0038789839
Iter: 378 loss: 0.00386292837
Iter: 379 loss: 0.00386122661
Iter: 380 loss: 0.00386026781
Iter: 381 loss: 0.00385952787
Iter: 382 loss: 0.00385706383
Iter: 383 loss: 0.00388146751
Iter: 384 loss: 0.00385698327
Iter: 385 loss: 0.00385517906
Iter: 386 loss: 0.00385722774
Iter: 387 loss: 0.00385420676
Iter: 388 loss: 0.00385272014
Iter: 389 loss: 0.00387055241
Iter: 390 loss: 0.00385269918
Iter: 391 loss: 0.00385137228
Iter: 392 loss: 0.00386150042
Iter: 393 loss: 0.00385127822
Iter: 394 loss: 0.0038504051
Iter: 395 loss: 0.00384971825
Iter: 396 loss: 0.00384945
Iter: 397 loss: 0.0038485988
Iter: 398 loss: 0.00384855596
Iter: 399 loss: 0.0038477676
Iter: 400 loss: 0.00385014527
Iter: 401 loss: 0.00384752941
Iter: 402 loss: 0.00384689635
Iter: 403 loss: 0.00384624489
Iter: 404 loss: 0.00384612498
Iter: 405 loss: 0.00384497433
Iter: 406 loss: 0.00384470774
Iter: 407 loss: 0.00384397199
Iter: 408 loss: 0.00384254125
Iter: 409 loss: 0.00384968892
Iter: 410 loss: 0.00384229561
Iter: 411 loss: 0.00384082156
Iter: 412 loss: 0.00384171959
Iter: 413 loss: 0.00383987022
Iter: 414 loss: 0.0038383808
Iter: 415 loss: 0.00384791638
Iter: 416 loss: 0.00383821595
Iter: 417 loss: 0.00383674819
Iter: 418 loss: 0.00383725297
Iter: 419 loss: 0.00383571093
Iter: 420 loss: 0.00383388484
Iter: 421 loss: 0.00384131866
Iter: 422 loss: 0.00383347971
Iter: 423 loss: 0.0038324669
Iter: 424 loss: 0.00383232627
Iter: 425 loss: 0.00383165665
Iter: 426 loss: 0.00383089529
Iter: 427 loss: 0.00383079657
Iter: 428 loss: 0.00382999796
Iter: 429 loss: 0.00384246348
Iter: 430 loss: 0.0038299968
Iter: 431 loss: 0.00382933696
Iter: 432 loss: 0.0038338108
Iter: 433 loss: 0.00382927153
Iter: 434 loss: 0.00382886943
Iter: 435 loss: 0.00382806733
Iter: 436 loss: 0.00384333846
Iter: 437 loss: 0.00382806058
Iter: 438 loss: 0.003827048
Iter: 439 loss: 0.00382912788
Iter: 440 loss: 0.00382664404
Iter: 441 loss: 0.00382576929
Iter: 442 loss: 0.0038265395
Iter: 443 loss: 0.0038252552
Iter: 444 loss: 0.00382409571
Iter: 445 loss: 0.00382897025
Iter: 446 loss: 0.00382385124
Iter: 447 loss: 0.00382293505
Iter: 448 loss: 0.00382449315
Iter: 449 loss: 0.00382252899
Iter: 450 loss: 0.0038212582
Iter: 451 loss: 0.00382404076
Iter: 452 loss: 0.00382077275
Iter: 453 loss: 0.00381957926
Iter: 454 loss: 0.00382271479
Iter: 455 loss: 0.00381917623
Iter: 456 loss: 0.00381873851
Iter: 457 loss: 0.00381855341
Iter: 458 loss: 0.00381802069
Iter: 459 loss: 0.00381785864
Iter: 460 loss: 0.00381754292
Iter: 461 loss: 0.00381695689
Iter: 462 loss: 0.0038168272
Iter: 463 loss: 0.00381644908
Iter: 464 loss: 0.00381565047
Iter: 465 loss: 0.00382818724
Iter: 466 loss: 0.00381564815
Iter: 467 loss: 0.00381529098
Iter: 468 loss: 0.0038143131
Iter: 469 loss: 0.00382079091
Iter: 470 loss: 0.00381407794
Iter: 471 loss: 0.00381282647
Iter: 472 loss: 0.00382397952
Iter: 473 loss: 0.00381276431
Iter: 474 loss: 0.00381172355
Iter: 475 loss: 0.00381369051
Iter: 476 loss: 0.00381128653
Iter: 477 loss: 0.00381046254
Iter: 478 loss: 0.00381264649
Iter: 479 loss: 0.00381018897
Iter: 480 loss: 0.00380929932
Iter: 481 loss: 0.00380970538
Iter: 482 loss: 0.00380869769
Iter: 483 loss: 0.0038077028
Iter: 484 loss: 0.00381323
Iter: 485 loss: 0.00380755984
Iter: 486 loss: 0.00380672188
Iter: 487 loss: 0.00380738592
Iter: 488 loss: 0.0038062185
Iter: 489 loss: 0.00380531279
Iter: 490 loss: 0.00380663713
Iter: 491 loss: 0.00380487274
Iter: 492 loss: 0.00380439521
Iter: 493 loss: 0.00380438939
Iter: 494 loss: 0.00380409393
Iter: 495 loss: 0.00380407902
Iter: 496 loss: 0.00380391069
Iter: 497 loss: 0.00380366412
Iter: 498 loss: 0.00380365876
Iter: 499 loss: 0.00380317215
Iter: 500 loss: 0.00380295329
Iter: 501 loss: 0.00380271324
Iter: 502 loss: 0.00380228134
Iter: 503 loss: 0.00380170299
Iter: 504 loss: 0.00380167179
Iter: 505 loss: 0.00380073348
Iter: 506 loss: 0.00380397262
Iter: 507 loss: 0.00380048878
Iter: 508 loss: 0.00379970064
Iter: 509 loss: 0.00380495191
Iter: 510 loss: 0.00379962102
Iter: 511 loss: 0.00379907875
Iter: 512 loss: 0.00380014977
Iter: 513 loss: 0.00379885733
Iter: 514 loss: 0.00379818585
Iter: 515 loss: 0.00379784196
Iter: 516 loss: 0.00379753392
Iter: 517 loss: 0.00379648665
Iter: 518 loss: 0.00380270579
Iter: 519 loss: 0.00379636139
Iter: 520 loss: 0.0037954296
Iter: 521 loss: 0.00379623217
Iter: 522 loss: 0.00379488501
Iter: 523 loss: 0.00379398349
Iter: 524 loss: 0.0037968941
Iter: 525 loss: 0.00379373087
Iter: 526 loss: 0.00379310409
Iter: 527 loss: 0.00379762
Iter: 528 loss: 0.00379304914
Iter: 529 loss: 0.00379260257
Iter: 530 loss: 0.00379257672
Iter: 531 loss: 0.00379236555
Iter: 532 loss: 0.00379195972
Iter: 533 loss: 0.00380013348
Iter: 534 loss: 0.0037919539
Iter: 535 loss: 0.00379142119
Iter: 536 loss: 0.00379084423
Iter: 537 loss: 0.00379075622
Iter: 538 loss: 0.00379011314
Iter: 539 loss: 0.00379327801
Iter: 540 loss: 0.00379000092
Iter: 541 loss: 0.00378927472
Iter: 542 loss: 0.00378984166
Iter: 543 loss: 0.00378883537
Iter: 544 loss: 0.00378824398
Iter: 545 loss: 0.00379577326
Iter: 546 loss: 0.00378823653
Iter: 547 loss: 0.00378791895
Iter: 548 loss: 0.00378799043
Iter: 549 loss: 0.00378768495
Iter: 550 loss: 0.00378719717
Iter: 551 loss: 0.00378776039
Iter: 552 loss: 0.0037869371
Iter: 553 loss: 0.00378640508
Iter: 554 loss: 0.00378920743
Iter: 555 loss: 0.0037863187
Iter: 556 loss: 0.0037858421
Iter: 557 loss: 0.00378545281
Iter: 558 loss: 0.00378531031
Iter: 559 loss: 0.00378480391
Iter: 560 loss: 0.00379196182
Iter: 561 loss: 0.00378480577
Iter: 562 loss: 0.00378480647
Iter: 563 loss: 0.00378460763
Iter: 564 loss: 0.0037844833
Iter: 565 loss: 0.0037841734
Iter: 566 loss: 0.00378694641
Iter: 567 loss: 0.0037841273
Iter: 568 loss: 0.00378371309
Iter: 569 loss: 0.00378402486
Iter: 570 loss: 0.00378346816
Iter: 571 loss: 0.00378312846
Iter: 572 loss: 0.00378378574
Iter: 573 loss: 0.00378298433
Iter: 574 loss: 0.00378254312
Iter: 575 loss: 0.00378377573
Iter: 576 loss: 0.00378240272
Iter: 577 loss: 0.00378208794
Iter: 578 loss: 0.00378349749
Iter: 579 loss: 0.003782026
Iter: 580 loss: 0.00378174195
Iter: 581 loss: 0.00378173264
Iter: 582 loss: 0.00378151587
Iter: 583 loss: 0.00378104206
Iter: 584 loss: 0.00378218456
Iter: 585 loss: 0.00378087512
Iter: 586 loss: 0.00378051074
Iter: 587 loss: 0.00378252449
Iter: 588 loss: 0.00378046138
Iter: 589 loss: 0.00378011609
Iter: 590 loss: 0.00377988443
Iter: 591 loss: 0.0037797587
Iter: 592 loss: 0.0037793098
Iter: 593 loss: 0.00378153683
Iter: 594 loss: 0.00377923623
Iter: 595 loss: 0.00378029351
Iter: 596 loss: 0.00377915567
Iter: 597 loss: 0.0037791
Iter: 598 loss: 0.00377893867
Iter: 599 loss: 0.00377932843
Iter: 600 loss: 0.00377885136
Iter: 601 loss: 0.00377857639
Iter: 602 loss: 0.00377873331
Iter: 603 loss: 0.00377839711
Iter: 604 loss: 0.00377816055
Iter: 605 loss: 0.00377854
Iter: 606 loss: 0.00377805252
Iter: 607 loss: 0.00377777684
Iter: 608 loss: 0.00377860386
Iter: 609 loss: 0.00377769768
Iter: 610 loss: 0.00377735682
Iter: 611 loss: 0.00377785112
Iter: 612 loss: 0.00377719197
Iter: 613 loss: 0.00377687579
Iter: 614 loss: 0.00377811631
Iter: 615 loss: 0.00377680548
Iter: 616 loss: 0.00377650186
Iter: 617 loss: 0.0037770581
Iter: 618 loss: 0.00377636869
Iter: 619 loss: 0.00377611211
Iter: 620 loss: 0.00377701828
Iter: 621 loss: 0.00377604831
Iter: 622 loss: 0.00377576356
Iter: 623 loss: 0.00377588207
Iter: 624 loss: 0.00377556821
Iter: 625 loss: 0.00377522828
Iter: 626 loss: 0.00377564202
Iter: 627 loss: 0.00377504947
Iter: 628 loss: 0.00377556565
Iter: 629 loss: 0.00377498963
Iter: 630 loss: 0.00377492909
Iter: 631 loss: 0.00377476076
Iter: 632 loss: 0.00377576239
Iter: 633 loss: 0.00377471396
Iter: 634 loss: 0.00377447228
Iter: 635 loss: 0.00377507554
Iter: 636 loss: 0.00377438613
Iter: 637 loss: 0.00377417286
Iter: 638 loss: 0.00377439568
Iter: 639 loss: 0.00377405761
Iter: 640 loss: 0.00377382571
Iter: 641 loss: 0.00377416704
Iter: 642 loss: 0.00377371069
Iter: 643 loss: 0.0037734136
Iter: 644 loss: 0.00377383875
Iter: 645 loss: 0.00377326831
Iter: 646 loss: 0.00377296959
Iter: 647 loss: 0.00377414376
Iter: 648 loss: 0.00377290021
Iter: 649 loss: 0.00377266668
Iter: 650 loss: 0.00377350021
Iter: 651 loss: 0.003772608
Iter: 652 loss: 0.00377236959
Iter: 653 loss: 0.00377255282
Iter: 654 loss: 0.00377222942
Iter: 655 loss: 0.00377195608
Iter: 656 loss: 0.00377315586
Iter: 657 loss: 0.00377190253
Iter: 658 loss: 0.00377167342
Iter: 659 loss: 0.00377198146
Iter: 660 loss: 0.00377155701
Iter: 661 loss: 0.00377209019
Iter: 662 loss: 0.0037715137
Iter: 663 loss: 0.00377146294
Iter: 664 loss: 0.00377133535
Iter: 665 loss: 0.00377224502
Iter: 666 loss: 0.00377130974
Iter: 667 loss: 0.00377116259
Iter: 668 loss: 0.00377125898
Iter: 669 loss: 0.00377107272
Iter: 670 loss: 0.00377089949
Iter: 671 loss: 0.00377103733
Iter: 672 loss: 0.00377079146
Iter: 673 loss: 0.00377059728
Iter: 674 loss: 0.00377162406
Iter: 675 loss: 0.00377056515
Iter: 676 loss: 0.0037703705
Iter: 677 loss: 0.00377075095
Iter: 678 loss: 0.00377028808
Iter: 679 loss: 0.00377010368
Iter: 680 loss: 0.00377038936
Iter: 681 loss: 0.00377002219
Iter: 682 loss: 0.00376982731
Iter: 683 loss: 0.00377037283
Iter: 684 loss: 0.00376976468
Iter: 685 loss: 0.00376954698
Iter: 686 loss: 0.00376974605
Iter: 687 loss: 0.00376942102
Iter: 688 loss: 0.00376919098
Iter: 689 loss: 0.00377038354
Iter: 690 loss: 0.00376915326
Iter: 691 loss: 0.0037689642
Iter: 692 loss: 0.00376892602
Iter: 693 loss: 0.00376880076
Iter: 694 loss: 0.00376910763
Iter: 695 loss: 0.00376875093
Iter: 696 loss: 0.00376868201
Iter: 697 loss: 0.00376855209
Iter: 698 loss: 0.00377048366
Iter: 699 loss: 0.00376854558
Iter: 700 loss: 0.00376840681
Iter: 701 loss: 0.0037685954
Iter: 702 loss: 0.00376833696
Iter: 703 loss: 0.00376818655
Iter: 704 loss: 0.00376812951
Iter: 705 loss: 0.00376804732
Iter: 706 loss: 0.00376782496
Iter: 707 loss: 0.0037689
Iter: 708 loss: 0.00376778748
Iter: 709 loss: 0.0037675933
Iter: 710 loss: 0.00376809272
Iter: 711 loss: 0.00376752508
Iter: 712 loss: 0.0037673295
Iter: 713 loss: 0.00376745802
Iter: 714 loss: 0.0037672061
Iter: 715 loss: 0.00376696931
Iter: 716 loss: 0.00376805
Iter: 717 loss: 0.00376692554
Iter: 718 loss: 0.00376668875
Iter: 719 loss: 0.00376683893
Iter: 720 loss: 0.00376654207
Iter: 721 loss: 0.00376625266
Iter: 722 loss: 0.00376707572
Iter: 723 loss: 0.00376616139
Iter: 724 loss: 0.00376588642
Iter: 725 loss: 0.00376658048
Iter: 726 loss: 0.00376578723
Iter: 727 loss: 0.00376597
Iter: 728 loss: 0.00376572693
Iter: 729 loss: 0.00376565242
Iter: 730 loss: 0.0037655
Iter: 731 loss: 0.00376824383
Iter: 732 loss: 0.0037654948
Iter: 733 loss: 0.0037653672
Iter: 734 loss: 0.00376544287
Iter: 735 loss: 0.00376528013
Iter: 736 loss: 0.00376510946
Iter: 737 loss: 0.00376499863
Iter: 738 loss: 0.00376492972
Iter: 739 loss: 0.00376465451
Iter: 740 loss: 0.00376649597
Iter: 741 loss: 0.0037646275
Iter: 742 loss: 0.00376440305
Iter: 743 loss: 0.00376520096
Iter: 744 loss: 0.00376434484
Iter: 745 loss: 0.00376414
Iter: 746 loss: 0.00376406801
Iter: 747 loss: 0.00376395066
Iter: 748 loss: 0.00376366638
Iter: 749 loss: 0.0037649842
Iter: 750 loss: 0.00376361236
Iter: 751 loss: 0.00376334088
Iter: 752 loss: 0.00376356975
Iter: 753 loss: 0.00376317953
Iter: 754 loss: 0.00376284868
Iter: 755 loss: 0.00376396207
Iter: 756 loss: 0.00376276
Iter: 757 loss: 0.00376247778
Iter: 758 loss: 0.00376308
Iter: 759 loss: 0.00376237161
Iter: 760 loss: 0.00376245286
Iter: 761 loss: 0.00376229757
Iter: 762 loss: 0.00376221165
Iter: 763 loss: 0.00376206497
Iter: 764 loss: 0.00376206543
Iter: 765 loss: 0.00376192923
Iter: 766 loss: 0.00376201374
Iter: 767 loss: 0.00376183982
Iter: 768 loss: 0.00376165472
Iter: 769 loss: 0.00376158394
Iter: 770 loss: 0.00376148382
Iter: 771 loss: 0.00376122608
Iter: 772 loss: 0.00376217859
Iter: 773 loss: 0.00376116158
Iter: 774 loss: 0.00376091385
Iter: 775 loss: 0.00376173924
Iter: 776 loss: 0.00376084726
Iter: 777 loss: 0.00376061071
Iter: 778 loss: 0.00376081141
Iter: 779 loss: 0.00376047147
Iter: 780 loss: 0.00376020279
Iter: 781 loss: 0.00376102747
Iter: 782 loss: 0.00376012176
Iter: 783 loss: 0.00375982095
Iter: 784 loss: 0.00376044563
Iter: 785 loss: 0.00375969801
Iter: 786 loss: 0.00375941908
Iter: 787 loss: 0.00376005284
Iter: 788 loss: 0.00375931407
Iter: 789 loss: 0.00375902
Iter: 790 loss: 0.00376003399
Iter: 791 loss: 0.00375894294
Iter: 792 loss: 0.00375899184
Iter: 793 loss: 0.00375887379
Iter: 794 loss: 0.0037587788
Iter: 795 loss: 0.00375867
Iter: 796 loss: 0.00375865679
Iter: 797 loss: 0.0037585611
Iter: 798 loss: 0.0037585455
Iter: 799 loss: 0.00375847379
Iter: 800 loss: 0.00375832617
Iter: 801 loss: 0.00375830289
Iter: 802 loss: 0.00375819951
Iter: 803 loss: 0.00375798903
Iter: 804 loss: 0.00375902024
Iter: 805 loss: 0.00375795458
Iter: 806 loss: 0.00375776738
Iter: 807 loss: 0.00375851244
Iter: 808 loss: 0.00375772128
Iter: 809 loss: 0.00375755434
Iter: 810 loss: 0.0037576193
Iter: 811 loss: 0.0037574349
Iter: 812 loss: 0.00375723466
Iter: 813 loss: 0.00375787308
Iter: 814 loss: 0.00375717692
Iter: 815 loss: 0.0037569555
Iter: 816 loss: 0.00375726214
Iter: 817 loss: 0.0037568484
Iter: 818 loss: 0.00375662651
Iter: 819 loss: 0.00375754293
Iter: 820 loss: 0.00375657948
Iter: 821 loss: 0.00375639717
Iter: 822 loss: 0.00375672849
Iter: 823 loss: 0.00375631847
Iter: 824 loss: 0.00375641463
Iter: 825 loss: 0.00375627354
Iter: 826 loss: 0.00375622138
Iter: 827 loss: 0.00375615223
Iter: 828 loss: 0.003756152
Iter: 829 loss: 0.00375608052
Iter: 830 loss: 0.00375608541
Iter: 831 loss: 0.0037560286
Iter: 832 loss: 0.00375593873
Iter: 833 loss: 0.00375587773
Iter: 834 loss: 0.00375584955
Iter: 835 loss: 0.00375570823
Iter: 836 loss: 0.0037562931
Iter: 837 loss: 0.00375567586
Iter: 838 loss: 0.00375553174
Iter: 839 loss: 0.00375592592
Iter: 840 loss: 0.00375548098
Iter: 841 loss: 0.00375532731
Iter: 842 loss: 0.00375556969
Iter: 843 loss: 0.00375524932
Iter: 844 loss: 0.00375509751
Iter: 845 loss: 0.00375535456
Iter: 846 loss: 0.00375502743
Iter: 847 loss: 0.00375483
Iter: 848 loss: 0.00375532592
Iter: 849 loss: 0.0037547634
Iter: 850 loss: 0.00375459343
Iter: 851 loss: 0.00375490868
Iter: 852 loss: 0.00375452149
Iter: 853 loss: 0.00375433895
Iter: 854 loss: 0.00375506957
Iter: 855 loss: 0.00375430146
Iter: 856 loss: 0.00375429494
Iter: 857 loss: 0.00375425303
Iter: 858 loss: 0.00375419226
Iter: 859 loss: 0.00375416083
Iter: 860 loss: 0.00375413289
Iter: 861 loss: 0.00375407981
Iter: 862 loss: 0.00375405769
Iter: 863 loss: 0.00375403091
Iter: 864 loss: 0.00375394756
Iter: 865 loss: 0.00375386025
Iter: 866 loss: 0.00375384139
Iter: 867 loss: 0.00375368749
Iter: 868 loss: 0.00375427422
Iter: 869 loss: 0.00375364861
Iter: 870 loss: 0.00375348888
Iter: 871 loss: 0.00375423534
Iter: 872 loss: 0.0037534635
Iter: 873 loss: 0.0037533259
Iter: 874 loss: 0.00375349075
Iter: 875 loss: 0.00375325466
Iter: 876 loss: 0.00375310774
Iter: 877 loss: 0.00375336688
Iter: 878 loss: 0.00375304231
Iter: 879 loss: 0.0037528614
Iter: 880 loss: 0.00375335477
Iter: 881 loss: 0.0037528039
Iter: 882 loss: 0.00375264604
Iter: 883 loss: 0.00375305954
Iter: 884 loss: 0.00375259109
Iter: 885 loss: 0.00375244278
Iter: 886 loss: 0.00375282555
Iter: 887 loss: 0.00375239039
Iter: 888 loss: 0.00375243928
Iter: 889 loss: 0.00375235197
Iter: 890 loss: 0.0037523082
Iter: 891 loss: 0.00375229307
Iter: 892 loss: 0.00375227118
Iter: 893 loss: 0.00375222275
Iter: 894 loss: 0.00375220785
Iter: 895 loss: 0.00375218247
Iter: 896 loss: 0.00375210657
Iter: 897 loss: 0.00375204952
Iter: 898 loss: 0.00375202671
Iter: 899 loss: 0.00375190098
Iter: 900 loss: 0.00375243439
Iter: 901 loss: 0.0037518777
Iter: 902 loss: 0.00375177269
Iter: 903 loss: 0.00375207979
Iter: 904 loss: 0.00375173963
Iter: 905 loss: 0.0037516423
Iter: 906 loss: 0.00375178317
Iter: 907 loss: 0.00375159248
Iter: 908 loss: 0.00375147676
Iter: 909 loss: 0.00375163369
Iter: 910 loss: 0.00375142135
Iter: 911 loss: 0.00375128118
Iter: 912 loss: 0.00375188654
Iter: 913 loss: 0.00375125417
Iter: 914 loss: 0.00375114498
Iter: 915 loss: 0.00375125185
Iter: 916 loss: 0.00375108537
Iter: 917 loss: 0.00375096546
Iter: 918 loss: 0.00375166675
Iter: 919 loss: 0.00375094451
Iter: 920 loss: 0.00375095895
Iter: 921 loss: 0.00375091797
Iter: 922 loss: 0.00375088677
Iter: 923 loss: 0.00375087583
Iter: 924 loss: 0.00375085697
Iter: 925 loss: 0.00375082623
Iter: 926 loss: 0.00375080365
Iter: 927 loss: 0.00375079154
Iter: 928 loss: 0.00375073776
Iter: 929 loss: 0.00375070516
Iter: 930 loss: 0.00375068281
Iter: 931 loss: 0.00375060784
Iter: 932 loss: 0.00375105953
Iter: 933 loss: 0.00375060085
Iter: 934 loss: 0.00375053706
Iter: 935 loss: 0.00375071075
Iter: 936 loss: 0.00375051843
Iter: 937 loss: 0.00375045766
Iter: 938 loss: 0.00375051331
Iter: 939 loss: 0.00375041924
Iter: 940 loss: 0.00375034404
Iter: 941 loss: 0.00375048514
Iter: 942 loss: 0.00375031191
Iter: 943 loss: 0.00375022762
Iter: 944 loss: 0.00375050539
Iter: 945 loss: 0.00375020388
Iter: 946 loss: 0.00375012611
Iter: 947 loss: 0.003750314
Iter: 948 loss: 0.00375009957
Iter: 949 loss: 0.00375003
Iter: 950 loss: 0.00375021482
Iter: 951 loss: 0.00375000457
Iter: 952 loss: 0.00375001831
Iter: 953 loss: 0.00374998618
Iter: 954 loss: 0.00374996406
Iter: 955 loss: 0.00374996359
Iter: 956 loss: 0.0037499445
Iter: 957 loss: 0.00374992285
Iter: 958 loss: 0.00374990073
Iter: 959 loss: 0.00374989701
Iter: 960 loss: 0.00374985859
Iter: 961 loss: 0.00374985067
Iter: 962 loss: 0.00374982972
Iter: 963 loss: 0.00374977849
Iter: 964 loss: 0.00375015335
Iter: 965 loss: 0.00374977733
Iter: 966 loss: 0.00374974078
Iter: 967 loss: 0.00374980271
Iter: 968 loss: 0.00374972471
Iter: 969 loss: 0.00374967977
Iter: 970 loss: 0.00374974031
Iter: 971 loss: 0.00374965975
Iter: 972 loss: 0.00374961272
Iter: 973 loss: 0.00374965603
Iter: 974 loss: 0.00374958781
Iter: 975 loss: 0.00374952471
Iter: 976 loss: 0.00374985882
Iter: 977 loss: 0.00374951703
Iter: 978 loss: 0.00374946883
Iter: 979 loss: 0.00374950096
Iter: 980 loss: 0.00374944112
Iter: 981 loss: 0.00374938478
Iter: 982 loss: 0.00374959572
Iter: 983 loss: 0.00374937127
Iter: 984 loss: 0.00374936638
Iter: 985 loss: 0.00374935637
Iter: 986 loss: 0.00374933518
Iter: 987 loss: 0.00374934031
Iter: 988 loss: 0.00374931796
Iter: 989 loss: 0.00374930468
Iter: 990 loss: 0.0037492814
Iter: 991 loss: 0.00374928117
Iter: 992 loss: 0.00374924461
Iter: 993 loss: 0.00374924834
Iter: 994 loss: 0.00374921644
Iter: 995 loss: 0.00374917686
Iter: 996 loss: 0.00374943949
Iter: 997 loss: 0.00374917453
Iter: 998 loss: 0.00374914031
Iter: 999 loss: 0.00374921667
Iter: 1000 loss: 0.00374912657
Iter: 1001 loss: 0.00374909444
Iter: 1002 loss: 0.00374911632
Iter: 1003 loss: 0.00374906976
Iter: 1004 loss: 0.00374902622
Iter: 1005 loss: 0.00374910701
Iter: 1006 loss: 0.00374900666
Iter: 1007 loss: 0.00374895846
Iter: 1008 loss: 0.00374914939
Iter: 1009 loss: 0.00374894449
Iter: 1010 loss: 0.00374890328
Iter: 1011 loss: 0.00374895846
Iter: 1012 loss: 0.00374887977
Iter: 1013 loss: 0.00374883274
Iter: 1014 loss: 0.00374901155
Iter: 1015 loss: 0.00374882086
Iter: 1016 loss: 0.0037488183
Iter: 1017 loss: 0.0037488048
Iter: 1018 loss: 0.00374878664
Iter: 1019 loss: 0.003748802
Iter: 1020 loss: 0.00374877686
Iter: 1021 loss: 0.00374876335
Iter: 1022 loss: 0.00374874054
Iter: 1023 loss: 0.00374874426
Iter: 1024 loss: 0.00374870771
Iter: 1025 loss: 0.00374872051
Iter: 1026 loss: 0.00374868512
Iter: 1027 loss: 0.00374864927
Iter: 1028 loss: 0.00374891981
Iter: 1029 loss: 0.00374864577
Iter: 1030 loss: 0.00374862249
Iter: 1031 loss: 0.00374864507
Iter: 1032 loss: 0.00374860782
Iter: 1033 loss: 0.00374857918
Iter: 1034 loss: 0.00374863832
Iter: 1035 loss: 0.00374856894
Iter: 1036 loss: 0.00374853867
Iter: 1037 loss: 0.00374856847
Iter: 1038 loss: 0.00374851865
Iter: 1039 loss: 0.00374848046
Iter: 1040 loss: 0.00374867488
Iter: 1041 loss: 0.00374847325
Iter: 1042 loss: 0.00374844205
Iter: 1043 loss: 0.00374848163
Iter: 1044 loss: 0.00374842761
Iter: 1045 loss: 0.00374839758
Iter: 1046 loss: 0.00374848908
Iter: 1047 loss: 0.0037483864
Iter: 1048 loss: 0.00374837662
Iter: 1049 loss: 0.00374837033
Iter: 1050 loss: 0.0037483545
Iter: 1051 loss: 0.00374836684
Iter: 1052 loss: 0.003748341
Iter: 1053 loss: 0.00374833
Iter: 1054 loss: 0.00374831026
Iter: 1055 loss: 0.00374879804
Iter: 1056 loss: 0.00374831
Iter: 1057 loss: 0.00374827767
Iter: 1058 loss: 0.0037483098
Iter: 1059 loss: 0.00374826184
Iter: 1060 loss: 0.00374823785
Iter: 1061 loss: 0.00374854426
Iter: 1062 loss: 0.00374823622
Iter: 1063 loss: 0.00374821946
Iter: 1064 loss: 0.00374824973
Iter: 1065 loss: 0.00374821294
Iter: 1066 loss: 0.00374819222
Iter: 1067 loss: 0.00374819059
Iter: 1068 loss: 0.00374817662
Iter: 1069 loss: 0.00374814821
Iter: 1070 loss: 0.00374819292
Iter: 1071 loss: 0.00374813518
Iter: 1072 loss: 0.00374810351
Iter: 1073 loss: 0.00374827487
Iter: 1074 loss: 0.00374809606
Iter: 1075 loss: 0.00374807045
Iter: 1076 loss: 0.00374810118
Iter: 1077 loss: 0.00374805345
Iter: 1078 loss: 0.00374802318
Iter: 1079 loss: 0.00374806114
Iter: 1080 loss: 0.00374800502
Iter: 1081 loss: 0.00374797685
Iter: 1082 loss: 0.00374797778
Iter: 1083 loss: 0.00374794193
Iter: 1084 loss: 0.00374801201
Iter: 1085 loss: 0.00374792819
Iter: 1086 loss: 0.00374791026
Iter: 1087 loss: 0.00374787953
Iter: 1088 loss: 0.00374857476
Iter: 1089 loss: 0.00374788
Iter: 1090 loss: 0.00374783506
Iter: 1091 loss: 0.0037479091
Iter: 1092 loss: 0.00374781759
Iter: 1093 loss: 0.00374778872
Iter: 1094 loss: 0.00374812
Iter: 1095 loss: 0.00374778593
Iter: 1096 loss: 0.00374776218
Iter: 1097 loss: 0.00374779012
Iter: 1098 loss: 0.00374774728
Iter: 1099 loss: 0.00374771934
Iter: 1100 loss: 0.00374772423
Iter: 1101 loss: 0.00374769652
Iter: 1102 loss: 0.00374765438
Iter: 1103 loss: 0.00374771166
Iter: 1104 loss: 0.00374763389
Iter: 1105 loss: 0.00374758733
Iter: 1106 loss: 0.00374791562
Iter: 1107 loss: 0.00374758104
Iter: 1108 loss: 0.00374754611
Iter: 1109 loss: 0.00374755799
Iter: 1110 loss: 0.00374752097
Iter: 1111 loss: 0.00374747184
Iter: 1112 loss: 0.00374753773
Iter: 1113 loss: 0.0037474467
Iter: 1114 loss: 0.00374740548
Iter: 1115 loss: 0.00374795403
Iter: 1116 loss: 0.00374740502
Iter: 1117 loss: 0.00374735263
Iter: 1118 loss: 0.00374763831
Iter: 1119 loss: 0.00374734425
Iter: 1120 loss: 0.00374733191
Iter: 1121 loss: 0.00374729396
Iter: 1122 loss: 0.00374768837
Iter: 1123 loss: 0.00374729466
Iter: 1124 loss: 0.00374725088
Iter: 1125 loss: 0.00374735845
Iter: 1126 loss: 0.00374723785
Iter: 1127 loss: 0.00374721
Iter: 1128 loss: 0.00374748791
Iter: 1129 loss: 0.00374720781
Iter: 1130 loss: 0.0037471843
Iter: 1131 loss: 0.00374722737
Iter: 1132 loss: 0.00374717358
Iter: 1133 loss: 0.0037471503
Iter: 1134 loss: 0.00374715868
Iter: 1135 loss: 0.00374713587
Iter: 1136 loss: 0.00374710793
Iter: 1137 loss: 0.00374716357
Iter: 1138 loss: 0.00374709466
Iter: 1139 loss: 0.00374707277
Iter: 1140 loss: 0.00374728022
Iter: 1141 loss: 0.00374706648
Iter: 1142 loss: 0.00374704716
Iter: 1143 loss: 0.00374705764
Iter: 1144 loss: 0.00374703435
Iter: 1145 loss: 0.0037470106
Iter: 1146 loss: 0.00374707929
Iter: 1147 loss: 0.00374700339
Iter: 1148 loss: 0.00374698383
Iter: 1149 loss: 0.00374707882
Iter: 1150 loss: 0.0037469794
Iter: 1151 loss: 0.00374695659
Iter: 1152 loss: 0.00374726159
Iter: 1153 loss: 0.00374695659
Iter: 1154 loss: 0.00374695286
Iter: 1155 loss: 0.0037469361
Iter: 1156 loss: 0.00374702923
Iter: 1157 loss: 0.00374693191
Iter: 1158 loss: 0.00374691188
Iter: 1159 loss: 0.00374695985
Iter: 1160 loss: 0.0037469042
Iter: 1161 loss: 0.0037468886
Iter: 1162 loss: 0.00374699291
Iter: 1163 loss: 0.00374688604
Iter: 1164 loss: 0.00374687207
Iter: 1165 loss: 0.00374690536
Iter: 1166 loss: 0.00374686881
Iter: 1167 loss: 0.00374685181
Iter: 1168 loss: 0.00374686113
Iter: 1169 loss: 0.00374684297
Iter: 1170 loss: 0.00374682387
Iter: 1171 loss: 0.00374684716
Iter: 1172 loss: 0.00374681386
Iter: 1173 loss: 0.0037467964
Iter: 1174 loss: 0.00374688115
Iter: 1175 loss: 0.003746795
Iter: 1176 loss: 0.00374677428
Iter: 1177 loss: 0.00374678755
Iter: 1178 loss: 0.0037467652
Iter: 1179 loss: 0.00374674401
Iter: 1180 loss: 0.00374681177
Iter: 1181 loss: 0.00374674099
Iter: 1182 loss: 0.00374672492
Iter: 1183 loss: 0.00374677801
Iter: 1184 loss: 0.0037467205
Iter: 1185 loss: 0.00374670676
Iter: 1186 loss: 0.00374670606
Iter: 1187 loss: 0.0037467021
Iter: 1188 loss: 0.00374668743
Iter: 1189 loss: 0.00374672585
Iter: 1190 loss: 0.00374668511
Iter: 1191 loss: 0.00374666648
Iter: 1192 loss: 0.0037467354
Iter: 1193 loss: 0.00374666485
Iter: 1194 loss: 0.00374665135
Iter: 1195 loss: 0.00374669302
Iter: 1196 loss: 0.00374665158
Iter: 1197 loss: 0.00374663202
Iter: 1198 loss: 0.00374668371
Iter: 1199 loss: 0.0037466241
Iter: 1200 loss: 0.00374661502
Iter: 1201 loss: 0.00374663156
Iter: 1202 loss: 0.00374660781
Iter: 1203 loss: 0.003746595
Iter: 1204 loss: 0.00374661223
Iter: 1205 loss: 0.00374658778
Iter: 1206 loss: 0.00374657614
Iter: 1207 loss: 0.00374662387
Iter: 1208 loss: 0.00374657242
Iter: 1209 loss: 0.00374655658
Iter: 1210 loss: 0.00374657684
Iter: 1211 loss: 0.003746551
Iter: 1212 loss: 0.00374653982
Iter: 1213 loss: 0.00374658895
Iter: 1214 loss: 0.00374653679
Iter: 1215 loss: 0.00374652585
Iter: 1216 loss: 0.00374654238
Iter: 1217 loss: 0.00374652259
Iter: 1218 loss: 0.00374651328
Iter: 1219 loss: 0.00374651188
Iter: 1220 loss: 0.00374650932
Iter: 1221 loss: 0.00374649791
Iter: 1222 loss: 0.00374651561
Iter: 1223 loss: 0.00374649675
Iter: 1224 loss: 0.00374648534
Iter: 1225 loss: 0.00374657474
Iter: 1226 loss: 0.00374648208
Iter: 1227 loss: 0.00374647276
Iter: 1228 loss: 0.00374649605
Iter: 1229 loss: 0.00374646601
Iter: 1230 loss: 0.00374645647
Iter: 1231 loss: 0.00374647602
Iter: 1232 loss: 0.00374645181
Iter: 1233 loss: 0.00374644552
Iter: 1234 loss: 0.00374643924
Iter: 1235 loss: 0.00374643458
Iter: 1236 loss: 0.0037464255
Iter: 1237 loss: 0.00374645088
Iter: 1238 loss: 0.00374641828
Iter: 1239 loss: 0.00374640478
Iter: 1240 loss: 0.00374645647
Iter: 1241 loss: 0.00374639872
Iter: 1242 loss: 0.00374638266
Iter: 1243 loss: 0.00374640827
Iter: 1244 loss: 0.00374637544
Iter: 1245 loss: 0.00374636264
Iter: 1246 loss: 0.00374638289
Iter: 1247 loss: 0.00374635379
Iter: 1248 loss: 0.00374633935
Iter: 1249 loss: 0.00374630559
Iter: 1250 loss: 0.00374691351
Iter: 1251 loss: 0.00374630303
Iter: 1252 loss: 0.00374645134
Iter: 1253 loss: 0.00374629325
Iter: 1254 loss: 0.00374629325
Iter: 1255 loss: 0.00374627742
Iter: 1256 loss: 0.00374629
Iter: 1257 loss: 0.00374626601
Iter: 1258 loss: 0.00374624878
Iter: 1259 loss: 0.00374632562
Iter: 1260 loss: 0.00374624156
Iter: 1261 loss: 0.00374622783
Iter: 1262 loss: 0.00374638778
Iter: 1263 loss: 0.00374623
Iter: 1264 loss: 0.00374622084
Iter: 1265 loss: 0.00374627532
Iter: 1266 loss: 0.00374622177
Iter: 1267 loss: 0.00374621223
Iter: 1268 loss: 0.00374619733
Iter: 1269 loss: 0.00374619756
Iter: 1270 loss: 0.00374618545
Iter: 1271 loss: 0.00374620967
Iter: 1272 loss: 0.00374618126
Iter: 1273 loss: 0.00374616706
Iter: 1274 loss: 0.00374627975
Iter: 1275 loss: 0.00374616706
Iter: 1276 loss: 0.00374615961
Iter: 1277 loss: 0.00374618499
Iter: 1278 loss: 0.00374615495
Iter: 1279 loss: 0.00374615099
Iter: 1280 loss: 0.00374615449
Iter: 1281 loss: 0.00374614494
Iter: 1282 loss: 0.00374613353
Iter: 1283 loss: 0.00374612887
Iter: 1284 loss: 0.00374612352
Iter: 1285 loss: 0.00374614308
Iter: 1286 loss: 0.00374612329
Iter: 1287 loss: 0.00374611956
Iter: 1288 loss: 0.00374610536
Iter: 1289 loss: 0.00374613795
Iter: 1290 loss: 0.00374610443
Iter: 1291 loss: 0.00374609022
Iter: 1292 loss: 0.00374620571
Iter: 1293 loss: 0.00374608766
Iter: 1294 loss: 0.00374607695
Iter: 1295 loss: 0.00374611327
Iter: 1296 loss: 0.00374607416
Iter: 1297 loss: 0.00374606461
Iter: 1298 loss: 0.00374608953
Iter: 1299 loss: 0.00374606345
Iter: 1300 loss: 0.00374605111
Iter: 1301 loss: 0.0037460411
Iter: 1302 loss: 0.00374603737
Iter: 1303 loss: 0.00374602014
Iter: 1304 loss: 0.00374600827
Iter: 1305 loss: 0.00374600291
Iter: 1306 loss: 0.00374597684
Iter: 1307 loss: 0.00374600384
Iter: 1308 loss: 0.00374596682
Iter: 1309 loss: 0.00374595216
Iter: 1310 loss: 0.00374617684
Iter: 1311 loss: 0.00374595076
Iter: 1312 loss: 0.00374594191
Iter: 1313 loss: 0.00374595774
Iter: 1314 loss: 0.00374593958
Iter: 1315 loss: 0.00374593236
Iter: 1316 loss: 0.00374592072
Iter: 1317 loss: 0.00374592165
Iter: 1318 loss: 0.00374591211
Iter: 1319 loss: 0.00374596566
Iter: 1320 loss: 0.00374591
Iter: 1321 loss: 0.00374589767
Iter: 1322 loss: 0.00374587788
Iter: 1323 loss: 0.00374616683
Iter: 1324 loss: 0.00374587509
Iter: 1325 loss: 0.00374585856
Iter: 1326 loss: 0.00374585018
Iter: 1327 loss: 0.00374584273
Iter: 1328 loss: 0.00374581851
Iter: 1329 loss: 0.00374598079
Iter: 1330 loss: 0.00374581525
Iter: 1331 loss: 0.00374578964
Iter: 1332 loss: 0.00374598778
Iter: 1333 loss: 0.00374578545
Iter: 1334 loss: 0.00374575891
Iter: 1335 loss: 0.0037457638
Iter: 1336 loss: 0.00374574028
Iter: 1337 loss: 0.00374572189
Iter: 1338 loss: 0.00374572119
Iter: 1339 loss: 0.00374570605
Iter: 1340 loss: 0.00374568556
Iter: 1341 loss: 0.00374577893
Iter: 1342 loss: 0.00374568347
Iter: 1343 loss: 0.00374566577
Iter: 1344 loss: 0.00374564109
Iter: 1345 loss: 0.0037456404
Iter: 1346 loss: 0.00374560896
Iter: 1347 loss: 0.00374604249
Iter: 1348 loss: 0.00374560896
Iter: 1349 loss: 0.00374559476
Iter: 1350 loss: 0.00374558056
Iter: 1351 loss: 0.00374557963
Iter: 1352 loss: 0.00374556729
Iter: 1353 loss: 0.00374556612
Iter: 1354 loss: 0.00374555984
Iter: 1355 loss: 0.00374554587
Iter: 1356 loss: 0.00374559825
Iter: 1357 loss: 0.00374554098
Iter: 1358 loss: 0.00374552561
Iter: 1359 loss: 0.00374555355
Iter: 1360 loss: 0.00374551956
Iter: 1361 loss: 0.0037455135
Iter: 1362 loss: 0.00374550419
Iter: 1363 loss: 0.00374550465
Iter: 1364 loss: 0.00374549534
Iter: 1365 loss: 0.00374547974
Iter: 1366 loss: 0.00374547718
Iter: 1367 loss: 0.00374547439
Iter: 1368 loss: 0.00374547066
Iter: 1369 loss: 0.00374546205
Iter: 1370 loss: 0.00374544668
Iter: 1371 loss: 0.00374580314
Iter: 1372 loss: 0.00374544901
Iter: 1373 loss: 0.00374542549
Iter: 1374 loss: 0.00374539918
Iter: 1375 loss: 0.00374539848
Iter: 1376 loss: 0.00374537217
Iter: 1377 loss: 0.00374535378
Iter: 1378 loss: 0.00374534819
Iter: 1379 loss: 0.00374531583
Iter: 1380 loss: 0.00374531792
Iter: 1381 loss: 0.00374529627
Iter: 1382 loss: 0.0037452504
Iter: 1383 loss: 0.00374554377
Iter: 1384 loss: 0.00374525134
Iter: 1385 loss: 0.00374521012
Iter: 1386 loss: 0.00374526065
Iter: 1387 loss: 0.00374519336
Iter: 1388 loss: 0.00374518987
Iter: 1389 loss: 0.0037451731
Iter: 1390 loss: 0.00374516752
Iter: 1391 loss: 0.00374515401
Iter: 1392 loss: 0.00374515448
Iter: 1393 loss: 0.00374513562
Iter: 1394 loss: 0.00374512211
Iter: 1395 loss: 0.0037451114
Iter: 1396 loss: 0.00374508137
Iter: 1397 loss: 0.00374532398
Iter: 1398 loss: 0.00374507857
Iter: 1399 loss: 0.00374506321
Iter: 1400 loss: 0.00374506228
Iter: 1401 loss: 0.00374504877
Iter: 1402 loss: 0.00374500267
Iter: 1403 loss: 0.00374514889
Iter: 1404 loss: 0.00374498335
Iter: 1405 loss: 0.0037449263
Iter: 1406 loss: 0.0037451
Iter: 1407 loss: 0.00374490954
Iter: 1408 loss: 0.00374488905
Iter: 1409 loss: 0.00374488439
Iter: 1410 loss: 0.00374486228
Iter: 1411 loss: 0.00374492677
Iter: 1412 loss: 0.00374485482
Iter: 1413 loss: 0.00374484225
Iter: 1414 loss: 0.00374480337
Iter: 1415 loss: 0.00374520919
Iter: 1416 loss: 0.00374479801
Iter: 1417 loss: 0.00374475913
Iter: 1418 loss: 0.00374514959
Iter: 1419 loss: 0.00374475634
Iter: 1420 loss: 0.0037447256
Iter: 1421 loss: 0.00374487741
Iter: 1422 loss: 0.00374471513
Iter: 1423 loss: 0.00374469487
Iter: 1424 loss: 0.00374469394
Iter: 1425 loss: 0.00374467671
Iter: 1426 loss: 0.00374464202
Iter: 1427 loss: 0.00374514633
Iter: 1428 loss: 0.00374463946
Iter: 1429 loss: 0.00374460267
Iter: 1430 loss: 0.00374486437
Iter: 1431 loss: 0.00374459475
Iter: 1432 loss: 0.00374458381
Iter: 1433 loss: 0.00374458288
Iter: 1434 loss: 0.00374456705
Iter: 1435 loss: 0.00374453329
Iter: 1436 loss: 0.00374501618
Iter: 1437 loss: 0.00374453631
Iter: 1438 loss: 0.00374450954
Iter: 1439 loss: 0.00374448649
Iter: 1440 loss: 0.00374448253
Iter: 1441 loss: 0.00374443526
Iter: 1442 loss: 0.00374448253
Iter: 1443 loss: 0.00374440779
Iter: 1444 loss: 0.00374437356
Iter: 1445 loss: 0.00374451512
Iter: 1446 loss: 0.00374436565
Iter: 1447 loss: 0.00374433538
Iter: 1448 loss: 0.00374433491
Iter: 1449 loss: 0.00374432048
Iter: 1450 loss: 0.0037442972
Iter: 1451 loss: 0.00374465133
Iter: 1452 loss: 0.00374429533
Iter: 1453 loss: 0.00374426716
Iter: 1454 loss: 0.00374438753
Iter: 1455 loss: 0.00374426
Iter: 1456 loss: 0.00374429277
Iter: 1457 loss: 0.00374425109
Iter: 1458 loss: 0.00374424318
Iter: 1459 loss: 0.00374422641
Iter: 1460 loss: 0.00374440243
Iter: 1461 loss: 0.00374422316
Iter: 1462 loss: 0.00374421407
Iter: 1463 loss: 0.00374420825
Iter: 1464 loss: 0.00374419941
Iter: 1465 loss: 0.00374418404
Iter: 1466 loss: 0.00374416169
Iter: 1467 loss: 0.00374416
Iter: 1468 loss: 0.00374413072
Iter: 1469 loss: 0.00374441245
Iter: 1470 loss: 0.00374412606
Iter: 1471 loss: 0.00374411256
Iter: 1472 loss: 0.00374408416
Iter: 1473 loss: 0.00374467904
Iter: 1474 loss: 0.00374408625
Iter: 1475 loss: 0.0037440625
Iter: 1476 loss: 0.00374405785
Iter: 1477 loss: 0.00374403875
Iter: 1478 loss: 0.00374403
Iter: 1479 loss: 0.0037440178
Iter: 1480 loss: 0.00374398613
Iter: 1481 loss: 0.00374402362
Iter: 1482 loss: 0.00374397147
Iter: 1483 loss: 0.00374394236
Iter: 1484 loss: 0.00374409417
Iter: 1485 loss: 0.00374394236
Iter: 1486 loss: 0.00374390418
Iter: 1487 loss: 0.00374392513
Iter: 1488 loss: 0.00374388299
Iter: 1489 loss: 0.00374384853
Iter: 1490 loss: 0.00374413724
Iter: 1491 loss: 0.00374385063
Iter: 1492 loss: 0.00374381943
Iter: 1493 loss: 0.00374402525
Iter: 1494 loss: 0.00374381919
Iter: 1495 loss: 0.00374380453
Iter: 1496 loss: 0.00374378986
Iter: 1497 loss: 0.00374378706
Iter: 1498 loss: 0.00374375703
Iter: 1499 loss: 0.00374402152
Iter: 1500 loss: 0.00374375586
Iter: 1501 loss: 0.0037437398
Iter: 1502 loss: 0.00374377263
Iter: 1503 loss: 0.00374373281
Iter: 1504 loss: 0.00374371745
Iter: 1505 loss: 0.00374368508
Iter: 1506 loss: 0.00374433119
Iter: 1507 loss: 0.00374368578
Iter: 1508 loss: 0.00374365691
Iter: 1509 loss: 0.00374369696
Iter: 1510 loss: 0.00374364154
Iter: 1511 loss: 0.0037436178
Iter: 1512 loss: 0.00374361919
Iter: 1513 loss: 0.0037436015
Iter: 1514 loss: 0.00374357798
Iter: 1515 loss: 0.00374358101
Iter: 1516 loss: 0.00374356052
Iter: 1517 loss: 0.00374356145
Iter: 1518 loss: 0.00374354841
Iter: 1519 loss: 0.00374358287
Iter: 1520 loss: 0.00374354143
Iter: 1521 loss: 0.00374352932
Iter: 1522 loss: 0.00374355051
Iter: 1523 loss: 0.00374352885
Iter: 1524 loss: 0.00374351558
Iter: 1525 loss: 0.00374363014
Iter: 1526 loss: 0.00374351605
Iter: 1527 loss: 0.00374351349
Iter: 1528 loss: 0.00374350743
Iter: 1529 loss: 0.0037435058
Iter: 1530 loss: 0.00374349533
Iter: 1531 loss: 0.0037435398
Iter: 1532 loss: 0.00374349137
Iter: 1533 loss: 0.00374348368
Iter: 1534 loss: 0.0037435093
Iter: 1535 loss: 0.00374348136
Iter: 1536 loss: 0.00374347251
Iter: 1537 loss: 0.00374346063
Iter: 1538 loss: 0.0037434618
Iter: 1539 loss: 0.00374344736
Iter: 1540 loss: 0.003743432
Iter: 1541 loss: 0.00374342711
Iter: 1542 loss: 0.0037434157
Iter: 1543 loss: 0.00374341127
Iter: 1544 loss: 0.0037434008
Iter: 1545 loss: 0.00374338496
Iter: 1546 loss: 0.00374338729
Iter: 1547 loss: 0.00374336867
Iter: 1548 loss: 0.00374351745
Iter: 1549 loss: 0.00374336913
Iter: 1550 loss: 0.00374335563
Iter: 1551 loss: 0.00374346739
Iter: 1552 loss: 0.0037433533
Iter: 1553 loss: 0.00374335097
Iter: 1554 loss: 0.00374335563
Iter: 1555 loss: 0.00374334631
Iter: 1556 loss: 0.0037433384
Iter: 1557 loss: 0.00374333863
Iter: 1558 loss: 0.0037433356
Iter: 1559 loss: 0.00374332676
Iter: 1560 loss: 0.00374347437
Iter: 1561 loss: 0.00374333072
Iter: 1562 loss: 0.00374332
Iter: 1563 loss: 0.00374334306
Iter: 1564 loss: 0.00374331791
Iter: 1565 loss: 0.00374331046
Iter: 1566 loss: 0.00374332583
Iter: 1567 loss: 0.00374330836
Iter: 1568 loss: 0.00374330184
Iter: 1569 loss: 0.0037432923
Iter: 1570 loss: 0.0037432937
Iter: 1571 loss: 0.00374327647
Iter: 1572 loss: 0.00374326
Iter: 1573 loss: 0.00374325598
Iter: 1574 loss: 0.00374324201
Iter: 1575 loss: 0.00374324108
Iter: 1576 loss: 0.00374322594
Iter: 1577 loss: 0.00374321337
Iter: 1578 loss: 0.00374321
Iter: 1579 loss: 0.00374318939
Iter: 1580 loss: 0.00374326389
Iter: 1581 loss: 0.00374318752
Iter: 1582 loss: 0.00374316447
Iter: 1583 loss: 0.00374316727
Iter: 1584 loss: 0.00374316145
Iter: 1585 loss: 0.00374315144
Iter: 1586 loss: 0.00374315027
Iter: 1587 loss: 0.00374313816
Iter: 1588 loss: 0.00374326832
Iter: 1589 loss: 0.0037431377
Iter: 1590 loss: 0.00374313304
Iter: 1591 loss: 0.00374312582
Iter: 1592 loss: 0.00374312419
Iter: 1593 loss: 0.00374311744
Iter: 1594 loss: 0.00374323106
Iter: 1595 loss: 0.00374311814
Iter: 1596 loss: 0.00374310976
Iter: 1597 loss: 0.00374311325
Iter: 1598 loss: 0.00374310208
Iter: 1599 loss: 0.00374309043
Iter: 1600 loss: 0.00374307251
Iter: 1601 loss: 0.00374307344
Iter: 1602 loss: 0.00374305062
Iter: 1603 loss: 0.00374305039
Iter: 1604 loss: 0.00374302967
Iter: 1605 loss: 0.00374300871
Iter: 1606 loss: 0.00374329812
Iter: 1607 loss: 0.00374300918
Iter: 1608 loss: 0.00374298776
Iter: 1609 loss: 0.00374299567
Iter: 1610 loss: 0.00374297192
Iter: 1611 loss: 0.00374294282
Iter: 1612 loss: 0.00374289509
Iter: 1613 loss: 0.00374289742
Iter: 1614 loss: 0.0037429207
Iter: 1615 loss: 0.00374287297
Iter: 1616 loss: 0.00374286203
Iter: 1617 loss: 0.00374295795
Iter: 1618 loss: 0.00374285877
Iter: 1619 loss: 0.00374285085
Iter: 1620 loss: 0.00374289136
Iter: 1621 loss: 0.00374284852
Iter: 1622 loss: 0.00374284224
Iter: 1623 loss: 0.00374283548
Iter: 1624 loss: 0.00374283362
Iter: 1625 loss: 0.00374282221
Iter: 1626 loss: 0.00374284433
Iter: 1627 loss: 0.00374282151
Iter: 1628 loss: 0.00374280778
Iter: 1629 loss: 0.00374283362
Iter: 1630 loss: 0.00374280312
Iter: 1631 loss: 0.00374278962
Iter: 1632 loss: 0.00374279777
Iter: 1633 loss: 0.0037427838
Iter: 1634 loss: 0.00374277309
Iter: 1635 loss: 0.0037427803
Iter: 1636 loss: 0.0037427661
Iter: 1637 loss: 0.0037427519
Iter: 1638 loss: 0.00374276983
Iter: 1639 loss: 0.00374274771
Iter: 1640 loss: 0.00374273234
Iter: 1641 loss: 0.00374282012
Iter: 1642 loss: 0.00374272931
Iter: 1643 loss: 0.00374271907
Iter: 1644 loss: 0.00374270137
Iter: 1645 loss: 0.00374270068
Iter: 1646 loss: 0.00374268275
Iter: 1647 loss: 0.00374266785
Iter: 1648 loss: 0.00374266412
Iter: 1649 loss: 0.00374269858
Iter: 1650 loss: 0.00374265574
Iter: 1651 loss: 0.00374264666
Iter: 1652 loss: 0.00374267879
Iter: 1653 loss: 0.00374264619
Iter: 1654 loss: 0.00374264363
Iter: 1655 loss: 0.00374262128
Iter: 1656 loss: 0.00374270556
Iter: 1657 loss: 0.00374262
Iter: 1658 loss: 0.00374261569
Iter: 1659 loss: 0.00374261243
Iter: 1660 loss: 0.00374260405
Iter: 1661 loss: 0.00374260056
Iter: 1662 loss: 0.00374259846
Iter: 1663 loss: 0.00374258915
Iter: 1664 loss: 0.00374260708
Iter: 1665 loss: 0.00374258636
Iter: 1666 loss: 0.00374257239
Iter: 1667 loss: 0.00374257308
Iter: 1668 loss: 0.00374256913
Iter: 1669 loss: 0.00374255
Iter: 1670 loss: 0.00374255283
Iter: 1671 loss: 0.003742537
Iter: 1672 loss: 0.00374252629
Iter: 1673 loss: 0.00374252861
Iter: 1674 loss: 0.00374251604
Iter: 1675 loss: 0.00374253932
Iter: 1676 loss: 0.00374251534
Iter: 1677 loss: 0.00374250673
Iter: 1678 loss: 0.00374249555
Iter: 1679 loss: 0.00374249602
Iter: 1680 loss: 0.00374248764
Iter: 1681 loss: 0.00374255166
Iter: 1682 loss: 0.00374248717
Iter: 1683 loss: 0.00374248088
Iter: 1684 loss: 0.00374248181
Iter: 1685 loss: 0.00374248205
Iter: 1686 loss: 0.00374247739
Iter: 1687 loss: 0.00374247716
Iter: 1688 loss: 0.00374247087
Iter: 1689 loss: 0.0037424746
Iter: 1690 loss: 0.00374246901
Iter: 1691 loss: 0.00374246598
Iter: 1692 loss: 0.00374251069
Iter: 1693 loss: 0.00374246389
Iter: 1694 loss: 0.00374246272
Iter: 1695 loss: 0.00374245457
Iter: 1696 loss: 0.00374246016
Iter: 1697 loss: 0.00374245155
Iter: 1698 loss: 0.00374243641
Iter: 1699 loss: 0.0037427349
Iter: 1700 loss: 0.00374243502
Iter: 1701 loss: 0.00374242687
Iter: 1702 loss: 0.00374246365
Iter: 1703 loss: 0.00374242128
Iter: 1704 loss: 0.00374241266
Iter: 1705 loss: 0.00374248042
Iter: 1706 loss: 0.00374241034
Iter: 1707 loss: 0.00374240102
Iter: 1708 loss: 0.00374243781
Iter: 1709 loss: 0.00374240382
Iter: 1710 loss: 0.00374239334
Iter: 1711 loss: 0.00374239148
Iter: 1712 loss: 0.00374239031
Iter: 1713 loss: 0.00374239404
Iter: 1714 loss: 0.0037423824
Iter: 1715 loss: 0.00374237821
Iter: 1716 loss: 0.00374243921
Iter: 1717 loss: 0.00374237914
Iter: 1718 loss: 0.00374237797
Iter: 1719 loss: 0.00374237262
Iter: 1720 loss: 0.0037423817
Iter: 1721 loss: 0.00374237052
Iter: 1722 loss: 0.00374235818
Iter: 1723 loss: 0.00374237495
Iter: 1724 loss: 0.00374235515
Iter: 1725 loss: 0.0037423477
Iter: 1726 loss: 0.00374234561
Iter: 1727 loss: 0.00374234025
Iter: 1728 loss: 0.00374233583
Iter: 1729 loss: 0.00374233699
Iter: 1730 loss: 0.00374232884
Iter: 1731 loss: 0.00374237122
Iter: 1732 loss: 0.00374232791
Iter: 1733 loss: 0.0037423186
Iter: 1734 loss: 0.0037423179
Iter: 1735 loss: 0.00374231441
Iter: 1736 loss: 0.00374230649
Iter: 1737 loss: 0.00374238146
Iter: 1738 loss: 0.00374230812
Iter: 1739 loss: 0.00374229951
Iter: 1740 loss: 0.00374232465
Iter: 1741 loss: 0.0037423016
Iter: 1742 loss: 0.00374229741
Iter: 1743 loss: 0.00374229206
Iter: 1744 loss: 0.00374228833
Iter: 1745 loss: 0.00374228181
Iter: 1746 loss: 0.00374229532
Iter: 1747 loss: 0.00374228088
Iter: 1748 loss: 0.00374230137
Iter: 1749 loss: 0.00374227879
Iter: 1750 loss: 0.00374227902
Iter: 1751 loss: 0.0037422739
Iter: 1752 loss: 0.00374228531
Iter: 1753 loss: 0.00374227483
Iter: 1754 loss: 0.0037422704
Iter: 1755 loss: 0.00374228414
Iter: 1756 loss: 0.00374226784
Iter: 1757 loss: 0.00374226645
Iter: 1758 loss: 0.00374226552
Iter: 1759 loss: 0.00374226482
Iter: 1760 loss: 0.00374226831
Iter: 1761 loss: 0.00374226365
Iter: 1762 loss: 0.00374226505
Iter: 1763 loss: 0.00374226202
Iter: 1764 loss: 0.00374226226
Iter: 1765 loss: 0.00374225853
Iter: 1766 loss: 0.00374226132
Iter: 1767 loss: 0.00374225574
Iter: 1768 loss: 0.00374225597
Iter: 1769 loss: 0.00374225085
Iter: 1770 loss: 0.00374226831
Iter: 1771 loss: 0.00374224875
Iter: 1772 loss: 0.00374224875
Iter: 1773 loss: 0.00374224898
Iter: 1774 loss: 0.00374224083
Iter: 1775 loss: 0.00374224572
Iter: 1776 loss: 0.00374224223
Iter: 1777 loss: 0.00374223641
Iter: 1778 loss: 0.00374223851
Iter: 1779 loss: 0.00374223315
Iter: 1780 loss: 0.00374222733
Iter: 1781 loss: 0.00374224689
Iter: 1782 loss: 0.00374222733
Iter: 1783 loss: 0.00374222547
Iter: 1784 loss: 0.00374222593
Iter: 1785 loss: 0.00374222407
Iter: 1786 loss: 0.00374221965
Iter: 1787 loss: 0.00374225248
Iter: 1788 loss: 0.00374222081
Iter: 1789 loss: 0.00374221429
Iter: 1790 loss: 0.00374223408
Iter: 1791 loss: 0.00374221266
Iter: 1792 loss: 0.00374221709
Iter: 1793 loss: 0.0037422087
Iter: 1794 loss: 0.00374220987
Iter: 1795 loss: 0.00374220498
Iter: 1796 loss: 0.00374223711
Iter: 1797 loss: 0.00374220498
Iter: 1798 loss: 0.00374220358
Iter: 1799 loss: 0.00374221895
Iter: 1800 loss: 0.00374219776
Iter: 1801 loss: 0.00374219706
Iter: 1802 loss: 0.0037421966
Iter: 1803 loss: 0.00374219567
Iter: 1804 loss: 0.00374219287
Iter: 1805 loss: 0.00374219101
Iter: 1806 loss: 0.00374218961
Iter: 1807 loss: 0.00374218659
Iter: 1808 loss: 0.00374218426
Iter: 1809 loss: 0.00374218076
Iter: 1810 loss: 0.0037421789
Iter: 1811 loss: 0.00374217727
Iter: 1812 loss: 0.00374217518
Iter: 1813 loss: 0.00374216912
Iter: 1814 loss: 0.00374216796
Iter: 1815 loss: 0.00374216912
Iter: 1816 loss: 0.00374216586
Iter: 1817 loss: 0.0037421626
Iter: 1818 loss: 0.00374217331
Iter: 1819 loss: 0.00374216214
Iter: 1820 loss: 0.00374216028
Iter: 1821 loss: 0.00374215795
Iter: 1822 loss: 0.00374220638
Iter: 1823 loss: 0.00374215702
Iter: 1824 loss: 0.00374215934
Iter: 1825 loss: 0.00374215702
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3
+ date
Tue Oct 27 17:48:12 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -2 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdf049158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ff3a24730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ff3a57e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdefa32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdef6b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdef6bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeeef598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdef1a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdef1a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeeaaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdee868c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdee90e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeea0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeea0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdee39510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeea0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdedbe0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdedbeea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdedd2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fded3cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fded4d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fded4db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdecba598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdecd1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdec6e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdec98268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdec54488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdebf6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdebf6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdebae8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeb66598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeb93488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeb93e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeb2db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeb93400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fdeb19ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0302161649
Iter: 2 loss: 1.17282152
Iter: 3 loss: 1.13114524
Iter: 4 loss: 0.735172033
Iter: 5 loss: 0.702383637
Iter: 6 loss: 0.449520707
Iter: 7 loss: 0.419086456
Iter: 8 loss: 0.251732498
Iter: 9 loss: 0.223387748
Iter: 10 loss: 0.119541734
Iter: 11 loss: 0.0979447961
Iter: 12 loss: 0.0450104661
Iter: 13 loss: 0.0348200127
Iter: 14 loss: 0.0171624348
Iter: 15 loss: 0.015853947
Iter: 16 loss: 0.014830675
Iter: 17 loss: 0.0132405218
Iter: 18 loss: 0.0131492512
Iter: 19 loss: 0.0121092796
Iter: 20 loss: 0.0108836181
Iter: 21 loss: 0.0106485244
Iter: 22 loss: 0.00796970911
Iter: 23 loss: 0.0177895371
Iter: 24 loss: 0.00784704369
Iter: 25 loss: 0.00735503063
Iter: 26 loss: 0.00873704534
Iter: 27 loss: 0.00714665744
Iter: 28 loss: 0.00686108926
Iter: 29 loss: 0.00726638408
Iter: 30 loss: 0.00671557058
Iter: 31 loss: 0.00619777199
Iter: 32 loss: 0.0065171537
Iter: 33 loss: 0.005913998
Iter: 34 loss: 0.00555990729
Iter: 35 loss: 0.00591665553
Iter: 36 loss: 0.00536895171
Iter: 37 loss: 0.00507032499
Iter: 38 loss: 0.0060315812
Iter: 39 loss: 0.00497235544
Iter: 40 loss: 0.00480883662
Iter: 41 loss: 0.00497276
Iter: 42 loss: 0.00472473446
Iter: 43 loss: 0.00463608187
Iter: 44 loss: 0.00493938662
Iter: 45 loss: 0.00461481139
Iter: 46 loss: 0.0045529129
Iter: 47 loss: 0.00463102525
Iter: 48 loss: 0.00451932661
Iter: 49 loss: 0.00447315397
Iter: 50 loss: 0.00447796751
Iter: 51 loss: 0.00443820655
Iter: 52 loss: 0.00438711
Iter: 53 loss: 0.004353147
Iter: 54 loss: 0.00433484651
Iter: 55 loss: 0.00429002242
Iter: 56 loss: 0.00446348358
Iter: 57 loss: 0.00427897042
Iter: 58 loss: 0.00424828101
Iter: 59 loss: 0.00428913394
Iter: 60 loss: 0.00423296029
Iter: 61 loss: 0.00422213459
Iter: 62 loss: 0.00421472872
Iter: 63 loss: 0.00419558259
Iter: 64 loss: 0.00426690467
Iter: 65 loss: 0.00419128733
Iter: 66 loss: 0.00418230705
Iter: 67 loss: 0.00416992512
Iter: 68 loss: 0.00416936073
Iter: 69 loss: 0.00415371638
Iter: 70 loss: 0.0041563022
Iter: 71 loss: 0.0041420497
Iter: 72 loss: 0.00412437832
Iter: 73 loss: 0.00415120088
Iter: 74 loss: 0.00411591167
Iter: 75 loss: 0.00410258118
Iter: 76 loss: 0.00427250238
Iter: 77 loss: 0.00410249317
Iter: 78 loss: 0.00409168284
Iter: 79 loss: 0.00417268788
Iter: 80 loss: 0.00409076735
Iter: 81 loss: 0.00408083061
Iter: 82 loss: 0.00410268363
Iter: 83 loss: 0.00407715142
Iter: 84 loss: 0.00406725658
Iter: 85 loss: 0.00407556631
Iter: 86 loss: 0.00406148843
Iter: 87 loss: 0.00405322714
Iter: 88 loss: 0.00407124218
Iter: 89 loss: 0.00404999871
Iter: 90 loss: 0.00404257374
Iter: 91 loss: 0.00407324918
Iter: 92 loss: 0.00404097559
Iter: 93 loss: 0.00403384306
Iter: 94 loss: 0.00408260711
Iter: 95 loss: 0.00403309613
Iter: 96 loss: 0.00402842509
Iter: 97 loss: 0.00402834825
Iter: 98 loss: 0.00402639247
Iter: 99 loss: 0.00402374752
Iter: 100 loss: 0.00402360782
Iter: 101 loss: 0.00401958264
Iter: 102 loss: 0.00402434357
Iter: 103 loss: 0.00401746109
Iter: 104 loss: 0.00401343312
Iter: 105 loss: 0.00401431136
Iter: 106 loss: 0.00401045661
Iter: 107 loss: 0.00400564913
Iter: 108 loss: 0.0040163314
Iter: 109 loss: 0.00400383445
Iter: 110 loss: 0.00399921136
Iter: 111 loss: 0.0040218858
Iter: 112 loss: 0.00399839133
Iter: 113 loss: 0.00399507396
Iter: 114 loss: 0.00399505766
Iter: 115 loss: 0.00399307441
Iter: 116 loss: 0.00399210444
Iter: 117 loss: 0.00399115775
Iter: 118 loss: 0.00398882059
Iter: 119 loss: 0.00400233967
Iter: 120 loss: 0.00398850534
Iter: 121 loss: 0.00398654956
Iter: 122 loss: 0.00398718379
Iter: 123 loss: 0.00398516608
Iter: 124 loss: 0.00398261
Iter: 125 loss: 0.0039880625
Iter: 126 loss: 0.00398161029
Iter: 127 loss: 0.00398039352
Iter: 128 loss: 0.00398012344
Iter: 129 loss: 0.00397874275
Iter: 130 loss: 0.00398020819
Iter: 131 loss: 0.00397797767
Iter: 132 loss: 0.00397686427
Iter: 133 loss: 0.00397809129
Iter: 134 loss: 0.00397626404
Iter: 135 loss: 0.00397499278
Iter: 136 loss: 0.00397384027
Iter: 137 loss: 0.00397352362
Iter: 138 loss: 0.00397135178
Iter: 139 loss: 0.00397799024
Iter: 140 loss: 0.0039707087
Iter: 141 loss: 0.00396890845
Iter: 142 loss: 0.00396868959
Iter: 143 loss: 0.00396739831
Iter: 144 loss: 0.00396591146
Iter: 145 loss: 0.0039658295
Iter: 146 loss: 0.00396448374
Iter: 147 loss: 0.0039673741
Iter: 148 loss: 0.00396395288
Iter: 149 loss: 0.00396253634
Iter: 150 loss: 0.00396167673
Iter: 151 loss: 0.00396109698
Iter: 152 loss: 0.00395988068
Iter: 153 loss: 0.00395986717
Iter: 154 loss: 0.00395886088
Iter: 155 loss: 0.00395909138
Iter: 156 loss: 0.00395811861
Iter: 157 loss: 0.00395696331
Iter: 158 loss: 0.00396573357
Iter: 159 loss: 0.00395687949
Iter: 160 loss: 0.0039558569
Iter: 161 loss: 0.00396399479
Iter: 162 loss: 0.00395578239
Iter: 163 loss: 0.00395501032
Iter: 164 loss: 0.00395471137
Iter: 165 loss: 0.00395429274
Iter: 166 loss: 0.00395319331
Iter: 167 loss: 0.00395342149
Iter: 168 loss: 0.00395237794
Iter: 169 loss: 0.00395075418
Iter: 170 loss: 0.00395360403
Iter: 171 loss: 0.00395004218
Iter: 172 loss: 0.00394852459
Iter: 173 loss: 0.00394940469
Iter: 174 loss: 0.00394753832
Iter: 175 loss: 0.0039459127
Iter: 176 loss: 0.00395211438
Iter: 177 loss: 0.00394552294
Iter: 178 loss: 0.00394417066
Iter: 179 loss: 0.00395576935
Iter: 180 loss: 0.00394409196
Iter: 181 loss: 0.00394283654
Iter: 182 loss: 0.00394747499
Iter: 183 loss: 0.00394252595
Iter: 184 loss: 0.00394183584
Iter: 185 loss: 0.00394056737
Iter: 186 loss: 0.00397054479
Iter: 187 loss: 0.00394056831
Iter: 188 loss: 0.00393904187
Iter: 189 loss: 0.0039588022
Iter: 190 loss: 0.00393903116
Iter: 191 loss: 0.00393797737
Iter: 192 loss: 0.00394533295
Iter: 193 loss: 0.00393788051
Iter: 194 loss: 0.00393720064
Iter: 195 loss: 0.00394281559
Iter: 196 loss: 0.0039371578
Iter: 197 loss: 0.00393654965
Iter: 198 loss: 0.00393620227
Iter: 199 loss: 0.00393594336
Iter: 200 loss: 0.00393511448
Iter: 201 loss: 0.00393610634
Iter: 202 loss: 0.00393467862
Iter: 203 loss: 0.00393383624
Iter: 204 loss: 0.00393574219
Iter: 205 loss: 0.00393352
Iter: 206 loss: 0.0039326814
Iter: 207 loss: 0.00393417384
Iter: 208 loss: 0.00393231213
Iter: 209 loss: 0.00393140782
Iter: 210 loss: 0.00393252634
Iter: 211 loss: 0.00393093657
Iter: 212 loss: 0.00393007789
Iter: 213 loss: 0.0039341636
Iter: 214 loss: 0.00392991677
Iter: 215 loss: 0.00392912515
Iter: 216 loss: 0.0039367
Iter: 217 loss: 0.00392909814
Iter: 218 loss: 0.00392858637
Iter: 219 loss: 0.00392894447
Iter: 220 loss: 0.0039282674
Iter: 221 loss: 0.00392772723
Iter: 222 loss: 0.00392754329
Iter: 223 loss: 0.00392723456
Iter: 224 loss: 0.00392651837
Iter: 225 loss: 0.0039367443
Iter: 226 loss: 0.00392652117
Iter: 227 loss: 0.00392608065
Iter: 228 loss: 0.00393132586
Iter: 229 loss: 0.00392607506
Iter: 230 loss: 0.00392569788
Iter: 231 loss: 0.00392546784
Iter: 232 loss: 0.0039253179
Iter: 233 loss: 0.00392485363
Iter: 234 loss: 0.00392599171
Iter: 235 loss: 0.00392469
Iter: 236 loss: 0.00392423803
Iter: 237 loss: 0.00392436795
Iter: 238 loss: 0.00392391253
Iter: 239 loss: 0.00392329041
Iter: 240 loss: 0.00392534724
Iter: 241 loss: 0.00392311905
Iter: 242 loss: 0.00392256305
Iter: 243 loss: 0.00392325968
Iter: 244 loss: 0.0039222762
Iter: 245 loss: 0.00392171554
Iter: 246 loss: 0.00392364524
Iter: 247 loss: 0.00392156513
Iter: 248 loss: 0.00392108737
Iter: 249 loss: 0.0039247917
Iter: 250 loss: 0.00392105384
Iter: 251 loss: 0.00392059423
Iter: 252 loss: 0.0039214897
Iter: 253 loss: 0.00392040331
Iter: 254 loss: 0.00392001029
Iter: 255 loss: 0.003919743
Iter: 256 loss: 0.00391959492
Iter: 257 loss: 0.00391904637
Iter: 258 loss: 0.00392438425
Iter: 259 loss: 0.00391902681
Iter: 260 loss: 0.00391867664
Iter: 261 loss: 0.00392388413
Iter: 262 loss: 0.0039186785
Iter: 263 loss: 0.00391837955
Iter: 264 loss: 0.00391860958
Iter: 265 loss: 0.00391820027
Iter: 266 loss: 0.00391790317
Iter: 267 loss: 0.00391780352
Iter: 268 loss: 0.00391763728
Iter: 269 loss: 0.00391722843
Iter: 270 loss: 0.00391840655
Iter: 271 loss: 0.00391710177
Iter: 272 loss: 0.00391669478
Iter: 273 loss: 0.00391727034
Iter: 274 loss: 0.00391649455
Iter: 275 loss: 0.00391604146
Iter: 276 loss: 0.00391737744
Iter: 277 loss: 0.00391590409
Iter: 278 loss: 0.00391547848
Iter: 279 loss: 0.00391595066
Iter: 280 loss: 0.00391525077
Iter: 281 loss: 0.00391481165
Iter: 282 loss: 0.00391661422
Iter: 283 loss: 0.00391471852
Iter: 284 loss: 0.00391428219
Iter: 285 loss: 0.00391793624
Iter: 286 loss: 0.00391425751
Iter: 287 loss: 0.00391401723
Iter: 288 loss: 0.00391411781
Iter: 289 loss: 0.00391384959
Iter: 290 loss: 0.00391355902
Iter: 291 loss: 0.00391387707
Iter: 292 loss: 0.00391339837
Iter: 293 loss: 0.00391324284
Iter: 294 loss: 0.00391319674
Iter: 295 loss: 0.0039130263
Iter: 296 loss: 0.00391324796
Iter: 297 loss: 0.00391293876
Iter: 298 loss: 0.00391275343
Iter: 299 loss: 0.00391249591
Iter: 300 loss: 0.00391248241
Iter: 301 loss: 0.00391217787
Iter: 302 loss: 0.00391353
Iter: 303 loss: 0.003912115
Iter: 304 loss: 0.00391183794
Iter: 305 loss: 0.00391234178
Iter: 306 loss: 0.00391171593
Iter: 307 loss: 0.00391143654
Iter: 308 loss: 0.00391212199
Iter: 309 loss: 0.00391134
Iter: 310 loss: 0.00391103653
Iter: 311 loss: 0.00391155295
Iter: 312 loss: 0.00391089963
Iter: 313 loss: 0.00391062815
Iter: 314 loss: 0.00391106028
Iter: 315 loss: 0.00391050102
Iter: 316 loss: 0.00391026819
Iter: 317 loss: 0.00391026866
Iter: 318 loss: 0.00391010148
Iter: 319 loss: 0.00391014758
Iter: 320 loss: 0.00390998228
Iter: 321 loss: 0.00390979555
Iter: 322 loss: 0.00390985422
Iter: 323 loss: 0.0039096633
Iter: 324 loss: 0.00390955154
Iter: 325 loss: 0.00390953198
Iter: 326 loss: 0.00390940905
Iter: 327 loss: 0.00390984491
Iter: 328 loss: 0.00390937924
Iter: 329 loss: 0.00390927587
Iter: 330 loss: 0.00390911521
Iter: 331 loss: 0.00390911428
Iter: 332 loss: 0.00390892802
Iter: 333 loss: 0.00390937831
Iter: 334 loss: 0.00390886143
Iter: 335 loss: 0.00390868587
Iter: 336 loss: 0.00390930939
Iter: 337 loss: 0.00390864164
Iter: 338 loss: 0.003908474
Iter: 339 loss: 0.00390877109
Iter: 340 loss: 0.00390840136
Iter: 341 loss: 0.0039082272
Iter: 342 loss: 0.00390862254
Iter: 343 loss: 0.00390816061
Iter: 344 loss: 0.00390796084
Iter: 345 loss: 0.00390824955
Iter: 346 loss: 0.00390786445
Iter: 347 loss: 0.00390770286
Iter: 348 loss: 0.00390902348
Iter: 349 loss: 0.00390769355
Iter: 350 loss: 0.00390753523
Iter: 351 loss: 0.00390796829
Iter: 352 loss: 0.00390748587
Iter: 353 loss: 0.00390736386
Iter: 354 loss: 0.00390729774
Iter: 355 loss: 0.00390724279
Iter: 356 loss: 0.00390711054
Iter: 357 loss: 0.00390900951
Iter: 358 loss: 0.00390710821
Iter: 359 loss: 0.00390701415
Iter: 360 loss: 0.00390843302
Iter: 361 loss: 0.00390701648
Iter: 362 loss: 0.00390695501
Iter: 363 loss: 0.00390684092
Iter: 364 loss: 0.00390928192
Iter: 365 loss: 0.00390684
Iter: 366 loss: 0.00390671473
Iter: 367 loss: 0.0039069932
Iter: 368 loss: 0.0039066649
Iter: 369 loss: 0.00390656572
Iter: 370 loss: 0.00390691124
Iter: 371 loss: 0.00390653918
Iter: 372 loss: 0.00390642788
Iter: 373 loss: 0.00390661
Iter: 374 loss: 0.00390637526
Iter: 375 loss: 0.00390626024
Iter: 376 loss: 0.00390648656
Iter: 377 loss: 0.00390621508
Iter: 378 loss: 0.00390607538
Iter: 379 loss: 0.00390636828
Iter: 380 loss: 0.00390602252
Iter: 381 loss: 0.00390590494
Iter: 382 loss: 0.00390641252
Iter: 383 loss: 0.00390588026
Iter: 384 loss: 0.00390577456
Iter: 385 loss: 0.0039065415
Iter: 386 loss: 0.00390576478
Iter: 387 loss: 0.0039056791
Iter: 388 loss: 0.00390565488
Iter: 389 loss: 0.00390560436
Iter: 390 loss: 0.00390549749
Iter: 391 loss: 0.00390554476
Iter: 392 loss: 0.00390542764
Iter: 393 loss: 0.00390545512
Iter: 394 loss: 0.00390536478
Iter: 395 loss: 0.00390532496
Iter: 396 loss: 0.00390525581
Iter: 397 loss: 0.00390525907
Iter: 398 loss: 0.00390518853
Iter: 399 loss: 0.00390524417
Iter: 400 loss: 0.00390514871
Iter: 401 loss: 0.00390507
Iter: 402 loss: 0.00390518
Iter: 403 loss: 0.00390503393
Iter: 404 loss: 0.00390494475
Iter: 405 loss: 0.00390537223
Iter: 406 loss: 0.00390493288
Iter: 407 loss: 0.00390485697
Iter: 408 loss: 0.00390503881
Iter: 409 loss: 0.00390483253
Iter: 410 loss: 0.00390475709
Iter: 411 loss: 0.00390486792
Iter: 412 loss: 0.00390472403
Iter: 413 loss: 0.00390464114
Iter: 414 loss: 0.00390487979
Iter: 415 loss: 0.00390461367
Iter: 416 loss: 0.00390454102
Iter: 417 loss: 0.00390500622
Iter: 418 loss: 0.00390452985
Iter: 419 loss: 0.00390446419
Iter: 420 loss: 0.00390474405
Iter: 421 loss: 0.00390444859
Iter: 422 loss: 0.00390440691
Iter: 423 loss: 0.00390434032
Iter: 424 loss: 0.00390433753
Iter: 425 loss: 0.00390431401
Iter: 426 loss: 0.00390429934
Iter: 427 loss: 0.00390425301
Iter: 428 loss: 0.00390434
Iter: 429 loss: 0.00390423695
Iter: 430 loss: 0.00390420738
Iter: 431 loss: 0.00390415965
Iter: 432 loss: 0.00390415848
Iter: 433 loss: 0.00390409678
Iter: 434 loss: 0.00390428794
Iter: 435 loss: 0.00390407909
Iter: 436 loss: 0.00390403252
Iter: 437 loss: 0.00390418665
Iter: 438 loss: 0.00390401762
Iter: 439 loss: 0.00390397129
Iter: 440 loss: 0.00390412542
Iter: 441 loss: 0.00390395895
Iter: 442 loss: 0.00390391285
Iter: 443 loss: 0.00390400598
Iter: 444 loss: 0.00390389538
Iter: 445 loss: 0.00390385278
Iter: 446 loss: 0.00390399876
Iter: 447 loss: 0.00390384137
Iter: 448 loss: 0.00390379573
Iter: 449 loss: 0.0039038863
Iter: 450 loss: 0.00390377967
Iter: 451 loss: 0.00390374102
Iter: 452 loss: 0.00390410959
Iter: 453 loss: 0.00390373869
Iter: 454 loss: 0.00390371168
Iter: 455 loss: 0.00390369073
Iter: 456 loss: 0.00390368234
Iter: 457 loss: 0.00390363391
Iter: 458 loss: 0.00390368258
Iter: 459 loss: 0.00390360737
Iter: 460 loss: 0.003903626
Iter: 461 loss: 0.00390359107
Iter: 462 loss: 0.00390357198
Iter: 463 loss: 0.00390353054
Iter: 464 loss: 0.00390398479
Iter: 465 loss: 0.00390352565
Iter: 466 loss: 0.00390349422
Iter: 467 loss: 0.00390358805
Iter: 468 loss: 0.00390348234
Iter: 469 loss: 0.00390344812
Iter: 470 loss: 0.00390350446
Iter: 471 loss: 0.00390343089
Iter: 472 loss: 0.00390339666
Iter: 473 loss: 0.00390351214
Iter: 474 loss: 0.00390338711
Iter: 475 loss: 0.00390335312
Iter: 476 loss: 0.00390347373
Iter: 477 loss: 0.00390334427
Iter: 478 loss: 0.00390331261
Iter: 479 loss: 0.0039033615
Iter: 480 loss: 0.0039033
Iter: 481 loss: 0.00390326697
Iter: 482 loss: 0.00390344509
Iter: 483 loss: 0.00390326139
Iter: 484 loss: 0.00390323717
Iter: 485 loss: 0.00390332146
Iter: 486 loss: 0.00390322832
Iter: 487 loss: 0.00390320318
Iter: 488 loss: 0.00390323251
Iter: 489 loss: 0.00390318711
Iter: 490 loss: 0.00390315708
Iter: 491 loss: 0.00390321692
Iter: 492 loss: 0.00390314963
Iter: 493 loss: 0.00390312
Iter: 494 loss: 0.00390315847
Iter: 495 loss: 0.00390310679
Iter: 496 loss: 0.00390311168
Iter: 497 loss: 0.00390309189
Iter: 498 loss: 0.0039030842
Iter: 499 loss: 0.00390305975
Iter: 500 loss: 0.00390311144
Iter: 501 loss: 0.00390304555
Iter: 502 loss: 0.00390301552
Iter: 503 loss: 0.00390310329
Iter: 504 loss: 0.00390300504
Iter: 505 loss: 0.00390297826
Iter: 506 loss: 0.00390313
Iter: 507 loss: 0.00390297454
Iter: 508 loss: 0.00390295195
Iter: 509 loss: 0.00390300923
Iter: 510 loss: 0.00390294357
Iter: 511 loss: 0.00390292378
Iter: 512 loss: 0.00390303694
Iter: 513 loss: 0.00390292099
Iter: 514 loss: 0.00390290236
Iter: 515 loss: 0.00390291237
Iter: 516 loss: 0.00390288793
Iter: 517 loss: 0.00390286813
Iter: 518 loss: 0.00390296523
Iter: 519 loss: 0.00390286534
Iter: 520 loss: 0.00390284974
Iter: 521 loss: 0.00390296988
Iter: 522 loss: 0.00390284741
Iter: 523 loss: 0.00390283531
Iter: 524 loss: 0.0039028367
Iter: 525 loss: 0.00390282436
Iter: 526 loss: 0.0039028062
Iter: 527 loss: 0.00390284462
Iter: 528 loss: 0.00390280015
Iter: 529 loss: 0.00390278804
Iter: 530 loss: 0.00390294427
Iter: 531 loss: 0.00390278781
Iter: 532 loss: 0.00390277314
Iter: 533 loss: 0.00390275568
Iter: 534 loss: 0.00390275475
Iter: 535 loss: 0.00390274194
Iter: 536 loss: 0.00390273123
Iter: 537 loss: 0.00390272588
Iter: 538 loss: 0.00390270795
Iter: 539 loss: 0.00390276127
Iter: 540 loss: 0.00390269933
Iter: 541 loss: 0.00390267931
Iter: 542 loss: 0.00390275661
Iter: 543 loss: 0.00390267046
Iter: 544 loss: 0.00390265509
Iter: 545 loss: 0.00390270306
Iter: 546 loss: 0.00390264741
Iter: 547 loss: 0.00390262972
Iter: 548 loss: 0.00390273938
Iter: 549 loss: 0.0039026232
Iter: 550 loss: 0.00390260853
Iter: 551 loss: 0.00390262692
Iter: 552 loss: 0.00390259968
Iter: 553 loss: 0.00390258711
Iter: 554 loss: 0.00390269724
Iter: 555 loss: 0.00390258385
Iter: 556 loss: 0.00390257174
Iter: 557 loss: 0.00390258967
Iter: 558 loss: 0.00390256708
Iter: 559 loss: 0.00390255405
Iter: 560 loss: 0.00390259456
Iter: 561 loss: 0.00390255149
Iter: 562 loss: 0.00390254054
Iter: 563 loss: 0.00390260108
Iter: 564 loss: 0.00390253845
Iter: 565 loss: 0.00390252657
Iter: 566 loss: 0.00390257966
Iter: 567 loss: 0.00390252378
Iter: 568 loss: 0.00390251866
Iter: 569 loss: 0.00390250538
Iter: 570 loss: 0.00390263461
Iter: 571 loss: 0.00390250352
Iter: 572 loss: 0.00390248559
Iter: 573 loss: 0.00390253053
Iter: 574 loss: 0.00390247907
Iter: 575 loss: 0.00390246371
Iter: 576 loss: 0.00390256406
Iter: 577 loss: 0.00390246022
Iter: 578 loss: 0.00390244857
Iter: 579 loss: 0.00390247209
Iter: 580 loss: 0.00390244136
Iter: 581 loss: 0.00390242692
Iter: 582 loss: 0.00390247884
Iter: 583 loss: 0.0039024204
Iter: 584 loss: 0.00390240573
Iter: 585 loss: 0.00390246278
Iter: 586 loss: 0.00390240201
Iter: 587 loss: 0.00390238781
Iter: 588 loss: 0.00390241691
Iter: 589 loss: 0.00390238222
Iter: 590 loss: 0.00390236848
Iter: 591 loss: 0.00390246231
Iter: 592 loss: 0.00390236732
Iter: 593 loss: 0.00390235893
Iter: 594 loss: 0.00390236382
Iter: 595 loss: 0.00390234985
Iter: 596 loss: 0.00390234264
Iter: 597 loss: 0.00390241924
Iter: 598 loss: 0.00390234147
Iter: 599 loss: 0.00390233123
Iter: 600 loss: 0.00390242343
Iter: 601 loss: 0.00390232773
Iter: 602 loss: 0.00390232587
Iter: 603 loss: 0.0039023133
Iter: 604 loss: 0.00390243134
Iter: 605 loss: 0.0039023119
Iter: 606 loss: 0.00390229886
Iter: 607 loss: 0.00390231353
Iter: 608 loss: 0.00390229211
Iter: 609 loss: 0.00390228024
Iter: 610 loss: 0.00390233984
Iter: 611 loss: 0.00390227512
Iter: 612 loss: 0.00390226301
Iter: 613 loss: 0.00390231982
Iter: 614 loss: 0.00390226045
Iter: 615 loss: 0.00390224671
Iter: 616 loss: 0.00390226813
Iter: 617 loss: 0.00390224089
Iter: 618 loss: 0.00390223041
Iter: 619 loss: 0.00390233099
Iter: 620 loss: 0.00390222808
Iter: 621 loss: 0.00390221947
Iter: 622 loss: 0.00390221644
Iter: 623 loss: 0.00390221109
Iter: 624 loss: 0.00390219782
Iter: 625 loss: 0.00390232401
Iter: 626 loss: 0.00390219758
Iter: 627 loss: 0.0039021913
Iter: 628 loss: 0.00390219642
Iter: 629 loss: 0.00390218641
Iter: 630 loss: 0.00390217779
Iter: 631 loss: 0.0039022183
Iter: 632 loss: 0.00390217523
Iter: 633 loss: 0.00390217174
Iter: 634 loss: 0.00390217081
Iter: 635 loss: 0.00390216592
Iter: 636 loss: 0.00390215637
Iter: 637 loss: 0.00390220154
Iter: 638 loss: 0.00390215404
Iter: 639 loss: 0.00390213844
Iter: 640 loss: 0.00390216592
Iter: 641 loss: 0.00390213262
Iter: 642 loss: 0.00390211935
Iter: 643 loss: 0.00390215917
Iter: 644 loss: 0.00390211795
Iter: 645 loss: 0.00390210329
Iter: 646 loss: 0.00390216988
Iter: 647 loss: 0.00390209956
Iter: 648 loss: 0.00390208885
Iter: 649 loss: 0.00390211935
Iter: 650 loss: 0.00390208629
Iter: 651 loss: 0.00390207395
Iter: 652 loss: 0.00390211935
Iter: 653 loss: 0.00390207022
Iter: 654 loss: 0.00390205625
Iter: 655 loss: 0.00390208373
Iter: 656 loss: 0.00390205253
Iter: 657 loss: 0.00390204
Iter: 658 loss: 0.00390209397
Iter: 659 loss: 0.00390203809
Iter: 660 loss: 0.00390202738
Iter: 661 loss: 0.00390205323
Iter: 662 loss: 0.00390202482
Iter: 663 loss: 0.00390201644
Iter: 664 loss: 0.00390203367
Iter: 665 loss: 0.00390201272
Iter: 666 loss: 0.00390201085
Iter: 667 loss: 0.00390200689
Iter: 668 loss: 0.00390200363
Iter: 669 loss: 0.00390199432
Iter: 670 loss: 0.00390206
Iter: 671 loss: 0.00390199432
Iter: 672 loss: 0.00390198361
Iter: 673 loss: 0.00390199083
Iter: 674 loss: 0.00390197802
Iter: 675 loss: 0.00390196405
Iter: 676 loss: 0.00390197313
Iter: 677 loss: 0.00390195427
Iter: 678 loss: 0.00390194217
Iter: 679 loss: 0.00390207884
Iter: 680 loss: 0.00390194263
Iter: 681 loss: 0.0039019282
Iter: 682 loss: 0.00390194473
Iter: 683 loss: 0.00390192098
Iter: 684 loss: 0.0039019098
Iter: 685 loss: 0.00390196405
Iter: 686 loss: 0.00390190701
Iter: 687 loss: 0.00390189304
Iter: 688 loss: 0.00390193192
Iter: 689 loss: 0.00390188908
Iter: 690 loss: 0.00390187465
Iter: 691 loss: 0.0039019268
Iter: 692 loss: 0.00390187232
Iter: 693 loss: 0.00390186138
Iter: 694 loss: 0.00390188792
Iter: 695 loss: 0.00390185649
Iter: 696 loss: 0.00390184601
Iter: 697 loss: 0.00390185672
Iter: 698 loss: 0.00390184019
Iter: 699 loss: 0.003901836
Iter: 700 loss: 0.00390183087
Iter: 701 loss: 0.00390182785
Iter: 702 loss: 0.00390181621
Iter: 703 loss: 0.00390195
Iter: 704 loss: 0.00390181364
Iter: 705 loss: 0.00390180293
Iter: 706 loss: 0.00390181364
Iter: 707 loss: 0.00390179455
Iter: 708 loss: 0.00390178338
Iter: 709 loss: 0.00390180014
Iter: 710 loss: 0.00390177686
Iter: 711 loss: 0.00390176405
Iter: 712 loss: 0.00390181644
Iter: 713 loss: 0.00390176
Iter: 714 loss: 0.00390174449
Iter: 715 loss: 0.0039018034
Iter: 716 loss: 0.0039017424
Iter: 717 loss: 0.00390172563
Iter: 718 loss: 0.00390178128
Iter: 719 loss: 0.00390172377
Iter: 720 loss: 0.00390171329
Iter: 721 loss: 0.00390176079
Iter: 722 loss: 0.0039017098
Iter: 723 loss: 0.00390169839
Iter: 724 loss: 0.00390172377
Iter: 725 loss: 0.00390169444
Iter: 726 loss: 0.00390168699
Iter: 727 loss: 0.00390175614
Iter: 728 loss: 0.00390168466
Iter: 729 loss: 0.00390167651
Iter: 730 loss: 0.00390167092
Iter: 731 loss: 0.00390166766
Iter: 732 loss: 0.00390166789
Iter: 733 loss: 0.00390166277
Iter: 734 loss: 0.00390165648
Iter: 735 loss: 0.00390164834
Iter: 736 loss: 0.00390178571
Iter: 737 loss: 0.00390164694
Iter: 738 loss: 0.00390163972
Iter: 739 loss: 0.00390164321
Iter: 740 loss: 0.00390163111
Iter: 741 loss: 0.0039016204
Iter: 742 loss: 0.00390162715
Iter: 743 loss: 0.00390161434
Iter: 744 loss: 0.00390160293
Iter: 745 loss: 0.00390167907
Iter: 746 loss: 0.0039016027
Iter: 747 loss: 0.00390159
Iter: 748 loss: 0.0039016197
Iter: 749 loss: 0.00390158733
Iter: 750 loss: 0.00390157662
Iter: 751 loss: 0.0039016162
Iter: 752 loss: 0.00390157336
Iter: 753 loss: 0.00390156405
Iter: 754 loss: 0.00390159851
Iter: 755 loss: 0.00390156242
Iter: 756 loss: 0.00390155194
Iter: 757 loss: 0.00390157872
Iter: 758 loss: 0.00390155
Iter: 759 loss: 0.0039015389
Iter: 760 loss: 0.00390159129
Iter: 761 loss: 0.00390153844
Iter: 762 loss: 0.00390152959
Iter: 763 loss: 0.00390153332
Iter: 764 loss: 0.0039015254
Iter: 765 loss: 0.00390152214
Iter: 766 loss: 0.00390152168
Iter: 767 loss: 0.00390151585
Iter: 768 loss: 0.0039015091
Iter: 769 loss: 0.0039015112
Iter: 770 loss: 0.00390150165
Iter: 771 loss: 0.00390149653
Iter: 772 loss: 0.00390149257
Iter: 773 loss: 0.00390148559
Iter: 774 loss: 0.00390150025
Iter: 775 loss: 0.00390148116
Iter: 776 loss: 0.00390147045
Iter: 777 loss: 0.0039014956
Iter: 778 loss: 0.00390146766
Iter: 779 loss: 0.00390145904
Iter: 780 loss: 0.0039015098
Iter: 781 loss: 0.00390145578
Iter: 782 loss: 0.00390144601
Iter: 783 loss: 0.00390148
Iter: 784 loss: 0.00390144624
Iter: 785 loss: 0.00390143925
Iter: 786 loss: 0.00390145229
Iter: 787 loss: 0.00390143436
Iter: 788 loss: 0.00390142482
Iter: 789 loss: 0.00390145089
Iter: 790 loss: 0.00390142
Iter: 791 loss: 0.00390141364
Iter: 792 loss: 0.00390148629
Iter: 793 loss: 0.00390141178
Iter: 794 loss: 0.0039014041
Iter: 795 loss: 0.00390140386
Iter: 796 loss: 0.00390139921
Iter: 797 loss: 0.00390139408
Iter: 798 loss: 0.00390139408
Iter: 799 loss: 0.00390138756
Iter: 800 loss: 0.00390138803
Iter: 801 loss: 0.00390138594
Iter: 802 loss: 0.00390138081
Iter: 803 loss: 0.00390137336
Iter: 804 loss: 0.00390137359
Iter: 805 loss: 0.00390136521
Iter: 806 loss: 0.00390138035
Iter: 807 loss: 0.00390136219
Iter: 808 loss: 0.00390135171
Iter: 809 loss: 0.00390136661
Iter: 810 loss: 0.00390134845
Iter: 811 loss: 0.00390133588
Iter: 812 loss: 0.00390137779
Iter: 813 loss: 0.00390133355
Iter: 814 loss: 0.00390132167
Iter: 815 loss: 0.00390139269
Iter: 816 loss: 0.00390132144
Iter: 817 loss: 0.00390131352
Iter: 818 loss: 0.00390131935
Iter: 819 loss: 0.00390130887
Iter: 820 loss: 0.00390129816
Iter: 821 loss: 0.00390134985
Iter: 822 loss: 0.00390129536
Iter: 823 loss: 0.00390128535
Iter: 824 loss: 0.00390133774
Iter: 825 loss: 0.00390128465
Iter: 826 loss: 0.00390127813
Iter: 827 loss: 0.00390128233
Iter: 828 loss: 0.00390127162
Iter: 829 loss: 0.00390126789
Iter: 830 loss: 0.00390126649
Iter: 831 loss: 0.00390126253
Iter: 832 loss: 0.00390126253
Iter: 833 loss: 0.00390125788
Iter: 834 loss: 0.00390125648
Iter: 835 loss: 0.00390124973
Iter: 836 loss: 0.00390124647
Iter: 837 loss: 0.00390124065
Iter: 838 loss: 0.00390125182
Iter: 839 loss: 0.00390123599
Iter: 840 loss: 0.00390122551
Iter: 841 loss: 0.00390123925
Iter: 842 loss: 0.00390122109
Iter: 843 loss: 0.00390120968
Iter: 844 loss: 0.00390124088
Iter: 845 loss: 0.00390120782
Iter: 846 loss: 0.00390119199
Iter: 847 loss: 0.00390128931
Iter: 848 loss: 0.00390119175
Iter: 849 loss: 0.00390118407
Iter: 850 loss: 0.00390119152
Iter: 851 loss: 0.00390117755
Iter: 852 loss: 0.00390116731
Iter: 853 loss: 0.00390121387
Iter: 854 loss: 0.00390116335
Iter: 855 loss: 0.00390115473
Iter: 856 loss: 0.00390119245
Iter: 857 loss: 0.00390115101
Iter: 858 loss: 0.00390114239
Iter: 859 loss: 0.00390116358
Iter: 860 loss: 0.0039011382
Iter: 861 loss: 0.00390113192
Iter: 862 loss: 0.00390119432
Iter: 863 loss: 0.00390113192
Iter: 864 loss: 0.00390112167
Iter: 865 loss: 0.00390115194
Iter: 866 loss: 0.00390112167
Iter: 867 loss: 0.00390111725
Iter: 868 loss: 0.003901107
Iter: 869 loss: 0.00390125322
Iter: 870 loss: 0.00390110584
Iter: 871 loss: 0.00390109327
Iter: 872 loss: 0.00390113657
Iter: 873 loss: 0.00390109187
Iter: 874 loss: 0.00390108163
Iter: 875 loss: 0.00390108465
Iter: 876 loss: 0.00390107417
Iter: 877 loss: 0.00390106137
Iter: 878 loss: 0.0039011084
Iter: 879 loss: 0.00390105648
Iter: 880 loss: 0.00390104158
Iter: 881 loss: 0.00390113331
Iter: 882 loss: 0.00390104065
Iter: 883 loss: 0.00390103
Iter: 884 loss: 0.00390105369
Iter: 885 loss: 0.00390102342
Iter: 886 loss: 0.00390101317
Iter: 887 loss: 0.00390104391
Iter: 888 loss: 0.00390100735
Iter: 889 loss: 0.00390099594
Iter: 890 loss: 0.00390105462
Iter: 891 loss: 0.00390099315
Iter: 892 loss: 0.00390098221
Iter: 893 loss: 0.00390101643
Iter: 894 loss: 0.00390097848
Iter: 895 loss: 0.00390097359
Iter: 896 loss: 0.00390103739
Iter: 897 loss: 0.00390097219
Iter: 898 loss: 0.00390096428
Iter: 899 loss: 0.00390101643
Iter: 900 loss: 0.00390096521
Iter: 901 loss: 0.00390096148
Iter: 902 loss: 0.00390095217
Iter: 903 loss: 0.00390101224
Iter: 904 loss: 0.00390094914
Iter: 905 loss: 0.00390093657
Iter: 906 loss: 0.00390100968
Iter: 907 loss: 0.00390093564
Iter: 908 loss: 0.00390092609
Iter: 909 loss: 0.00390092586
Iter: 910 loss: 0.00390092144
Iter: 911 loss: 0.00390090654
Iter: 912 loss: 0.00390094402
Iter: 913 loss: 0.00390090304
Iter: 914 loss: 0.00390088977
Iter: 915 loss: 0.00390096777
Iter: 916 loss: 0.00390088744
Iter: 917 loss: 0.00390087813
Iter: 918 loss: 0.0039009
Iter: 919 loss: 0.00390087324
Iter: 920 loss: 0.00390086137
Iter: 921 loss: 0.00390091469
Iter: 922 loss: 0.00390085904
Iter: 923 loss: 0.00390084926
Iter: 924 loss: 0.00390088279
Iter: 925 loss: 0.00390084577
Iter: 926 loss: 0.00390083855
Iter: 927 loss: 0.00390087068
Iter: 928 loss: 0.00390083715
Iter: 929 loss: 0.0039008325
Iter: 930 loss: 0.00390086975
Iter: 931 loss: 0.00390083087
Iter: 932 loss: 0.00390082458
Iter: 933 loss: 0.00390087161
Iter: 934 loss: 0.00390082551
Iter: 935 loss: 0.00390082342
Iter: 936 loss: 0.0039008148
Iter: 937 loss: 0.00390088186
Iter: 938 loss: 0.00390081247
Iter: 939 loss: 0.00390080409
Iter: 940 loss: 0.00390083948
Iter: 941 loss: 0.00390079897
Iter: 942 loss: 0.00390079105
Iter: 943 loss: 0.0039008006
Iter: 944 loss: 0.00390078872
Iter: 945 loss: 0.00390077871
Iter: 946 loss: 0.00390080595
Iter: 947 loss: 0.00390077499
Iter: 948 loss: 0.00390076661
Iter: 949 loss: 0.0039008
Iter: 950 loss: 0.00390076707
Iter: 951 loss: 0.00390075287
Iter: 952 loss: 0.003900802
Iter: 953 loss: 0.00390075194
Iter: 954 loss: 0.00390074681
Iter: 955 loss: 0.00390076567
Iter: 956 loss: 0.00390074449
Iter: 957 loss: 0.0039007368
Iter: 958 loss: 0.00390076358
Iter: 959 loss: 0.00390073331
Iter: 960 loss: 0.00390072726
Iter: 961 loss: 0.00390075403
Iter: 962 loss: 0.00390072516
Iter: 963 loss: 0.00390072237
Iter: 964 loss: 0.00390074332
Iter: 965 loss: 0.00390071911
Iter: 966 loss: 0.00390071701
Iter: 967 loss: 0.00390071562
Iter: 968 loss: 0.00390071585
Iter: 969 loss: 0.00390070956
Iter: 970 loss: 0.00390074775
Iter: 971 loss: 0.0039007063
Iter: 972 loss: 0.00390070071
Iter: 973 loss: 0.00390072819
Iter: 974 loss: 0.00390070071
Iter: 975 loss: 0.0039006942
Iter: 976 loss: 0.00390069862
Iter: 977 loss: 0.00390068977
Iter: 978 loss: 0.00390068698
Iter: 979 loss: 0.00390071073
Iter: 980 loss: 0.00390068139
Iter: 981 loss: 0.00390067464
Iter: 982 loss: 0.00390069047
Iter: 983 loss: 0.00390067417
Iter: 984 loss: 0.00390066789
Iter: 985 loss: 0.00390071422
Iter: 986 loss: 0.00390066789
Iter: 987 loss: 0.00390065927
Iter: 988 loss: 0.00390066532
Iter: 989 loss: 0.00390065834
Iter: 990 loss: 0.00390065298
Iter: 991 loss: 0.00390069908
Iter: 992 loss: 0.00390065252
Iter: 993 loss: 0.003900646
Iter: 994 loss: 0.00390065927
Iter: 995 loss: 0.00390064623
Iter: 996 loss: 0.00390064344
Iter: 997 loss: 0.00390066043
Iter: 998 loss: 0.00390064158
Iter: 999 loss: 0.00390063948
Iter: 1000 loss: 0.00390067301
Iter: 1001 loss: 0.00390063832
Iter: 1002 loss: 0.00390063855
Iter: 1003 loss: 0.00390063412
Iter: 1004 loss: 0.00390067394
Iter: 1005 loss: 0.00390063296
Iter: 1006 loss: 0.00390062877
Iter: 1007 loss: 0.00390064763
Iter: 1008 loss: 0.00390062854
Iter: 1009 loss: 0.00390062388
Iter: 1010 loss: 0.00390062411
Iter: 1011 loss: 0.00390062085
Iter: 1012 loss: 0.00390061736
Iter: 1013 loss: 0.00390063692
Iter: 1014 loss: 0.00390061457
Iter: 1015 loss: 0.00390060851
Iter: 1016 loss: 0.00390062202
Iter: 1017 loss: 0.00390060572
Iter: 1018 loss: 0.00390060246
Iter: 1019 loss: 0.00390064018
Iter: 1020 loss: 0.00390060223
Iter: 1021 loss: 0.0039005992
Iter: 1022 loss: 0.00390060199
Iter: 1023 loss: 0.00390059547
Iter: 1024 loss: 0.00390059222
Iter: 1025 loss: 0.0039006169
Iter: 1026 loss: 0.00390059128
Iter: 1027 loss: 0.00390059
Iter: 1028 loss: 0.00390059897
Iter: 1029 loss: 0.00390058756
Iter: 1030 loss: 0.00390058453
Iter: 1031 loss: 0.00390060642
Iter: 1032 loss: 0.00390058616
Iter: 1033 loss: 0.00390058081
Iter: 1034 loss: 0.00390060269
Iter: 1035 loss: 0.00390058267
Iter: 1036 loss: 0.00390058151
Iter: 1037 loss: 0.00390057964
Iter: 1038 loss: 0.00390062178
Iter: 1039 loss: 0.00390057918
Iter: 1040 loss: 0.00390057475
Iter: 1041 loss: 0.00390058
Iter: 1042 loss: 0.00390057429
Iter: 1043 loss: 0.00390057033
Iter: 1044 loss: 0.00390057592
Iter: 1045 loss: 0.00390056754
Iter: 1046 loss: 0.00390056311
Iter: 1047 loss: 0.00390057568
Iter: 1048 loss: 0.00390056195
Iter: 1049 loss: 0.00390055915
Iter: 1050 loss: 0.00390057056
Iter: 1051 loss: 0.0039005552
Iter: 1052 loss: 0.00390055543
Iter: 1053 loss: 0.00390058174
Iter: 1054 loss: 0.00390055333
Iter: 1055 loss: 0.00390055054
Iter: 1056 loss: 0.00390055473
Iter: 1057 loss: 0.00390054751
Iter: 1058 loss: 0.00390054611
Iter: 1059 loss: 0.00390056055
Iter: 1060 loss: 0.00390054681
Iter: 1061 loss: 0.00390054099
Iter: 1062 loss: 0.00390056055
Iter: 1063 loss: 0.00390054099
Iter: 1064 loss: 0.0039005382
Iter: 1065 loss: 0.00390055124
Iter: 1066 loss: 0.00390054076
Iter: 1067 loss: 0.00390053797
Iter: 1068 loss: 0.00390055589
Iter: 1069 loss: 0.00390053773
Iter: 1070 loss: 0.0039005361
Iter: 1071 loss: 0.00390053564
Iter: 1072 loss: 0.00390057289
Iter: 1073 loss: 0.00390053377
Iter: 1074 loss: 0.00390053168
Iter: 1075 loss: 0.00390053308
Iter: 1076 loss: 0.00390053121
Iter: 1077 loss: 0.00390052865
Iter: 1078 loss: 0.00390054053
Iter: 1079 loss: 0.00390052563
Iter: 1080 loss: 0.00390052656
Iter: 1081 loss: 0.00390052889
Iter: 1082 loss: 0.0039005233
Iter: 1083 loss: 0.00390052167
Iter: 1084 loss: 0.00390052306
Iter: 1085 loss: 0.00390051794
Iter: 1086 loss: 0.00390051655
Iter: 1087 loss: 0.00390056148
Iter: 1088 loss: 0.00390051585
Iter: 1089 loss: 0.00390051259
Iter: 1090 loss: 0.00390051305
Iter: 1091 loss: 0.00390051259
Iter: 1092 loss: 0.00390050863
Iter: 1093 loss: 0.00390052493
Iter: 1094 loss: 0.00390050793
Iter: 1095 loss: 0.00390050467
Iter: 1096 loss: 0.00390052143
Iter: 1097 loss: 0.00390050421
Iter: 1098 loss: 0.00390050304
Iter: 1099 loss: 0.00390051119
Iter: 1100 loss: 0.00390050281
Iter: 1101 loss: 0.00390050141
Iter: 1102 loss: 0.00390051771
Iter: 1103 loss: 0.00390050304
Iter: 1104 loss: 0.00390050048
Iter: 1105 loss: 0.00390050025
Iter: 1106 loss: 0.00390053261
Iter: 1107 loss: 0.00390049862
Iter: 1108 loss: 0.00390049652
Iter: 1109 loss: 0.00390049815
Iter: 1110 loss: 0.00390049629
Iter: 1111 loss: 0.00390049466
Iter: 1112 loss: 0.00390050141
Iter: 1113 loss: 0.00390049256
Iter: 1114 loss: 0.00390048954
Iter: 1115 loss: 0.00390049489
Iter: 1116 loss: 0.0039004893
Iter: 1117 loss: 0.00390048558
Iter: 1118 loss: 0.00390048977
Iter: 1119 loss: 0.00390048511
Iter: 1120 loss: 0.00390048162
Iter: 1121 loss: 0.00390051398
Iter: 1122 loss: 0.00390048232
Iter: 1123 loss: 0.00390048278
Iter: 1124 loss: 0.00390048232
Iter: 1125 loss: 0.00390047883
Iter: 1126 loss: 0.00390047557
Iter: 1127 loss: 0.00390049187
Iter: 1128 loss: 0.00390047673
Iter: 1129 loss: 0.00390047231
Iter: 1130 loss: 0.00390048162
Iter: 1131 loss: 0.00390047114
Iter: 1132 loss: 0.00390047254
Iter: 1133 loss: 0.00390048139
Iter: 1134 loss: 0.00390047277
Iter: 1135 loss: 0.00390047068
Iter: 1136 loss: 0.00390048162
Iter: 1137 loss: 0.00390047021
Iter: 1138 loss: 0.00390047021
Iter: 1139 loss: 0.00390046835
Iter: 1140 loss: 0.00390046835
Iter: 1141 loss: 0.00390046556
Iter: 1142 loss: 0.00390046765
Iter: 1143 loss: 0.00390046649
Iter: 1144 loss: 0.00390046462
Iter: 1145 loss: 0.00390046928
Iter: 1146 loss: 0.00390046462
Iter: 1147 loss: 0.00390046183
Iter: 1148 loss: 0.00390046765
Iter: 1149 loss: 0.0039004609
Iter: 1150 loss: 0.00390045764
Iter: 1151 loss: 0.00390045671
Iter: 1152 loss: 0.0039004581
Iter: 1153 loss: 0.00390045438
Iter: 1154 loss: 0.00390048046
Iter: 1155 loss: 0.00390045415
Iter: 1156 loss: 0.00390045205
Iter: 1157 loss: 0.00390045554
Iter: 1158 loss: 0.00390045159
Iter: 1159 loss: 0.00390044879
Iter: 1160 loss: 0.00390045857
Iter: 1161 loss: 0.00390044693
Iter: 1162 loss: 0.00390044646
Iter: 1163 loss: 0.00390045438
Iter: 1164 loss: 0.00390044646
Iter: 1165 loss: 0.00390044437
Iter: 1166 loss: 0.00390045438
Iter: 1167 loss: 0.00390044576
Iter: 1168 loss: 0.003900446
Iter: 1169 loss: 0.00390045275
Iter: 1170 loss: 0.003900446
Iter: 1171 loss: 0.00390044414
Iter: 1172 loss: 0.00390044181
Iter: 1173 loss: 0.0039004432
Iter: 1174 loss: 0.00390044088
Iter: 1175 loss: 0.00390044088
Iter: 1176 loss: 0.00390043901
Iter: 1177 loss: 0.00390043575
Iter: 1178 loss: 0.00390044274
Iter: 1179 loss: 0.00390043552
Iter: 1180 loss: 0.00390043366
Iter: 1181 loss: 0.00390044
Iter: 1182 loss: 0.00390043482
Iter: 1183 loss: 0.0039004318
Iter: 1184 loss: 0.00390043436
Iter: 1185 loss: 0.0039004311
Iter: 1186 loss: 0.0039004276
Iter: 1187 loss: 0.00390044879
Iter: 1188 loss: 0.0039004297
Iter: 1189 loss: 0.00390042667
Iter: 1190 loss: 0.00390043203
Iter: 1191 loss: 0.0039004276
Iter: 1192 loss: 0.00390042528
Iter: 1193 loss: 0.00390042644
Iter: 1194 loss: 0.00390042434
Iter: 1195 loss: 0.00390042248
Iter: 1196 loss: 0.00390043901
Iter: 1197 loss: 0.00390041946
Iter: 1198 loss: 0.00390042085
Iter: 1199 loss: 0.00390043017
Iter: 1200 loss: 0.00390042039
Iter: 1201 loss: 0.00390042108
Iter: 1202 loss: 0.0039004304
Iter: 1203 loss: 0.00390041969
Iter: 1204 loss: 0.00390042039
Iter: 1205 loss: 0.00390041806
Iter: 1206 loss: 0.00390041643
Iter: 1207 loss: 0.00390041852
Iter: 1208 loss: 0.0039004155
Iter: 1209 loss: 0.0039004148
Iter: 1210 loss: 0.00390041433
Iter: 1211 loss: 0.00390042365
Iter: 1212 loss: 0.00390041294
Iter: 1213 loss: 0.00390041061
Iter: 1214 loss: 0.0039004127
Iter: 1215 loss: 0.00390041
Iter: 1216 loss: 0.00390040549
Iter: 1217 loss: 0.00390041131
Iter: 1218 loss: 0.00390040549
Iter: 1219 loss: 0.00390040176
Iter: 1220 loss: 0.00390041363
Iter: 1221 loss: 0.00390040223
Iter: 1222 loss: 0.00390040036
Iter: 1223 loss: 0.00390041713
Iter: 1224 loss: 0.00390040036
Iter: 1225 loss: 0.0039003992
Iter: 1226 loss: 0.0039003992
Iter: 1227 loss: 0.00390039617
Iter: 1228 loss: 0.00390039524
Iter: 1229 loss: 0.00390040711
Iter: 1230 loss: 0.00390039408
Iter: 1231 loss: 0.00390039361
Iter: 1232 loss: 0.00390039803
Iter: 1233 loss: 0.00390039384
Iter: 1234 loss: 0.00390039431
Iter: 1235 loss: 0.00390040595
Iter: 1236 loss: 0.00390039245
Iter: 1237 loss: 0.00390039058
Iter: 1238 loss: 0.00390038919
Iter: 1239 loss: 0.00390038919
Iter: 1240 loss: 0.00390038616
Iter: 1241 loss: 0.00390038616
Iter: 1242 loss: 0.00390044204
Iter: 1243 loss: 0.0039003843
Iter: 1244 loss: 0.00390038243
Iter: 1245 loss: 0.00390041
Iter: 1246 loss: 0.00390037987
Iter: 1247 loss: 0.00390037871
Iter: 1248 loss: 0.00390038267
Iter: 1249 loss: 0.00390037545
Iter: 1250 loss: 0.00390037289
Iter: 1251 loss: 0.00390038383
Iter: 1252 loss: 0.00390037149
Iter: 1253 loss: 0.0039003687
Iter: 1254 loss: 0.00390037475
Iter: 1255 loss: 0.00390036847
Iter: 1256 loss: 0.00390036707
Iter: 1257 loss: 0.00390039384
Iter: 1258 loss: 0.0039003673
Iter: 1259 loss: 0.00390036404
Iter: 1260 loss: 0.00390036893
Iter: 1261 loss: 0.00390036264
Iter: 1262 loss: 0.00390036264
Iter: 1263 loss: 0.00390037056
Iter: 1264 loss: 0.00390036334
Iter: 1265 loss: 0.00390036358
Iter: 1266 loss: 0.00390036
Iter: 1267 loss: 0.00390036
Iter: 1268 loss: 0.00390035845
Iter: 1269 loss: 0.00390037452
Iter: 1270 loss: 0.00390036032
Iter: 1271 loss: 0.00390035752
Iter: 1272 loss: 0.00390035706
Iter: 1273 loss: 0.00390035729
Iter: 1274 loss: 0.0039003545
Iter: 1275 loss: 0.00390035496
Iter: 1276 loss: 0.00390035496
Iter: 1277 loss: 0.00390035473
Iter: 1278 loss: 0.00390037149
Iter: 1279 loss: 0.00390035426
Iter: 1280 loss: 0.00390035217
Iter: 1281 loss: 0.0039003538
Iter: 1282 loss: 0.00390035124
Iter: 1283 loss: 0.00390035
Iter: 1284 loss: 0.00390035473
Iter: 1285 loss: 0.00390035147
Iter: 1286 loss: 0.00390034961
Iter: 1287 loss: 0.00390035356
Iter: 1288 loss: 0.00390035
Iter: 1289 loss: 0.00390034728
Iter: 1290 loss: 0.00390035799
Iter: 1291 loss: 0.00390034704
Iter: 1292 loss: 0.00390034751
Iter: 1293 loss: 0.00390034751
Iter: 1294 loss: 0.00390034821
Iter: 1295 loss: 0.00390034658
Iter: 1296 loss: 0.00390035147
Iter: 1297 loss: 0.00390034728
Iter: 1298 loss: 0.00390034495
Iter: 1299 loss: 0.00390034937
Iter: 1300 loss: 0.00390034541
Iter: 1301 loss: 0.00390034541
Iter: 1302 loss: 0.00390035
Iter: 1303 loss: 0.00390034541
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/k3
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0
+ date
Tue Oct 27 17:53:31 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ad1e68d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ad1d9a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ad1e8b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ad1e8b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ad1e32488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ad1e32598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac4d3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac49fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac449400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac46f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac425268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac449e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac449d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac46f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac3d4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac34cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac308598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac308f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac2e07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac29f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac29f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac24fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac284620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac216f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac2167b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac1d48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac1928c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac1acd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac1be7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac192158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac1be2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac192488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac119950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac1199d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac0b6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5aac063950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00812054239
Iter: 2 loss: 0.00808880944
Iter: 3 loss: 0.00799102709
Iter: 4 loss: 0.00820140075
Iter: 5 loss: 0.0079315491
Iter: 6 loss: 0.00790324714
Iter: 7 loss: 0.00789342355
Iter: 8 loss: 0.00788846612
Iter: 9 loss: 0.00788741559
Iter: 10 loss: 0.00788417
Iter: 11 loss: 0.00788341835
Iter: 12 loss: 0.00788341649
Iter: 13 loss: 0.00788337737
Iter: 14 loss: 0.00788328517
Iter: 15 loss: 0.00788326748
Iter: 16 loss: 0.0078832591
Iter: 17 loss: 0.00788325071
Iter: 18 loss: 0.00788325
Iter: 19 loss: 0.00788324885
Iter: 20 loss: 0.00788324699
Iter: 21 loss: 0.00788324885
Iter: 22 loss: 0.00788324792
Iter: 23 loss: 0.00788324699
Iter: 24 loss: 0.00788324699
Iter: 25 loss: 0.00788324885
Iter: 26 loss: 0.00788324513
Iter: 27 loss: 0.00788324699
Iter: 28 loss: 0.00788324606
Iter: 29 loss: 0.00788324699
Iter: 30 loss: 0.00788324513
Iter: 31 loss: 0.00788324885
Iter: 32 loss: 0.00788324606
Iter: 33 loss: 0.00788324699
Iter: 34 loss: 0.00788324699
Iter: 35 loss: 0.00788324699
Iter: 36 loss: 0.00788324699
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4
+ date
Tue Oct 27 17:53:58 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0628dfc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0628d6a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0628d6ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06045b5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06045ca8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06045b5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06045286a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060455b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060455b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604503d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06044c99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604472840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604472ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060442c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060444ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060444cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604402268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604402510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604371840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604402ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06043a0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604353488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604305510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060431a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06042be7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06042d32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060429c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604249268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0604249378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06041f6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06041ac598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06041d0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06041d0d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06041796a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f060419fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f06041516a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0337376669
Iter: 2 loss: 0.0296154711
Iter: 3 loss: 0.0173974559
Iter: 4 loss: 0.0524757057
Iter: 5 loss: 0.0109172501
Iter: 6 loss: 0.0100713586
Iter: 7 loss: 0.00974198617
Iter: 8 loss: 0.00930185802
Iter: 9 loss: 0.0143571179
Iter: 10 loss: 0.00928609446
Iter: 11 loss: 0.00918853655
Iter: 12 loss: 0.00954360794
Iter: 13 loss: 0.00916431751
Iter: 14 loss: 0.00914395135
Iter: 15 loss: 0.00913669914
Iter: 16 loss: 0.00912615191
Iter: 17 loss: 0.00914330594
Iter: 18 loss: 0.00912133418
Iter: 19 loss: 0.00911895745
Iter: 20 loss: 0.00911895186
Iter: 21 loss: 0.00911831483
Iter: 22 loss: 0.00911828876
Iter: 23 loss: 0.00911817513
Iter: 24 loss: 0.00911842566
Iter: 25 loss: 0.00911813322
Iter: 26 loss: 0.00911811
Iter: 27 loss: 0.00911810808
Iter: 28 loss: 0.00911809783
Iter: 29 loss: 0.00911818165
Iter: 30 loss: 0.00911809225
Iter: 31 loss: 0.00911809225
Iter: 32 loss: 0.0091180969
Iter: 33 loss: 0.00911809132
Iter: 34 loss: 0.00911809132
Iter: 35 loss: 0.0091180969
Iter: 36 loss: 0.00911809132
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8
+ date
Tue Oct 27 17:54:26 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92143a3158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92143b9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92143b9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92143b9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d25b8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d25b8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac4b7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac4ea510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac4751e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac490c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac451950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac4016a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac4018c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac42a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac401ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac3cabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac396598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac338ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac2f7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac30cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac328620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac2de598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac298840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac298730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac245598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac2591e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac224620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac1cd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac1cd0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac183378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac134ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac15a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac15a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac0f0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac12d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac0c8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0286779478
Iter: 2 loss: 0.0253059678
Iter: 3 loss: 0.0172633156
Iter: 4 loss: 0.722605944
Iter: 5 loss: 0.0172214545
Iter: 6 loss: 0.0123780891
Iter: 7 loss: 0.0569589511
Iter: 8 loss: 0.0120159425
Iter: 9 loss: 0.0110978903
Iter: 10 loss: 0.0110137668
Iter: 11 loss: 0.0108652106
Iter: 12 loss: 0.0115759727
Iter: 13 loss: 0.0108363563
Iter: 14 loss: 0.0107400678
Iter: 15 loss: 0.0110700428
Iter: 16 loss: 0.0107135978
Iter: 17 loss: 0.0106563689
Iter: 18 loss: 0.010955682
Iter: 19 loss: 0.0106476145
Iter: 20 loss: 0.0106267966
Iter: 21 loss: 0.0107819624
Iter: 22 loss: 0.010625096
Iter: 23 loss: 0.0106200986
Iter: 24 loss: 0.0106199523
Iter: 25 loss: 0.0106185526
Iter: 26 loss: 0.0106218625
Iter: 27 loss: 0.0106180403
Iter: 28 loss: 0.0106177703
Iter: 29 loss: 0.0106214723
Iter: 30 loss: 0.0106177712
Iter: 31 loss: 0.0106176855
Iter: 32 loss: 0.0106188171
Iter: 33 loss: 0.0106176864
Iter: 34 loss: 0.0106176529
Iter: 35 loss: 0.0106177498
Iter: 36 loss: 0.0106176427
Iter: 37 loss: 0.0106176334
Iter: 38 loss: 0.0106176948
Iter: 39 loss: 0.0106176306
Iter: 40 loss: 0.0106176287
Iter: 41 loss: 0.0106176501
Iter: 42 loss: 0.0106176296
Iter: 43 loss: 0.0106176259
Iter: 44 loss: 0.0106176287
Iter: 45 loss: 0.0106176278
Iter: 46 loss: 0.0106176268
Iter: 47 loss: 0.0106176287
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2
+ date
Tue Oct 27 17:54:55 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi0.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03a25581e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03607b9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0360840d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03608401e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0360762488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03607628c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320788620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03207b4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320788268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320761730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320724b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03206c97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03206c9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03206f48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320696e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320696840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320655620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320655400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320607b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03205d5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03205ea158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03205a9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f032055f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320508840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320510598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03205242f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03204f69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f032049c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03204f62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f032044d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f032049c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03204f6e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320428730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0320428b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03203eea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f03203ee7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0307839736
Iter: 2 loss: 0.0250529442
Iter: 3 loss: 0.0252715163
Iter: 4 loss: 0.0196193941
Iter: 5 loss: 0.0158222429
Iter: 6 loss: 0.144493133
Iter: 7 loss: 0.0157955755
Iter: 8 loss: 0.0131263621
Iter: 9 loss: 0.032906305
Iter: 10 loss: 0.012867542
Iter: 11 loss: 0.0122607201
Iter: 12 loss: 0.0131868348
Iter: 13 loss: 0.0119616427
Iter: 14 loss: 0.0118031912
Iter: 15 loss: 0.0138456589
Iter: 16 loss: 0.0118012726
Iter: 17 loss: 0.011715373
Iter: 18 loss: 0.0119397454
Iter: 19 loss: 0.0116855558
Iter: 20 loss: 0.0116115157
Iter: 21 loss: 0.0123169627
Iter: 22 loss: 0.0116086425
Iter: 23 loss: 0.0115829371
Iter: 24 loss: 0.0118005145
Iter: 25 loss: 0.0115815122
Iter: 26 loss: 0.011572985
Iter: 27 loss: 0.0115933847
Iter: 28 loss: 0.0115698706
Iter: 29 loss: 0.0115665793
Iter: 30 loss: 0.0115835276
Iter: 31 loss: 0.011566055
Iter: 32 loss: 0.0115651255
Iter: 33 loss: 0.0115732485
Iter: 34 loss: 0.0115650743
Iter: 35 loss: 0.0115647856
Iter: 36 loss: 0.0115666911
Iter: 37 loss: 0.011564753
Iter: 38 loss: 0.0115646338
Iter: 39 loss: 0.0115658268
Iter: 40 loss: 0.0115646282
Iter: 41 loss: 0.011564591
Iter: 42 loss: 0.0115647856
Iter: 43 loss: 0.0115645863
Iter: 44 loss: 0.0115645621
Iter: 45 loss: 0.0115648722
Iter: 46 loss: 0.0115645621
Iter: 47 loss: 0.0115645546
Iter: 48 loss: 0.0115645686
Iter: 49 loss: 0.0115645491
Iter: 50 loss: 0.0115645472
Iter: 51 loss: 0.0115645733
Iter: 52 loss: 0.0115645472
Iter: 53 loss: 0.0115645435
Iter: 54 loss: 0.0115645546
Iter: 55 loss: 0.0115645416
Iter: 56 loss: 0.0115645435
Iter: 57 loss: 0.0115645491
Iter: 58 loss: 0.0115645435
Iter: 59 loss: 0.0115645435
Iter: 60 loss: 0.0115645435
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6
+ date
Tue Oct 27 17:55:24 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2ad7a5d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a95d52d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a95d52950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a95d52488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a95c609d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a95c60b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a7035f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a7038d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a7031a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a70337c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a702ffa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a7029e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a7029e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a702c9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a702c9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a702c9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a70239d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a701df950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a701a6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a701b2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a701cb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a70185378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a7013b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a700e2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a700e2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a701028c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a700d0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a700d0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a700d0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a700d02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a50099510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a50099840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a500bc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a500cc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a5008bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2a50046400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0392215773
Iter: 2 loss: 0.0246074982
Iter: 3 loss: 1860.17786
Iter: 4 loss: 0.0407725126
Iter: 5 loss: 0.0275275707
Iter: 6 loss: 0.0300568603
Iter: 7 loss: 0.0214258
Iter: 8 loss: 0.0182568152
Iter: 9 loss: 0.0180436485
Iter: 10 loss: 0.0162310768
Iter: 11 loss: 0.0174925067
Iter: 12 loss: 0.0150280902
Iter: 13 loss: 0.0135890059
Iter: 14 loss: 0.0207451191
Iter: 15 loss: 0.0133450078
Iter: 16 loss: 0.0129262116
Iter: 17 loss: 0.016198054
Iter: 18 loss: 0.0128830429
Iter: 19 loss: 0.0127924439
Iter: 20 loss: 0.013255069
Iter: 21 loss: 0.0127760358
Iter: 22 loss: 0.0127092358
Iter: 23 loss: 0.012821639
Iter: 24 loss: 0.0126791447
Iter: 25 loss: 0.0126037635
Iter: 26 loss: 0.0126341367
Iter: 27 loss: 0.0125515983
Iter: 28 loss: 0.0124806575
Iter: 29 loss: 0.0127450721
Iter: 30 loss: 0.0124619156
Iter: 31 loss: 0.0124278152
Iter: 32 loss: 0.0124675417
Iter: 33 loss: 0.0124098025
Iter: 34 loss: 0.0123898275
Iter: 35 loss: 0.0124756722
Iter: 36 loss: 0.0123856682
Iter: 37 loss: 0.0123794675
Iter: 38 loss: 0.0124241766
Iter: 39 loss: 0.0123789459
Iter: 40 loss: 0.01237626
Iter: 41 loss: 0.0123860911
Iter: 42 loss: 0.0123755857
Iter: 43 loss: 0.0123742847
Iter: 44 loss: 0.0123840161
Iter: 45 loss: 0.0123741813
Iter: 46 loss: 0.0123737585
Iter: 47 loss: 0.0123751098
Iter: 48 loss: 0.0123736355
Iter: 49 loss: 0.0123734549
Iter: 50 loss: 0.0123755382
Iter: 51 loss: 0.0123734483
Iter: 52 loss: 0.0123733468
Iter: 53 loss: 0.0123738209
Iter: 54 loss: 0.0123733282
Iter: 55 loss: 0.0123732705
Iter: 56 loss: 0.0123739671
Iter: 57 loss: 0.0123732686
Iter: 58 loss: 0.0123732397
Iter: 59 loss: 0.0123734567
Iter: 60 loss: 0.012373236
Iter: 61 loss: 0.012373223
Iter: 62 loss: 0.0123732332
Iter: 63 loss: 0.012373209
Iter: 64 loss: 0.0123731941
Iter: 65 loss: 0.012373249
Iter: 66 loss: 0.0123731904
Iter: 67 loss: 0.0123731829
Iter: 68 loss: 0.0123732276
Iter: 69 loss: 0.012373182
Iter: 70 loss: 0.0123731857
Iter: 71 loss: 0.012373182
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2
+ date
Tue Oct 27 17:55:54 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi1.6/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89d13fe158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89d147bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89d147bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f71ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f672488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f672400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f5e7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f60d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f6222f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f898f622488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89685371e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89684af8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89684af378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89684afbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968498ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968498598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f896842dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89683e7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968414e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89683d5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89683d57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968389c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968345048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968360598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968360e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968313840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89682d9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968281510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89682d97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968230d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89682602f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968260488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89682149d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89682148c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968214bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8968260598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0608320311
Iter: 2 loss: 0.439879298
Iter: 3 loss: 0.0597339794
Iter: 4 loss: 0.0308864955
Iter: 5 loss: 0.0308843851
Iter: 6 loss: 0.0277000442
Iter: 7 loss: 0.0373087451
Iter: 8 loss: 0.0262862407
Iter: 9 loss: 0.0226663258
Iter: 10 loss: 0.0215254407
Iter: 11 loss: 0.0202244781
Iter: 12 loss: 0.0214411616
Iter: 13 loss: 0.0194700398
Iter: 14 loss: 0.0181069598
Iter: 15 loss: 0.0192038696
Iter: 16 loss: 0.0171960108
Iter: 17 loss: 0.0162191968
Iter: 18 loss: 0.0162184574
Iter: 19 loss: 0.0157165602
Iter: 20 loss: 0.0198914856
Iter: 21 loss: 0.0156830736
Iter: 22 loss: 0.015464047
Iter: 23 loss: 0.0156931411
Iter: 24 loss: 0.0153334197
Iter: 25 loss: 0.0151729481
Iter: 26 loss: 0.0161509179
Iter: 27 loss: 0.0151534136
Iter: 28 loss: 0.0150874201
Iter: 29 loss: 0.0154220033
Iter: 30 loss: 0.015075732
Iter: 31 loss: 0.0150362775
Iter: 32 loss: 0.0152547378
Iter: 33 loss: 0.015030236
Iter: 34 loss: 0.0149960518
Iter: 35 loss: 0.0149555784
Iter: 36 loss: 0.0149513222
Iter: 37 loss: 0.014887495
Iter: 38 loss: 0.0153282834
Iter: 39 loss: 0.0148802642
Iter: 40 loss: 0.0148279108
Iter: 41 loss: 0.0149294762
Iter: 42 loss: 0.0148062129
Iter: 43 loss: 0.0147524113
Iter: 44 loss: 0.0147769246
Iter: 45 loss: 0.0147157917
Iter: 46 loss: 0.0146800959
Iter: 47 loss: 0.0148418872
Iter: 48 loss: 0.0146731064
Iter: 49 loss: 0.0146458317
Iter: 50 loss: 0.0148229506
Iter: 51 loss: 0.0146428403
Iter: 52 loss: 0.0146297226
Iter: 53 loss: 0.0146748312
Iter: 54 loss: 0.0146261556
Iter: 55 loss: 0.0146180671
Iter: 56 loss: 0.0147364698
Iter: 57 loss: 0.0146180503
Iter: 58 loss: 0.0146132326
Iter: 59 loss: 0.014633067
Iter: 60 loss: 0.0146121969
Iter: 61 loss: 0.0146092065
Iter: 62 loss: 0.0146157593
Iter: 63 loss: 0.014608047
Iter: 64 loss: 0.014605511
Iter: 65 loss: 0.0146123134
Iter: 66 loss: 0.0146046653
Iter: 67 loss: 0.0146032637
Iter: 68 loss: 0.0146107497
Iter: 69 loss: 0.0146030458
Iter: 70 loss: 0.0146023873
Iter: 71 loss: 0.0146122556
Iter: 72 loss: 0.0146023873
Iter: 73 loss: 0.0146019701
Iter: 74 loss: 0.0146047994
Iter: 75 loss: 0.0146019245
Iter: 76 loss: 0.0146015957
Iter: 77 loss: 0.0146014579
Iter: 78 loss: 0.0146012874
Iter: 79 loss: 0.0146009307
Iter: 80 loss: 0.0146014197
Iter: 81 loss: 0.0146007603
Iter: 82 loss: 0.014600548
Iter: 83 loss: 0.0146017484
Iter: 84 loss: 0.0146005144
Iter: 85 loss: 0.0146003366
Iter: 86 loss: 0.0146008916
Iter: 87 loss: 0.0146002788
Iter: 88 loss: 0.0146001391
Iter: 89 loss: 0.0146006439
Iter: 90 loss: 0.0146001093
Iter: 91 loss: 0.0146000274
Iter: 92 loss: 0.0146009075
Iter: 93 loss: 0.0146000274
Iter: 94 loss: 0.0145999677
Iter: 95 loss: 0.0146002248
Iter: 96 loss: 0.0145999566
Iter: 97 loss: 0.0145999035
Iter: 98 loss: 0.0145999808
Iter: 99 loss: 0.0145998802
Iter: 100 loss: 0.0145998402
Iter: 101 loss: 0.0146000255
Iter: 102 loss: 0.0145998299
Iter: 103 loss: 0.0145998
Iter: 104 loss: 0.0145998187
Iter: 105 loss: 0.0145997824
Iter: 106 loss: 0.0145997787
Iter: 107 loss: 0.0145997684
Iter: 108 loss: 0.0145997554
Iter: 109 loss: 0.0145997647
Iter: 110 loss: 0.0145997489
Iter: 111 loss: 0.0145997405
Iter: 112 loss: 0.0145997554
Iter: 113 loss: 0.0145997368
Iter: 114 loss: 0.0145997293
Iter: 115 loss: 0.0145997293
Iter: 116 loss: 0.0145997219
Iter: 117 loss: 0.0145997172
Iter: 118 loss: 0.0145997517
Iter: 119 loss: 0.0145997144
Iter: 120 loss: 0.0145997107
Iter: 121 loss: 0.0145997601
Iter: 122 loss: 0.0145997116
Iter: 123 loss: 0.014599707
Iter: 124 loss: 0.0145997107
Iter: 125 loss: 0.0145997033
Iter: 126 loss: 0.0145997023
Iter: 127 loss: 0.0145997321
Iter: 128 loss: 0.0145997051
Iter: 129 loss: 0.0145996977
Iter: 130 loss: 0.014599707
Iter: 131 loss: 0.0145996986
Iter: 132 loss: 0.0145996977
Iter: 133 loss: 0.0145996986
Iter: 134 loss: 0.0145996977
Iter: 135 loss: 0.0145996958
Iter: 136 loss: 0.0145996995
Iter: 137 loss: 0.0145996949
Iter: 138 loss: 0.014599693
Iter: 139 loss: 0.0145996995
Iter: 140 loss: 0.014599693
Iter: 141 loss: 0.014599693
Iter: 142 loss: 0.0145996939
Iter: 143 loss: 0.0145996949
Iter: 144 loss: 0.0145996939
Iter: 145 loss: 0.014599706
Iter: 146 loss: 0.0145996921
Iter: 147 loss: 0.0145996921
Iter: 148 loss: 0.0145996958
Iter: 149 loss: 0.0145996921
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4
+ date
Tue Oct 27 17:56:29 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8416620268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8416630c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f84166a0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f84165e0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f04ba488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f04692f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f049ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f04357b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0462268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0435730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f03ce9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f03d7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f03777b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f03847b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0384d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f03026a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0302598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0302488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f02b9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f02a2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f02a28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0256d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0211730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f021db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f01ba378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f01c69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f019d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0145950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0150bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f00ffb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f00af950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f00d7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f00d7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0076620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f0027bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f83f005f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.131805629
Iter: 2 loss: 2730.79272
Iter: 3 loss: 480.884186
Iter: 4 loss: 0.131798208
Iter: 5 loss: 623.688477
Iter: 6 loss: 0.13055566
Iter: 7 loss: 0.0507442355
Iter: 8 loss: 0.0833718628
Iter: 9 loss: 1.41712713
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8
+ date
Tue Oct 27 17:56:55 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f501f73c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fdd9f7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fdda0cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fdda0c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fdd93c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fdd8e72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fdd918c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fb804d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fb8065400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa0108f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa00dc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa007a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa007aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa004d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa0056840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4fa0056ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f547912f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54791d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54735bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54707f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f5471a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f546fdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54692730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f546376a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54637400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54651268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f54626840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f545ca2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f545d6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f545d67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f545307b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f5454b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f5454b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f544f5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f5454b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f544e36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0850151628
Iter: 2 loss: 0.562367797
Iter: 3 loss: 0.0842455253
Iter: 4 loss: 0.0902451053
Iter: 5 loss: 0.0785782486
Iter: 6 loss: 0.0611427315
Iter: 7 loss: 11027.7793
Iter: 8 loss: 0.110662401
Iter: 9 loss: 0.0654955208
Iter: 10 loss: 0.0461612269
Iter: 11 loss: 0.208642215
Iter: 12 loss: 0.0453485325
Iter: 13 loss: 0.0378831625
Iter: 14 loss: 0.150061756
Iter: 15 loss: 0.0375180617
Iter: 16 loss: 0.0326861814
Iter: 17 loss: 0.0593721457
Iter: 18 loss: 0.0317343511
Iter: 19 loss: 0.0290495064
Iter: 20 loss: 0.0526934266
Iter: 21 loss: 0.0286526792
Iter: 22 loss: 0.026385244
Iter: 23 loss: 0.0764282644
Iter: 24 loss: 0.02637548
Iter: 25 loss: 0.0252212845
Iter: 26 loss: 0.0296137128
Iter: 27 loss: 0.0248392113
Iter: 28 loss: 0.0239977427
Iter: 29 loss: 0.0268146247
Iter: 30 loss: 0.0237678736
Iter: 31 loss: 0.023015
Iter: 32 loss: 0.0234784149
Iter: 33 loss: 0.0225074887
Iter: 34 loss: 0.0215713214
Iter: 35 loss: 0.0281834975
Iter: 36 loss: 0.021456223
Iter: 37 loss: 0.0210065544
Iter: 38 loss: 0.0258193128
Iter: 39 loss: 0.0209895484
Iter: 40 loss: 0.0207157824
Iter: 41 loss: 0.0207090732
Iter: 42 loss: 0.0205364302
Iter: 43 loss: 0.021378994
Iter: 44 loss: 0.0205070749
Iter: 45 loss: 0.020451583
Iter: 46 loss: 0.0204888564
Iter: 47 loss: 0.0204157121
Iter: 48 loss: 0.0203137603
Iter: 49 loss: 0.0208484121
Iter: 50 loss: 0.0202971324
Iter: 51 loss: 0.020244997
Iter: 52 loss: 0.0205543563
Iter: 53 loss: 0.0202379804
Iter: 54 loss: 0.0201985426
Iter: 55 loss: 0.0203198381
Iter: 56 loss: 0.0201867707
Iter: 57 loss: 0.0201462377
Iter: 58 loss: 0.0203481521
Iter: 59 loss: 0.0201388448
Iter: 60 loss: 0.0200984031
Iter: 61 loss: 0.0201799907
Iter: 62 loss: 0.020082254
Iter: 63 loss: 0.0200326033
Iter: 64 loss: 0.0201861262
Iter: 65 loss: 0.0200177934
Iter: 66 loss: 0.0199766532
Iter: 67 loss: 0.0199111775
Iter: 68 loss: 0.0199106187
Iter: 69 loss: 0.0198482834
Iter: 70 loss: 0.0198395848
Iter: 71 loss: 0.0197943151
Iter: 72 loss: 0.0197461192
Iter: 73 loss: 0.0197441652
Iter: 74 loss: 0.0197156798
Iter: 75 loss: 0.0198052377
Iter: 76 loss: 0.0197072327
Iter: 77 loss: 0.0196726061
Iter: 78 loss: 0.0197067857
Iter: 79 loss: 0.0196532086
Iter: 80 loss: 0.0196138527
Iter: 81 loss: 0.0195962489
Iter: 82 loss: 0.0195759144
Iter: 83 loss: 0.0195253659
Iter: 84 loss: 0.0197199136
Iter: 85 loss: 0.0195129961
Iter: 86 loss: 0.0194726922
Iter: 87 loss: 0.0199236553
Iter: 88 loss: 0.0194718018
Iter: 89 loss: 0.0194380246
Iter: 90 loss: 0.0194046702
Iter: 91 loss: 0.0193974972
Iter: 92 loss: 0.0193717424
Iter: 93 loss: 0.0193688311
Iter: 94 loss: 0.0193510987
Iter: 95 loss: 0.0193724595
Iter: 96 loss: 0.0193417929
Iter: 97 loss: 0.0193280168
Iter: 98 loss: 0.0195111372
Iter: 99 loss: 0.0193278976
Iter: 100 loss: 0.0193196908
Iter: 101 loss: 0.0193407573
Iter: 102 loss: 0.0193169378
Iter: 103 loss: 0.0193089973
Iter: 104 loss: 0.019334197
Iter: 105 loss: 0.019306669
Iter: 106 loss: 0.0193017628
Iter: 107 loss: 0.0193251073
Iter: 108 loss: 0.0193008874
Iter: 109 loss: 0.0192957968
Iter: 110 loss: 0.0193022564
Iter: 111 loss: 0.0192931741
Iter: 112 loss: 0.0192875639
Iter: 113 loss: 0.0193054825
Iter: 114 loss: 0.0192859899
Iter: 115 loss: 0.0192803983
Iter: 116 loss: 0.019280985
Iter: 117 loss: 0.0192760956
Iter: 118 loss: 0.0192707237
Iter: 119 loss: 0.0193034187
Iter: 120 loss: 0.0192700624
Iter: 121 loss: 0.0192645341
Iter: 122 loss: 0.0192790888
Iter: 123 loss: 0.0192626584
Iter: 124 loss: 0.0192599688
Iter: 125 loss: 0.0192859285
Iter: 126 loss: 0.0192598719
Iter: 127 loss: 0.0192575641
Iter: 128 loss: 0.0192609541
Iter: 129 loss: 0.0192564316
Iter: 130 loss: 0.0192544758
Iter: 131 loss: 0.0192545578
Iter: 132 loss: 0.019252928
Iter: 133 loss: 0.0192520507
Iter: 134 loss: 0.0192517582
Iter: 135 loss: 0.0192511138
Iter: 136 loss: 0.0192532837
Iter: 137 loss: 0.0192509405
Iter: 138 loss: 0.0192503706
Iter: 139 loss: 0.0192533396
Iter: 140 loss: 0.0192502886
Iter: 141 loss: 0.0192499049
Iter: 142 loss: 0.0192499608
Iter: 143 loss: 0.0192496069
Iter: 144 loss: 0.0192492045
Iter: 145 loss: 0.0192505307
Iter: 146 loss: 0.0192490891
Iter: 147 loss: 0.0192486756
Iter: 148 loss: 0.0192489661
Iter: 149 loss: 0.0192484185
Iter: 150 loss: 0.0192480572
Iter: 151 loss: 0.0192490183
Iter: 152 loss: 0.0192479268
Iter: 153 loss: 0.0192475393
Iter: 154 loss: 0.0192507524
Iter: 155 loss: 0.019247517
Iter: 156 loss: 0.0192473084
Iter: 157 loss: 0.019247612
Iter: 158 loss: 0.0192471966
Iter: 159 loss: 0.0192469694
Iter: 160 loss: 0.0192485116
Iter: 161 loss: 0.0192469507
Iter: 162 loss: 0.0192467514
Iter: 163 loss: 0.0192468744
Iter: 164 loss: 0.0192466248
Iter: 165 loss: 0.0192465205
Iter: 166 loss: 0.019246513
Iter: 167 loss: 0.0192464255
Iter: 168 loss: 0.0192468166
Iter: 169 loss: 0.0192464162
Iter: 170 loss: 0.0192463435
Iter: 171 loss: 0.0192464516
Iter: 172 loss: 0.0192463137
Iter: 173 loss: 0.0192462299
Iter: 174 loss: 0.0192464944
Iter: 175 loss: 0.0192462113
Iter: 176 loss: 0.0192461591
Iter: 177 loss: 0.0192460939
Iter: 178 loss: 0.0192460902
Iter: 179 loss: 0.0192459859
Iter: 180 loss: 0.0192467012
Iter: 181 loss: 0.0192459747
Iter: 182 loss: 0.0192459077
Iter: 183 loss: 0.0192458704
Iter: 184 loss: 0.0192458443
Iter: 185 loss: 0.0192457829
Iter: 186 loss: 0.0192457847
Iter: 187 loss: 0.0192457438
Iter: 188 loss: 0.0192457
Iter: 189 loss: 0.0192456953
Iter: 190 loss: 0.019245632
Iter: 191 loss: 0.0192462616
Iter: 192 loss: 0.0192456283
Iter: 193 loss: 0.019245578
Iter: 194 loss: 0.0192456394
Iter: 195 loss: 0.0192455463
Iter: 196 loss: 0.0192455053
Iter: 197 loss: 0.0192458034
Iter: 198 loss: 0.0192455091
Iter: 199 loss: 0.0192454755
Iter: 200 loss: 0.0192457363
Iter: 201 loss: 0.0192454718
Iter: 202 loss: 0.0192454457
Iter: 203 loss: 0.0192455165
Iter: 204 loss: 0.0192454476
Iter: 205 loss: 0.0192454271
Iter: 206 loss: 0.0192454569
Iter: 207 loss: 0.0192454122
Iter: 208 loss: 0.0192453936
Iter: 209 loss: 0.0192453787
Iter: 210 loss: 0.0192453675
Iter: 211 loss: 0.019245334
Iter: 212 loss: 0.0192455798
Iter: 213 loss: 0.0192453414
Iter: 214 loss: 0.0192453191
Iter: 215 loss: 0.0192453153
Iter: 216 loss: 0.0192453
Iter: 217 loss: 0.0192452874
Iter: 218 loss: 0.0192455351
Iter: 219 loss: 0.0192452893
Iter: 220 loss: 0.01924528
Iter: 221 loss: 0.0192452632
Iter: 222 loss: 0.0192452557
Iter: 223 loss: 0.0192452408
Iter: 224 loss: 0.0192453973
Iter: 225 loss: 0.0192452371
Iter: 226 loss: 0.0192452185
Iter: 227 loss: 0.0192452781
Iter: 228 loss: 0.0192452166
Iter: 229 loss: 0.0192452073
Iter: 230 loss: 0.0192452539
Iter: 231 loss: 0.0192452
Iter: 232 loss: 0.0192451924
Iter: 233 loss: 0.0192452762
Iter: 234 loss: 0.0192451905
Iter: 235 loss: 0.0192451887
Iter: 236 loss: 0.0192451924
Iter: 237 loss: 0.019245185
Iter: 238 loss: 0.0192451775
Iter: 239 loss: 0.0192451924
Iter: 240 loss: 0.0192451775
Iter: 241 loss: 0.0192451682
Iter: 242 loss: 0.0192451663
Iter: 243 loss: 0.0192451626
Iter: 244 loss: 0.0192451552
Iter: 245 loss: 0.0192452017
Iter: 246 loss: 0.0192451552
Iter: 247 loss: 0.019245144
Iter: 248 loss: 0.0192451477
Iter: 249 loss: 0.0192451403
Iter: 250 loss: 0.0192451328
Iter: 251 loss: 0.019245198
Iter: 252 loss: 0.0192451328
Iter: 253 loss: 0.0192451291
Iter: 254 loss: 0.0192451254
Iter: 255 loss: 0.019245116
Iter: 256 loss: 0.0192451123
Iter: 257 loss: 0.0192452129
Iter: 258 loss: 0.0192451179
Iter: 259 loss: 0.0192451067
Iter: 260 loss: 0.0192451365
Iter: 261 loss: 0.0192451086
Iter: 262 loss: 0.019245103
Iter: 263 loss: 0.0192451105
Iter: 264 loss: 0.0192451049
Iter: 265 loss: 0.0192451
Iter: 266 loss: 0.0192451291
Iter: 267 loss: 0.0192451011
Iter: 268 loss: 0.0192450937
Iter: 269 loss: 0.0192451011
Iter: 270 loss: 0.0192450956
Iter: 271 loss: 0.0192450956
Iter: 272 loss: 0.019245103
Iter: 273 loss: 0.0192450956
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3
+ date
Tue Oct 27 17:57:38 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi2.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -2 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f928c3b21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f928c3bca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f928c3bcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f924a664e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f924a5bc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f924a5bcd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92244c28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92244c2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92244e5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f922449cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f922445ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224401950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224401378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92243b88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92243d76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92243d78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224392510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224392a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f922430a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224321048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224392bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92242d4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224297730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224240378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92242409d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224265268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92242976a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224297158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224265048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f922417b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92242978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f922415b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92241678c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92241670d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224167ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9224119268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0425219759
Iter: 2 loss: 0.747162342
Iter: 3 loss: 0.587912083
Iter: 4 loss: 0.305568933
Iter: 5 loss: 0.225501448
Iter: 6 loss: 0.103495248
Iter: 7 loss: 0.0695692673
Iter: 8 loss: 0.0315010101
Iter: 9 loss: 0.0263143834
Iter: 10 loss: 0.0237727873
Iter: 11 loss: 0.0280920155
Iter: 12 loss: 0.0222075
Iter: 13 loss: 0.0214540735
Iter: 14 loss: 0.0214491449
Iter: 15 loss: 0.0209920257
Iter: 16 loss: 0.0200685021
Iter: 17 loss: 0.0317957178
Iter: 18 loss: 0.0200476088
Iter: 19 loss: 0.0196346901
Iter: 20 loss: 0.0227520373
Iter: 21 loss: 0.0196055546
Iter: 22 loss: 0.0194045436
Iter: 23 loss: 0.0193945877
Iter: 24 loss: 0.0192407612
Iter: 25 loss: 0.0190968439
Iter: 26 loss: 0.0190967899
Iter: 27 loss: 0.0190442167
Iter: 28 loss: 0.0193222724
Iter: 29 loss: 0.0190362688
Iter: 30 loss: 0.0190140568
Iter: 31 loss: 0.0191595163
Iter: 32 loss: 0.0190117639
Iter: 33 loss: 0.0189964641
Iter: 34 loss: 0.0190205984
Iter: 35 loss: 0.0189894345
Iter: 36 loss: 0.0189760346
Iter: 37 loss: 0.0190279577
Iter: 38 loss: 0.0189729761
Iter: 39 loss: 0.0189662017
Iter: 40 loss: 0.0190040506
Iter: 41 loss: 0.0189652741
Iter: 42 loss: 0.018961411
Iter: 43 loss: 0.0189828314
Iter: 44 loss: 0.0189608708
Iter: 45 loss: 0.0189591683
Iter: 46 loss: 0.018978266
Iter: 47 loss: 0.0189591404
Iter: 48 loss: 0.0189591534
Iter: 49 loss: 0.0189587269
Iter: 50 loss: 0.0189584717
Iter: 51 loss: 0.018957762
Iter: 52 loss: 0.0189617854
Iter: 53 loss: 0.018957559
Iter: 54 loss: 0.0189566873
Iter: 55 loss: 0.0189578496
Iter: 56 loss: 0.0189562496
Iter: 57 loss: 0.018955294
Iter: 58 loss: 0.0189566724
Iter: 59 loss: 0.0189548302
Iter: 60 loss: 0.0189540125
Iter: 61 loss: 0.0189574324
Iter: 62 loss: 0.0189538412
Iter: 63 loss: 0.0189532
Iter: 64 loss: 0.0189595111
Iter: 65 loss: 0.0189531781
Iter: 66 loss: 0.0189528018
Iter: 67 loss: 0.0189531446
Iter: 68 loss: 0.0189525709
Iter: 69 loss: 0.0189522393
Iter: 70 loss: 0.0189551935
Iter: 71 loss: 0.0189522225
Iter: 72 loss: 0.018951999
Iter: 73 loss: 0.0189524777
Iter: 74 loss: 0.0189519133
Iter: 75 loss: 0.0189516898
Iter: 76 loss: 0.0189523548
Iter: 77 loss: 0.0189516228
Iter: 78 loss: 0.0189514272
Iter: 79 loss: 0.0189520083
Iter: 80 loss: 0.0189513676
Iter: 81 loss: 0.0189512428
Iter: 82 loss: 0.0189523809
Iter: 83 loss: 0.0189512372
Iter: 84 loss: 0.0189511664
Iter: 85 loss: 0.0189511608
Iter: 86 loss: 0.018951118
Iter: 87 loss: 0.0189510174
Iter: 88 loss: 0.0189518146
Iter: 89 loss: 0.0189509988
Iter: 90 loss: 0.0189509094
Iter: 91 loss: 0.0189511403
Iter: 92 loss: 0.0189508777
Iter: 93 loss: 0.0189508051
Iter: 94 loss: 0.0189512949
Iter: 95 loss: 0.0189507902
Iter: 96 loss: 0.0189507455
Iter: 97 loss: 0.0189507492
Iter: 98 loss: 0.0189507119
Iter: 99 loss: 0.0189506672
Iter: 100 loss: 0.0189510267
Iter: 101 loss: 0.0189506672
Iter: 102 loss: 0.0189506356
Iter: 103 loss: 0.0189508256
Iter: 104 loss: 0.01895063
Iter: 105 loss: 0.0189506114
Iter: 106 loss: 0.0189506374
Iter: 107 loss: 0.0189505927
Iter: 108 loss: 0.0189505722
Iter: 109 loss: 0.0189507473
Iter: 110 loss: 0.0189505704
Iter: 111 loss: 0.0189505592
Iter: 112 loss: 0.0189505611
Iter: 113 loss: 0.0189505443
Iter: 114 loss: 0.0189505238
Iter: 115 loss: 0.0189506039
Iter: 116 loss: 0.0189505182
Iter: 117 loss: 0.0189505052
Iter: 118 loss: 0.0189506747
Iter: 119 loss: 0.018950507
Iter: 120 loss: 0.0189505
Iter: 121 loss: 0.0189505015
Iter: 122 loss: 0.018950494
Iter: 123 loss: 0.0189504847
Iter: 124 loss: 0.0189505219
Iter: 125 loss: 0.018950481
Iter: 126 loss: 0.0189504772
Iter: 127 loss: 0.0189505015
Iter: 128 loss: 0.0189504772
Iter: 129 loss: 0.0189504698
Iter: 130 loss: 0.0189505089
Iter: 131 loss: 0.0189504642
Iter: 132 loss: 0.0189504661
Iter: 133 loss: 0.0189504866
Iter: 134 loss: 0.0189504586
Iter: 135 loss: 0.0189504623
Iter: 136 loss: 0.0189504679
Iter: 137 loss: 0.0189504586
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-2_phi3/k2
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0
+ date
Tue Oct 27 17:58:14 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f340c5c3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f340c5f2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f340c61a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f344e303f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f344e2fc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f340c51e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f344e2fcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f344e303d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e42fdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e42d2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e4286268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e42fdae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e42fd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e42fdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e423e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e41b5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e41ec598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e417c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e417cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e417c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e41ecbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e417c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e4142b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e407c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e407c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e408d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e4048840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e4065840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33e4048620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d078c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d07f8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d0762ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d0762d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d070e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d078c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f33d06fbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.000636193668
Iter: 2 loss: 0.000633503776
Iter: 3 loss: 0.000622968771
Iter: 4 loss: 0.00057567464
Iter: 5 loss: 0.000473635155
Iter: 6 loss: 0.000473414635
Iter: 7 loss: 0.000379963371
Iter: 8 loss: 0.00122716022
Iter: 9 loss: 0.000374939758
Iter: 10 loss: 0.000327172864
Iter: 11 loss: 0.000360629812
Iter: 12 loss: 0.000297458319
Iter: 13 loss: 0.000258697226
Iter: 14 loss: 0.000836330932
Iter: 15 loss: 0.000258687389
Iter: 16 loss: 0.000229545956
Iter: 17 loss: 0.000241720438
Iter: 18 loss: 0.000209475824
Iter: 19 loss: 0.000183320939
Iter: 20 loss: 0.000224345669
Iter: 21 loss: 0.000171073756
Iter: 22 loss: 0.000153005589
Iter: 23 loss: 0.000432918605
Iter: 24 loss: 0.000153003944
Iter: 25 loss: 0.000137961644
Iter: 26 loss: 0.000171445557
Iter: 27 loss: 0.00013223142
Iter: 28 loss: 0.000121328107
Iter: 29 loss: 0.000125223436
Iter: 30 loss: 0.000113666894
Iter: 31 loss: 0.000104335231
Iter: 32 loss: 0.00010433323
Iter: 33 loss: 9.71795234e-05
Iter: 34 loss: 0.000106189626
Iter: 35 loss: 9.34861819e-05
Iter: 36 loss: 8.7253844e-05
Iter: 37 loss: 9.17451107e-05
Iter: 38 loss: 8.34047896e-05
Iter: 39 loss: 7.86287783e-05
Iter: 40 loss: 0.000150469175
Iter: 41 loss: 7.8625395e-05
Iter: 42 loss: 7.46620281e-05
Iter: 43 loss: 8.37244952e-05
Iter: 44 loss: 7.3181e-05
Iter: 45 loss: 7.02355101e-05
Iter: 46 loss: 7.01325553e-05
Iter: 47 loss: 6.78488504e-05
Iter: 48 loss: 6.45775435e-05
Iter: 49 loss: 7.94703956e-05
Iter: 50 loss: 6.39483114e-05
Iter: 51 loss: 6.18756312e-05
Iter: 52 loss: 9.15081764e-05
Iter: 53 loss: 6.18721242e-05
Iter: 54 loss: 6.02444561e-05
Iter: 55 loss: 6.17605256e-05
Iter: 56 loss: 5.93063633e-05
Iter: 57 loss: 5.79277621e-05
Iter: 58 loss: 6.51789451e-05
Iter: 59 loss: 5.77117389e-05
Iter: 60 loss: 5.64132424e-05
Iter: 61 loss: 6.11472642e-05
Iter: 62 loss: 5.60908811e-05
Iter: 63 loss: 5.51387566e-05
Iter: 64 loss: 5.49481229e-05
Iter: 65 loss: 5.4316748e-05
Iter: 66 loss: 5.33699822e-05
Iter: 67 loss: 6.21204381e-05
Iter: 68 loss: 5.3329e-05
Iter: 69 loss: 5.25475189e-05
Iter: 70 loss: 5.72788376e-05
Iter: 71 loss: 5.24514398e-05
Iter: 72 loss: 5.1945688e-05
Iter: 73 loss: 5.16376131e-05
Iter: 74 loss: 5.14312633e-05
Iter: 75 loss: 5.08365556e-05
Iter: 76 loss: 5.4871969e-05
Iter: 77 loss: 5.07779805e-05
Iter: 78 loss: 5.03104966e-05
Iter: 79 loss: 5.4146054e-05
Iter: 80 loss: 5.02813382e-05
Iter: 81 loss: 4.99535599e-05
Iter: 82 loss: 4.96762586e-05
Iter: 83 loss: 4.95848799e-05
Iter: 84 loss: 4.91797036e-05
Iter: 85 loss: 5.16798755e-05
Iter: 86 loss: 4.9131675e-05
Iter: 87 loss: 4.88032238e-05
Iter: 88 loss: 5.18100351e-05
Iter: 89 loss: 4.87885263e-05
Iter: 90 loss: 4.85822857e-05
Iter: 91 loss: 4.8392576e-05
Iter: 92 loss: 4.83427066e-05
Iter: 93 loss: 4.80486851e-05
Iter: 94 loss: 4.8789585e-05
Iter: 95 loss: 4.79461851e-05
Iter: 96 loss: 4.76910282e-05
Iter: 97 loss: 4.88872101e-05
Iter: 98 loss: 4.76441346e-05
Iter: 99 loss: 4.74680055e-05
Iter: 100 loss: 4.95778513e-05
Iter: 101 loss: 4.7465739e-05
Iter: 102 loss: 4.73119726e-05
Iter: 103 loss: 4.7529451e-05
Iter: 104 loss: 4.72365e-05
Iter: 105 loss: 4.71060775e-05
Iter: 106 loss: 4.73719556e-05
Iter: 107 loss: 4.70534578e-05
Iter: 108 loss: 4.69103179e-05
Iter: 109 loss: 4.77943759e-05
Iter: 110 loss: 4.68932376e-05
Iter: 111 loss: 4.67946957e-05
Iter: 112 loss: 4.67436585e-05
Iter: 113 loss: 4.66981728e-05
Iter: 114 loss: 4.65895027e-05
Iter: 115 loss: 4.76860223e-05
Iter: 116 loss: 4.65861158e-05
Iter: 117 loss: 4.64872282e-05
Iter: 118 loss: 4.68256221e-05
Iter: 119 loss: 4.64608383e-05
Iter: 120 loss: 4.63885663e-05
Iter: 121 loss: 4.63478864e-05
Iter: 122 loss: 4.63163706e-05
Iter: 123 loss: 4.62186035e-05
Iter: 124 loss: 4.65601115e-05
Iter: 125 loss: 4.61931377e-05
Iter: 126 loss: 4.61300224e-05
Iter: 127 loss: 4.61296513e-05
Iter: 128 loss: 4.6077319e-05
Iter: 129 loss: 4.60533047e-05
Iter: 130 loss: 4.60273659e-05
Iter: 131 loss: 4.59660696e-05
Iter: 132 loss: 4.6015346e-05
Iter: 133 loss: 4.59292351e-05
Iter: 134 loss: 4.58775721e-05
Iter: 135 loss: 4.5877583e-05
Iter: 136 loss: 4.58308859e-05
Iter: 137 loss: 4.5885743e-05
Iter: 138 loss: 4.58060968e-05
Iter: 139 loss: 4.57638962e-05
Iter: 140 loss: 4.5755296e-05
Iter: 141 loss: 4.57274436e-05
Iter: 142 loss: 4.56755115e-05
Iter: 143 loss: 4.59699841e-05
Iter: 144 loss: 4.56683847e-05
Iter: 145 loss: 4.56339185e-05
Iter: 146 loss: 4.61537638e-05
Iter: 147 loss: 4.56339731e-05
Iter: 148 loss: 4.56071866e-05
Iter: 149 loss: 4.55942318e-05
Iter: 150 loss: 4.55813133e-05
Iter: 151 loss: 4.55502413e-05
Iter: 152 loss: 4.57091519e-05
Iter: 153 loss: 4.55450863e-05
Iter: 154 loss: 4.55151567e-05
Iter: 155 loss: 4.56230628e-05
Iter: 156 loss: 4.55075788e-05
Iter: 157 loss: 4.54838737e-05
Iter: 158 loss: 4.54810506e-05
Iter: 159 loss: 4.54640103e-05
Iter: 160 loss: 4.54387264e-05
Iter: 161 loss: 4.57321948e-05
Iter: 162 loss: 4.54382971e-05
Iter: 163 loss: 4.54154906e-05
Iter: 164 loss: 4.54564288e-05
Iter: 165 loss: 4.54055044e-05
Iter: 166 loss: 4.53856192e-05
Iter: 167 loss: 4.53834327e-05
Iter: 168 loss: 4.53689499e-05
Iter: 169 loss: 4.5344219e-05
Iter: 170 loss: 4.5413959e-05
Iter: 171 loss: 4.533639e-05
Iter: 172 loss: 4.531796e-05
Iter: 173 loss: 4.55669651e-05
Iter: 174 loss: 4.53178181e-05
Iter: 175 loss: 4.53019893e-05
Iter: 176 loss: 4.53380126e-05
Iter: 177 loss: 4.52959648e-05
Iter: 178 loss: 4.52825043e-05
Iter: 179 loss: 4.52784589e-05
Iter: 180 loss: 4.5270448e-05
Iter: 181 loss: 4.52538516e-05
Iter: 182 loss: 4.53096509e-05
Iter: 183 loss: 4.52494023e-05
Iter: 184 loss: 4.52376553e-05
Iter: 185 loss: 4.5237648e-05
Iter: 186 loss: 4.52278837e-05
Iter: 187 loss: 4.52263266e-05
Iter: 188 loss: 4.521964e-05
Iter: 189 loss: 4.52087697e-05
Iter: 190 loss: 4.52293607e-05
Iter: 191 loss: 4.52041131e-05
Iter: 192 loss: 4.51954766e-05
Iter: 193 loss: 4.51956e-05
Iter: 194 loss: 4.51890373e-05
Iter: 195 loss: 4.51833839e-05
Iter: 196 loss: 4.51817104e-05
Iter: 197 loss: 4.51733031e-05
Iter: 198 loss: 4.52141103e-05
Iter: 199 loss: 4.5171917e-05
Iter: 200 loss: 4.51639644e-05
Iter: 201 loss: 4.5202185e-05
Iter: 202 loss: 4.51624655e-05
Iter: 203 loss: 4.51567139e-05
Iter: 204 loss: 4.51556371e-05
Iter: 205 loss: 4.51517553e-05
Iter: 206 loss: 4.51455344e-05
Iter: 207 loss: 4.52091626e-05
Iter: 208 loss: 4.51453634e-05
Iter: 209 loss: 4.51397937e-05
Iter: 210 loss: 4.51563901e-05
Iter: 211 loss: 4.51381e-05
Iter: 212 loss: 4.51339e-05
Iter: 213 loss: 4.51316591e-05
Iter: 214 loss: 4.51297019e-05
Iter: 215 loss: 4.51240412e-05
Iter: 216 loss: 4.51401866e-05
Iter: 217 loss: 4.51222877e-05
Iter: 218 loss: 4.51179294e-05
Iter: 219 loss: 4.51537708e-05
Iter: 220 loss: 4.51176165e-05
Iter: 221 loss: 4.51141859e-05
Iter: 222 loss: 4.51445885e-05
Iter: 223 loss: 4.51139822e-05
Iter: 224 loss: 4.51118976e-05
Iter: 225 loss: 4.51094893e-05
Iter: 226 loss: 4.51091037e-05
Iter: 227 loss: 4.51058e-05
Iter: 228 loss: 4.5113924e-05
Iter: 229 loss: 4.51045817e-05
Iter: 230 loss: 4.51021479e-05
Iter: 231 loss: 4.51021842e-05
Iter: 232 loss: 4.51001433e-05
Iter: 233 loss: 4.5103603e-05
Iter: 234 loss: 4.50991793e-05
Iter: 235 loss: 4.50973603e-05
Iter: 236 loss: 4.50984e-05
Iter: 237 loss: 4.50962252e-05
Iter: 238 loss: 4.50943189e-05
Iter: 239 loss: 4.5116707e-05
Iter: 240 loss: 4.50942534e-05
Iter: 241 loss: 4.50929438e-05
Iter: 242 loss: 4.50928273e-05
Iter: 243 loss: 4.50918051e-05
Iter: 244 loss: 4.50901789e-05
Iter: 245 loss: 4.50962143e-05
Iter: 246 loss: 4.50899097e-05
Iter: 247 loss: 4.50883963e-05
Iter: 248 loss: 4.50976877e-05
Iter: 249 loss: 4.50882e-05
Iter: 250 loss: 4.50871376e-05
Iter: 251 loss: 4.50868756e-05
Iter: 252 loss: 4.50862244e-05
Iter: 253 loss: 4.50850384e-05
Iter: 254 loss: 4.50939224e-05
Iter: 255 loss: 4.5084922e-05
Iter: 256 loss: 4.50838415e-05
Iter: 257 loss: 4.50895604e-05
Iter: 258 loss: 4.50837506e-05
Iter: 259 loss: 4.50830303e-05
Iter: 260 loss: 4.50825428e-05
Iter: 261 loss: 4.50822226e-05
Iter: 262 loss: 4.50813313e-05
Iter: 263 loss: 4.50835e-05
Iter: 264 loss: 4.5080953e-05
Iter: 265 loss: 4.50800617e-05
Iter: 266 loss: 4.50835832e-05
Iter: 267 loss: 4.50799562e-05
Iter: 268 loss: 4.50793705e-05
Iter: 269 loss: 4.50793523e-05
Iter: 270 loss: 4.50789157e-05
Iter: 271 loss: 4.50786792e-05
Iter: 272 loss: 4.50785665e-05
Iter: 273 loss: 4.50780208e-05
Iter: 274 loss: 4.50786974e-05
Iter: 275 loss: 4.50777188e-05
Iter: 276 loss: 4.50772859e-05
Iter: 277 loss: 4.50827974e-05
Iter: 278 loss: 4.50773332e-05
Iter: 279 loss: 4.50769367e-05
Iter: 280 loss: 4.50778316e-05
Iter: 281 loss: 4.50768275e-05
Iter: 282 loss: 4.50765e-05
Iter: 283 loss: 4.50765583e-05
Iter: 284 loss: 4.50762491e-05
Iter: 285 loss: 4.50760599e-05
Iter: 286 loss: 4.50787375e-05
Iter: 287 loss: 4.5076009e-05
Iter: 288 loss: 4.50757507e-05
Iter: 289 loss: 4.50762782e-05
Iter: 290 loss: 4.50755688e-05
Iter: 291 loss: 4.50753651e-05
Iter: 292 loss: 4.50756124e-05
Iter: 293 loss: 4.50752159e-05
Iter: 294 loss: 4.50749976e-05
Iter: 295 loss: 4.50778934e-05
Iter: 296 loss: 4.50749685e-05
Iter: 297 loss: 4.50748266e-05
Iter: 298 loss: 4.50748521e-05
Iter: 299 loss: 4.50746957e-05
Iter: 300 loss: 4.50744774e-05
Iter: 301 loss: 4.50748776e-05
Iter: 302 loss: 4.50743973e-05
Iter: 303 loss: 4.50742882e-05
Iter: 304 loss: 4.50743028e-05
Iter: 305 loss: 4.507423e-05
Iter: 306 loss: 4.50740918e-05
Iter: 307 loss: 4.50740918e-05
Iter: 308 loss: 4.50738844e-05
Iter: 309 loss: 4.50741281e-05
Iter: 310 loss: 4.5073888e-05
Iter: 311 loss: 4.50737498e-05
Iter: 312 loss: 4.50742373e-05
Iter: 313 loss: 4.50737571e-05
Iter: 314 loss: 4.50736406e-05
Iter: 315 loss: 4.50736952e-05
Iter: 316 loss: 4.50735388e-05
Iter: 317 loss: 4.50737134e-05
Iter: 318 loss: 4.50735461e-05
Iter: 319 loss: 4.5073466e-05
Iter: 320 loss: 4.50734224e-05
Iter: 321 loss: 4.50733969e-05
Iter: 322 loss: 4.50732914e-05
Iter: 323 loss: 4.50741e-05
Iter: 324 loss: 4.50733205e-05
Iter: 325 loss: 4.50732114e-05
Iter: 326 loss: 4.50734588e-05
Iter: 327 loss: 4.5073175e-05
Iter: 328 loss: 4.50731459e-05
Iter: 329 loss: 4.50732259e-05
Iter: 330 loss: 4.50731422e-05
Iter: 331 loss: 4.50731022e-05
Iter: 332 loss: 4.50735934e-05
Iter: 333 loss: 4.50731568e-05
Iter: 334 loss: 4.50730731e-05
Iter: 335 loss: 4.5073095e-05
Iter: 336 loss: 4.5073044e-05
Iter: 337 loss: 4.5073044e-05
Iter: 338 loss: 4.50730295e-05
Iter: 339 loss: 4.50730076e-05
Iter: 340 loss: 4.50729422e-05
Iter: 341 loss: 4.50733642e-05
Iter: 342 loss: 4.50729931e-05
Iter: 343 loss: 4.50728912e-05
Iter: 344 loss: 4.5073004e-05
Iter: 345 loss: 4.50728658e-05
Iter: 346 loss: 4.50728112e-05
Iter: 347 loss: 4.50728767e-05
Iter: 348 loss: 4.50728185e-05
Iter: 349 loss: 4.50728476e-05
Iter: 350 loss: 4.50728112e-05
Iter: 351 loss: 4.50728076e-05
Iter: 352 loss: 4.50728039e-05
Iter: 353 loss: 4.50727748e-05
Iter: 354 loss: 4.50727748e-05
Iter: 355 loss: 4.50728367e-05
Iter: 356 loss: 4.50727894e-05
Iter: 357 loss: 4.50728112e-05
Iter: 358 loss: 4.50728439e-05
Iter: 359 loss: 4.50728e-05
Iter: 360 loss: 4.50727166e-05
Iter: 361 loss: 4.50727966e-05
Iter: 362 loss: 4.50727821e-05
Iter: 363 loss: 4.50727166e-05
Iter: 364 loss: 4.50727603e-05
Iter: 365 loss: 4.50727166e-05
Iter: 366 loss: 4.5072713e-05
Iter: 367 loss: 4.50726657e-05
Iter: 368 loss: 4.50727021e-05
Iter: 369 loss: 4.50726802e-05
Iter: 370 loss: 4.50726438e-05
Iter: 371 loss: 4.50727457e-05
Iter: 372 loss: 4.50726839e-05
Iter: 373 loss: 4.50727021e-05
Iter: 374 loss: 4.50726802e-05
Iter: 375 loss: 4.50726802e-05
Iter: 376 loss: 4.50726584e-05
Iter: 377 loss: 4.50726402e-05
Iter: 378 loss: 4.50726184e-05
Iter: 379 loss: 4.5072622e-05
Iter: 380 loss: 4.50726147e-05
Iter: 381 loss: 4.50727093e-05
Iter: 382 loss: 4.50727093e-05
Iter: 383 loss: 4.50727166e-05
Iter: 384 loss: 4.50726729e-05
Iter: 385 loss: 4.50726657e-05
Iter: 386 loss: 4.50726475e-05
Iter: 387 loss: 4.50726911e-05
Iter: 388 loss: 4.50726438e-05
Iter: 389 loss: 4.50726511e-05
Iter: 390 loss: 4.50726948e-05
Iter: 391 loss: 4.50726802e-05
Iter: 392 loss: 4.50726766e-05
Iter: 393 loss: 4.50726802e-05
Iter: 394 loss: 4.50726548e-05
Iter: 395 loss: 4.50726911e-05
Iter: 396 loss: 4.50726584e-05
Iter: 397 loss: 4.50726802e-05
Iter: 398 loss: 4.50726802e-05
Iter: 399 loss: 4.50726657e-05
Iter: 400 loss: 4.50726584e-05
Iter: 401 loss: 4.50726657e-05
Iter: 402 loss: 4.5072662e-05
Iter: 403 loss: 4.5072662e-05
Iter: 404 loss: 4.50726657e-05
Iter: 405 loss: 4.5072662e-05
Iter: 406 loss: 4.50726657e-05
Iter: 407 loss: 4.5072662e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4
+ date
Tue Oct 27 18:03:56 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fa1ab268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fa1a5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fa1a57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d407fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c07c8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c07c87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c07b4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c075b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c077ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c077a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c06d5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c06edf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0695598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0648840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0659840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0659b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c062d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c05c6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0592a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0599f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c05b5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c056d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0527510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c05369d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c04c8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c04de8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c04a2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c04a2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c045d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0416b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c03c5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c03e8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c03e8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c0385ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c03bbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c036d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0261471029
Iter: 2 loss: 0.0257396568
Iter: 3 loss: 0.0241622403
Iter: 4 loss: 0.0174747147
Iter: 5 loss: 0.011021751
Iter: 6 loss: 0.00818577409
Iter: 7 loss: 0.00413347734
Iter: 8 loss: 0.0040114196
Iter: 9 loss: 0.00236800546
Iter: 10 loss: 0.0136364726
Iter: 11 loss: 0.0020661063
Iter: 12 loss: 0.00131875277
Iter: 13 loss: 0.00552299526
Iter: 14 loss: 0.0011917816
Iter: 15 loss: 0.000765028584
Iter: 16 loss: 0.00494399853
Iter: 17 loss: 0.000747123733
Iter: 18 loss: 0.000532261387
Iter: 19 loss: 0.00335079478
Iter: 20 loss: 0.000531516504
Iter: 21 loss: 0.000422411773
Iter: 22 loss: 0.000685046776
Iter: 23 loss: 0.000382500177
Iter: 24 loss: 0.000308329123
Iter: 25 loss: 0.0012373029
Iter: 26 loss: 0.000307114504
Iter: 27 loss: 0.000263637514
Iter: 28 loss: 0.000316029589
Iter: 29 loss: 0.000240768175
Iter: 30 loss: 0.000205683464
Iter: 31 loss: 0.000341248
Iter: 32 loss: 0.000197605783
Iter: 33 loss: 0.000170917832
Iter: 34 loss: 0.000306771515
Iter: 35 loss: 0.000166396072
Iter: 36 loss: 0.000148136169
Iter: 37 loss: 0.000185140525
Iter: 38 loss: 0.000140705059
Iter: 39 loss: 0.000124777958
Iter: 40 loss: 0.000194505847
Iter: 41 loss: 0.000121550751
Iter: 42 loss: 0.000110179506
Iter: 43 loss: 0.000166124373
Iter: 44 loss: 0.000108212909
Iter: 45 loss: 0.000100584628
Iter: 46 loss: 0.000181982745
Iter: 47 loss: 0.000100403406
Iter: 48 loss: 9.50012181e-05
Iter: 49 loss: 0.0001037935
Iter: 50 loss: 9.25103959e-05
Iter: 51 loss: 8.7739485e-05
Iter: 52 loss: 0.0001047244
Iter: 53 loss: 8.6508473e-05
Iter: 54 loss: 8.24161252e-05
Iter: 55 loss: 9.82353959e-05
Iter: 56 loss: 8.14539526e-05
Iter: 57 loss: 7.83152209e-05
Iter: 58 loss: 8.61815788e-05
Iter: 59 loss: 7.72192943e-05
Iter: 60 loss: 7.46219e-05
Iter: 61 loss: 8.82895911e-05
Iter: 62 loss: 7.42125121e-05
Iter: 63 loss: 7.20715325e-05
Iter: 64 loss: 8.16189931e-05
Iter: 65 loss: 7.16504874e-05
Iter: 66 loss: 6.99798911e-05
Iter: 67 loss: 7.55694e-05
Iter: 68 loss: 6.95267081e-05
Iter: 69 loss: 6.79440709e-05
Iter: 70 loss: 7.31685577e-05
Iter: 71 loss: 6.75057527e-05
Iter: 72 loss: 6.62246748e-05
Iter: 73 loss: 6.71151574e-05
Iter: 74 loss: 6.54252217e-05
Iter: 75 loss: 6.40629514e-05
Iter: 76 loss: 6.90645829e-05
Iter: 77 loss: 6.37258709e-05
Iter: 78 loss: 6.25797475e-05
Iter: 79 loss: 6.80963567e-05
Iter: 80 loss: 6.23747837e-05
Iter: 81 loss: 6.1447543e-05
Iter: 82 loss: 6.38217825e-05
Iter: 83 loss: 6.11290307e-05
Iter: 84 loss: 6.03783119e-05
Iter: 85 loss: 6.60437654e-05
Iter: 86 loss: 6.03193548e-05
Iter: 87 loss: 5.96642567e-05
Iter: 88 loss: 6.0904662e-05
Iter: 89 loss: 5.93876321e-05
Iter: 90 loss: 5.88328367e-05
Iter: 91 loss: 5.95741585e-05
Iter: 92 loss: 5.85531961e-05
Iter: 93 loss: 5.79966218e-05
Iter: 94 loss: 6.06422764e-05
Iter: 95 loss: 5.78961772e-05
Iter: 96 loss: 5.74276346e-05
Iter: 97 loss: 5.94498233e-05
Iter: 98 loss: 5.73312391e-05
Iter: 99 loss: 5.69443182e-05
Iter: 100 loss: 5.81582644e-05
Iter: 101 loss: 5.68322357e-05
Iter: 102 loss: 5.65039445e-05
Iter: 103 loss: 5.82849971e-05
Iter: 104 loss: 5.64552574e-05
Iter: 105 loss: 5.61674024e-05
Iter: 106 loss: 5.67396128e-05
Iter: 107 loss: 5.60491972e-05
Iter: 108 loss: 5.57780659e-05
Iter: 109 loss: 5.60553e-05
Iter: 110 loss: 5.56268824e-05
Iter: 111 loss: 5.53398932e-05
Iter: 112 loss: 5.66412127e-05
Iter: 113 loss: 5.52844976e-05
Iter: 114 loss: 5.50606128e-05
Iter: 115 loss: 5.58031752e-05
Iter: 116 loss: 5.49989127e-05
Iter: 117 loss: 5.47860545e-05
Iter: 118 loss: 5.53255486e-05
Iter: 119 loss: 5.47121526e-05
Iter: 120 loss: 5.45249641e-05
Iter: 121 loss: 5.48677417e-05
Iter: 122 loss: 5.44444229e-05
Iter: 123 loss: 5.42721e-05
Iter: 124 loss: 5.49735123e-05
Iter: 125 loss: 5.42341804e-05
Iter: 126 loss: 5.4102693e-05
Iter: 127 loss: 5.5511573e-05
Iter: 128 loss: 5.40995425e-05
Iter: 129 loss: 5.3992193e-05
Iter: 130 loss: 5.41480767e-05
Iter: 131 loss: 5.39400608e-05
Iter: 132 loss: 5.38363602e-05
Iter: 133 loss: 5.39597604e-05
Iter: 134 loss: 5.37815504e-05
Iter: 135 loss: 5.368438e-05
Iter: 136 loss: 5.43182687e-05
Iter: 137 loss: 5.36740445e-05
Iter: 138 loss: 5.35915751e-05
Iter: 139 loss: 5.39417706e-05
Iter: 140 loss: 5.3574382e-05
Iter: 141 loss: 5.35057443e-05
Iter: 142 loss: 5.36385123e-05
Iter: 143 loss: 5.34770697e-05
Iter: 144 loss: 5.34095525e-05
Iter: 145 loss: 5.35904255e-05
Iter: 146 loss: 5.33870334e-05
Iter: 147 loss: 5.33247257e-05
Iter: 148 loss: 5.34232895e-05
Iter: 149 loss: 5.32957201e-05
Iter: 150 loss: 5.32356207e-05
Iter: 151 loss: 5.35078798e-05
Iter: 152 loss: 5.32239428e-05
Iter: 153 loss: 5.31722944e-05
Iter: 154 loss: 5.33093953e-05
Iter: 155 loss: 5.31551414e-05
Iter: 156 loss: 5.31083933e-05
Iter: 157 loss: 5.32015729e-05
Iter: 158 loss: 5.30892939e-05
Iter: 159 loss: 5.30463149e-05
Iter: 160 loss: 5.3213309e-05
Iter: 161 loss: 5.30362558e-05
Iter: 162 loss: 5.2999425e-05
Iter: 163 loss: 5.32144441e-05
Iter: 164 loss: 5.299451e-05
Iter: 165 loss: 5.29647841e-05
Iter: 166 loss: 5.30505495e-05
Iter: 167 loss: 5.29554382e-05
Iter: 168 loss: 5.29298086e-05
Iter: 169 loss: 5.3082782e-05
Iter: 170 loss: 5.29265562e-05
Iter: 171 loss: 5.290431e-05
Iter: 172 loss: 5.29435893e-05
Iter: 173 loss: 5.28946039e-05
Iter: 174 loss: 5.287366e-05
Iter: 175 loss: 5.28982127e-05
Iter: 176 loss: 5.2862626e-05
Iter: 177 loss: 5.28433084e-05
Iter: 178 loss: 5.29863828e-05
Iter: 179 loss: 5.28417295e-05
Iter: 180 loss: 5.28248638e-05
Iter: 181 loss: 5.28862365e-05
Iter: 182 loss: 5.28206619e-05
Iter: 183 loss: 5.2806965e-05
Iter: 184 loss: 5.28143355e-05
Iter: 185 loss: 5.27978918e-05
Iter: 186 loss: 5.27826633e-05
Iter: 187 loss: 5.28187047e-05
Iter: 188 loss: 5.2777079e-05
Iter: 189 loss: 5.27625234e-05
Iter: 190 loss: 5.28026576e-05
Iter: 191 loss: 5.2757794e-05
Iter: 192 loss: 5.27443044e-05
Iter: 193 loss: 5.27857337e-05
Iter: 194 loss: 5.27402626e-05
Iter: 195 loss: 5.27285301e-05
Iter: 196 loss: 5.28051023e-05
Iter: 197 loss: 5.27271841e-05
Iter: 198 loss: 5.27177071e-05
Iter: 199 loss: 5.27393204e-05
Iter: 200 loss: 5.27141674e-05
Iter: 201 loss: 5.27058255e-05
Iter: 202 loss: 5.27360789e-05
Iter: 203 loss: 5.27036609e-05
Iter: 204 loss: 5.2695912e-05
Iter: 205 loss: 5.27506127e-05
Iter: 206 loss: 5.26952499e-05
Iter: 207 loss: 5.2689571e-05
Iter: 208 loss: 5.26926124e-05
Iter: 209 loss: 5.26858312e-05
Iter: 210 loss: 5.26788936e-05
Iter: 211 loss: 5.2702977e-05
Iter: 212 loss: 5.26770455e-05
Iter: 213 loss: 5.26710865e-05
Iter: 214 loss: 5.26853219e-05
Iter: 215 loss: 5.26690565e-05
Iter: 216 loss: 5.26636686e-05
Iter: 217 loss: 5.27130069e-05
Iter: 218 loss: 5.26633958e-05
Iter: 219 loss: 5.26595286e-05
Iter: 220 loss: 5.26573131e-05
Iter: 221 loss: 5.26556541e-05
Iter: 222 loss: 5.26504664e-05
Iter: 223 loss: 5.26656258e-05
Iter: 224 loss: 5.26488329e-05
Iter: 225 loss: 5.26440199e-05
Iter: 226 loss: 5.26604235e-05
Iter: 227 loss: 5.26428666e-05
Iter: 228 loss: 5.26386757e-05
Iter: 229 loss: 5.26601143e-05
Iter: 230 loss: 5.26381336e-05
Iter: 231 loss: 5.26345975e-05
Iter: 232 loss: 5.26398762e-05
Iter: 233 loss: 5.26328513e-05
Iter: 234 loss: 5.26294243e-05
Iter: 235 loss: 5.2637417e-05
Iter: 236 loss: 5.26281947e-05
Iter: 237 loss: 5.26252443e-05
Iter: 238 loss: 5.26448239e-05
Iter: 239 loss: 5.26250078e-05
Iter: 240 loss: 5.26225231e-05
Iter: 241 loss: 5.26391559e-05
Iter: 242 loss: 5.26224721e-05
Iter: 243 loss: 5.2620584e-05
Iter: 244 loss: 5.26210861e-05
Iter: 245 loss: 5.26192e-05
Iter: 246 loss: 5.26172371e-05
Iter: 247 loss: 5.26233343e-05
Iter: 248 loss: 5.26165859e-05
Iter: 249 loss: 5.26146905e-05
Iter: 250 loss: 5.26263757e-05
Iter: 251 loss: 5.26144868e-05
Iter: 252 loss: 5.26129734e-05
Iter: 253 loss: 5.26173e-05
Iter: 254 loss: 5.26125514e-05
Iter: 255 loss: 5.26109834e-05
Iter: 256 loss: 5.26139593e-05
Iter: 257 loss: 5.26104232e-05
Iter: 258 loss: 5.26091899e-05
Iter: 259 loss: 5.2611751e-05
Iter: 260 loss: 5.26086951e-05
Iter: 261 loss: 5.26073491e-05
Iter: 262 loss: 5.26103977e-05
Iter: 263 loss: 5.26067815e-05
Iter: 264 loss: 5.2605581e-05
Iter: 265 loss: 5.26099502e-05
Iter: 266 loss: 5.26052536e-05
Iter: 267 loss: 5.26041258e-05
Iter: 268 loss: 5.26066069e-05
Iter: 269 loss: 5.2603722e-05
Iter: 270 loss: 5.2602627e-05
Iter: 271 loss: 5.26056319e-05
Iter: 272 loss: 5.26022413e-05
Iter: 273 loss: 5.26014082e-05
Iter: 274 loss: 5.26064723e-05
Iter: 275 loss: 5.26013173e-05
Iter: 276 loss: 5.26006297e-05
Iter: 277 loss: 5.26055737e-05
Iter: 278 loss: 5.26004224e-05
Iter: 279 loss: 5.2599913e-05
Iter: 280 loss: 5.26008444e-05
Iter: 281 loss: 5.25995965e-05
Iter: 282 loss: 5.2598989e-05
Iter: 283 loss: 5.25995711e-05
Iter: 284 loss: 5.25986397e-05
Iter: 285 loss: 5.25981122e-05
Iter: 286 loss: 5.26019576e-05
Iter: 287 loss: 5.25981231e-05
Iter: 288 loss: 5.25975411e-05
Iter: 289 loss: 5.25991345e-05
Iter: 290 loss: 5.25974e-05
Iter: 291 loss: 5.25970063e-05
Iter: 292 loss: 5.2598014e-05
Iter: 293 loss: 5.25968389e-05
Iter: 294 loss: 5.25963551e-05
Iter: 295 loss: 5.25971554e-05
Iter: 296 loss: 5.25961e-05
Iter: 297 loss: 5.25957803e-05
Iter: 298 loss: 5.25960713e-05
Iter: 299 loss: 5.25956093e-05
Iter: 300 loss: 5.25950309e-05
Iter: 301 loss: 5.25966861e-05
Iter: 302 loss: 5.25949072e-05
Iter: 303 loss: 5.25945688e-05
Iter: 304 loss: 5.25969881e-05
Iter: 305 loss: 5.25945e-05
Iter: 306 loss: 5.25942705e-05
Iter: 307 loss: 5.25949945e-05
Iter: 308 loss: 5.25941141e-05
Iter: 309 loss: 5.25938231e-05
Iter: 310 loss: 5.25946634e-05
Iter: 311 loss: 5.25937103e-05
Iter: 312 loss: 5.25933865e-05
Iter: 313 loss: 5.25948344e-05
Iter: 314 loss: 5.25934083e-05
Iter: 315 loss: 5.25931937e-05
Iter: 316 loss: 5.25941796e-05
Iter: 317 loss: 5.25931537e-05
Iter: 318 loss: 5.25930336e-05
Iter: 319 loss: 5.25931391e-05
Iter: 320 loss: 5.25928845e-05
Iter: 321 loss: 5.25927062e-05
Iter: 322 loss: 5.25933501e-05
Iter: 323 loss: 5.2592688e-05
Iter: 324 loss: 5.25925425e-05
Iter: 325 loss: 5.25931646e-05
Iter: 326 loss: 5.25924806e-05
Iter: 327 loss: 5.25923497e-05
Iter: 328 loss: 5.25930882e-05
Iter: 329 loss: 5.25923097e-05
Iter: 330 loss: 5.25921423e-05
Iter: 331 loss: 5.25922151e-05
Iter: 332 loss: 5.25921423e-05
Iter: 333 loss: 5.25919859e-05
Iter: 334 loss: 5.25922442e-05
Iter: 335 loss: 5.2591844e-05
Iter: 336 loss: 5.25918222e-05
Iter: 337 loss: 5.25922551e-05
Iter: 338 loss: 5.25918076e-05
Iter: 339 loss: 5.25916257e-05
Iter: 340 loss: 5.25921714e-05
Iter: 341 loss: 5.25916039e-05
Iter: 342 loss: 5.25914475e-05
Iter: 343 loss: 5.25918294e-05
Iter: 344 loss: 5.25914438e-05
Iter: 345 loss: 5.25913565e-05
Iter: 346 loss: 5.25915602e-05
Iter: 347 loss: 5.25913274e-05
Iter: 348 loss: 5.25913e-05
Iter: 349 loss: 5.25915602e-05
Iter: 350 loss: 5.25913165e-05
Iter: 351 loss: 5.2591211e-05
Iter: 352 loss: 5.25917276e-05
Iter: 353 loss: 5.25911564e-05
Iter: 354 loss: 5.259112e-05
Iter: 355 loss: 5.25911491e-05
Iter: 356 loss: 5.25910436e-05
Iter: 357 loss: 5.25910145e-05
Iter: 358 loss: 5.25913383e-05
Iter: 359 loss: 5.25910036e-05
Iter: 360 loss: 5.25909891e-05
Iter: 361 loss: 5.25912183e-05
Iter: 362 loss: 5.25909127e-05
Iter: 363 loss: 5.25909127e-05
Iter: 364 loss: 5.25910364e-05
Iter: 365 loss: 5.25909272e-05
Iter: 366 loss: 5.25908617e-05
Iter: 367 loss: 5.25909563e-05
Iter: 368 loss: 5.25908363e-05
Iter: 369 loss: 5.2590789e-05
Iter: 370 loss: 5.25909345e-05
Iter: 371 loss: 5.25907744e-05
Iter: 372 loss: 5.25907271e-05
Iter: 373 loss: 5.25909563e-05
Iter: 374 loss: 5.25907562e-05
Iter: 375 loss: 5.25907744e-05
Iter: 376 loss: 5.25907744e-05
Iter: 377 loss: 5.25907162e-05
Iter: 378 loss: 5.25907672e-05
Iter: 379 loss: 5.2590749e-05
Iter: 380 loss: 5.25906507e-05
Iter: 381 loss: 5.25905525e-05
Iter: 382 loss: 5.25906544e-05
Iter: 383 loss: 5.25905562e-05
Iter: 384 loss: 5.25905925e-05
Iter: 385 loss: 5.25906726e-05
Iter: 386 loss: 5.25905707e-05
Iter: 387 loss: 5.25906144e-05
Iter: 388 loss: 5.25907526e-05
Iter: 389 loss: 5.25905671e-05
Iter: 390 loss: 5.25905343e-05
Iter: 391 loss: 5.25905161e-05
Iter: 392 loss: 5.25904834e-05
Iter: 393 loss: 5.25905562e-05
Iter: 394 loss: 5.25905052e-05
Iter: 395 loss: 5.25904725e-05
Iter: 396 loss: 5.2590527e-05
Iter: 397 loss: 5.25904543e-05
Iter: 398 loss: 5.25905489e-05
Iter: 399 loss: 5.25904979e-05
Iter: 400 loss: 5.25905234e-05
Iter: 401 loss: 5.25905452e-05
Iter: 402 loss: 5.25904943e-05
Iter: 403 loss: 5.25905416e-05
Iter: 404 loss: 5.25904979e-05
Iter: 405 loss: 5.25905198e-05
Iter: 406 loss: 5.25905125e-05
Iter: 407 loss: 5.25905161e-05
Iter: 408 loss: 5.25905416e-05
Iter: 409 loss: 5.2590538e-05
Iter: 410 loss: 5.25905198e-05
Iter: 411 loss: 5.25905307e-05
Iter: 412 loss: 5.2590538e-05
Iter: 413 loss: 5.25905307e-05
Iter: 414 loss: 5.25905343e-05
Iter: 415 loss: 5.25905343e-05
Iter: 416 loss: 5.25905343e-05
Iter: 417 loss: 5.2590538e-05
Iter: 418 loss: 5.25905343e-05
Iter: 419 loss: 5.25905125e-05
Iter: 420 loss: 5.25908144e-05
Iter: 421 loss: 5.25904325e-05
Iter: 422 loss: 5.25904397e-05
Iter: 423 loss: 5.25904543e-05
Iter: 424 loss: 5.25905198e-05
Iter: 425 loss: 5.25904943e-05
Iter: 426 loss: 5.25904761e-05
Iter: 427 loss: 5.25904616e-05
Iter: 428 loss: 5.25903852e-05
Iter: 429 loss: 5.25904361e-05
Iter: 430 loss: 5.25904543e-05
Iter: 431 loss: 5.25904106e-05
Iter: 432 loss: 5.2590487e-05
Iter: 433 loss: 5.25904725e-05
Iter: 434 loss: 5.25904834e-05
Iter: 435 loss: 5.25905089e-05
Iter: 436 loss: 5.25904907e-05
Iter: 437 loss: 5.2590527e-05
Iter: 438 loss: 5.25904907e-05
Iter: 439 loss: 5.25905089e-05
Iter: 440 loss: 5.25905e-05
Iter: 441 loss: 5.25905089e-05
Iter: 442 loss: 5.25905052e-05
Iter: 443 loss: 5.25905089e-05
Iter: 444 loss: 5.25905089e-05
Iter: 445 loss: 5.25905052e-05
Iter: 446 loss: 5.25905052e-05
Iter: 447 loss: 5.25905052e-05
Iter: 448 loss: 5.25905089e-05
Iter: 449 loss: 5.25905052e-05
Iter: 450 loss: 5.25904907e-05
Iter: 451 loss: 5.25906144e-05
Iter: 452 loss: 5.25905161e-05
Iter: 453 loss: 5.25904834e-05
Iter: 454 loss: 5.25904179e-05
Iter: 455 loss: 5.25903815e-05
Iter: 456 loss: 5.25903779e-05
Iter: 457 loss: 5.25903852e-05
Iter: 458 loss: 5.25903852e-05
Iter: 459 loss: 5.25904179e-05
Iter: 460 loss: 5.25904252e-05
Iter: 461 loss: 5.25903561e-05
Iter: 462 loss: 5.25903197e-05
Iter: 463 loss: 5.25905489e-05
Iter: 464 loss: 5.25903852e-05
Iter: 465 loss: 5.2590367e-05
Iter: 466 loss: 5.2590367e-05
Iter: 467 loss: 5.25903524e-05
Iter: 468 loss: 5.25903197e-05
Iter: 469 loss: 5.25903706e-05
Iter: 470 loss: 5.25904106e-05
Iter: 471 loss: 5.25904179e-05
Iter: 472 loss: 5.25903888e-05
Iter: 473 loss: 5.25903488e-05
Iter: 474 loss: 5.25903633e-05
Iter: 475 loss: 5.25903743e-05
Iter: 476 loss: 5.2590367e-05
Iter: 477 loss: 5.25903633e-05
Iter: 478 loss: 5.25903779e-05
Iter: 479 loss: 5.25903852e-05
Iter: 480 loss: 5.25903451e-05
Iter: 481 loss: 5.25904034e-05
Iter: 482 loss: 5.25903233e-05
Iter: 483 loss: 5.2590367e-05
Iter: 484 loss: 5.25903706e-05
Iter: 485 loss: 5.25903743e-05
Iter: 486 loss: 5.25902724e-05
Iter: 487 loss: 5.25903888e-05
Iter: 488 loss: 5.25903924e-05
Iter: 489 loss: 5.25902906e-05
Iter: 490 loss: 5.25902651e-05
Iter: 491 loss: 5.25903088e-05
Iter: 492 loss: 5.25903815e-05
Iter: 493 loss: 5.25903306e-05
Iter: 494 loss: 5.25903342e-05
Iter: 495 loss: 5.25903743e-05
Iter: 496 loss: 5.25903051e-05
Iter: 497 loss: 5.25903451e-05
Iter: 498 loss: 5.25903415e-05
Iter: 499 loss: 5.25903306e-05
Iter: 500 loss: 5.25903233e-05
Iter: 501 loss: 5.25903306e-05
Iter: 502 loss: 5.25903488e-05
Iter: 503 loss: 5.25903306e-05
Iter: 504 loss: 5.25903e-05
Iter: 505 loss: 5.25903197e-05
Iter: 506 loss: 5.2590316e-05
Iter: 507 loss: 5.25903306e-05
Iter: 508 loss: 5.25903233e-05
Iter: 509 loss: 5.25903124e-05
Iter: 510 loss: 5.25903124e-05
Iter: 511 loss: 5.2590316e-05
Iter: 512 loss: 5.25903197e-05
Iter: 513 loss: 5.2590316e-05
Iter: 514 loss: 5.2590316e-05
Iter: 515 loss: 5.2590316e-05
Iter: 516 loss: 5.2590316e-05
Iter: 517 loss: 5.2590316e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8
+ date
Tue Oct 27 18:11:03 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26e8ccd158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26e8ce4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26e8ce4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26e8ce40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4481488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c44818c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c43fb6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c43fbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4421268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c43fbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c439a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4345bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4345f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c43627b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c43109d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4310950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c42d0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4285ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4239620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c424cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c42697b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c421e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c41d78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c41d7510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c418a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c419d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c416b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4107950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c41070d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c416b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c40f3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c409b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c409b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4038400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26c4064598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f26b0674378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0189302042
Iter: 2 loss: 0.0185577199
Iter: 3 loss: 0.0171408
Iter: 4 loss: 0.0123445131
Iter: 5 loss: 4552.89697
Iter: 6 loss: 0.012344514
Iter: 7 loss: 0.00795927271
Iter: 8 loss: 0.105985574
Iter: 9 loss: 0.00778492
Iter: 10 loss: 0.00417605042
Iter: 11 loss: 0.0760644898
Iter: 12 loss: 0.00416728435
Iter: 13 loss: 0.00259283883
Iter: 14 loss: 0.0150756855
Iter: 15 loss: 0.00239700684
Iter: 16 loss: 0.00167892489
Iter: 17 loss: 0.00629831199
Iter: 18 loss: 0.00157347368
Iter: 19 loss: 0.00118749239
Iter: 20 loss: 0.0011868393
Iter: 21 loss: 0.000945863198
Iter: 22 loss: 0.00320259109
Iter: 23 loss: 0.000935498
Iter: 24 loss: 0.000784846605
Iter: 25 loss: 0.000815604522
Iter: 26 loss: 0.000671821181
Iter: 27 loss: 0.000540526875
Iter: 28 loss: 0.00188570027
Iter: 29 loss: 0.000532343285
Iter: 30 loss: 0.000452699867
Iter: 31 loss: 0.000693860289
Iter: 32 loss: 0.000428625848
Iter: 33 loss: 0.00036096797
Iter: 34 loss: 0.000594416284
Iter: 35 loss: 0.000342096959
Iter: 36 loss: 0.00029636448
Iter: 37 loss: 0.000498406822
Iter: 38 loss: 0.000287689792
Iter: 39 loss: 0.000253731385
Iter: 40 loss: 0.000337430363
Iter: 41 loss: 0.000241000293
Iter: 42 loss: 0.000214999163
Iter: 43 loss: 0.000323683402
Iter: 44 loss: 0.000209478108
Iter: 45 loss: 0.00018793522
Iter: 46 loss: 0.000351182767
Iter: 47 loss: 0.000186154924
Iter: 48 loss: 0.000170773696
Iter: 49 loss: 0.000218817717
Iter: 50 loss: 0.000166416183
Iter: 51 loss: 0.000154594774
Iter: 52 loss: 0.000182944408
Iter: 53 loss: 0.000150254054
Iter: 54 loss: 0.000140113727
Iter: 55 loss: 0.000161442542
Iter: 56 loss: 0.000136058385
Iter: 57 loss: 0.000126285508
Iter: 58 loss: 0.000165653735
Iter: 59 loss: 0.000124087645
Iter: 60 loss: 0.000117941614
Iter: 61 loss: 0.000207749094
Iter: 62 loss: 0.000117930256
Iter: 63 loss: 0.000112999987
Iter: 64 loss: 0.000118351702
Iter: 65 loss: 0.000110299901
Iter: 66 loss: 0.000105749838
Iter: 67 loss: 0.000111861264
Iter: 68 loss: 0.000103470644
Iter: 69 loss: 9.92435089e-05
Iter: 70 loss: 0.00013584565
Iter: 71 loss: 9.89955151e-05
Iter: 72 loss: 9.5657655e-05
Iter: 73 loss: 0.000107435459
Iter: 74 loss: 9.48168e-05
Iter: 75 loss: 9.21604224e-05
Iter: 76 loss: 9.43232226e-05
Iter: 77 loss: 9.05615889e-05
Iter: 78 loss: 8.77955317e-05
Iter: 79 loss: 9.75155417e-05
Iter: 80 loss: 8.70805088e-05
Iter: 81 loss: 8.47579358e-05
Iter: 82 loss: 9.67604356e-05
Iter: 83 loss: 8.43790767e-05
Iter: 84 loss: 8.24366798e-05
Iter: 85 loss: 8.9789115e-05
Iter: 86 loss: 8.19766865e-05
Iter: 87 loss: 8.03310104e-05
Iter: 88 loss: 8.19678389e-05
Iter: 89 loss: 7.93991203e-05
Iter: 90 loss: 7.76891902e-05
Iter: 91 loss: 8.38264605e-05
Iter: 92 loss: 7.72528074e-05
Iter: 93 loss: 7.57607122e-05
Iter: 94 loss: 8.12850631e-05
Iter: 95 loss: 7.53937638e-05
Iter: 96 loss: 7.43113342e-05
Iter: 97 loss: 8.49049247e-05
Iter: 98 loss: 7.42726697e-05
Iter: 99 loss: 7.33479901e-05
Iter: 100 loss: 7.45234283e-05
Iter: 101 loss: 7.28714149e-05
Iter: 102 loss: 7.19660311e-05
Iter: 103 loss: 7.27461e-05
Iter: 104 loss: 7.14327616e-05
Iter: 105 loss: 7.04687845e-05
Iter: 106 loss: 7.56226946e-05
Iter: 107 loss: 7.03191181e-05
Iter: 108 loss: 6.95988128e-05
Iter: 109 loss: 7.58488532e-05
Iter: 110 loss: 6.95627532e-05
Iter: 111 loss: 6.89938e-05
Iter: 112 loss: 6.91153691e-05
Iter: 113 loss: 6.85721316e-05
Iter: 114 loss: 6.7949979e-05
Iter: 115 loss: 6.89768785e-05
Iter: 116 loss: 6.76666677e-05
Iter: 117 loss: 6.70783338e-05
Iter: 118 loss: 7.18739175e-05
Iter: 119 loss: 6.70400914e-05
Iter: 120 loss: 6.65596235e-05
Iter: 121 loss: 6.71990201e-05
Iter: 122 loss: 6.63174e-05
Iter: 123 loss: 6.58125646e-05
Iter: 124 loss: 6.67909771e-05
Iter: 125 loss: 6.56016928e-05
Iter: 126 loss: 6.51030641e-05
Iter: 127 loss: 6.65998596e-05
Iter: 128 loss: 6.49524954e-05
Iter: 129 loss: 6.45210239e-05
Iter: 130 loss: 6.67133863e-05
Iter: 131 loss: 6.44502579e-05
Iter: 132 loss: 6.40885119e-05
Iter: 133 loss: 6.66557462e-05
Iter: 134 loss: 6.40560902e-05
Iter: 135 loss: 6.37668636e-05
Iter: 136 loss: 6.38899292e-05
Iter: 137 loss: 6.35687538e-05
Iter: 138 loss: 6.32440933e-05
Iter: 139 loss: 6.3887841e-05
Iter: 140 loss: 6.31112271e-05
Iter: 141 loss: 6.28202251e-05
Iter: 142 loss: 6.47494671e-05
Iter: 143 loss: 6.27897389e-05
Iter: 144 loss: 6.2545143e-05
Iter: 145 loss: 6.38552156e-05
Iter: 146 loss: 6.25087268e-05
Iter: 147 loss: 6.23101732e-05
Iter: 148 loss: 6.23416272e-05
Iter: 149 loss: 6.21602812e-05
Iter: 150 loss: 6.19276398e-05
Iter: 151 loss: 6.25604225e-05
Iter: 152 loss: 6.18514387e-05
Iter: 153 loss: 6.16387915e-05
Iter: 154 loss: 6.29469723e-05
Iter: 155 loss: 6.16132e-05
Iter: 156 loss: 6.14265518e-05
Iter: 157 loss: 6.15642639e-05
Iter: 158 loss: 6.1312021e-05
Iter: 159 loss: 6.11196447e-05
Iter: 160 loss: 6.16583275e-05
Iter: 161 loss: 6.10579737e-05
Iter: 162 loss: 6.08753107e-05
Iter: 163 loss: 6.15012686e-05
Iter: 164 loss: 6.082666e-05
Iter: 165 loss: 6.06763679e-05
Iter: 166 loss: 6.1705141e-05
Iter: 167 loss: 6.06618742e-05
Iter: 168 loss: 6.05300957e-05
Iter: 169 loss: 6.09956587e-05
Iter: 170 loss: 6.04959932e-05
Iter: 171 loss: 6.0387436e-05
Iter: 172 loss: 6.04166526e-05
Iter: 173 loss: 6.03086264e-05
Iter: 174 loss: 6.01844404e-05
Iter: 175 loss: 6.06252288e-05
Iter: 176 loss: 6.01526481e-05
Iter: 177 loss: 6.00478052e-05
Iter: 178 loss: 6.09441922e-05
Iter: 179 loss: 6.00419371e-05
Iter: 180 loss: 5.99531559e-05
Iter: 181 loss: 6.00951789e-05
Iter: 182 loss: 5.99121886e-05
Iter: 183 loss: 5.98242259e-05
Iter: 184 loss: 5.98861225e-05
Iter: 185 loss: 5.97695871e-05
Iter: 186 loss: 5.96752652e-05
Iter: 187 loss: 6.01594365e-05
Iter: 188 loss: 5.96601021e-05
Iter: 189 loss: 5.95764068e-05
Iter: 190 loss: 5.98421575e-05
Iter: 191 loss: 5.95523925e-05
Iter: 192 loss: 5.9475653e-05
Iter: 193 loss: 5.95877791e-05
Iter: 194 loss: 5.94384255e-05
Iter: 195 loss: 5.93607037e-05
Iter: 196 loss: 5.9549242e-05
Iter: 197 loss: 5.9332815e-05
Iter: 198 loss: 5.92566867e-05
Iter: 199 loss: 5.95772872e-05
Iter: 200 loss: 5.92403958e-05
Iter: 201 loss: 5.91812714e-05
Iter: 202 loss: 5.96835525e-05
Iter: 203 loss: 5.91779099e-05
Iter: 204 loss: 5.91274875e-05
Iter: 205 loss: 5.91673379e-05
Iter: 206 loss: 5.90970158e-05
Iter: 207 loss: 5.90452837e-05
Iter: 208 loss: 5.90917116e-05
Iter: 209 loss: 5.90152231e-05
Iter: 210 loss: 5.89604169e-05
Iter: 211 loss: 5.93038712e-05
Iter: 212 loss: 5.89541305e-05
Iter: 213 loss: 5.89097326e-05
Iter: 214 loss: 5.92424803e-05
Iter: 215 loss: 5.89061892e-05
Iter: 216 loss: 5.88734692e-05
Iter: 217 loss: 5.88725125e-05
Iter: 218 loss: 5.88468647e-05
Iter: 219 loss: 5.88054354e-05
Iter: 220 loss: 5.88879266e-05
Iter: 221 loss: 5.87883733e-05
Iter: 222 loss: 5.8747828e-05
Iter: 223 loss: 5.8994061e-05
Iter: 224 loss: 5.87429022e-05
Iter: 225 loss: 5.8708858e-05
Iter: 226 loss: 5.87766881e-05
Iter: 227 loss: 5.86949318e-05
Iter: 228 loss: 5.86628375e-05
Iter: 229 loss: 5.8712234e-05
Iter: 230 loss: 5.86478127e-05
Iter: 231 loss: 5.86126807e-05
Iter: 232 loss: 5.87557697e-05
Iter: 233 loss: 5.86050301e-05
Iter: 234 loss: 5.85778798e-05
Iter: 235 loss: 5.86943206e-05
Iter: 236 loss: 5.8572321e-05
Iter: 237 loss: 5.85467678e-05
Iter: 238 loss: 5.87053401e-05
Iter: 239 loss: 5.85438393e-05
Iter: 240 loss: 5.85253692e-05
Iter: 241 loss: 5.85150483e-05
Iter: 242 loss: 5.85069829e-05
Iter: 243 loss: 5.8482321e-05
Iter: 244 loss: 5.85909584e-05
Iter: 245 loss: 5.84773734e-05
Iter: 246 loss: 5.84578156e-05
Iter: 247 loss: 5.8619491e-05
Iter: 248 loss: 5.84566e-05
Iter: 249 loss: 5.84395457e-05
Iter: 250 loss: 5.84740119e-05
Iter: 251 loss: 5.84325389e-05
Iter: 252 loss: 5.84171139e-05
Iter: 253 loss: 5.842e-05
Iter: 254 loss: 5.84056033e-05
Iter: 255 loss: 5.83878427e-05
Iter: 256 loss: 5.84754e-05
Iter: 257 loss: 5.83847395e-05
Iter: 258 loss: 5.83679212e-05
Iter: 259 loss: 5.84234076e-05
Iter: 260 loss: 5.83632391e-05
Iter: 261 loss: 5.83482324e-05
Iter: 262 loss: 5.83714609e-05
Iter: 263 loss: 5.8341313e-05
Iter: 264 loss: 5.83262081e-05
Iter: 265 loss: 5.83784968e-05
Iter: 266 loss: 5.83222063e-05
Iter: 267 loss: 5.83087822e-05
Iter: 268 loss: 5.83486471e-05
Iter: 269 loss: 5.83047295e-05
Iter: 270 loss: 5.82926514e-05
Iter: 271 loss: 5.83950641e-05
Iter: 272 loss: 5.82919347e-05
Iter: 273 loss: 5.82822395e-05
Iter: 274 loss: 5.82889297e-05
Iter: 275 loss: 5.82761277e-05
Iter: 276 loss: 5.82657231e-05
Iter: 277 loss: 5.82741559e-05
Iter: 278 loss: 5.82593384e-05
Iter: 279 loss: 5.82488e-05
Iter: 280 loss: 5.83380352e-05
Iter: 281 loss: 5.82480752e-05
Iter: 282 loss: 5.82393477e-05
Iter: 283 loss: 5.8284204e-05
Iter: 284 loss: 5.8237878e-05
Iter: 285 loss: 5.82307221e-05
Iter: 286 loss: 5.82310495e-05
Iter: 287 loss: 5.82250832e-05
Iter: 288 loss: 5.82163266e-05
Iter: 289 loss: 5.82353532e-05
Iter: 290 loss: 5.82130087e-05
Iter: 291 loss: 5.82047142e-05
Iter: 292 loss: 5.82547727e-05
Iter: 293 loss: 5.82036882e-05
Iter: 294 loss: 5.81968161e-05
Iter: 295 loss: 5.82084213e-05
Iter: 296 loss: 5.8193662e-05
Iter: 297 loss: 5.81866407e-05
Iter: 298 loss: 5.82025241e-05
Iter: 299 loss: 5.81838503e-05
Iter: 300 loss: 5.817704e-05
Iter: 301 loss: 5.81983622e-05
Iter: 302 loss: 5.81750173e-05
Iter: 303 loss: 5.81690401e-05
Iter: 304 loss: 5.82075736e-05
Iter: 305 loss: 5.81684071e-05
Iter: 306 loss: 5.81630411e-05
Iter: 307 loss: 5.81806926e-05
Iter: 308 loss: 5.81616259e-05
Iter: 309 loss: 5.81568529e-05
Iter: 310 loss: 5.81565037e-05
Iter: 311 loss: 5.81529275e-05
Iter: 312 loss: 5.81474851e-05
Iter: 313 loss: 5.81703898e-05
Iter: 314 loss: 5.81462882e-05
Iter: 315 loss: 5.8141708e-05
Iter: 316 loss: 5.81902932e-05
Iter: 317 loss: 5.81417189e-05
Iter: 318 loss: 5.81381355e-05
Iter: 319 loss: 5.81392087e-05
Iter: 320 loss: 5.81355271e-05
Iter: 321 loss: 5.81314671e-05
Iter: 322 loss: 5.81380555e-05
Iter: 323 loss: 5.81295717e-05
Iter: 324 loss: 5.81254208e-05
Iter: 325 loss: 5.81404383e-05
Iter: 326 loss: 5.81243512e-05
Iter: 327 loss: 5.81203749e-05
Iter: 328 loss: 5.81342174e-05
Iter: 329 loss: 5.81193126e-05
Iter: 330 loss: 5.81158783e-05
Iter: 331 loss: 5.81239219e-05
Iter: 332 loss: 5.81145141e-05
Iter: 333 loss: 5.81110689e-05
Iter: 334 loss: 5.81176355e-05
Iter: 335 loss: 5.81095082e-05
Iter: 336 loss: 5.81060922e-05
Iter: 337 loss: 5.81213862e-05
Iter: 338 loss: 5.81054337e-05
Iter: 339 loss: 5.81024869e-05
Iter: 340 loss: 5.81239692e-05
Iter: 341 loss: 5.81022105e-05
Iter: 342 loss: 5.80998e-05
Iter: 343 loss: 5.81001295e-05
Iter: 344 loss: 5.80979904e-05
Iter: 345 loss: 5.80951491e-05
Iter: 346 loss: 5.80997803e-05
Iter: 347 loss: 5.80937813e-05
Iter: 348 loss: 5.80912638e-05
Iter: 349 loss: 5.81158674e-05
Iter: 350 loss: 5.8091111e-05
Iter: 351 loss: 5.80888773e-05
Iter: 352 loss: 5.8096477e-05
Iter: 353 loss: 5.80882843e-05
Iter: 354 loss: 5.80864289e-05
Iter: 355 loss: 5.80863343e-05
Iter: 356 loss: 5.80850283e-05
Iter: 357 loss: 5.80828e-05
Iter: 358 loss: 5.80921733e-05
Iter: 359 loss: 5.80822816e-05
Iter: 360 loss: 5.80801679e-05
Iter: 361 loss: 5.80850174e-05
Iter: 362 loss: 5.80794294e-05
Iter: 363 loss: 5.80773121e-05
Iter: 364 loss: 5.80860797e-05
Iter: 365 loss: 5.80769483e-05
Iter: 366 loss: 5.80751293e-05
Iter: 367 loss: 5.8077665e-05
Iter: 368 loss: 5.80742562e-05
Iter: 369 loss: 5.80723135e-05
Iter: 370 loss: 5.80771411e-05
Iter: 371 loss: 5.80716733e-05
Iter: 372 loss: 5.80699125e-05
Iter: 373 loss: 5.80850501e-05
Iter: 374 loss: 5.80698e-05
Iter: 375 loss: 5.80683336e-05
Iter: 376 loss: 5.80711785e-05
Iter: 377 loss: 5.80677734e-05
Iter: 378 loss: 5.80664055e-05
Iter: 379 loss: 5.80665401e-05
Iter: 380 loss: 5.80653286e-05
Iter: 381 loss: 5.80636624e-05
Iter: 382 loss: 5.80729757e-05
Iter: 383 loss: 5.80635169e-05
Iter: 384 loss: 5.80621381e-05
Iter: 385 loss: 5.80759406e-05
Iter: 386 loss: 5.80621636e-05
Iter: 387 loss: 5.80611268e-05
Iter: 388 loss: 5.80605411e-05
Iter: 389 loss: 5.80602136e-05
Iter: 390 loss: 5.80589112e-05
Iter: 391 loss: 5.80623528e-05
Iter: 392 loss: 5.80584419e-05
Iter: 393 loss: 5.80571796e-05
Iter: 394 loss: 5.80621891e-05
Iter: 395 loss: 5.80568376e-05
Iter: 396 loss: 5.80557607e-05
Iter: 397 loss: 5.80593914e-05
Iter: 398 loss: 5.80554115e-05
Iter: 399 loss: 5.80543383e-05
Iter: 400 loss: 5.80567503e-05
Iter: 401 loss: 5.80539272e-05
Iter: 402 loss: 5.80529e-05
Iter: 403 loss: 5.80553569e-05
Iter: 404 loss: 5.8052552e-05
Iter: 405 loss: 5.80515116e-05
Iter: 406 loss: 5.80558772e-05
Iter: 407 loss: 5.80512969e-05
Iter: 408 loss: 5.80504493e-05
Iter: 409 loss: 5.80559863e-05
Iter: 410 loss: 5.80503693e-05
Iter: 411 loss: 5.80496308e-05
Iter: 412 loss: 5.8049518e-05
Iter: 413 loss: 5.80490705e-05
Iter: 414 loss: 5.80482774e-05
Iter: 415 loss: 5.80510095e-05
Iter: 416 loss: 5.80480555e-05
Iter: 417 loss: 5.80474407e-05
Iter: 418 loss: 5.80543e-05
Iter: 419 loss: 5.80473497e-05
Iter: 420 loss: 5.80467749e-05
Iter: 421 loss: 5.80472697e-05
Iter: 422 loss: 5.80463857e-05
Iter: 423 loss: 5.80458654e-05
Iter: 424 loss: 5.80460801e-05
Iter: 425 loss: 5.8045418e-05
Iter: 426 loss: 5.80446285e-05
Iter: 427 loss: 5.8048081e-05
Iter: 428 loss: 5.80445521e-05
Iter: 429 loss: 5.80439155e-05
Iter: 430 loss: 5.80460292e-05
Iter: 431 loss: 5.80437372e-05
Iter: 432 loss: 5.80431661e-05
Iter: 433 loss: 5.80445339e-05
Iter: 434 loss: 5.80428641e-05
Iter: 435 loss: 5.8042333e-05
Iter: 436 loss: 5.80440901e-05
Iter: 437 loss: 5.80422711e-05
Iter: 438 loss: 5.8041609e-05
Iter: 439 loss: 5.80429623e-05
Iter: 440 loss: 5.80414926e-05
Iter: 441 loss: 5.80410815e-05
Iter: 442 loss: 5.8045629e-05
Iter: 443 loss: 5.80410706e-05
Iter: 444 loss: 5.80406486e-05
Iter: 445 loss: 5.80406122e-05
Iter: 446 loss: 5.80403939e-05
Iter: 447 loss: 5.80398482e-05
Iter: 448 loss: 5.8040634e-05
Iter: 449 loss: 5.80397573e-05
Iter: 450 loss: 5.80392734e-05
Iter: 451 loss: 5.80424457e-05
Iter: 452 loss: 5.80392734e-05
Iter: 453 loss: 5.80388732e-05
Iter: 454 loss: 5.80405758e-05
Iter: 455 loss: 5.80388114e-05
Iter: 456 loss: 5.80384112e-05
Iter: 457 loss: 5.80383639e-05
Iter: 458 loss: 5.80382693e-05
Iter: 459 loss: 5.8037811e-05
Iter: 460 loss: 5.80390406e-05
Iter: 461 loss: 5.80377309e-05
Iter: 462 loss: 5.80373671e-05
Iter: 463 loss: 5.80390115e-05
Iter: 464 loss: 5.80372871e-05
Iter: 465 loss: 5.80369597e-05
Iter: 466 loss: 5.8037891e-05
Iter: 467 loss: 5.80369087e-05
Iter: 468 loss: 5.8036585e-05
Iter: 469 loss: 5.8037087e-05
Iter: 470 loss: 5.80365086e-05
Iter: 471 loss: 5.80360902e-05
Iter: 472 loss: 5.80372871e-05
Iter: 473 loss: 5.80360356e-05
Iter: 474 loss: 5.80357628e-05
Iter: 475 loss: 5.80369815e-05
Iter: 476 loss: 5.80357118e-05
Iter: 477 loss: 5.80354827e-05
Iter: 478 loss: 5.80362757e-05
Iter: 479 loss: 5.80354244e-05
Iter: 480 loss: 5.80352607e-05
Iter: 481 loss: 5.8035097e-05
Iter: 482 loss: 5.8034937e-05
Iter: 483 loss: 5.8034726e-05
Iter: 484 loss: 5.80360138e-05
Iter: 485 loss: 5.80346168e-05
Iter: 486 loss: 5.80344e-05
Iter: 487 loss: 5.80368833e-05
Iter: 488 loss: 5.80343694e-05
Iter: 489 loss: 5.80343112e-05
Iter: 490 loss: 5.80341693e-05
Iter: 491 loss: 5.80340929e-05
Iter: 492 loss: 5.80338929e-05
Iter: 493 loss: 5.80343039e-05
Iter: 494 loss: 5.8033751e-05
Iter: 495 loss: 5.80335545e-05
Iter: 496 loss: 5.80343585e-05
Iter: 497 loss: 5.80334454e-05
Iter: 498 loss: 5.80333326e-05
Iter: 499 loss: 5.8034293e-05
Iter: 500 loss: 5.8033238e-05
Iter: 501 loss: 5.80331471e-05
Iter: 502 loss: 5.80333508e-05
Iter: 503 loss: 5.80329834e-05
Iter: 504 loss: 5.80328706e-05
Iter: 505 loss: 5.80336746e-05
Iter: 506 loss: 5.80326778e-05
Iter: 507 loss: 5.80326341e-05
Iter: 508 loss: 5.80331543e-05
Iter: 509 loss: 5.80325541e-05
Iter: 510 loss: 5.80324922e-05
Iter: 511 loss: 5.8033369e-05
Iter: 512 loss: 5.80324158e-05
Iter: 513 loss: 5.80323467e-05
Iter: 514 loss: 5.80322449e-05
Iter: 515 loss: 5.80321648e-05
Iter: 516 loss: 5.80320193e-05
Iter: 517 loss: 5.80324158e-05
Iter: 518 loss: 5.80320338e-05
Iter: 519 loss: 5.80317937e-05
Iter: 520 loss: 5.80338819e-05
Iter: 521 loss: 5.80318083e-05
Iter: 522 loss: 5.8031721e-05
Iter: 523 loss: 5.80317392e-05
Iter: 524 loss: 5.8031681e-05
Iter: 525 loss: 5.80314445e-05
Iter: 526 loss: 5.803159e-05
Iter: 527 loss: 5.80314882e-05
Iter: 528 loss: 5.80312e-05
Iter: 529 loss: 5.80316337e-05
Iter: 530 loss: 5.8031259e-05
Iter: 531 loss: 5.80311025e-05
Iter: 532 loss: 5.80316555e-05
Iter: 533 loss: 5.80310734e-05
Iter: 534 loss: 5.80309679e-05
Iter: 535 loss: 5.80312444e-05
Iter: 536 loss: 5.80308842e-05
Iter: 537 loss: 5.80308442e-05
Iter: 538 loss: 5.8031e-05
Iter: 539 loss: 5.80307533e-05
Iter: 540 loss: 5.8030535e-05
Iter: 541 loss: 5.80311716e-05
Iter: 542 loss: 5.80306332e-05
Iter: 543 loss: 5.8030615e-05
Iter: 544 loss: 5.8031248e-05
Iter: 545 loss: 5.80305e-05
Iter: 546 loss: 5.80304622e-05
Iter: 547 loss: 5.80303677e-05
Iter: 548 loss: 5.80303495e-05
Iter: 549 loss: 5.80303822e-05
Iter: 550 loss: 5.80303386e-05
Iter: 551 loss: 5.80303167e-05
Iter: 552 loss: 5.80301712e-05
Iter: 553 loss: 5.80307133e-05
Iter: 554 loss: 5.80301094e-05
Iter: 555 loss: 5.80300621e-05
Iter: 556 loss: 5.80305641e-05
Iter: 557 loss: 5.80300657e-05
Iter: 558 loss: 5.80300475e-05
Iter: 559 loss: 5.8030033e-05
Iter: 560 loss: 5.80299893e-05
Iter: 561 loss: 5.80299529e-05
Iter: 562 loss: 5.80301275e-05
Iter: 563 loss: 5.80298765e-05
Iter: 564 loss: 5.80297747e-05
Iter: 565 loss: 5.80299311e-05
Iter: 566 loss: 5.80298e-05
Iter: 567 loss: 5.80296655e-05
Iter: 568 loss: 5.80300184e-05
Iter: 569 loss: 5.80296874e-05
Iter: 570 loss: 5.80296146e-05
Iter: 571 loss: 5.80297128e-05
Iter: 572 loss: 5.80296255e-05
Iter: 573 loss: 5.80296e-05
Iter: 574 loss: 5.80296946e-05
Iter: 575 loss: 5.80294472e-05
Iter: 576 loss: 5.80294763e-05
Iter: 577 loss: 5.80298656e-05
Iter: 578 loss: 5.80294873e-05
Iter: 579 loss: 5.80294836e-05
Iter: 580 loss: 5.80295637e-05
Iter: 581 loss: 5.80293163e-05
Iter: 582 loss: 5.80293199e-05
Iter: 583 loss: 5.80293417e-05
Iter: 584 loss: 5.80293126e-05
Iter: 585 loss: 5.80292181e-05
Iter: 586 loss: 5.80295055e-05
Iter: 587 loss: 5.80293454e-05
Iter: 588 loss: 5.80292472e-05
Iter: 589 loss: 5.80296546e-05
Iter: 590 loss: 5.80292326e-05
Iter: 591 loss: 5.80292e-05
Iter: 592 loss: 5.80291598e-05
Iter: 593 loss: 5.80291453e-05
Iter: 594 loss: 5.80291453e-05
Iter: 595 loss: 5.80292144e-05
Iter: 596 loss: 5.80291198e-05
Iter: 597 loss: 5.80291235e-05
Iter: 598 loss: 5.8029178e-05
Iter: 599 loss: 5.80290071e-05
Iter: 600 loss: 5.80291235e-05
Iter: 601 loss: 5.80289525e-05
Iter: 602 loss: 5.80290725e-05
Iter: 603 loss: 5.8029e-05
Iter: 604 loss: 5.80290143e-05
Iter: 605 loss: 5.8029e-05
Iter: 606 loss: 5.80290143e-05
Iter: 607 loss: 5.80290834e-05
Iter: 608 loss: 5.80290471e-05
Iter: 609 loss: 5.80290871e-05
Iter: 610 loss: 5.80290252e-05
Iter: 611 loss: 5.80290362e-05
Iter: 612 loss: 5.80290907e-05
Iter: 613 loss: 5.80290434e-05
Iter: 614 loss: 5.80290653e-05
Iter: 615 loss: 5.80290653e-05
Iter: 616 loss: 5.80290762e-05
Iter: 617 loss: 5.80290725e-05
Iter: 618 loss: 5.80290653e-05
Iter: 619 loss: 5.80290653e-05
Iter: 620 loss: 5.80290798e-05
Iter: 621 loss: 5.80290725e-05
Iter: 622 loss: 5.80290725e-05
Iter: 623 loss: 5.80290653e-05
Iter: 624 loss: 5.80290725e-05
Iter: 625 loss: 5.80290653e-05
Iter: 626 loss: 5.80289525e-05
Iter: 627 loss: 5.80293417e-05
Iter: 628 loss: 5.8029e-05
Iter: 629 loss: 5.80289634e-05
Iter: 630 loss: 5.80293854e-05
Iter: 631 loss: 5.80289125e-05
Iter: 632 loss: 5.80289634e-05
Iter: 633 loss: 5.80289161e-05
Iter: 634 loss: 5.80288397e-05
Iter: 635 loss: 5.80288543e-05
Iter: 636 loss: 5.80289416e-05
Iter: 637 loss: 5.80288652e-05
Iter: 638 loss: 5.80287669e-05
Iter: 639 loss: 5.80287306e-05
Iter: 640 loss: 5.80288179e-05
Iter: 641 loss: 5.80287815e-05
Iter: 642 loss: 5.80287488e-05
Iter: 643 loss: 5.80286833e-05
Iter: 644 loss: 5.80286869e-05
Iter: 645 loss: 5.80290907e-05
Iter: 646 loss: 5.80287415e-05
Iter: 647 loss: 5.80287378e-05
Iter: 648 loss: 5.80287233e-05
Iter: 649 loss: 5.80286796e-05
Iter: 650 loss: 5.80286869e-05
Iter: 651 loss: 5.80286796e-05
Iter: 652 loss: 5.80286251e-05
Iter: 653 loss: 5.80285414e-05
Iter: 654 loss: 5.80286141e-05
Iter: 655 loss: 5.80286287e-05
Iter: 656 loss: 5.80285741e-05
Iter: 657 loss: 5.80287597e-05
Iter: 658 loss: 5.80285232e-05
Iter: 659 loss: 5.8028505e-05
Iter: 660 loss: 5.80286069e-05
Iter: 661 loss: 5.80285268e-05
Iter: 662 loss: 5.80285196e-05
Iter: 663 loss: 5.80285814e-05
Iter: 664 loss: 5.80285268e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2
+ date
Tue Oct 27 18:20:04 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e84bf20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e84c9fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e84ce7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e84ce7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6047b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6048b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6045bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e604067b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60424268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60406730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e603908c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60391f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6032f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60390488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6033df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e602bb730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e602cf6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60276378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6023b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60266158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e602669d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60215ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e601d2e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60175730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e601d2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6019a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6014ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6014e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e601180d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e600b7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e600727b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e600721e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e60096620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e600a18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6005ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6005eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.020469781
Iter: 2 loss: 0.0191067606
Iter: 3 loss: 0.0148489401
Iter: 4 loss: 4624.99658
Iter: 5 loss: 0.0148489382
Iter: 6 loss: 0.0119080395
Iter: 7 loss: 0.0114608509
Iter: 8 loss: 0.00870555453
Iter: 9 loss: 0.106633231
Iter: 10 loss: 0.00870514475
Iter: 11 loss: 0.0064672213
Iter: 12 loss: 0.0186219849
Iter: 13 loss: 0.0061089918
Iter: 14 loss: 0.00482086651
Iter: 15 loss: 0.00788323395
Iter: 16 loss: 0.0044005271
Iter: 17 loss: 0.00328618172
Iter: 18 loss: 0.00865444168
Iter: 19 loss: 0.00294138351
Iter: 20 loss: 0.00230362266
Iter: 21 loss: 0.00228628796
Iter: 22 loss: 0.00194111536
Iter: 23 loss: 0.00273860944
Iter: 24 loss: 0.0018178171
Iter: 25 loss: 0.0015887256
Iter: 26 loss: 0.00195791898
Iter: 27 loss: 0.00147611659
Iter: 28 loss: 0.00126292696
Iter: 29 loss: 0.00216237968
Iter: 30 loss: 0.00121138198
Iter: 31 loss: 0.00105869642
Iter: 32 loss: 0.00168117252
Iter: 33 loss: 0.00102443015
Iter: 34 loss: 0.000908262795
Iter: 35 loss: 0.00111169147
Iter: 36 loss: 0.000854726764
Iter: 37 loss: 0.00075355731
Iter: 38 loss: 0.00113929727
Iter: 39 loss: 0.000728527666
Iter: 40 loss: 0.000655866461
Iter: 41 loss: 0.00125927234
Iter: 42 loss: 0.000651182607
Iter: 43 loss: 0.000592307828
Iter: 44 loss: 0.000652893388
Iter: 45 loss: 0.000558484811
Iter: 46 loss: 0.000503198884
Iter: 47 loss: 0.000955723342
Iter: 48 loss: 0.000499912887
Iter: 49 loss: 0.000456825568
Iter: 50 loss: 0.000669100671
Iter: 51 loss: 0.000448172941
Iter: 52 loss: 0.000412232039
Iter: 53 loss: 0.00042614821
Iter: 54 loss: 0.000387380074
Iter: 55 loss: 0.000351238239
Iter: 56 loss: 0.000719694304
Iter: 57 loss: 0.000349803129
Iter: 58 loss: 0.000327231479
Iter: 59 loss: 0.000327155052
Iter: 60 loss: 0.000314466248
Iter: 61 loss: 0.000296807411
Iter: 62 loss: 0.000296043
Iter: 63 loss: 0.000275147264
Iter: 64 loss: 0.000322601816
Iter: 65 loss: 0.000267125724
Iter: 66 loss: 0.000247184129
Iter: 67 loss: 0.000347932772
Iter: 68 loss: 0.000243848539
Iter: 69 loss: 0.000229054946
Iter: 70 loss: 0.000372297945
Iter: 71 loss: 0.000228400881
Iter: 72 loss: 0.00021691795
Iter: 73 loss: 0.000236136038
Iter: 74 loss: 0.000211746636
Iter: 75 loss: 0.000201317496
Iter: 76 loss: 0.000220905029
Iter: 77 loss: 0.00019681835
Iter: 78 loss: 0.000186894235
Iter: 79 loss: 0.000208799043
Iter: 80 loss: 0.000183053839
Iter: 81 loss: 0.000173158478
Iter: 82 loss: 0.000213866326
Iter: 83 loss: 0.000170929663
Iter: 84 loss: 0.00016249629
Iter: 85 loss: 0.000179232389
Iter: 86 loss: 0.00015904622
Iter: 87 loss: 0.000151842964
Iter: 88 loss: 0.000203439544
Iter: 89 loss: 0.00015125057
Iter: 90 loss: 0.000145878177
Iter: 91 loss: 0.000181898911
Iter: 92 loss: 0.000145276324
Iter: 93 loss: 0.000140682692
Iter: 94 loss: 0.000170380197
Iter: 95 loss: 0.000140216696
Iter: 96 loss: 0.000136888673
Iter: 97 loss: 0.000133704452
Iter: 98 loss: 0.000132953544
Iter: 99 loss: 0.000128532542
Iter: 100 loss: 0.000143142301
Iter: 101 loss: 0.000127314022
Iter: 102 loss: 0.000123493737
Iter: 103 loss: 0.000137585681
Iter: 104 loss: 0.000122555357
Iter: 105 loss: 0.00011889208
Iter: 106 loss: 0.000135238573
Iter: 107 loss: 0.000118157375
Iter: 108 loss: 0.000115097784
Iter: 109 loss: 0.000130962449
Iter: 110 loss: 0.000114616574
Iter: 111 loss: 0.000112271155
Iter: 112 loss: 0.000110411791
Iter: 113 loss: 0.000109692395
Iter: 114 loss: 0.000106298445
Iter: 115 loss: 0.000120775148
Iter: 116 loss: 0.000105591746
Iter: 117 loss: 0.000102709731
Iter: 118 loss: 0.000110790876
Iter: 119 loss: 0.000101777136
Iter: 120 loss: 9.92930436e-05
Iter: 121 loss: 0.000111129426
Iter: 122 loss: 9.88416432e-05
Iter: 123 loss: 9.66760563e-05
Iter: 124 loss: 0.000107130218
Iter: 125 loss: 9.63003476e-05
Iter: 126 loss: 9.48319066e-05
Iter: 127 loss: 0.000113080692
Iter: 128 loss: 9.48135712e-05
Iter: 129 loss: 9.34353156e-05
Iter: 130 loss: 9.35199641e-05
Iter: 131 loss: 9.23611951e-05
Iter: 132 loss: 9.10187155e-05
Iter: 133 loss: 9.0861e-05
Iter: 134 loss: 8.98943908e-05
Iter: 135 loss: 8.8146342e-05
Iter: 136 loss: 0.000100532445
Iter: 137 loss: 8.79882282e-05
Iter: 138 loss: 8.67308772e-05
Iter: 139 loss: 8.88188515e-05
Iter: 140 loss: 8.61600274e-05
Iter: 141 loss: 8.47929696e-05
Iter: 142 loss: 9.65287618e-05
Iter: 143 loss: 8.47152842e-05
Iter: 144 loss: 8.37278203e-05
Iter: 145 loss: 8.42891677e-05
Iter: 146 loss: 8.30853824e-05
Iter: 147 loss: 8.18698245e-05
Iter: 148 loss: 8.40718276e-05
Iter: 149 loss: 8.13405131e-05
Iter: 150 loss: 8.02503855e-05
Iter: 151 loss: 8.2790044e-05
Iter: 152 loss: 7.98474e-05
Iter: 153 loss: 7.87633253e-05
Iter: 154 loss: 8.13309307e-05
Iter: 155 loss: 7.83665819e-05
Iter: 156 loss: 7.73514475e-05
Iter: 157 loss: 8.00850103e-05
Iter: 158 loss: 7.70137849e-05
Iter: 159 loss: 7.61748379e-05
Iter: 160 loss: 8.66697519e-05
Iter: 161 loss: 7.61677875e-05
Iter: 162 loss: 7.55704241e-05
Iter: 163 loss: 8.06344542e-05
Iter: 164 loss: 7.55347282e-05
Iter: 165 loss: 7.5059419e-05
Iter: 166 loss: 7.43105047e-05
Iter: 167 loss: 7.43025375e-05
Iter: 168 loss: 7.35044159e-05
Iter: 169 loss: 7.66980229e-05
Iter: 170 loss: 7.3324547e-05
Iter: 171 loss: 7.26605795e-05
Iter: 172 loss: 7.41781914e-05
Iter: 173 loss: 7.24112397e-05
Iter: 174 loss: 7.17834555e-05
Iter: 175 loss: 7.70104e-05
Iter: 176 loss: 7.17461589e-05
Iter: 177 loss: 7.12582405e-05
Iter: 178 loss: 7.24919955e-05
Iter: 179 loss: 7.10874665e-05
Iter: 180 loss: 7.05747589e-05
Iter: 181 loss: 7.16386421e-05
Iter: 182 loss: 7.03703845e-05
Iter: 183 loss: 6.99210213e-05
Iter: 184 loss: 7.00860837e-05
Iter: 185 loss: 6.9606016e-05
Iter: 186 loss: 6.90738088e-05
Iter: 187 loss: 7.17454823e-05
Iter: 188 loss: 6.89846e-05
Iter: 189 loss: 6.84984043e-05
Iter: 190 loss: 6.94419432e-05
Iter: 191 loss: 6.8295958e-05
Iter: 192 loss: 6.78322758e-05
Iter: 193 loss: 6.89563094e-05
Iter: 194 loss: 6.76650816e-05
Iter: 195 loss: 6.72312162e-05
Iter: 196 loss: 7.02725956e-05
Iter: 197 loss: 6.7192108e-05
Iter: 198 loss: 6.69012225e-05
Iter: 199 loss: 7.14023263e-05
Iter: 200 loss: 6.69011351e-05
Iter: 201 loss: 6.66792475e-05
Iter: 202 loss: 6.6312e-05
Iter: 203 loss: 6.63106694e-05
Iter: 204 loss: 6.59189e-05
Iter: 205 loss: 6.70832669e-05
Iter: 206 loss: 6.57996716e-05
Iter: 207 loss: 6.54410687e-05
Iter: 208 loss: 6.61759696e-05
Iter: 209 loss: 6.52965537e-05
Iter: 210 loss: 6.49442227e-05
Iter: 211 loss: 6.62825332e-05
Iter: 212 loss: 6.48599744e-05
Iter: 213 loss: 6.45354885e-05
Iter: 214 loss: 6.61209415e-05
Iter: 215 loss: 6.4478736e-05
Iter: 216 loss: 6.42026134e-05
Iter: 217 loss: 6.58272911e-05
Iter: 218 loss: 6.41671868e-05
Iter: 219 loss: 6.39334321e-05
Iter: 220 loss: 6.39585924e-05
Iter: 221 loss: 6.37533958e-05
Iter: 222 loss: 6.34708558e-05
Iter: 223 loss: 6.39140562e-05
Iter: 224 loss: 6.3338739e-05
Iter: 225 loss: 6.30301656e-05
Iter: 226 loss: 6.40528306e-05
Iter: 227 loss: 6.29453571e-05
Iter: 228 loss: 6.26677866e-05
Iter: 229 loss: 6.39389764e-05
Iter: 230 loss: 6.26149413e-05
Iter: 231 loss: 6.23690212e-05
Iter: 232 loss: 6.2774845e-05
Iter: 233 loss: 6.2257277e-05
Iter: 234 loss: 6.21313302e-05
Iter: 235 loss: 6.21033541e-05
Iter: 236 loss: 6.19971252e-05
Iter: 237 loss: 6.17531e-05
Iter: 238 loss: 6.48550049e-05
Iter: 239 loss: 6.17357728e-05
Iter: 240 loss: 6.14940291e-05
Iter: 241 loss: 6.25517932e-05
Iter: 242 loss: 6.14451055e-05
Iter: 243 loss: 6.12124568e-05
Iter: 244 loss: 6.17335318e-05
Iter: 245 loss: 6.11241194e-05
Iter: 246 loss: 6.0905455e-05
Iter: 247 loss: 6.15007e-05
Iter: 248 loss: 6.08336668e-05
Iter: 249 loss: 6.06410322e-05
Iter: 250 loss: 6.15510871e-05
Iter: 251 loss: 6.0605882e-05
Iter: 252 loss: 6.0432576e-05
Iter: 253 loss: 6.177045e-05
Iter: 254 loss: 6.04199413e-05
Iter: 255 loss: 6.02963773e-05
Iter: 256 loss: 6.02751206e-05
Iter: 257 loss: 6.0190705e-05
Iter: 258 loss: 6.0011309e-05
Iter: 259 loss: 6.04009329e-05
Iter: 260 loss: 5.99417108e-05
Iter: 261 loss: 5.97715334e-05
Iter: 262 loss: 6.01815627e-05
Iter: 263 loss: 5.97102699e-05
Iter: 264 loss: 5.95435122e-05
Iter: 265 loss: 6.02655273e-05
Iter: 266 loss: 5.95092788e-05
Iter: 267 loss: 5.93866171e-05
Iter: 268 loss: 6.05076712e-05
Iter: 269 loss: 5.93810837e-05
Iter: 270 loss: 5.92699907e-05
Iter: 271 loss: 5.97667095e-05
Iter: 272 loss: 5.92479155e-05
Iter: 273 loss: 5.91643184e-05
Iter: 274 loss: 5.9069971e-05
Iter: 275 loss: 5.90574709e-05
Iter: 276 loss: 5.8924139e-05
Iter: 277 loss: 5.91270909e-05
Iter: 278 loss: 5.88609073e-05
Iter: 279 loss: 5.87180257e-05
Iter: 280 loss: 5.92955512e-05
Iter: 281 loss: 5.86862661e-05
Iter: 282 loss: 5.85662201e-05
Iter: 283 loss: 5.90597847e-05
Iter: 284 loss: 5.85400521e-05
Iter: 285 loss: 5.84285954e-05
Iter: 286 loss: 5.87387112e-05
Iter: 287 loss: 5.83926267e-05
Iter: 288 loss: 5.830386e-05
Iter: 289 loss: 5.92489814e-05
Iter: 290 loss: 5.830187e-05
Iter: 291 loss: 5.82246794e-05
Iter: 292 loss: 5.81925487e-05
Iter: 293 loss: 5.81521e-05
Iter: 294 loss: 5.80574706e-05
Iter: 295 loss: 5.81723943e-05
Iter: 296 loss: 5.80079213e-05
Iter: 297 loss: 5.79048574e-05
Iter: 298 loss: 5.84652807e-05
Iter: 299 loss: 5.78895852e-05
Iter: 300 loss: 5.78050531e-05
Iter: 301 loss: 5.80072774e-05
Iter: 302 loss: 5.7774294e-05
Iter: 303 loss: 5.77072096e-05
Iter: 304 loss: 5.77071405e-05
Iter: 305 loss: 5.76501116e-05
Iter: 306 loss: 5.77075116e-05
Iter: 307 loss: 5.76181483e-05
Iter: 308 loss: 5.75628183e-05
Iter: 309 loss: 5.75107479e-05
Iter: 310 loss: 5.74979749e-05
Iter: 311 loss: 5.74160476e-05
Iter: 312 loss: 5.77230421e-05
Iter: 313 loss: 5.73962243e-05
Iter: 314 loss: 5.73194484e-05
Iter: 315 loss: 5.7655172e-05
Iter: 316 loss: 5.73040961e-05
Iter: 317 loss: 5.72378922e-05
Iter: 318 loss: 5.73163052e-05
Iter: 319 loss: 5.72027784e-05
Iter: 320 loss: 5.71360142e-05
Iter: 321 loss: 5.74971091e-05
Iter: 322 loss: 5.71260352e-05
Iter: 323 loss: 5.70696357e-05
Iter: 324 loss: 5.75054728e-05
Iter: 325 loss: 5.70656084e-05
Iter: 326 loss: 5.70220946e-05
Iter: 327 loss: 5.70727134e-05
Iter: 328 loss: 5.6998957e-05
Iter: 329 loss: 5.69504591e-05
Iter: 330 loss: 5.69683398e-05
Iter: 331 loss: 5.69162912e-05
Iter: 332 loss: 5.68613068e-05
Iter: 333 loss: 5.70157245e-05
Iter: 334 loss: 5.68437536e-05
Iter: 335 loss: 5.6794117e-05
Iter: 336 loss: 5.70031807e-05
Iter: 337 loss: 5.67834832e-05
Iter: 338 loss: 5.67508032e-05
Iter: 339 loss: 5.67497846e-05
Iter: 340 loss: 5.67257302e-05
Iter: 341 loss: 5.67050811e-05
Iter: 342 loss: 5.66984891e-05
Iter: 343 loss: 5.66623057e-05
Iter: 344 loss: 5.66997478e-05
Iter: 345 loss: 5.66420749e-05
Iter: 346 loss: 5.66028866e-05
Iter: 347 loss: 5.66290473e-05
Iter: 348 loss: 5.6578192e-05
Iter: 349 loss: 5.65359587e-05
Iter: 350 loss: 5.68122341e-05
Iter: 351 loss: 5.6531615e-05
Iter: 352 loss: 5.64945913e-05
Iter: 353 loss: 5.66017479e-05
Iter: 354 loss: 5.6483128e-05
Iter: 355 loss: 5.64477268e-05
Iter: 356 loss: 5.65426672e-05
Iter: 357 loss: 5.64359761e-05
Iter: 358 loss: 5.64101247e-05
Iter: 359 loss: 5.67151183e-05
Iter: 360 loss: 5.64097572e-05
Iter: 361 loss: 5.6386285e-05
Iter: 362 loss: 5.63845279e-05
Iter: 363 loss: 5.63671456e-05
Iter: 364 loss: 5.63390349e-05
Iter: 365 loss: 5.63594622e-05
Iter: 366 loss: 5.63217654e-05
Iter: 367 loss: 5.62885944e-05
Iter: 368 loss: 5.6445253e-05
Iter: 369 loss: 5.62826644e-05
Iter: 370 loss: 5.62554706e-05
Iter: 371 loss: 5.6335517e-05
Iter: 372 loss: 5.62472924e-05
Iter: 373 loss: 5.62270725e-05
Iter: 374 loss: 5.62269634e-05
Iter: 375 loss: 5.62119e-05
Iter: 376 loss: 5.6204095e-05
Iter: 377 loss: 5.61971974e-05
Iter: 378 loss: 5.61774832e-05
Iter: 379 loss: 5.61684137e-05
Iter: 380 loss: 5.61586348e-05
Iter: 381 loss: 5.61325469e-05
Iter: 382 loss: 5.62750647e-05
Iter: 383 loss: 5.61287525e-05
Iter: 384 loss: 5.61063935e-05
Iter: 385 loss: 5.61478664e-05
Iter: 386 loss: 5.60969056e-05
Iter: 387 loss: 5.60747176e-05
Iter: 388 loss: 5.61466441e-05
Iter: 389 loss: 5.60684784e-05
Iter: 390 loss: 5.6047109e-05
Iter: 391 loss: 5.61063607e-05
Iter: 392 loss: 5.60401968e-05
Iter: 393 loss: 5.60236476e-05
Iter: 394 loss: 5.62578e-05
Iter: 395 loss: 5.60236331e-05
Iter: 396 loss: 5.60107364e-05
Iter: 397 loss: 5.60145854e-05
Iter: 398 loss: 5.60015833e-05
Iter: 399 loss: 5.59851978e-05
Iter: 400 loss: 5.6027784e-05
Iter: 401 loss: 5.59795953e-05
Iter: 402 loss: 5.59650362e-05
Iter: 403 loss: 5.59710825e-05
Iter: 404 loss: 5.59550026e-05
Iter: 405 loss: 5.59380314e-05
Iter: 406 loss: 5.60477311e-05
Iter: 407 loss: 5.59361433e-05
Iter: 408 loss: 5.59250911e-05
Iter: 409 loss: 5.60868648e-05
Iter: 410 loss: 5.59251312e-05
Iter: 411 loss: 5.59151122e-05
Iter: 412 loss: 5.59121036e-05
Iter: 413 loss: 5.59061082e-05
Iter: 414 loss: 5.58944776e-05
Iter: 415 loss: 5.59116306e-05
Iter: 416 loss: 5.58888605e-05
Iter: 417 loss: 5.58759275e-05
Iter: 418 loss: 5.58796055e-05
Iter: 419 loss: 5.58666216e-05
Iter: 420 loss: 5.58509782e-05
Iter: 421 loss: 5.58823449e-05
Iter: 422 loss: 5.58446191e-05
Iter: 423 loss: 5.58294523e-05
Iter: 424 loss: 5.58804604e-05
Iter: 425 loss: 5.58253e-05
Iter: 426 loss: 5.58122119e-05
Iter: 427 loss: 5.5927776e-05
Iter: 428 loss: 5.58115389e-05
Iter: 429 loss: 5.58008323e-05
Iter: 430 loss: 5.58359825e-05
Iter: 431 loss: 5.57977619e-05
Iter: 432 loss: 5.57881431e-05
Iter: 433 loss: 5.58502288e-05
Iter: 434 loss: 5.57871535e-05
Iter: 435 loss: 5.57795138e-05
Iter: 436 loss: 5.577103e-05
Iter: 437 loss: 5.57697967e-05
Iter: 438 loss: 5.57584135e-05
Iter: 439 loss: 5.58113898e-05
Iter: 440 loss: 5.57562562e-05
Iter: 441 loss: 5.57464591e-05
Iter: 442 loss: 5.57722087e-05
Iter: 443 loss: 5.57431813e-05
Iter: 444 loss: 5.57363819e-05
Iter: 445 loss: 5.57360654e-05
Iter: 446 loss: 5.57306885e-05
Iter: 447 loss: 5.57276981e-05
Iter: 448 loss: 5.57252388e-05
Iter: 449 loss: 5.57175e-05
Iter: 450 loss: 5.57172643e-05
Iter: 451 loss: 5.57114254e-05
Iter: 452 loss: 5.57022e-05
Iter: 453 loss: 5.5733839e-05
Iter: 454 loss: 5.56997911e-05
Iter: 455 loss: 5.56904342e-05
Iter: 456 loss: 5.57162675e-05
Iter: 457 loss: 5.56874438e-05
Iter: 458 loss: 5.56792729e-05
Iter: 459 loss: 5.5707751e-05
Iter: 460 loss: 5.56772102e-05
Iter: 461 loss: 5.56696286e-05
Iter: 462 loss: 5.56882587e-05
Iter: 463 loss: 5.56668856e-05
Iter: 464 loss: 5.5659737e-05
Iter: 465 loss: 5.56821105e-05
Iter: 466 loss: 5.5657707e-05
Iter: 467 loss: 5.56505875e-05
Iter: 468 loss: 5.56930681e-05
Iter: 469 loss: 5.56497798e-05
Iter: 470 loss: 5.56441373e-05
Iter: 471 loss: 5.56705345e-05
Iter: 472 loss: 5.56431514e-05
Iter: 473 loss: 5.56381819e-05
Iter: 474 loss: 5.56383457e-05
Iter: 475 loss: 5.56343075e-05
Iter: 476 loss: 5.56282466e-05
Iter: 477 loss: 5.56414052e-05
Iter: 478 loss: 5.56259583e-05
Iter: 479 loss: 5.56220039e-05
Iter: 480 loss: 5.56220475e-05
Iter: 481 loss: 5.56180457e-05
Iter: 482 loss: 5.56159721e-05
Iter: 483 loss: 5.56143641e-05
Iter: 484 loss: 5.56098821e-05
Iter: 485 loss: 5.56124724e-05
Iter: 486 loss: 5.56069426e-05
Iter: 487 loss: 5.56015948e-05
Iter: 488 loss: 5.56227242e-05
Iter: 489 loss: 5.56003215e-05
Iter: 490 loss: 5.55956685e-05
Iter: 491 loss: 5.56012601e-05
Iter: 492 loss: 5.55930528e-05
Iter: 493 loss: 5.55878214e-05
Iter: 494 loss: 5.56041632e-05
Iter: 495 loss: 5.55862425e-05
Iter: 496 loss: 5.5581233e-05
Iter: 497 loss: 5.56006198e-05
Iter: 498 loss: 5.5580269e-05
Iter: 499 loss: 5.55757142e-05
Iter: 500 loss: 5.55891238e-05
Iter: 501 loss: 5.55742918e-05
Iter: 502 loss: 5.55701808e-05
Iter: 503 loss: 5.55845727e-05
Iter: 504 loss: 5.55690531e-05
Iter: 505 loss: 5.55653969e-05
Iter: 506 loss: 5.55955849e-05
Iter: 507 loss: 5.55650477e-05
Iter: 508 loss: 5.55623046e-05
Iter: 509 loss: 5.5563396e-05
Iter: 510 loss: 5.55602346e-05
Iter: 511 loss: 5.55566476e-05
Iter: 512 loss: 5.55669503e-05
Iter: 513 loss: 5.55556908e-05
Iter: 514 loss: 5.55531151e-05
Iter: 515 loss: 5.55925653e-05
Iter: 516 loss: 5.55532024e-05
Iter: 517 loss: 5.55508959e-05
Iter: 518 loss: 5.55494698e-05
Iter: 519 loss: 5.55486622e-05
Iter: 520 loss: 5.55457118e-05
Iter: 521 loss: 5.55446459e-05
Iter: 522 loss: 5.55431034e-05
Iter: 523 loss: 5.55394654e-05
Iter: 524 loss: 5.55547813e-05
Iter: 525 loss: 5.55386214e-05
Iter: 526 loss: 5.5535158e-05
Iter: 527 loss: 5.55536026e-05
Iter: 528 loss: 5.55346196e-05
Iter: 529 loss: 5.55317856e-05
Iter: 530 loss: 5.55295337e-05
Iter: 531 loss: 5.55287043e-05
Iter: 532 loss: 5.552527e-05
Iter: 533 loss: 5.55618317e-05
Iter: 534 loss: 5.552519e-05
Iter: 535 loss: 5.55219849e-05
Iter: 536 loss: 5.55278821e-05
Iter: 537 loss: 5.55206934e-05
Iter: 538 loss: 5.55179795e-05
Iter: 539 loss: 5.55331899e-05
Iter: 540 loss: 5.5517572e-05
Iter: 541 loss: 5.55152583e-05
Iter: 542 loss: 5.55291299e-05
Iter: 543 loss: 5.55148799e-05
Iter: 544 loss: 5.55128463e-05
Iter: 545 loss: 5.55135048e-05
Iter: 546 loss: 5.55115548e-05
Iter: 547 loss: 5.55093029e-05
Iter: 548 loss: 5.55232946e-05
Iter: 549 loss: 5.55089646e-05
Iter: 550 loss: 5.55071529e-05
Iter: 551 loss: 5.5520537e-05
Iter: 552 loss: 5.55070947e-05
Iter: 553 loss: 5.5505785e-05
Iter: 554 loss: 5.55040206e-05
Iter: 555 loss: 5.55038932e-05
Iter: 556 loss: 5.55016231e-05
Iter: 557 loss: 5.55052357e-05
Iter: 558 loss: 5.55004663e-05
Iter: 559 loss: 5.5498047e-05
Iter: 560 loss: 5.55019469e-05
Iter: 561 loss: 5.54969e-05
Iter: 562 loss: 5.54943545e-05
Iter: 563 loss: 5.55162333e-05
Iter: 564 loss: 5.54942817e-05
Iter: 565 loss: 5.54923463e-05
Iter: 566 loss: 5.54935505e-05
Iter: 567 loss: 5.54912549e-05
Iter: 568 loss: 5.54891631e-05
Iter: 569 loss: 5.54959042e-05
Iter: 570 loss: 5.54885701e-05
Iter: 571 loss: 5.54865146e-05
Iter: 572 loss: 5.54950311e-05
Iter: 573 loss: 5.54862054e-05
Iter: 574 loss: 5.54844082e-05
Iter: 575 loss: 5.54910948e-05
Iter: 576 loss: 5.54839426e-05
Iter: 577 loss: 5.54823564e-05
Iter: 578 loss: 5.54931321e-05
Iter: 579 loss: 5.54821745e-05
Iter: 580 loss: 5.54808139e-05
Iter: 581 loss: 5.54817816e-05
Iter: 582 loss: 5.54800245e-05
Iter: 583 loss: 5.5478853e-05
Iter: 584 loss: 5.54934886e-05
Iter: 585 loss: 5.54788312e-05
Iter: 586 loss: 5.54777507e-05
Iter: 587 loss: 5.54775761e-05
Iter: 588 loss: 5.54768194e-05
Iter: 589 loss: 5.54755316e-05
Iter: 590 loss: 5.54760081e-05
Iter: 591 loss: 5.54745384e-05
Iter: 592 loss: 5.54730032e-05
Iter: 593 loss: 5.54775543e-05
Iter: 594 loss: 5.54725593e-05
Iter: 595 loss: 5.54711e-05
Iter: 596 loss: 5.54747967e-05
Iter: 597 loss: 5.54706021e-05
Iter: 598 loss: 5.54691105e-05
Iter: 599 loss: 5.54725812e-05
Iter: 600 loss: 5.54686703e-05
Iter: 601 loss: 5.54672079e-05
Iter: 602 loss: 5.54731523e-05
Iter: 603 loss: 5.54669205e-05
Iter: 604 loss: 5.54655489e-05
Iter: 605 loss: 5.54684375e-05
Iter: 606 loss: 5.54651306e-05
Iter: 607 loss: 5.54637772e-05
Iter: 608 loss: 5.54675826e-05
Iter: 609 loss: 5.54633e-05
Iter: 610 loss: 5.54621547e-05
Iter: 611 loss: 5.5470533e-05
Iter: 612 loss: 5.54620892e-05
Iter: 613 loss: 5.54610851e-05
Iter: 614 loss: 5.54650505e-05
Iter: 615 loss: 5.5460765e-05
Iter: 616 loss: 5.54599028e-05
Iter: 617 loss: 5.54625e-05
Iter: 618 loss: 5.54596882e-05
Iter: 619 loss: 5.54587932e-05
Iter: 620 loss: 5.54628641e-05
Iter: 621 loss: 5.54585422e-05
Iter: 622 loss: 5.54578583e-05
Iter: 623 loss: 5.54579929e-05
Iter: 624 loss: 5.54572798e-05
Iter: 625 loss: 5.54563558e-05
Iter: 626 loss: 5.54559738e-05
Iter: 627 loss: 5.5455479e-05
Iter: 628 loss: 5.54544167e-05
Iter: 629 loss: 5.54605831e-05
Iter: 630 loss: 5.54542e-05
Iter: 631 loss: 5.54531871e-05
Iter: 632 loss: 5.54572398e-05
Iter: 633 loss: 5.54529615e-05
Iter: 634 loss: 5.54520484e-05
Iter: 635 loss: 5.54522376e-05
Iter: 636 loss: 5.54513899e-05
Iter: 637 loss: 5.54502185e-05
Iter: 638 loss: 5.5456163e-05
Iter: 639 loss: 5.5450022e-05
Iter: 640 loss: 5.54491526e-05
Iter: 641 loss: 5.54518811e-05
Iter: 642 loss: 5.54486905e-05
Iter: 643 loss: 5.54479557e-05
Iter: 644 loss: 5.54515027e-05
Iter: 645 loss: 5.54476901e-05
Iter: 646 loss: 5.54469916e-05
Iter: 647 loss: 5.54518738e-05
Iter: 648 loss: 5.54468788e-05
Iter: 649 loss: 5.54461876e-05
Iter: 650 loss: 5.54485086e-05
Iter: 651 loss: 5.54460275e-05
Iter: 652 loss: 5.54454782e-05
Iter: 653 loss: 5.54482831e-05
Iter: 654 loss: 5.54453582e-05
Iter: 655 loss: 5.54448452e-05
Iter: 656 loss: 5.54447834e-05
Iter: 657 loss: 5.5444445e-05
Iter: 658 loss: 5.54437465e-05
Iter: 659 loss: 5.54447106e-05
Iter: 660 loss: 5.54434591e-05
Iter: 661 loss: 5.54427024e-05
Iter: 662 loss: 5.54436519e-05
Iter: 663 loss: 5.5442295e-05
Iter: 664 loss: 5.54413928e-05
Iter: 665 loss: 5.54435028e-05
Iter: 666 loss: 5.54411527e-05
Iter: 667 loss: 5.54403305e-05
Iter: 668 loss: 5.54436e-05
Iter: 669 loss: 5.54402686e-05
Iter: 670 loss: 5.54395447e-05
Iter: 671 loss: 5.54419821e-05
Iter: 672 loss: 5.54393482e-05
Iter: 673 loss: 5.54386934e-05
Iter: 674 loss: 5.54396465e-05
Iter: 675 loss: 5.54383878e-05
Iter: 676 loss: 5.54377184e-05
Iter: 677 loss: 5.54400758e-05
Iter: 678 loss: 5.54375729e-05
Iter: 679 loss: 5.54368853e-05
Iter: 680 loss: 5.54405196e-05
Iter: 681 loss: 5.54368708e-05
Iter: 682 loss: 5.54364269e-05
Iter: 683 loss: 5.54399776e-05
Iter: 684 loss: 5.54362123e-05
Iter: 685 loss: 5.54359431e-05
Iter: 686 loss: 5.54367289e-05
Iter: 687 loss: 5.54356811e-05
Iter: 688 loss: 5.54352591e-05
Iter: 689 loss: 5.54368598e-05
Iter: 690 loss: 5.54351391e-05
Iter: 691 loss: 5.54347534e-05
Iter: 692 loss: 5.54346843e-05
Iter: 693 loss: 5.54344151e-05
Iter: 694 loss: 5.5433833e-05
Iter: 695 loss: 5.54347e-05
Iter: 696 loss: 5.54335929e-05
Iter: 697 loss: 5.54330072e-05
Iter: 698 loss: 5.54349172e-05
Iter: 699 loss: 5.54329199e-05
Iter: 700 loss: 5.54323888e-05
Iter: 701 loss: 5.54334256e-05
Iter: 702 loss: 5.54322214e-05
Iter: 703 loss: 5.54316284e-05
Iter: 704 loss: 5.5433542e-05
Iter: 705 loss: 5.54313738e-05
Iter: 706 loss: 5.54309736e-05
Iter: 707 loss: 5.54316575e-05
Iter: 708 loss: 5.54306862e-05
Iter: 709 loss: 5.54301951e-05
Iter: 710 loss: 5.5433713e-05
Iter: 711 loss: 5.54300859e-05
Iter: 712 loss: 5.54296566e-05
Iter: 713 loss: 5.54302169e-05
Iter: 714 loss: 5.54294711e-05
Iter: 715 loss: 5.54290309e-05
Iter: 716 loss: 5.54342e-05
Iter: 717 loss: 5.542902e-05
Iter: 718 loss: 5.54287108e-05
Iter: 719 loss: 5.54299731e-05
Iter: 720 loss: 5.54285725e-05
Iter: 721 loss: 5.54283761e-05
Iter: 722 loss: 5.54289873e-05
Iter: 723 loss: 5.54282196e-05
Iter: 724 loss: 5.54279031e-05
Iter: 725 loss: 5.54280632e-05
Iter: 726 loss: 5.54276739e-05
Iter: 727 loss: 5.54273574e-05
Iter: 728 loss: 5.54276558e-05
Iter: 729 loss: 5.54271573e-05
Iter: 730 loss: 5.54267572e-05
Iter: 731 loss: 5.54280632e-05
Iter: 732 loss: 5.54266589e-05
Iter: 733 loss: 5.54261642e-05
Iter: 734 loss: 5.54266808e-05
Iter: 735 loss: 5.54259968e-05
Iter: 736 loss: 5.54255457e-05
Iter: 737 loss: 5.54268554e-05
Iter: 738 loss: 5.5425473e-05
Iter: 739 loss: 5.54250582e-05
Iter: 740 loss: 5.54270409e-05
Iter: 741 loss: 5.54249636e-05
Iter: 742 loss: 5.54245962e-05
Iter: 743 loss: 5.54251164e-05
Iter: 744 loss: 5.54245307e-05
Iter: 745 loss: 5.54241524e-05
Iter: 746 loss: 5.54251237e-05
Iter: 747 loss: 5.54239195e-05
Iter: 748 loss: 5.5423563e-05
Iter: 749 loss: 5.54252547e-05
Iter: 750 loss: 5.54234502e-05
Iter: 751 loss: 5.54233266e-05
Iter: 752 loss: 5.54267972e-05
Iter: 753 loss: 5.54232138e-05
Iter: 754 loss: 5.54230501e-05
Iter: 755 loss: 5.54233557e-05
Iter: 756 loss: 5.54229591e-05
Iter: 757 loss: 5.54227445e-05
Iter: 758 loss: 5.54229337e-05
Iter: 759 loss: 5.54225517e-05
Iter: 760 loss: 5.54223661e-05
Iter: 761 loss: 5.542293e-05
Iter: 762 loss: 5.54222606e-05
Iter: 763 loss: 5.54219951e-05
Iter: 764 loss: 5.54219769e-05
Iter: 765 loss: 5.54217659e-05
Iter: 766 loss: 5.54215294e-05
Iter: 767 loss: 5.54230282e-05
Iter: 768 loss: 5.54214457e-05
Iter: 769 loss: 5.54211692e-05
Iter: 770 loss: 5.54218132e-05
Iter: 771 loss: 5.5420991e-05
Iter: 772 loss: 5.54207254e-05
Iter: 773 loss: 5.54213111e-05
Iter: 774 loss: 5.54206053e-05
Iter: 775 loss: 5.54203143e-05
Iter: 776 loss: 5.54211147e-05
Iter: 777 loss: 5.54201179e-05
Iter: 778 loss: 5.54198923e-05
Iter: 779 loss: 5.54204526e-05
Iter: 780 loss: 5.54198268e-05
Iter: 781 loss: 5.54194121e-05
Iter: 782 loss: 5.5421584e-05
Iter: 783 loss: 5.54194048e-05
Iter: 784 loss: 5.54193102e-05
Iter: 785 loss: 5.54204817e-05
Iter: 786 loss: 5.54191683e-05
Iter: 787 loss: 5.54189646e-05
Iter: 788 loss: 5.54204671e-05
Iter: 789 loss: 5.54190665e-05
Iter: 790 loss: 5.54188446e-05
Iter: 791 loss: 5.54187718e-05
Iter: 792 loss: 5.54187536e-05
Iter: 793 loss: 5.54185681e-05
Iter: 794 loss: 5.54191793e-05
Iter: 795 loss: 5.5418488e-05
Iter: 796 loss: 5.54183134e-05
Iter: 797 loss: 5.54182116e-05
Iter: 798 loss: 5.54181388e-05
Iter: 799 loss: 5.5417906e-05
Iter: 800 loss: 5.54190847e-05
Iter: 801 loss: 5.54178514e-05
Iter: 802 loss: 5.54176e-05
Iter: 803 loss: 5.54181206e-05
Iter: 804 loss: 5.54175058e-05
Iter: 805 loss: 5.54173821e-05
Iter: 806 loss: 5.54177495e-05
Iter: 807 loss: 5.54172948e-05
Iter: 808 loss: 5.54169492e-05
Iter: 809 loss: 5.54177896e-05
Iter: 810 loss: 5.54169092e-05
Iter: 811 loss: 5.54167527e-05
Iter: 812 loss: 5.54173821e-05
Iter: 813 loss: 5.54167418e-05
Iter: 814 loss: 5.54163707e-05
Iter: 815 loss: 5.5417102e-05
Iter: 816 loss: 5.54163416e-05
Iter: 817 loss: 5.54161415e-05
Iter: 818 loss: 5.54167746e-05
Iter: 819 loss: 5.54161743e-05
Iter: 820 loss: 5.54160433e-05
Iter: 821 loss: 5.54160652e-05
Iter: 822 loss: 5.54158905e-05
Iter: 823 loss: 5.54157923e-05
Iter: 824 loss: 5.54158105e-05
Iter: 825 loss: 5.54156504e-05
Iter: 826 loss: 5.54160652e-05
Iter: 827 loss: 5.54155959e-05
Iter: 828 loss: 5.54154394e-05
Iter: 829 loss: 5.54157232e-05
Iter: 830 loss: 5.54154067e-05
Iter: 831 loss: 5.54152793e-05
Iter: 832 loss: 5.54154394e-05
Iter: 833 loss: 5.54151738e-05
Iter: 834 loss: 5.54150756e-05
Iter: 835 loss: 5.54154103e-05
Iter: 836 loss: 5.54149519e-05
Iter: 837 loss: 5.5414861e-05
Iter: 838 loss: 5.54150683e-05
Iter: 839 loss: 5.54147e-05
Iter: 840 loss: 5.54145918e-05
Iter: 841 loss: 5.54155304e-05
Iter: 842 loss: 5.54145e-05
Iter: 843 loss: 5.54144208e-05
Iter: 844 loss: 5.54145554e-05
Iter: 845 loss: 5.54143735e-05
Iter: 846 loss: 5.54141734e-05
Iter: 847 loss: 5.54146754e-05
Iter: 848 loss: 5.54141407e-05
Iter: 849 loss: 5.54139478e-05
Iter: 850 loss: 5.54143771e-05
Iter: 851 loss: 5.54139588e-05
Iter: 852 loss: 5.54138169e-05
Iter: 853 loss: 5.54153485e-05
Iter: 854 loss: 5.54139078e-05
Iter: 855 loss: 5.54137514e-05
Iter: 856 loss: 5.54140934e-05
Iter: 857 loss: 5.54137296e-05
Iter: 858 loss: 5.54136168e-05
Iter: 859 loss: 5.54136132e-05
Iter: 860 loss: 5.5413635e-05
Iter: 861 loss: 5.54134749e-05
Iter: 862 loss: 5.54137696e-05
Iter: 863 loss: 5.54134749e-05
Iter: 864 loss: 5.54133621e-05
Iter: 865 loss: 5.54135695e-05
Iter: 866 loss: 5.54132821e-05
Iter: 867 loss: 5.54131948e-05
Iter: 868 loss: 5.54132312e-05
Iter: 869 loss: 5.54130675e-05
Iter: 870 loss: 5.54129911e-05
Iter: 871 loss: 5.5413333e-05
Iter: 872 loss: 5.5412871e-05
Iter: 873 loss: 5.54128856e-05
Iter: 874 loss: 5.54133803e-05
Iter: 875 loss: 5.54128201e-05
Iter: 876 loss: 5.54127073e-05
Iter: 877 loss: 5.54129656e-05
Iter: 878 loss: 5.54126091e-05
Iter: 879 loss: 5.54125436e-05
Iter: 880 loss: 5.54125727e-05
Iter: 881 loss: 5.54124381e-05
Iter: 882 loss: 5.54123108e-05
Iter: 883 loss: 5.54131511e-05
Iter: 884 loss: 5.5412318e-05
Iter: 885 loss: 5.54123e-05
Iter: 886 loss: 5.54126236e-05
Iter: 887 loss: 5.54122307e-05
Iter: 888 loss: 5.54122089e-05
Iter: 889 loss: 5.54122162e-05
Iter: 890 loss: 5.54121434e-05
Iter: 891 loss: 5.54120634e-05
Iter: 892 loss: 5.54120234e-05
Iter: 893 loss: 5.54119833e-05
Iter: 894 loss: 5.5412198e-05
Iter: 895 loss: 5.54119979e-05
Iter: 896 loss: 5.5411896e-05
Iter: 897 loss: 5.54121943e-05
Iter: 898 loss: 5.54118196e-05
Iter: 899 loss: 5.54117432e-05
Iter: 900 loss: 5.54118342e-05
Iter: 901 loss: 5.54116632e-05
Iter: 902 loss: 5.54116777e-05
Iter: 903 loss: 5.54119033e-05
Iter: 904 loss: 5.54115832e-05
Iter: 905 loss: 5.54115468e-05
Iter: 906 loss: 5.54117869e-05
Iter: 907 loss: 5.54115031e-05
Iter: 908 loss: 5.54113758e-05
Iter: 909 loss: 5.54115832e-05
Iter: 910 loss: 5.54114449e-05
Iter: 911 loss: 5.54113212e-05
Iter: 912 loss: 5.54116923e-05
Iter: 913 loss: 5.54113794e-05
Iter: 914 loss: 5.5411183e-05
Iter: 915 loss: 5.54113758e-05
Iter: 916 loss: 5.54112376e-05
Iter: 917 loss: 5.54110666e-05
Iter: 918 loss: 5.54112557e-05
Iter: 919 loss: 5.54110811e-05
Iter: 920 loss: 5.54109647e-05
Iter: 921 loss: 5.54109974e-05
Iter: 922 loss: 5.54109392e-05
Iter: 923 loss: 5.54112776e-05
Iter: 924 loss: 5.54109865e-05
Iter: 925 loss: 5.54109683e-05
Iter: 926 loss: 5.54108e-05
Iter: 927 loss: 5.54109138e-05
Iter: 928 loss: 5.54108628e-05
Iter: 929 loss: 5.54111939e-05
Iter: 930 loss: 5.54107828e-05
Iter: 931 loss: 5.54107246e-05
Iter: 932 loss: 5.54108592e-05
Iter: 933 loss: 5.54106809e-05
Iter: 934 loss: 5.54105536e-05
Iter: 935 loss: 5.54108083e-05
Iter: 936 loss: 5.54106955e-05
Iter: 937 loss: 5.54107173e-05
Iter: 938 loss: 5.54107028e-05
Iter: 939 loss: 5.54105973e-05
Iter: 940 loss: 5.5410379e-05
Iter: 941 loss: 5.54105463e-05
Iter: 942 loss: 5.54104809e-05
Iter: 943 loss: 5.54103535e-05
Iter: 944 loss: 5.541071e-05
Iter: 945 loss: 5.54103608e-05
Iter: 946 loss: 5.54103572e-05
Iter: 947 loss: 5.54105791e-05
Iter: 948 loss: 5.5410419e-05
Iter: 949 loss: 5.54103099e-05
Iter: 950 loss: 5.54103572e-05
Iter: 951 loss: 5.54103062e-05
Iter: 952 loss: 5.54102735e-05
Iter: 953 loss: 5.54103826e-05
Iter: 954 loss: 5.54103863e-05
Iter: 955 loss: 5.54103317e-05
Iter: 956 loss: 5.54104518e-05
Iter: 957 loss: 5.54103608e-05
Iter: 958 loss: 5.54104117e-05
Iter: 959 loss: 5.5410419e-05
Iter: 960 loss: 5.54103972e-05
Iter: 961 loss: 5.54104263e-05
Iter: 962 loss: 5.54104117e-05
Iter: 963 loss: 5.54104226e-05
Iter: 964 loss: 5.54104226e-05
Iter: 965 loss: 5.5410419e-05
Iter: 966 loss: 5.54104154e-05
Iter: 967 loss: 5.54104117e-05
Iter: 968 loss: 5.54104154e-05
Iter: 969 loss: 5.5410419e-05
Iter: 970 loss: 5.5410419e-05
Iter: 971 loss: 5.54104154e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6
+ date
Tue Oct 27 18:32:58 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34e49b01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34e49c1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34e49c1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34e49c12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceec26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceef3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cee9aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cee4e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cee60268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cee60ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cee16730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cede8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ced77598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cee60c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ced51c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ced51840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ced106a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cecbb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cec85840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceca8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceca89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cec5fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cec5ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cec5f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cebc4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34cebcc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceb97c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceb97840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceb4c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceb06620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceaba840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceaba620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceadd488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceaddb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceadd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f34ceaddbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.029888466
Iter: 2 loss: 0.0218118429
Iter: 3 loss: 3128.30029
Iter: 4 loss: 0.0218118429
Iter: 5 loss: 0.0181237087
Iter: 6 loss: 0.0312826186
Iter: 7 loss: 0.0165286493
Iter: 8 loss: 0.0123164151
Iter: 9 loss: 0.0122978128
Iter: 10 loss: 0.0103760948
Iter: 11 loss: 0.0272912607
Iter: 12 loss: 0.0102714617
Iter: 13 loss: 0.0093117645
Iter: 14 loss: 0.0105927493
Iter: 15 loss: 0.00871568
Iter: 16 loss: 0.00710981851
Iter: 17 loss: 0.0522562116
Iter: 18 loss: 0.0070708571
Iter: 19 loss: 0.00571247051
Iter: 20 loss: 0.00570016541
Iter: 21 loss: 0.00481668534
Iter: 22 loss: 0.0130302859
Iter: 23 loss: 0.00479251426
Iter: 24 loss: 0.00430234615
Iter: 25 loss: 0.00651336322
Iter: 26 loss: 0.00415582675
Iter: 27 loss: 0.00372415362
Iter: 28 loss: 0.00835930556
Iter: 29 loss: 0.00371792424
Iter: 30 loss: 0.0033766143
Iter: 31 loss: 0.00464055734
Iter: 32 loss: 0.00326628168
Iter: 33 loss: 0.00288803643
Iter: 34 loss: 0.0047154
Iter: 35 loss: 0.00282528391
Iter: 36 loss: 0.00250661187
Iter: 37 loss: 0.00421244279
Iter: 38 loss: 0.00245340681
Iter: 39 loss: 0.00218825927
Iter: 40 loss: 0.0044781277
Iter: 41 loss: 0.00215788279
Iter: 42 loss: 0.00197191
Iter: 43 loss: 0.00262529124
Iter: 44 loss: 0.00191705953
Iter: 45 loss: 0.00174908841
Iter: 46 loss: 0.00216663489
Iter: 47 loss: 0.00168554916
Iter: 48 loss: 0.00151064212
Iter: 49 loss: 0.00276579289
Iter: 50 loss: 0.00149444141
Iter: 51 loss: 0.00138834026
Iter: 52 loss: 0.00172735727
Iter: 53 loss: 0.00135642523
Iter: 54 loss: 0.00126257748
Iter: 55 loss: 0.0016643079
Iter: 56 loss: 0.00124172564
Iter: 57 loss: 0.0011627886
Iter: 58 loss: 0.00174415228
Iter: 59 loss: 0.0011539266
Iter: 60 loss: 0.00108858501
Iter: 61 loss: 0.0010882332
Iter: 62 loss: 0.00105132814
Iter: 63 loss: 0.00106269
Iter: 64 loss: 0.00102337892
Iter: 65 loss: 0.000981829595
Iter: 66 loss: 0.000980312936
Iter: 67 loss: 0.000948182074
Iter: 68 loss: 0.000902460364
Iter: 69 loss: 0.0011073912
Iter: 70 loss: 0.000893179444
Iter: 71 loss: 0.00085509225
Iter: 72 loss: 0.000963159779
Iter: 73 loss: 0.00084288331
Iter: 74 loss: 0.000806437922
Iter: 75 loss: 0.000793982821
Iter: 76 loss: 0.00077297719
Iter: 77 loss: 0.000732296845
Iter: 78 loss: 0.00094169355
Iter: 79 loss: 0.000725503895
Iter: 80 loss: 0.000690083252
Iter: 81 loss: 0.000800231821
Iter: 82 loss: 0.000679580087
Iter: 83 loss: 0.000648067566
Iter: 84 loss: 0.000676103635
Iter: 85 loss: 0.00062930095
Iter: 86 loss: 0.000594407786
Iter: 87 loss: 0.000902547559
Iter: 88 loss: 0.000592370867
Iter: 89 loss: 0.000568093092
Iter: 90 loss: 0.00061760738
Iter: 91 loss: 0.000558159663
Iter: 92 loss: 0.000533145969
Iter: 93 loss: 0.000638804107
Iter: 94 loss: 0.000527942495
Iter: 95 loss: 0.00052239222
Iter: 96 loss: 0.00051739614
Iter: 97 loss: 0.000507350429
Iter: 98 loss: 0.000497725036
Iter: 99 loss: 0.000495480315
Iter: 100 loss: 0.000479018578
Iter: 101 loss: 0.000488777179
Iter: 102 loss: 0.000468389189
Iter: 103 loss: 0.000452251639
Iter: 104 loss: 0.00049751508
Iter: 105 loss: 0.000447053055
Iter: 106 loss: 0.000428407162
Iter: 107 loss: 0.000493906846
Iter: 108 loss: 0.000423412799
Iter: 109 loss: 0.000407988031
Iter: 110 loss: 0.000435264024
Iter: 111 loss: 0.000401194062
Iter: 112 loss: 0.000385704
Iter: 113 loss: 0.000457152579
Iter: 114 loss: 0.000382683036
Iter: 115 loss: 0.000367486558
Iter: 116 loss: 0.00040564104
Iter: 117 loss: 0.000362079707
Iter: 118 loss: 0.000349747512
Iter: 119 loss: 0.000389557914
Iter: 120 loss: 0.00034618465
Iter: 121 loss: 0.000334616343
Iter: 122 loss: 0.000361934595
Iter: 123 loss: 0.000330358656
Iter: 124 loss: 0.000319070823
Iter: 125 loss: 0.00033733953
Iter: 126 loss: 0.000313836557
Iter: 127 loss: 0.00030532747
Iter: 128 loss: 0.000451459113
Iter: 129 loss: 0.000305325782
Iter: 130 loss: 0.000298602274
Iter: 131 loss: 0.000375691801
Iter: 132 loss: 0.000298534491
Iter: 133 loss: 0.000294467231
Iter: 134 loss: 0.000286556256
Iter: 135 loss: 0.000452911976
Iter: 136 loss: 0.000286503287
Iter: 137 loss: 0.000278401276
Iter: 138 loss: 0.000287055387
Iter: 139 loss: 0.000273917831
Iter: 140 loss: 0.000265465438
Iter: 141 loss: 0.00027525716
Iter: 142 loss: 0.000260925881
Iter: 143 loss: 0.000251457735
Iter: 144 loss: 0.000302520726
Iter: 145 loss: 0.000250066776
Iter: 146 loss: 0.000242372771
Iter: 147 loss: 0.00026466744
Iter: 148 loss: 0.000239993737
Iter: 149 loss: 0.000233789047
Iter: 150 loss: 0.000265755516
Iter: 151 loss: 0.000232784689
Iter: 152 loss: 0.000226351549
Iter: 153 loss: 0.000235306739
Iter: 154 loss: 0.000223187017
Iter: 155 loss: 0.000217310677
Iter: 156 loss: 0.000230915466
Iter: 157 loss: 0.000215114094
Iter: 158 loss: 0.000209281076
Iter: 159 loss: 0.000242363167
Iter: 160 loss: 0.000208472149
Iter: 161 loss: 0.00020386737
Iter: 162 loss: 0.000207589823
Iter: 163 loss: 0.000201119954
Iter: 164 loss: 0.000200202558
Iter: 165 loss: 0.000198868627
Iter: 166 loss: 0.000196813809
Iter: 167 loss: 0.000193874526
Iter: 168 loss: 0.000193780084
Iter: 169 loss: 0.000189575047
Iter: 170 loss: 0.000192080683
Iter: 171 loss: 0.000186862249
Iter: 172 loss: 0.000182736549
Iter: 173 loss: 0.000187484606
Iter: 174 loss: 0.000180519623
Iter: 175 loss: 0.000175863985
Iter: 176 loss: 0.00020650214
Iter: 177 loss: 0.000175362307
Iter: 178 loss: 0.000172001164
Iter: 179 loss: 0.00017415265
Iter: 180 loss: 0.000169857391
Iter: 181 loss: 0.000165593374
Iter: 182 loss: 0.000179590701
Iter: 183 loss: 0.000164396231
Iter: 184 loss: 0.000160838419
Iter: 185 loss: 0.000183591779
Iter: 186 loss: 0.000160433527
Iter: 187 loss: 0.000157277085
Iter: 188 loss: 0.000166565966
Iter: 189 loss: 0.00015630007
Iter: 190 loss: 0.000153437242
Iter: 191 loss: 0.000155648217
Iter: 192 loss: 0.000151682965
Iter: 193 loss: 0.000148846375
Iter: 194 loss: 0.000167988634
Iter: 195 loss: 0.000148556428
Iter: 196 loss: 0.000146110295
Iter: 197 loss: 0.000160846044
Iter: 198 loss: 0.000145822443
Iter: 199 loss: 0.000143981422
Iter: 200 loss: 0.000143980753
Iter: 201 loss: 0.000143139332
Iter: 202 loss: 0.000140979464
Iter: 203 loss: 0.000158941097
Iter: 204 loss: 0.000140607648
Iter: 205 loss: 0.000138048927
Iter: 206 loss: 0.000150080916
Iter: 207 loss: 0.000137575786
Iter: 208 loss: 0.000135396025
Iter: 209 loss: 0.000137457508
Iter: 210 loss: 0.000134144211
Iter: 211 loss: 0.0001318125
Iter: 212 loss: 0.000146326376
Iter: 213 loss: 0.000131537949
Iter: 214 loss: 0.00012934074
Iter: 215 loss: 0.000128812957
Iter: 216 loss: 0.000127408915
Iter: 217 loss: 0.000124932703
Iter: 218 loss: 0.000137127397
Iter: 219 loss: 0.000124506798
Iter: 220 loss: 0.000122399826
Iter: 221 loss: 0.000143875135
Iter: 222 loss: 0.000122333644
Iter: 223 loss: 0.000120754245
Iter: 224 loss: 0.000121578858
Iter: 225 loss: 0.000119708042
Iter: 226 loss: 0.000117851567
Iter: 227 loss: 0.000125524122
Iter: 228 loss: 0.000117448428
Iter: 229 loss: 0.000115855029
Iter: 230 loss: 0.000120377641
Iter: 231 loss: 0.000115345174
Iter: 232 loss: 0.000114495902
Iter: 233 loss: 0.000114366318
Iter: 234 loss: 0.000113373135
Iter: 235 loss: 0.000112362715
Iter: 236 loss: 0.00011216315
Iter: 237 loss: 0.000111093905
Iter: 238 loss: 0.000110110814
Iter: 239 loss: 0.000109851579
Iter: 240 loss: 0.000108107124
Iter: 241 loss: 0.000117592652
Iter: 242 loss: 0.000107848027
Iter: 243 loss: 0.000106364736
Iter: 244 loss: 0.000107485292
Iter: 245 loss: 0.000105457591
Iter: 246 loss: 0.000103629223
Iter: 247 loss: 0.000110085406
Iter: 248 loss: 0.000103155529
Iter: 249 loss: 0.00010137049
Iter: 250 loss: 0.000105736821
Iter: 251 loss: 0.00010072923
Iter: 252 loss: 9.93151771e-05
Iter: 253 loss: 0.000107117725
Iter: 254 loss: 9.9109755e-05
Iter: 255 loss: 9.77893797e-05
Iter: 256 loss: 9.9160563e-05
Iter: 257 loss: 9.7054668e-05
Iter: 258 loss: 9.58089804e-05
Iter: 259 loss: 0.000101606434
Iter: 260 loss: 9.55784781e-05
Iter: 261 loss: 9.43656123e-05
Iter: 262 loss: 9.98318428e-05
Iter: 263 loss: 9.41303e-05
Iter: 264 loss: 9.33801421e-05
Iter: 265 loss: 9.87969688e-05
Iter: 266 loss: 9.33114788e-05
Iter: 267 loss: 9.25547065e-05
Iter: 268 loss: 9.79668403e-05
Iter: 269 loss: 9.24919223e-05
Iter: 270 loss: 9.20670427e-05
Iter: 271 loss: 9.1263275e-05
Iter: 272 loss: 0.000109140659
Iter: 273 loss: 9.12607793e-05
Iter: 274 loss: 9.02660468e-05
Iter: 275 loss: 9.17726866e-05
Iter: 276 loss: 8.97919817e-05
Iter: 277 loss: 8.88464856e-05
Iter: 278 loss: 9.0963862e-05
Iter: 279 loss: 8.84871624e-05
Iter: 280 loss: 8.7530032e-05
Iter: 281 loss: 9.21164901e-05
Iter: 282 loss: 8.73572426e-05
Iter: 283 loss: 8.65874608e-05
Iter: 284 loss: 8.85506597e-05
Iter: 285 loss: 8.63213354e-05
Iter: 286 loss: 8.55061371e-05
Iter: 287 loss: 8.69739306e-05
Iter: 288 loss: 8.5150823e-05
Iter: 289 loss: 8.42697336e-05
Iter: 290 loss: 8.81791493e-05
Iter: 291 loss: 8.4092957e-05
Iter: 292 loss: 8.33617669e-05
Iter: 293 loss: 8.45889736e-05
Iter: 294 loss: 8.30309582e-05
Iter: 295 loss: 8.23592e-05
Iter: 296 loss: 8.60015e-05
Iter: 297 loss: 8.22587463e-05
Iter: 298 loss: 8.15821259e-05
Iter: 299 loss: 8.378856e-05
Iter: 300 loss: 8.13946244e-05
Iter: 301 loss: 8.12428189e-05
Iter: 302 loss: 8.11319478e-05
Iter: 303 loss: 8.09010526e-05
Iter: 304 loss: 8.03488e-05
Iter: 305 loss: 8.64678441e-05
Iter: 306 loss: 8.02938375e-05
Iter: 307 loss: 7.97473331e-05
Iter: 308 loss: 8.21011781e-05
Iter: 309 loss: 7.96339955e-05
Iter: 310 loss: 7.91612692e-05
Iter: 311 loss: 7.9287478e-05
Iter: 312 loss: 7.88182369e-05
Iter: 313 loss: 7.82434436e-05
Iter: 314 loss: 8.14905216e-05
Iter: 315 loss: 7.81632843e-05
Iter: 316 loss: 7.7639379e-05
Iter: 317 loss: 7.84214499e-05
Iter: 318 loss: 7.73883949e-05
Iter: 319 loss: 7.68439932e-05
Iter: 320 loss: 7.80326227e-05
Iter: 321 loss: 7.66339726e-05
Iter: 322 loss: 7.60927505e-05
Iter: 323 loss: 7.85301236e-05
Iter: 324 loss: 7.59876202e-05
Iter: 325 loss: 7.55271321e-05
Iter: 326 loss: 7.70941551e-05
Iter: 327 loss: 7.54035573e-05
Iter: 328 loss: 7.49624596e-05
Iter: 329 loss: 7.5708369e-05
Iter: 330 loss: 7.47634476e-05
Iter: 331 loss: 7.42883567e-05
Iter: 332 loss: 7.54068606e-05
Iter: 333 loss: 7.41134572e-05
Iter: 334 loss: 7.39321258e-05
Iter: 335 loss: 7.38515591e-05
Iter: 336 loss: 7.36041547e-05
Iter: 337 loss: 7.38361705e-05
Iter: 338 loss: 7.34609494e-05
Iter: 339 loss: 7.32323824e-05
Iter: 340 loss: 7.29828e-05
Iter: 341 loss: 7.2945295e-05
Iter: 342 loss: 7.25356076e-05
Iter: 343 loss: 7.28773884e-05
Iter: 344 loss: 7.22916302e-05
Iter: 345 loss: 7.18127922e-05
Iter: 346 loss: 7.29695457e-05
Iter: 347 loss: 7.16403592e-05
Iter: 348 loss: 7.1203307e-05
Iter: 349 loss: 7.41586482e-05
Iter: 350 loss: 7.11592947e-05
Iter: 351 loss: 7.07706859e-05
Iter: 352 loss: 7.11256725e-05
Iter: 353 loss: 7.05457496e-05
Iter: 354 loss: 7.01244426e-05
Iter: 355 loss: 7.12127367e-05
Iter: 356 loss: 6.99797674e-05
Iter: 357 loss: 6.956375e-05
Iter: 358 loss: 7.14234629e-05
Iter: 359 loss: 6.94821356e-05
Iter: 360 loss: 6.91222085e-05
Iter: 361 loss: 6.92720641e-05
Iter: 362 loss: 6.8874564e-05
Iter: 363 loss: 6.84644765e-05
Iter: 364 loss: 7.23825069e-05
Iter: 365 loss: 6.84486804e-05
Iter: 366 loss: 6.81342353e-05
Iter: 367 loss: 6.90504166e-05
Iter: 368 loss: 6.80360245e-05
Iter: 369 loss: 6.78190772e-05
Iter: 370 loss: 6.78015276e-05
Iter: 371 loss: 6.7687e-05
Iter: 372 loss: 6.74084877e-05
Iter: 373 loss: 7.03539117e-05
Iter: 374 loss: 6.73771137e-05
Iter: 375 loss: 6.70385198e-05
Iter: 376 loss: 6.83322214e-05
Iter: 377 loss: 6.69584697e-05
Iter: 378 loss: 6.6680368e-05
Iter: 379 loss: 6.64025574e-05
Iter: 380 loss: 6.63455721e-05
Iter: 381 loss: 6.5924949e-05
Iter: 382 loss: 6.88752552e-05
Iter: 383 loss: 6.58860299e-05
Iter: 384 loss: 6.555859e-05
Iter: 385 loss: 6.73035393e-05
Iter: 386 loss: 6.55084223e-05
Iter: 387 loss: 6.52292219e-05
Iter: 388 loss: 6.55836193e-05
Iter: 389 loss: 6.50855654e-05
Iter: 390 loss: 6.47801353e-05
Iter: 391 loss: 6.55229524e-05
Iter: 392 loss: 6.46707631e-05
Iter: 393 loss: 6.43588719e-05
Iter: 394 loss: 6.53375901e-05
Iter: 395 loss: 6.42683299e-05
Iter: 396 loss: 6.39676728e-05
Iter: 397 loss: 6.46197732e-05
Iter: 398 loss: 6.38511e-05
Iter: 399 loss: 6.35428805e-05
Iter: 400 loss: 6.49317517e-05
Iter: 401 loss: 6.34832395e-05
Iter: 402 loss: 6.33782474e-05
Iter: 403 loss: 6.33403542e-05
Iter: 404 loss: 6.32179726e-05
Iter: 405 loss: 6.30661598e-05
Iter: 406 loss: 6.30531576e-05
Iter: 407 loss: 6.28730486e-05
Iter: 408 loss: 6.29173e-05
Iter: 409 loss: 6.27411937e-05
Iter: 410 loss: 6.2492305e-05
Iter: 411 loss: 6.3034262e-05
Iter: 412 loss: 6.23958185e-05
Iter: 413 loss: 6.21767394e-05
Iter: 414 loss: 6.28764101e-05
Iter: 415 loss: 6.21144354e-05
Iter: 416 loss: 6.18929625e-05
Iter: 417 loss: 6.24685636e-05
Iter: 418 loss: 6.18176564e-05
Iter: 419 loss: 6.15995814e-05
Iter: 420 loss: 6.17598562e-05
Iter: 421 loss: 6.14654e-05
Iter: 422 loss: 6.12197182e-05
Iter: 423 loss: 6.26622495e-05
Iter: 424 loss: 6.11876312e-05
Iter: 425 loss: 6.09768e-05
Iter: 426 loss: 6.15389581e-05
Iter: 427 loss: 6.09063572e-05
Iter: 428 loss: 6.07070324e-05
Iter: 429 loss: 6.10996067e-05
Iter: 430 loss: 6.06250469e-05
Iter: 431 loss: 6.03866938e-05
Iter: 432 loss: 6.12266158e-05
Iter: 433 loss: 6.03253138e-05
Iter: 434 loss: 6.01588763e-05
Iter: 435 loss: 6.10177e-05
Iter: 436 loss: 6.0132792e-05
Iter: 437 loss: 5.99227897e-05
Iter: 438 loss: 6.11521609e-05
Iter: 439 loss: 5.98950319e-05
Iter: 440 loss: 5.9811282e-05
Iter: 441 loss: 5.96339305e-05
Iter: 442 loss: 6.25369066e-05
Iter: 443 loss: 5.96285718e-05
Iter: 444 loss: 5.94139128e-05
Iter: 445 loss: 6.07123584e-05
Iter: 446 loss: 5.93873701e-05
Iter: 447 loss: 5.92401739e-05
Iter: 448 loss: 5.93640179e-05
Iter: 449 loss: 5.91529351e-05
Iter: 450 loss: 5.89688134e-05
Iter: 451 loss: 5.93671612e-05
Iter: 452 loss: 5.88972252e-05
Iter: 453 loss: 5.86994356e-05
Iter: 454 loss: 5.93283148e-05
Iter: 455 loss: 5.86427705e-05
Iter: 456 loss: 5.84748632e-05
Iter: 457 loss: 5.90906566e-05
Iter: 458 loss: 5.84333866e-05
Iter: 459 loss: 5.8279169e-05
Iter: 460 loss: 5.85127855e-05
Iter: 461 loss: 5.82058019e-05
Iter: 462 loss: 5.80114065e-05
Iter: 463 loss: 5.85281559e-05
Iter: 464 loss: 5.79462103e-05
Iter: 465 loss: 5.77696337e-05
Iter: 466 loss: 5.84661066e-05
Iter: 467 loss: 5.77291175e-05
Iter: 468 loss: 5.75757877e-05
Iter: 469 loss: 5.79721091e-05
Iter: 470 loss: 5.75231206e-05
Iter: 471 loss: 5.7473e-05
Iter: 472 loss: 5.74345468e-05
Iter: 473 loss: 5.73712387e-05
Iter: 474 loss: 5.72356184e-05
Iter: 475 loss: 5.9407037e-05
Iter: 476 loss: 5.72309582e-05
Iter: 477 loss: 5.70971461e-05
Iter: 478 loss: 5.7254736e-05
Iter: 479 loss: 5.70259581e-05
Iter: 480 loss: 5.68668402e-05
Iter: 481 loss: 5.70663178e-05
Iter: 482 loss: 5.67843708e-05
Iter: 483 loss: 5.66176277e-05
Iter: 484 loss: 5.7511279e-05
Iter: 485 loss: 5.65924347e-05
Iter: 486 loss: 5.6433757e-05
Iter: 487 loss: 5.6863184e-05
Iter: 488 loss: 5.63814392e-05
Iter: 489 loss: 5.62378227e-05
Iter: 490 loss: 5.63701324e-05
Iter: 491 loss: 5.61547167e-05
Iter: 492 loss: 5.59885193e-05
Iter: 493 loss: 5.66623785e-05
Iter: 494 loss: 5.59513464e-05
Iter: 495 loss: 5.57921157e-05
Iter: 496 loss: 5.59004693e-05
Iter: 497 loss: 5.56922132e-05
Iter: 498 loss: 5.55215156e-05
Iter: 499 loss: 5.62393543e-05
Iter: 500 loss: 5.54852886e-05
Iter: 501 loss: 5.53151913e-05
Iter: 502 loss: 5.62755e-05
Iter: 503 loss: 5.52914062e-05
Iter: 504 loss: 5.51996418e-05
Iter: 505 loss: 5.51995436e-05
Iter: 506 loss: 5.50970035e-05
Iter: 507 loss: 5.51207e-05
Iter: 508 loss: 5.50214572e-05
Iter: 509 loss: 5.49268188e-05
Iter: 510 loss: 5.4811615e-05
Iter: 511 loss: 5.48005337e-05
Iter: 512 loss: 5.46516458e-05
Iter: 513 loss: 5.52357633e-05
Iter: 514 loss: 5.46172814e-05
Iter: 515 loss: 5.44751456e-05
Iter: 516 loss: 5.48849021e-05
Iter: 517 loss: 5.44305876e-05
Iter: 518 loss: 5.43139395e-05
Iter: 519 loss: 5.47379423e-05
Iter: 520 loss: 5.42846974e-05
Iter: 521 loss: 5.41536792e-05
Iter: 522 loss: 5.43916685e-05
Iter: 523 loss: 5.40967849e-05
Iter: 524 loss: 5.3974e-05
Iter: 525 loss: 5.41033369e-05
Iter: 526 loss: 5.39061948e-05
Iter: 527 loss: 5.37620217e-05
Iter: 528 loss: 5.4492928e-05
Iter: 529 loss: 5.37381857e-05
Iter: 530 loss: 5.36176885e-05
Iter: 531 loss: 5.39069079e-05
Iter: 532 loss: 5.35742547e-05
Iter: 533 loss: 5.34556202e-05
Iter: 534 loss: 5.37761698e-05
Iter: 535 loss: 5.34163337e-05
Iter: 536 loss: 5.33070925e-05
Iter: 537 loss: 5.38747518e-05
Iter: 538 loss: 5.32898048e-05
Iter: 539 loss: 5.32152189e-05
Iter: 540 loss: 5.32122576e-05
Iter: 541 loss: 5.31676087e-05
Iter: 542 loss: 5.30441648e-05
Iter: 543 loss: 5.3770229e-05
Iter: 544 loss: 5.30096877e-05
Iter: 545 loss: 5.28840174e-05
Iter: 546 loss: 5.36863299e-05
Iter: 547 loss: 5.28698256e-05
Iter: 548 loss: 5.2753152e-05
Iter: 549 loss: 5.28853161e-05
Iter: 550 loss: 5.26901676e-05
Iter: 551 loss: 5.25732976e-05
Iter: 552 loss: 5.31216065e-05
Iter: 553 loss: 5.25517025e-05
Iter: 554 loss: 5.24471e-05
Iter: 555 loss: 5.27274969e-05
Iter: 556 loss: 5.24122e-05
Iter: 557 loss: 5.23221e-05
Iter: 558 loss: 5.26576077e-05
Iter: 559 loss: 5.22999726e-05
Iter: 560 loss: 5.2197789e-05
Iter: 561 loss: 5.22928131e-05
Iter: 562 loss: 5.21389084e-05
Iter: 563 loss: 5.20386857e-05
Iter: 564 loss: 5.2178224e-05
Iter: 565 loss: 5.19890382e-05
Iter: 566 loss: 5.18707093e-05
Iter: 567 loss: 5.24561838e-05
Iter: 568 loss: 5.18505476e-05
Iter: 569 loss: 5.17489e-05
Iter: 570 loss: 5.19992391e-05
Iter: 571 loss: 5.17126537e-05
Iter: 572 loss: 5.17131411e-05
Iter: 573 loss: 5.16729051e-05
Iter: 574 loss: 5.16345171e-05
Iter: 575 loss: 5.15465072e-05
Iter: 576 loss: 5.26884905e-05
Iter: 577 loss: 5.1540439e-05
Iter: 578 loss: 5.14601597e-05
Iter: 579 loss: 5.14712483e-05
Iter: 580 loss: 5.13991035e-05
Iter: 581 loss: 5.12940205e-05
Iter: 582 loss: 5.19422247e-05
Iter: 583 loss: 5.12815168e-05
Iter: 584 loss: 5.11956459e-05
Iter: 585 loss: 5.12918123e-05
Iter: 586 loss: 5.11493199e-05
Iter: 587 loss: 5.10674763e-05
Iter: 588 loss: 5.14011626e-05
Iter: 589 loss: 5.10495229e-05
Iter: 590 loss: 5.09616293e-05
Iter: 591 loss: 5.12361657e-05
Iter: 592 loss: 5.0936178e-05
Iter: 593 loss: 5.08578087e-05
Iter: 594 loss: 5.10149403e-05
Iter: 595 loss: 5.08259618e-05
Iter: 596 loss: 5.07371042e-05
Iter: 597 loss: 5.08674675e-05
Iter: 598 loss: 5.06941687e-05
Iter: 599 loss: 5.06003926e-05
Iter: 600 loss: 5.10100508e-05
Iter: 601 loss: 5.05815e-05
Iter: 602 loss: 5.05036e-05
Iter: 603 loss: 5.07474761e-05
Iter: 604 loss: 5.04810123e-05
Iter: 605 loss: 5.04102136e-05
Iter: 606 loss: 5.07811055e-05
Iter: 607 loss: 5.03990086e-05
Iter: 608 loss: 5.03300034e-05
Iter: 609 loss: 5.11500839e-05
Iter: 610 loss: 5.03291412e-05
Iter: 611 loss: 5.03031843e-05
Iter: 612 loss: 5.02372932e-05
Iter: 613 loss: 5.08197518e-05
Iter: 614 loss: 5.02271105e-05
Iter: 615 loss: 5.01411487e-05
Iter: 616 loss: 5.03645424e-05
Iter: 617 loss: 5.01118848e-05
Iter: 618 loss: 5.00336537e-05
Iter: 619 loss: 5.01818577e-05
Iter: 620 loss: 5.00005663e-05
Iter: 621 loss: 4.99276757e-05
Iter: 622 loss: 5.04656928e-05
Iter: 623 loss: 4.99216912e-05
Iter: 624 loss: 4.98572117e-05
Iter: 625 loss: 4.99188754e-05
Iter: 626 loss: 4.98204026e-05
Iter: 627 loss: 4.97496076e-05
Iter: 628 loss: 5.00738533e-05
Iter: 629 loss: 4.97361762e-05
Iter: 630 loss: 4.96637949e-05
Iter: 631 loss: 4.97478031e-05
Iter: 632 loss: 4.96252687e-05
Iter: 633 loss: 4.95592758e-05
Iter: 634 loss: 4.97665715e-05
Iter: 635 loss: 4.95399581e-05
Iter: 636 loss: 4.94667402e-05
Iter: 637 loss: 4.97126421e-05
Iter: 638 loss: 4.94469e-05
Iter: 639 loss: 4.93839871e-05
Iter: 640 loss: 4.95013155e-05
Iter: 641 loss: 4.93570806e-05
Iter: 642 loss: 4.9346283e-05
Iter: 643 loss: 4.93237967e-05
Iter: 644 loss: 4.93015541e-05
Iter: 645 loss: 4.92404579e-05
Iter: 646 loss: 4.96002103e-05
Iter: 647 loss: 4.92233412e-05
Iter: 648 loss: 4.91553e-05
Iter: 649 loss: 4.93544067e-05
Iter: 650 loss: 4.91343235e-05
Iter: 651 loss: 4.9066417e-05
Iter: 652 loss: 4.93289626e-05
Iter: 653 loss: 4.90506063e-05
Iter: 654 loss: 4.89859449e-05
Iter: 655 loss: 4.90502243e-05
Iter: 656 loss: 4.89494923e-05
Iter: 657 loss: 4.88819023e-05
Iter: 658 loss: 4.92565086e-05
Iter: 659 loss: 4.88721089e-05
Iter: 660 loss: 4.88138867e-05
Iter: 661 loss: 4.89365775e-05
Iter: 662 loss: 4.87911457e-05
Iter: 663 loss: 4.87346151e-05
Iter: 664 loss: 4.90738676e-05
Iter: 665 loss: 4.8727612e-05
Iter: 666 loss: 4.86813296e-05
Iter: 667 loss: 4.87037723e-05
Iter: 668 loss: 4.86502104e-05
Iter: 669 loss: 4.85910059e-05
Iter: 670 loss: 4.87722646e-05
Iter: 671 loss: 4.85735727e-05
Iter: 672 loss: 4.85183555e-05
Iter: 673 loss: 4.8714217e-05
Iter: 674 loss: 4.85041273e-05
Iter: 675 loss: 4.8475853e-05
Iter: 676 loss: 4.84741686e-05
Iter: 677 loss: 4.84401316e-05
Iter: 678 loss: 4.8428119e-05
Iter: 679 loss: 4.84087359e-05
Iter: 680 loss: 4.83756739e-05
Iter: 681 loss: 4.83725817e-05
Iter: 682 loss: 4.83482181e-05
Iter: 683 loss: 4.83026524e-05
Iter: 684 loss: 4.83320036e-05
Iter: 685 loss: 4.82737487e-05
Iter: 686 loss: 4.82227333e-05
Iter: 687 loss: 4.84094053e-05
Iter: 688 loss: 4.82099567e-05
Iter: 689 loss: 4.81584e-05
Iter: 690 loss: 4.83132535e-05
Iter: 691 loss: 4.8142967e-05
Iter: 692 loss: 4.80970921e-05
Iter: 693 loss: 4.81186071e-05
Iter: 694 loss: 4.80660601e-05
Iter: 695 loss: 4.80240524e-05
Iter: 696 loss: 4.86549179e-05
Iter: 697 loss: 4.80239978e-05
Iter: 698 loss: 4.79854425e-05
Iter: 699 loss: 4.79809023e-05
Iter: 700 loss: 4.79533192e-05
Iter: 701 loss: 4.79079572e-05
Iter: 702 loss: 4.80709132e-05
Iter: 703 loss: 4.78966285e-05
Iter: 704 loss: 4.78538568e-05
Iter: 705 loss: 4.80067902e-05
Iter: 706 loss: 4.78428774e-05
Iter: 707 loss: 4.78060392e-05
Iter: 708 loss: 4.80322233e-05
Iter: 709 loss: 4.78015936e-05
Iter: 710 loss: 4.77696558e-05
Iter: 711 loss: 4.8193142e-05
Iter: 712 loss: 4.77695285e-05
Iter: 713 loss: 4.77526846e-05
Iter: 714 loss: 4.77106041e-05
Iter: 715 loss: 4.8115282e-05
Iter: 716 loss: 4.77049325e-05
Iter: 717 loss: 4.76601417e-05
Iter: 718 loss: 4.78245238e-05
Iter: 719 loss: 4.76491186e-05
Iter: 720 loss: 4.76094501e-05
Iter: 721 loss: 4.77015e-05
Iter: 722 loss: 4.75947891e-05
Iter: 723 loss: 4.75541383e-05
Iter: 724 loss: 4.762557e-05
Iter: 725 loss: 4.7536425e-05
Iter: 726 loss: 4.74961562e-05
Iter: 727 loss: 4.76870227e-05
Iter: 728 loss: 4.74888511e-05
Iter: 729 loss: 4.74528e-05
Iter: 730 loss: 4.75401466e-05
Iter: 731 loss: 4.74398403e-05
Iter: 732 loss: 4.74035623e-05
Iter: 733 loss: 4.7543188e-05
Iter: 734 loss: 4.73950167e-05
Iter: 735 loss: 4.73608452e-05
Iter: 736 loss: 4.74458429e-05
Iter: 737 loss: 4.73487125e-05
Iter: 738 loss: 4.7315647e-05
Iter: 739 loss: 4.74018852e-05
Iter: 740 loss: 4.73044493e-05
Iter: 741 loss: 4.72713145e-05
Iter: 742 loss: 4.74040462e-05
Iter: 743 loss: 4.72637403e-05
Iter: 744 loss: 4.72503598e-05
Iter: 745 loss: 4.72480315e-05
Iter: 746 loss: 4.72315733e-05
Iter: 747 loss: 4.71981548e-05
Iter: 748 loss: 4.78109e-05
Iter: 749 loss: 4.719766e-05
Iter: 750 loss: 4.71694657e-05
Iter: 751 loss: 4.72186075e-05
Iter: 752 loss: 4.71570456e-05
Iter: 753 loss: 4.71265412e-05
Iter: 754 loss: 4.71399799e-05
Iter: 755 loss: 4.71058083e-05
Iter: 756 loss: 4.70726227e-05
Iter: 757 loss: 4.73329201e-05
Iter: 758 loss: 4.70702871e-05
Iter: 759 loss: 4.70393e-05
Iter: 760 loss: 4.70530576e-05
Iter: 761 loss: 4.70182567e-05
Iter: 762 loss: 4.69848674e-05
Iter: 763 loss: 4.70734667e-05
Iter: 764 loss: 4.69736769e-05
Iter: 765 loss: 4.69427578e-05
Iter: 766 loss: 4.7089743e-05
Iter: 767 loss: 4.69371153e-05
Iter: 768 loss: 4.69101906e-05
Iter: 769 loss: 4.70280065e-05
Iter: 770 loss: 4.69047627e-05
Iter: 771 loss: 4.68788967e-05
Iter: 772 loss: 4.69127e-05
Iter: 773 loss: 4.68657818e-05
Iter: 774 loss: 4.6838144e-05
Iter: 775 loss: 4.6978821e-05
Iter: 776 loss: 4.68334729e-05
Iter: 777 loss: 4.68130966e-05
Iter: 778 loss: 4.69815604e-05
Iter: 779 loss: 4.68118888e-05
Iter: 780 loss: 4.67893042e-05
Iter: 781 loss: 4.68684084e-05
Iter: 782 loss: 4.67833e-05
Iter: 783 loss: 4.67720965e-05
Iter: 784 loss: 4.67489663e-05
Iter: 785 loss: 4.71601234e-05
Iter: 786 loss: 4.67484133e-05
Iter: 787 loss: 4.6721736e-05
Iter: 788 loss: 4.68297367e-05
Iter: 789 loss: 4.67157843e-05
Iter: 790 loss: 4.66891433e-05
Iter: 791 loss: 4.67230275e-05
Iter: 792 loss: 4.66755e-05
Iter: 793 loss: 4.66474376e-05
Iter: 794 loss: 4.67459904e-05
Iter: 795 loss: 4.6640147e-05
Iter: 796 loss: 4.66148376e-05
Iter: 797 loss: 4.67021891e-05
Iter: 798 loss: 4.66082201e-05
Iter: 799 loss: 4.65853336e-05
Iter: 800 loss: 4.6613859e-05
Iter: 801 loss: 4.65734702e-05
Iter: 802 loss: 4.65484045e-05
Iter: 803 loss: 4.67221689e-05
Iter: 804 loss: 4.65460398e-05
Iter: 805 loss: 4.65255362e-05
Iter: 806 loss: 4.65497e-05
Iter: 807 loss: 4.65147095e-05
Iter: 808 loss: 4.64938785e-05
Iter: 809 loss: 4.65958728e-05
Iter: 810 loss: 4.64902841e-05
Iter: 811 loss: 4.64711338e-05
Iter: 812 loss: 4.6546771e-05
Iter: 813 loss: 4.646663e-05
Iter: 814 loss: 4.6455e-05
Iter: 815 loss: 4.64540863e-05
Iter: 816 loss: 4.64467121e-05
Iter: 817 loss: 4.64320146e-05
Iter: 818 loss: 4.67072023e-05
Iter: 819 loss: 4.64318437e-05
Iter: 820 loss: 4.64144978e-05
Iter: 821 loss: 4.64113691e-05
Iter: 822 loss: 4.63996294e-05
Iter: 823 loss: 4.63775868e-05
Iter: 824 loss: 4.64199875e-05
Iter: 825 loss: 4.63684919e-05
Iter: 826 loss: 4.63469441e-05
Iter: 827 loss: 4.65361809e-05
Iter: 828 loss: 4.63458491e-05
Iter: 829 loss: 4.63289543e-05
Iter: 830 loss: 4.63383185e-05
Iter: 831 loss: 4.63178658e-05
Iter: 832 loss: 4.62993048e-05
Iter: 833 loss: 4.638463e-05
Iter: 834 loss: 4.62958342e-05
Iter: 835 loss: 4.62786047e-05
Iter: 836 loss: 4.63342e-05
Iter: 837 loss: 4.62736e-05
Iter: 838 loss: 4.6257348e-05
Iter: 839 loss: 4.62815588e-05
Iter: 840 loss: 4.62496027e-05
Iter: 841 loss: 4.62314201e-05
Iter: 842 loss: 4.62708849e-05
Iter: 843 loss: 4.62243697e-05
Iter: 844 loss: 4.62077332e-05
Iter: 845 loss: 4.63916076e-05
Iter: 846 loss: 4.62074e-05
Iter: 847 loss: 4.62009339e-05
Iter: 848 loss: 4.62004609e-05
Iter: 849 loss: 4.6193858e-05
Iter: 850 loss: 4.61822347e-05
Iter: 851 loss: 4.64652549e-05
Iter: 852 loss: 4.61821328e-05
Iter: 853 loss: 4.6169167e-05
Iter: 854 loss: 4.6160847e-05
Iter: 855 loss: 4.61558266e-05
Iter: 856 loss: 4.61385171e-05
Iter: 857 loss: 4.62433563e-05
Iter: 858 loss: 4.61364325e-05
Iter: 859 loss: 4.61226446e-05
Iter: 860 loss: 4.61432937e-05
Iter: 861 loss: 4.61160562e-05
Iter: 862 loss: 4.61010386e-05
Iter: 863 loss: 4.6160174e-05
Iter: 864 loss: 4.6097477e-05
Iter: 865 loss: 4.60820447e-05
Iter: 866 loss: 4.60967676e-05
Iter: 867 loss: 4.60732626e-05
Iter: 868 loss: 4.60566771e-05
Iter: 869 loss: 4.61013115e-05
Iter: 870 loss: 4.60510491e-05
Iter: 871 loss: 4.60344163e-05
Iter: 872 loss: 4.61204399e-05
Iter: 873 loss: 4.60316369e-05
Iter: 874 loss: 4.60178344e-05
Iter: 875 loss: 4.60494157e-05
Iter: 876 loss: 4.60128358e-05
Iter: 877 loss: 4.59990479e-05
Iter: 878 loss: 4.60588271e-05
Iter: 879 loss: 4.59961957e-05
Iter: 880 loss: 4.59879084e-05
Iter: 881 loss: 4.61179552e-05
Iter: 882 loss: 4.59878829e-05
Iter: 883 loss: 4.59786243e-05
Iter: 884 loss: 4.59848598e-05
Iter: 885 loss: 4.59726907e-05
Iter: 886 loss: 4.5964e-05
Iter: 887 loss: 4.59617804e-05
Iter: 888 loss: 4.59564799e-05
Iter: 889 loss: 4.59454823e-05
Iter: 890 loss: 4.59527146e-05
Iter: 891 loss: 4.5938421e-05
Iter: 892 loss: 4.59234579e-05
Iter: 893 loss: 4.59575531e-05
Iter: 894 loss: 4.59178955e-05
Iter: 895 loss: 4.59027942e-05
Iter: 896 loss: 4.59645744e-05
Iter: 897 loss: 4.5899731e-05
Iter: 898 loss: 4.5887653e-05
Iter: 899 loss: 4.5904053e-05
Iter: 900 loss: 4.58817594e-05
Iter: 901 loss: 4.5868248e-05
Iter: 902 loss: 4.58935465e-05
Iter: 903 loss: 4.58625218e-05
Iter: 904 loss: 4.58500799e-05
Iter: 905 loss: 4.59292787e-05
Iter: 906 loss: 4.58486065e-05
Iter: 907 loss: 4.58365757e-05
Iter: 908 loss: 4.58658687e-05
Iter: 909 loss: 4.58323193e-05
Iter: 910 loss: 4.58216236e-05
Iter: 911 loss: 4.58420109e-05
Iter: 912 loss: 4.58170434e-05
Iter: 913 loss: 4.58077484e-05
Iter: 914 loss: 4.59156217e-05
Iter: 915 loss: 4.58075956e-05
Iter: 916 loss: 4.57999704e-05
Iter: 917 loss: 4.58768918e-05
Iter: 918 loss: 4.57996794e-05
Iter: 919 loss: 4.57945607e-05
Iter: 920 loss: 4.57844435e-05
Iter: 921 loss: 4.59790899e-05
Iter: 922 loss: 4.57842834e-05
Iter: 923 loss: 4.57740316e-05
Iter: 924 loss: 4.57995702e-05
Iter: 925 loss: 4.57704336e-05
Iter: 926 loss: 4.57593924e-05
Iter: 927 loss: 4.57809219e-05
Iter: 928 loss: 4.57547576e-05
Iter: 929 loss: 4.57448841e-05
Iter: 930 loss: 4.57578208e-05
Iter: 931 loss: 4.57399401e-05
Iter: 932 loss: 4.57280184e-05
Iter: 933 loss: 4.5792538e-05
Iter: 934 loss: 4.57261849e-05
Iter: 935 loss: 4.57166316e-05
Iter: 936 loss: 4.57265414e-05
Iter: 937 loss: 4.57112401e-05
Iter: 938 loss: 4.5701272e-05
Iter: 939 loss: 4.57535971e-05
Iter: 940 loss: 4.56997659e-05
Iter: 941 loss: 4.56905545e-05
Iter: 942 loss: 4.57050337e-05
Iter: 943 loss: 4.5686189e-05
Iter: 944 loss: 4.56767484e-05
Iter: 945 loss: 4.570491e-05
Iter: 946 loss: 4.56739144e-05
Iter: 947 loss: 4.56644048e-05
Iter: 948 loss: 4.56970629e-05
Iter: 949 loss: 4.56618e-05
Iter: 950 loss: 4.56602429e-05
Iter: 951 loss: 4.5657609e-05
Iter: 952 loss: 4.56539747e-05
Iter: 953 loss: 4.56461275e-05
Iter: 954 loss: 4.57591377e-05
Iter: 955 loss: 4.5645651e-05
Iter: 956 loss: 4.56383495e-05
Iter: 957 loss: 4.56709749e-05
Iter: 958 loss: 4.56368325e-05
Iter: 959 loss: 4.56304551e-05
Iter: 960 loss: 4.56265843e-05
Iter: 961 loss: 4.5623965e-05
Iter: 962 loss: 4.56153502e-05
Iter: 963 loss: 4.56591551e-05
Iter: 964 loss: 4.56139751e-05
Iter: 965 loss: 4.56055168e-05
Iter: 966 loss: 4.56302041e-05
Iter: 967 loss: 4.56028247e-05
Iter: 968 loss: 4.55950212e-05
Iter: 969 loss: 4.56043781e-05
Iter: 970 loss: 4.55908194e-05
Iter: 971 loss: 4.55826666e-05
Iter: 972 loss: 4.56027483e-05
Iter: 973 loss: 4.55798763e-05
Iter: 974 loss: 4.55715963e-05
Iter: 975 loss: 4.56109665e-05
Iter: 976 loss: 4.55699665e-05
Iter: 977 loss: 4.55628033e-05
Iter: 978 loss: 4.55801855e-05
Iter: 979 loss: 4.55603367e-05
Iter: 980 loss: 4.55532863e-05
Iter: 981 loss: 4.55680638e-05
Iter: 982 loss: 4.55504924e-05
Iter: 983 loss: 4.55465924e-05
Iter: 984 loss: 4.55461e-05
Iter: 985 loss: 4.55416412e-05
Iter: 986 loss: 4.55470508e-05
Iter: 987 loss: 4.55394074e-05
Iter: 988 loss: 4.55356894e-05
Iter: 989 loss: 4.55311456e-05
Iter: 990 loss: 4.55308182e-05
Iter: 991 loss: 4.55244553e-05
Iter: 992 loss: 4.55386617e-05
Iter: 993 loss: 4.55220506e-05
Iter: 994 loss: 4.55154659e-05
Iter: 995 loss: 4.55374247e-05
Iter: 996 loss: 4.55135305e-05
Iter: 997 loss: 4.55075206e-05
Iter: 998 loss: 4.55182308e-05
Iter: 999 loss: 4.5504843e-05
Iter: 1000 loss: 4.54977053e-05
Iter: 1001 loss: 4.5520057e-05
Iter: 1002 loss: 4.54957917e-05
Iter: 1003 loss: 4.54900364e-05
Iter: 1004 loss: 4.54948749e-05
Iter: 1005 loss: 4.54866167e-05
Iter: 1006 loss: 4.54795954e-05
Iter: 1007 loss: 4.55242844e-05
Iter: 1008 loss: 4.54788533e-05
Iter: 1009 loss: 4.54735782e-05
Iter: 1010 loss: 4.54792389e-05
Iter: 1011 loss: 4.54706169e-05
Iter: 1012 loss: 4.54644542e-05
Iter: 1013 loss: 4.54972615e-05
Iter: 1014 loss: 4.54635301e-05
Iter: 1015 loss: 4.54579858e-05
Iter: 1016 loss: 4.54652618e-05
Iter: 1017 loss: 4.5455341e-05
Iter: 1018 loss: 4.54550463e-05
Iter: 1019 loss: 4.54524161e-05
Iter: 1020 loss: 4.54506953e-05
Iter: 1021 loss: 4.54458786e-05
Iter: 1022 loss: 4.5462064e-05
Iter: 1023 loss: 4.54437322e-05
Iter: 1024 loss: 4.54379551e-05
Iter: 1025 loss: 4.54745605e-05
Iter: 1026 loss: 4.54373439e-05
Iter: 1027 loss: 4.54321125e-05
Iter: 1028 loss: 4.54443507e-05
Iter: 1029 loss: 4.54302208e-05
Iter: 1030 loss: 4.54253459e-05
Iter: 1031 loss: 4.54336332e-05
Iter: 1032 loss: 4.5422923e-05
Iter: 1033 loss: 4.54177571e-05
Iter: 1034 loss: 4.54366091e-05
Iter: 1035 loss: 4.5416371e-05
Iter: 1036 loss: 4.54109104e-05
Iter: 1037 loss: 4.54143265e-05
Iter: 1038 loss: 4.54074761e-05
Iter: 1039 loss: 4.54012406e-05
Iter: 1040 loss: 4.54313122e-05
Iter: 1041 loss: 4.54002366e-05
Iter: 1042 loss: 4.53950233e-05
Iter: 1043 loss: 4.5413537e-05
Iter: 1044 loss: 4.53937428e-05
Iter: 1045 loss: 4.53885586e-05
Iter: 1046 loss: 4.53950779e-05
Iter: 1047 loss: 4.53858484e-05
Iter: 1048 loss: 4.53807079e-05
Iter: 1049 loss: 4.53934554e-05
Iter: 1050 loss: 4.53788161e-05
Iter: 1051 loss: 4.53783e-05
Iter: 1052 loss: 4.53764696e-05
Iter: 1053 loss: 4.53741086e-05
Iter: 1054 loss: 4.53707326e-05
Iter: 1055 loss: 4.53705034e-05
Iter: 1056 loss: 4.53671237e-05
Iter: 1057 loss: 4.53659086e-05
Iter: 1058 loss: 4.53638895e-05
Iter: 1059 loss: 4.53591092e-05
Iter: 1060 loss: 4.53778557e-05
Iter: 1061 loss: 4.5358036e-05
Iter: 1062 loss: 4.53534594e-05
Iter: 1063 loss: 4.53636676e-05
Iter: 1064 loss: 4.53516404e-05
Iter: 1065 loss: 4.53476168e-05
Iter: 1066 loss: 4.53633074e-05
Iter: 1067 loss: 4.53468856e-05
Iter: 1068 loss: 4.53422472e-05
Iter: 1069 loss: 4.53455723e-05
Iter: 1070 loss: 4.53394023e-05
Iter: 1071 loss: 4.53351677e-05
Iter: 1072 loss: 4.53550165e-05
Iter: 1073 loss: 4.53342946e-05
Iter: 1074 loss: 4.53302782e-05
Iter: 1075 loss: 4.53366301e-05
Iter: 1076 loss: 4.53284301e-05
Iter: 1077 loss: 4.53244e-05
Iter: 1078 loss: 4.53311732e-05
Iter: 1079 loss: 4.53225875e-05
Iter: 1080 loss: 4.53180546e-05
Iter: 1081 loss: 4.53389766e-05
Iter: 1082 loss: 4.53171597e-05
Iter: 1083 loss: 4.53132743e-05
Iter: 1084 loss: 4.53419852e-05
Iter: 1085 loss: 4.53130415e-05
Iter: 1086 loss: 4.53103276e-05
Iter: 1087 loss: 4.53102621e-05
Iter: 1088 loss: 4.53089451e-05
Iter: 1089 loss: 4.53049834e-05
Iter: 1090 loss: 4.53326065e-05
Iter: 1091 loss: 4.53041794e-05
Iter: 1092 loss: 4.5300294e-05
Iter: 1093 loss: 4.53205212e-05
Iter: 1094 loss: 4.5299741e-05
Iter: 1095 loss: 4.52960739e-05
Iter: 1096 loss: 4.53022731e-05
Iter: 1097 loss: 4.52944732e-05
Iter: 1098 loss: 4.5290737e-05
Iter: 1099 loss: 4.53008179e-05
Iter: 1100 loss: 4.52894601e-05
Iter: 1101 loss: 4.52857275e-05
Iter: 1102 loss: 4.53074317e-05
Iter: 1103 loss: 4.52853128e-05
Iter: 1104 loss: 4.52822787e-05
Iter: 1105 loss: 4.52844979e-05
Iter: 1106 loss: 4.52804306e-05
Iter: 1107 loss: 4.52767817e-05
Iter: 1108 loss: 4.52796085e-05
Iter: 1109 loss: 4.5274508e-05
Iter: 1110 loss: 4.52703061e-05
Iter: 1111 loss: 4.53029825e-05
Iter: 1112 loss: 4.52700951e-05
Iter: 1113 loss: 4.52667955e-05
Iter: 1114 loss: 4.52724271e-05
Iter: 1115 loss: 4.52653185e-05
Iter: 1116 loss: 4.52622262e-05
Iter: 1117 loss: 4.5273624e-05
Iter: 1118 loss: 4.52613749e-05
Iter: 1119 loss: 4.52604836e-05
Iter: 1120 loss: 4.5259796e-05
Iter: 1121 loss: 4.52583081e-05
Iter: 1122 loss: 4.52552194e-05
Iter: 1123 loss: 4.53133216e-05
Iter: 1124 loss: 4.52552194e-05
Iter: 1125 loss: 4.52526438e-05
Iter: 1126 loss: 4.52511267e-05
Iter: 1127 loss: 4.52500717e-05
Iter: 1128 loss: 4.52466047e-05
Iter: 1129 loss: 4.52798195e-05
Iter: 1130 loss: 4.52465792e-05
Iter: 1131 loss: 4.52438326e-05
Iter: 1132 loss: 4.524408e-05
Iter: 1133 loss: 4.52417516e-05
Iter: 1134 loss: 4.52384193e-05
Iter: 1135 loss: 4.52610329e-05
Iter: 1136 loss: 4.52381537e-05
Iter: 1137 loss: 4.52352142e-05
Iter: 1138 loss: 4.52393324e-05
Iter: 1139 loss: 4.52340246e-05
Iter: 1140 loss: 4.52313943e-05
Iter: 1141 loss: 4.5246321e-05
Iter: 1142 loss: 4.52310487e-05
Iter: 1143 loss: 4.52285058e-05
Iter: 1144 loss: 4.52283857e-05
Iter: 1145 loss: 4.52264685e-05
Iter: 1146 loss: 4.52232052e-05
Iter: 1147 loss: 4.52327949e-05
Iter: 1148 loss: 4.52221648e-05
Iter: 1149 loss: 4.5219138e-05
Iter: 1150 loss: 4.52345812e-05
Iter: 1151 loss: 4.52185814e-05
Iter: 1152 loss: 4.52163949e-05
Iter: 1153 loss: 4.52346321e-05
Iter: 1154 loss: 4.52161839e-05
Iter: 1155 loss: 4.52138156e-05
Iter: 1156 loss: 4.52293607e-05
Iter: 1157 loss: 4.52135864e-05
Iter: 1158 loss: 4.52125e-05
Iter: 1159 loss: 4.52098502e-05
Iter: 1160 loss: 4.52306558e-05
Iter: 1161 loss: 4.52091954e-05
Iter: 1162 loss: 4.52060594e-05
Iter: 1163 loss: 4.52268832e-05
Iter: 1164 loss: 4.52057611e-05
Iter: 1165 loss: 4.52031454e-05
Iter: 1166 loss: 4.52078166e-05
Iter: 1167 loss: 4.52020322e-05
Iter: 1168 loss: 4.51993692e-05
Iter: 1169 loss: 4.52051681e-05
Iter: 1170 loss: 4.51983215e-05
Iter: 1171 loss: 4.51954911e-05
Iter: 1172 loss: 4.52017848e-05
Iter: 1173 loss: 4.5194327e-05
Iter: 1174 loss: 4.51916e-05
Iter: 1175 loss: 4.52150889e-05
Iter: 1176 loss: 4.51913656e-05
Iter: 1177 loss: 4.51893793e-05
Iter: 1178 loss: 4.51886044e-05
Iter: 1179 loss: 4.51876222e-05
Iter: 1180 loss: 4.51846463e-05
Iter: 1181 loss: 4.51993546e-05
Iter: 1182 loss: 4.51842061e-05
Iter: 1183 loss: 4.51817541e-05
Iter: 1184 loss: 4.51876804e-05
Iter: 1185 loss: 4.51809829e-05
Iter: 1186 loss: 4.51786727e-05
Iter: 1187 loss: 4.5188317e-05
Iter: 1188 loss: 4.51782325e-05
Iter: 1189 loss: 4.51773813e-05
Iter: 1190 loss: 4.51770393e-05
Iter: 1191 loss: 4.51759588e-05
Iter: 1192 loss: 4.51735687e-05
Iter: 1193 loss: 4.51974047e-05
Iter: 1194 loss: 4.51732885e-05
Iter: 1195 loss: 4.51710184e-05
Iter: 1196 loss: 4.51747e-05
Iter: 1197 loss: 4.51700253e-05
Iter: 1198 loss: 4.51673841e-05
Iter: 1199 loss: 4.51764136e-05
Iter: 1200 loss: 4.51666965e-05
Iter: 1201 loss: 4.51640335e-05
Iter: 1202 loss: 4.51676387e-05
Iter: 1203 loss: 4.51629239e-05
Iter: 1204 loss: 4.5160632e-05
Iter: 1205 loss: 4.51794658e-05
Iter: 1206 loss: 4.51604137e-05
Iter: 1207 loss: 4.51585693e-05
Iter: 1208 loss: 4.51597589e-05
Iter: 1209 loss: 4.51574742e-05
Iter: 1210 loss: 4.51549713e-05
Iter: 1211 loss: 4.51637898e-05
Iter: 1212 loss: 4.51543528e-05
Iter: 1213 loss: 4.51523811e-05
Iter: 1214 loss: 4.51613705e-05
Iter: 1215 loss: 4.51519663e-05
Iter: 1216 loss: 4.51500637e-05
Iter: 1217 loss: 4.5151326e-05
Iter: 1218 loss: 4.5149045e-05
Iter: 1219 loss: 4.51467458e-05
Iter: 1220 loss: 4.51557644e-05
Iter: 1221 loss: 4.51461347e-05
Iter: 1222 loss: 4.51443921e-05
Iter: 1223 loss: 4.51608721e-05
Iter: 1224 loss: 4.51443775e-05
Iter: 1225 loss: 4.51426858e-05
Iter: 1226 loss: 4.51534506e-05
Iter: 1227 loss: 4.51424894e-05
Iter: 1228 loss: 4.51416927e-05
Iter: 1229 loss: 4.51397864e-05
Iter: 1230 loss: 4.5161516e-05
Iter: 1231 loss: 4.513967e-05
Iter: 1232 loss: 4.51376836e-05
Iter: 1233 loss: 4.51430205e-05
Iter: 1234 loss: 4.51371525e-05
Iter: 1235 loss: 4.51351516e-05
Iter: 1236 loss: 4.51465603e-05
Iter: 1237 loss: 4.51346314e-05
Iter: 1238 loss: 4.51331143e-05
Iter: 1239 loss: 4.51340966e-05
Iter: 1240 loss: 4.51321102e-05
Iter: 1241 loss: 4.51301421e-05
Iter: 1242 loss: 4.51345222e-05
Iter: 1243 loss: 4.51293454e-05
Iter: 1244 loss: 4.51270716e-05
Iter: 1245 loss: 4.51384331e-05
Iter: 1246 loss: 4.51267115e-05
Iter: 1247 loss: 4.51251362e-05
Iter: 1248 loss: 4.51336527e-05
Iter: 1249 loss: 4.51249e-05
Iter: 1250 loss: 4.51233573e-05
Iter: 1251 loss: 4.51229862e-05
Iter: 1252 loss: 4.51219385e-05
Iter: 1253 loss: 4.5120134e-05
Iter: 1254 loss: 4.51287342e-05
Iter: 1255 loss: 4.51198575e-05
Iter: 1256 loss: 4.51183441e-05
Iter: 1257 loss: 4.51278793e-05
Iter: 1258 loss: 4.51180604e-05
Iter: 1259 loss: 4.51172964e-05
Iter: 1260 loss: 4.51172091e-05
Iter: 1261 loss: 4.5116496e-05
Iter: 1262 loss: 4.5115e-05
Iter: 1263 loss: 4.5125118e-05
Iter: 1264 loss: 4.51144297e-05
Iter: 1265 loss: 4.51127198e-05
Iter: 1266 loss: 4.51153537e-05
Iter: 1267 loss: 4.51118722e-05
Iter: 1268 loss: 4.51101951e-05
Iter: 1269 loss: 4.51233755e-05
Iter: 1270 loss: 4.51100423e-05
Iter: 1271 loss: 4.51087471e-05
Iter: 1272 loss: 4.51079468e-05
Iter: 1273 loss: 4.51073865e-05
Iter: 1274 loss: 4.51055312e-05
Iter: 1275 loss: 4.51190062e-05
Iter: 1276 loss: 4.5105473e-05
Iter: 1277 loss: 4.51038868e-05
Iter: 1278 loss: 4.51087762e-05
Iter: 1279 loss: 4.51035e-05
Iter: 1280 loss: 4.51020496e-05
Iter: 1281 loss: 4.51045125e-05
Iter: 1282 loss: 4.51014275e-05
Iter: 1283 loss: 4.50998814e-05
Iter: 1284 loss: 4.51041487e-05
Iter: 1285 loss: 4.50993393e-05
Iter: 1286 loss: 4.50976877e-05
Iter: 1287 loss: 4.51033447e-05
Iter: 1288 loss: 4.50972766e-05
Iter: 1289 loss: 4.50956941e-05
Iter: 1290 loss: 4.50993684e-05
Iter: 1291 loss: 4.5095152e-05
Iter: 1292 loss: 4.50943626e-05
Iter: 1293 loss: 4.50943371e-05
Iter: 1294 loss: 4.50932712e-05
Iter: 1295 loss: 4.5093162e-05
Iter: 1296 loss: 4.50926309e-05
Iter: 1297 loss: 4.50918888e-05
Iter: 1298 loss: 4.50904845e-05
Iter: 1299 loss: 4.50905354e-05
Iter: 1300 loss: 4.50890366e-05
Iter: 1301 loss: 4.50956977e-05
Iter: 1302 loss: 4.50888365e-05
Iter: 1303 loss: 4.50873486e-05
Iter: 1304 loss: 4.50909647e-05
Iter: 1305 loss: 4.5086992e-05
Iter: 1306 loss: 4.50855659e-05
Iter: 1307 loss: 4.50892367e-05
Iter: 1308 loss: 4.50851876e-05
Iter: 1309 loss: 4.50838197e-05
Iter: 1310 loss: 4.50869702e-05
Iter: 1311 loss: 4.50834486e-05
Iter: 1312 loss: 4.50819571e-05
Iter: 1313 loss: 4.50858424e-05
Iter: 1314 loss: 4.5081586e-05
Iter: 1315 loss: 4.50802872e-05
Iter: 1316 loss: 4.50820953e-05
Iter: 1317 loss: 4.50796724e-05
Iter: 1318 loss: 4.507829e-05
Iter: 1319 loss: 4.5089073e-05
Iter: 1320 loss: 4.50780644e-05
Iter: 1321 loss: 4.50770967e-05
Iter: 1322 loss: 4.50782063e-05
Iter: 1323 loss: 4.50766092e-05
Iter: 1324 loss: 4.50753687e-05
Iter: 1325 loss: 4.50825028e-05
Iter: 1326 loss: 4.50751832e-05
Iter: 1327 loss: 4.5074572e-05
Iter: 1328 loss: 4.50745065e-05
Iter: 1329 loss: 4.50740554e-05
Iter: 1330 loss: 4.50731022e-05
Iter: 1331 loss: 4.50817206e-05
Iter: 1332 loss: 4.50729131e-05
Iter: 1333 loss: 4.50718726e-05
Iter: 1334 loss: 4.50739935e-05
Iter: 1335 loss: 4.50713742e-05
Iter: 1336 loss: 4.50702282e-05
Iter: 1337 loss: 4.50746338e-05
Iter: 1338 loss: 4.5069828e-05
Iter: 1339 loss: 4.50688167e-05
Iter: 1340 loss: 4.50706939e-05
Iter: 1341 loss: 4.50682419e-05
Iter: 1342 loss: 4.5067005e-05
Iter: 1343 loss: 4.50683547e-05
Iter: 1344 loss: 4.50661755e-05
Iter: 1345 loss: 4.50649641e-05
Iter: 1346 loss: 4.50740445e-05
Iter: 1347 loss: 4.50648695e-05
Iter: 1348 loss: 4.50637672e-05
Iter: 1349 loss: 4.50663902e-05
Iter: 1350 loss: 4.50634179e-05
Iter: 1351 loss: 4.50622283e-05
Iter: 1352 loss: 4.50649313e-05
Iter: 1353 loss: 4.50618172e-05
Iter: 1354 loss: 4.50606749e-05
Iter: 1355 loss: 4.50636071e-05
Iter: 1356 loss: 4.50602965e-05
Iter: 1357 loss: 4.50593725e-05
Iter: 1358 loss: 4.50661173e-05
Iter: 1359 loss: 4.50593288e-05
Iter: 1360 loss: 4.50586886e-05
Iter: 1361 loss: 4.50586049e-05
Iter: 1362 loss: 4.50581101e-05
Iter: 1363 loss: 4.50577427e-05
Iter: 1364 loss: 4.50575026e-05
Iter: 1365 loss: 4.50570114e-05
Iter: 1366 loss: 4.5055931e-05
Iter: 1367 loss: 4.50559819e-05
Iter: 1368 loss: 4.50548941e-05
Iter: 1369 loss: 4.50593725e-05
Iter: 1370 loss: 4.50546759e-05
Iter: 1371 loss: 4.50535445e-05
Iter: 1372 loss: 4.50558e-05
Iter: 1373 loss: 4.50531588e-05
Iter: 1374 loss: 4.50521038e-05
Iter: 1375 loss: 4.50535081e-05
Iter: 1376 loss: 4.50515e-05
Iter: 1377 loss: 4.50504958e-05
Iter: 1378 loss: 4.50588086e-05
Iter: 1379 loss: 4.5050474e-05
Iter: 1380 loss: 4.50495027e-05
Iter: 1381 loss: 4.50495645e-05
Iter: 1382 loss: 4.50488078e-05
Iter: 1383 loss: 4.50478437e-05
Iter: 1384 loss: 4.50554326e-05
Iter: 1385 loss: 4.50476364e-05
Iter: 1386 loss: 4.50468215e-05
Iter: 1387 loss: 4.50473e-05
Iter: 1388 loss: 4.50461921e-05
Iter: 1389 loss: 4.50453808e-05
Iter: 1390 loss: 4.50517546e-05
Iter: 1391 loss: 4.50451698e-05
Iter: 1392 loss: 4.50446059e-05
Iter: 1393 loss: 4.50536536e-05
Iter: 1394 loss: 4.50445659e-05
Iter: 1395 loss: 4.50440493e-05
Iter: 1396 loss: 4.50457665e-05
Iter: 1397 loss: 4.50437874e-05
Iter: 1398 loss: 4.50433145e-05
Iter: 1399 loss: 4.5042776e-05
Iter: 1400 loss: 4.50427397e-05
Iter: 1401 loss: 4.50418447e-05
Iter: 1402 loss: 4.5042354e-05
Iter: 1403 loss: 4.50413572e-05
Iter: 1404 loss: 4.50403895e-05
Iter: 1405 loss: 4.50450607e-05
Iter: 1406 loss: 4.50402331e-05
Iter: 1407 loss: 4.50393454e-05
Iter: 1408 loss: 4.50407824e-05
Iter: 1409 loss: 4.50388943e-05
Iter: 1410 loss: 4.50380467e-05
Iter: 1411 loss: 4.50407533e-05
Iter: 1412 loss: 4.50377775e-05
Iter: 1413 loss: 4.50369189e-05
Iter: 1414 loss: 4.50378211e-05
Iter: 1415 loss: 4.50364023e-05
Iter: 1416 loss: 4.50355292e-05
Iter: 1417 loss: 4.5039993e-05
Iter: 1418 loss: 4.503534e-05
Iter: 1419 loss: 4.50343614e-05
Iter: 1420 loss: 4.5038465e-05
Iter: 1421 loss: 4.50341795e-05
Iter: 1422 loss: 4.50334555e-05
Iter: 1423 loss: 4.50338266e-05
Iter: 1424 loss: 4.50329062e-05
Iter: 1425 loss: 4.50322186e-05
Iter: 1426 loss: 4.50426487e-05
Iter: 1427 loss: 4.50321313e-05
Iter: 1428 loss: 4.50318075e-05
Iter: 1429 loss: 4.503729e-05
Iter: 1430 loss: 4.50317129e-05
Iter: 1431 loss: 4.50313164e-05
Iter: 1432 loss: 4.50305815e-05
Iter: 1433 loss: 4.50306761e-05
Iter: 1434 loss: 4.50300249e-05
Iter: 1435 loss: 4.50306507e-05
Iter: 1436 loss: 4.50296502e-05
Iter: 1437 loss: 4.50289081e-05
Iter: 1438 loss: 4.50314728e-05
Iter: 1439 loss: 4.50286498e-05
Iter: 1440 loss: 4.50279149e-05
Iter: 1441 loss: 4.50281877e-05
Iter: 1442 loss: 4.50274165e-05
Iter: 1443 loss: 4.50265798e-05
Iter: 1444 loss: 4.50300577e-05
Iter: 1445 loss: 4.50265143e-05
Iter: 1446 loss: 4.50256557e-05
Iter: 1447 loss: 4.50278312e-05
Iter: 1448 loss: 4.5025241e-05
Iter: 1449 loss: 4.50246152e-05
Iter: 1450 loss: 4.50272128e-05
Iter: 1451 loss: 4.5024346e-05
Iter: 1452 loss: 4.50236475e-05
Iter: 1453 loss: 4.50247753e-05
Iter: 1454 loss: 4.50231964e-05
Iter: 1455 loss: 4.50223961e-05
Iter: 1456 loss: 4.50254593e-05
Iter: 1457 loss: 4.50222287e-05
Iter: 1458 loss: 4.50215157e-05
Iter: 1459 loss: 4.50232692e-05
Iter: 1460 loss: 4.50212319e-05
Iter: 1461 loss: 4.50210136e-05
Iter: 1462 loss: 4.50208245e-05
Iter: 1463 loss: 4.50206135e-05
Iter: 1464 loss: 4.50200096e-05
Iter: 1465 loss: 4.50200423e-05
Iter: 1466 loss: 4.50194348e-05
Iter: 1467 loss: 4.50200605e-05
Iter: 1468 loss: 4.50190091e-05
Iter: 1469 loss: 4.50184598e-05
Iter: 1470 loss: 4.50196858e-05
Iter: 1471 loss: 4.50181833e-05
Iter: 1472 loss: 4.50175648e-05
Iter: 1473 loss: 4.50196894e-05
Iter: 1474 loss: 4.50173538e-05
Iter: 1475 loss: 4.50168e-05
Iter: 1476 loss: 4.50179832e-05
Iter: 1477 loss: 4.50165462e-05
Iter: 1478 loss: 4.50158077e-05
Iter: 1479 loss: 4.50172447e-05
Iter: 1480 loss: 4.50155858e-05
Iter: 1481 loss: 4.50150328e-05
Iter: 1482 loss: 4.50158077e-05
Iter: 1483 loss: 4.5014629e-05
Iter: 1484 loss: 4.50139341e-05
Iter: 1485 loss: 4.5018518e-05
Iter: 1486 loss: 4.50139196e-05
Iter: 1487 loss: 4.50133666e-05
Iter: 1488 loss: 4.5013745e-05
Iter: 1489 loss: 4.50130901e-05
Iter: 1490 loss: 4.5012348e-05
Iter: 1491 loss: 4.50140506e-05
Iter: 1492 loss: 4.50121588e-05
Iter: 1493 loss: 4.50117732e-05
Iter: 1494 loss: 4.50116931e-05
Iter: 1495 loss: 4.5011293e-05
Iter: 1496 loss: 4.50120351e-05
Iter: 1497 loss: 4.5011242e-05
Iter: 1498 loss: 4.50108564e-05
Iter: 1499 loss: 4.50104417e-05
Iter: 1500 loss: 4.5010398e-05
Iter: 1501 loss: 4.50097032e-05
Iter: 1502 loss: 4.50120715e-05
Iter: 1503 loss: 4.50096923e-05
Iter: 1504 loss: 4.50091393e-05
Iter: 1505 loss: 4.50103944e-05
Iter: 1506 loss: 4.50089647e-05
Iter: 1507 loss: 4.50083935e-05
Iter: 1508 loss: 4.50089501e-05
Iter: 1509 loss: 4.50079715e-05
Iter: 1510 loss: 4.5007444e-05
Iter: 1511 loss: 4.5009423e-05
Iter: 1512 loss: 4.50073494e-05
Iter: 1513 loss: 4.50067382e-05
Iter: 1514 loss: 4.50082189e-05
Iter: 1515 loss: 4.50064763e-05
Iter: 1516 loss: 4.50058578e-05
Iter: 1517 loss: 4.50077168e-05
Iter: 1518 loss: 4.50056614e-05
Iter: 1519 loss: 4.50050538e-05
Iter: 1520 loss: 4.50063053e-05
Iter: 1521 loss: 4.50048683e-05
Iter: 1522 loss: 4.50042535e-05
Iter: 1523 loss: 4.50059451e-05
Iter: 1524 loss: 4.50040061e-05
Iter: 1525 loss: 4.5003515e-05
Iter: 1526 loss: 4.5006811e-05
Iter: 1527 loss: 4.50035186e-05
Iter: 1528 loss: 4.50030348e-05
Iter: 1529 loss: 4.50074294e-05
Iter: 1530 loss: 4.50030311e-05
Iter: 1531 loss: 4.50028238e-05
Iter: 1532 loss: 4.50024745e-05
Iter: 1533 loss: 4.50023726e-05
Iter: 1534 loss: 4.50017978e-05
Iter: 1535 loss: 4.50026819e-05
Iter: 1536 loss: 4.50016596e-05
Iter: 1537 loss: 4.50010884e-05
Iter: 1538 loss: 4.50028892e-05
Iter: 1539 loss: 4.50010339e-05
Iter: 1540 loss: 4.500059e-05
Iter: 1541 loss: 4.50012376e-05
Iter: 1542 loss: 4.50003135e-05
Iter: 1543 loss: 4.49998224e-05
Iter: 1544 loss: 4.50018779e-05
Iter: 1545 loss: 4.49996e-05
Iter: 1546 loss: 4.49991967e-05
Iter: 1547 loss: 4.49993313e-05
Iter: 1548 loss: 4.49988365e-05
Iter: 1549 loss: 4.4998149e-05
Iter: 1550 loss: 4.50021435e-05
Iter: 1551 loss: 4.49981162e-05
Iter: 1552 loss: 4.49976724e-05
Iter: 1553 loss: 4.49980726e-05
Iter: 1554 loss: 4.49973486e-05
Iter: 1555 loss: 4.4996752e-05
Iter: 1556 loss: 4.49977451e-05
Iter: 1557 loss: 4.49965701e-05
Iter: 1558 loss: 4.49958497e-05
Iter: 1559 loss: 4.4999324e-05
Iter: 1560 loss: 4.49958025e-05
Iter: 1561 loss: 4.49955733e-05
Iter: 1562 loss: 4.49955696e-05
Iter: 1563 loss: 4.49952859e-05
Iter: 1564 loss: 4.49949584e-05
Iter: 1565 loss: 4.49950239e-05
Iter: 1566 loss: 4.49946456e-05
Iter: 1567 loss: 4.49943764e-05
Iter: 1568 loss: 4.49943327e-05
Iter: 1569 loss: 4.49936779e-05
Iter: 1570 loss: 4.49956824e-05
Iter: 1571 loss: 4.49935833e-05
Iter: 1572 loss: 4.49930631e-05
Iter: 1573 loss: 4.49948129e-05
Iter: 1574 loss: 4.49929139e-05
Iter: 1575 loss: 4.49924046e-05
Iter: 1576 loss: 4.49931249e-05
Iter: 1577 loss: 4.49920844e-05
Iter: 1578 loss: 4.4991677e-05
Iter: 1579 loss: 4.49933868e-05
Iter: 1580 loss: 4.49915897e-05
Iter: 1581 loss: 4.49910076e-05
Iter: 1582 loss: 4.49920663e-05
Iter: 1583 loss: 4.49909894e-05
Iter: 1584 loss: 4.49903528e-05
Iter: 1585 loss: 4.49919098e-05
Iter: 1586 loss: 4.49903018e-05
Iter: 1587 loss: 4.4989607e-05
Iter: 1588 loss: 4.49909e-05
Iter: 1589 loss: 4.49893632e-05
Iter: 1590 loss: 4.49888867e-05
Iter: 1591 loss: 4.49898507e-05
Iter: 1592 loss: 4.4988672e-05
Iter: 1593 loss: 4.4988421e-05
Iter: 1594 loss: 4.49884683e-05
Iter: 1595 loss: 4.49880717e-05
Iter: 1596 loss: 4.49887302e-05
Iter: 1597 loss: 4.49880317e-05
Iter: 1598 loss: 4.49877189e-05
Iter: 1599 loss: 4.49872641e-05
Iter: 1600 loss: 4.49943655e-05
Iter: 1601 loss: 4.49872459e-05
Iter: 1602 loss: 4.49868312e-05
Iter: 1603 loss: 4.49890358e-05
Iter: 1604 loss: 4.49866857e-05
Iter: 1605 loss: 4.49863e-05
Iter: 1606 loss: 4.4987064e-05
Iter: 1607 loss: 4.49861654e-05
Iter: 1608 loss: 4.49856889e-05
Iter: 1609 loss: 4.4987868e-05
Iter: 1610 loss: 4.49856816e-05
Iter: 1611 loss: 4.49852305e-05
Iter: 1612 loss: 4.49851505e-05
Iter: 1613 loss: 4.49848376e-05
Iter: 1614 loss: 4.49844192e-05
Iter: 1615 loss: 4.49864601e-05
Iter: 1616 loss: 4.49843355e-05
Iter: 1617 loss: 4.49838262e-05
Iter: 1618 loss: 4.49852887e-05
Iter: 1619 loss: 4.49836953e-05
Iter: 1620 loss: 4.4983306e-05
Iter: 1621 loss: 4.49836225e-05
Iter: 1622 loss: 4.49830259e-05
Iter: 1623 loss: 4.49825748e-05
Iter: 1624 loss: 4.49834697e-05
Iter: 1625 loss: 4.49823929e-05
Iter: 1626 loss: 4.49821346e-05
Iter: 1627 loss: 4.49821127e-05
Iter: 1628 loss: 4.49818326e-05
Iter: 1629 loss: 4.49828149e-05
Iter: 1630 loss: 4.49818617e-05
Iter: 1631 loss: 4.49815852e-05
Iter: 1632 loss: 4.49813197e-05
Iter: 1633 loss: 4.49813e-05
Iter: 1634 loss: 4.49808722e-05
Iter: 1635 loss: 4.49811669e-05
Iter: 1636 loss: 4.4980683e-05
Iter: 1637 loss: 4.4980181e-05
Iter: 1638 loss: 4.49826257e-05
Iter: 1639 loss: 4.49802392e-05
Iter: 1640 loss: 4.49798827e-05
Iter: 1641 loss: 4.49806976e-05
Iter: 1642 loss: 4.49796644e-05
Iter: 1643 loss: 4.49793151e-05
Iter: 1644 loss: 4.49803156e-05
Iter: 1645 loss: 4.49791514e-05
Iter: 1646 loss: 4.49788531e-05
Iter: 1647 loss: 4.49791369e-05
Iter: 1648 loss: 4.49787331e-05
Iter: 1649 loss: 4.49781692e-05
Iter: 1650 loss: 4.49796571e-05
Iter: 1651 loss: 4.49778963e-05
Iter: 1652 loss: 4.49775762e-05
Iter: 1653 loss: 4.49790386e-05
Iter: 1654 loss: 4.4977518e-05
Iter: 1655 loss: 4.49770814e-05
Iter: 1656 loss: 4.49774e-05
Iter: 1657 loss: 4.49768413e-05
Iter: 1658 loss: 4.49763647e-05
Iter: 1659 loss: 4.49797699e-05
Iter: 1660 loss: 4.49764e-05
Iter: 1661 loss: 4.49761574e-05
Iter: 1662 loss: 4.49762665e-05
Iter: 1663 loss: 4.497603e-05
Iter: 1664 loss: 4.49757e-05
Iter: 1665 loss: 4.49815379e-05
Iter: 1666 loss: 4.49757208e-05
Iter: 1667 loss: 4.49755244e-05
Iter: 1668 loss: 4.49755025e-05
Iter: 1669 loss: 4.49752406e-05
Iter: 1670 loss: 4.49748477e-05
Iter: 1671 loss: 4.49762738e-05
Iter: 1672 loss: 4.49746731e-05
Iter: 1673 loss: 4.49744111e-05
Iter: 1674 loss: 4.49755862e-05
Iter: 1675 loss: 4.49743602e-05
Iter: 1676 loss: 4.49739018e-05
Iter: 1677 loss: 4.49744693e-05
Iter: 1678 loss: 4.49737854e-05
Iter: 1679 loss: 4.49733852e-05
Iter: 1680 loss: 4.49745567e-05
Iter: 1681 loss: 4.49732761e-05
Iter: 1682 loss: 4.49729632e-05
Iter: 1683 loss: 4.4973418e-05
Iter: 1684 loss: 4.49726867e-05
Iter: 1685 loss: 4.49722793e-05
Iter: 1686 loss: 4.49742765e-05
Iter: 1687 loss: 4.49721556e-05
Iter: 1688 loss: 4.49718427e-05
Iter: 1689 loss: 4.49718282e-05
Iter: 1690 loss: 4.49714571e-05
Iter: 1691 loss: 4.49711042e-05
Iter: 1692 loss: 4.49711e-05
Iter: 1693 loss: 4.49709769e-05
Iter: 1694 loss: 4.49733234e-05
Iter: 1695 loss: 4.49709623e-05
Iter: 1696 loss: 4.49705913e-05
Iter: 1697 loss: 4.49706713e-05
Iter: 1698 loss: 4.49706276e-05
Iter: 1699 loss: 4.49703075e-05
Iter: 1700 loss: 4.49700892e-05
Iter: 1701 loss: 4.4970122e-05
Iter: 1702 loss: 4.49697072e-05
Iter: 1703 loss: 4.49707259e-05
Iter: 1704 loss: 4.4969529e-05
Iter: 1705 loss: 4.49693325e-05
Iter: 1706 loss: 4.49703693e-05
Iter: 1707 loss: 4.4969318e-05
Iter: 1708 loss: 4.49687977e-05
Iter: 1709 loss: 4.49694453e-05
Iter: 1710 loss: 4.49686195e-05
Iter: 1711 loss: 4.49682702e-05
Iter: 1712 loss: 4.49691761e-05
Iter: 1713 loss: 4.49682266e-05
Iter: 1714 loss: 4.496779e-05
Iter: 1715 loss: 4.49686559e-05
Iter: 1716 loss: 4.49676481e-05
Iter: 1717 loss: 4.49674335e-05
Iter: 1718 loss: 4.49686413e-05
Iter: 1719 loss: 4.49672298e-05
Iter: 1720 loss: 4.49669024e-05
Iter: 1721 loss: 4.49670661e-05
Iter: 1722 loss: 4.49666768e-05
Iter: 1723 loss: 4.49663858e-05
Iter: 1724 loss: 4.49679683e-05
Iter: 1725 loss: 4.4966313e-05
Iter: 1726 loss: 4.4966102e-05
Iter: 1727 loss: 4.49660947e-05
Iter: 1728 loss: 4.49657709e-05
Iter: 1729 loss: 4.49665313e-05
Iter: 1730 loss: 4.49656363e-05
Iter: 1731 loss: 4.49656363e-05
Iter: 1732 loss: 4.49652871e-05
Iter: 1733 loss: 4.49653671e-05
Iter: 1734 loss: 4.4965047e-05
Iter: 1735 loss: 4.49660365e-05
Iter: 1736 loss: 4.49648214e-05
Iter: 1737 loss: 4.49645631e-05
Iter: 1738 loss: 4.49649524e-05
Iter: 1739 loss: 4.4964534e-05
Iter: 1740 loss: 4.49641047e-05
Iter: 1741 loss: 4.49658583e-05
Iter: 1742 loss: 4.4963992e-05
Iter: 1743 loss: 4.49637591e-05
Iter: 1744 loss: 4.49644103e-05
Iter: 1745 loss: 4.49635481e-05
Iter: 1746 loss: 4.49633226e-05
Iter: 1747 loss: 4.49642394e-05
Iter: 1748 loss: 4.49632207e-05
Iter: 1749 loss: 4.49628933e-05
Iter: 1750 loss: 4.49632062e-05
Iter: 1751 loss: 4.49627405e-05
Iter: 1752 loss: 4.4962344e-05
Iter: 1753 loss: 4.49640975e-05
Iter: 1754 loss: 4.49623658e-05
Iter: 1755 loss: 4.49619329e-05
Iter: 1756 loss: 4.49628205e-05
Iter: 1757 loss: 4.49618237e-05
Iter: 1758 loss: 4.496162e-05
Iter: 1759 loss: 4.49616e-05
Iter: 1760 loss: 4.49614163e-05
Iter: 1761 loss: 4.49632171e-05
Iter: 1762 loss: 4.49615072e-05
Iter: 1763 loss: 4.49612889e-05
Iter: 1764 loss: 4.49610307e-05
Iter: 1765 loss: 4.49642175e-05
Iter: 1766 loss: 4.49609797e-05
Iter: 1767 loss: 4.49607469e-05
Iter: 1768 loss: 4.49616637e-05
Iter: 1769 loss: 4.49606778e-05
Iter: 1770 loss: 4.49603358e-05
Iter: 1771 loss: 4.49608706e-05
Iter: 1772 loss: 4.49603067e-05
Iter: 1773 loss: 4.49599e-05
Iter: 1774 loss: 4.49617e-05
Iter: 1775 loss: 4.49598883e-05
Iter: 1776 loss: 4.49596664e-05
Iter: 1777 loss: 4.4959932e-05
Iter: 1778 loss: 4.49595682e-05
Iter: 1779 loss: 4.49592881e-05
Iter: 1780 loss: 4.49604049e-05
Iter: 1781 loss: 4.49591898e-05
Iter: 1782 loss: 4.49589716e-05
Iter: 1783 loss: 4.49592662e-05
Iter: 1784 loss: 4.49587678e-05
Iter: 1785 loss: 4.49585204e-05
Iter: 1786 loss: 4.49592117e-05
Iter: 1787 loss: 4.49583822e-05
Iter: 1788 loss: 4.49580257e-05
Iter: 1789 loss: 4.49588042e-05
Iter: 1790 loss: 4.4958033e-05
Iter: 1791 loss: 4.49576255e-05
Iter: 1792 loss: 4.49600557e-05
Iter: 1793 loss: 4.49577055e-05
Iter: 1794 loss: 4.49574618e-05
Iter: 1795 loss: 4.49573672e-05
Iter: 1796 loss: 4.49573199e-05
Iter: 1797 loss: 4.49570725e-05
Iter: 1798 loss: 4.49605359e-05
Iter: 1799 loss: 4.49572108e-05
Iter: 1800 loss: 4.49569125e-05
Iter: 1801 loss: 4.4957058e-05
Iter: 1802 loss: 4.49568106e-05
Iter: 1803 loss: 4.49563886e-05
Iter: 1804 loss: 4.49576728e-05
Iter: 1805 loss: 4.49563231e-05
Iter: 1806 loss: 4.49561594e-05
Iter: 1807 loss: 4.49566396e-05
Iter: 1808 loss: 4.49560248e-05
Iter: 1809 loss: 4.4955741e-05
Iter: 1810 loss: 4.49569307e-05
Iter: 1811 loss: 4.49557556e-05
Iter: 1812 loss: 4.49554973e-05
Iter: 1813 loss: 4.49555737e-05
Iter: 1814 loss: 4.49552463e-05
Iter: 1815 loss: 4.49549807e-05
Iter: 1816 loss: 4.49568724e-05
Iter: 1817 loss: 4.49550134e-05
Iter: 1818 loss: 4.49547297e-05
Iter: 1819 loss: 4.49547369e-05
Iter: 1820 loss: 4.49545769e-05
Iter: 1821 loss: 4.4954184e-05
Iter: 1822 loss: 4.49559e-05
Iter: 1823 loss: 4.49541512e-05
Iter: 1824 loss: 4.49538275e-05
Iter: 1825 loss: 4.49542822e-05
Iter: 1826 loss: 4.4953762e-05
Iter: 1827 loss: 4.49537329e-05
Iter: 1828 loss: 4.49536383e-05
Iter: 1829 loss: 4.49534418e-05
Iter: 1830 loss: 4.49532672e-05
Iter: 1831 loss: 4.49576546e-05
Iter: 1832 loss: 4.49532599e-05
Iter: 1833 loss: 4.49530526e-05
Iter: 1834 loss: 4.49530198e-05
Iter: 1835 loss: 4.49527688e-05
Iter: 1836 loss: 4.49525905e-05
Iter: 1837 loss: 4.49540421e-05
Iter: 1838 loss: 4.49524887e-05
Iter: 1839 loss: 4.49522e-05
Iter: 1840 loss: 4.4953129e-05
Iter: 1841 loss: 4.49521503e-05
Iter: 1842 loss: 4.49518338e-05
Iter: 1843 loss: 4.49523977e-05
Iter: 1844 loss: 4.49517174e-05
Iter: 1845 loss: 4.49514955e-05
Iter: 1846 loss: 4.49522195e-05
Iter: 1847 loss: 4.49513864e-05
Iter: 1848 loss: 4.49511936e-05
Iter: 1849 loss: 4.49523322e-05
Iter: 1850 loss: 4.49511135e-05
Iter: 1851 loss: 4.49508225e-05
Iter: 1852 loss: 4.49510444e-05
Iter: 1853 loss: 4.49507279e-05
Iter: 1854 loss: 4.49504223e-05
Iter: 1855 loss: 4.49512299e-05
Iter: 1856 loss: 4.49503277e-05
Iter: 1857 loss: 4.49501094e-05
Iter: 1858 loss: 4.49513282e-05
Iter: 1859 loss: 4.49500585e-05
Iter: 1860 loss: 4.49497966e-05
Iter: 1861 loss: 4.49498075e-05
Iter: 1862 loss: 4.49496802e-05
Iter: 1863 loss: 4.49495492e-05
Iter: 1864 loss: 4.49495055e-05
Iter: 1865 loss: 4.49494109e-05
Iter: 1866 loss: 4.49491781e-05
Iter: 1867 loss: 4.49491672e-05
Iter: 1868 loss: 4.49488725e-05
Iter: 1869 loss: 4.49494073e-05
Iter: 1870 loss: 4.49487161e-05
Iter: 1871 loss: 4.49484942e-05
Iter: 1872 loss: 4.4950546e-05
Iter: 1873 loss: 4.49484651e-05
Iter: 1874 loss: 4.49482322e-05
Iter: 1875 loss: 4.49483487e-05
Iter: 1876 loss: 4.4948174e-05
Iter: 1877 loss: 4.49478648e-05
Iter: 1878 loss: 4.49491927e-05
Iter: 1879 loss: 4.49478903e-05
Iter: 1880 loss: 4.49476283e-05
Iter: 1881 loss: 4.49478648e-05
Iter: 1882 loss: 4.49475665e-05
Iter: 1883 loss: 4.49472573e-05
Iter: 1884 loss: 4.4948014e-05
Iter: 1885 loss: 4.49472027e-05
Iter: 1886 loss: 4.49469298e-05
Iter: 1887 loss: 4.49474865e-05
Iter: 1888 loss: 4.49469371e-05
Iter: 1889 loss: 4.49466461e-05
Iter: 1890 loss: 4.49472209e-05
Iter: 1891 loss: 4.49466497e-05
Iter: 1892 loss: 4.49463587e-05
Iter: 1893 loss: 4.49485851e-05
Iter: 1894 loss: 4.49464205e-05
Iter: 1895 loss: 4.49461768e-05
Iter: 1896 loss: 4.49477229e-05
Iter: 1897 loss: 4.49461259e-05
Iter: 1898 loss: 4.49461077e-05
Iter: 1899 loss: 4.49458857e-05
Iter: 1900 loss: 4.49481377e-05
Iter: 1901 loss: 4.49458748e-05
Iter: 1902 loss: 4.49456747e-05
Iter: 1903 loss: 4.49466897e-05
Iter: 1904 loss: 4.49456347e-05
Iter: 1905 loss: 4.49454e-05
Iter: 1906 loss: 4.4946064e-05
Iter: 1907 loss: 4.49453582e-05
Iter: 1908 loss: 4.49451763e-05
Iter: 1909 loss: 4.49455692e-05
Iter: 1910 loss: 4.49450745e-05
Iter: 1911 loss: 4.49447834e-05
Iter: 1912 loss: 4.49456857e-05
Iter: 1913 loss: 4.49448489e-05
Iter: 1914 loss: 4.49446379e-05
Iter: 1915 loss: 4.49452491e-05
Iter: 1916 loss: 4.49445943e-05
Iter: 1917 loss: 4.49444633e-05
Iter: 1918 loss: 4.49446052e-05
Iter: 1919 loss: 4.49442887e-05
Iter: 1920 loss: 4.49440777e-05
Iter: 1921 loss: 4.49448853e-05
Iter: 1922 loss: 4.49440777e-05
Iter: 1923 loss: 4.4943863e-05
Iter: 1924 loss: 4.49442414e-05
Iter: 1925 loss: 4.49437e-05
Iter: 1926 loss: 4.49434738e-05
Iter: 1927 loss: 4.49445251e-05
Iter: 1928 loss: 4.49435902e-05
Iter: 1929 loss: 4.4943492e-05
Iter: 1930 loss: 4.49434e-05
Iter: 1931 loss: 4.49433028e-05
Iter: 1932 loss: 4.49430663e-05
Iter: 1933 loss: 4.49453291e-05
Iter: 1934 loss: 4.4943059e-05
Iter: 1935 loss: 4.49428408e-05
Iter: 1936 loss: 4.49430299e-05
Iter: 1937 loss: 4.49429e-05
Iter: 1938 loss: 4.49425679e-05
Iter: 1939 loss: 4.4943532e-05
Iter: 1940 loss: 4.4942637e-05
Iter: 1941 loss: 4.49424624e-05
Iter: 1942 loss: 4.49425e-05
Iter: 1943 loss: 4.49422805e-05
Iter: 1944 loss: 4.49420404e-05
Iter: 1945 loss: 4.49433428e-05
Iter: 1946 loss: 4.49421e-05
Iter: 1947 loss: 4.49418585e-05
Iter: 1948 loss: 4.49422369e-05
Iter: 1949 loss: 4.49417203e-05
Iter: 1950 loss: 4.4941582e-05
Iter: 1951 loss: 4.4942266e-05
Iter: 1952 loss: 4.49414874e-05
Iter: 1953 loss: 4.4941371e-05
Iter: 1954 loss: 4.49414656e-05
Iter: 1955 loss: 4.49412546e-05
Iter: 1956 loss: 4.494108e-05
Iter: 1957 loss: 4.49422078e-05
Iter: 1958 loss: 4.49409563e-05
Iter: 1959 loss: 4.49407598e-05
Iter: 1960 loss: 4.49409599e-05
Iter: 1961 loss: 4.49407235e-05
Iter: 1962 loss: 4.49406834e-05
Iter: 1963 loss: 4.49406216e-05
Iter: 1964 loss: 4.49405125e-05
Iter: 1965 loss: 4.49404179e-05
Iter: 1966 loss: 4.49403888e-05
Iter: 1967 loss: 4.49402869e-05
Iter: 1968 loss: 4.49402651e-05
Iter: 1969 loss: 4.49401341e-05
Iter: 1970 loss: 4.49399085e-05
Iter: 1971 loss: 4.494116e-05
Iter: 1972 loss: 4.49399777e-05
Iter: 1973 loss: 4.49398722e-05
Iter: 1974 loss: 4.49398358e-05
Iter: 1975 loss: 4.49397558e-05
Iter: 1976 loss: 4.49393956e-05
Iter: 1977 loss: 4.49398904e-05
Iter: 1978 loss: 4.49394465e-05
Iter: 1979 loss: 4.4939221e-05
Iter: 1980 loss: 4.49402432e-05
Iter: 1981 loss: 4.49392101e-05
Iter: 1982 loss: 4.49390282e-05
Iter: 1983 loss: 4.49396975e-05
Iter: 1984 loss: 4.49389627e-05
Iter: 1985 loss: 4.4938839e-05
Iter: 1986 loss: 4.49389117e-05
Iter: 1987 loss: 4.49387226e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2
+ date
Tue Oct 27 18:58:46 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6c4a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00fb647730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00fb66db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6c00ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6b5d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6b5da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6b3bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6ae47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6af6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6ae4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6a729d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6a157b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6a15268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d69d3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d69d3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d69d3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d69d3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d69e0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d691c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6951ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d69387b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d68f4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d68a7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d68a7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d68bc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d68641e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d683e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d67eb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d67eb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d67eb158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d67ca840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d67ca378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d6770950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d677bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d673f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00d673f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0600567423
Iter: 2 loss: 785.447754
Iter: 3 loss: 0.0600564368
Iter: 4 loss: 1798.63477
Iter: 5 loss: 1269.99597
Iter: 6 loss: 0.0600560568
Iter: 7 loss: 1139.72107
Iter: 8 loss: 0.060056
Iter: 9 loss: 0.0640450716
Iter: 10 loss: 0.057288602
Iter: 11 loss: 0.0484403893
Iter: 12 loss: 0.0479464158
Iter: 13 loss: 2493.14136
Iter: 14 loss: 0.0522215962
Iter: 15 loss: 0.0462833904
Iter: 16 loss: 0.0390164517
Iter: 17 loss: 0.0389969349
Iter: 18 loss: 0.0349222645
Iter: 19 loss: 0.0345884115
Iter: 20 loss: 0.0278696269
Iter: 21 loss: 0.0446068272
Iter: 22 loss: 0.0269183908
Iter: 23 loss: 0.0257787667
Iter: 24 loss: 0.023654893
Iter: 25 loss: 0.0550616644
Iter: 26 loss: 0.0236136131
Iter: 27 loss: 0.0222439207
Iter: 28 loss: 0.0466420427
Iter: 29 loss: 0.0221793503
Iter: 30 loss: 0.020069778
Iter: 31 loss: 0.10050562
Iter: 32 loss: 0.0200405791
Iter: 33 loss: 0.0185236745
Iter: 34 loss: 1.32181633
Iter: 35 loss: 0.0260774642
Iter: 36 loss: 0.0191147309
Iter: 37 loss: 0.0174791347
Iter: 38 loss: 0.202977851
Iter: 39 loss: 0.0174779873
Iter: 40 loss: 0.0163708664
Iter: 41 loss: 0.0206922591
Iter: 42 loss: 0.0161823053
Iter: 43 loss: 0.0153008839
Iter: 44 loss: 0.0147084603
Iter: 45 loss: 0.0142650148
Iter: 46 loss: 0.0133264353
Iter: 47 loss: 0.0252808277
Iter: 48 loss: 0.0132909026
Iter: 49 loss: 0.0122281481
Iter: 50 loss: 0.0940545723
Iter: 51 loss: 0.0122140273
Iter: 52 loss: 0.011129803
Iter: 53 loss: 0.0925142318
Iter: 54 loss: 0.0111298086
Iter: 55 loss: 0.0104900356
Iter: 56 loss: 0.0104330275
Iter: 57 loss: 0.0100636845
Iter: 58 loss: 0.0138727734
Iter: 59 loss: 0.0100225052
Iter: 60 loss: 0.00970626809
Iter: 61 loss: 0.0115257222
Iter: 62 loss: 0.00966254063
Iter: 63 loss: 0.00916810706
Iter: 64 loss: 0.0109630013
Iter: 65 loss: 0.0090115685
Iter: 66 loss: 0.00856099464
Iter: 67 loss: 0.0103629455
Iter: 68 loss: 0.00847447477
Iter: 69 loss: 0.00822644
Iter: 70 loss: 0.00856888667
Iter: 71 loss: 0.00808151
Iter: 72 loss: 0.00788058899
Iter: 73 loss: 0.00806500576
Iter: 74 loss: 0.00776950456
Iter: 75 loss: 0.00750446739
Iter: 76 loss: 0.00802500267
Iter: 77 loss: 0.00738931354
Iter: 78 loss: 0.00709395297
Iter: 79 loss: 0.00836168323
Iter: 80 loss: 0.00701234816
Iter: 81 loss: 0.00656297477
Iter: 82 loss: 0.0122151449
Iter: 83 loss: 0.00655743945
Iter: 84 loss: 0.00622607488
Iter: 85 loss: 0.00695000077
Iter: 86 loss: 0.00606536865
Iter: 87 loss: 0.00591283478
Iter: 88 loss: 0.00633949414
Iter: 89 loss: 0.00585641526
Iter: 90 loss: 0.00560595887
Iter: 91 loss: 0.00596165285
Iter: 92 loss: 0.0054865852
Iter: 93 loss: 0.00526223751
Iter: 94 loss: 0.00679370575
Iter: 95 loss: 0.00522969943
Iter: 96 loss: 0.00496810768
Iter: 97 loss: 0.00540000759
Iter: 98 loss: 0.00484896079
Iter: 99 loss: 0.00459056627
Iter: 100 loss: 0.00697054574
Iter: 101 loss: 0.0045697405
Iter: 102 loss: 0.0043925466
Iter: 103 loss: 0.00656308653
Iter: 104 loss: 0.00439210283
Iter: 105 loss: 0.00428768434
Iter: 106 loss: 0.00482077152
Iter: 107 loss: 0.00426459406
Iter: 108 loss: 0.00417801
Iter: 109 loss: 0.00411605649
Iter: 110 loss: 0.00408552494
Iter: 111 loss: 0.0039248364
Iter: 112 loss: 0.00462955842
Iter: 113 loss: 0.00389561313
Iter: 114 loss: 0.00382938189
Iter: 115 loss: 0.00372389657
Iter: 116 loss: 0.00372283091
Iter: 117 loss: 0.00358767
Iter: 118 loss: 0.00404959219
Iter: 119 loss: 0.00355126359
Iter: 120 loss: 0.00342729362
Iter: 121 loss: 0.00382132828
Iter: 122 loss: 0.00339008356
Iter: 123 loss: 0.00327708316
Iter: 124 loss: 0.00354586076
Iter: 125 loss: 0.00323112984
Iter: 126 loss: 0.00315445638
Iter: 127 loss: 0.00330261094
Iter: 128 loss: 0.00312357582
Iter: 129 loss: 0.00306103704
Iter: 130 loss: 0.00305782771
Iter: 131 loss: 0.00300911954
Iter: 132 loss: 0.00291090412
Iter: 133 loss: 0.00347670866
Iter: 134 loss: 0.00289950334
Iter: 135 loss: 0.00282054022
Iter: 136 loss: 0.00342891552
Iter: 137 loss: 0.00281210383
Iter: 138 loss: 0.00276587717
Iter: 139 loss: 0.00312857796
Iter: 140 loss: 0.0027640583
Iter: 141 loss: 0.00272127776
Iter: 142 loss: 0.00269276882
Iter: 143 loss: 0.00267604552
Iter: 144 loss: 0.00261917477
Iter: 145 loss: 0.00267231488
Iter: 146 loss: 0.00258713984
Iter: 147 loss: 0.00253318716
Iter: 148 loss: 0.00300523173
Iter: 149 loss: 0.00253110984
Iter: 150 loss: 0.00247718161
Iter: 151 loss: 0.00253374572
Iter: 152 loss: 0.0024460468
Iter: 153 loss: 0.00241472246
Iter: 154 loss: 0.00236469
Iter: 155 loss: 0.00236429088
Iter: 156 loss: 0.00227883388
Iter: 157 loss: 0.00267161895
Iter: 158 loss: 0.00226214
Iter: 159 loss: 0.00219291775
Iter: 160 loss: 0.00235780748
Iter: 161 loss: 0.00216608215
Iter: 162 loss: 0.0021062179
Iter: 163 loss: 0.00280866539
Iter: 164 loss: 0.002104518
Iter: 165 loss: 0.00206023362
Iter: 166 loss: 0.00224691443
Iter: 167 loss: 0.00205025077
Iter: 168 loss: 0.0020138477
Iter: 169 loss: 0.00262719812
Iter: 170 loss: 0.00201383047
Iter: 171 loss: 0.00198478531
Iter: 172 loss: 0.00229157321
Iter: 173 loss: 0.00198446168
Iter: 174 loss: 0.00196957542
Iter: 175 loss: 0.00196246454
Iter: 176 loss: 0.00195505586
Iter: 177 loss: 0.00192731153
Iter: 178 loss: 0.00192602
Iter: 179 loss: 0.00190471765
Iter: 180 loss: 0.00185506791
Iter: 181 loss: 0.00199880102
Iter: 182 loss: 0.00183899596
Iter: 183 loss: 0.0018139414
Iter: 184 loss: 0.00181122194
Iter: 185 loss: 0.00177895755
Iter: 186 loss: 0.00176496909
Iter: 187 loss: 0.00174822845
Iter: 188 loss: 0.00172067538
Iter: 189 loss: 0.00169875415
Iter: 190 loss: 0.00169022882
Iter: 191 loss: 0.0016465747
Iter: 192 loss: 0.001959007
Iter: 193 loss: 0.00164238946
Iter: 194 loss: 0.0016089665
Iter: 195 loss: 0.00185853941
Iter: 196 loss: 0.0016062113
Iter: 197 loss: 0.00157657359
Iter: 198 loss: 0.00159590249
Iter: 199 loss: 0.00155771594
Iter: 200 loss: 0.00153024634
Iter: 201 loss: 0.00162202946
Iter: 202 loss: 0.00152296782
Iter: 203 loss: 0.00149382325
Iter: 204 loss: 0.00151373539
Iter: 205 loss: 0.00147520192
Iter: 206 loss: 0.00146818976
Iter: 207 loss: 0.00146070344
Iter: 208 loss: 0.00144310773
Iter: 209 loss: 0.00145207648
Iter: 210 loss: 0.00143099553
Iter: 211 loss: 0.00141979649
Iter: 212 loss: 0.00141472649
Iter: 213 loss: 0.00140911527
Iter: 214 loss: 0.0013917411
Iter: 215 loss: 0.00140744611
Iter: 216 loss: 0.0013815714
Iter: 217 loss: 0.00136293354
Iter: 218 loss: 0.00149222952
Iter: 219 loss: 0.00136131083
Iter: 220 loss: 0.00134083908
Iter: 221 loss: 0.0013639743
Iter: 222 loss: 0.0013294341
Iter: 223 loss: 0.00130391307
Iter: 224 loss: 0.00132657541
Iter: 225 loss: 0.00128894183
Iter: 226 loss: 0.00126349553
Iter: 227 loss: 0.00142243586
Iter: 228 loss: 0.00126066757
Iter: 229 loss: 0.00123968779
Iter: 230 loss: 0.00129102892
Iter: 231 loss: 0.00123213534
Iter: 232 loss: 0.00121246243
Iter: 233 loss: 0.00130935828
Iter: 234 loss: 0.00120914401
Iter: 235 loss: 0.00119148451
Iter: 236 loss: 0.00119765266
Iter: 237 loss: 0.00117915147
Iter: 238 loss: 0.00116455625
Iter: 239 loss: 0.00116432202
Iter: 240 loss: 0.001154506
Iter: 241 loss: 0.00124795269
Iter: 242 loss: 0.00115425396
Iter: 243 loss: 0.00114844786
Iter: 244 loss: 0.00114043523
Iter: 245 loss: 0.00114005152
Iter: 246 loss: 0.00113130431
Iter: 247 loss: 0.00111627346
Iter: 248 loss: 0.00111626182
Iter: 249 loss: 0.00110329897
Iter: 250 loss: 0.0012020797
Iter: 251 loss: 0.00110218697
Iter: 252 loss: 0.00108987256
Iter: 253 loss: 0.00111293711
Iter: 254 loss: 0.00108467462
Iter: 255 loss: 0.00107218465
Iter: 256 loss: 0.00109170796
Iter: 257 loss: 0.00106630893
Iter: 258 loss: 0.00105277589
Iter: 259 loss: 0.0010400808
Iter: 260 loss: 0.00103693164
Iter: 261 loss: 0.00101784873
Iter: 262 loss: 0.00112685631
Iter: 263 loss: 0.00101500715
Iter: 264 loss: 0.00100153976
Iter: 265 loss: 0.00101271668
Iter: 266 loss: 0.000993291382
Iter: 267 loss: 0.000982457306
Iter: 268 loss: 0.000980307814
Iter: 269 loss: 0.000973205722
Iter: 270 loss: 0.000965641229
Iter: 271 loss: 0.000955463271
Iter: 272 loss: 0.000954880263
Iter: 273 loss: 0.000944486703
Iter: 274 loss: 0.000986931
Iter: 275 loss: 0.000942358049
Iter: 276 loss: 0.000933331903
Iter: 277 loss: 0.000981889898
Iter: 278 loss: 0.000931873
Iter: 279 loss: 0.00092249515
Iter: 280 loss: 0.000936744735
Iter: 281 loss: 0.000918129808
Iter: 282 loss: 0.00090779108
Iter: 283 loss: 0.000994731672
Iter: 284 loss: 0.000907072215
Iter: 285 loss: 0.000900328218
Iter: 286 loss: 0.000894157274
Iter: 287 loss: 0.000892523734
Iter: 288 loss: 0.000879447965
Iter: 289 loss: 0.000893070421
Iter: 290 loss: 0.000872136792
Iter: 291 loss: 0.000859589898
Iter: 292 loss: 0.000903053209
Iter: 293 loss: 0.000856181374
Iter: 294 loss: 0.000842848734
Iter: 295 loss: 0.000858675048
Iter: 296 loss: 0.000835707062
Iter: 297 loss: 0.00082125864
Iter: 298 loss: 0.000843247573
Iter: 299 loss: 0.000814256317
Iter: 300 loss: 0.000801713788
Iter: 301 loss: 0.000974098453
Iter: 302 loss: 0.000801581657
Iter: 303 loss: 0.000793579617
Iter: 304 loss: 0.000902105705
Iter: 305 loss: 0.000793571409
Iter: 306 loss: 0.000786939578
Iter: 307 loss: 0.000792538
Iter: 308 loss: 0.000782919058
Iter: 309 loss: 0.000776145433
Iter: 310 loss: 0.000785510521
Iter: 311 loss: 0.000772869913
Iter: 312 loss: 0.000763445743
Iter: 313 loss: 0.000787668861
Iter: 314 loss: 0.000760116382
Iter: 315 loss: 0.00075230957
Iter: 316 loss: 0.000805717311
Iter: 317 loss: 0.000751665153
Iter: 318 loss: 0.000745882513
Iter: 319 loss: 0.000737937284
Iter: 320 loss: 0.000737554161
Iter: 321 loss: 0.000728649087
Iter: 322 loss: 0.000742887263
Iter: 323 loss: 0.000724538404
Iter: 324 loss: 0.00071690575
Iter: 325 loss: 0.000728392042
Iter: 326 loss: 0.000713199144
Iter: 327 loss: 0.000703019672
Iter: 328 loss: 0.000726291502
Iter: 329 loss: 0.000699133845
Iter: 330 loss: 0.000690174871
Iter: 331 loss: 0.000698353164
Iter: 332 loss: 0.000684931641
Iter: 333 loss: 0.000672469498
Iter: 334 loss: 0.000698699267
Iter: 335 loss: 0.000667542685
Iter: 336 loss: 0.000660499209
Iter: 337 loss: 0.000660242396
Iter: 338 loss: 0.000651912182
Iter: 339 loss: 0.000682257756
Iter: 340 loss: 0.000649939873
Iter: 341 loss: 0.000644103333
Iter: 342 loss: 0.000638447818
Iter: 343 loss: 0.000637160148
Iter: 344 loss: 0.000631286763
Iter: 345 loss: 0.000706318417
Iter: 346 loss: 0.000631256378
Iter: 347 loss: 0.000626083813
Iter: 348 loss: 0.00063407555
Iter: 349 loss: 0.000623584376
Iter: 350 loss: 0.000618278631
Iter: 351 loss: 0.000644700485
Iter: 352 loss: 0.000617397076
Iter: 353 loss: 0.000612986507
Iter: 354 loss: 0.000615709287
Iter: 355 loss: 0.000610138755
Iter: 356 loss: 0.000604401692
Iter: 357 loss: 0.000600318366
Iter: 358 loss: 0.00059828849
Iter: 359 loss: 0.000591587508
Iter: 360 loss: 0.000685340725
Iter: 361 loss: 0.000591567077
Iter: 362 loss: 0.000585465925
Iter: 363 loss: 0.000578939565
Iter: 364 loss: 0.000577869301
Iter: 365 loss: 0.0005702161
Iter: 366 loss: 0.000639115635
Iter: 367 loss: 0.000569816737
Iter: 368 loss: 0.000564352667
Iter: 369 loss: 0.000588960596
Iter: 370 loss: 0.000563237234
Iter: 371 loss: 0.000563334
Iter: 372 loss: 0.000560332846
Iter: 373 loss: 0.000557699241
Iter: 374 loss: 0.000553768303
Iter: 375 loss: 0.000553673832
Iter: 376 loss: 0.000549413264
Iter: 377 loss: 0.000549785385
Iter: 378 loss: 0.00054611417
Iter: 379 loss: 0.000540573441
Iter: 380 loss: 0.000549827528
Iter: 381 loss: 0.000538000604
Iter: 382 loss: 0.000533593877
Iter: 383 loss: 0.000549338583
Iter: 384 loss: 0.000532472
Iter: 385 loss: 0.000526506396
Iter: 386 loss: 0.000538731227
Iter: 387 loss: 0.000524072326
Iter: 388 loss: 0.000518223969
Iter: 389 loss: 0.000550547265
Iter: 390 loss: 0.000517404522
Iter: 391 loss: 0.00051280082
Iter: 392 loss: 0.000508745317
Iter: 393 loss: 0.000507519348
Iter: 394 loss: 0.000502106035
Iter: 395 loss: 0.000513938896
Iter: 396 loss: 0.000500001945
Iter: 397 loss: 0.000494800915
Iter: 398 loss: 0.000493106549
Iter: 399 loss: 0.000490054896
Iter: 400 loss: 0.000483673502
Iter: 401 loss: 0.000543551
Iter: 402 loss: 0.000483394659
Iter: 403 loss: 0.000477477966
Iter: 404 loss: 0.000491255254
Iter: 405 loss: 0.000475294946
Iter: 406 loss: 0.000481047144
Iter: 407 loss: 0.000473414606
Iter: 408 loss: 0.000472083455
Iter: 409 loss: 0.000469978317
Iter: 410 loss: 0.000469956954
Iter: 411 loss: 0.000466667436
Iter: 412 loss: 0.000474359753
Iter: 413 loss: 0.00046543224
Iter: 414 loss: 0.000462214084
Iter: 415 loss: 0.000474186119
Iter: 416 loss: 0.000461448042
Iter: 417 loss: 0.000459236675
Iter: 418 loss: 0.000460382667
Iter: 419 loss: 0.000457751245
Iter: 420 loss: 0.000455414411
Iter: 421 loss: 0.000456407201
Iter: 422 loss: 0.000453822518
Iter: 423 loss: 0.000451796048
Iter: 424 loss: 0.000461401651
Iter: 425 loss: 0.000451416912
Iter: 426 loss: 0.000449453364
Iter: 427 loss: 0.000444899342
Iter: 428 loss: 0.000501633447
Iter: 429 loss: 0.00044455225
Iter: 430 loss: 0.000440080126
Iter: 431 loss: 0.00047622202
Iter: 432 loss: 0.000439783034
Iter: 433 loss: 0.000436012109
Iter: 434 loss: 0.000435791735
Iter: 435 loss: 0.000432922214
Iter: 436 loss: 0.000429055188
Iter: 437 loss: 0.000434211921
Iter: 438 loss: 0.00042707476
Iter: 439 loss: 0.000424854865
Iter: 440 loss: 0.000444968464
Iter: 441 loss: 0.000424762547
Iter: 442 loss: 0.000422911718
Iter: 443 loss: 0.000421478238
Iter: 444 loss: 0.000420893
Iter: 445 loss: 0.000417656323
Iter: 446 loss: 0.000415477407
Iter: 447 loss: 0.000414283713
Iter: 448 loss: 0.000409401
Iter: 449 loss: 0.000436840171
Iter: 450 loss: 0.000408690888
Iter: 451 loss: 0.000404493127
Iter: 452 loss: 0.000416495692
Iter: 453 loss: 0.000403209124
Iter: 454 loss: 0.00039924751
Iter: 455 loss: 0.000442028861
Iter: 456 loss: 0.000399133714
Iter: 457 loss: 0.000396618387
Iter: 458 loss: 0.000395013834
Iter: 459 loss: 0.00039404424
Iter: 460 loss: 0.000390496803
Iter: 461 loss: 0.000396807445
Iter: 462 loss: 0.000388911
Iter: 463 loss: 0.000385408872
Iter: 464 loss: 0.000381836348
Iter: 465 loss: 0.000381151447
Iter: 466 loss: 0.000377694436
Iter: 467 loss: 0.000389740395
Iter: 468 loss: 0.000376783224
Iter: 469 loss: 0.00037318375
Iter: 470 loss: 0.000381187914
Iter: 471 loss: 0.000371789443
Iter: 472 loss: 0.000370406487
Iter: 473 loss: 0.000370075519
Iter: 474 loss: 0.000368039822
Iter: 475 loss: 0.000366642314
Iter: 476 loss: 0.000365893357
Iter: 477 loss: 0.000363325758
Iter: 478 loss: 0.000365450978
Iter: 479 loss: 0.000361795654
Iter: 480 loss: 0.000359425612
Iter: 481 loss: 0.000364170643
Iter: 482 loss: 0.000358453079
Iter: 483 loss: 0.000356222095
Iter: 484 loss: 0.000369256712
Iter: 485 loss: 0.000355936354
Iter: 486 loss: 0.000354590564
Iter: 487 loss: 0.000372290815
Iter: 488 loss: 0.000354581221
Iter: 489 loss: 0.000353634183
Iter: 490 loss: 0.000355195894
Iter: 491 loss: 0.000353204203
Iter: 492 loss: 0.000352003175
Iter: 493 loss: 0.000350486895
Iter: 494 loss: 0.00035036722
Iter: 495 loss: 0.000348240836
Iter: 496 loss: 0.000356426346
Iter: 497 loss: 0.000347739202
Iter: 498 loss: 0.000345893146
Iter: 499 loss: 0.000344799657
Iter: 500 loss: 0.000344024
Iter: 501 loss: 0.000341004052
Iter: 502 loss: 0.000346928486
Iter: 503 loss: 0.000339750666
Iter: 504 loss: 0.000336296856
Iter: 505 loss: 0.000341172039
Iter: 506 loss: 0.000334599579
Iter: 507 loss: 0.000338595943
Iter: 508 loss: 0.000333561562
Iter: 509 loss: 0.000332705502
Iter: 510 loss: 0.000330684416
Iter: 511 loss: 0.00035534802
Iter: 512 loss: 0.000330509502
Iter: 513 loss: 0.000329037313
Iter: 514 loss: 0.000330410287
Iter: 515 loss: 0.000328201946
Iter: 516 loss: 0.00032707944
Iter: 517 loss: 0.000325460162
Iter: 518 loss: 0.000325408648
Iter: 519 loss: 0.000323458633
Iter: 520 loss: 0.000323500193
Iter: 521 loss: 0.000321912
Iter: 522 loss: 0.000320465129
Iter: 523 loss: 0.000320056395
Iter: 524 loss: 0.000318040489
Iter: 525 loss: 0.000317396334
Iter: 526 loss: 0.000316223828
Iter: 527 loss: 0.000314371544
Iter: 528 loss: 0.000314779521
Iter: 529 loss: 0.000312996766
Iter: 530 loss: 0.000311276846
Iter: 531 loss: 0.000312993216
Iter: 532 loss: 0.00031031
Iter: 533 loss: 0.000308013172
Iter: 534 loss: 0.00030589482
Iter: 535 loss: 0.000305339752
Iter: 536 loss: 0.000302154105
Iter: 537 loss: 0.000311221927
Iter: 538 loss: 0.000301145861
Iter: 539 loss: 0.000298887026
Iter: 540 loss: 0.000303931825
Iter: 541 loss: 0.000298042025
Iter: 542 loss: 0.000296141952
Iter: 543 loss: 0.000296140148
Iter: 544 loss: 0.000295145612
Iter: 545 loss: 0.000296946382
Iter: 546 loss: 0.000294722733
Iter: 547 loss: 0.000293346064
Iter: 548 loss: 0.000292003941
Iter: 549 loss: 0.000291702861
Iter: 550 loss: 0.000289809861
Iter: 551 loss: 0.000292307668
Iter: 552 loss: 0.000288849813
Iter: 553 loss: 0.000287347328
Iter: 554 loss: 0.000300345971
Iter: 555 loss: 0.000287258794
Iter: 556 loss: 0.000285761547
Iter: 557 loss: 0.000290986383
Iter: 558 loss: 0.000285375427
Iter: 559 loss: 0.000283898553
Iter: 560 loss: 0.000283662521
Iter: 561 loss: 0.000282640103
Iter: 562 loss: 0.000280750566
Iter: 563 loss: 0.000289667194
Iter: 564 loss: 0.000280408101
Iter: 565 loss: 0.000278614607
Iter: 566 loss: 0.000275714672
Iter: 567 loss: 0.000275693397
Iter: 568 loss: 0.00027324594
Iter: 569 loss: 0.000273210724
Iter: 570 loss: 0.000271306606
Iter: 571 loss: 0.000276872888
Iter: 572 loss: 0.000270722812
Iter: 573 loss: 0.000269350596
Iter: 574 loss: 0.000283074565
Iter: 575 loss: 0.000269302167
Iter: 576 loss: 0.000268418749
Iter: 577 loss: 0.000268922129
Iter: 578 loss: 0.000267846714
Iter: 579 loss: 0.000266461459
Iter: 580 loss: 0.000268249714
Iter: 581 loss: 0.000265746028
Iter: 582 loss: 0.000264350208
Iter: 583 loss: 0.000264123344
Iter: 584 loss: 0.000263161608
Iter: 585 loss: 0.000261608453
Iter: 586 loss: 0.00027002854
Iter: 587 loss: 0.000261365843
Iter: 588 loss: 0.000259643857
Iter: 589 loss: 0.000269214273
Iter: 590 loss: 0.000259403663
Iter: 591 loss: 0.000257949927
Iter: 592 loss: 0.000259050954
Iter: 593 loss: 0.000257058709
Iter: 594 loss: 0.000255604857
Iter: 595 loss: 0.000259251334
Iter: 596 loss: 0.000255099556
Iter: 597 loss: 0.00025319308
Iter: 598 loss: 0.000250722631
Iter: 599 loss: 0.000250555
Iter: 600 loss: 0.000248266937
Iter: 601 loss: 0.000275835686
Iter: 602 loss: 0.000248234603
Iter: 603 loss: 0.000246464624
Iter: 604 loss: 0.000264715083
Iter: 605 loss: 0.000246416137
Iter: 606 loss: 0.000245368166
Iter: 607 loss: 0.000248920376
Iter: 608 loss: 0.00024508161
Iter: 609 loss: 0.000244021736
Iter: 610 loss: 0.000244338
Iter: 611 loss: 0.000243266011
Iter: 612 loss: 0.000241627029
Iter: 613 loss: 0.0002463407
Iter: 614 loss: 0.000241104484
Iter: 615 loss: 0.000239762419
Iter: 616 loss: 0.000239577916
Iter: 617 loss: 0.000238633831
Iter: 618 loss: 0.000236901556
Iter: 619 loss: 0.00024132838
Iter: 620 loss: 0.000236292632
Iter: 621 loss: 0.000234490668
Iter: 622 loss: 0.000253224716
Iter: 623 loss: 0.000234445877
Iter: 624 loss: 0.000233355269
Iter: 625 loss: 0.000234815656
Iter: 626 loss: 0.000232802951
Iter: 627 loss: 0.000231798578
Iter: 628 loss: 0.000232739156
Iter: 629 loss: 0.000231221391
Iter: 630 loss: 0.000229688
Iter: 631 loss: 0.000230278398
Iter: 632 loss: 0.00022861801
Iter: 633 loss: 0.000227127282
Iter: 634 loss: 0.000229798374
Iter: 635 loss: 0.000226471937
Iter: 636 loss: 0.000225467797
Iter: 637 loss: 0.000225357915
Iter: 638 loss: 0.000224532923
Iter: 639 loss: 0.00022734105
Iter: 640 loss: 0.000224308184
Iter: 641 loss: 0.000223543044
Iter: 642 loss: 0.000223700888
Iter: 643 loss: 0.000222977949
Iter: 644 loss: 0.000221834387
Iter: 645 loss: 0.000225930387
Iter: 646 loss: 0.000221536131
Iter: 647 loss: 0.000220589834
Iter: 648 loss: 0.000219909271
Iter: 649 loss: 0.000219582143
Iter: 650 loss: 0.000218276778
Iter: 651 loss: 0.000224004398
Iter: 652 loss: 0.000218007364
Iter: 653 loss: 0.000216920918
Iter: 654 loss: 0.000226597738
Iter: 655 loss: 0.000216870918
Iter: 656 loss: 0.000216075059
Iter: 657 loss: 0.00021667988
Iter: 658 loss: 0.000215589243
Iter: 659 loss: 0.000214694926
Iter: 660 loss: 0.000215018517
Iter: 661 loss: 0.000214068612
Iter: 662 loss: 0.000212664338
Iter: 663 loss: 0.000216467248
Iter: 664 loss: 0.000212197207
Iter: 665 loss: 0.000211230421
Iter: 666 loss: 0.000211321327
Iter: 667 loss: 0.000210481521
Iter: 668 loss: 0.000209302932
Iter: 669 loss: 0.000224409698
Iter: 670 loss: 0.000209296093
Iter: 671 loss: 0.000208392565
Iter: 672 loss: 0.000217637193
Iter: 673 loss: 0.000208363461
Iter: 674 loss: 0.000207870384
Iter: 675 loss: 0.000207788413
Iter: 676 loss: 0.00020745139
Iter: 677 loss: 0.000206697267
Iter: 678 loss: 0.000209892183
Iter: 679 loss: 0.000206534838
Iter: 680 loss: 0.000205913486
Iter: 681 loss: 0.000205350807
Iter: 682 loss: 0.000205195742
Iter: 683 loss: 0.000204331009
Iter: 684 loss: 0.00020929653
Iter: 685 loss: 0.000204211668
Iter: 686 loss: 0.000203511401
Iter: 687 loss: 0.000207418343
Iter: 688 loss: 0.000203415097
Iter: 689 loss: 0.000202792318
Iter: 690 loss: 0.000203771109
Iter: 691 loss: 0.000202501193
Iter: 692 loss: 0.000201844639
Iter: 693 loss: 0.000201364266
Iter: 694 loss: 0.000201141345
Iter: 695 loss: 0.000199858099
Iter: 696 loss: 0.000205739576
Iter: 697 loss: 0.000199609902
Iter: 698 loss: 0.000198765294
Iter: 699 loss: 0.000198316207
Iter: 700 loss: 0.000197934
Iter: 701 loss: 0.000196731591
Iter: 702 loss: 0.000208716141
Iter: 703 loss: 0.000196694076
Iter: 704 loss: 0.000196026842
Iter: 705 loss: 0.000196011068
Iter: 706 loss: 0.000195689528
Iter: 707 loss: 0.000195355708
Iter: 708 loss: 0.000195295259
Iter: 709 loss: 0.000194682099
Iter: 710 loss: 0.00019771533
Iter: 711 loss: 0.00019457523
Iter: 712 loss: 0.000194009757
Iter: 713 loss: 0.000193706583
Iter: 714 loss: 0.000193451153
Iter: 715 loss: 0.000192698091
Iter: 716 loss: 0.000196274836
Iter: 717 loss: 0.000192559033
Iter: 718 loss: 0.000191915373
Iter: 719 loss: 0.000194772278
Iter: 720 loss: 0.000191790328
Iter: 721 loss: 0.000191205763
Iter: 722 loss: 0.000192284031
Iter: 723 loss: 0.000190954626
Iter: 724 loss: 0.000190306193
Iter: 725 loss: 0.000189587037
Iter: 726 loss: 0.00018948564
Iter: 727 loss: 0.000188244812
Iter: 728 loss: 0.000198103095
Iter: 729 loss: 0.000188157806
Iter: 730 loss: 0.00018738411
Iter: 731 loss: 0.000186667079
Iter: 732 loss: 0.00018648355
Iter: 733 loss: 0.000185457407
Iter: 734 loss: 0.000198757421
Iter: 735 loss: 0.000185451732
Iter: 736 loss: 0.000184965698
Iter: 737 loss: 0.000184936507
Iter: 738 loss: 0.000184658216
Iter: 739 loss: 0.000184118384
Iter: 740 loss: 0.000194941793
Iter: 741 loss: 0.000184114775
Iter: 742 loss: 0.000183393713
Iter: 743 loss: 0.000187652215
Iter: 744 loss: 0.00018329786
Iter: 745 loss: 0.000182613381
Iter: 746 loss: 0.000183184471
Iter: 747 loss: 0.000182206277
Iter: 748 loss: 0.000181545372
Iter: 749 loss: 0.000183661497
Iter: 750 loss: 0.000181354393
Iter: 751 loss: 0.000180692557
Iter: 752 loss: 0.000183121301
Iter: 753 loss: 0.00018053
Iter: 754 loss: 0.000179892173
Iter: 755 loss: 0.000180666873
Iter: 756 loss: 0.000179556664
Iter: 757 loss: 0.000178717397
Iter: 758 loss: 0.0001784958
Iter: 759 loss: 0.000177974813
Iter: 760 loss: 0.00017694218
Iter: 761 loss: 0.000189058046
Iter: 762 loss: 0.000176925852
Iter: 763 loss: 0.000176278671
Iter: 764 loss: 0.000175174704
Iter: 765 loss: 0.000175173191
Iter: 766 loss: 0.000174020795
Iter: 767 loss: 0.000186832738
Iter: 768 loss: 0.000173998153
Iter: 769 loss: 0.000173547349
Iter: 770 loss: 0.000173454828
Iter: 771 loss: 0.000173145556
Iter: 772 loss: 0.000172372558
Iter: 773 loss: 0.00017954511
Iter: 774 loss: 0.00017226272
Iter: 775 loss: 0.000171243126
Iter: 776 loss: 0.000178203452
Iter: 777 loss: 0.000171139414
Iter: 778 loss: 0.000170147
Iter: 779 loss: 0.000173192
Iter: 780 loss: 0.000169856794
Iter: 781 loss: 0.000169186183
Iter: 782 loss: 0.000169890278
Iter: 783 loss: 0.00016881185
Iter: 784 loss: 0.000167957536
Iter: 785 loss: 0.000170808024
Iter: 786 loss: 0.000167725855
Iter: 787 loss: 0.000166983635
Iter: 788 loss: 0.000167237333
Iter: 789 loss: 0.000166458718
Iter: 790 loss: 0.000165386547
Iter: 791 loss: 0.000167496037
Iter: 792 loss: 0.000164942903
Iter: 793 loss: 0.000163978635
Iter: 794 loss: 0.000172282133
Iter: 795 loss: 0.000163924647
Iter: 796 loss: 0.000163195044
Iter: 797 loss: 0.000162063923
Iter: 798 loss: 0.00016204844
Iter: 799 loss: 0.000160775729
Iter: 800 loss: 0.000168373037
Iter: 801 loss: 0.000160615906
Iter: 802 loss: 0.000160402153
Iter: 803 loss: 0.000160086114
Iter: 804 loss: 0.000159729709
Iter: 805 loss: 0.000158815499
Iter: 806 loss: 0.00016641512
Iter: 807 loss: 0.00015865796
Iter: 808 loss: 0.000157554663
Iter: 809 loss: 0.000164129146
Iter: 810 loss: 0.000157409653
Iter: 811 loss: 0.000156398892
Iter: 812 loss: 0.000163450866
Iter: 813 loss: 0.000156308583
Iter: 814 loss: 0.0001557715
Iter: 815 loss: 0.00015607012
Iter: 816 loss: 0.000155417569
Iter: 817 loss: 0.000154752342
Iter: 818 loss: 0.000158433351
Iter: 819 loss: 0.000154658686
Iter: 820 loss: 0.000154207053
Iter: 821 loss: 0.000153693021
Iter: 822 loss: 0.000153627741
Iter: 823 loss: 0.000152759327
Iter: 824 loss: 0.00015589071
Iter: 825 loss: 0.000152539287
Iter: 826 loss: 0.000151758519
Iter: 827 loss: 0.000155699367
Iter: 828 loss: 0.000151627348
Iter: 829 loss: 0.000150964697
Iter: 830 loss: 0.00015076487
Iter: 831 loss: 0.000150369669
Iter: 832 loss: 0.000149472675
Iter: 833 loss: 0.000150284643
Iter: 834 loss: 0.000148951221
Iter: 835 loss: 0.00014925265
Iter: 836 loss: 0.000148603329
Iter: 837 loss: 0.000148313498
Iter: 838 loss: 0.000147688464
Iter: 839 loss: 0.000157256261
Iter: 840 loss: 0.000147664949
Iter: 841 loss: 0.000147043495
Iter: 842 loss: 0.000151169559
Iter: 843 loss: 0.000146977574
Iter: 844 loss: 0.000146549864
Iter: 845 loss: 0.000153259403
Iter: 846 loss: 0.000146549457
Iter: 847 loss: 0.000146267732
Iter: 848 loss: 0.000146437436
Iter: 849 loss: 0.000146085644
Iter: 850 loss: 0.000145740589
Iter: 851 loss: 0.000147839921
Iter: 852 loss: 0.000145699334
Iter: 853 loss: 0.000145396451
Iter: 854 loss: 0.00014456232
Iter: 855 loss: 0.00014945319
Iter: 856 loss: 0.000144326565
Iter: 857 loss: 0.000143160694
Iter: 858 loss: 0.00015348036
Iter: 859 loss: 0.000143101264
Iter: 860 loss: 0.000142263467
Iter: 861 loss: 0.000144746475
Iter: 862 loss: 0.00014200568
Iter: 863 loss: 0.000141188357
Iter: 864 loss: 0.000144500344
Iter: 865 loss: 0.000141007782
Iter: 866 loss: 0.000140489094
Iter: 867 loss: 0.000140183081
Iter: 868 loss: 0.000139965734
Iter: 869 loss: 0.000140185526
Iter: 870 loss: 0.000139695287
Iter: 871 loss: 0.000139470038
Iter: 872 loss: 0.000139207608
Iter: 873 loss: 0.000139177631
Iter: 874 loss: 0.000138901392
Iter: 875 loss: 0.000138740987
Iter: 876 loss: 0.000138623262
Iter: 877 loss: 0.000138206582
Iter: 878 loss: 0.000140208489
Iter: 879 loss: 0.000138133808
Iter: 880 loss: 0.000137712355
Iter: 881 loss: 0.000138745178
Iter: 882 loss: 0.000137561685
Iter: 883 loss: 0.000137160707
Iter: 884 loss: 0.000139216281
Iter: 885 loss: 0.000137096446
Iter: 886 loss: 0.000136543502
Iter: 887 loss: 0.000135731883
Iter: 888 loss: 0.000135710463
Iter: 889 loss: 0.000135023714
Iter: 890 loss: 0.000139099924
Iter: 891 loss: 0.000134936068
Iter: 892 loss: 0.000134316797
Iter: 893 loss: 0.000134920439
Iter: 894 loss: 0.000133965921
Iter: 895 loss: 0.000133464637
Iter: 896 loss: 0.000139128824
Iter: 897 loss: 0.000133455906
Iter: 898 loss: 0.000133009627
Iter: 899 loss: 0.000132066722
Iter: 900 loss: 0.000147580664
Iter: 901 loss: 0.000132040295
Iter: 902 loss: 0.000132208108
Iter: 903 loss: 0.000131556153
Iter: 904 loss: 0.000131145018
Iter: 905 loss: 0.000131272071
Iter: 906 loss: 0.000130852524
Iter: 907 loss: 0.000130330416
Iter: 908 loss: 0.000131005654
Iter: 909 loss: 0.000130062836
Iter: 910 loss: 0.000129641339
Iter: 911 loss: 0.000129638429
Iter: 912 loss: 0.000129285487
Iter: 913 loss: 0.000129025779
Iter: 914 loss: 0.000128906686
Iter: 915 loss: 0.000128331565
Iter: 916 loss: 0.000128921805
Iter: 917 loss: 0.000128012034
Iter: 918 loss: 0.000127105421
Iter: 919 loss: 0.000131400069
Iter: 920 loss: 0.000126938772
Iter: 921 loss: 0.000126462022
Iter: 922 loss: 0.00012596944
Iter: 923 loss: 0.000125878869
Iter: 924 loss: 0.000125015678
Iter: 925 loss: 0.000130454879
Iter: 926 loss: 0.000124916682
Iter: 927 loss: 0.000124463666
Iter: 928 loss: 0.000126702493
Iter: 929 loss: 0.000124387574
Iter: 930 loss: 0.000123868551
Iter: 931 loss: 0.000124478014
Iter: 932 loss: 0.000123592617
Iter: 933 loss: 0.000123095175
Iter: 934 loss: 0.000122899539
Iter: 935 loss: 0.000122630503
Iter: 936 loss: 0.000122609024
Iter: 937 loss: 0.00012241317
Iter: 938 loss: 0.000122200465
Iter: 939 loss: 0.000122706289
Iter: 940 loss: 0.000122123514
Iter: 941 loss: 0.000121988764
Iter: 942 loss: 0.000121823927
Iter: 943 loss: 0.000121808807
Iter: 944 loss: 0.000121541103
Iter: 945 loss: 0.000123834106
Iter: 946 loss: 0.000121526777
Iter: 947 loss: 0.000121298028
Iter: 948 loss: 0.000121507648
Iter: 949 loss: 0.000121165431
Iter: 950 loss: 0.000120982302
Iter: 951 loss: 0.000123038233
Iter: 952 loss: 0.000120978963
Iter: 953 loss: 0.000120818571
Iter: 954 loss: 0.000120459365
Iter: 955 loss: 0.000125436258
Iter: 956 loss: 0.000120439399
Iter: 957 loss: 0.000119965815
Iter: 958 loss: 0.000121315665
Iter: 959 loss: 0.000119817676
Iter: 960 loss: 0.000119312434
Iter: 961 loss: 0.000121501922
Iter: 962 loss: 0.000119208285
Iter: 963 loss: 0.000118723903
Iter: 964 loss: 0.000120081058
Iter: 965 loss: 0.000118568496
Iter: 966 loss: 0.000118025942
Iter: 967 loss: 0.000118981297
Iter: 968 loss: 0.000117786753
Iter: 969 loss: 0.00011736
Iter: 970 loss: 0.00011935216
Iter: 971 loss: 0.000117282201
Iter: 972 loss: 0.00011691462
Iter: 973 loss: 0.000122548663
Iter: 974 loss: 0.000116914714
Iter: 975 loss: 0.000116736024
Iter: 976 loss: 0.000116368894
Iter: 977 loss: 0.000122773839
Iter: 978 loss: 0.000116361669
Iter: 979 loss: 0.000115997827
Iter: 980 loss: 0.000121013232
Iter: 981 loss: 0.000115996212
Iter: 982 loss: 0.000115705036
Iter: 983 loss: 0.000115944102
Iter: 984 loss: 0.00011553154
Iter: 985 loss: 0.000115227027
Iter: 986 loss: 0.000116085663
Iter: 987 loss: 0.000115129078
Iter: 988 loss: 0.000114743059
Iter: 989 loss: 0.000114643728
Iter: 990 loss: 0.000114402792
Iter: 991 loss: 0.000113870701
Iter: 992 loss: 0.000114614748
Iter: 993 loss: 0.000113607763
Iter: 994 loss: 0.000113064365
Iter: 995 loss: 0.000116365874
Iter: 996 loss: 0.00011299771
Iter: 997 loss: 0.000112490452
Iter: 998 loss: 0.000113323753
Iter: 999 loss: 0.000112258509
Iter: 1000 loss: 0.000111854191
Iter: 1001 loss: 0.000115326344
Iter: 1002 loss: 0.000111832072
Iter: 1003 loss: 0.000111590474
Iter: 1004 loss: 0.000111867281
Iter: 1005 loss: 0.000111460038
Iter: 1006 loss: 0.000111325979
Iter: 1007 loss: 0.000111288398
Iter: 1008 loss: 0.000111189467
Iter: 1009 loss: 0.000110986381
Iter: 1010 loss: 0.000114649491
Iter: 1011 loss: 0.000110982757
Iter: 1012 loss: 0.000110765526
Iter: 1013 loss: 0.000111935777
Iter: 1014 loss: 0.000110733963
Iter: 1015 loss: 0.000110522291
Iter: 1016 loss: 0.000110910318
Iter: 1017 loss: 0.000110430454
Iter: 1018 loss: 0.000110227083
Iter: 1019 loss: 0.000110482433
Iter: 1020 loss: 0.000110122783
Iter: 1021 loss: 0.000109814078
Iter: 1022 loss: 0.000110022534
Iter: 1023 loss: 0.000109620123
Iter: 1024 loss: 0.000109239947
Iter: 1025 loss: 0.000109169327
Iter: 1026 loss: 0.000108914173
Iter: 1027 loss: 0.000108438624
Iter: 1028 loss: 0.000110878624
Iter: 1029 loss: 0.000108361302
Iter: 1030 loss: 0.000107915621
Iter: 1031 loss: 0.000109218592
Iter: 1032 loss: 0.000107777909
Iter: 1033 loss: 0.000107348875
Iter: 1034 loss: 0.000109623281
Iter: 1035 loss: 0.000107282467
Iter: 1036 loss: 0.000106967971
Iter: 1037 loss: 0.000108108128
Iter: 1038 loss: 0.000106889864
Iter: 1039 loss: 0.000106758423
Iter: 1040 loss: 0.000106743224
Iter: 1041 loss: 0.000106633837
Iter: 1042 loss: 0.000106372281
Iter: 1043 loss: 0.000109301138
Iter: 1044 loss: 0.000106347645
Iter: 1045 loss: 0.000106099265
Iter: 1046 loss: 0.000109140827
Iter: 1047 loss: 0.000106096253
Iter: 1048 loss: 0.000105901367
Iter: 1049 loss: 0.000106302061
Iter: 1050 loss: 0.000105824089
Iter: 1051 loss: 0.000105607352
Iter: 1052 loss: 0.000105699233
Iter: 1053 loss: 0.000105458283
Iter: 1054 loss: 0.000105106177
Iter: 1055 loss: 0.00010582016
Iter: 1056 loss: 0.000104964442
Iter: 1057 loss: 0.0001046135
Iter: 1058 loss: 0.000105007552
Iter: 1059 loss: 0.000104423831
Iter: 1060 loss: 0.000104080704
Iter: 1061 loss: 0.000104748091
Iter: 1062 loss: 0.000103938051
Iter: 1063 loss: 0.000103500322
Iter: 1064 loss: 0.00010518956
Iter: 1065 loss: 0.000103397222
Iter: 1066 loss: 0.000103054721
Iter: 1067 loss: 0.000104922903
Iter: 1068 loss: 0.000103004699
Iter: 1069 loss: 0.000102751917
Iter: 1070 loss: 0.000103856233
Iter: 1071 loss: 0.000102700571
Iter: 1072 loss: 0.000102545193
Iter: 1073 loss: 0.00010440906
Iter: 1074 loss: 0.000102543519
Iter: 1075 loss: 0.000102378559
Iter: 1076 loss: 0.000102146529
Iter: 1077 loss: 0.00010213707
Iter: 1078 loss: 0.000101915015
Iter: 1079 loss: 0.000102751175
Iter: 1080 loss: 0.000101861806
Iter: 1081 loss: 0.000101601021
Iter: 1082 loss: 0.000102459715
Iter: 1083 loss: 0.000101528094
Iter: 1084 loss: 0.000101293175
Iter: 1085 loss: 0.000101193487
Iter: 1086 loss: 0.000101072023
Iter: 1087 loss: 0.000100695019
Iter: 1088 loss: 0.000103035563
Iter: 1089 loss: 0.000100650257
Iter: 1090 loss: 0.000100417856
Iter: 1091 loss: 0.000100549645
Iter: 1092 loss: 0.00010026653
Iter: 1093 loss: 9.99827535e-05
Iter: 1094 loss: 0.000100102479
Iter: 1095 loss: 9.97871102e-05
Iter: 1096 loss: 9.93649737e-05
Iter: 1097 loss: 0.000101213765
Iter: 1098 loss: 9.92801797e-05
Iter: 1099 loss: 9.89209948e-05
Iter: 1100 loss: 0.000100619101
Iter: 1101 loss: 9.88552929e-05
Iter: 1102 loss: 9.85756633e-05
Iter: 1103 loss: 9.98442702e-05
Iter: 1104 loss: 9.8522396e-05
Iter: 1105 loss: 9.83589925e-05
Iter: 1106 loss: 0.000100479418
Iter: 1107 loss: 9.83579957e-05
Iter: 1108 loss: 9.81975609e-05
Iter: 1109 loss: 9.80171244e-05
Iter: 1110 loss: 9.79933393e-05
Iter: 1111 loss: 9.77736927e-05
Iter: 1112 loss: 9.8661847e-05
Iter: 1113 loss: 9.7724318e-05
Iter: 1114 loss: 9.74845752e-05
Iter: 1115 loss: 9.81928606e-05
Iter: 1116 loss: 9.74121504e-05
Iter: 1117 loss: 9.71741101e-05
Iter: 1118 loss: 9.75015282e-05
Iter: 1119 loss: 9.70558176e-05
Iter: 1120 loss: 9.68388194e-05
Iter: 1121 loss: 9.84182552e-05
Iter: 1122 loss: 9.68208042e-05
Iter: 1123 loss: 9.66676e-05
Iter: 1124 loss: 9.65730287e-05
Iter: 1125 loss: 9.65110303e-05
Iter: 1126 loss: 9.62687554e-05
Iter: 1127 loss: 9.65948711e-05
Iter: 1128 loss: 9.61471378e-05
Iter: 1129 loss: 9.58658566e-05
Iter: 1130 loss: 9.74472714e-05
Iter: 1131 loss: 9.58262608e-05
Iter: 1132 loss: 9.55862633e-05
Iter: 1133 loss: 9.61611368e-05
Iter: 1134 loss: 9.54995121e-05
Iter: 1135 loss: 9.52827759e-05
Iter: 1136 loss: 9.71558839e-05
Iter: 1137 loss: 9.52708215e-05
Iter: 1138 loss: 9.5150026e-05
Iter: 1139 loss: 9.59360041e-05
Iter: 1140 loss: 9.5137264e-05
Iter: 1141 loss: 9.49960304e-05
Iter: 1142 loss: 9.49821479e-05
Iter: 1143 loss: 9.48786328e-05
Iter: 1144 loss: 9.47461958e-05
Iter: 1145 loss: 9.47878143e-05
Iter: 1146 loss: 9.46516375e-05
Iter: 1147 loss: 9.44500789e-05
Iter: 1148 loss: 9.58854071e-05
Iter: 1149 loss: 9.44319254e-05
Iter: 1150 loss: 9.42867555e-05
Iter: 1151 loss: 9.43614723e-05
Iter: 1152 loss: 9.41906255e-05
Iter: 1153 loss: 9.4018018e-05
Iter: 1154 loss: 9.471878e-05
Iter: 1155 loss: 9.39793827e-05
Iter: 1156 loss: 9.38225712e-05
Iter: 1157 loss: 9.38538506e-05
Iter: 1158 loss: 9.37061122e-05
Iter: 1159 loss: 9.35027492e-05
Iter: 1160 loss: 9.36094439e-05
Iter: 1161 loss: 9.33681295e-05
Iter: 1162 loss: 9.30710521e-05
Iter: 1163 loss: 9.4254312e-05
Iter: 1164 loss: 9.30041e-05
Iter: 1165 loss: 9.27360379e-05
Iter: 1166 loss: 9.41599355e-05
Iter: 1167 loss: 9.26949651e-05
Iter: 1168 loss: 9.25261411e-05
Iter: 1169 loss: 9.37733057e-05
Iter: 1170 loss: 9.25121931e-05
Iter: 1171 loss: 9.23990883e-05
Iter: 1172 loss: 9.30290844e-05
Iter: 1173 loss: 9.2382732e-05
Iter: 1174 loss: 9.22469844e-05
Iter: 1175 loss: 9.22782347e-05
Iter: 1176 loss: 9.21471874e-05
Iter: 1177 loss: 9.20065795e-05
Iter: 1178 loss: 9.22008549e-05
Iter: 1179 loss: 9.19361628e-05
Iter: 1180 loss: 9.1764814e-05
Iter: 1181 loss: 9.25886707e-05
Iter: 1182 loss: 9.17348225e-05
Iter: 1183 loss: 9.1568807e-05
Iter: 1184 loss: 9.16301797e-05
Iter: 1185 loss: 9.14523698e-05
Iter: 1186 loss: 9.12578325e-05
Iter: 1187 loss: 9.22002509e-05
Iter: 1188 loss: 9.12237811e-05
Iter: 1189 loss: 9.10553208e-05
Iter: 1190 loss: 9.11509851e-05
Iter: 1191 loss: 9.09453956e-05
Iter: 1192 loss: 9.07463836e-05
Iter: 1193 loss: 9.07292e-05
Iter: 1194 loss: 9.05820198e-05
Iter: 1195 loss: 9.02867469e-05
Iter: 1196 loss: 9.21059254e-05
Iter: 1197 loss: 9.02517131e-05
Iter: 1198 loss: 9.00251616e-05
Iter: 1199 loss: 9.10109811e-05
Iter: 1200 loss: 8.99795705e-05
Iter: 1201 loss: 8.98141152e-05
Iter: 1202 loss: 9.08411821e-05
Iter: 1203 loss: 8.97947102e-05
Iter: 1204 loss: 8.96741e-05
Iter: 1205 loss: 9.01833191e-05
Iter: 1206 loss: 8.96486745e-05
Iter: 1207 loss: 8.95003614e-05
Iter: 1208 loss: 8.98079e-05
Iter: 1209 loss: 8.94406257e-05
Iter: 1210 loss: 8.9339781e-05
Iter: 1211 loss: 8.92571406e-05
Iter: 1212 loss: 8.92276221e-05
Iter: 1213 loss: 8.90444353e-05
Iter: 1214 loss: 9.03109467e-05
Iter: 1215 loss: 8.90266674e-05
Iter: 1216 loss: 8.88820068e-05
Iter: 1217 loss: 8.90613373e-05
Iter: 1218 loss: 8.88065842e-05
Iter: 1219 loss: 8.86557245e-05
Iter: 1220 loss: 8.92521057e-05
Iter: 1221 loss: 8.86210328e-05
Iter: 1222 loss: 8.84748151e-05
Iter: 1223 loss: 8.8515073e-05
Iter: 1224 loss: 8.83694e-05
Iter: 1225 loss: 8.81847373e-05
Iter: 1226 loss: 8.82881577e-05
Iter: 1227 loss: 8.80639418e-05
Iter: 1228 loss: 8.78320716e-05
Iter: 1229 loss: 8.89789808e-05
Iter: 1230 loss: 8.77928396e-05
Iter: 1231 loss: 8.76031045e-05
Iter: 1232 loss: 8.87027854e-05
Iter: 1233 loss: 8.75772821e-05
Iter: 1234 loss: 8.74532852e-05
Iter: 1235 loss: 8.82283857e-05
Iter: 1236 loss: 8.74387624e-05
Iter: 1237 loss: 8.73527315e-05
Iter: 1238 loss: 8.78871288e-05
Iter: 1239 loss: 8.73422541e-05
Iter: 1240 loss: 8.7255874e-05
Iter: 1241 loss: 8.7411594e-05
Iter: 1242 loss: 8.72184173e-05
Iter: 1243 loss: 8.71406664e-05
Iter: 1244 loss: 8.71186203e-05
Iter: 1245 loss: 8.70712247e-05
Iter: 1246 loss: 8.69550931e-05
Iter: 1247 loss: 8.77437e-05
Iter: 1248 loss: 8.694391e-05
Iter: 1249 loss: 8.68448187e-05
Iter: 1250 loss: 8.69357682e-05
Iter: 1251 loss: 8.67876588e-05
Iter: 1252 loss: 8.66802e-05
Iter: 1253 loss: 8.69577198e-05
Iter: 1254 loss: 8.66433184e-05
Iter: 1255 loss: 8.65206821e-05
Iter: 1256 loss: 8.66216287e-05
Iter: 1257 loss: 8.6447486e-05
Iter: 1258 loss: 8.63096939e-05
Iter: 1259 loss: 8.63458554e-05
Iter: 1260 loss: 8.62092347e-05
Iter: 1261 loss: 8.60301298e-05
Iter: 1262 loss: 8.7104956e-05
Iter: 1263 loss: 8.60073778e-05
Iter: 1264 loss: 8.58676212e-05
Iter: 1265 loss: 8.65014e-05
Iter: 1266 loss: 8.58408166e-05
Iter: 1267 loss: 8.57372943e-05
Iter: 1268 loss: 8.64179747e-05
Iter: 1269 loss: 8.57263731e-05
Iter: 1270 loss: 8.56525e-05
Iter: 1271 loss: 8.59401e-05
Iter: 1272 loss: 8.56356855e-05
Iter: 1273 loss: 8.554956e-05
Iter: 1274 loss: 8.58443382e-05
Iter: 1275 loss: 8.55263061e-05
Iter: 1276 loss: 8.54709942e-05
Iter: 1277 loss: 8.54114187e-05
Iter: 1278 loss: 8.54017126e-05
Iter: 1279 loss: 8.53045931e-05
Iter: 1280 loss: 8.61312365e-05
Iter: 1281 loss: 8.52990925e-05
Iter: 1282 loss: 8.521993e-05
Iter: 1283 loss: 8.5286345e-05
Iter: 1284 loss: 8.51732621e-05
Iter: 1285 loss: 8.50783836e-05
Iter: 1286 loss: 8.53248202e-05
Iter: 1287 loss: 8.50458e-05
Iter: 1288 loss: 8.49424905e-05
Iter: 1289 loss: 8.5043037e-05
Iter: 1290 loss: 8.48835698e-05
Iter: 1291 loss: 8.47664196e-05
Iter: 1292 loss: 8.47661649e-05
Iter: 1293 loss: 8.46724724e-05
Iter: 1294 loss: 8.4506748e-05
Iter: 1295 loss: 8.52390731e-05
Iter: 1296 loss: 8.44735914e-05
Iter: 1297 loss: 8.43286689e-05
Iter: 1298 loss: 8.51594305e-05
Iter: 1299 loss: 8.43092e-05
Iter: 1300 loss: 8.42057634e-05
Iter: 1301 loss: 8.47453339e-05
Iter: 1302 loss: 8.41893634e-05
Iter: 1303 loss: 8.41116635e-05
Iter: 1304 loss: 8.45949471e-05
Iter: 1305 loss: 8.4102765e-05
Iter: 1306 loss: 8.4032421e-05
Iter: 1307 loss: 8.42416921e-05
Iter: 1308 loss: 8.40111388e-05
Iter: 1309 loss: 8.39549466e-05
Iter: 1310 loss: 8.39097193e-05
Iter: 1311 loss: 8.38931155e-05
Iter: 1312 loss: 8.38061096e-05
Iter: 1313 loss: 8.45041359e-05
Iter: 1314 loss: 8.38002888e-05
Iter: 1315 loss: 8.372507e-05
Iter: 1316 loss: 8.38098495e-05
Iter: 1317 loss: 8.36840773e-05
Iter: 1318 loss: 8.35989631e-05
Iter: 1319 loss: 8.378856e-05
Iter: 1320 loss: 8.3566425e-05
Iter: 1321 loss: 8.34677921e-05
Iter: 1322 loss: 8.36134932e-05
Iter: 1323 loss: 8.34204548e-05
Iter: 1324 loss: 8.33159284e-05
Iter: 1325 loss: 8.32857404e-05
Iter: 1326 loss: 8.32226069e-05
Iter: 1327 loss: 8.30684512e-05
Iter: 1328 loss: 8.38564738e-05
Iter: 1329 loss: 8.3043582e-05
Iter: 1330 loss: 8.29143319e-05
Iter: 1331 loss: 8.3477149e-05
Iter: 1332 loss: 8.28881748e-05
Iter: 1333 loss: 8.2786064e-05
Iter: 1334 loss: 8.3488907e-05
Iter: 1335 loss: 8.27763579e-05
Iter: 1336 loss: 8.27083277e-05
Iter: 1337 loss: 8.30430654e-05
Iter: 1338 loss: 8.26964751e-05
Iter: 1339 loss: 8.26278701e-05
Iter: 1340 loss: 8.29076162e-05
Iter: 1341 loss: 8.26124888e-05
Iter: 1342 loss: 8.2563507e-05
Iter: 1343 loss: 8.25062452e-05
Iter: 1344 loss: 8.2499726e-05
Iter: 1345 loss: 8.24185117e-05
Iter: 1346 loss: 8.31640718e-05
Iter: 1347 loss: 8.24144881e-05
Iter: 1348 loss: 8.23496084e-05
Iter: 1349 loss: 8.24151357e-05
Iter: 1350 loss: 8.23131268e-05
Iter: 1351 loss: 8.22366856e-05
Iter: 1352 loss: 8.24050221e-05
Iter: 1353 loss: 8.22069414e-05
Iter: 1354 loss: 8.21208159e-05
Iter: 1355 loss: 8.22772e-05
Iter: 1356 loss: 8.20838177e-05
Iter: 1357 loss: 8.19961424e-05
Iter: 1358 loss: 8.19762718e-05
Iter: 1359 loss: 8.1919643e-05
Iter: 1360 loss: 8.17930268e-05
Iter: 1361 loss: 8.22782895e-05
Iter: 1362 loss: 8.1763239e-05
Iter: 1363 loss: 8.16427055e-05
Iter: 1364 loss: 8.22608708e-05
Iter: 1365 loss: 8.16229149e-05
Iter: 1366 loss: 8.15345848e-05
Iter: 1367 loss: 8.20765854e-05
Iter: 1368 loss: 8.15239182e-05
Iter: 1369 loss: 8.1461083e-05
Iter: 1370 loss: 8.18178814e-05
Iter: 1371 loss: 8.145225e-05
Iter: 1372 loss: 8.13940642e-05
Iter: 1373 loss: 8.15978638e-05
Iter: 1374 loss: 8.13788647e-05
Iter: 1375 loss: 8.13313e-05
Iter: 1376 loss: 8.12836297e-05
Iter: 1377 loss: 8.1273829e-05
Iter: 1378 loss: 8.11989e-05
Iter: 1379 loss: 8.18181434e-05
Iter: 1380 loss: 8.11944701e-05
Iter: 1381 loss: 8.11292266e-05
Iter: 1382 loss: 8.12377548e-05
Iter: 1383 loss: 8.10993515e-05
Iter: 1384 loss: 8.1035425e-05
Iter: 1385 loss: 8.11451318e-05
Iter: 1386 loss: 8.10067431e-05
Iter: 1387 loss: 8.09304911e-05
Iter: 1388 loss: 8.10707e-05
Iter: 1389 loss: 8.08978148e-05
Iter: 1390 loss: 8.08159166e-05
Iter: 1391 loss: 8.07934557e-05
Iter: 1392 loss: 8.07433244e-05
Iter: 1393 loss: 8.06208e-05
Iter: 1394 loss: 8.11760692e-05
Iter: 1395 loss: 8.05971504e-05
Iter: 1396 loss: 8.04893498e-05
Iter: 1397 loss: 8.09237172e-05
Iter: 1398 loss: 8.04657684e-05
Iter: 1399 loss: 8.03801959e-05
Iter: 1400 loss: 8.09655103e-05
Iter: 1401 loss: 8.03718431e-05
Iter: 1402 loss: 8.03134171e-05
Iter: 1403 loss: 8.06282187e-05
Iter: 1404 loss: 8.03047e-05
Iter: 1405 loss: 8.02484792e-05
Iter: 1406 loss: 8.04546144e-05
Iter: 1407 loss: 8.02344803e-05
Iter: 1408 loss: 8.01894057e-05
Iter: 1409 loss: 8.01283459e-05
Iter: 1410 loss: 8.01253045e-05
Iter: 1411 loss: 8.00536654e-05
Iter: 1412 loss: 8.08738041e-05
Iter: 1413 loss: 8.00525959e-05
Iter: 1414 loss: 7.99970076e-05
Iter: 1415 loss: 8.00697453e-05
Iter: 1416 loss: 7.99690315e-05
Iter: 1417 loss: 7.99033151e-05
Iter: 1418 loss: 8.00030539e-05
Iter: 1419 loss: 7.98721594e-05
Iter: 1420 loss: 7.97933899e-05
Iter: 1421 loss: 7.99556947e-05
Iter: 1422 loss: 7.97618559e-05
Iter: 1423 loss: 7.96803652e-05
Iter: 1424 loss: 7.96744e-05
Iter: 1425 loss: 7.96132663e-05
Iter: 1426 loss: 7.95023225e-05
Iter: 1427 loss: 7.98977e-05
Iter: 1428 loss: 7.94737571e-05
Iter: 1429 loss: 7.93655199e-05
Iter: 1430 loss: 7.99408e-05
Iter: 1431 loss: 7.93488e-05
Iter: 1432 loss: 7.92691208e-05
Iter: 1433 loss: 7.97741959e-05
Iter: 1434 loss: 7.926e-05
Iter: 1435 loss: 7.92040955e-05
Iter: 1436 loss: 7.95457672e-05
Iter: 1437 loss: 7.91970378e-05
Iter: 1438 loss: 7.91474449e-05
Iter: 1439 loss: 7.93199e-05
Iter: 1440 loss: 7.91344282e-05
Iter: 1441 loss: 7.90915801e-05
Iter: 1442 loss: 7.90486592e-05
Iter: 1443 loss: 7.90400372e-05
Iter: 1444 loss: 7.89760525e-05
Iter: 1445 loss: 7.9387275e-05
Iter: 1446 loss: 7.89691549e-05
Iter: 1447 loss: 7.89093174e-05
Iter: 1448 loss: 7.90001432e-05
Iter: 1449 loss: 7.88808684e-05
Iter: 1450 loss: 7.88156322e-05
Iter: 1451 loss: 7.89456244e-05
Iter: 1452 loss: 7.87889439e-05
Iter: 1453 loss: 7.87122772e-05
Iter: 1454 loss: 7.88951875e-05
Iter: 1455 loss: 7.86843812e-05
Iter: 1456 loss: 7.86072414e-05
Iter: 1457 loss: 7.85698721e-05
Iter: 1458 loss: 7.85328e-05
Iter: 1459 loss: 7.84197327e-05
Iter: 1460 loss: 7.89138867e-05
Iter: 1461 loss: 7.83971409e-05
Iter: 1462 loss: 7.82952338e-05
Iter: 1463 loss: 7.86730088e-05
Iter: 1464 loss: 7.82703719e-05
Iter: 1465 loss: 7.8185607e-05
Iter: 1466 loss: 7.88497782e-05
Iter: 1467 loss: 7.81795316e-05
Iter: 1468 loss: 7.8123936e-05
Iter: 1469 loss: 7.84893127e-05
Iter: 1470 loss: 7.81182098e-05
Iter: 1471 loss: 7.80714108e-05
Iter: 1472 loss: 7.82550778e-05
Iter: 1473 loss: 7.80606e-05
Iter: 1474 loss: 7.8021214e-05
Iter: 1475 loss: 7.79633847e-05
Iter: 1476 loss: 7.79620241e-05
Iter: 1477 loss: 7.78928952e-05
Iter: 1478 loss: 7.86149903e-05
Iter: 1479 loss: 7.78909816e-05
Iter: 1480 loss: 7.78351823e-05
Iter: 1481 loss: 7.78912436e-05
Iter: 1482 loss: 7.7804e-05
Iter: 1483 loss: 7.7738041e-05
Iter: 1484 loss: 7.78538233e-05
Iter: 1485 loss: 7.77091482e-05
Iter: 1486 loss: 7.76349552e-05
Iter: 1487 loss: 7.77765381e-05
Iter: 1488 loss: 7.76038141e-05
Iter: 1489 loss: 7.75178487e-05
Iter: 1490 loss: 7.75313238e-05
Iter: 1491 loss: 7.74522487e-05
Iter: 1492 loss: 7.73445354e-05
Iter: 1493 loss: 7.77214445e-05
Iter: 1494 loss: 7.73163338e-05
Iter: 1495 loss: 7.72051e-05
Iter: 1496 loss: 7.7658231e-05
Iter: 1497 loss: 7.71806735e-05
Iter: 1498 loss: 7.7094548e-05
Iter: 1499 loss: 7.76961242e-05
Iter: 1500 loss: 7.708669e-05
Iter: 1501 loss: 7.70290062e-05
Iter: 1502 loss: 7.7450728e-05
Iter: 1503 loss: 7.70240149e-05
Iter: 1504 loss: 7.6977245e-05
Iter: 1505 loss: 7.71106425e-05
Iter: 1506 loss: 7.6962664e-05
Iter: 1507 loss: 7.69145408e-05
Iter: 1508 loss: 7.6874785e-05
Iter: 1509 loss: 7.68606551e-05
Iter: 1510 loss: 7.6794473e-05
Iter: 1511 loss: 7.72586282e-05
Iter: 1512 loss: 7.67885504e-05
Iter: 1513 loss: 7.67254169e-05
Iter: 1514 loss: 7.67980819e-05
Iter: 1515 loss: 7.669146e-05
Iter: 1516 loss: 7.66205339e-05
Iter: 1517 loss: 7.67327656e-05
Iter: 1518 loss: 7.65874e-05
Iter: 1519 loss: 7.65042496e-05
Iter: 1520 loss: 7.67996535e-05
Iter: 1521 loss: 7.6482931e-05
Iter: 1522 loss: 7.64083088e-05
Iter: 1523 loss: 7.63656572e-05
Iter: 1524 loss: 7.63336793e-05
Iter: 1525 loss: 7.62212876e-05
Iter: 1526 loss: 7.66242811e-05
Iter: 1527 loss: 7.61928604e-05
Iter: 1528 loss: 7.60815456e-05
Iter: 1529 loss: 7.64666329e-05
Iter: 1530 loss: 7.60517723e-05
Iter: 1531 loss: 7.59576214e-05
Iter: 1532 loss: 7.67194724e-05
Iter: 1533 loss: 7.59515387e-05
Iter: 1534 loss: 7.58862807e-05
Iter: 1535 loss: 7.62681157e-05
Iter: 1536 loss: 7.58780079e-05
Iter: 1537 loss: 7.58217648e-05
Iter: 1538 loss: 7.60201219e-05
Iter: 1539 loss: 7.58070091e-05
Iter: 1540 loss: 7.5757358e-05
Iter: 1541 loss: 7.56976442e-05
Iter: 1542 loss: 7.5691627e-05
Iter: 1543 loss: 7.561245e-05
Iter: 1544 loss: 7.62890413e-05
Iter: 1545 loss: 7.56081135e-05
Iter: 1546 loss: 7.55392102e-05
Iter: 1547 loss: 7.56030713e-05
Iter: 1548 loss: 7.54993234e-05
Iter: 1549 loss: 7.54203284e-05
Iter: 1550 loss: 7.56601221e-05
Iter: 1551 loss: 7.53963832e-05
Iter: 1552 loss: 7.5323871e-05
Iter: 1553 loss: 7.55311339e-05
Iter: 1554 loss: 7.53007625e-05
Iter: 1555 loss: 7.52221822e-05
Iter: 1556 loss: 7.52001361e-05
Iter: 1557 loss: 7.5151911e-05
Iter: 1558 loss: 7.50476538e-05
Iter: 1559 loss: 7.54078e-05
Iter: 1560 loss: 7.50202889e-05
Iter: 1561 loss: 7.49108e-05
Iter: 1562 loss: 7.52593696e-05
Iter: 1563 loss: 7.48798411e-05
Iter: 1564 loss: 7.4786e-05
Iter: 1565 loss: 7.54538341e-05
Iter: 1566 loss: 7.47772283e-05
Iter: 1567 loss: 7.47089653e-05
Iter: 1568 loss: 7.52965e-05
Iter: 1569 loss: 7.47051818e-05
Iter: 1570 loss: 7.46545629e-05
Iter: 1571 loss: 7.47829836e-05
Iter: 1572 loss: 7.46371516e-05
Iter: 1573 loss: 7.45830257e-05
Iter: 1574 loss: 7.45513e-05
Iter: 1575 loss: 7.45281723e-05
Iter: 1576 loss: 7.44596473e-05
Iter: 1577 loss: 7.4866839e-05
Iter: 1578 loss: 7.44513236e-05
Iter: 1579 loss: 7.43847631e-05
Iter: 1580 loss: 7.44528807e-05
Iter: 1581 loss: 7.43473938e-05
Iter: 1582 loss: 7.42781558e-05
Iter: 1583 loss: 7.44156278e-05
Iter: 1584 loss: 7.4250187e-05
Iter: 1585 loss: 7.41739641e-05
Iter: 1586 loss: 7.44666177e-05
Iter: 1587 loss: 7.41564e-05
Iter: 1588 loss: 7.40852483e-05
Iter: 1589 loss: 7.40519536e-05
Iter: 1590 loss: 7.40170071e-05
Iter: 1591 loss: 7.39162351e-05
Iter: 1592 loss: 7.42335105e-05
Iter: 1593 loss: 7.38872914e-05
Iter: 1594 loss: 7.37797236e-05
Iter: 1595 loss: 7.40670366e-05
Iter: 1596 loss: 7.37438386e-05
Iter: 1597 loss: 7.36474831e-05
Iter: 1598 loss: 7.44358e-05
Iter: 1599 loss: 7.36417933e-05
Iter: 1600 loss: 7.35752e-05
Iter: 1601 loss: 7.40730757e-05
Iter: 1602 loss: 7.35701324e-05
Iter: 1603 loss: 7.35185458e-05
Iter: 1604 loss: 7.36803049e-05
Iter: 1605 loss: 7.35034846e-05
Iter: 1606 loss: 7.34551e-05
Iter: 1607 loss: 7.3419993e-05
Iter: 1608 loss: 7.34033383e-05
Iter: 1609 loss: 7.33352499e-05
Iter: 1610 loss: 7.38547751e-05
Iter: 1611 loss: 7.33301567e-05
Iter: 1612 loss: 7.32673361e-05
Iter: 1613 loss: 7.32971e-05
Iter: 1614 loss: 7.32248445e-05
Iter: 1615 loss: 7.31469627e-05
Iter: 1616 loss: 7.33465058e-05
Iter: 1617 loss: 7.31199543e-05
Iter: 1618 loss: 7.30443717e-05
Iter: 1619 loss: 7.33115594e-05
Iter: 1620 loss: 7.30249e-05
Iter: 1621 loss: 7.29454332e-05
Iter: 1622 loss: 7.29318272e-05
Iter: 1623 loss: 7.28777231e-05
Iter: 1624 loss: 7.27710722e-05
Iter: 1625 loss: 7.30307875e-05
Iter: 1626 loss: 7.27329316e-05
Iter: 1627 loss: 7.26093131e-05
Iter: 1628 loss: 7.30053798e-05
Iter: 1629 loss: 7.25744612e-05
Iter: 1630 loss: 7.24693527e-05
Iter: 1631 loss: 7.31161563e-05
Iter: 1632 loss: 7.24569763e-05
Iter: 1633 loss: 7.23786361e-05
Iter: 1634 loss: 7.31089531e-05
Iter: 1635 loss: 7.23756093e-05
Iter: 1636 loss: 7.23216071e-05
Iter: 1637 loss: 7.24274287e-05
Iter: 1638 loss: 7.22993645e-05
Iter: 1639 loss: 7.22374e-05
Iter: 1640 loss: 7.22576515e-05
Iter: 1641 loss: 7.21933684e-05
Iter: 1642 loss: 7.21264587e-05
Iter: 1643 loss: 7.24147394e-05
Iter: 1644 loss: 7.21128308e-05
Iter: 1645 loss: 7.20333919e-05
Iter: 1646 loss: 7.20874232e-05
Iter: 1647 loss: 7.19837481e-05
Iter: 1648 loss: 7.18966112e-05
Iter: 1649 loss: 7.20554963e-05
Iter: 1650 loss: 7.18594747e-05
Iter: 1651 loss: 7.1768256e-05
Iter: 1652 loss: 7.20589451e-05
Iter: 1653 loss: 7.17423172e-05
Iter: 1654 loss: 7.16457944e-05
Iter: 1655 loss: 7.1605522e-05
Iter: 1656 loss: 7.1555005e-05
Iter: 1657 loss: 7.1413e-05
Iter: 1658 loss: 7.18647061e-05
Iter: 1659 loss: 7.13725894e-05
Iter: 1660 loss: 7.12226902e-05
Iter: 1661 loss: 7.1629569e-05
Iter: 1662 loss: 7.11735556e-05
Iter: 1663 loss: 7.10372551e-05
Iter: 1664 loss: 7.19830568e-05
Iter: 1665 loss: 7.10242748e-05
Iter: 1666 loss: 7.09279557e-05
Iter: 1667 loss: 7.17364237e-05
Iter: 1668 loss: 7.09221495e-05
Iter: 1669 loss: 7.08513617e-05
Iter: 1670 loss: 7.10750755e-05
Iter: 1671 loss: 7.08307343e-05
Iter: 1672 loss: 7.0764072e-05
Iter: 1673 loss: 7.0742135e-05
Iter: 1674 loss: 7.07036961e-05
Iter: 1675 loss: 7.06148057e-05
Iter: 1676 loss: 7.11478206e-05
Iter: 1677 loss: 7.06035571e-05
Iter: 1678 loss: 7.05116e-05
Iter: 1679 loss: 7.05951825e-05
Iter: 1680 loss: 7.04581253e-05
Iter: 1681 loss: 7.03559854e-05
Iter: 1682 loss: 7.05884377e-05
Iter: 1683 loss: 7.03172846e-05
Iter: 1684 loss: 7.02195612e-05
Iter: 1685 loss: 7.04893e-05
Iter: 1686 loss: 7.01878e-05
Iter: 1687 loss: 7.00734818e-05
Iter: 1688 loss: 7.00696e-05
Iter: 1689 loss: 6.99807861e-05
Iter: 1690 loss: 6.98313961e-05
Iter: 1691 loss: 7.02246616e-05
Iter: 1692 loss: 6.97813157e-05
Iter: 1693 loss: 6.96179777e-05
Iter: 1694 loss: 7.02169636e-05
Iter: 1695 loss: 6.95776325e-05
Iter: 1696 loss: 6.94460832e-05
Iter: 1697 loss: 7.02549878e-05
Iter: 1698 loss: 6.94300688e-05
Iter: 1699 loss: 6.93339607e-05
Iter: 1700 loss: 7.02652687e-05
Iter: 1701 loss: 6.93301845e-05
Iter: 1702 loss: 6.92641188e-05
Iter: 1703 loss: 6.94130504e-05
Iter: 1704 loss: 6.92393223e-05
Iter: 1705 loss: 6.91670939e-05
Iter: 1706 loss: 6.91870664e-05
Iter: 1707 loss: 6.9114707e-05
Iter: 1708 loss: 6.90390807e-05
Iter: 1709 loss: 6.93539478e-05
Iter: 1710 loss: 6.90230809e-05
Iter: 1711 loss: 6.89375593e-05
Iter: 1712 loss: 6.90593442e-05
Iter: 1713 loss: 6.88955e-05
Iter: 1714 loss: 6.88120635e-05
Iter: 1715 loss: 6.9007292e-05
Iter: 1716 loss: 6.8781359e-05
Iter: 1717 loss: 6.86985295e-05
Iter: 1718 loss: 6.89491e-05
Iter: 1719 loss: 6.86734274e-05
Iter: 1720 loss: 6.85846171e-05
Iter: 1721 loss: 6.85668274e-05
Iter: 1722 loss: 6.85080959e-05
Iter: 1723 loss: 6.83884e-05
Iter: 1724 loss: 6.877337e-05
Iter: 1725 loss: 6.83543258e-05
Iter: 1726 loss: 6.82372192e-05
Iter: 1727 loss: 6.8661735e-05
Iter: 1728 loss: 6.82075843e-05
Iter: 1729 loss: 6.81118472e-05
Iter: 1730 loss: 6.87880456e-05
Iter: 1731 loss: 6.81032543e-05
Iter: 1732 loss: 6.80340236e-05
Iter: 1733 loss: 6.85821215e-05
Iter: 1734 loss: 6.80293961e-05
Iter: 1735 loss: 6.79779259e-05
Iter: 1736 loss: 6.81273668e-05
Iter: 1737 loss: 6.79620571e-05
Iter: 1738 loss: 6.79137447e-05
Iter: 1739 loss: 6.79031582e-05
Iter: 1740 loss: 6.7871908e-05
Iter: 1741 loss: 6.78142678e-05
Iter: 1742 loss: 6.81852398e-05
Iter: 1743 loss: 6.78078213e-05
Iter: 1744 loss: 6.77536e-05
Iter: 1745 loss: 6.78335491e-05
Iter: 1746 loss: 6.77277e-05
Iter: 1747 loss: 6.76724958e-05
Iter: 1748 loss: 6.78012148e-05
Iter: 1749 loss: 6.76519558e-05
Iter: 1750 loss: 6.75974297e-05
Iter: 1751 loss: 6.77469798e-05
Iter: 1752 loss: 6.75800402e-05
Iter: 1753 loss: 6.75189804e-05
Iter: 1754 loss: 6.75365e-05
Iter: 1755 loss: 6.74750772e-05
Iter: 1756 loss: 6.74061739e-05
Iter: 1757 loss: 6.75833726e-05
Iter: 1758 loss: 6.73826216e-05
Iter: 1759 loss: 6.73087852e-05
Iter: 1760 loss: 6.76021955e-05
Iter: 1761 loss: 6.72920796e-05
Iter: 1762 loss: 6.72320602e-05
Iter: 1763 loss: 6.75516931e-05
Iter: 1764 loss: 6.72230526e-05
Iter: 1765 loss: 6.71763482e-05
Iter: 1766 loss: 6.76555937e-05
Iter: 1767 loss: 6.71748785e-05
Iter: 1768 loss: 6.71426096e-05
Iter: 1769 loss: 6.72118113e-05
Iter: 1770 loss: 6.71306188e-05
Iter: 1771 loss: 6.70953887e-05
Iter: 1772 loss: 6.71185335e-05
Iter: 1773 loss: 6.70732479e-05
Iter: 1774 loss: 6.70414302e-05
Iter: 1775 loss: 6.71540329e-05
Iter: 1776 loss: 6.70333684e-05
Iter: 1777 loss: 6.6995708e-05
Iter: 1778 loss: 6.70468726e-05
Iter: 1779 loss: 6.69770234e-05
Iter: 1780 loss: 6.6937e-05
Iter: 1781 loss: 6.70211375e-05
Iter: 1782 loss: 6.69214e-05
Iter: 1783 loss: 6.68796711e-05
Iter: 1784 loss: 6.70420122e-05
Iter: 1785 loss: 6.68699358e-05
Iter: 1786 loss: 6.68308276e-05
Iter: 1787 loss: 6.68259599e-05
Iter: 1788 loss: 6.67977292e-05
Iter: 1789 loss: 6.67473359e-05
Iter: 1790 loss: 6.68876164e-05
Iter: 1791 loss: 6.67311106e-05
Iter: 1792 loss: 6.66784254e-05
Iter: 1793 loss: 6.68260182e-05
Iter: 1794 loss: 6.66613923e-05
Iter: 1795 loss: 6.66111e-05
Iter: 1796 loss: 6.69151632e-05
Iter: 1797 loss: 6.66046835e-05
Iter: 1798 loss: 6.65668485e-05
Iter: 1799 loss: 6.69239162e-05
Iter: 1800 loss: 6.65651314e-05
Iter: 1801 loss: 6.65382395e-05
Iter: 1802 loss: 6.66214182e-05
Iter: 1803 loss: 6.65303232e-05
Iter: 1804 loss: 6.65036205e-05
Iter: 1805 loss: 6.65044936e-05
Iter: 1806 loss: 6.6482804e-05
Iter: 1807 loss: 6.64504914e-05
Iter: 1808 loss: 6.65829721e-05
Iter: 1809 loss: 6.64435065e-05
Iter: 1810 loss: 6.64069375e-05
Iter: 1811 loss: 6.64300678e-05
Iter: 1812 loss: 6.63837272e-05
Iter: 1813 loss: 6.63395549e-05
Iter: 1814 loss: 6.64483232e-05
Iter: 1815 loss: 6.63236715e-05
Iter: 1816 loss: 6.62822276e-05
Iter: 1817 loss: 6.64003528e-05
Iter: 1818 loss: 6.62691164e-05
Iter: 1819 loss: 6.62223174e-05
Iter: 1820 loss: 6.62442471e-05
Iter: 1821 loss: 6.61907e-05
Iter: 1822 loss: 6.6137487e-05
Iter: 1823 loss: 6.62250386e-05
Iter: 1824 loss: 6.6113309e-05
Iter: 1825 loss: 6.60479564e-05
Iter: 1826 loss: 6.62693565e-05
Iter: 1827 loss: 6.60302903e-05
Iter: 1828 loss: 6.59710931e-05
Iter: 1829 loss: 6.62463717e-05
Iter: 1830 loss: 6.596e-05
Iter: 1831 loss: 6.59123616e-05
Iter: 1832 loss: 6.64286927e-05
Iter: 1833 loss: 6.59110374e-05
Iter: 1834 loss: 6.58789868e-05
Iter: 1835 loss: 6.5932385e-05
Iter: 1836 loss: 6.58641293e-05
Iter: 1837 loss: 6.58238787e-05
Iter: 1838 loss: 6.58399513e-05
Iter: 1839 loss: 6.57959245e-05
Iter: 1840 loss: 6.57519049e-05
Iter: 1841 loss: 6.58719582e-05
Iter: 1842 loss: 6.57378332e-05
Iter: 1843 loss: 6.56828e-05
Iter: 1844 loss: 6.57445271e-05
Iter: 1845 loss: 6.56527191e-05
Iter: 1846 loss: 6.55954354e-05
Iter: 1847 loss: 6.57114724e-05
Iter: 1848 loss: 6.55722761e-05
Iter: 1849 loss: 6.55109179e-05
Iter: 1850 loss: 6.57442288e-05
Iter: 1851 loss: 6.54962787e-05
Iter: 1852 loss: 6.54336618e-05
Iter: 1853 loss: 6.54609903e-05
Iter: 1854 loss: 6.53909738e-05
Iter: 1855 loss: 6.53178067e-05
Iter: 1856 loss: 6.54579344e-05
Iter: 1857 loss: 6.52868621e-05
Iter: 1858 loss: 6.52030649e-05
Iter: 1859 loss: 6.54165779e-05
Iter: 1860 loss: 6.51741721e-05
Iter: 1861 loss: 6.5089087e-05
Iter: 1862 loss: 6.55233598e-05
Iter: 1863 loss: 6.50751172e-05
Iter: 1864 loss: 6.50071597e-05
Iter: 1865 loss: 6.56552875e-05
Iter: 1866 loss: 6.50045404e-05
Iter: 1867 loss: 6.49549183e-05
Iter: 1868 loss: 6.50736183e-05
Iter: 1869 loss: 6.49370049e-05
Iter: 1870 loss: 6.4882639e-05
Iter: 1871 loss: 6.49065769e-05
Iter: 1872 loss: 6.48459609e-05
Iter: 1873 loss: 6.47871057e-05
Iter: 1874 loss: 6.50482e-05
Iter: 1875 loss: 6.47750931e-05
Iter: 1876 loss: 6.47114066e-05
Iter: 1877 loss: 6.47921624e-05
Iter: 1878 loss: 6.46785e-05
Iter: 1879 loss: 6.46112167e-05
Iter: 1880 loss: 6.47316847e-05
Iter: 1881 loss: 6.45819237e-05
Iter: 1882 loss: 6.45129621e-05
Iter: 1883 loss: 6.47165289e-05
Iter: 1884 loss: 6.44915563e-05
Iter: 1885 loss: 6.44149841e-05
Iter: 1886 loss: 6.44947504e-05
Iter: 1887 loss: 6.43723906e-05
Iter: 1888 loss: 6.42940722e-05
Iter: 1889 loss: 6.44223401e-05
Iter: 1890 loss: 6.42579471e-05
Iter: 1891 loss: 6.41591105e-05
Iter: 1892 loss: 6.44516113e-05
Iter: 1893 loss: 6.41287334e-05
Iter: 1894 loss: 6.40332437e-05
Iter: 1895 loss: 6.44281245e-05
Iter: 1896 loss: 6.40127037e-05
Iter: 1897 loss: 6.39348946e-05
Iter: 1898 loss: 6.48472778e-05
Iter: 1899 loss: 6.39336213e-05
Iter: 1900 loss: 6.38829515e-05
Iter: 1901 loss: 6.39858481e-05
Iter: 1902 loss: 6.3862557e-05
Iter: 1903 loss: 6.3805157e-05
Iter: 1904 loss: 6.38515703e-05
Iter: 1905 loss: 6.37706835e-05
Iter: 1906 loss: 6.37162157e-05
Iter: 1907 loss: 6.38721103e-05
Iter: 1908 loss: 6.36989425e-05
Iter: 1909 loss: 6.36307e-05
Iter: 1910 loss: 6.3732994e-05
Iter: 1911 loss: 6.35979377e-05
Iter: 1912 loss: 6.35292527e-05
Iter: 1913 loss: 6.36483237e-05
Iter: 1914 loss: 6.34988392e-05
Iter: 1915 loss: 6.34245225e-05
Iter: 1916 loss: 6.3659958e-05
Iter: 1917 loss: 6.3402942e-05
Iter: 1918 loss: 6.33251693e-05
Iter: 1919 loss: 6.34021126e-05
Iter: 1920 loss: 6.32813317e-05
Iter: 1921 loss: 6.31991934e-05
Iter: 1922 loss: 6.33295858e-05
Iter: 1923 loss: 6.31607545e-05
Iter: 1924 loss: 6.30579e-05
Iter: 1925 loss: 6.32975862e-05
Iter: 1926 loss: 6.30200375e-05
Iter: 1927 loss: 6.29131246e-05
Iter: 1928 loss: 6.34899625e-05
Iter: 1929 loss: 6.28971757e-05
Iter: 1930 loss: 6.28217531e-05
Iter: 1931 loss: 6.37320481e-05
Iter: 1932 loss: 6.28207927e-05
Iter: 1933 loss: 6.2770865e-05
Iter: 1934 loss: 6.28836424e-05
Iter: 1935 loss: 6.2752e-05
Iter: 1936 loss: 6.2695719e-05
Iter: 1937 loss: 6.27211339e-05
Iter: 1938 loss: 6.26574765e-05
Iter: 1939 loss: 6.25962493e-05
Iter: 1940 loss: 6.28346315e-05
Iter: 1941 loss: 6.25822577e-05
Iter: 1942 loss: 6.25153189e-05
Iter: 1943 loss: 6.25982721e-05
Iter: 1944 loss: 6.24805762e-05
Iter: 1945 loss: 6.2409963e-05
Iter: 1946 loss: 6.2547886e-05
Iter: 1947 loss: 6.23808592e-05
Iter: 1948 loss: 6.23087e-05
Iter: 1949 loss: 6.24715176e-05
Iter: 1950 loss: 6.22810185e-05
Iter: 1951 loss: 6.21961663e-05
Iter: 1952 loss: 6.2313964e-05
Iter: 1953 loss: 6.21538347e-05
Iter: 1954 loss: 6.20702e-05
Iter: 1955 loss: 6.216568e-05
Iter: 1956 loss: 6.20254432e-05
Iter: 1957 loss: 6.19151615e-05
Iter: 1958 loss: 6.23369924e-05
Iter: 1959 loss: 6.18887861e-05
Iter: 1960 loss: 6.17956612e-05
Iter: 1961 loss: 6.22679217e-05
Iter: 1962 loss: 6.17802507e-05
Iter: 1963 loss: 6.17134865e-05
Iter: 1964 loss: 6.25349858e-05
Iter: 1965 loss: 6.17129263e-05
Iter: 1966 loss: 6.16688121e-05
Iter: 1967 loss: 6.17456899e-05
Iter: 1968 loss: 6.1649509e-05
Iter: 1969 loss: 6.15966565e-05
Iter: 1970 loss: 6.16310717e-05
Iter: 1971 loss: 6.15631e-05
Iter: 1972 loss: 6.15111203e-05
Iter: 1973 loss: 6.16707e-05
Iter: 1974 loss: 6.14957535e-05
Iter: 1975 loss: 6.14337041e-05
Iter: 1976 loss: 6.15480094e-05
Iter: 1977 loss: 6.14069504e-05
Iter: 1978 loss: 6.13465e-05
Iter: 1979 loss: 6.14678429e-05
Iter: 1980 loss: 6.13215961e-05
Iter: 1981 loss: 6.12559379e-05
Iter: 1982 loss: 6.14171295e-05
Iter: 1983 loss: 6.1232553e-05
Iter: 1984 loss: 6.11591677e-05
Iter: 1985 loss: 6.1250008e-05
Iter: 1986 loss: 6.11208961e-05
Iter: 1987 loss: 6.10490897e-05
Iter: 1988 loss: 6.11964206e-05
Iter: 1989 loss: 6.10198949e-05
Iter: 1990 loss: 6.09435119e-05
Iter: 1991 loss: 6.12143194e-05
Iter: 1992 loss: 6.09238268e-05
Iter: 1993 loss: 6.08563314e-05
Iter: 1994 loss: 6.11883297e-05
Iter: 1995 loss: 6.0844759e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4
+ date
Tue Oct 27 19:24:39 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5f0e7812f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5f0e81de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5f0e81d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee86dcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee863c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8640598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee85ad8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee85db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee856c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee856cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee858a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee84ee8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee84ee9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee851c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee851c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee851c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee84830d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee84ee7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee83f89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee841e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee841ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee83d3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8386510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8334510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8334400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee83346a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee83208c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee82c6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee82c6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8276840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee822e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee822e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8245400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee8245e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee822e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ee82238c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.222070545
Iter: 2 loss: 2584.05835
Iter: 3 loss: 23563.5547
Iter: 4 loss: 9221.63086
Iter: 5 loss: 0.202081
Iter: 6 loss: 2519.59668
Iter: 7 loss: 0.202079907
Iter: 8 loss: 965.085327
Iter: 9 loss: 0.20207414
Iter: 10 loss: 1167.63757
Iter: 11 loss: 1328.51978
Iter: 12 loss: 122.764908
Iter: 13 loss: 511.44043
Iter: 14 loss: 164.521194
Iter: 15 loss: 0.176173761
Iter: 16 loss: 0.17403999
Iter: 17 loss: 0.173566908
Iter: 18 loss: 0.171014577
Iter: 19 loss: 0.170961469
Iter: 20 loss: 152.731079
Iter: 21 loss: 0.17095986
Iter: 22 loss: 0.182045847
Iter: 23 loss: 0.170793444
Iter: 24 loss: 0.17163901
Iter: 25 loss: 0.169808805
Iter: 26 loss: 0.169789881
Iter: 27 loss: 0.246168464
Iter: 28 loss: 0.168801248
Iter: 29 loss: 0.157917082
Iter: 30 loss: 0.157887191
Iter: 31 loss: 162.21402
Iter: 32 loss: 0.157744288
Iter: 33 loss: 15.7105885
Iter: 34 loss: 0.157738358
Iter: 35 loss: 0.217720255
Iter: 36 loss: 0.156740397
Iter: 37 loss: 0.143730536
Iter: 38 loss: 0.143648833
Iter: 39 loss: 210.770538
Iter: 40 loss: 200.534592
Iter: 41 loss: 0.143641755
Iter: 42 loss: 0.143551901
Iter: 43 loss: 0.141535461
Iter: 44 loss: 0.141493991
Iter: 45 loss: 0.140536189
Iter: 46 loss: 0.139986485
Iter: 47 loss: 0.247037396
Iter: 48 loss: 0.139989376
Iter: 49 loss: 0.141588897
Iter: 50 loss: 0.139802769
Iter: 51 loss: 0.139732838
Iter: 52 loss: 0.140272245
Iter: 53 loss: 0.139725283
Iter: 54 loss: 0.139656395
Iter: 55 loss: 0.139533579
Iter: 56 loss: 0.139530718
Iter: 57 loss: 0.139407098
Iter: 58 loss: 0.139122903
Iter: 59 loss: 0.166348651
Iter: 60 loss: 0.139117807
Iter: 61 loss: 0.138409227
Iter: 62 loss: 0.137201428
Iter: 63 loss: 0.191480502
Iter: 64 loss: 0.137131646
Iter: 65 loss: 0.20709984
Iter: 66 loss: 0.137025565
Iter: 67 loss: 0.133225679
Iter: 68 loss: 0.133215189
Iter: 69 loss: 0.13330774
Iter: 70 loss: 0.133125857
Iter: 71 loss: 0.13302891
Iter: 72 loss: 0.132837281
Iter: 73 loss: 0.142569214
Iter: 74 loss: 0.132836565
Iter: 75 loss: 0.132356882
Iter: 76 loss: 0.133186653
Iter: 77 loss: 0.132030144
Iter: 78 loss: 0.130939752
Iter: 79 loss: 0.13093406
Iter: 80 loss: 0.130426779
Iter: 81 loss: 0.129970849
Iter: 82 loss: 0.128180817
Iter: 83 loss: 0.198537499
Iter: 84 loss: 0.128160253
Iter: 85 loss: 0.125883162
Iter: 86 loss: 0.134454027
Iter: 87 loss: 0.12505284
Iter: 88 loss: 0.124232918
Iter: 89 loss: 0.126267523
Iter: 90 loss: 0.124435596
Iter: 91 loss: 0.124104083
Iter: 92 loss: 0.128479213
Iter: 93 loss: 0.124090746
Iter: 94 loss: 0.123671308
Iter: 95 loss: 0.131791934
Iter: 96 loss: 0.123661689
Iter: 97 loss: 0.122991472
Iter: 98 loss: 0.121158622
Iter: 99 loss: 0.136195391
Iter: 100 loss: 0.120687209
Iter: 101 loss: 0.118794277
Iter: 102 loss: 0.118632972
Iter: 103 loss: 0.117073759
Iter: 104 loss: 0.117055297
Iter: 105 loss: 0.113412201
Iter: 106 loss: 0.263908535
Iter: 107 loss: 0.113412164
Iter: 108 loss: 0.111266211
Iter: 109 loss: 0.11097461
Iter: 110 loss: 0.109887704
Iter: 111 loss: 0.109222092
Iter: 112 loss: 0.106673867
Iter: 113 loss: 0.105979443
Iter: 114 loss: 0.105507538
Iter: 115 loss: 0.101358548
Iter: 116 loss: 0.100390628
Iter: 117 loss: 0.104987875
Iter: 118 loss: 0.0986329466
Iter: 119 loss: 0.0994216055
Iter: 120 loss: 0.0944410935
Iter: 121 loss: 0.361141294
Iter: 122 loss: 0.0943132415
Iter: 123 loss: 0.0939636827
Iter: 124 loss: 0.092823714
Iter: 125 loss: 0.0910585076
Iter: 126 loss: 0.090282768
Iter: 127 loss: 0.0865432248
Iter: 128 loss: 0.116956711
Iter: 129 loss: 0.086347796
Iter: 130 loss: 0.0840693638
Iter: 131 loss: 0.0840625763
Iter: 132 loss: 0.0827826
Iter: 133 loss: 0.0857039541
Iter: 134 loss: 0.0822207
Iter: 135 loss: 0.0787797
Iter: 136 loss: 0.086278446
Iter: 137 loss: 0.0785085112
Iter: 138 loss: 0.0775814056
Iter: 139 loss: 0.0757392868
Iter: 140 loss: 0.0855431855
Iter: 141 loss: 0.0751479715
Iter: 142 loss: 0.0741377
Iter: 143 loss: 0.0736924857
Iter: 144 loss: 0.0723627359
Iter: 145 loss: 0.0821635276
Iter: 146 loss: 0.0721454248
Iter: 147 loss: 0.0704580247
Iter: 148 loss: 0.077182889
Iter: 149 loss: 0.0699991137
Iter: 150 loss: 0.0678441152
Iter: 151 loss: 0.110378556
Iter: 152 loss: 0.0678009912
Iter: 153 loss: 0.0673581213
Iter: 154 loss: 0.0665714294
Iter: 155 loss: 0.0650231689
Iter: 156 loss: 0.0768124163
Iter: 157 loss: 0.0649810582
Iter: 158 loss: 0.0636048093
Iter: 159 loss: 0.0641021878
Iter: 160 loss: 0.0626720339
Iter: 161 loss: 0.0618885942
Iter: 162 loss: 0.0618856475
Iter: 163 loss: 0.0617021397
Iter: 164 loss: 0.062081147
Iter: 165 loss: 0.0616218671
Iter: 166 loss: 0.060714975
Iter: 167 loss: 0.0658086836
Iter: 168 loss: 0.060549207
Iter: 169 loss: 0.059231136
Iter: 170 loss: 0.0632127821
Iter: 171 loss: 0.0587264076
Iter: 172 loss: 0.05755312
Iter: 173 loss: 0.0664475113
Iter: 174 loss: 0.057494469
Iter: 175 loss: 0.056939967
Iter: 176 loss: 0.0607324764
Iter: 177 loss: 0.0568486266
Iter: 178 loss: 0.0566608086
Iter: 179 loss: 0.0585889742
Iter: 180 loss: 0.0566522926
Iter: 181 loss: 0.0565060675
Iter: 182 loss: 0.0568951666
Iter: 183 loss: 0.056461446
Iter: 184 loss: 0.0561853945
Iter: 185 loss: 0.055975914
Iter: 186 loss: 0.0558995195
Iter: 187 loss: 0.0554933436
Iter: 188 loss: 0.0549171641
Iter: 189 loss: 0.0548749194
Iter: 190 loss: 0.0538893268
Iter: 191 loss: 0.0551022738
Iter: 192 loss: 0.0532676652
Iter: 193 loss: 0.0531047583
Iter: 194 loss: 0.0525773689
Iter: 195 loss: 0.0517003499
Iter: 196 loss: 0.0514127836
Iter: 197 loss: 0.0509021208
Iter: 198 loss: 0.0504188053
Iter: 199 loss: 0.0503198579
Iter: 200 loss: 0.0494105518
Iter: 201 loss: 0.0507367887
Iter: 202 loss: 0.0489248857
Iter: 203 loss: 0.0481846258
Iter: 204 loss: 0.0514421836
Iter: 205 loss: 0.0480380952
Iter: 206 loss: 0.0485826805
Iter: 207 loss: 0.0475654043
Iter: 208 loss: 0.0472101197
Iter: 209 loss: 0.05066479
Iter: 210 loss: 0.0472045019
Iter: 211 loss: 0.0469724089
Iter: 212 loss: 0.0465358868
Iter: 213 loss: 0.0543803908
Iter: 214 loss: 0.0465337709
Iter: 215 loss: 0.045292072
Iter: 216 loss: 0.0540291108
Iter: 217 loss: 0.0450646952
Iter: 218 loss: 0.0446774
Iter: 219 loss: 0.0445341952
Iter: 220 loss: 0.0437853783
Iter: 221 loss: 0.05469843
Iter: 222 loss: 0.0437562689
Iter: 223 loss: 0.0432956
Iter: 224 loss: 0.0450568199
Iter: 225 loss: 0.043171104
Iter: 226 loss: 0.0429254696
Iter: 227 loss: 0.0426047891
Iter: 228 loss: 0.0425849557
Iter: 229 loss: 0.0422292501
Iter: 230 loss: 0.042029731
Iter: 231 loss: 0.0418520831
Iter: 232 loss: 0.0415731668
Iter: 233 loss: 0.0420384482
Iter: 234 loss: 0.0414319038
Iter: 235 loss: 0.0409553759
Iter: 236 loss: 0.0412446074
Iter: 237 loss: 0.0406351425
Iter: 238 loss: 0.0400714874
Iter: 239 loss: 0.0418520235
Iter: 240 loss: 0.0398978367
Iter: 241 loss: 0.0431989282
Iter: 242 loss: 0.0395003706
Iter: 243 loss: 0.0388496555
Iter: 244 loss: 0.0421343818
Iter: 245 loss: 0.038694948
Iter: 246 loss: 0.0382969454
Iter: 247 loss: 0.0407360606
Iter: 248 loss: 0.0382137671
Iter: 249 loss: 0.0377190411
Iter: 250 loss: 0.038432613
Iter: 251 loss: 0.0375132822
Iter: 252 loss: 0.0370541774
Iter: 253 loss: 0.0376309976
Iter: 254 loss: 0.0368179902
Iter: 255 loss: 0.0361856036
Iter: 256 loss: 0.0372434407
Iter: 257 loss: 0.0359214619
Iter: 258 loss: 0.0358017087
Iter: 259 loss: 0.0356061906
Iter: 260 loss: 0.0354135782
Iter: 261 loss: 0.0356103592
Iter: 262 loss: 0.0353074186
Iter: 263 loss: 0.0349891037
Iter: 264 loss: 0.0364877693
Iter: 265 loss: 0.0349281207
Iter: 266 loss: 0.034742184
Iter: 267 loss: 0.0347421691
Iter: 268 loss: 0.0345847458
Iter: 269 loss: 0.0344588235
Iter: 270 loss: 0.0344154239
Iter: 271 loss: 0.0341720507
Iter: 272 loss: 0.0345007926
Iter: 273 loss: 0.0340492651
Iter: 274 loss: 0.0338855423
Iter: 275 loss: 0.0343024582
Iter: 276 loss: 0.0338404737
Iter: 277 loss: 0.0335447304
Iter: 278 loss: 0.0332742929
Iter: 279 loss: 0.0331958421
Iter: 280 loss: 0.0323858112
Iter: 281 loss: 0.0343739092
Iter: 282 loss: 0.0320722573
Iter: 283 loss: 0.0312835872
Iter: 284 loss: 0.0312730707
Iter: 285 loss: 0.0362829715
Iter: 286 loss: 0.0309843458
Iter: 287 loss: 0.0306954123
Iter: 288 loss: 0.033364635
Iter: 289 loss: 0.0306891724
Iter: 290 loss: 0.0304331239
Iter: 291 loss: 0.0309899878
Iter: 292 loss: 0.030331837
Iter: 293 loss: 0.0300312918
Iter: 294 loss: 0.0300385039
Iter: 295 loss: 0.0297809038
Iter: 296 loss: 0.0292924903
Iter: 297 loss: 0.0298108533
Iter: 298 loss: 0.0290234089
Iter: 299 loss: 0.0291502401
Iter: 300 loss: 0.0288080648
Iter: 301 loss: 0.0285301153
Iter: 302 loss: 0.0310565904
Iter: 303 loss: 0.0285064038
Iter: 304 loss: 0.0279000141
Iter: 305 loss: 0.0366303734
Iter: 306 loss: 0.027885478
Iter: 307 loss: 0.027317591
Iter: 308 loss: 0.0297838133
Iter: 309 loss: 0.027210027
Iter: 310 loss: 0.0267491676
Iter: 311 loss: 0.0336072892
Iter: 312 loss: 0.0267457198
Iter: 313 loss: 0.0264550932
Iter: 314 loss: 0.0303132646
Iter: 315 loss: 0.026454933
Iter: 316 loss: 0.0263381377
Iter: 317 loss: 0.0261269677
Iter: 318 loss: 0.0314215049
Iter: 319 loss: 0.026126761
Iter: 320 loss: 0.0259693451
Iter: 321 loss: 0.0272650272
Iter: 322 loss: 0.0259619635
Iter: 323 loss: 0.0258636959
Iter: 324 loss: 0.0260148831
Iter: 325 loss: 0.0258146115
Iter: 326 loss: 0.0257029459
Iter: 327 loss: 0.0257470906
Iter: 328 loss: 0.0256215837
Iter: 329 loss: 0.0254764296
Iter: 330 loss: 0.0252585951
Iter: 331 loss: 0.025254149
Iter: 332 loss: 0.0249863416
Iter: 333 loss: 0.0254212059
Iter: 334 loss: 0.0248604082
Iter: 335 loss: 0.0245183483
Iter: 336 loss: 0.0253829695
Iter: 337 loss: 0.0243875645
Iter: 338 loss: 0.0241466649
Iter: 339 loss: 0.0250640139
Iter: 340 loss: 0.0240930356
Iter: 341 loss: 0.0238137431
Iter: 342 loss: 0.0240674261
Iter: 343 loss: 0.0236726385
Iter: 344 loss: 0.0234701708
Iter: 345 loss: 0.0234699324
Iter: 346 loss: 0.0233526975
Iter: 347 loss: 0.0244571529
Iter: 348 loss: 0.0233495329
Iter: 349 loss: 0.0232890882
Iter: 350 loss: 0.0232485309
Iter: 351 loss: 0.023226982
Iter: 352 loss: 0.0229453631
Iter: 353 loss: 0.0245876499
Iter: 354 loss: 0.0229206681
Iter: 355 loss: 0.02260039
Iter: 356 loss: 0.0225990564
Iter: 357 loss: 0.0225104392
Iter: 358 loss: 0.022601068
Iter: 359 loss: 0.0224615969
Iter: 360 loss: 0.022274103
Iter: 361 loss: 0.022725692
Iter: 362 loss: 0.0221999343
Iter: 363 loss: 0.0220350213
Iter: 364 loss: 0.0225569699
Iter: 365 loss: 0.021985298
Iter: 366 loss: 0.0216790363
Iter: 367 loss: 0.0240897033
Iter: 368 loss: 0.0216551647
Iter: 369 loss: 0.02138393
Iter: 370 loss: 0.0235195383
Iter: 371 loss: 0.0213626828
Iter: 372 loss: 0.0211548917
Iter: 373 loss: 0.0210174173
Iter: 374 loss: 0.0209305137
Iter: 375 loss: 0.0207112227
Iter: 376 loss: 0.0213377737
Iter: 377 loss: 0.0206415169
Iter: 378 loss: 0.0205121469
Iter: 379 loss: 0.0209928378
Iter: 380 loss: 0.0204793774
Iter: 381 loss: 0.0202985592
Iter: 382 loss: 0.0202815346
Iter: 383 loss: 0.0202061534
Iter: 384 loss: 0.0206650291
Iter: 385 loss: 0.0201960392
Iter: 386 loss: 0.020167686
Iter: 387 loss: 0.0200797953
Iter: 388 loss: 0.0202357676
Iter: 389 loss: 0.0200231299
Iter: 390 loss: 0.0199513827
Iter: 391 loss: 0.0199018233
Iter: 392 loss: 0.0197100081
Iter: 393 loss: 0.0223119184
Iter: 394 loss: 0.0197100583
Iter: 395 loss: 0.0196652394
Iter: 396 loss: 0.0196384825
Iter: 397 loss: 0.019620087
Iter: 398 loss: 0.0194877498
Iter: 399 loss: 0.0194535069
Iter: 400 loss: 0.0193710849
Iter: 401 loss: 0.0191536918
Iter: 402 loss: 0.0201630536
Iter: 403 loss: 0.0190985799
Iter: 404 loss: 0.0189549625
Iter: 405 loss: 0.0187893957
Iter: 406 loss: 0.0187681541
Iter: 407 loss: 0.0184997432
Iter: 408 loss: 0.0186835174
Iter: 409 loss: 0.0183270089
Iter: 410 loss: 0.0182607975
Iter: 411 loss: 0.0181581303
Iter: 412 loss: 0.0180218462
Iter: 413 loss: 0.0180212203
Iter: 414 loss: 0.0179627
Iter: 415 loss: 0.0180376563
Iter: 416 loss: 0.0179307181
Iter: 417 loss: 0.0178655181
Iter: 418 loss: 0.0177606829
Iter: 419 loss: 0.0177598651
Iter: 420 loss: 0.0176388957
Iter: 421 loss: 0.018217396
Iter: 422 loss: 0.0176157448
Iter: 423 loss: 0.0175330937
Iter: 424 loss: 0.018306179
Iter: 425 loss: 0.0175307728
Iter: 426 loss: 0.0174317211
Iter: 427 loss: 0.0174198821
Iter: 428 loss: 0.0173467156
Iter: 429 loss: 0.0172706731
Iter: 430 loss: 0.0174456984
Iter: 431 loss: 0.0172433145
Iter: 432 loss: 0.017162919
Iter: 433 loss: 0.0174710713
Iter: 434 loss: 0.0171438288
Iter: 435 loss: 0.01704631
Iter: 436 loss: 0.0169143304
Iter: 437 loss: 0.0169077236
Iter: 438 loss: 0.0166568309
Iter: 439 loss: 0.0172703322
Iter: 440 loss: 0.0165825617
Iter: 441 loss: 0.0164215192
Iter: 442 loss: 0.0174848363
Iter: 443 loss: 0.0164002702
Iter: 444 loss: 0.0162950773
Iter: 445 loss: 0.0165612791
Iter: 446 loss: 0.0162590891
Iter: 447 loss: 0.0161720365
Iter: 448 loss: 0.0164171271
Iter: 449 loss: 0.0161467176
Iter: 450 loss: 0.0160909705
Iter: 451 loss: 0.0165211186
Iter: 452 loss: 0.0160864051
Iter: 453 loss: 0.0160339884
Iter: 454 loss: 0.0160708539
Iter: 455 loss: 0.0160004366
Iter: 456 loss: 0.0159314573
Iter: 457 loss: 0.0160149671
Iter: 458 loss: 0.0158961471
Iter: 459 loss: 0.0158527251
Iter: 460 loss: 0.015835885
Iter: 461 loss: 0.0157773141
Iter: 462 loss: 0.0158152618
Iter: 463 loss: 0.015740104
Iter: 464 loss: 0.0155986985
Iter: 465 loss: 0.0155472858
Iter: 466 loss: 0.0154688656
Iter: 467 loss: 0.0153058022
Iter: 468 loss: 0.0159419626
Iter: 469 loss: 0.0152701885
Iter: 470 loss: 0.015159782
Iter: 471 loss: 0.0154408794
Iter: 472 loss: 0.0151235247
Iter: 473 loss: 0.0152503783
Iter: 474 loss: 0.0150817297
Iter: 475 loss: 0.0150517374
Iter: 476 loss: 0.0151228216
Iter: 477 loss: 0.0150401648
Iter: 478 loss: 0.0149445869
Iter: 479 loss: 0.0151840141
Iter: 480 loss: 0.0149117578
Iter: 481 loss: 0.0148376916
Iter: 482 loss: 0.0148373805
Iter: 483 loss: 0.0147372857
Iter: 484 loss: 0.0149336606
Iter: 485 loss: 0.014697805
Iter: 486 loss: 0.0146198589
Iter: 487 loss: 0.0145981517
Iter: 488 loss: 0.0145501662
Iter: 489 loss: 0.0146191008
Iter: 490 loss: 0.014522016
Iter: 491 loss: 0.0144857261
Iter: 492 loss: 0.0144311152
Iter: 493 loss: 0.0144301848
Iter: 494 loss: 0.0142340343
Iter: 495 loss: 0.015248891
Iter: 496 loss: 0.0142036676
Iter: 497 loss: 0.0140757021
Iter: 498 loss: 0.0151238684
Iter: 499 loss: 0.0140716247
Iter: 500 loss: 0.0139982495
Iter: 501 loss: 0.0139636528
Iter: 502 loss: 0.0139257312
Iter: 503 loss: 0.0138747189
Iter: 504 loss: 0.0138316136
Iter: 505 loss: 0.0138179194
Iter: 506 loss: 0.0137570826
Iter: 507 loss: 0.014592072
Iter: 508 loss: 0.0137563916
Iter: 509 loss: 0.0137106786
Iter: 510 loss: 0.0138099547
Iter: 511 loss: 0.0136929573
Iter: 512 loss: 0.0136103248
Iter: 513 loss: 0.0137230754
Iter: 514 loss: 0.01356869
Iter: 515 loss: 0.0137835797
Iter: 516 loss: 0.013495829
Iter: 517 loss: 0.0134469597
Iter: 518 loss: 0.0134506598
Iter: 519 loss: 0.0134092262
Iter: 520 loss: 0.0133977262
Iter: 521 loss: 0.0133803934
Iter: 522 loss: 0.0133370934
Iter: 523 loss: 0.0133614819
Iter: 524 loss: 0.0133092627
Iter: 525 loss: 0.0132315792
Iter: 526 loss: 0.013309136
Iter: 527 loss: 0.0131902583
Iter: 528 loss: 0.0131168934
Iter: 529 loss: 0.013115597
Iter: 530 loss: 0.0130385291
Iter: 531 loss: 0.0134937763
Iter: 532 loss: 0.0130263567
Iter: 533 loss: 0.0129753463
Iter: 534 loss: 0.0129665323
Iter: 535 loss: 0.0129327383
Iter: 536 loss: 0.0128501169
Iter: 537 loss: 0.0132470494
Iter: 538 loss: 0.0128339175
Iter: 539 loss: 0.0127477013
Iter: 540 loss: 0.0132421684
Iter: 541 loss: 0.0127360281
Iter: 542 loss: 0.0126849208
Iter: 543 loss: 0.0127707459
Iter: 544 loss: 0.0126618342
Iter: 545 loss: 0.012612096
Iter: 546 loss: 0.0129050519
Iter: 547 loss: 0.0126059391
Iter: 548 loss: 0.0125561813
Iter: 549 loss: 0.0126829334
Iter: 550 loss: 0.0125382636
Iter: 551 loss: 0.0124946041
Iter: 552 loss: 0.0124980174
Iter: 553 loss: 0.0124599962
Iter: 554 loss: 0.0123992031
Iter: 555 loss: 0.0123969391
Iter: 556 loss: 0.0123691112
Iter: 557 loss: 0.0123882592
Iter: 558 loss: 0.0123515418
Iter: 559 loss: 0.0123167513
Iter: 560 loss: 0.0122644203
Iter: 561 loss: 0.0122632086
Iter: 562 loss: 0.0121911056
Iter: 563 loss: 0.0132554136
Iter: 564 loss: 0.0121910982
Iter: 565 loss: 0.0121456683
Iter: 566 loss: 0.0122196171
Iter: 567 loss: 0.0121239051
Iter: 568 loss: 0.0120756645
Iter: 569 loss: 0.0120881358
Iter: 570 loss: 0.0120406263
Iter: 571 loss: 0.0119790984
Iter: 572 loss: 0.0119714551
Iter: 573 loss: 0.0119323768
Iter: 574 loss: 0.0118831648
Iter: 575 loss: 0.0118797012
Iter: 576 loss: 0.0117884837
Iter: 577 loss: 0.0118077807
Iter: 578 loss: 0.0117215943
Iter: 579 loss: 0.0116589759
Iter: 580 loss: 0.012551113
Iter: 581 loss: 0.0116586536
Iter: 582 loss: 0.0115912789
Iter: 583 loss: 0.0119700264
Iter: 584 loss: 0.0115803704
Iter: 585 loss: 0.0115544051
Iter: 586 loss: 0.0115543762
Iter: 587 loss: 0.0115308147
Iter: 588 loss: 0.0117583573
Iter: 589 loss: 0.0115297362
Iter: 590 loss: 0.0115042198
Iter: 591 loss: 0.0114578316
Iter: 592 loss: 0.0126157058
Iter: 593 loss: 0.0114577822
Iter: 594 loss: 0.0113668423
Iter: 595 loss: 0.0120150931
Iter: 596 loss: 0.0113597559
Iter: 597 loss: 0.0112753846
Iter: 598 loss: 0.0120894108
Iter: 599 loss: 0.0112717263
Iter: 600 loss: 0.0112373102
Iter: 601 loss: 0.0111973817
Iter: 602 loss: 0.0111925723
Iter: 603 loss: 0.0111423982
Iter: 604 loss: 0.0112019461
Iter: 605 loss: 0.0111158378
Iter: 606 loss: 0.0110665
Iter: 607 loss: 0.0110478029
Iter: 608 loss: 0.0110208848
Iter: 609 loss: 0.0109341964
Iter: 610 loss: 0.0116654783
Iter: 611 loss: 0.0109300837
Iter: 612 loss: 0.0108781187
Iter: 613 loss: 0.0117465388
Iter: 614 loss: 0.0108779594
Iter: 615 loss: 0.0108462973
Iter: 616 loss: 0.0108458139
Iter: 617 loss: 0.0108291823
Iter: 618 loss: 0.0109178992
Iter: 619 loss: 0.0108267032
Iter: 620 loss: 0.0108085293
Iter: 621 loss: 0.0108509976
Iter: 622 loss: 0.0108015472
Iter: 623 loss: 0.0107587948
Iter: 624 loss: 0.0106740836
Iter: 625 loss: 0.0123787038
Iter: 626 loss: 0.0106732138
Iter: 627 loss: 0.0105948895
Iter: 628 loss: 0.010866181
Iter: 629 loss: 0.0105757006
Iter: 630 loss: 0.010509748
Iter: 631 loss: 0.0113010369
Iter: 632 loss: 0.0105089676
Iter: 633 loss: 0.0104443794
Iter: 634 loss: 0.010657277
Iter: 635 loss: 0.0104266349
Iter: 636 loss: 0.0103933867
Iter: 637 loss: 0.0103929648
Iter: 638 loss: 0.0103646656
Iter: 639 loss: 0.0103651192
Iter: 640 loss: 0.0103417328
Iter: 641 loss: 0.0103102624
Iter: 642 loss: 0.010300044
Iter: 643 loss: 0.0102821635
Iter: 644 loss: 0.0102443192
Iter: 645 loss: 0.010194038
Iter: 646 loss: 0.0101910196
Iter: 647 loss: 0.0101533644
Iter: 648 loss: 0.0101468656
Iter: 649 loss: 0.0101218261
Iter: 650 loss: 0.0100884233
Iter: 651 loss: 0.0100455154
Iter: 652 loss: 0.0100424178
Iter: 653 loss: 0.0100535359
Iter: 654 loss: 0.010018127
Iter: 655 loss: 0.0100008519
Iter: 656 loss: 0.0100186076
Iter: 657 loss: 0.00999138225
Iter: 658 loss: 0.00997563452
Iter: 659 loss: 0.00994134694
Iter: 660 loss: 0.010528313
Iter: 661 loss: 0.00994003285
Iter: 662 loss: 0.009858937
Iter: 663 loss: 0.00985586084
Iter: 664 loss: 0.00977733545
Iter: 665 loss: 0.0101007931
Iter: 666 loss: 0.00975961424
Iter: 667 loss: 0.00971010886
Iter: 668 loss: 0.010334339
Iter: 669 loss: 0.00970973074
Iter: 670 loss: 0.00967569
Iter: 671 loss: 0.00977744348
Iter: 672 loss: 0.00966525
Iter: 673 loss: 0.00962052
Iter: 674 loss: 0.00960501842
Iter: 675 loss: 0.00957927667
Iter: 676 loss: 0.00951953139
Iter: 677 loss: 0.00993784145
Iter: 678 loss: 0.00951472
Iter: 679 loss: 0.00953657553
Iter: 680 loss: 0.00948730111
Iter: 681 loss: 0.00947164185
Iter: 682 loss: 0.00944961794
Iter: 683 loss: 0.009448695
Iter: 684 loss: 0.00942324568
Iter: 685 loss: 0.00943196379
Iter: 686 loss: 0.00940528698
Iter: 687 loss: 0.00936105195
Iter: 688 loss: 0.0094746314
Iter: 689 loss: 0.00934562832
Iter: 690 loss: 0.00933157466
Iter: 691 loss: 0.00932542
Iter: 692 loss: 0.00929904729
Iter: 693 loss: 0.00929386728
Iter: 694 loss: 0.00927612185
Iter: 695 loss: 0.00925512705
Iter: 696 loss: 0.00923499092
Iter: 697 loss: 0.00923042838
Iter: 698 loss: 0.00919091702
Iter: 699 loss: 0.00915101916
Iter: 700 loss: 0.00914348103
Iter: 701 loss: 0.0090853041
Iter: 702 loss: 0.00945012271
Iter: 703 loss: 0.00907822885
Iter: 704 loss: 0.00904644839
Iter: 705 loss: 0.00904396735
Iter: 706 loss: 0.00901403185
Iter: 707 loss: 0.00899479166
Iter: 708 loss: 0.00898321159
Iter: 709 loss: 0.00896360911
Iter: 710 loss: 0.00896126404
Iter: 711 loss: 0.00894873
Iter: 712 loss: 0.00895257294
Iter: 713 loss: 0.00893971
Iter: 714 loss: 0.00892101787
Iter: 715 loss: 0.00890573859
Iter: 716 loss: 0.00890046172
Iter: 717 loss: 0.00887110457
Iter: 718 loss: 0.00896850415
Iter: 719 loss: 0.00886251125
Iter: 720 loss: 0.00883128401
Iter: 721 loss: 0.00878381543
Iter: 722 loss: 0.00878299773
Iter: 723 loss: 0.00874643866
Iter: 724 loss: 0.00874601118
Iter: 725 loss: 0.00872981269
Iter: 726 loss: 0.00874175876
Iter: 727 loss: 0.00872013345
Iter: 728 loss: 0.00870041084
Iter: 729 loss: 0.00871269777
Iter: 730 loss: 0.00868784077
Iter: 731 loss: 0.00866140239
Iter: 732 loss: 0.0086338222
Iter: 733 loss: 0.00862877909
Iter: 734 loss: 0.00860443152
Iter: 735 loss: 0.00860243849
Iter: 736 loss: 0.00857616402
Iter: 737 loss: 0.00853962731
Iter: 738 loss: 0.00853802264
Iter: 739 loss: 0.00850790273
Iter: 740 loss: 0.00850636885
Iter: 741 loss: 0.0084721949
Iter: 742 loss: 0.00877764542
Iter: 743 loss: 0.00847002119
Iter: 744 loss: 0.00846098922
Iter: 745 loss: 0.008432284
Iter: 746 loss: 0.00846853293
Iter: 747 loss: 0.00841092132
Iter: 748 loss: 0.00834128633
Iter: 749 loss: 0.00889942236
Iter: 750 loss: 0.0083363289
Iter: 751 loss: 0.00829315651
Iter: 752 loss: 0.00868392549
Iter: 753 loss: 0.00829180144
Iter: 754 loss: 0.00827271864
Iter: 755 loss: 0.00834776182
Iter: 756 loss: 0.00826818496
Iter: 757 loss: 0.008251369
Iter: 758 loss: 0.00822282769
Iter: 759 loss: 0.00822281372
Iter: 760 loss: 0.00819818676
Iter: 761 loss: 0.00817795284
Iter: 762 loss: 0.00817059539
Iter: 763 loss: 0.00813574716
Iter: 764 loss: 0.00815278664
Iter: 765 loss: 0.00811207667
Iter: 766 loss: 0.00807155576
Iter: 767 loss: 0.00803266
Iter: 768 loss: 0.00802338589
Iter: 769 loss: 0.00797870569
Iter: 770 loss: 0.00797486864
Iter: 771 loss: 0.0079421727
Iter: 772 loss: 0.00809859391
Iter: 773 loss: 0.00793632865
Iter: 774 loss: 0.00793873
Iter: 775 loss: 0.00792413857
Iter: 776 loss: 0.0079139173
Iter: 777 loss: 0.00789795909
Iter: 778 loss: 0.00789774489
Iter: 779 loss: 0.00787454937
Iter: 780 loss: 0.00793591514
Iter: 781 loss: 0.00786712207
Iter: 782 loss: 0.007851406
Iter: 783 loss: 0.00787008088
Iter: 784 loss: 0.00784297287
Iter: 785 loss: 0.00784052163
Iter: 786 loss: 0.00783551391
Iter: 787 loss: 0.00782970805
Iter: 788 loss: 0.00782436319
Iter: 789 loss: 0.0078229215
Iter: 790 loss: 0.00780892093
Iter: 791 loss: 0.00778477546
Iter: 792 loss: 0.00778473634
Iter: 793 loss: 0.0077289
Iter: 794 loss: 0.00806215685
Iter: 795 loss: 0.00772211514
Iter: 796 loss: 0.00767535949
Iter: 797 loss: 0.00793933868
Iter: 798 loss: 0.00766785629
Iter: 799 loss: 0.00762631
Iter: 800 loss: 0.00792281702
Iter: 801 loss: 0.00762293674
Iter: 802 loss: 0.00760131609
Iter: 803 loss: 0.00768841757
Iter: 804 loss: 0.00759637682
Iter: 805 loss: 0.00757974386
Iter: 806 loss: 0.00768287526
Iter: 807 loss: 0.00757762697
Iter: 808 loss: 0.00755050313
Iter: 809 loss: 0.00751706772
Iter: 810 loss: 0.00751401624
Iter: 811 loss: 0.00748806773
Iter: 812 loss: 0.0078447964
Iter: 813 loss: 0.00748804491
Iter: 814 loss: 0.00747549906
Iter: 815 loss: 0.00759273395
Iter: 816 loss: 0.00747489277
Iter: 817 loss: 0.00746820169
Iter: 818 loss: 0.00753036235
Iter: 819 loss: 0.00746796373
Iter: 820 loss: 0.00745863281
Iter: 821 loss: 0.00744981598
Iter: 822 loss: 0.00744766509
Iter: 823 loss: 0.0074299546
Iter: 824 loss: 0.00740455277
Iter: 825 loss: 0.0074037984
Iter: 826 loss: 0.00735829119
Iter: 827 loss: 0.00741197728
Iter: 828 loss: 0.00733432407
Iter: 829 loss: 0.00729305204
Iter: 830 loss: 0.007292822
Iter: 831 loss: 0.0072572045
Iter: 832 loss: 0.00731274066
Iter: 833 loss: 0.00723958062
Iter: 834 loss: 0.0072145178
Iter: 835 loss: 0.00731022842
Iter: 836 loss: 0.007208711
Iter: 837 loss: 0.00718546566
Iter: 838 loss: 0.0072628418
Iter: 839 loss: 0.00717887189
Iter: 840 loss: 0.0071636159
Iter: 841 loss: 0.00731054507
Iter: 842 loss: 0.00716315955
Iter: 843 loss: 0.00714737503
Iter: 844 loss: 0.00712400395
Iter: 845 loss: 0.00712339487
Iter: 846 loss: 0.00710642943
Iter: 847 loss: 0.00708224392
Iter: 848 loss: 0.00708143413
Iter: 849 loss: 0.00715443632
Iter: 850 loss: 0.00706921751
Iter: 851 loss: 0.00703629432
Iter: 852 loss: 0.00709875813
Iter: 853 loss: 0.00702288561
Iter: 854 loss: 0.00700245565
Iter: 855 loss: 0.00703989156
Iter: 856 loss: 0.0069939862
Iter: 857 loss: 0.00696579553
Iter: 858 loss: 0.00699493941
Iter: 859 loss: 0.00694992393
Iter: 860 loss: 0.00692961458
Iter: 861 loss: 0.00693578506
Iter: 862 loss: 0.00691528758
Iter: 863 loss: 0.00688284822
Iter: 864 loss: 0.00697216112
Iter: 865 loss: 0.00687186047
Iter: 866 loss: 0.00683923252
Iter: 867 loss: 0.00690121669
Iter: 868 loss: 0.00682563335
Iter: 869 loss: 0.00680298917
Iter: 870 loss: 0.00680291047
Iter: 871 loss: 0.00678946497
Iter: 872 loss: 0.0067894645
Iter: 873 loss: 0.00677907933
Iter: 874 loss: 0.00678873155
Iter: 875 loss: 0.00677318219
Iter: 876 loss: 0.00676145544
Iter: 877 loss: 0.00672759209
Iter: 878 loss: 0.00686750747
Iter: 879 loss: 0.00671425
Iter: 880 loss: 0.00672371453
Iter: 881 loss: 0.00670265034
Iter: 882 loss: 0.0066864118
Iter: 883 loss: 0.00671776617
Iter: 884 loss: 0.00667955074
Iter: 885 loss: 0.00666335085
Iter: 886 loss: 0.0066940221
Iter: 887 loss: 0.00665687
Iter: 888 loss: 0.00664070714
Iter: 889 loss: 0.00667114928
Iter: 890 loss: 0.0066336086
Iter: 891 loss: 0.00662439503
Iter: 892 loss: 0.00661252812
Iter: 893 loss: 0.00661169831
Iter: 894 loss: 0.00659098104
Iter: 895 loss: 0.00658495491
Iter: 896 loss: 0.00657237647
Iter: 897 loss: 0.00654693926
Iter: 898 loss: 0.00677546067
Iter: 899 loss: 0.00654585473
Iter: 900 loss: 0.00652686413
Iter: 901 loss: 0.00651599094
Iter: 902 loss: 0.00650773756
Iter: 903 loss: 0.00649405736
Iter: 904 loss: 0.00662592566
Iter: 905 loss: 0.00649346504
Iter: 906 loss: 0.00647918414
Iter: 907 loss: 0.00648537651
Iter: 908 loss: 0.00646948069
Iter: 909 loss: 0.00645259721
Iter: 910 loss: 0.00645624381
Iter: 911 loss: 0.00644011935
Iter: 912 loss: 0.0064223255
Iter: 913 loss: 0.00650267955
Iter: 914 loss: 0.0064189015
Iter: 915 loss: 0.00642372575
Iter: 916 loss: 0.0064080013
Iter: 917 loss: 0.00640147692
Iter: 918 loss: 0.00639338885
Iter: 919 loss: 0.00639270432
Iter: 920 loss: 0.00638225768
Iter: 921 loss: 0.00636286288
Iter: 922 loss: 0.00676790252
Iter: 923 loss: 0.00636283122
Iter: 924 loss: 0.0063554165
Iter: 925 loss: 0.0063445447
Iter: 926 loss: 0.00634425413
Iter: 927 loss: 0.00633067917
Iter: 928 loss: 0.00630893372
Iter: 929 loss: 0.00630873907
Iter: 930 loss: 0.00627917796
Iter: 931 loss: 0.00632652
Iter: 932 loss: 0.00626580184
Iter: 933 loss: 0.00623382
Iter: 934 loss: 0.00648211688
Iter: 935 loss: 0.00623110635
Iter: 936 loss: 0.0062117409
Iter: 937 loss: 0.00620851
Iter: 938 loss: 0.00619517919
Iter: 939 loss: 0.00618600054
Iter: 940 loss: 0.00618065428
Iter: 941 loss: 0.00617356319
Iter: 942 loss: 0.00618176628
Iter: 943 loss: 0.00616982952
Iter: 944 loss: 0.00616233703
Iter: 945 loss: 0.00614032522
Iter: 946 loss: 0.00622123107
Iter: 947 loss: 0.00613056635
Iter: 948 loss: 0.00610847585
Iter: 949 loss: 0.00615349598
Iter: 950 loss: 0.00609985739
Iter: 951 loss: 0.00608765427
Iter: 952 loss: 0.0061039892
Iter: 953 loss: 0.00608138368
Iter: 954 loss: 0.00606803037
Iter: 955 loss: 0.00606757915
Iter: 956 loss: 0.00605909294
Iter: 957 loss: 0.00605822261
Iter: 958 loss: 0.00605200417
Iter: 959 loss: 0.00603010831
Iter: 960 loss: 0.00599688711
Iter: 961 loss: 0.0059962403
Iter: 962 loss: 0.00596860563
Iter: 963 loss: 0.00607000478
Iter: 964 loss: 0.0059614582
Iter: 965 loss: 0.00594054069
Iter: 966 loss: 0.0059112981
Iter: 967 loss: 0.00591003755
Iter: 968 loss: 0.00588736869
Iter: 969 loss: 0.00601620087
Iter: 970 loss: 0.00588430744
Iter: 971 loss: 0.00587397907
Iter: 972 loss: 0.00587394554
Iter: 973 loss: 0.00586191379
Iter: 974 loss: 0.00596899958
Iter: 975 loss: 0.00586145557
Iter: 976 loss: 0.00585343596
Iter: 977 loss: 0.00583728123
Iter: 978 loss: 0.00613694172
Iter: 979 loss: 0.00583701953
Iter: 980 loss: 0.00582124665
Iter: 981 loss: 0.00590648595
Iter: 982 loss: 0.00581902685
Iter: 983 loss: 0.00580914039
Iter: 984 loss: 0.00579221547
Iter: 985 loss: 0.00579221128
Iter: 986 loss: 0.00577017153
Iter: 987 loss: 0.00604784302
Iter: 988 loss: 0.00577008165
Iter: 989 loss: 0.00574551
Iter: 990 loss: 0.00574549055
Iter: 991 loss: 0.00573969167
Iter: 992 loss: 0.00573332608
Iter: 993 loss: 0.00573236821
Iter: 994 loss: 0.00571800862
Iter: 995 loss: 0.00568461418
Iter: 996 loss: 0.00613527372
Iter: 997 loss: 0.00568219367
Iter: 998 loss: 0.00566412928
Iter: 999 loss: 0.00566362496
Iter: 1000 loss: 0.00563766574
Iter: 1001 loss: 0.00567135913
Iter: 1002 loss: 0.00562469382
Iter: 1003 loss: 0.00560533861
Iter: 1004 loss: 0.0058415439
Iter: 1005 loss: 0.00560520589
Iter: 1006 loss: 0.00559900561
Iter: 1007 loss: 0.00559834437
Iter: 1008 loss: 0.005593854
Iter: 1009 loss: 0.00558430748
Iter: 1010 loss: 0.00559479091
Iter: 1011 loss: 0.00557920337
Iter: 1012 loss: 0.005568658
Iter: 1013 loss: 0.00563536026
Iter: 1014 loss: 0.00556741469
Iter: 1015 loss: 0.00554945
Iter: 1016 loss: 0.0055281492
Iter: 1017 loss: 0.0055259685
Iter: 1018 loss: 0.00551224779
Iter: 1019 loss: 0.00551861897
Iter: 1020 loss: 0.00550279394
Iter: 1021 loss: 0.00549490843
Iter: 1022 loss: 0.00560713606
Iter: 1023 loss: 0.0054948749
Iter: 1024 loss: 0.00548853446
Iter: 1025 loss: 0.00547975348
Iter: 1026 loss: 0.00547941262
Iter: 1027 loss: 0.0054627792
Iter: 1028 loss: 0.0056662
Iter: 1029 loss: 0.00546265
Iter: 1030 loss: 0.00544608571
Iter: 1031 loss: 0.00547293667
Iter: 1032 loss: 0.00543819
Iter: 1033 loss: 0.00542527717
Iter: 1034 loss: 0.00539736915
Iter: 1035 loss: 0.005855266
Iter: 1036 loss: 0.00539636333
Iter: 1037 loss: 0.00537151704
Iter: 1038 loss: 0.00537100155
Iter: 1039 loss: 0.00535666756
Iter: 1040 loss: 0.0053242296
Iter: 1041 loss: 0.0057988679
Iter: 1042 loss: 0.00532239
Iter: 1043 loss: 0.00528977206
Iter: 1044 loss: 0.00547097484
Iter: 1045 loss: 0.00528533757
Iter: 1046 loss: 0.00526571833
Iter: 1047 loss: 0.0053724125
Iter: 1048 loss: 0.00526276231
Iter: 1049 loss: 0.00524358079
Iter: 1050 loss: 0.00522301439
Iter: 1051 loss: 0.00521975709
Iter: 1052 loss: 0.00532071153
Iter: 1053 loss: 0.00521348324
Iter: 1054 loss: 0.00521026
Iter: 1055 loss: 0.00520751625
Iter: 1056 loss: 0.00520660263
Iter: 1057 loss: 0.0051955143
Iter: 1058 loss: 0.00518090278
Iter: 1059 loss: 0.00518006505
Iter: 1060 loss: 0.00516473316
Iter: 1061 loss: 0.00516391825
Iter: 1062 loss: 0.00514978264
Iter: 1063 loss: 0.00518485904
Iter: 1064 loss: 0.00514466967
Iter: 1065 loss: 0.00513722375
Iter: 1066 loss: 0.00514609134
Iter: 1067 loss: 0.00513328752
Iter: 1068 loss: 0.00512355473
Iter: 1069 loss: 0.00512208277
Iter: 1070 loss: 0.00511536328
Iter: 1071 loss: 0.00510393
Iter: 1072 loss: 0.00512028905
Iter: 1073 loss: 0.00509830564
Iter: 1074 loss: 0.00508217514
Iter: 1075 loss: 0.00509120896
Iter: 1076 loss: 0.00507173967
Iter: 1077 loss: 0.00506094657
Iter: 1078 loss: 0.00505758077
Iter: 1079 loss: 0.00505109597
Iter: 1080 loss: 0.00504365936
Iter: 1081 loss: 0.00502804108
Iter: 1082 loss: 0.00527302641
Iter: 1083 loss: 0.00502762571
Iter: 1084 loss: 0.00501592644
Iter: 1085 loss: 0.00502200797
Iter: 1086 loss: 0.00500821508
Iter: 1087 loss: 0.00500281155
Iter: 1088 loss: 0.0050001014
Iter: 1089 loss: 0.00499756169
Iter: 1090 loss: 0.00496987067
Iter: 1091 loss: 0.0051615471
Iter: 1092 loss: 0.00496750278
Iter: 1093 loss: 0.00496392744
Iter: 1094 loss: 0.00495590735
Iter: 1095 loss: 0.00494619925
Iter: 1096 loss: 0.00499061216
Iter: 1097 loss: 0.00494439062
Iter: 1098 loss: 0.00493722502
Iter: 1099 loss: 0.00495086657
Iter: 1100 loss: 0.00493412139
Iter: 1101 loss: 0.00492758304
Iter: 1102 loss: 0.00493568322
Iter: 1103 loss: 0.00492412224
Iter: 1104 loss: 0.00491192844
Iter: 1105 loss: 0.00492926687
Iter: 1106 loss: 0.00490592234
Iter: 1107 loss: 0.00488919299
Iter: 1108 loss: 0.00493389694
Iter: 1109 loss: 0.00488361251
Iter: 1110 loss: 0.0048744427
Iter: 1111 loss: 0.00487395748
Iter: 1112 loss: 0.00486763706
Iter: 1113 loss: 0.00488961628
Iter: 1114 loss: 0.00486595323
Iter: 1115 loss: 0.00485850219
Iter: 1116 loss: 0.00486923102
Iter: 1117 loss: 0.00485488353
Iter: 1118 loss: 0.00484695565
Iter: 1119 loss: 0.00483135413
Iter: 1120 loss: 0.00514758192
Iter: 1121 loss: 0.00483122841
Iter: 1122 loss: 0.00481098797
Iter: 1123 loss: 0.00480534788
Iter: 1124 loss: 0.00479299
Iter: 1125 loss: 0.00478243
Iter: 1126 loss: 0.00486951182
Iter: 1127 loss: 0.00478186226
Iter: 1128 loss: 0.00478159916
Iter: 1129 loss: 0.00477533787
Iter: 1130 loss: 0.00477112969
Iter: 1131 loss: 0.00476081343
Iter: 1132 loss: 0.00485660741
Iter: 1133 loss: 0.00475948583
Iter: 1134 loss: 0.00473975623
Iter: 1135 loss: 0.00471177138
Iter: 1136 loss: 0.0047107446
Iter: 1137 loss: 0.00469187042
Iter: 1138 loss: 0.00478646345
Iter: 1139 loss: 0.00468886551
Iter: 1140 loss: 0.00467878068
Iter: 1141 loss: 0.00467805658
Iter: 1142 loss: 0.00467059622
Iter: 1143 loss: 0.00465133507
Iter: 1144 loss: 0.00469324831
Iter: 1145 loss: 0.00464362185
Iter: 1146 loss: 0.00463738712
Iter: 1147 loss: 0.0046346793
Iter: 1148 loss: 0.00463162409
Iter: 1149 loss: 0.00463316962
Iter: 1150 loss: 0.00462961197
Iter: 1151 loss: 0.00462253811
Iter: 1152 loss: 0.00460958201
Iter: 1153 loss: 0.00489558652
Iter: 1154 loss: 0.00460957689
Iter: 1155 loss: 0.00459519774
Iter: 1156 loss: 0.00476904307
Iter: 1157 loss: 0.00459498912
Iter: 1158 loss: 0.00458446238
Iter: 1159 loss: 0.00459873769
Iter: 1160 loss: 0.00457911938
Iter: 1161 loss: 0.00456643244
Iter: 1162 loss: 0.00461743632
Iter: 1163 loss: 0.00456339121
Iter: 1164 loss: 0.00455387915
Iter: 1165 loss: 0.00455301628
Iter: 1166 loss: 0.00454719272
Iter: 1167 loss: 0.00453691
Iter: 1168 loss: 0.0045369165
Iter: 1169 loss: 0.00452845171
Iter: 1170 loss: 0.00452730898
Iter: 1171 loss: 0.0045212917
Iter: 1172 loss: 0.00450986344
Iter: 1173 loss: 0.00450081844
Iter: 1174 loss: 0.00449730316
Iter: 1175 loss: 0.00447755679
Iter: 1176 loss: 0.00453033112
Iter: 1177 loss: 0.00447113719
Iter: 1178 loss: 0.00446758233
Iter: 1179 loss: 0.00446388219
Iter: 1180 loss: 0.00445989287
Iter: 1181 loss: 0.00449311826
Iter: 1182 loss: 0.00445971126
Iter: 1183 loss: 0.00445438875
Iter: 1184 loss: 0.00443976
Iter: 1185 loss: 0.00452995254
Iter: 1186 loss: 0.00443582283
Iter: 1187 loss: 0.00442808541
Iter: 1188 loss: 0.00444215583
Iter: 1189 loss: 0.00442476943
Iter: 1190 loss: 0.00441607833
Iter: 1191 loss: 0.00439451775
Iter: 1192 loss: 0.00460134633
Iter: 1193 loss: 0.00439168885
Iter: 1194 loss: 0.00437735114
Iter: 1195 loss: 0.00455214269
Iter: 1196 loss: 0.00437718956
Iter: 1197 loss: 0.00437209755
Iter: 1198 loss: 0.00437048683
Iter: 1199 loss: 0.00436357409
Iter: 1200 loss: 0.00440466916
Iter: 1201 loss: 0.00436269026
Iter: 1202 loss: 0.00435976591
Iter: 1203 loss: 0.00435052533
Iter: 1204 loss: 0.00436268281
Iter: 1205 loss: 0.00434366614
Iter: 1206 loss: 0.00431872578
Iter: 1207 loss: 0.00432570232
Iter: 1208 loss: 0.00430060085
Iter: 1209 loss: 0.00428643636
Iter: 1210 loss: 0.00436144788
Iter: 1211 loss: 0.00428423379
Iter: 1212 loss: 0.0042670751
Iter: 1213 loss: 0.00428289641
Iter: 1214 loss: 0.00425723381
Iter: 1215 loss: 0.00423679315
Iter: 1216 loss: 0.00456027268
Iter: 1217 loss: 0.00423679315
Iter: 1218 loss: 0.00424457248
Iter: 1219 loss: 0.00423203595
Iter: 1220 loss: 0.00423097471
Iter: 1221 loss: 0.00422785711
Iter: 1222 loss: 0.00423516752
Iter: 1223 loss: 0.00422601122
Iter: 1224 loss: 0.00421417505
Iter: 1225 loss: 0.00418881699
Iter: 1226 loss: 0.00458233105
Iter: 1227 loss: 0.00418797554
Iter: 1228 loss: 0.00417304691
Iter: 1229 loss: 0.00419011759
Iter: 1230 loss: 0.00416499702
Iter: 1231 loss: 0.00415192079
Iter: 1232 loss: 0.00419837516
Iter: 1233 loss: 0.00414851494
Iter: 1234 loss: 0.00414018612
Iter: 1235 loss: 0.00423387252
Iter: 1236 loss: 0.00414002314
Iter: 1237 loss: 0.00413147965
Iter: 1238 loss: 0.00422967924
Iter: 1239 loss: 0.00413132831
Iter: 1240 loss: 0.00412717182
Iter: 1241 loss: 0.00412441697
Iter: 1242 loss: 0.00412285235
Iter: 1243 loss: 0.00411794055
Iter: 1244 loss: 0.00412123185
Iter: 1245 loss: 0.00411483226
Iter: 1246 loss: 0.00411121221
Iter: 1247 loss: 0.00409939699
Iter: 1248 loss: 0.00410491694
Iter: 1249 loss: 0.00408855453
Iter: 1250 loss: 0.00407345
Iter: 1251 loss: 0.00428190082
Iter: 1252 loss: 0.00407338608
Iter: 1253 loss: 0.00406649336
Iter: 1254 loss: 0.00406777905
Iter: 1255 loss: 0.00406130916
Iter: 1256 loss: 0.00405309256
Iter: 1257 loss: 0.00408288417
Iter: 1258 loss: 0.00405098312
Iter: 1259 loss: 0.00404620031
Iter: 1260 loss: 0.00403955765
Iter: 1261 loss: 0.00403923821
Iter: 1262 loss: 0.00402999343
Iter: 1263 loss: 0.00402680784
Iter: 1264 loss: 0.00402154122
Iter: 1265 loss: 0.00400605332
Iter: 1266 loss: 0.00402179919
Iter: 1267 loss: 0.00399721554
Iter: 1268 loss: 0.00398113485
Iter: 1269 loss: 0.00405317172
Iter: 1270 loss: 0.00397799909
Iter: 1271 loss: 0.00397425657
Iter: 1272 loss: 0.00397272874
Iter: 1273 loss: 0.00397092476
Iter: 1274 loss: 0.0039699059
Iter: 1275 loss: 0.00396912312
Iter: 1276 loss: 0.003964114
Iter: 1277 loss: 0.00397112174
Iter: 1278 loss: 0.00396161433
Iter: 1279 loss: 0.00395509042
Iter: 1280 loss: 0.00395661779
Iter: 1281 loss: 0.0039503118
Iter: 1282 loss: 0.00394092407
Iter: 1283 loss: 0.00394056365
Iter: 1284 loss: 0.00393323507
Iter: 1285 loss: 0.00392555259
Iter: 1286 loss: 0.00391568616
Iter: 1287 loss: 0.00391498813
Iter: 1288 loss: 0.00392428366
Iter: 1289 loss: 0.00391019415
Iter: 1290 loss: 0.00390579225
Iter: 1291 loss: 0.00391913578
Iter: 1292 loss: 0.00390450284
Iter: 1293 loss: 0.00390264811
Iter: 1294 loss: 0.00389914657
Iter: 1295 loss: 0.00397828827
Iter: 1296 loss: 0.00389913842
Iter: 1297 loss: 0.00389481708
Iter: 1298 loss: 0.00389254582
Iter: 1299 loss: 0.0038905791
Iter: 1300 loss: 0.00388784171
Iter: 1301 loss: 0.00388172176
Iter: 1302 loss: 0.00397039065
Iter: 1303 loss: 0.00388139393
Iter: 1304 loss: 0.00387968495
Iter: 1305 loss: 0.00387767283
Iter: 1306 loss: 0.00387137383
Iter: 1307 loss: 0.00386409974
Iter: 1308 loss: 0.00386323128
Iter: 1309 loss: 0.00385367102
Iter: 1310 loss: 0.003854512
Iter: 1311 loss: 0.00384633197
Iter: 1312 loss: 0.00383517751
Iter: 1313 loss: 0.00385485659
Iter: 1314 loss: 0.00383022125
Iter: 1315 loss: 0.00382302748
Iter: 1316 loss: 0.00381324417
Iter: 1317 loss: 0.003812721
Iter: 1318 loss: 0.00380137539
Iter: 1319 loss: 0.00385692809
Iter: 1320 loss: 0.00379927177
Iter: 1321 loss: 0.00378884235
Iter: 1322 loss: 0.00380696915
Iter: 1323 loss: 0.00378405396
Iter: 1324 loss: 0.00377308088
Iter: 1325 loss: 0.00379763637
Iter: 1326 loss: 0.00376892136
Iter: 1327 loss: 0.00377461105
Iter: 1328 loss: 0.00376509526
Iter: 1329 loss: 0.00376305403
Iter: 1330 loss: 0.00376082258
Iter: 1331 loss: 0.00376046496
Iter: 1332 loss: 0.0037562435
Iter: 1333 loss: 0.00374647742
Iter: 1334 loss: 0.00386495609
Iter: 1335 loss: 0.00374578964
Iter: 1336 loss: 0.00373341586
Iter: 1337 loss: 0.00387405884
Iter: 1338 loss: 0.00373315718
Iter: 1339 loss: 0.0037232067
Iter: 1340 loss: 0.00377617031
Iter: 1341 loss: 0.00372171402
Iter: 1342 loss: 0.00371676823
Iter: 1343 loss: 0.00372905
Iter: 1344 loss: 0.00371500198
Iter: 1345 loss: 0.0037092003
Iter: 1346 loss: 0.00373003678
Iter: 1347 loss: 0.00370771578
Iter: 1348 loss: 0.00370236556
Iter: 1349 loss: 0.00371579127
Iter: 1350 loss: 0.00370052084
Iter: 1351 loss: 0.00369703071
Iter: 1352 loss: 0.00368734705
Iter: 1353 loss: 0.00373972626
Iter: 1354 loss: 0.00368432747
Iter: 1355 loss: 0.00367546082
Iter: 1356 loss: 0.00367291016
Iter: 1357 loss: 0.00366756087
Iter: 1358 loss: 0.00366261322
Iter: 1359 loss: 0.00366889732
Iter: 1360 loss: 0.0036599813
Iter: 1361 loss: 0.00365569373
Iter: 1362 loss: 0.00364757096
Iter: 1363 loss: 0.00382023025
Iter: 1364 loss: 0.00364754861
Iter: 1365 loss: 0.00363979908
Iter: 1366 loss: 0.00368677732
Iter: 1367 loss: 0.00363882445
Iter: 1368 loss: 0.00363779115
Iter: 1369 loss: 0.00363516924
Iter: 1370 loss: 0.00363368774
Iter: 1371 loss: 0.00362983602
Iter: 1372 loss: 0.00366363954
Iter: 1373 loss: 0.00362920109
Iter: 1374 loss: 0.00362423132
Iter: 1375 loss: 0.00361335441
Iter: 1376 loss: 0.00377854379
Iter: 1377 loss: 0.00361288758
Iter: 1378 loss: 0.00360006746
Iter: 1379 loss: 0.0035979785
Iter: 1380 loss: 0.00358912814
Iter: 1381 loss: 0.00357858604
Iter: 1382 loss: 0.0036161968
Iter: 1383 loss: 0.00357593666
Iter: 1384 loss: 0.00359162292
Iter: 1385 loss: 0.00357106421
Iter: 1386 loss: 0.00356838596
Iter: 1387 loss: 0.00357297
Iter: 1388 loss: 0.00356717594
Iter: 1389 loss: 0.00356419408
Iter: 1390 loss: 0.00356194959
Iter: 1391 loss: 0.00356095866
Iter: 1392 loss: 0.00355606433
Iter: 1393 loss: 0.00354681117
Iter: 1394 loss: 0.00374829257
Iter: 1395 loss: 0.00354679162
Iter: 1396 loss: 0.00353251956
Iter: 1397 loss: 0.00356738269
Iter: 1398 loss: 0.00352728646
Iter: 1399 loss: 0.00351633597
Iter: 1400 loss: 0.00351619418
Iter: 1401 loss: 0.00351000344
Iter: 1402 loss: 0.00358595722
Iter: 1403 loss: 0.00350993616
Iter: 1404 loss: 0.00350362319
Iter: 1405 loss: 0.00354218087
Iter: 1406 loss: 0.00350290979
Iter: 1407 loss: 0.00349883176
Iter: 1408 loss: 0.00348812807
Iter: 1409 loss: 0.00357226119
Iter: 1410 loss: 0.00348598
Iter: 1411 loss: 0.0034774458
Iter: 1412 loss: 0.00350722624
Iter: 1413 loss: 0.0034751636
Iter: 1414 loss: 0.00347053399
Iter: 1415 loss: 0.00347251864
Iter: 1416 loss: 0.0034673519
Iter: 1417 loss: 0.00346085429
Iter: 1418 loss: 0.00346786482
Iter: 1419 loss: 0.00345730269
Iter: 1420 loss: 0.00345136598
Iter: 1421 loss: 0.00353047252
Iter: 1422 loss: 0.00345133711
Iter: 1423 loss: 0.00345025887
Iter: 1424 loss: 0.00344811217
Iter: 1425 loss: 0.00344678899
Iter: 1426 loss: 0.00344245462
Iter: 1427 loss: 0.00344312
Iter: 1428 loss: 0.00343814725
Iter: 1429 loss: 0.00343157072
Iter: 1430 loss: 0.00344744418
Iter: 1431 loss: 0.00342912949
Iter: 1432 loss: 0.00342714274
Iter: 1433 loss: 0.00342418393
Iter: 1434 loss: 0.00342410803
Iter: 1435 loss: 0.00341827609
Iter: 1436 loss: 0.00340553652
Iter: 1437 loss: 0.00360382441
Iter: 1438 loss: 0.00340501196
Iter: 1439 loss: 0.0033868032
Iter: 1440 loss: 0.00350861717
Iter: 1441 loss: 0.00338504906
Iter: 1442 loss: 0.00338483648
Iter: 1443 loss: 0.00338135217
Iter: 1444 loss: 0.00337886019
Iter: 1445 loss: 0.00338080642
Iter: 1446 loss: 0.00337734981
Iter: 1447 loss: 0.00337163545
Iter: 1448 loss: 0.00336125027
Iter: 1449 loss: 0.00359907211
Iter: 1450 loss: 0.0033612377
Iter: 1451 loss: 0.00335420901
Iter: 1452 loss: 0.0033714
Iter: 1453 loss: 0.00335173658
Iter: 1454 loss: 0.00334786135
Iter: 1455 loss: 0.0033408287
Iter: 1456 loss: 0.00350634381
Iter: 1457 loss: 0.00334082264
Iter: 1458 loss: 0.00333985849
Iter: 1459 loss: 0.00333846919
Iter: 1460 loss: 0.00333641097
Iter: 1461 loss: 0.00333802379
Iter: 1462 loss: 0.0033351609
Iter: 1463 loss: 0.00332299247
Iter: 1464 loss: 0.00337201869
Iter: 1465 loss: 0.00332023739
Iter: 1466 loss: 0.00331924832
Iter: 1467 loss: 0.00331489253
Iter: 1468 loss: 0.00330900215
Iter: 1469 loss: 0.00330217904
Iter: 1470 loss: 0.00330140279
Iter: 1471 loss: 0.00329374056
Iter: 1472 loss: 0.00330288755
Iter: 1473 loss: 0.0032897098
Iter: 1474 loss: 0.00328263245
Iter: 1475 loss: 0.00334015838
Iter: 1476 loss: 0.00328216702
Iter: 1477 loss: 0.00327504426
Iter: 1478 loss: 0.00329924631
Iter: 1479 loss: 0.00327306986
Iter: 1480 loss: 0.00326632732
Iter: 1481 loss: 0.00329300435
Iter: 1482 loss: 0.00326486328
Iter: 1483 loss: 0.00326010608
Iter: 1484 loss: 0.00326010166
Iter: 1485 loss: 0.0032577829
Iter: 1486 loss: 0.00326324906
Iter: 1487 loss: 0.00325692305
Iter: 1488 loss: 0.00325505529
Iter: 1489 loss: 0.00327626849
Iter: 1490 loss: 0.00325499987
Iter: 1491 loss: 0.00325253489
Iter: 1492 loss: 0.00324740331
Iter: 1493 loss: 0.00333446916
Iter: 1494 loss: 0.00324725825
Iter: 1495 loss: 0.0032426524
Iter: 1496 loss: 0.00324266637
Iter: 1497 loss: 0.00323893456
Iter: 1498 loss: 0.00323398598
Iter: 1499 loss: 0.00322881807
Iter: 1500 loss: 0.00322789978
Iter: 1501 loss: 0.00323367445
Iter: 1502 loss: 0.00322529697
Iter: 1503 loss: 0.00322308345
Iter: 1504 loss: 0.00321623078
Iter: 1505 loss: 0.00323250936
Iter: 1506 loss: 0.00321219722
Iter: 1507 loss: 0.00320512592
Iter: 1508 loss: 0.00324128
Iter: 1509 loss: 0.00320400414
Iter: 1510 loss: 0.00320121041
Iter: 1511 loss: 0.00319757592
Iter: 1512 loss: 0.00319736451
Iter: 1513 loss: 0.00319156656
Iter: 1514 loss: 0.00322432257
Iter: 1515 loss: 0.00319071067
Iter: 1516 loss: 0.0031857295
Iter: 1517 loss: 0.00318344333
Iter: 1518 loss: 0.00318097742
Iter: 1519 loss: 0.00318080862
Iter: 1520 loss: 0.00317857973
Iter: 1521 loss: 0.00317685632
Iter: 1522 loss: 0.00318263494
Iter: 1523 loss: 0.00317639
Iter: 1524 loss: 0.00317401579
Iter: 1525 loss: 0.00317169027
Iter: 1526 loss: 0.00317116058
Iter: 1527 loss: 0.00316759385
Iter: 1528 loss: 0.00316447672
Iter: 1529 loss: 0.00316355587
Iter: 1530 loss: 0.00315587502
Iter: 1531 loss: 0.00316669652
Iter: 1532 loss: 0.00315211318
Iter: 1533 loss: 0.0031461725
Iter: 1534 loss: 0.00313853752
Iter: 1535 loss: 0.00313800713
Iter: 1536 loss: 0.00315611297
Iter: 1537 loss: 0.00313435635
Iter: 1538 loss: 0.0031326469
Iter: 1539 loss: 0.0031317519
Iter: 1540 loss: 0.0031309505
Iter: 1541 loss: 0.00312687154
Iter: 1542 loss: 0.00312304636
Iter: 1543 loss: 0.00312211504
Iter: 1544 loss: 0.00311348122
Iter: 1545 loss: 0.00310262712
Iter: 1546 loss: 0.00310180429
Iter: 1547 loss: 0.00310201501
Iter: 1548 loss: 0.00309515186
Iter: 1549 loss: 0.00309260376
Iter: 1550 loss: 0.00308960723
Iter: 1551 loss: 0.00308928103
Iter: 1552 loss: 0.00308593549
Iter: 1553 loss: 0.00308557414
Iter: 1554 loss: 0.00308357878
Iter: 1555 loss: 0.00308283418
Iter: 1556 loss: 0.00308170216
Iter: 1557 loss: 0.00307759
Iter: 1558 loss: 0.00307011977
Iter: 1559 loss: 0.00326215988
Iter: 1560 loss: 0.00307012233
Iter: 1561 loss: 0.00306596956
Iter: 1562 loss: 0.00306964875
Iter: 1563 loss: 0.00306355674
Iter: 1564 loss: 0.00305844727
Iter: 1565 loss: 0.0030572433
Iter: 1566 loss: 0.00305398321
Iter: 1567 loss: 0.00304656196
Iter: 1568 loss: 0.00314914924
Iter: 1569 loss: 0.00304654706
Iter: 1570 loss: 0.00304076262
Iter: 1571 loss: 0.00304704183
Iter: 1572 loss: 0.00303766178
Iter: 1573 loss: 0.00302894786
Iter: 1574 loss: 0.00306613883
Iter: 1575 loss: 0.00302711269
Iter: 1576 loss: 0.00302043092
Iter: 1577 loss: 0.00302102
Iter: 1578 loss: 0.00301521085
Iter: 1579 loss: 0.00301830051
Iter: 1580 loss: 0.00301132584
Iter: 1581 loss: 0.0030090888
Iter: 1582 loss: 0.00301263854
Iter: 1583 loss: 0.00300809182
Iter: 1584 loss: 0.00300625339
Iter: 1585 loss: 0.00301004061
Iter: 1586 loss: 0.00300553069
Iter: 1587 loss: 0.00300346781
Iter: 1588 loss: 0.00300019025
Iter: 1589 loss: 0.00300016045
Iter: 1590 loss: 0.00299743051
Iter: 1591 loss: 0.00299955485
Iter: 1592 loss: 0.00299579324
Iter: 1593 loss: 0.00298966886
Iter: 1594 loss: 0.00297965785
Iter: 1595 loss: 0.00297957263
Iter: 1596 loss: 0.00297050225
Iter: 1597 loss: 0.00303401705
Iter: 1598 loss: 0.00296963053
Iter: 1599 loss: 0.00296445074
Iter: 1600 loss: 0.00298166508
Iter: 1601 loss: 0.00296302862
Iter: 1602 loss: 0.00295775337
Iter: 1603 loss: 0.00300279073
Iter: 1604 loss: 0.00295747817
Iter: 1605 loss: 0.00295332866
Iter: 1606 loss: 0.00294947205
Iter: 1607 loss: 0.00294850348
Iter: 1608 loss: 0.00293951854
Iter: 1609 loss: 0.00294754608
Iter: 1610 loss: 0.00293429964
Iter: 1611 loss: 0.00292493426
Iter: 1612 loss: 0.0029382729
Iter: 1613 loss: 0.00292034354
Iter: 1614 loss: 0.002922785
Iter: 1615 loss: 0.00291870208
Iter: 1616 loss: 0.00291753956
Iter: 1617 loss: 0.00292788818
Iter: 1618 loss: 0.00291746226
Iter: 1619 loss: 0.00291632023
Iter: 1620 loss: 0.00291475444
Iter: 1621 loss: 0.00291468459
Iter: 1622 loss: 0.0029131812
Iter: 1623 loss: 0.002927389
Iter: 1624 loss: 0.00291313743
Iter: 1625 loss: 0.00291183824
Iter: 1626 loss: 0.00290817721
Iter: 1627 loss: 0.00292443181
Iter: 1628 loss: 0.00290681934
Iter: 1629 loss: 0.00290428475
Iter: 1630 loss: 0.00291902665
Iter: 1631 loss: 0.00290392339
Iter: 1632 loss: 0.00290294411
Iter: 1633 loss: 0.00289992942
Iter: 1634 loss: 0.00290757231
Iter: 1635 loss: 0.00289820926
Iter: 1636 loss: 0.00289325346
Iter: 1637 loss: 0.00292818854
Iter: 1638 loss: 0.00289281714
Iter: 1639 loss: 0.00289026788
Iter: 1640 loss: 0.0028902893
Iter: 1641 loss: 0.00288825296
Iter: 1642 loss: 0.00288588
Iter: 1643 loss: 0.00288125966
Iter: 1644 loss: 0.00297951838
Iter: 1645 loss: 0.00288122287
Iter: 1646 loss: 0.00287915394
Iter: 1647 loss: 0.00288376887
Iter: 1648 loss: 0.00287837861
Iter: 1649 loss: 0.00287743611
Iter: 1650 loss: 0.00287498534
Iter: 1651 loss: 0.00289469049
Iter: 1652 loss: 0.00287451479
Iter: 1653 loss: 0.00287150266
Iter: 1654 loss: 0.00289969053
Iter: 1655 loss: 0.00287137553
Iter: 1656 loss: 0.00287297438
Iter: 1657 loss: 0.00286810449
Iter: 1658 loss: 0.00286626164
Iter: 1659 loss: 0.00287926127
Iter: 1660 loss: 0.0028660954
Iter: 1661 loss: 0.00286452589
Iter: 1662 loss: 0.00286628446
Iter: 1663 loss: 0.00286366558
Iter: 1664 loss: 0.00286114356
Iter: 1665 loss: 0.00285494304
Iter: 1666 loss: 0.0029152371
Iter: 1667 loss: 0.00285412301
Iter: 1668 loss: 0.00284983846
Iter: 1669 loss: 0.00284982543
Iter: 1670 loss: 0.00284623588
Iter: 1671 loss: 0.00285011507
Iter: 1672 loss: 0.00284427218
Iter: 1673 loss: 0.00284273224
Iter: 1674 loss: 0.00284241652
Iter: 1675 loss: 0.00284141395
Iter: 1676 loss: 0.00285559986
Iter: 1677 loss: 0.00284142187
Iter: 1678 loss: 0.00284076715
Iter: 1679 loss: 0.00284230034
Iter: 1680 loss: 0.00284055527
Iter: 1681 loss: 0.00283950637
Iter: 1682 loss: 0.00283718132
Iter: 1683 loss: 0.00286917668
Iter: 1684 loss: 0.00283706095
Iter: 1685 loss: 0.00283519109
Iter: 1686 loss: 0.0028473651
Iter: 1687 loss: 0.00283500412
Iter: 1688 loss: 0.00283330749
Iter: 1689 loss: 0.00282834796
Iter: 1690 loss: 0.00284878584
Iter: 1691 loss: 0.00282632653
Iter: 1692 loss: 0.00282106758
Iter: 1693 loss: 0.00283333939
Iter: 1694 loss: 0.00281910133
Iter: 1695 loss: 0.00284215412
Iter: 1696 loss: 0.00281592412
Iter: 1697 loss: 0.00281367311
Iter: 1698 loss: 0.00280870823
Iter: 1699 loss: 0.0028859186
Iter: 1700 loss: 0.00280849845
Iter: 1701 loss: 0.00280630169
Iter: 1702 loss: 0.00280659902
Iter: 1703 loss: 0.00280463253
Iter: 1704 loss: 0.00280187023
Iter: 1705 loss: 0.00279405527
Iter: 1706 loss: 0.00283470866
Iter: 1707 loss: 0.00279152556
Iter: 1708 loss: 0.00278698513
Iter: 1709 loss: 0.00278653391
Iter: 1710 loss: 0.00278379396
Iter: 1711 loss: 0.00277968822
Iter: 1712 loss: 0.00277959974
Iter: 1713 loss: 0.00277607096
Iter: 1714 loss: 0.00277563464
Iter: 1715 loss: 0.00277263229
Iter: 1716 loss: 0.00277434429
Iter: 1717 loss: 0.00277069909
Iter: 1718 loss: 0.00276296446
Iter: 1719 loss: 0.00279809255
Iter: 1720 loss: 0.00276144617
Iter: 1721 loss: 0.00275720027
Iter: 1722 loss: 0.00275847735
Iter: 1723 loss: 0.00275415368
Iter: 1724 loss: 0.00274737971
Iter: 1725 loss: 0.00285959197
Iter: 1726 loss: 0.00274738437
Iter: 1727 loss: 0.00274125393
Iter: 1728 loss: 0.0027412395
Iter: 1729 loss: 0.00273828022
Iter: 1730 loss: 0.00274512265
Iter: 1731 loss: 0.00273714494
Iter: 1732 loss: 0.00273542153
Iter: 1733 loss: 0.00273132091
Iter: 1734 loss: 0.0027763953
Iter: 1735 loss: 0.00273093162
Iter: 1736 loss: 0.00272808759
Iter: 1737 loss: 0.00273803901
Iter: 1738 loss: 0.00272736838
Iter: 1739 loss: 0.00272257044
Iter: 1740 loss: 0.00273016188
Iter: 1741 loss: 0.00272027124
Iter: 1742 loss: 0.0027122465
Iter: 1743 loss: 0.0027254147
Iter: 1744 loss: 0.0027086013
Iter: 1745 loss: 0.00270509813
Iter: 1746 loss: 0.00270417845
Iter: 1747 loss: 0.0027014513
Iter: 1748 loss: 0.00270348717
Iter: 1749 loss: 0.00269979984
Iter: 1750 loss: 0.00269626454
Iter: 1751 loss: 0.00269035576
Iter: 1752 loss: 0.00269031106
Iter: 1753 loss: 0.00268471241
Iter: 1754 loss: 0.00268952
Iter: 1755 loss: 0.00268138293
Iter: 1756 loss: 0.00267956732
Iter: 1757 loss: 0.00267610839
Iter: 1758 loss: 0.00275111198
Iter: 1759 loss: 0.00267609116
Iter: 1760 loss: 0.00267180987
Iter: 1761 loss: 0.00271517527
Iter: 1762 loss: 0.00267165853
Iter: 1763 loss: 0.00266857678
Iter: 1764 loss: 0.00266845198
Iter: 1765 loss: 0.0026669784
Iter: 1766 loss: 0.00266376021
Iter: 1767 loss: 0.00271153753
Iter: 1768 loss: 0.00266361516
Iter: 1769 loss: 0.00265724491
Iter: 1770 loss: 0.00267116446
Iter: 1771 loss: 0.00265479833
Iter: 1772 loss: 0.00264646462
Iter: 1773 loss: 0.00265357736
Iter: 1774 loss: 0.0026415172
Iter: 1775 loss: 0.00263383379
Iter: 1776 loss: 0.00263384404
Iter: 1777 loss: 0.00263141887
Iter: 1778 loss: 0.0026539797
Iter: 1779 loss: 0.00263130805
Iter: 1780 loss: 0.00262780627
Iter: 1781 loss: 0.00263136439
Iter: 1782 loss: 0.00262581743
Iter: 1783 loss: 0.00262409705
Iter: 1784 loss: 0.00262257224
Iter: 1785 loss: 0.00262211077
Iter: 1786 loss: 0.00261976849
Iter: 1787 loss: 0.00261883065
Iter: 1788 loss: 0.00261756871
Iter: 1789 loss: 0.00261543528
Iter: 1790 loss: 0.00261633703
Iter: 1791 loss: 0.0026139617
Iter: 1792 loss: 0.0026118774
Iter: 1793 loss: 0.00261167018
Iter: 1794 loss: 0.00261012535
Iter: 1795 loss: 0.00262508215
Iter: 1796 loss: 0.00261004921
Iter: 1797 loss: 0.00260871137
Iter: 1798 loss: 0.00260539446
Iter: 1799 loss: 0.00263643172
Iter: 1800 loss: 0.00260491716
Iter: 1801 loss: 0.00260199211
Iter: 1802 loss: 0.00260700518
Iter: 1803 loss: 0.00260064285
Iter: 1804 loss: 0.00259713572
Iter: 1805 loss: 0.00258737919
Iter: 1806 loss: 0.0026430937
Iter: 1807 loss: 0.00258443132
Iter: 1808 loss: 0.00258552562
Iter: 1809 loss: 0.00258123456
Iter: 1810 loss: 0.00257903174
Iter: 1811 loss: 0.00257502962
Iter: 1812 loss: 0.00266863219
Iter: 1813 loss: 0.00257502217
Iter: 1814 loss: 0.00256965216
Iter: 1815 loss: 0.00261324691
Iter: 1816 loss: 0.00256922515
Iter: 1817 loss: 0.00256268959
Iter: 1818 loss: 0.00263036438
Iter: 1819 loss: 0.00256251614
Iter: 1820 loss: 0.00256104534
Iter: 1821 loss: 0.0025582707
Iter: 1822 loss: 0.00261946535
Iter: 1823 loss: 0.00255826721
Iter: 1824 loss: 0.00255548325
Iter: 1825 loss: 0.00255520782
Iter: 1826 loss: 0.0025531631
Iter: 1827 loss: 0.0025538085
Iter: 1828 loss: 0.00255083875
Iter: 1829 loss: 0.00254854397
Iter: 1830 loss: 0.00254824851
Iter: 1831 loss: 0.00254681706
Iter: 1832 loss: 0.00254365127
Iter: 1833 loss: 0.002588765
Iter: 1834 loss: 0.00254350109
Iter: 1835 loss: 0.0025394503
Iter: 1836 loss: 0.00254869182
Iter: 1837 loss: 0.00253795413
Iter: 1838 loss: 0.00253456202
Iter: 1839 loss: 0.0025844255
Iter: 1840 loss: 0.00253455201
Iter: 1841 loss: 0.00253235316
Iter: 1842 loss: 0.00252788584
Iter: 1843 loss: 0.00261061103
Iter: 1844 loss: 0.00252782134
Iter: 1845 loss: 0.00252229674
Iter: 1846 loss: 0.00254265498
Iter: 1847 loss: 0.00252095726
Iter: 1848 loss: 0.00251673348
Iter: 1849 loss: 0.00251280097
Iter: 1850 loss: 0.00251181354
Iter: 1851 loss: 0.00255791703
Iter: 1852 loss: 0.00251044519
Iter: 1853 loss: 0.00250884844
Iter: 1854 loss: 0.00251077954
Iter: 1855 loss: 0.00250799628
Iter: 1856 loss: 0.00250626868
Iter: 1857 loss: 0.0025023208
Iter: 1858 loss: 0.00255479058
Iter: 1859 loss: 0.00250206864
Iter: 1860 loss: 0.00249826955
Iter: 1861 loss: 0.00249149185
Iter: 1862 loss: 0.00266127451
Iter: 1863 loss: 0.00249149231
Iter: 1864 loss: 0.00248558517
Iter: 1865 loss: 0.0024855698
Iter: 1866 loss: 0.00248232367
Iter: 1867 loss: 0.0024811253
Iter: 1868 loss: 0.0024793304
Iter: 1869 loss: 0.00247269426
Iter: 1870 loss: 0.00249698781
Iter: 1871 loss: 0.00247106072
Iter: 1872 loss: 0.0024705315
Iter: 1873 loss: 0.00246700784
Iter: 1874 loss: 0.00246515754
Iter: 1875 loss: 0.00246990123
Iter: 1876 loss: 0.00246450887
Iter: 1877 loss: 0.00246318942
Iter: 1878 loss: 0.0024606
Iter: 1879 loss: 0.0025139004
Iter: 1880 loss: 0.00246057566
Iter: 1881 loss: 0.00245682
Iter: 1882 loss: 0.00245304173
Iter: 1883 loss: 0.00245228154
Iter: 1884 loss: 0.00244544027
Iter: 1885 loss: 0.00251922617
Iter: 1886 loss: 0.00244531594
Iter: 1887 loss: 0.0024450263
Iter: 1888 loss: 0.00244320184
Iter: 1889 loss: 0.00244249427
Iter: 1890 loss: 0.00244160509
Iter: 1891 loss: 0.00244154828
Iter: 1892 loss: 0.00243773405
Iter: 1893 loss: 0.00243412261
Iter: 1894 loss: 0.00243329979
Iter: 1895 loss: 0.00242722896
Iter: 1896 loss: 0.00244416296
Iter: 1897 loss: 0.00242525735
Iter: 1898 loss: 0.00242036767
Iter: 1899 loss: 0.00244192174
Iter: 1900 loss: 0.00241937768
Iter: 1901 loss: 0.00241559884
Iter: 1902 loss: 0.00242080563
Iter: 1903 loss: 0.00241370802
Iter: 1904 loss: 0.00240899227
Iter: 1905 loss: 0.00242982223
Iter: 1906 loss: 0.00240803929
Iter: 1907 loss: 0.0024026949
Iter: 1908 loss: 0.00242212694
Iter: 1909 loss: 0.00240134494
Iter: 1910 loss: 0.00239952141
Iter: 1911 loss: 0.00239952095
Iter: 1912 loss: 0.00239775167
Iter: 1913 loss: 0.00239287317
Iter: 1914 loss: 0.00242048316
Iter: 1915 loss: 0.00239144824
Iter: 1916 loss: 0.00238969969
Iter: 1917 loss: 0.00238764565
Iter: 1918 loss: 0.002390699
Iter: 1919 loss: 0.00238645775
Iter: 1920 loss: 0.0023859879
Iter: 1921 loss: 0.00238480279
Iter: 1922 loss: 0.00239487039
Iter: 1923 loss: 0.00238460978
Iter: 1924 loss: 0.00238142931
Iter: 1925 loss: 0.00238430803
Iter: 1926 loss: 0.0023795946
Iter: 1927 loss: 0.0023765848
Iter: 1928 loss: 0.00238542771
Iter: 1929 loss: 0.00237567769
Iter: 1930 loss: 0.00237217499
Iter: 1931 loss: 0.00238627219
Iter: 1932 loss: 0.00237138779
Iter: 1933 loss: 0.00236750161
Iter: 1934 loss: 0.00237060757
Iter: 1935 loss: 0.00236514886
Iter: 1936 loss: 0.00236216956
Iter: 1937 loss: 0.00235868897
Iter: 1938 loss: 0.00235828524
Iter: 1939 loss: 0.00235535717
Iter: 1940 loss: 0.0023553581
Iter: 1941 loss: 0.00235300395
Iter: 1942 loss: 0.00234930916
Iter: 1943 loss: 0.00234929193
Iter: 1944 loss: 0.00234537944
Iter: 1945 loss: 0.00234150491
Iter: 1946 loss: 0.0023406595
Iter: 1947 loss: 0.00233926321
Iter: 1948 loss: 0.00234105159
Iter: 1949 loss: 0.0023385759
Iter: 1950 loss: 0.0023369696
Iter: 1951 loss: 0.00233646203
Iter: 1952 loss: 0.00233551161
Iter: 1953 loss: 0.00233285199
Iter: 1954 loss: 0.00234262319
Iter: 1955 loss: 0.00233219191
Iter: 1956 loss: 0.00232939725
Iter: 1957 loss: 0.00232461886
Iter: 1958 loss: 0.00232462701
Iter: 1959 loss: 0.00232039229
Iter: 1960 loss: 0.00238152593
Iter: 1961 loss: 0.00232038903
Iter: 1962 loss: 0.00231742626
Iter: 1963 loss: 0.0023185648
Iter: 1964 loss: 0.00231537526
Iter: 1965 loss: 0.00231213332
Iter: 1966 loss: 0.00233085826
Iter: 1967 loss: 0.00231169513
Iter: 1968 loss: 0.00230917893
Iter: 1969 loss: 0.00230429647
Iter: 1970 loss: 0.00240404345
Iter: 1971 loss: 0.00230425107
Iter: 1972 loss: 0.00230246596
Iter: 1973 loss: 0.00230084197
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8
+ date
Tue Oct 27 19:50:15 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f43302158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f4330e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f4330ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c1d2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c1d2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c140ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c0a4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c0d3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c05d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c05d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f1c02d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f000a8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f000a89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f000c6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f000789d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f0003e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f00043488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea07c3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea07887b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea0794f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea07a7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea073bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea07256a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea0725ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea06cd488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea06cd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea06b1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea065e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea065e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea065e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea05bc7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea05e4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea05e42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea057f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea05b4488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea05720d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.21513167
Iter: 2 loss: 11.4063587
Iter: 3 loss: 11.4052076
Iter: 4 loss: 7.53938293
Iter: 5 loss: 7.53837872
Iter: 6 loss: 5.04269075
Iter: 7 loss: 5.04190731
Iter: 8 loss: 3.50323725
Iter: 9 loss: 3.50263691
Iter: 10 loss: 2.52465
Iter: 11 loss: 2.52413082
Iter: 12 loss: 1.86777699
Iter: 13 loss: 1.86729133
Iter: 14 loss: 1.40935421
Iter: 15 loss: 1.40885139
Iter: 16 loss: 1.0686388
Iter: 17 loss: 1.06804991
Iter: 18 loss: 0.803680539
Iter: 19 loss: 0.802944779
Iter: 20 loss: 0.591020703
Iter: 21 loss: 0.59005332
Iter: 22 loss: 0.419326365
Iter: 23 loss: 0.418101519
Iter: 24 loss: 0.285904408
Iter: 25 loss: 0.28452754
Iter: 26 loss: 0.188977063
Iter: 27 loss: 0.187617898
Iter: 28 loss: 0.185925215
Iter: 29 loss: 0.179063052
Iter: 30 loss: 0.142389894
Iter: 31 loss: 1000.49414
Iter: 32 loss: 0.0763532519
Iter: 33 loss: 0.0800801218
Iter: 34 loss: 848.705444
Iter: 35 loss: 0.080074653
Iter: 36 loss: 0.0858783275
Iter: 37 loss: 0.0764660388
Iter: 38 loss: 0.0831786394
Iter: 39 loss: 0.06996952
Iter: 40 loss: 0.138281569
Iter: 41 loss: 0.0661278367
Iter: 42 loss: 923.654175
Iter: 43 loss: 0.052090317
Iter: 44 loss: 0.0521044657
Iter: 45 loss: 0.047063984
Iter: 46 loss: 0.0466935933
Iter: 47 loss: 0.0477968678
Iter: 48 loss: 0.045491375
Iter: 49 loss: 0.0435481668
Iter: 50 loss: 0.0608318672
Iter: 51 loss: 0.0430796705
Iter: 52 loss: 0.0462095663
Iter: 53 loss: 0.0421651304
Iter: 54 loss: 0.041734539
Iter: 55 loss: 0.0407354608
Iter: 56 loss: 0.038679637
Iter: 57 loss: 0.190423697
Iter: 58 loss: 0.0386758074
Iter: 59 loss: 0.0358979702
Iter: 60 loss: 0.0373303033
Iter: 61 loss: 0.034783572
Iter: 62 loss: 0.03409224
Iter: 63 loss: 0.033027567
Iter: 64 loss: 0.0329699777
Iter: 65 loss: 0.0318335183
Iter: 66 loss: 0.0314541236
Iter: 67 loss: 0.0306668486
Iter: 68 loss: 0.0279402286
Iter: 69 loss: 0.0342215747
Iter: 70 loss: 0.0268843696
Iter: 71 loss: 0.0252608359
Iter: 72 loss: 0.0271360893
Iter: 73 loss: 0.024364803
Iter: 74 loss: 0.0228652265
Iter: 75 loss: 0.0313255414
Iter: 76 loss: 0.0225124657
Iter: 77 loss: 0.0213080421
Iter: 78 loss: 0.0327082686
Iter: 79 loss: 0.0212523
Iter: 80 loss: 0.0205313675
Iter: 81 loss: 0.0205029473
Iter: 82 loss: 0.0198099278
Iter: 83 loss: 0.0196493622
Iter: 84 loss: 0.0192373637
Iter: 85 loss: 0.0184511039
Iter: 86 loss: 0.0477798283
Iter: 87 loss: 0.0184509344
Iter: 88 loss: 0.0180218127
Iter: 89 loss: 0.0186584871
Iter: 90 loss: 0.0178269763
Iter: 91 loss: 0.0171329603
Iter: 92 loss: 0.0204641167
Iter: 93 loss: 0.0169727243
Iter: 94 loss: 0.0174739286
Iter: 95 loss: 0.0163838118
Iter: 96 loss: 0.0160580557
Iter: 97 loss: 0.0182973631
Iter: 98 loss: 0.0159912128
Iter: 99 loss: 0.0157931186
Iter: 100 loss: 0.0163595
Iter: 101 loss: 0.0157167353
Iter: 102 loss: 0.0154705644
Iter: 103 loss: 0.0157073103
Iter: 104 loss: 0.015340562
Iter: 105 loss: 0.0150948185
Iter: 106 loss: 0.015201482
Iter: 107 loss: 0.0149245467
Iter: 108 loss: 0.014478988
Iter: 109 loss: 0.0161912031
Iter: 110 loss: 0.0143843647
Iter: 111 loss: 0.0140297813
Iter: 112 loss: 0.0163888577
Iter: 113 loss: 0.013982648
Iter: 114 loss: 0.0136364289
Iter: 115 loss: 0.0139014162
Iter: 116 loss: 0.0134174693
Iter: 117 loss: 0.0129632056
Iter: 118 loss: 0.0131482612
Iter: 119 loss: 0.0126792435
Iter: 120 loss: 0.0122937746
Iter: 121 loss: 0.0166358594
Iter: 122 loss: 0.0122840703
Iter: 123 loss: 0.0119186044
Iter: 124 loss: 0.0139743462
Iter: 125 loss: 0.0118583748
Iter: 126 loss: 0.0115717575
Iter: 127 loss: 0.0142410323
Iter: 128 loss: 0.0115612671
Iter: 129 loss: 0.0113425758
Iter: 130 loss: 0.0120431483
Iter: 131 loss: 0.0112672877
Iter: 132 loss: 0.0110757789
Iter: 133 loss: 0.0134022832
Iter: 134 loss: 0.011075153
Iter: 135 loss: 0.0109732067
Iter: 136 loss: 0.0110506043
Iter: 137 loss: 0.0109091634
Iter: 138 loss: 0.0106670586
Iter: 139 loss: 0.010960035
Iter: 140 loss: 0.0105509777
Iter: 141 loss: 0.0103437901
Iter: 142 loss: 0.0114448182
Iter: 143 loss: 0.0103022307
Iter: 144 loss: 0.0101660583
Iter: 145 loss: 0.0100658704
Iter: 146 loss: 0.0100207292
Iter: 147 loss: 0.00977344904
Iter: 148 loss: 0.0115813669
Iter: 149 loss: 0.00975397788
Iter: 150 loss: 0.00952822901
Iter: 151 loss: 0.010036191
Iter: 152 loss: 0.0094463937
Iter: 153 loss: 0.00927525386
Iter: 154 loss: 0.00929889176
Iter: 155 loss: 0.00913924444
Iter: 156 loss: 0.00898970757
Iter: 157 loss: 0.00886489823
Iter: 158 loss: 0.00882683136
Iter: 159 loss: 0.00871316
Iter: 160 loss: 0.00900269952
Iter: 161 loss: 0.00866929069
Iter: 162 loss: 0.00861335918
Iter: 163 loss: 0.00851816311
Iter: 164 loss: 0.00851792935
Iter: 165 loss: 0.00839114282
Iter: 166 loss: 0.00917544775
Iter: 167 loss: 0.00838056765
Iter: 168 loss: 0.00829920545
Iter: 169 loss: 0.00865606777
Iter: 170 loss: 0.00828237738
Iter: 171 loss: 0.0080960067
Iter: 172 loss: 0.00937014632
Iter: 173 loss: 0.00808108319
Iter: 174 loss: 0.00785732269
Iter: 175 loss: 0.0109147318
Iter: 176 loss: 0.00785479881
Iter: 177 loss: 0.00771714048
Iter: 178 loss: 0.00828044862
Iter: 179 loss: 0.00768944668
Iter: 180 loss: 0.00760438479
Iter: 181 loss: 0.0075294124
Iter: 182 loss: 0.0075062653
Iter: 183 loss: 0.00741178636
Iter: 184 loss: 0.00727408
Iter: 185 loss: 0.00727065932
Iter: 186 loss: 0.00715030637
Iter: 187 loss: 0.00747559825
Iter: 188 loss: 0.00711335521
Iter: 189 loss: 0.00702339364
Iter: 190 loss: 0.00779847894
Iter: 191 loss: 0.00701518822
Iter: 192 loss: 0.00694201794
Iter: 193 loss: 0.0069151856
Iter: 194 loss: 0.00687440112
Iter: 195 loss: 0.00674883509
Iter: 196 loss: 0.0086529
Iter: 197 loss: 0.00674845604
Iter: 198 loss: 0.00688092038
Iter: 199 loss: 0.00671356963
Iter: 200 loss: 0.00668775523
Iter: 201 loss: 0.00672282651
Iter: 202 loss: 0.00667467341
Iter: 203 loss: 0.00661421707
Iter: 204 loss: 0.00649489835
Iter: 205 loss: 0.0088285869
Iter: 206 loss: 0.00649366621
Iter: 207 loss: 0.00640384946
Iter: 208 loss: 0.00636879308
Iter: 209 loss: 0.00629607169
Iter: 210 loss: 0.00628995057
Iter: 211 loss: 0.00625914242
Iter: 212 loss: 0.00621376466
Iter: 213 loss: 0.00621259818
Iter: 214 loss: 0.00615400448
Iter: 215 loss: 0.00614981959
Iter: 216 loss: 0.00610449258
Iter: 217 loss: 0.00609473512
Iter: 218 loss: 0.00606605411
Iter: 219 loss: 0.00601345487
Iter: 220 loss: 0.00603971351
Iter: 221 loss: 0.00597700849
Iter: 222 loss: 0.00592570286
Iter: 223 loss: 0.0062526227
Iter: 224 loss: 0.00592048559
Iter: 225 loss: 0.00587289128
Iter: 226 loss: 0.00579760969
Iter: 227 loss: 0.00579669047
Iter: 228 loss: 0.00569255417
Iter: 229 loss: 0.00619304273
Iter: 230 loss: 0.00567412656
Iter: 231 loss: 0.00571048073
Iter: 232 loss: 0.00564230653
Iter: 233 loss: 0.00562742725
Iter: 234 loss: 0.00559345167
Iter: 235 loss: 0.00605578395
Iter: 236 loss: 0.00559124909
Iter: 237 loss: 0.00554400822
Iter: 238 loss: 0.00553198485
Iter: 239 loss: 0.00550385518
Iter: 240 loss: 0.00547479838
Iter: 241 loss: 0.00543728378
Iter: 242 loss: 0.00543429889
Iter: 243 loss: 0.00540552661
Iter: 244 loss: 0.00545744319
Iter: 245 loss: 0.00539356051
Iter: 246 loss: 0.00536276586
Iter: 247 loss: 0.00532727083
Iter: 248 loss: 0.00532313623
Iter: 249 loss: 0.00526984688
Iter: 250 loss: 0.0058603338
Iter: 251 loss: 0.00526873069
Iter: 252 loss: 0.00523469131
Iter: 253 loss: 0.00523428479
Iter: 254 loss: 0.00520900963
Iter: 255 loss: 0.00534770172
Iter: 256 loss: 0.00520566059
Iter: 257 loss: 0.00517756445
Iter: 258 loss: 0.00519342115
Iter: 259 loss: 0.0051588784
Iter: 260 loss: 0.00512212701
Iter: 261 loss: 0.00513420906
Iter: 262 loss: 0.00509597594
Iter: 263 loss: 0.00506488793
Iter: 264 loss: 0.00506359758
Iter: 265 loss: 0.00503740413
Iter: 266 loss: 0.00511363335
Iter: 267 loss: 0.00502975797
Iter: 268 loss: 0.00501656719
Iter: 269 loss: 0.00499283802
Iter: 270 loss: 0.0056216009
Iter: 271 loss: 0.00499282498
Iter: 272 loss: 0.00497423857
Iter: 273 loss: 0.00503929146
Iter: 274 loss: 0.00496979896
Iter: 275 loss: 0.00495895
Iter: 276 loss: 0.00493563199
Iter: 277 loss: 0.005338897
Iter: 278 loss: 0.00493489346
Iter: 279 loss: 0.0049022045
Iter: 280 loss: 0.00493197469
Iter: 281 loss: 0.00488337781
Iter: 282 loss: 0.00484555867
Iter: 283 loss: 0.00484497054
Iter: 284 loss: 0.00479965657
Iter: 285 loss: 0.00477393251
Iter: 286 loss: 0.00475428719
Iter: 287 loss: 0.00473624887
Iter: 288 loss: 0.00473244302
Iter: 289 loss: 0.00471288618
Iter: 290 loss: 0.00470799254
Iter: 291 loss: 0.00469544902
Iter: 292 loss: 0.00465398468
Iter: 293 loss: 0.00469814613
Iter: 294 loss: 0.0046308469
Iter: 295 loss: 0.00459228177
Iter: 296 loss: 0.00507778116
Iter: 297 loss: 0.00459213741
Iter: 298 loss: 0.00457502436
Iter: 299 loss: 0.00473022275
Iter: 300 loss: 0.00457401481
Iter: 301 loss: 0.00456414139
Iter: 302 loss: 0.00456054322
Iter: 303 loss: 0.00455506332
Iter: 304 loss: 0.00453982782
Iter: 305 loss: 0.00453958893
Iter: 306 loss: 0.00452134712
Iter: 307 loss: 0.00458003534
Iter: 308 loss: 0.00451627187
Iter: 309 loss: 0.00450563058
Iter: 310 loss: 0.0044947844
Iter: 311 loss: 0.00449261628
Iter: 312 loss: 0.00447184779
Iter: 313 loss: 0.00445774477
Iter: 314 loss: 0.00445015356
Iter: 315 loss: 0.00442314288
Iter: 316 loss: 0.00462372135
Iter: 317 loss: 0.00442091608
Iter: 318 loss: 0.00439097267
Iter: 319 loss: 0.00452494295
Iter: 320 loss: 0.00438534748
Iter: 321 loss: 0.00436865678
Iter: 322 loss: 0.00444900617
Iter: 323 loss: 0.00436533848
Iter: 324 loss: 0.00434080604
Iter: 325 loss: 0.00430360297
Iter: 326 loss: 0.00430294
Iter: 327 loss: 0.00428099185
Iter: 328 loss: 0.00427823514
Iter: 329 loss: 0.00426693168
Iter: 330 loss: 0.00424920488
Iter: 331 loss: 0.00424899859
Iter: 332 loss: 0.00424024
Iter: 333 loss: 0.00423390139
Iter: 334 loss: 0.00422049873
Iter: 335 loss: 0.00426819129
Iter: 336 loss: 0.00421673572
Iter: 337 loss: 0.00420814939
Iter: 338 loss: 0.00418752851
Iter: 339 loss: 0.00441933842
Iter: 340 loss: 0.00418544607
Iter: 341 loss: 0.00416201
Iter: 342 loss: 0.00420137122
Iter: 343 loss: 0.00415133918
Iter: 344 loss: 0.0041351323
Iter: 345 loss: 0.00419401936
Iter: 346 loss: 0.00413091248
Iter: 347 loss: 0.00410430972
Iter: 348 loss: 0.00435536774
Iter: 349 loss: 0.00410305755
Iter: 350 loss: 0.0040840758
Iter: 351 loss: 0.00427207584
Iter: 352 loss: 0.00408353377
Iter: 353 loss: 0.0040667383
Iter: 354 loss: 0.00409607729
Iter: 355 loss: 0.00405938737
Iter: 356 loss: 0.00404538261
Iter: 357 loss: 0.00404900359
Iter: 358 loss: 0.00403507892
Iter: 359 loss: 0.00400969572
Iter: 360 loss: 0.00408742065
Iter: 361 loss: 0.00400270894
Iter: 362 loss: 0.00399005134
Iter: 363 loss: 0.00398823712
Iter: 364 loss: 0.00397985242
Iter: 365 loss: 0.00395779684
Iter: 366 loss: 0.00411571236
Iter: 367 loss: 0.00395319518
Iter: 368 loss: 0.00399358431
Iter: 369 loss: 0.00394114619
Iter: 370 loss: 0.0039290241
Iter: 371 loss: 0.00393139385
Iter: 372 loss: 0.00392003078
Iter: 373 loss: 0.00388983265
Iter: 374 loss: 0.00395953562
Iter: 375 loss: 0.00387876318
Iter: 376 loss: 0.00385185773
Iter: 377 loss: 0.00386273186
Iter: 378 loss: 0.00383325503
Iter: 379 loss: 0.00380572397
Iter: 380 loss: 0.00400850037
Iter: 381 loss: 0.00380332349
Iter: 382 loss: 0.00377821946
Iter: 383 loss: 0.00376594486
Iter: 384 loss: 0.00375400018
Iter: 385 loss: 0.00372614013
Iter: 386 loss: 0.00373246288
Iter: 387 loss: 0.00370535837
Iter: 388 loss: 0.00367641356
Iter: 389 loss: 0.00367620401
Iter: 390 loss: 0.00365971867
Iter: 391 loss: 0.00367577653
Iter: 392 loss: 0.00365001499
Iter: 393 loss: 0.00363536971
Iter: 394 loss: 0.00365233095
Iter: 395 loss: 0.00362764881
Iter: 396 loss: 0.00361858727
Iter: 397 loss: 0.00368953682
Iter: 398 loss: 0.00361777493
Iter: 399 loss: 0.00361069944
Iter: 400 loss: 0.00366861885
Iter: 401 loss: 0.00361037953
Iter: 402 loss: 0.00360202161
Iter: 403 loss: 0.00359925791
Iter: 404 loss: 0.00359432027
Iter: 405 loss: 0.00358863268
Iter: 406 loss: 0.00358331413
Iter: 407 loss: 0.00358199235
Iter: 408 loss: 0.00356990402
Iter: 409 loss: 0.00355039164
Iter: 410 loss: 0.00355025101
Iter: 411 loss: 0.00353152887
Iter: 412 loss: 0.00381896156
Iter: 413 loss: 0.00353150815
Iter: 414 loss: 0.00351565657
Iter: 415 loss: 0.00348735228
Iter: 416 loss: 0.00418216828
Iter: 417 loss: 0.00348735484
Iter: 418 loss: 0.00346318819
Iter: 419 loss: 0.00368571072
Iter: 420 loss: 0.0034621316
Iter: 421 loss: 0.00344209606
Iter: 422 loss: 0.0034595984
Iter: 423 loss: 0.00343006244
Iter: 424 loss: 0.00341410632
Iter: 425 loss: 0.00340322638
Iter: 426 loss: 0.00339750596
Iter: 427 loss: 0.00337773864
Iter: 428 loss: 0.00344690983
Iter: 429 loss: 0.00337227783
Iter: 430 loss: 0.00334911235
Iter: 431 loss: 0.00349862967
Iter: 432 loss: 0.00334683293
Iter: 433 loss: 0.00333995046
Iter: 434 loss: 0.00341408863
Iter: 435 loss: 0.00333971879
Iter: 436 loss: 0.00333354436
Iter: 437 loss: 0.00333822472
Iter: 438 loss: 0.00332984119
Iter: 439 loss: 0.00332183368
Iter: 440 loss: 0.00332028512
Iter: 441 loss: 0.00331491255
Iter: 442 loss: 0.00330307242
Iter: 443 loss: 0.00328968326
Iter: 444 loss: 0.00328793982
Iter: 445 loss: 0.00326321553
Iter: 446 loss: 0.00329128699
Iter: 447 loss: 0.00324976444
Iter: 448 loss: 0.00323390891
Iter: 449 loss: 0.00341457012
Iter: 450 loss: 0.00323364814
Iter: 451 loss: 0.00321606849
Iter: 452 loss: 0.00321416743
Iter: 453 loss: 0.00320143206
Iter: 454 loss: 0.0031821765
Iter: 455 loss: 0.00324923405
Iter: 456 loss: 0.0031771115
Iter: 457 loss: 0.0031554536
Iter: 458 loss: 0.00326304347
Iter: 459 loss: 0.00315206125
Iter: 460 loss: 0.00313147972
Iter: 461 loss: 0.00325496914
Iter: 462 loss: 0.0031286045
Iter: 463 loss: 0.00311067
Iter: 464 loss: 0.00325021241
Iter: 465 loss: 0.00310954172
Iter: 466 loss: 0.00310700177
Iter: 467 loss: 0.00310267741
Iter: 468 loss: 0.00309730484
Iter: 469 loss: 0.00310596591
Iter: 470 loss: 0.00309487223
Iter: 471 loss: 0.00308845448
Iter: 472 loss: 0.00307524414
Iter: 473 loss: 0.00332447561
Iter: 474 loss: 0.0030749985
Iter: 475 loss: 0.00305537228
Iter: 476 loss: 0.00304942485
Iter: 477 loss: 0.00303773372
Iter: 478 loss: 0.00301267859
Iter: 479 loss: 0.00310143526
Iter: 480 loss: 0.00300649111
Iter: 481 loss: 0.00298953964
Iter: 482 loss: 0.00297772372
Iter: 483 loss: 0.0029716515
Iter: 484 loss: 0.00294833211
Iter: 485 loss: 0.00294832606
Iter: 486 loss: 0.00293238834
Iter: 487 loss: 0.00295292516
Iter: 488 loss: 0.00292425416
Iter: 489 loss: 0.00290993811
Iter: 490 loss: 0.00288402429
Iter: 491 loss: 0.00351805473
Iter: 492 loss: 0.00288401218
Iter: 493 loss: 0.00285898359
Iter: 494 loss: 0.00285782013
Iter: 495 loss: 0.0028449581
Iter: 496 loss: 0.00287732133
Iter: 497 loss: 0.00284071406
Iter: 498 loss: 0.00283127604
Iter: 499 loss: 0.00284759561
Iter: 500 loss: 0.0028268774
Iter: 501 loss: 0.00281920889
Iter: 502 loss: 0.00283753639
Iter: 503 loss: 0.00281661027
Iter: 504 loss: 0.00280661648
Iter: 505 loss: 0.00279553421
Iter: 506 loss: 0.00279391091
Iter: 507 loss: 0.00278503564
Iter: 508 loss: 0.00277701346
Iter: 509 loss: 0.00277477968
Iter: 510 loss: 0.00275810878
Iter: 511 loss: 0.0028215372
Iter: 512 loss: 0.00275421562
Iter: 513 loss: 0.00273953541
Iter: 514 loss: 0.00287736324
Iter: 515 loss: 0.00273895543
Iter: 516 loss: 0.00273153535
Iter: 517 loss: 0.00273928558
Iter: 518 loss: 0.00272741029
Iter: 519 loss: 0.00271667191
Iter: 520 loss: 0.00272682356
Iter: 521 loss: 0.00271042669
Iter: 522 loss: 0.00269720517
Iter: 523 loss: 0.00272803
Iter: 524 loss: 0.00269239629
Iter: 525 loss: 0.00267797895
Iter: 526 loss: 0.0026717314
Iter: 527 loss: 0.00266429316
Iter: 528 loss: 0.00265536876
Iter: 529 loss: 0.00265256152
Iter: 530 loss: 0.00264635612
Iter: 531 loss: 0.00273390114
Iter: 532 loss: 0.00264635659
Iter: 533 loss: 0.00264380733
Iter: 534 loss: 0.00263950927
Iter: 535 loss: 0.00263949763
Iter: 536 loss: 0.00263383612
Iter: 537 loss: 0.0026556761
Iter: 538 loss: 0.00263255183
Iter: 539 loss: 0.00262780627
Iter: 540 loss: 0.00261426694
Iter: 541 loss: 0.00268364022
Iter: 542 loss: 0.00260956632
Iter: 543 loss: 0.00259251264
Iter: 544 loss: 0.00258788187
Iter: 545 loss: 0.00257734908
Iter: 546 loss: 0.00255843764
Iter: 547 loss: 0.00276122289
Iter: 548 loss: 0.00255794404
Iter: 549 loss: 0.00253923284
Iter: 550 loss: 0.00259164115
Iter: 551 loss: 0.00253324537
Iter: 552 loss: 0.00252150046
Iter: 553 loss: 0.00259471522
Iter: 554 loss: 0.00252010603
Iter: 555 loss: 0.00250751874
Iter: 556 loss: 0.0025030626
Iter: 557 loss: 0.00249596778
Iter: 558 loss: 0.00247553154
Iter: 559 loss: 0.00258088484
Iter: 560 loss: 0.00247223559
Iter: 561 loss: 0.00246797269
Iter: 562 loss: 0.00246207765
Iter: 563 loss: 0.00245722383
Iter: 564 loss: 0.00245714211
Iter: 565 loss: 0.00245321728
Iter: 566 loss: 0.00244907942
Iter: 567 loss: 0.002448346
Iter: 568 loss: 0.00244080322
Iter: 569 loss: 0.00245131738
Iter: 570 loss: 0.00243718247
Iter: 571 loss: 0.00242946157
Iter: 572 loss: 0.0024187481
Iter: 573 loss: 0.00241827429
Iter: 574 loss: 0.00240626326
Iter: 575 loss: 0.00239174254
Iter: 576 loss: 0.00239031296
Iter: 577 loss: 0.0023750728
Iter: 578 loss: 0.00237991544
Iter: 579 loss: 0.0023643421
Iter: 580 loss: 0.00235118042
Iter: 581 loss: 0.00239043799
Iter: 582 loss: 0.0023470677
Iter: 583 loss: 0.00233550044
Iter: 584 loss: 0.00236454187
Iter: 585 loss: 0.00233132509
Iter: 586 loss: 0.00231988123
Iter: 587 loss: 0.00234801089
Iter: 588 loss: 0.00231577
Iter: 589 loss: 0.0023028946
Iter: 590 loss: 0.00231047836
Iter: 591 loss: 0.00229458627
Iter: 592 loss: 0.00228161667
Iter: 593 loss: 0.00239484455
Iter: 594 loss: 0.00228086207
Iter: 595 loss: 0.00227233418
Iter: 596 loss: 0.00226132385
Iter: 597 loss: 0.00226061372
Iter: 598 loss: 0.00227164919
Iter: 599 loss: 0.00225533638
Iter: 600 loss: 0.0022505275
Iter: 601 loss: 0.00224484759
Iter: 602 loss: 0.00224425341
Iter: 603 loss: 0.00223155878
Iter: 604 loss: 0.0022464369
Iter: 605 loss: 0.0022247131
Iter: 606 loss: 0.00221226364
Iter: 607 loss: 0.00221877359
Iter: 608 loss: 0.00220401585
Iter: 609 loss: 0.00219054823
Iter: 610 loss: 0.0022354424
Iter: 611 loss: 0.00218684878
Iter: 612 loss: 0.00218083151
Iter: 613 loss: 0.00217149174
Iter: 614 loss: 0.00217136415
Iter: 615 loss: 0.00216063205
Iter: 616 loss: 0.00216056593
Iter: 617 loss: 0.00215101521
Iter: 618 loss: 0.00217003934
Iter: 619 loss: 0.00214730855
Iter: 620 loss: 0.00214152411
Iter: 621 loss: 0.00213485816
Iter: 622 loss: 0.00213407935
Iter: 623 loss: 0.00212546531
Iter: 624 loss: 0.0021253638
Iter: 625 loss: 0.00212089065
Iter: 626 loss: 0.00212233979
Iter: 627 loss: 0.0021177493
Iter: 628 loss: 0.00211255532
Iter: 629 loss: 0.00210848311
Iter: 630 loss: 0.00210682978
Iter: 631 loss: 0.00210091146
Iter: 632 loss: 0.0021488145
Iter: 633 loss: 0.00210057572
Iter: 634 loss: 0.00209478871
Iter: 635 loss: 0.00209583156
Iter: 636 loss: 0.00209039194
Iter: 637 loss: 0.0020854352
Iter: 638 loss: 0.00208087498
Iter: 639 loss: 0.00207966752
Iter: 640 loss: 0.00207330333
Iter: 641 loss: 0.00215841085
Iter: 642 loss: 0.00207326561
Iter: 643 loss: 0.00206751656
Iter: 644 loss: 0.0020702458
Iter: 645 loss: 0.00206365623
Iter: 646 loss: 0.00205456349
Iter: 647 loss: 0.0020545
Iter: 648 loss: 0.00204730174
Iter: 649 loss: 0.00204411498
Iter: 650 loss: 0.00203966838
Iter: 651 loss: 0.0020343042
Iter: 652 loss: 0.00202312972
Iter: 653 loss: 0.0022172411
Iter: 654 loss: 0.00202287664
Iter: 655 loss: 0.00201037782
Iter: 656 loss: 0.00202303147
Iter: 657 loss: 0.00200335123
Iter: 658 loss: 0.00199854583
Iter: 659 loss: 0.00199830858
Iter: 660 loss: 0.00199402426
Iter: 661 loss: 0.00206266204
Iter: 662 loss: 0.00199402543
Iter: 663 loss: 0.00199064193
Iter: 664 loss: 0.00198956137
Iter: 665 loss: 0.00198760442
Iter: 666 loss: 0.00198242115
Iter: 667 loss: 0.00199709041
Iter: 668 loss: 0.00198072661
Iter: 669 loss: 0.00197727
Iter: 670 loss: 0.00197139033
Iter: 671 loss: 0.00197138125
Iter: 672 loss: 0.00196249015
Iter: 673 loss: 0.0019801273
Iter: 674 loss: 0.00195886102
Iter: 675 loss: 0.00195164757
Iter: 676 loss: 0.0019984711
Iter: 677 loss: 0.00195088214
Iter: 678 loss: 0.00194211968
Iter: 679 loss: 0.00194961985
Iter: 680 loss: 0.00193695095
Iter: 681 loss: 0.0019244469
Iter: 682 loss: 0.00190455373
Iter: 683 loss: 0.00190436665
Iter: 684 loss: 0.00191916933
Iter: 685 loss: 0.00189713563
Iter: 686 loss: 0.00189140474
Iter: 687 loss: 0.00188386731
Iter: 688 loss: 0.00188338012
Iter: 689 loss: 0.00187572569
Iter: 690 loss: 0.00188253797
Iter: 691 loss: 0.00187127443
Iter: 692 loss: 0.0018651057
Iter: 693 loss: 0.00190659589
Iter: 694 loss: 0.00186443131
Iter: 695 loss: 0.00185870251
Iter: 696 loss: 0.00191462575
Iter: 697 loss: 0.00185853755
Iter: 698 loss: 0.00185531587
Iter: 699 loss: 0.00185020408
Iter: 700 loss: 0.00185014587
Iter: 701 loss: 0.00184415979
Iter: 702 loss: 0.00183620269
Iter: 703 loss: 0.00183575065
Iter: 704 loss: 0.00183138077
Iter: 705 loss: 0.001835
Iter: 706 loss: 0.00182875781
Iter: 707 loss: 0.00182523008
Iter: 708 loss: 0.0018194851
Iter: 709 loss: 0.00181945611
Iter: 710 loss: 0.00181450625
Iter: 711 loss: 0.00180948304
Iter: 712 loss: 0.0018084948
Iter: 713 loss: 0.00180138252
Iter: 714 loss: 0.00182546501
Iter: 715 loss: 0.00179945538
Iter: 716 loss: 0.00179066474
Iter: 717 loss: 0.00184680289
Iter: 718 loss: 0.00178972946
Iter: 719 loss: 0.00178239623
Iter: 720 loss: 0.00179696013
Iter: 721 loss: 0.00177939539
Iter: 722 loss: 0.00177426706
Iter: 723 loss: 0.00183356775
Iter: 724 loss: 0.00177414855
Iter: 725 loss: 0.00176993804
Iter: 726 loss: 0.00176502601
Iter: 727 loss: 0.001764455
Iter: 728 loss: 0.00175628578
Iter: 729 loss: 0.00177816476
Iter: 730 loss: 0.00175364572
Iter: 731 loss: 0.00175147294
Iter: 732 loss: 0.00174818723
Iter: 733 loss: 0.00174447056
Iter: 734 loss: 0.00173815084
Iter: 735 loss: 0.00173813803
Iter: 736 loss: 0.00173332
Iter: 737 loss: 0.00173323252
Iter: 738 loss: 0.00172973424
Iter: 739 loss: 0.00173479901
Iter: 740 loss: 0.00172807742
Iter: 741 loss: 0.00172446703
Iter: 742 loss: 0.00171443797
Iter: 743 loss: 0.00177335355
Iter: 744 loss: 0.00171148614
Iter: 745 loss: 0.00170633942
Iter: 746 loss: 0.00172514166
Iter: 747 loss: 0.00170512986
Iter: 748 loss: 0.00170277222
Iter: 749 loss: 0.00169487798
Iter: 750 loss: 0.00169300381
Iter: 751 loss: 0.00168595696
Iter: 752 loss: 0.0016760435
Iter: 753 loss: 0.00177768676
Iter: 754 loss: 0.0016757237
Iter: 755 loss: 0.00166834216
Iter: 756 loss: 0.00168158836
Iter: 757 loss: 0.00166517904
Iter: 758 loss: 0.00165486988
Iter: 759 loss: 0.00173707562
Iter: 760 loss: 0.00165413227
Iter: 761 loss: 0.00164754223
Iter: 762 loss: 0.00167652976
Iter: 763 loss: 0.00164618529
Iter: 764 loss: 0.0016419125
Iter: 765 loss: 0.00164004578
Iter: 766 loss: 0.00163787697
Iter: 767 loss: 0.00163324503
Iter: 768 loss: 0.00165376836
Iter: 769 loss: 0.00163232279
Iter: 770 loss: 0.00162723754
Iter: 771 loss: 0.00170425628
Iter: 772 loss: 0.00162723404
Iter: 773 loss: 0.00162705476
Iter: 774 loss: 0.00162394822
Iter: 775 loss: 0.00162174157
Iter: 776 loss: 0.00162713917
Iter: 777 loss: 0.00162096357
Iter: 778 loss: 0.00161985634
Iter: 779 loss: 0.00161917228
Iter: 780 loss: 0.00161675853
Iter: 781 loss: 0.00161011657
Iter: 782 loss: 0.00164856855
Iter: 783 loss: 0.0016082332
Iter: 784 loss: 0.00160037377
Iter: 785 loss: 0.00164103694
Iter: 786 loss: 0.00159907481
Iter: 787 loss: 0.0015928949
Iter: 788 loss: 0.00159588479
Iter: 789 loss: 0.0015887206
Iter: 790 loss: 0.00158210844
Iter: 791 loss: 0.0015920857
Iter: 792 loss: 0.00157890352
Iter: 793 loss: 0.0015745064
Iter: 794 loss: 0.00157450954
Iter: 795 loss: 0.00157102989
Iter: 796 loss: 0.0015824415
Iter: 797 loss: 0.00157003524
Iter: 798 loss: 0.00156716839
Iter: 799 loss: 0.00156050478
Iter: 800 loss: 0.00164173846
Iter: 801 loss: 0.00155998301
Iter: 802 loss: 0.00155341276
Iter: 803 loss: 0.00156378839
Iter: 804 loss: 0.0015503068
Iter: 805 loss: 0.00154556672
Iter: 806 loss: 0.00158152368
Iter: 807 loss: 0.00154520548
Iter: 808 loss: 0.00154087413
Iter: 809 loss: 0.00159651472
Iter: 810 loss: 0.0015408342
Iter: 811 loss: 0.00153849029
Iter: 812 loss: 0.00154444517
Iter: 813 loss: 0.00153771
Iter: 814 loss: 0.0015332374
Iter: 815 loss: 0.00153050967
Iter: 816 loss: 0.00152866589
Iter: 817 loss: 0.0015260498
Iter: 818 loss: 0.00152371102
Iter: 819 loss: 0.00152305851
Iter: 820 loss: 0.00151911261
Iter: 821 loss: 0.00151880272
Iter: 822 loss: 0.00151584751
Iter: 823 loss: 0.00151220616
Iter: 824 loss: 0.00152140553
Iter: 825 loss: 0.00151093956
Iter: 826 loss: 0.00150661916
Iter: 827 loss: 0.00150511693
Iter: 828 loss: 0.00150267466
Iter: 829 loss: 0.0014975667
Iter: 830 loss: 0.00149648322
Iter: 831 loss: 0.00149313069
Iter: 832 loss: 0.00148609874
Iter: 833 loss: 0.00150529109
Iter: 834 loss: 0.00148374867
Iter: 835 loss: 0.00147506641
Iter: 836 loss: 0.00149194244
Iter: 837 loss: 0.00147151074
Iter: 838 loss: 0.00146218273
Iter: 839 loss: 0.00150814082
Iter: 840 loss: 0.00146059028
Iter: 841 loss: 0.00146424817
Iter: 842 loss: 0.00145655242
Iter: 843 loss: 0.00145495264
Iter: 844 loss: 0.00145182153
Iter: 845 loss: 0.00151065714
Iter: 846 loss: 0.00145179871
Iter: 847 loss: 0.00144820265
Iter: 848 loss: 0.00144803384
Iter: 849 loss: 0.0014450762
Iter: 850 loss: 0.00144618982
Iter: 851 loss: 0.00144303194
Iter: 852 loss: 0.0014409381
Iter: 853 loss: 0.00144201017
Iter: 854 loss: 0.00143953122
Iter: 855 loss: 0.00143787684
Iter: 856 loss: 0.00143511989
Iter: 857 loss: 0.00143510604
Iter: 858 loss: 0.00142973661
Iter: 859 loss: 0.0014564374
Iter: 860 loss: 0.00142878713
Iter: 861 loss: 0.00142472703
Iter: 862 loss: 0.00147486397
Iter: 863 loss: 0.00142468151
Iter: 864 loss: 0.00142113934
Iter: 865 loss: 0.00141996122
Iter: 866 loss: 0.00141794304
Iter: 867 loss: 0.00141444162
Iter: 868 loss: 0.00140961725
Iter: 869 loss: 0.00140939921
Iter: 870 loss: 0.00140381465
Iter: 871 loss: 0.00139915943
Iter: 872 loss: 0.00139754766
Iter: 873 loss: 0.00138966076
Iter: 874 loss: 0.00143956789
Iter: 875 loss: 0.00138876191
Iter: 876 loss: 0.00138392253
Iter: 877 loss: 0.00138386851
Iter: 878 loss: 0.00138103578
Iter: 879 loss: 0.00138097769
Iter: 880 loss: 0.00137844391
Iter: 881 loss: 0.0013751795
Iter: 882 loss: 0.00137494435
Iter: 883 loss: 0.00136978319
Iter: 884 loss: 0.00138578471
Iter: 885 loss: 0.00136832823
Iter: 886 loss: 0.00136408163
Iter: 887 loss: 0.00136926677
Iter: 888 loss: 0.00136184215
Iter: 889 loss: 0.00135804119
Iter: 890 loss: 0.00135312439
Iter: 891 loss: 0.00135278422
Iter: 892 loss: 0.00134686858
Iter: 893 loss: 0.00137672538
Iter: 894 loss: 0.00134588452
Iter: 895 loss: 0.00134106772
Iter: 896 loss: 0.00135258608
Iter: 897 loss: 0.00133934116
Iter: 898 loss: 0.00133485603
Iter: 899 loss: 0.0013546783
Iter: 900 loss: 0.0013339452
Iter: 901 loss: 0.0013299014
Iter: 902 loss: 0.00134388346
Iter: 903 loss: 0.00132880709
Iter: 904 loss: 0.0013246662
Iter: 905 loss: 0.0013518054
Iter: 906 loss: 0.00132425653
Iter: 907 loss: 0.00132187421
Iter: 908 loss: 0.00131725275
Iter: 909 loss: 0.00141264801
Iter: 910 loss: 0.00131722
Iter: 911 loss: 0.00132029154
Iter: 912 loss: 0.00131547637
Iter: 913 loss: 0.00131414668
Iter: 914 loss: 0.00131487765
Iter: 915 loss: 0.00131326937
Iter: 916 loss: 0.0013116193
Iter: 917 loss: 0.00131170638
Iter: 918 loss: 0.00131032988
Iter: 919 loss: 0.00130775641
Iter: 920 loss: 0.0013037076
Iter: 921 loss: 0.00130366138
Iter: 922 loss: 0.00129895238
Iter: 923 loss: 0.0013292454
Iter: 924 loss: 0.00129844074
Iter: 925 loss: 0.00129521114
Iter: 926 loss: 0.00129256747
Iter: 927 loss: 0.00129162369
Iter: 928 loss: 0.00128725288
Iter: 929 loss: 0.00130479061
Iter: 930 loss: 0.00128626171
Iter: 931 loss: 0.00128313038
Iter: 932 loss: 0.00128179439
Iter: 933 loss: 0.00128017389
Iter: 934 loss: 0.00127691007
Iter: 935 loss: 0.00128991029
Iter: 936 loss: 0.00127613603
Iter: 937 loss: 0.00127333426
Iter: 938 loss: 0.00128311815
Iter: 939 loss: 0.00127262
Iter: 940 loss: 0.00126949418
Iter: 941 loss: 0.00126797147
Iter: 942 loss: 0.00126646948
Iter: 943 loss: 0.00126574258
Iter: 944 loss: 0.00126494991
Iter: 945 loss: 0.0012635832
Iter: 946 loss: 0.00126542826
Iter: 947 loss: 0.00126288831
Iter: 948 loss: 0.00126121799
Iter: 949 loss: 0.00125993602
Iter: 950 loss: 0.0012594061
Iter: 951 loss: 0.0012558389
Iter: 952 loss: 0.00125969
Iter: 953 loss: 0.00125385704
Iter: 954 loss: 0.00125065807
Iter: 955 loss: 0.00125272619
Iter: 956 loss: 0.00124862907
Iter: 957 loss: 0.00124484813
Iter: 958 loss: 0.00125059683
Iter: 959 loss: 0.00124304718
Iter: 960 loss: 0.00123989221
Iter: 961 loss: 0.00124664791
Iter: 962 loss: 0.00123864959
Iter: 963 loss: 0.0012347477
Iter: 964 loss: 0.00125014666
Iter: 965 loss: 0.00123387761
Iter: 966 loss: 0.00123134849
Iter: 967 loss: 0.00122857152
Iter: 968 loss: 0.00122816151
Iter: 969 loss: 0.00122379721
Iter: 970 loss: 0.00123446831
Iter: 971 loss: 0.00122227403
Iter: 972 loss: 0.00121891673
Iter: 973 loss: 0.00121864094
Iter: 974 loss: 0.00121766282
Iter: 975 loss: 0.00121589773
Iter: 976 loss: 0.0012577083
Iter: 977 loss: 0.0012158996
Iter: 978 loss: 0.00121372635
Iter: 979 loss: 0.00121370098
Iter: 980 loss: 0.00121273124
Iter: 981 loss: 0.00121121062
Iter: 982 loss: 0.00121119164
Iter: 983 loss: 0.00120799639
Iter: 984 loss: 0.00121376931
Iter: 985 loss: 0.00120659824
Iter: 986 loss: 0.00120390835
Iter: 987 loss: 0.00121692521
Iter: 988 loss: 0.00120345061
Iter: 989 loss: 0.00120035943
Iter: 990 loss: 0.00119845034
Iter: 991 loss: 0.00119720621
Iter: 992 loss: 0.00119382353
Iter: 993 loss: 0.00119834288
Iter: 994 loss: 0.00119209895
Iter: 995 loss: 0.0011888576
Iter: 996 loss: 0.00118885725
Iter: 997 loss: 0.00118577899
Iter: 998 loss: 0.00118388
Iter: 999 loss: 0.00118263485
Iter: 1000 loss: 0.00117930095
Iter: 1001 loss: 0.00117316097
Iter: 1002 loss: 0.00131258322
Iter: 1003 loss: 0.00117315247
Iter: 1004 loss: 0.00117133185
Iter: 1005 loss: 0.00117080135
Iter: 1006 loss: 0.0011692252
Iter: 1007 loss: 0.00116831774
Iter: 1008 loss: 0.00116763916
Iter: 1009 loss: 0.00116362621
Iter: 1010 loss: 0.00119875907
Iter: 1011 loss: 0.0011633893
Iter: 1012 loss: 0.00115958345
Iter: 1013 loss: 0.00120967824
Iter: 1014 loss: 0.00115957088
Iter: 1015 loss: 0.00115854118
Iter: 1016 loss: 0.00115623022
Iter: 1017 loss: 0.00118790264
Iter: 1018 loss: 0.00115609518
Iter: 1019 loss: 0.00115323719
Iter: 1020 loss: 0.00114976137
Iter: 1021 loss: 0.00114942819
Iter: 1022 loss: 0.00114482862
Iter: 1023 loss: 0.00115690334
Iter: 1024 loss: 0.00114327157
Iter: 1025 loss: 0.00113897515
Iter: 1026 loss: 0.00115660881
Iter: 1027 loss: 0.00113804534
Iter: 1028 loss: 0.00113435346
Iter: 1029 loss: 0.00113426265
Iter: 1030 loss: 0.00113263424
Iter: 1031 loss: 0.00112949393
Iter: 1032 loss: 0.00119279488
Iter: 1033 loss: 0.00112948
Iter: 1034 loss: 0.00112744863
Iter: 1035 loss: 0.00112942967
Iter: 1036 loss: 0.00112628017
Iter: 1037 loss: 0.00112508936
Iter: 1038 loss: 0.00112237025
Iter: 1039 loss: 0.00115717575
Iter: 1040 loss: 0.00112218596
Iter: 1041 loss: 0.0011199431
Iter: 1042 loss: 0.00113783136
Iter: 1043 loss: 0.00111978245
Iter: 1044 loss: 0.00111778174
Iter: 1045 loss: 0.00114884507
Iter: 1046 loss: 0.00111778011
Iter: 1047 loss: 0.0011162376
Iter: 1048 loss: 0.00111616706
Iter: 1049 loss: 0.00111435074
Iter: 1050 loss: 0.00111314608
Iter: 1051 loss: 0.00111246156
Iter: 1052 loss: 0.00111041451
Iter: 1053 loss: 0.00110733847
Iter: 1054 loss: 0.00110727502
Iter: 1055 loss: 0.0011031063
Iter: 1056 loss: 0.00110364798
Iter: 1057 loss: 0.00109994493
Iter: 1058 loss: 0.00109423825
Iter: 1059 loss: 0.00111579115
Iter: 1060 loss: 0.00109284266
Iter: 1061 loss: 0.00108802621
Iter: 1062 loss: 0.00111342804
Iter: 1063 loss: 0.0010872758
Iter: 1064 loss: 0.00108345516
Iter: 1065 loss: 0.00108958175
Iter: 1066 loss: 0.00108168437
Iter: 1067 loss: 0.00108981575
Iter: 1068 loss: 0.00108064828
Iter: 1069 loss: 0.00107961847
Iter: 1070 loss: 0.00107732322
Iter: 1071 loss: 0.00111109845
Iter: 1072 loss: 0.00107721169
Iter: 1073 loss: 0.00107583147
Iter: 1074 loss: 0.00107561355
Iter: 1075 loss: 0.00107465987
Iter: 1076 loss: 0.00107327406
Iter: 1077 loss: 0.00107168267
Iter: 1078 loss: 0.00107148278
Iter: 1079 loss: 0.00106988917
Iter: 1080 loss: 0.00106870627
Iter: 1081 loss: 0.00106817659
Iter: 1082 loss: 0.00106603978
Iter: 1083 loss: 0.00106972456
Iter: 1084 loss: 0.001065091
Iter: 1085 loss: 0.00106288318
Iter: 1086 loss: 0.001080035
Iter: 1087 loss: 0.00106271252
Iter: 1088 loss: 0.00105958653
Iter: 1089 loss: 0.00107659888
Iter: 1090 loss: 0.00105913787
Iter: 1091 loss: 0.00105560408
Iter: 1092 loss: 0.00105867919
Iter: 1093 loss: 0.00105351489
Iter: 1094 loss: 0.0010492024
Iter: 1095 loss: 0.00105122174
Iter: 1096 loss: 0.00104630343
Iter: 1097 loss: 0.0010434041
Iter: 1098 loss: 0.00104996632
Iter: 1099 loss: 0.00104228186
Iter: 1100 loss: 0.00104081258
Iter: 1101 loss: 0.00103818905
Iter: 1102 loss: 0.00110205531
Iter: 1103 loss: 0.00103819091
Iter: 1104 loss: 0.00103816367
Iter: 1105 loss: 0.00103670941
Iter: 1106 loss: 0.0010358505
Iter: 1107 loss: 0.00103750965
Iter: 1108 loss: 0.00103549217
Iter: 1109 loss: 0.00103444955
Iter: 1110 loss: 0.00103344384
Iter: 1111 loss: 0.00103321148
Iter: 1112 loss: 0.00103165244
Iter: 1113 loss: 0.0010340343
Iter: 1114 loss: 0.0010309153
Iter: 1115 loss: 0.00102846371
Iter: 1116 loss: 0.00102710607
Iter: 1117 loss: 0.0010260283
Iter: 1118 loss: 0.00102278264
Iter: 1119 loss: 0.00103107584
Iter: 1120 loss: 0.00102165435
Iter: 1121 loss: 0.00101821229
Iter: 1122 loss: 0.00102972751
Iter: 1123 loss: 0.00101727492
Iter: 1124 loss: 0.00101415417
Iter: 1125 loss: 0.00102022686
Iter: 1126 loss: 0.00101285079
Iter: 1127 loss: 0.00101062225
Iter: 1128 loss: 0.00103977637
Iter: 1129 loss: 0.0010106134
Iter: 1130 loss: 0.00100903516
Iter: 1131 loss: 0.00101589353
Iter: 1132 loss: 0.00100870407
Iter: 1133 loss: 0.00100751198
Iter: 1134 loss: 0.00100514106
Iter: 1135 loss: 0.0010506094
Iter: 1136 loss: 0.00100511219
Iter: 1137 loss: 0.001005125
Iter: 1138 loss: 0.00100370776
Iter: 1139 loss: 0.00100241043
Iter: 1140 loss: 0.00100916019
Iter: 1141 loss: 0.00100220833
Iter: 1142 loss: 0.00100099167
Iter: 1143 loss: 0.00100025651
Iter: 1144 loss: 0.000999747
Iter: 1145 loss: 0.00099815568
Iter: 1146 loss: 0.00100287364
Iter: 1147 loss: 0.000997672323
Iter: 1148 loss: 0.000995723065
Iter: 1149 loss: 0.000993187306
Iter: 1150 loss: 0.000993013848
Iter: 1151 loss: 0.000990725937
Iter: 1152 loss: 0.00101077743
Iter: 1153 loss: 0.000990602188
Iter: 1154 loss: 0.000988447922
Iter: 1155 loss: 0.000988388201
Iter: 1156 loss: 0.000986710074
Iter: 1157 loss: 0.000983363716
Iter: 1158 loss: 0.000978598604
Iter: 1159 loss: 0.00097843539
Iter: 1160 loss: 0.000972794602
Iter: 1161 loss: 0.000993100461
Iter: 1162 loss: 0.000971383823
Iter: 1163 loss: 0.000971112459
Iter: 1164 loss: 0.000969777466
Iter: 1165 loss: 0.000968261797
Iter: 1166 loss: 0.000965967192
Iter: 1167 loss: 0.00096592278
Iter: 1168 loss: 0.000963426661
Iter: 1169 loss: 0.000970937137
Iter: 1170 loss: 0.000962694059
Iter: 1171 loss: 0.000960922218
Iter: 1172 loss: 0.000973298098
Iter: 1173 loss: 0.000960753125
Iter: 1174 loss: 0.000959631696
Iter: 1175 loss: 0.000959707599
Iter: 1176 loss: 0.00095876155
Iter: 1177 loss: 0.000955973752
Iter: 1178 loss: 0.00096982636
Iter: 1179 loss: 0.000955495692
Iter: 1180 loss: 0.00095287594
Iter: 1181 loss: 0.000960024772
Iter: 1182 loss: 0.000952024304
Iter: 1183 loss: 0.000950290356
Iter: 1184 loss: 0.000946197775
Iter: 1185 loss: 0.000993965659
Iter: 1186 loss: 0.000945839158
Iter: 1187 loss: 0.00094448257
Iter: 1188 loss: 0.000943169813
Iter: 1189 loss: 0.000941235165
Iter: 1190 loss: 0.000942194369
Iter: 1191 loss: 0.000939953723
Iter: 1192 loss: 0.000938692247
Iter: 1193 loss: 0.000936945144
Iter: 1194 loss: 0.000936862256
Iter: 1195 loss: 0.000935741584
Iter: 1196 loss: 0.000935682678
Iter: 1197 loss: 0.000934828888
Iter: 1198 loss: 0.000934347569
Iter: 1199 loss: 0.000933603093
Iter: 1200 loss: 0.000933590345
Iter: 1201 loss: 0.000932599069
Iter: 1202 loss: 0.000931804068
Iter: 1203 loss: 0.000931507966
Iter: 1204 loss: 0.000929662259
Iter: 1205 loss: 0.000932180323
Iter: 1206 loss: 0.000928745721
Iter: 1207 loss: 0.000926439883
Iter: 1208 loss: 0.000926433
Iter: 1209 loss: 0.000924382766
Iter: 1210 loss: 0.000946639106
Iter: 1211 loss: 0.000924338412
Iter: 1212 loss: 0.000923238287
Iter: 1213 loss: 0.000923315238
Iter: 1214 loss: 0.000922374602
Iter: 1215 loss: 0.000919860438
Iter: 1216 loss: 0.000923689862
Iter: 1217 loss: 0.00091866788
Iter: 1218 loss: 0.00091595907
Iter: 1219 loss: 0.000915137527
Iter: 1220 loss: 0.000913522439
Iter: 1221 loss: 0.000911751704
Iter: 1222 loss: 0.000936380355
Iter: 1223 loss: 0.000911745534
Iter: 1224 loss: 0.000910613453
Iter: 1225 loss: 0.000910601695
Iter: 1226 loss: 0.000909849419
Iter: 1227 loss: 0.000914398
Iter: 1228 loss: 0.000909759896
Iter: 1229 loss: 0.000909165887
Iter: 1230 loss: 0.000908292
Iter: 1231 loss: 0.000908266637
Iter: 1232 loss: 0.000907190552
Iter: 1233 loss: 0.000908698072
Iter: 1234 loss: 0.000906659407
Iter: 1235 loss: 0.000905407593
Iter: 1236 loss: 0.000903157692
Iter: 1237 loss: 0.00095863227
Iter: 1238 loss: 0.000903155946
Iter: 1239 loss: 0.000900374725
Iter: 1240 loss: 0.000903995067
Iter: 1241 loss: 0.000898943399
Iter: 1242 loss: 0.000897443737
Iter: 1243 loss: 0.000896934187
Iter: 1244 loss: 0.000894908851
Iter: 1245 loss: 0.000891503762
Iter: 1246 loss: 0.000891496078
Iter: 1247 loss: 0.000889154675
Iter: 1248 loss: 0.000892308424
Iter: 1249 loss: 0.000888002105
Iter: 1250 loss: 0.00088315492
Iter: 1251 loss: 0.000882390304
Iter: 1252 loss: 0.000879023806
Iter: 1253 loss: 0.000874781923
Iter: 1254 loss: 0.000930565468
Iter: 1255 loss: 0.000874761143
Iter: 1256 loss: 0.00087534741
Iter: 1257 loss: 0.000873845769
Iter: 1258 loss: 0.000873183482
Iter: 1259 loss: 0.000872724166
Iter: 1260 loss: 0.000872494187
Iter: 1261 loss: 0.000870911521
Iter: 1262 loss: 0.000872209668
Iter: 1263 loss: 0.000869958138
Iter: 1264 loss: 0.000868656905
Iter: 1265 loss: 0.000872479461
Iter: 1266 loss: 0.000868266157
Iter: 1267 loss: 0.000867155264
Iter: 1268 loss: 0.000864916772
Iter: 1269 loss: 0.000908145099
Iter: 1270 loss: 0.00086488761
Iter: 1271 loss: 0.000862783752
Iter: 1272 loss: 0.000868622272
Iter: 1273 loss: 0.000862106
Iter: 1274 loss: 0.000860697881
Iter: 1275 loss: 0.000860462897
Iter: 1276 loss: 0.00085950183
Iter: 1277 loss: 0.000857433479
Iter: 1278 loss: 0.000886479393
Iter: 1279 loss: 0.000857428764
Iter: 1280 loss: 0.000856397441
Iter: 1281 loss: 0.000853866397
Iter: 1282 loss: 0.000879000523
Iter: 1283 loss: 0.000853553531
Iter: 1284 loss: 0.000849565433
Iter: 1285 loss: 0.000866633083
Iter: 1286 loss: 0.000848747906
Iter: 1287 loss: 0.000845954521
Iter: 1288 loss: 0.000852274476
Iter: 1289 loss: 0.000844918308
Iter: 1290 loss: 0.000843062706
Iter: 1291 loss: 0.000869684096
Iter: 1292 loss: 0.000843052054
Iter: 1293 loss: 0.000841775
Iter: 1294 loss: 0.000852736528
Iter: 1295 loss: 0.000841711415
Iter: 1296 loss: 0.000840631896
Iter: 1297 loss: 0.000841248431
Iter: 1298 loss: 0.000839924323
Iter: 1299 loss: 0.000838306849
Iter: 1300 loss: 0.000840115128
Iter: 1301 loss: 0.000837439322
Iter: 1302 loss: 0.000836462073
Iter: 1303 loss: 0.000834150705
Iter: 1304 loss: 0.000861315173
Iter: 1305 loss: 0.000833940809
Iter: 1306 loss: 0.000831654528
Iter: 1307 loss: 0.000840661058
Iter: 1308 loss: 0.000831131707
Iter: 1309 loss: 0.00082889694
Iter: 1310 loss: 0.000833072758
Iter: 1311 loss: 0.00082793372
Iter: 1312 loss: 0.00082583155
Iter: 1313 loss: 0.000856299885
Iter: 1314 loss: 0.000825835101
Iter: 1315 loss: 0.000824071
Iter: 1316 loss: 0.000825254247
Iter: 1317 loss: 0.00082296133
Iter: 1318 loss: 0.000821326
Iter: 1319 loss: 0.000823168
Iter: 1320 loss: 0.000820445071
Iter: 1321 loss: 0.000818550121
Iter: 1322 loss: 0.000825972878
Iter: 1323 loss: 0.000818105065
Iter: 1324 loss: 0.000816551852
Iter: 1325 loss: 0.000821239082
Iter: 1326 loss: 0.000816076761
Iter: 1327 loss: 0.000816208078
Iter: 1328 loss: 0.000815141539
Iter: 1329 loss: 0.00081470341
Iter: 1330 loss: 0.000813996943
Iter: 1331 loss: 0.00081399
Iter: 1332 loss: 0.000812985585
Iter: 1333 loss: 0.000816215063
Iter: 1334 loss: 0.000812703453
Iter: 1335 loss: 0.000811812468
Iter: 1336 loss: 0.000809365243
Iter: 1337 loss: 0.000824337068
Iter: 1338 loss: 0.000808710465
Iter: 1339 loss: 0.000805361196
Iter: 1340 loss: 0.000815828447
Iter: 1341 loss: 0.000804390875
Iter: 1342 loss: 0.000801271177
Iter: 1343 loss: 0.000808454701
Iter: 1344 loss: 0.000800089736
Iter: 1345 loss: 0.000798263354
Iter: 1346 loss: 0.000821906957
Iter: 1347 loss: 0.000798254274
Iter: 1348 loss: 0.000796772889
Iter: 1349 loss: 0.0007982073
Iter: 1350 loss: 0.000795927364
Iter: 1351 loss: 0.000793857849
Iter: 1352 loss: 0.000795122469
Iter: 1353 loss: 0.000792521867
Iter: 1354 loss: 0.000789719168
Iter: 1355 loss: 0.000801828
Iter: 1356 loss: 0.000789134705
Iter: 1357 loss: 0.000787213
Iter: 1358 loss: 0.000787101628
Iter: 1359 loss: 0.000785645214
Iter: 1360 loss: 0.000784823031
Iter: 1361 loss: 0.000784686
Iter: 1362 loss: 0.000783970463
Iter: 1363 loss: 0.000786432414
Iter: 1364 loss: 0.000783784199
Iter: 1365 loss: 0.000783296535
Iter: 1366 loss: 0.000783108582
Iter: 1367 loss: 0.000782845193
Iter: 1368 loss: 0.000782223651
Iter: 1369 loss: 0.000780562754
Iter: 1370 loss: 0.000792223378
Iter: 1371 loss: 0.00078018842
Iter: 1372 loss: 0.000778614776
Iter: 1373 loss: 0.000778354355
Iter: 1374 loss: 0.00077727309
Iter: 1375 loss: 0.000775054
Iter: 1376 loss: 0.000798639
Iter: 1377 loss: 0.000775002758
Iter: 1378 loss: 0.000773344538
Iter: 1379 loss: 0.000778465881
Iter: 1380 loss: 0.000772852916
Iter: 1381 loss: 0.000770496437
Iter: 1382 loss: 0.000784956268
Iter: 1383 loss: 0.000770214479
Iter: 1384 loss: 0.00076911191
Iter: 1385 loss: 0.000771238
Iter: 1386 loss: 0.000768644852
Iter: 1387 loss: 0.000767788268
Iter: 1388 loss: 0.000766480749
Iter: 1389 loss: 0.000766457233
Iter: 1390 loss: 0.000765219331
Iter: 1391 loss: 0.000784329721
Iter: 1392 loss: 0.00076521904
Iter: 1393 loss: 0.000764303
Iter: 1394 loss: 0.000764048193
Iter: 1395 loss: 0.000763490039
Iter: 1396 loss: 0.000763248303
Iter: 1397 loss: 0.000762600917
Iter: 1398 loss: 0.00076209195
Iter: 1399 loss: 0.000761110452
Iter: 1400 loss: 0.000781175564
Iter: 1401 loss: 0.000761104864
Iter: 1402 loss: 0.000759286922
Iter: 1403 loss: 0.000760588679
Iter: 1404 loss: 0.000758157
Iter: 1405 loss: 0.000756648835
Iter: 1406 loss: 0.000758117763
Iter: 1407 loss: 0.000755795627
Iter: 1408 loss: 0.000754483
Iter: 1409 loss: 0.00075561885
Iter: 1410 loss: 0.000753700268
Iter: 1411 loss: 0.000752590888
Iter: 1412 loss: 0.000750564
Iter: 1413 loss: 0.00079819886
Iter: 1414 loss: 0.000750561594
Iter: 1415 loss: 0.000749310479
Iter: 1416 loss: 0.000749307685
Iter: 1417 loss: 0.000748719031
Iter: 1418 loss: 0.000747433107
Iter: 1419 loss: 0.000766591169
Iter: 1420 loss: 0.000747378799
Iter: 1421 loss: 0.000746124191
Iter: 1422 loss: 0.000758270617
Iter: 1423 loss: 0.000746076112
Iter: 1424 loss: 0.000745283091
Iter: 1425 loss: 0.000746097416
Iter: 1426 loss: 0.000744843623
Iter: 1427 loss: 0.00074419193
Iter: 1428 loss: 0.000743669108
Iter: 1429 loss: 0.000743472
Iter: 1430 loss: 0.000742520089
Iter: 1431 loss: 0.000743846875
Iter: 1432 loss: 0.0007420521
Iter: 1433 loss: 0.000741336087
Iter: 1434 loss: 0.000743982615
Iter: 1435 loss: 0.000741158612
Iter: 1436 loss: 0.000740557443
Iter: 1437 loss: 0.000739710871
Iter: 1438 loss: 0.000739679439
Iter: 1439 loss: 0.000738149043
Iter: 1440 loss: 0.000740328571
Iter: 1441 loss: 0.000737398863
Iter: 1442 loss: 0.000735391281
Iter: 1443 loss: 0.000731952139
Iter: 1444 loss: 0.000731947948
Iter: 1445 loss: 0.000729208463
Iter: 1446 loss: 0.000742753036
Iter: 1447 loss: 0.000728727668
Iter: 1448 loss: 0.000727078412
Iter: 1449 loss: 0.000727076316
Iter: 1450 loss: 0.00072538422
Iter: 1451 loss: 0.00072326127
Iter: 1452 loss: 0.000723089208
Iter: 1453 loss: 0.000720323529
Iter: 1454 loss: 0.000729675055
Iter: 1455 loss: 0.000719567528
Iter: 1456 loss: 0.000718347612
Iter: 1457 loss: 0.000734624569
Iter: 1458 loss: 0.000718341209
Iter: 1459 loss: 0.000717320538
Iter: 1460 loss: 0.000716815703
Iter: 1461 loss: 0.000716334
Iter: 1462 loss: 0.000718498428
Iter: 1463 loss: 0.000715958537
Iter: 1464 loss: 0.000715712958
Iter: 1465 loss: 0.000714915
Iter: 1466 loss: 0.000715262722
Iter: 1467 loss: 0.000714178139
Iter: 1468 loss: 0.00071467692
Iter: 1469 loss: 0.000713066082
Iter: 1470 loss: 0.000712086912
Iter: 1471 loss: 0.000712602283
Iter: 1472 loss: 0.000711447443
Iter: 1473 loss: 0.000710731489
Iter: 1474 loss: 0.000710573862
Iter: 1475 loss: 0.000710110529
Iter: 1476 loss: 0.000709287531
Iter: 1477 loss: 0.0007076927
Iter: 1478 loss: 0.000740642601
Iter: 1479 loss: 0.000707685947
Iter: 1480 loss: 0.000706443505
Iter: 1481 loss: 0.000707272382
Iter: 1482 loss: 0.000705657527
Iter: 1483 loss: 0.000703832193
Iter: 1484 loss: 0.000716570299
Iter: 1485 loss: 0.000703670783
Iter: 1486 loss: 0.000701884273
Iter: 1487 loss: 0.000719497912
Iter: 1488 loss: 0.000701823446
Iter: 1489 loss: 0.000701024197
Iter: 1490 loss: 0.000698992342
Iter: 1491 loss: 0.000716947834
Iter: 1492 loss: 0.000698668242
Iter: 1493 loss: 0.000697142503
Iter: 1494 loss: 0.000696916
Iter: 1495 loss: 0.000695843948
Iter: 1496 loss: 0.000695014838
Iter: 1497 loss: 0.000694675837
Iter: 1498 loss: 0.000694815884
Iter: 1499 loss: 0.000693933223
Iter: 1500 loss: 0.00069337216
Iter: 1501 loss: 0.000693367
Iter: 1502 loss: 0.000692924717
Iter: 1503 loss: 0.000692241767
Iter: 1504 loss: 0.000693341368
Iter: 1505 loss: 0.000691924943
Iter: 1506 loss: 0.000691340771
Iter: 1507 loss: 0.000689735054
Iter: 1508 loss: 0.000699349272
Iter: 1509 loss: 0.000689295237
Iter: 1510 loss: 0.000687415362
Iter: 1511 loss: 0.000688960659
Iter: 1512 loss: 0.000686289161
Iter: 1513 loss: 0.0006845725
Iter: 1514 loss: 0.00068452768
Iter: 1515 loss: 0.00068318611
Iter: 1516 loss: 0.000681552803
Iter: 1517 loss: 0.000697931566
Iter: 1518 loss: 0.00068150775
Iter: 1519 loss: 0.000679984514
Iter: 1520 loss: 0.000682048267
Iter: 1521 loss: 0.000679218094
Iter: 1522 loss: 0.000678263314
Iter: 1523 loss: 0.000677855336
Iter: 1524 loss: 0.000677361037
Iter: 1525 loss: 0.000676054507
Iter: 1526 loss: 0.000675133313
Iter: 1527 loss: 0.000674670679
Iter: 1528 loss: 0.000672911061
Iter: 1529 loss: 0.000676018768
Iter: 1530 loss: 0.000672139577
Iter: 1531 loss: 0.000671520887
Iter: 1532 loss: 0.000671058195
Iter: 1533 loss: 0.000670609821
Iter: 1534 loss: 0.000676170632
Iter: 1535 loss: 0.000670608133
Iter: 1536 loss: 0.000670271285
Iter: 1537 loss: 0.000669769477
Iter: 1538 loss: 0.000669758592
Iter: 1539 loss: 0.000669154455
Iter: 1540 loss: 0.000669151428
Iter: 1541 loss: 0.000668672379
Iter: 1542 loss: 0.000667884771
Iter: 1543 loss: 0.000666835636
Iter: 1544 loss: 0.000666774693
Iter: 1545 loss: 0.000665809
Iter: 1546 loss: 0.000669036817
Iter: 1547 loss: 0.000665546046
Iter: 1548 loss: 0.000664172287
Iter: 1549 loss: 0.000662929728
Iter: 1550 loss: 0.000662586
Iter: 1551 loss: 0.000662604114
Iter: 1552 loss: 0.000661933853
Iter: 1553 loss: 0.000661274
Iter: 1554 loss: 0.000660993392
Iter: 1555 loss: 0.000660648919
Iter: 1556 loss: 0.000659859856
Iter: 1557 loss: 0.000659377198
Iter: 1558 loss: 0.000659054669
Iter: 1559 loss: 0.000657786
Iter: 1560 loss: 0.000661031052
Iter: 1561 loss: 0.000657343713
Iter: 1562 loss: 0.000657053839
Iter: 1563 loss: 0.000656776247
Iter: 1564 loss: 0.000656315126
Iter: 1565 loss: 0.000660710153
Iter: 1566 loss: 0.000656298827
Iter: 1567 loss: 0.000655863376
Iter: 1568 loss: 0.000655987649
Iter: 1569 loss: 0.000655551848
Iter: 1570 loss: 0.000655149284
Iter: 1571 loss: 0.000654971926
Iter: 1572 loss: 0.000654772739
Iter: 1573 loss: 0.000653968949
Iter: 1574 loss: 0.000652575574
Iter: 1575 loss: 0.000652573886
Iter: 1576 loss: 0.000651275157
Iter: 1577 loss: 0.000653739669
Iter: 1578 loss: 0.00065072556
Iter: 1579 loss: 0.000648712739
Iter: 1580 loss: 0.000654822
Iter: 1581 loss: 0.000648112968
Iter: 1582 loss: 0.000647157605
Iter: 1583 loss: 0.000658845529
Iter: 1584 loss: 0.000647145731
Iter: 1585 loss: 0.000646194385
Iter: 1586 loss: 0.000652966555
Iter: 1587 loss: 0.000646112254
Iter: 1588 loss: 0.000645539
Iter: 1589 loss: 0.000644191401
Iter: 1590 loss: 0.000659804209
Iter: 1591 loss: 0.000644070446
Iter: 1592 loss: 0.000643267238
Iter: 1593 loss: 0.000642799714
Iter: 1594 loss: 0.000642465428
Iter: 1595 loss: 0.000641879276
Iter: 1596 loss: 0.000641559833
Iter: 1597 loss: 0.000641298131
Iter: 1598 loss: 0.000640837825
Iter: 1599 loss: 0.000639702659
Iter: 1600 loss: 0.000651013397
Iter: 1601 loss: 0.000639563776
Iter: 1602 loss: 0.000638820173
Iter: 1603 loss: 0.000639030535
Iter: 1604 loss: 0.000638284138
Iter: 1605 loss: 0.000637722085
Iter: 1606 loss: 0.000637695659
Iter: 1607 loss: 0.000637020683
Iter: 1608 loss: 0.000636274111
Iter: 1609 loss: 0.000636169454
Iter: 1610 loss: 0.000635198434
Iter: 1611 loss: 0.000639526115
Iter: 1612 loss: 0.000635004253
Iter: 1613 loss: 0.000633798831
Iter: 1614 loss: 0.000634934055
Iter: 1615 loss: 0.000633107033
Iter: 1616 loss: 0.000632177223
Iter: 1617 loss: 0.000636255252
Iter: 1618 loss: 0.000631995383
Iter: 1619 loss: 0.000631244795
Iter: 1620 loss: 0.00063853903
Iter: 1621 loss: 0.000631220115
Iter: 1622 loss: 0.0006308
Iter: 1623 loss: 0.000636676734
Iter: 1624 loss: 0.000630797294
Iter: 1625 loss: 0.000630619354
Iter: 1626 loss: 0.000632199575
Iter: 1627 loss: 0.000630611787
Iter: 1628 loss: 0.000630473136
Iter: 1629 loss: 0.000631739851
Iter: 1630 loss: 0.000630465453
Iter: 1631 loss: 0.000630326336
Iter: 1632 loss: 0.000629981048
Iter: 1633 loss: 0.000633385265
Iter: 1634 loss: 0.000629936112
Iter: 1635 loss: 0.000629563292
Iter: 1636 loss: 0.000629002694
Iter: 1637 loss: 0.000628990412
Iter: 1638 loss: 0.00062799122
Iter: 1639 loss: 0.000632144336
Iter: 1640 loss: 0.000627772301
Iter: 1641 loss: 0.000626440393
Iter: 1642 loss: 0.000627847388
Iter: 1643 loss: 0.000625707791
Iter: 1644 loss: 0.000624702254
Iter: 1645 loss: 0.000626371067
Iter: 1646 loss: 0.00062424707
Iter: 1647 loss: 0.000623146887
Iter: 1648 loss: 0.000627893955
Iter: 1649 loss: 0.000622919295
Iter: 1650 loss: 0.000622087391
Iter: 1651 loss: 0.00062135217
Iter: 1652 loss: 0.000621137093
Iter: 1653 loss: 0.000620094885
Iter: 1654 loss: 0.000628459326
Iter: 1655 loss: 0.000620026723
Iter: 1656 loss: 0.000619427825
Iter: 1657 loss: 0.000619360828
Iter: 1658 loss: 0.000619121827
Iter: 1659 loss: 0.000619169208
Iter: 1660 loss: 0.000618941907
Iter: 1661 loss: 0.000618669554
Iter: 1662 loss: 0.000621895248
Iter: 1663 loss: 0.000618664431
Iter: 1664 loss: 0.000618417689
Iter: 1665 loss: 0.00061790843
Iter: 1666 loss: 0.000626614
Iter: 1667 loss: 0.000617897254
Iter: 1668 loss: 0.00061739923
Iter: 1669 loss: 0.000617705635
Iter: 1670 loss: 0.000617083686
Iter: 1671 loss: 0.000616334146
Iter: 1672 loss: 0.000620471
Iter: 1673 loss: 0.000616226404
Iter: 1674 loss: 0.000615606259
Iter: 1675 loss: 0.000622686464
Iter: 1676 loss: 0.000615596655
Iter: 1677 loss: 0.00061529997
Iter: 1678 loss: 0.000614616205
Iter: 1679 loss: 0.000623204396
Iter: 1680 loss: 0.000614565157
Iter: 1681 loss: 0.000613668235
Iter: 1682 loss: 0.000620503211
Iter: 1683 loss: 0.000613598619
Iter: 1684 loss: 0.000612692034
Iter: 1685 loss: 0.000611854717
Iter: 1686 loss: 0.000611636
Iter: 1687 loss: 0.000610424671
Iter: 1688 loss: 0.000608541653
Iter: 1689 loss: 0.000608517556
Iter: 1690 loss: 0.000608214177
Iter: 1691 loss: 0.000607937225
Iter: 1692 loss: 0.000607568421
Iter: 1693 loss: 0.000607410911
Iter: 1694 loss: 0.000607221853
Iter: 1695 loss: 0.000605980807
Iter: 1696 loss: 0.000612696516
Iter: 1697 loss: 0.000605791109
Iter: 1698 loss: 0.000604167231
Iter: 1699 loss: 0.000614408753
Iter: 1700 loss: 0.000603988417
Iter: 1701 loss: 0.000603670429
Iter: 1702 loss: 0.000602882123
Iter: 1703 loss: 0.000610580493
Iter: 1704 loss: 0.000602778164
Iter: 1705 loss: 0.000601905049
Iter: 1706 loss: 0.000602502143
Iter: 1707 loss: 0.000601360225
Iter: 1708 loss: 0.000600449683
Iter: 1709 loss: 0.00060466514
Iter: 1710 loss: 0.000600280124
Iter: 1711 loss: 0.000599922438
Iter: 1712 loss: 0.000599830877
Iter: 1713 loss: 0.000599383
Iter: 1714 loss: 0.000598367769
Iter: 1715 loss: 0.000611996627
Iter: 1716 loss: 0.000598306942
Iter: 1717 loss: 0.000597507867
Iter: 1718 loss: 0.000609191484
Iter: 1719 loss: 0.000597507926
Iter: 1720 loss: 0.000596837199
Iter: 1721 loss: 0.000597025268
Iter: 1722 loss: 0.000596350641
Iter: 1723 loss: 0.000595539284
Iter: 1724 loss: 0.000595541846
Iter: 1725 loss: 0.000594889862
Iter: 1726 loss: 0.000595318503
Iter: 1727 loss: 0.000594613783
Iter: 1728 loss: 0.000594336714
Iter: 1729 loss: 0.000594962446
Iter: 1730 loss: 0.000594233454
Iter: 1731 loss: 0.000593954115
Iter: 1732 loss: 0.000593105215
Iter: 1733 loss: 0.000595454243
Iter: 1734 loss: 0.000592653174
Iter: 1735 loss: 0.00059165206
Iter: 1736 loss: 0.000594780548
Iter: 1737 loss: 0.000591361662
Iter: 1738 loss: 0.000590468699
Iter: 1739 loss: 0.000588916708
Iter: 1740 loss: 0.000588915718
Iter: 1741 loss: 0.000587486953
Iter: 1742 loss: 0.000590859097
Iter: 1743 loss: 0.000586960639
Iter: 1744 loss: 0.000585475296
Iter: 1745 loss: 0.000592505792
Iter: 1746 loss: 0.000585206959
Iter: 1747 loss: 0.000584703404
Iter: 1748 loss: 0.000584687456
Iter: 1749 loss: 0.000583954039
Iter: 1750 loss: 0.000584832509
Iter: 1751 loss: 0.000583566958
Iter: 1752 loss: 0.00058325089
Iter: 1753 loss: 0.00058310735
Iter: 1754 loss: 0.000582951
Iter: 1755 loss: 0.000582735636
Iter: 1756 loss: 0.000582911307
Iter: 1757 loss: 0.000582607463
Iter: 1758 loss: 0.000582468056
Iter: 1759 loss: 0.000582004082
Iter: 1760 loss: 0.000581768923
Iter: 1761 loss: 0.000581441389
Iter: 1762 loss: 0.000580722466
Iter: 1763 loss: 0.000590402866
Iter: 1764 loss: 0.000580718042
Iter: 1765 loss: 0.000580384
Iter: 1766 loss: 0.000579761865
Iter: 1767 loss: 0.00059396727
Iter: 1768 loss: 0.000579760468
Iter: 1769 loss: 0.000579135783
Iter: 1770 loss: 0.000580247608
Iter: 1771 loss: 0.000578862499
Iter: 1772 loss: 0.000577982049
Iter: 1773 loss: 0.000581507804
Iter: 1774 loss: 0.000577784725
Iter: 1775 loss: 0.000577282044
Iter: 1776 loss: 0.000578421343
Iter: 1777 loss: 0.00057709578
Iter: 1778 loss: 0.000576887629
Iter: 1779 loss: 0.000576319289
Iter: 1780 loss: 0.000579808548
Iter: 1781 loss: 0.000576164806
Iter: 1782 loss: 0.000575727434
Iter: 1783 loss: 0.000575018057
Iter: 1784 loss: 0.000575012935
Iter: 1785 loss: 0.000574438716
Iter: 1786 loss: 0.000575244485
Iter: 1787 loss: 0.000574158563
Iter: 1788 loss: 0.000575308106
Iter: 1789 loss: 0.000573853904
Iter: 1790 loss: 0.000573613681
Iter: 1791 loss: 0.000572799181
Iter: 1792 loss: 0.000572201097
Iter: 1793 loss: 0.000571743818
Iter: 1794 loss: 0.000569934375
Iter: 1795 loss: 0.000579350395
Iter: 1796 loss: 0.000569644268
Iter: 1797 loss: 0.000569572265
Iter: 1798 loss: 0.00056901481
Iter: 1799 loss: 0.000568608404
Iter: 1800 loss: 0.000568149437
Iter: 1801 loss: 0.000568087911
Iter: 1802 loss: 0.000567493844
Iter: 1803 loss: 0.00056918012
Iter: 1804 loss: 0.000567306648
Iter: 1805 loss: 0.000566626491
Iter: 1806 loss: 0.000571915414
Iter: 1807 loss: 0.000566576375
Iter: 1808 loss: 0.00056634174
Iter: 1809 loss: 0.000566338422
Iter: 1810 loss: 0.000566189527
Iter: 1811 loss: 0.000565901
Iter: 1812 loss: 0.000571697892
Iter: 1813 loss: 0.0005659
Iter: 1814 loss: 0.000565422524
Iter: 1815 loss: 0.000565423514
Iter: 1816 loss: 0.000564912218
Iter: 1817 loss: 0.000565971714
Iter: 1818 loss: 0.000564706395
Iter: 1819 loss: 0.000564481888
Iter: 1820 loss: 0.000563999405
Iter: 1821 loss: 0.000571429089
Iter: 1822 loss: 0.0005639827
Iter: 1823 loss: 0.000563121401
Iter: 1824 loss: 0.000564595102
Iter: 1825 loss: 0.000562731875
Iter: 1826 loss: 0.000562254689
Iter: 1827 loss: 0.000561851601
Iter: 1828 loss: 0.000561717607
Iter: 1829 loss: 0.000560732209
Iter: 1830 loss: 0.000560567889
Iter: 1831 loss: 0.000559888314
Iter: 1832 loss: 0.000559571316
Iter: 1833 loss: 0.000559224805
Iter: 1834 loss: 0.000558706117
Iter: 1835 loss: 0.000557664433
Iter: 1836 loss: 0.000577112194
Iter: 1837 loss: 0.000557650928
Iter: 1838 loss: 0.000556731364
Iter: 1839 loss: 0.00055994757
Iter: 1840 loss: 0.000556494691
Iter: 1841 loss: 0.000555634382
Iter: 1842 loss: 0.000557347084
Iter: 1843 loss: 0.000555285602
Iter: 1844 loss: 0.000554146536
Iter: 1845 loss: 0.000555981125
Iter: 1846 loss: 0.000553621212
Iter: 1847 loss: 0.00055608619
Iter: 1848 loss: 0.000553326041
Iter: 1849 loss: 0.000553188962
Iter: 1850 loss: 0.000552881742
Iter: 1851 loss: 0.000557067
Iter: 1852 loss: 0.000552864105
Iter: 1853 loss: 0.000552388723
Iter: 1854 loss: 0.000552267767
Iter: 1855 loss: 0.000551970094
Iter: 1856 loss: 0.000551348552
Iter: 1857 loss: 0.000552675
Iter: 1858 loss: 0.000551101693
Iter: 1859 loss: 0.000550566707
Iter: 1860 loss: 0.000549881137
Iter: 1861 loss: 0.000549832068
Iter: 1862 loss: 0.000548745738
Iter: 1863 loss: 0.000554586295
Iter: 1864 loss: 0.000548582058
Iter: 1865 loss: 0.000548095442
Iter: 1866 loss: 0.000548076234
Iter: 1867 loss: 0.000547567033
Iter: 1868 loss: 0.000548749696
Iter: 1869 loss: 0.000547380536
Iter: 1870 loss: 0.000546883093
Iter: 1871 loss: 0.000546983094
Iter: 1872 loss: 0.000546510913
Iter: 1873 loss: 0.000546109222
Iter: 1874 loss: 0.000545032497
Iter: 1875 loss: 0.000552333076
Iter: 1876 loss: 0.000544781622
Iter: 1877 loss: 0.000543859205
Iter: 1878 loss: 0.000545277493
Iter: 1879 loss: 0.000543420785
Iter: 1880 loss: 0.000543039059
Iter: 1881 loss: 0.000543004135
Iter: 1882 loss: 0.00054269121
Iter: 1883 loss: 0.0005432326
Iter: 1884 loss: 0.000542551221
Iter: 1885 loss: 0.000542201218
Iter: 1886 loss: 0.000542455586
Iter: 1887 loss: 0.00054198713
Iter: 1888 loss: 0.000541498302
Iter: 1889 loss: 0.000541967922
Iter: 1890 loss: 0.000541221
Iter: 1891 loss: 0.000540583045
Iter: 1892 loss: 0.000539614237
Iter: 1893 loss: 0.000539598404
Iter: 1894 loss: 0.000538355962
Iter: 1895 loss: 0.000538659515
Iter: 1896 loss: 0.000537449319
Iter: 1897 loss: 0.000536094
Iter: 1898 loss: 0.00054100604
Iter: 1899 loss: 0.000535756291
Iter: 1900 loss: 0.000534555409
Iter: 1901 loss: 0.000543352508
Iter: 1902 loss: 0.00053445634
Iter: 1903 loss: 0.000534429622
Iter: 1904 loss: 0.000534188934
Iter: 1905 loss: 0.000533932936
Iter: 1906 loss: 0.000533314189
Iter: 1907 loss: 0.00053979631
Iter: 1908 loss: 0.000533244282
Iter: 1909 loss: 0.000532539678
Iter: 1910 loss: 0.000541922287
Iter: 1911 loss: 0.000532537349
Iter: 1912 loss: 0.000532432692
Iter: 1913 loss: 0.000532296486
Iter: 1914 loss: 0.000532096892
Iter: 1915 loss: 0.000531987287
Iter: 1916 loss: 0.000531900383
Iter: 1917 loss: 0.000531598227
Iter: 1918 loss: 0.000531803
Iter: 1919 loss: 0.000531409401
Iter: 1920 loss: 0.000530938851
Iter: 1921 loss: 0.00053067517
Iter: 1922 loss: 0.000530465215
Iter: 1923 loss: 0.00052960997
Iter: 1924 loss: 0.000529913814
Iter: 1925 loss: 0.000529007521
Iter: 1926 loss: 0.000528193195
Iter: 1927 loss: 0.000528569508
Iter: 1928 loss: 0.000527638244
Iter: 1929 loss: 0.000526865071
Iter: 1930 loss: 0.000534824969
Iter: 1931 loss: 0.000526841264
Iter: 1932 loss: 0.000526175951
Iter: 1933 loss: 0.00052612432
Iter: 1934 loss: 0.000525627518
Iter: 1935 loss: 0.0005250221
Iter: 1936 loss: 0.000530215097
Iter: 1937 loss: 0.000524989213
Iter: 1938 loss: 0.000524155679
Iter: 1939 loss: 0.000524280476
Iter: 1940 loss: 0.000523527153
Iter: 1941 loss: 0.00052289071
Iter: 1942 loss: 0.000523710798
Iter: 1943 loss: 0.000522568705
Iter: 1944 loss: 0.000522288494
Iter: 1945 loss: 0.000522180111
Iter: 1946 loss: 0.000521756941
Iter: 1947 loss: 0.000523154391
Iter: 1948 loss: 0.000521638
Iter: 1949 loss: 0.000521399779
Iter: 1950 loss: 0.000521313923
Iter: 1951 loss: 0.000521181326
Iter: 1952 loss: 0.000520771602
Iter: 1953 loss: 0.000522221904
Iter: 1954 loss: 0.00052066613
Iter: 1955 loss: 0.000520338188
Iter: 1956 loss: 0.00052016374
Iter: 1957 loss: 0.000520015834
Iter: 1958 loss: 0.000519451685
Iter: 1959 loss: 0.000518730958
Iter: 1960 loss: 0.000518679852
Iter: 1961 loss: 0.0005179164
Iter: 1962 loss: 0.00052579114
Iter: 1963 loss: 0.000517895329
Iter: 1964 loss: 0.000517217442
Iter: 1965 loss: 0.000518474786
Iter: 1966 loss: 0.000516926695
Iter: 1967 loss: 0.000516398111
Iter: 1968 loss: 0.000520698
Iter: 1969 loss: 0.000516363245
Iter: 1970 loss: 0.000515712542
Iter: 1971 loss: 0.000516332511
Iter: 1972 loss: 0.000515343272
Iter: 1973 loss: 0.000514835294
Iter: 1974 loss: 0.00051426969
Iter: 1975 loss: 0.000514188665
Iter: 1976 loss: 0.000513149193
Iter: 1977 loss: 0.000516874308
Iter: 1978 loss: 0.000512885395
Iter: 1979 loss: 0.000512207393
Iter: 1980 loss: 0.000512075378
Iter: 1981 loss: 0.000511840102
Iter: 1982 loss: 0.000511231134
Iter: 1983 loss: 0.000515896245
Iter: 1984 loss: 0.000511110178
Iter: 1985 loss: 0.000510164653
Iter: 1986 loss: 0.000516189029
Iter: 1987 loss: 0.000510055746
Iter: 1988 loss: 0.000509363075
Iter: 1989 loss: 0.000509353704
Iter: 1990 loss: 0.000508809346
Iter: 1991 loss: 0.000508043799
Iter: 1992 loss: 0.000509139267
Iter: 1993 loss: 0.000507667544
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3
+ date
Tue Oct 27 20:16:09 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi -1 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40652401e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40652ccc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40652cc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40652cc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040253b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040253ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040236f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40401d86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40401fc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40401b1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f404016b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040172e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040108488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040108b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40400e6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40400e6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f404009f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f404009fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40400b3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f404001cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4040042730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40207436a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40206fb048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40206fb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4020709488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40206ab840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f402068cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4020635840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4020635488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40205e5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4020618840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40205c0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40205c0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4020560c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40205c06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f40205548c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0373316258
Iter: 2 loss: 2.45799875
Iter: 3 loss: 2.44941092
Iter: 4 loss: 1.74728751
Iter: 5 loss: 1.74003279
Iter: 6 loss: 1.2653898
Iter: 7 loss: 1.2581954
Iter: 8 loss: 0.917561173
Iter: 9 loss: 0.909676969
Iter: 10 loss: 0.652912438
Iter: 11 loss: 0.643448949
Iter: 12 loss: 0.445166558
Iter: 13 loss: 0.433647752
Iter: 14 loss: 0.281545937
Iter: 15 loss: 0.267776638
Iter: 16 loss: 0.156427547
Iter: 17 loss: 0.142530859
Iter: 18 loss: 0.0731055
Iter: 19 loss: 0.0635607317
Iter: 20 loss: 0.0300108269
Iter: 21 loss: 0.0264286269
Iter: 22 loss: 0.0233699083
Iter: 23 loss: 0.0152071565
Iter: 24 loss: 6976.12842
Iter: 25 loss: 1354.86768
Iter: 26 loss: 0.0264280513
Iter: 27 loss: 0.0155908866
Iter: 28 loss: 0.0157957934
Iter: 29 loss: 0.0191595759
Iter: 30 loss: 0.0146654295
Iter: 31 loss: 0.0126790721
Iter: 32 loss: 0.0125620812
Iter: 33 loss: 0.0106630968
Iter: 34 loss: 0.527569771
Iter: 35 loss: 0.0106595373
Iter: 36 loss: 0.00796630047
Iter: 37 loss: 0.0175607894
Iter: 38 loss: 0.00788435899
Iter: 39 loss: 0.00744002638
Iter: 40 loss: 0.00902763
Iter: 41 loss: 0.00727843028
Iter: 42 loss: 0.0069902488
Iter: 43 loss: 0.0088895
Iter: 44 loss: 0.00695092231
Iter: 45 loss: 0.00638479833
Iter: 46 loss: 0.00606178399
Iter: 47 loss: 0.00585492328
Iter: 48 loss: 0.00541529432
Iter: 49 loss: 0.00531553058
Iter: 50 loss: 0.00498039741
Iter: 51 loss: 0.00459176349
Iter: 52 loss: 0.0045446055
Iter: 53 loss: 0.00411137706
Iter: 54 loss: 0.00484652678
Iter: 55 loss: 0.00390877947
Iter: 56 loss: 0.00360950828
Iter: 57 loss: 0.00435472839
Iter: 58 loss: 0.00352233695
Iter: 59 loss: 0.0033900016
Iter: 60 loss: 0.00331898499
Iter: 61 loss: 0.00326064695
Iter: 62 loss: 0.00307195261
Iter: 63 loss: 0.00367635535
Iter: 64 loss: 0.0030121326
Iter: 65 loss: 0.00287911156
Iter: 66 loss: 0.0029017413
Iter: 67 loss: 0.00278267846
Iter: 68 loss: 0.00261216704
Iter: 69 loss: 0.00279080262
Iter: 70 loss: 0.00251877354
Iter: 71 loss: 0.0026056054
Iter: 72 loss: 0.00245796703
Iter: 73 loss: 0.00240788
Iter: 74 loss: 0.00241762633
Iter: 75 loss: 0.00236947276
Iter: 76 loss: 0.00232120208
Iter: 77 loss: 0.0022161894
Iter: 78 loss: 0.00359665672
Iter: 79 loss: 0.00221130275
Iter: 80 loss: 0.00211384613
Iter: 81 loss: 0.00230635586
Iter: 82 loss: 0.00207242183
Iter: 83 loss: 0.00200241851
Iter: 84 loss: 0.00209487532
Iter: 85 loss: 0.00196481915
Iter: 86 loss: 0.00184490799
Iter: 87 loss: 0.00204438949
Iter: 88 loss: 0.00179241947
Iter: 89 loss: 0.00171097007
Iter: 90 loss: 0.00182500959
Iter: 91 loss: 0.00167237339
Iter: 92 loss: 0.00159157626
Iter: 93 loss: 0.00285013532
Iter: 94 loss: 0.00159151689
Iter: 95 loss: 0.00153910171
Iter: 96 loss: 0.00177940691
Iter: 97 loss: 0.00152946613
Iter: 98 loss: 0.00147812977
Iter: 99 loss: 0.00147670298
Iter: 100 loss: 0.00144589087
Iter: 101 loss: 0.00143000507
Iter: 102 loss: 0.00141627283
Iter: 103 loss: 0.00138334022
Iter: 104 loss: 0.00135371403
Iter: 105 loss: 0.00134512805
Iter: 106 loss: 0.00131654623
Iter: 107 loss: 0.00144984096
Iter: 108 loss: 0.00131238881
Iter: 109 loss: 0.00127947971
Iter: 110 loss: 0.00137982587
Iter: 111 loss: 0.00126876845
Iter: 112 loss: 0.00123579381
Iter: 113 loss: 0.00122090615
Iter: 114 loss: 0.00120460219
Iter: 115 loss: 0.0011629553
Iter: 116 loss: 0.00116113783
Iter: 117 loss: 0.00112812954
Iter: 118 loss: 0.00117492909
Iter: 119 loss: 0.00111287786
Iter: 120 loss: 0.00108559127
Iter: 121 loss: 0.00108203292
Iter: 122 loss: 0.00106261298
Iter: 123 loss: 0.00102921377
Iter: 124 loss: 0.00104943221
Iter: 125 loss: 0.00100770488
Iter: 126 loss: 0.00097106304
Iter: 127 loss: 0.00121716689
Iter: 128 loss: 0.000967670872
Iter: 129 loss: 0.000949688081
Iter: 130 loss: 0.00111925299
Iter: 131 loss: 0.00094901782
Iter: 132 loss: 0.000933385221
Iter: 133 loss: 0.00097844447
Iter: 134 loss: 0.000928255788
Iter: 135 loss: 0.000915109762
Iter: 136 loss: 0.000931827468
Iter: 137 loss: 0.000908499525
Iter: 138 loss: 0.000896906538
Iter: 139 loss: 0.000951516791
Iter: 140 loss: 0.00089461793
Iter: 141 loss: 0.000884015171
Iter: 142 loss: 0.000883894507
Iter: 143 loss: 0.000875560043
Iter: 144 loss: 0.000859893276
Iter: 145 loss: 0.00121057173
Iter: 146 loss: 0.000859858
Iter: 147 loss: 0.000846803363
Iter: 148 loss: 0.000879505125
Iter: 149 loss: 0.000842242967
Iter: 150 loss: 0.000828531745
Iter: 151 loss: 0.000829722674
Iter: 152 loss: 0.000817971712
Iter: 153 loss: 0.000803397095
Iter: 154 loss: 0.000831130543
Iter: 155 loss: 0.000797154498
Iter: 156 loss: 0.00078592659
Iter: 157 loss: 0.000875124417
Iter: 158 loss: 0.00078524393
Iter: 159 loss: 0.000773493259
Iter: 160 loss: 0.000782279181
Iter: 161 loss: 0.000766301877
Iter: 162 loss: 0.000754454522
Iter: 163 loss: 0.000814468134
Iter: 164 loss: 0.000752441934
Iter: 165 loss: 0.00074925361
Iter: 166 loss: 0.000747520244
Iter: 167 loss: 0.000743825
Iter: 168 loss: 0.000735101756
Iter: 169 loss: 0.000841395231
Iter: 170 loss: 0.000734350702
Iter: 171 loss: 0.000727172126
Iter: 172 loss: 0.000748039456
Iter: 173 loss: 0.000725016
Iter: 174 loss: 0.00071962009
Iter: 175 loss: 0.000718797382
Iter: 176 loss: 0.000714981463
Iter: 177 loss: 0.000706363237
Iter: 178 loss: 0.000753054279
Iter: 179 loss: 0.000705140876
Iter: 180 loss: 0.000699977216
Iter: 181 loss: 0.000695466879
Iter: 182 loss: 0.000694082
Iter: 183 loss: 0.000686040847
Iter: 184 loss: 0.000717544695
Iter: 185 loss: 0.000684207655
Iter: 186 loss: 0.000677123375
Iter: 187 loss: 0.000679346907
Iter: 188 loss: 0.000672084396
Iter: 189 loss: 0.000664262217
Iter: 190 loss: 0.000708222156
Iter: 191 loss: 0.000663117506
Iter: 192 loss: 0.000656116754
Iter: 193 loss: 0.000668969238
Iter: 194 loss: 0.000653187686
Iter: 195 loss: 0.000646428089
Iter: 196 loss: 0.000643267646
Iter: 197 loss: 0.000639946782
Iter: 198 loss: 0.000637003861
Iter: 199 loss: 0.000635522185
Iter: 200 loss: 0.000632577285
Iter: 201 loss: 0.000651484239
Iter: 202 loss: 0.00063228386
Iter: 203 loss: 0.000629851653
Iter: 204 loss: 0.000627229223
Iter: 205 loss: 0.000626813213
Iter: 206 loss: 0.000623200671
Iter: 207 loss: 0.000654060277
Iter: 208 loss: 0.000623021857
Iter: 209 loss: 0.000621013693
Iter: 210 loss: 0.000622295716
Iter: 211 loss: 0.000619727303
Iter: 212 loss: 0.000616859121
Iter: 213 loss: 0.000616228092
Iter: 214 loss: 0.000614375458
Iter: 215 loss: 0.000610304298
Iter: 216 loss: 0.000635674
Iter: 217 loss: 0.000609835144
Iter: 218 loss: 0.000606323942
Iter: 219 loss: 0.000604118337
Iter: 220 loss: 0.000602735789
Iter: 221 loss: 0.000598268467
Iter: 222 loss: 0.000635360833
Iter: 223 loss: 0.000598004437
Iter: 224 loss: 0.000594469369
Iter: 225 loss: 0.000610707
Iter: 226 loss: 0.000593774486
Iter: 227 loss: 0.000590785232
Iter: 228 loss: 0.000584725814
Iter: 229 loss: 0.000690453569
Iter: 230 loss: 0.000584625232
Iter: 231 loss: 0.000579240383
Iter: 232 loss: 0.000594896905
Iter: 233 loss: 0.000577569474
Iter: 234 loss: 0.000583432266
Iter: 235 loss: 0.000575499958
Iter: 236 loss: 0.00057417131
Iter: 237 loss: 0.000572037359
Iter: 238 loss: 0.000572022866
Iter: 239 loss: 0.000569213473
Iter: 240 loss: 0.000599419756
Iter: 241 loss: 0.00056913757
Iter: 242 loss: 0.000566794
Iter: 243 loss: 0.000569047115
Iter: 244 loss: 0.000565477298
Iter: 245 loss: 0.000563434849
Iter: 246 loss: 0.000561759167
Iter: 247 loss: 0.000561158871
Iter: 248 loss: 0.000558870379
Iter: 249 loss: 0.000557375257
Iter: 250 loss: 0.000556504761
Iter: 251 loss: 0.000553816557
Iter: 252 loss: 0.000552806
Iter: 253 loss: 0.000551325502
Iter: 254 loss: 0.000548041251
Iter: 255 loss: 0.000552236685
Iter: 256 loss: 0.000546333613
Iter: 257 loss: 0.000543537491
Iter: 258 loss: 0.000567857176
Iter: 259 loss: 0.000543401693
Iter: 260 loss: 0.000540449459
Iter: 261 loss: 0.00054347812
Iter: 262 loss: 0.000538812717
Iter: 263 loss: 0.000535318046
Iter: 264 loss: 0.000548903714
Iter: 265 loss: 0.000534484629
Iter: 266 loss: 0.000532283448
Iter: 267 loss: 0.000540140318
Iter: 268 loss: 0.000531735714
Iter: 269 loss: 0.00052949565
Iter: 270 loss: 0.000541263493
Iter: 271 loss: 0.000529136509
Iter: 272 loss: 0.000527268
Iter: 273 loss: 0.000537354383
Iter: 274 loss: 0.000527003198
Iter: 275 loss: 0.000525447831
Iter: 276 loss: 0.000544027309
Iter: 277 loss: 0.000525422627
Iter: 278 loss: 0.000524420582
Iter: 279 loss: 0.000523116265
Iter: 280 loss: 0.000523033086
Iter: 281 loss: 0.000520911533
Iter: 282 loss: 0.000530538266
Iter: 283 loss: 0.000520501169
Iter: 284 loss: 0.000519059598
Iter: 285 loss: 0.000522531278
Iter: 286 loss: 0.000518548128
Iter: 287 loss: 0.000517313601
Iter: 288 loss: 0.000517156324
Iter: 289 loss: 0.000516282162
Iter: 290 loss: 0.000514591113
Iter: 291 loss: 0.00052173622
Iter: 292 loss: 0.000514229527
Iter: 293 loss: 0.000511926599
Iter: 294 loss: 0.000512735161
Iter: 295 loss: 0.000510310754
Iter: 296 loss: 0.000507836638
Iter: 297 loss: 0.000510545
Iter: 298 loss: 0.000506505778
Iter: 299 loss: 0.000504999771
Iter: 300 loss: 0.000504772412
Iter: 301 loss: 0.000503617455
Iter: 302 loss: 0.000502075709
Iter: 303 loss: 0.000501993578
Iter: 304 loss: 0.000500119233
Iter: 305 loss: 0.000510255
Iter: 306 loss: 0.000499828428
Iter: 307 loss: 0.000498436682
Iter: 308 loss: 0.000506062293
Iter: 309 loss: 0.000498244539
Iter: 310 loss: 0.000496726483
Iter: 311 loss: 0.000497103436
Iter: 312 loss: 0.000495614833
Iter: 313 loss: 0.000493979256
Iter: 314 loss: 0.000500828959
Iter: 315 loss: 0.00049363781
Iter: 316 loss: 0.000492343
Iter: 317 loss: 0.00049509434
Iter: 318 loss: 0.000491829356
Iter: 319 loss: 0.000490627368
Iter: 320 loss: 0.000490161066
Iter: 321 loss: 0.000489507627
Iter: 322 loss: 0.000487732788
Iter: 323 loss: 0.000491043087
Iter: 324 loss: 0.000486981
Iter: 325 loss: 0.000485410623
Iter: 326 loss: 0.000485409226
Iter: 327 loss: 0.00048447054
Iter: 328 loss: 0.000482225412
Iter: 329 loss: 0.000507392397
Iter: 330 loss: 0.000482004281
Iter: 331 loss: 0.000480838702
Iter: 332 loss: 0.000480557559
Iter: 333 loss: 0.000479182898
Iter: 334 loss: 0.00048041172
Iter: 335 loss: 0.000478375907
Iter: 336 loss: 0.000476926391
Iter: 337 loss: 0.000484349701
Iter: 338 loss: 0.000476700196
Iter: 339 loss: 0.000475596113
Iter: 340 loss: 0.000476465211
Iter: 341 loss: 0.000474918983
Iter: 342 loss: 0.000473606749
Iter: 343 loss: 0.000477651076
Iter: 344 loss: 0.000473227294
Iter: 345 loss: 0.000472455
Iter: 346 loss: 0.000471155741
Iter: 347 loss: 0.00047115254
Iter: 348 loss: 0.000469573366
Iter: 349 loss: 0.00047659222
Iter: 350 loss: 0.000469266088
Iter: 351 loss: 0.000467984763
Iter: 352 loss: 0.000471389038
Iter: 353 loss: 0.000467553677
Iter: 354 loss: 0.000466273748
Iter: 355 loss: 0.000465848745
Iter: 356 loss: 0.000465107965
Iter: 357 loss: 0.000464220502
Iter: 358 loss: 0.000464178622
Iter: 359 loss: 0.000463295088
Iter: 360 loss: 0.000462530501
Iter: 361 loss: 0.000462291297
Iter: 362 loss: 0.000461222895
Iter: 363 loss: 0.000461100659
Iter: 364 loss: 0.000460330921
Iter: 365 loss: 0.000458913739
Iter: 366 loss: 0.000462143536
Iter: 367 loss: 0.000458380498
Iter: 368 loss: 0.000458738621
Iter: 369 loss: 0.000457771908
Iter: 370 loss: 0.000457360758
Iter: 371 loss: 0.00045731783
Iter: 372 loss: 0.000457015529
Iter: 373 loss: 0.000456482492
Iter: 374 loss: 0.000461245072
Iter: 375 loss: 0.000456458249
Iter: 376 loss: 0.000456108071
Iter: 377 loss: 0.00045549302
Iter: 378 loss: 0.000455492293
Iter: 379 loss: 0.000454686495
Iter: 380 loss: 0.000458210678
Iter: 381 loss: 0.00045452523
Iter: 382 loss: 0.000453753368
Iter: 383 loss: 0.000453652494
Iter: 384 loss: 0.000453104207
Iter: 385 loss: 0.000452154782
Iter: 386 loss: 0.000455228437
Iter: 387 loss: 0.00045188886
Iter: 388 loss: 0.000451113709
Iter: 389 loss: 0.000453536341
Iter: 390 loss: 0.000450890861
Iter: 391 loss: 0.000450068066
Iter: 392 loss: 0.000449525076
Iter: 393 loss: 0.000449214043
Iter: 394 loss: 0.000448107
Iter: 395 loss: 0.000451745931
Iter: 396 loss: 0.000447804719
Iter: 397 loss: 0.000446378021
Iter: 398 loss: 0.00044969155
Iter: 399 loss: 0.000445849728
Iter: 400 loss: 0.000444917532
Iter: 401 loss: 0.000446138845
Iter: 402 loss: 0.000444447913
Iter: 403 loss: 0.000443466241
Iter: 404 loss: 0.000443449215
Iter: 405 loss: 0.000442925666
Iter: 406 loss: 0.000443320809
Iter: 407 loss: 0.000442608434
Iter: 408 loss: 0.000441825134
Iter: 409 loss: 0.000440935954
Iter: 410 loss: 0.000440821634
Iter: 411 loss: 0.000439693773
Iter: 412 loss: 0.00044126084
Iter: 413 loss: 0.000439138676
Iter: 414 loss: 0.000437468349
Iter: 415 loss: 0.000439168041
Iter: 416 loss: 0.000436534348
Iter: 417 loss: 0.000435014139
Iter: 418 loss: 0.000444425794
Iter: 419 loss: 0.000434835907
Iter: 420 loss: 0.000433660374
Iter: 421 loss: 0.000434815825
Iter: 422 loss: 0.00043299445
Iter: 423 loss: 0.000431569846
Iter: 424 loss: 0.000438320887
Iter: 425 loss: 0.000431310502
Iter: 426 loss: 0.000430159242
Iter: 427 loss: 0.000431280088
Iter: 428 loss: 0.00042950947
Iter: 429 loss: 0.000428055355
Iter: 430 loss: 0.000434480171
Iter: 431 loss: 0.000427761
Iter: 432 loss: 0.000426488317
Iter: 433 loss: 0.000429706881
Iter: 434 loss: 0.000426052196
Iter: 435 loss: 0.000426112732
Iter: 436 loss: 0.000425680075
Iter: 437 loss: 0.00042534672
Iter: 438 loss: 0.000425141712
Iter: 439 loss: 0.000425007311
Iter: 440 loss: 0.00042435067
Iter: 441 loss: 0.000424306403
Iter: 442 loss: 0.000423810619
Iter: 443 loss: 0.00042323739
Iter: 444 loss: 0.000425357
Iter: 445 loss: 0.000423096586
Iter: 446 loss: 0.000422427198
Iter: 447 loss: 0.000422725832
Iter: 448 loss: 0.000421969336
Iter: 449 loss: 0.000421179284
Iter: 450 loss: 0.000423636346
Iter: 451 loss: 0.000420948432
Iter: 452 loss: 0.000420115335
Iter: 453 loss: 0.000420689292
Iter: 454 loss: 0.00041959493
Iter: 455 loss: 0.000418538082
Iter: 456 loss: 0.000423445483
Iter: 457 loss: 0.000418337528
Iter: 458 loss: 0.000417494943
Iter: 459 loss: 0.000420826895
Iter: 460 loss: 0.000417302857
Iter: 461 loss: 0.000416600204
Iter: 462 loss: 0.000416883326
Iter: 463 loss: 0.000416112278
Iter: 464 loss: 0.000415038405
Iter: 465 loss: 0.000418825424
Iter: 466 loss: 0.000414763461
Iter: 467 loss: 0.000414255657
Iter: 468 loss: 0.000414254959
Iter: 469 loss: 0.000413681788
Iter: 470 loss: 0.00041471544
Iter: 471 loss: 0.000413436152
Iter: 472 loss: 0.000412892579
Iter: 473 loss: 0.000412774971
Iter: 474 loss: 0.0004124197
Iter: 475 loss: 0.000411819696
Iter: 476 loss: 0.000411893503
Iter: 477 loss: 0.000411361718
Iter: 478 loss: 0.000410524488
Iter: 479 loss: 0.000414465962
Iter: 480 loss: 0.000410368724
Iter: 481 loss: 0.000409652188
Iter: 482 loss: 0.000409858068
Iter: 483 loss: 0.000409137429
Iter: 484 loss: 0.000408078573
Iter: 485 loss: 0.000412074238
Iter: 486 loss: 0.000407824205
Iter: 487 loss: 0.00040685173
Iter: 488 loss: 0.000408459338
Iter: 489 loss: 0.000406407635
Iter: 490 loss: 0.00040534875
Iter: 491 loss: 0.000412979454
Iter: 492 loss: 0.000405258295
Iter: 493 loss: 0.00040451219
Iter: 494 loss: 0.000405044557
Iter: 495 loss: 0.00040404906
Iter: 496 loss: 0.000403059821
Iter: 497 loss: 0.00040573033
Iter: 498 loss: 0.000402735663
Iter: 499 loss: 0.000402008067
Iter: 500 loss: 0.000406614272
Iter: 501 loss: 0.000401925237
Iter: 502 loss: 0.000401440542
Iter: 503 loss: 0.000401422265
Iter: 504 loss: 0.000401168567
Iter: 505 loss: 0.000400724937
Iter: 506 loss: 0.000400725461
Iter: 507 loss: 0.000400153338
Iter: 508 loss: 0.000399516197
Iter: 509 loss: 0.000399428362
Iter: 510 loss: 0.000398653
Iter: 511 loss: 0.00040554491
Iter: 512 loss: 0.000398613396
Iter: 513 loss: 0.000397987722
Iter: 514 loss: 0.000397228927
Iter: 515 loss: 0.000397155934
Iter: 516 loss: 0.000396034098
Iter: 517 loss: 0.000404998078
Iter: 518 loss: 0.000395958778
Iter: 519 loss: 0.000395101029
Iter: 520 loss: 0.000396218878
Iter: 521 loss: 0.000394664938
Iter: 522 loss: 0.000393807335
Iter: 523 loss: 0.000398202508
Iter: 524 loss: 0.000393670285
Iter: 525 loss: 0.000392754388
Iter: 526 loss: 0.000395783893
Iter: 527 loss: 0.000392498
Iter: 528 loss: 0.000391764188
Iter: 529 loss: 0.00039345707
Iter: 530 loss: 0.000391492562
Iter: 531 loss: 0.000390825619
Iter: 532 loss: 0.000391360081
Iter: 533 loss: 0.000390422181
Iter: 534 loss: 0.000390208734
Iter: 535 loss: 0.000389966968
Iter: 536 loss: 0.000389630324
Iter: 537 loss: 0.000389066408
Iter: 538 loss: 0.000389064488
Iter: 539 loss: 0.000388423534
Iter: 540 loss: 0.000388261396
Iter: 541 loss: 0.000387859705
Iter: 542 loss: 0.000387032545
Iter: 543 loss: 0.000388092041
Iter: 544 loss: 0.000386604777
Iter: 545 loss: 0.00038530305
Iter: 546 loss: 0.000385368534
Iter: 547 loss: 0.000384280604
Iter: 548 loss: 0.000383053964
Iter: 549 loss: 0.000391776557
Iter: 550 loss: 0.000382946542
Iter: 551 loss: 0.000381921302
Iter: 552 loss: 0.000384062878
Iter: 553 loss: 0.000381513528
Iter: 554 loss: 0.000380486628
Iter: 555 loss: 0.000380552839
Iter: 556 loss: 0.000379682868
Iter: 557 loss: 0.00037843184
Iter: 558 loss: 0.000393937167
Iter: 559 loss: 0.000378418597
Iter: 560 loss: 0.000377458229
Iter: 561 loss: 0.000381530495
Iter: 562 loss: 0.000377260119
Iter: 563 loss: 0.000376484066
Iter: 564 loss: 0.000377755845
Iter: 565 loss: 0.000376124779
Iter: 566 loss: 0.000375865435
Iter: 567 loss: 0.000375760254
Iter: 568 loss: 0.000375367119
Iter: 569 loss: 0.000374959636
Iter: 570 loss: 0.000374885043
Iter: 571 loss: 0.000374291703
Iter: 572 loss: 0.000374216441
Iter: 573 loss: 0.000373796385
Iter: 574 loss: 0.000373052317
Iter: 575 loss: 0.000374821801
Iter: 576 loss: 0.000372779963
Iter: 577 loss: 0.000371880858
Iter: 578 loss: 0.000372375856
Iter: 579 loss: 0.000371292117
Iter: 580 loss: 0.000370101741
Iter: 581 loss: 0.000371916889
Iter: 582 loss: 0.000369537272
Iter: 583 loss: 0.00036856503
Iter: 584 loss: 0.00037632219
Iter: 585 loss: 0.000368499896
Iter: 586 loss: 0.000367584493
Iter: 587 loss: 0.000367092143
Iter: 588 loss: 0.000366679829
Iter: 589 loss: 0.000365662621
Iter: 590 loss: 0.00037276058
Iter: 591 loss: 0.000365566055
Iter: 592 loss: 0.000364576
Iter: 593 loss: 0.000370842637
Iter: 594 loss: 0.000364465872
Iter: 595 loss: 0.000363670872
Iter: 596 loss: 0.000365106098
Iter: 597 loss: 0.000363321305
Iter: 598 loss: 0.000362768187
Iter: 599 loss: 0.00036621897
Iter: 600 loss: 0.000362706254
Iter: 601 loss: 0.000362065592
Iter: 602 loss: 0.000365636835
Iter: 603 loss: 0.000361973274
Iter: 604 loss: 0.000361626793
Iter: 605 loss: 0.000360822945
Iter: 606 loss: 0.000370742724
Iter: 607 loss: 0.000360762555
Iter: 608 loss: 0.000359673286
Iter: 609 loss: 0.000364477572
Iter: 610 loss: 0.000359452
Iter: 611 loss: 0.000358520541
Iter: 612 loss: 0.000361974759
Iter: 613 loss: 0.000358292775
Iter: 614 loss: 0.000357336714
Iter: 615 loss: 0.000357454846
Iter: 616 loss: 0.000356606906
Iter: 617 loss: 0.000355754542
Iter: 618 loss: 0.00036015021
Iter: 619 loss: 0.000355617813
Iter: 620 loss: 0.000354742806
Iter: 621 loss: 0.000357522
Iter: 622 loss: 0.000354492979
Iter: 623 loss: 0.000353875745
Iter: 624 loss: 0.000354333024
Iter: 625 loss: 0.000353497977
Iter: 626 loss: 0.000352771487
Iter: 627 loss: 0.000355622673
Iter: 628 loss: 0.000352607807
Iter: 629 loss: 0.00035173088
Iter: 630 loss: 0.000356487872
Iter: 631 loss: 0.000351596682
Iter: 632 loss: 0.00035115637
Iter: 633 loss: 0.000351717463
Iter: 634 loss: 0.000350929855
Iter: 635 loss: 0.000350548595
Iter: 636 loss: 0.000350534567
Iter: 637 loss: 0.000350306858
Iter: 638 loss: 0.000349699723
Iter: 639 loss: 0.000353887386
Iter: 640 loss: 0.000349560461
Iter: 641 loss: 0.000348981586
Iter: 642 loss: 0.000352841074
Iter: 643 loss: 0.000348921167
Iter: 644 loss: 0.000348428322
Iter: 645 loss: 0.000347952242
Iter: 646 loss: 0.000347844034
Iter: 647 loss: 0.000347085
Iter: 648 loss: 0.00035523955
Iter: 649 loss: 0.000347067253
Iter: 650 loss: 0.000346529239
Iter: 651 loss: 0.000346530811
Iter: 652 loss: 0.000346098968
Iter: 653 loss: 0.000345437467
Iter: 654 loss: 0.000346661778
Iter: 655 loss: 0.000345153618
Iter: 656 loss: 0.000344246742
Iter: 657 loss: 0.00034680462
Iter: 658 loss: 0.000343954132
Iter: 659 loss: 0.00034318908
Iter: 660 loss: 0.00034433
Iter: 661 loss: 0.000342822517
Iter: 662 loss: 0.000342152431
Iter: 663 loss: 0.000347853784
Iter: 664 loss: 0.000342113373
Iter: 665 loss: 0.000341673091
Iter: 666 loss: 0.000342677871
Iter: 667 loss: 0.000341509585
Iter: 668 loss: 0.000341213512
Iter: 669 loss: 0.000344378845
Iter: 670 loss: 0.000341206091
Iter: 671 loss: 0.000341026403
Iter: 672 loss: 0.000340682513
Iter: 673 loss: 0.000347864057
Iter: 674 loss: 0.00034068065
Iter: 675 loss: 0.000340263592
Iter: 676 loss: 0.00034054686
Iter: 677 loss: 0.000340001163
Iter: 678 loss: 0.000339538208
Iter: 679 loss: 0.000341687759
Iter: 680 loss: 0.000339451188
Iter: 681 loss: 0.000339108636
Iter: 682 loss: 0.00033922703
Iter: 683 loss: 0.00033886591
Iter: 684 loss: 0.000338293379
Iter: 685 loss: 0.000340059196
Iter: 686 loss: 0.000338125508
Iter: 687 loss: 0.000337681675
Iter: 688 loss: 0.000337391044
Iter: 689 loss: 0.000337221543
Iter: 690 loss: 0.000336647208
Iter: 691 loss: 0.000343732943
Iter: 692 loss: 0.0003366413
Iter: 693 loss: 0.000336246041
Iter: 694 loss: 0.000337064615
Iter: 695 loss: 0.0003360876
Iter: 696 loss: 0.000335786754
Iter: 697 loss: 0.000339250837
Iter: 698 loss: 0.000335782504
Iter: 699 loss: 0.000335564779
Iter: 700 loss: 0.00033632922
Iter: 701 loss: 0.000335508958
Iter: 702 loss: 0.000335281948
Iter: 703 loss: 0.000335944351
Iter: 704 loss: 0.000335210061
Iter: 705 loss: 0.00033496879
Iter: 706 loss: 0.000334551645
Iter: 707 loss: 0.000334551238
Iter: 708 loss: 0.000334077951
Iter: 709 loss: 0.000335407356
Iter: 710 loss: 0.000333926815
Iter: 711 loss: 0.000333432923
Iter: 712 loss: 0.000334467535
Iter: 713 loss: 0.000333238044
Iter: 714 loss: 0.000332704338
Iter: 715 loss: 0.000333340955
Iter: 716 loss: 0.000332421914
Iter: 717 loss: 0.000331888499
Iter: 718 loss: 0.000335506164
Iter: 719 loss: 0.000331836491
Iter: 720 loss: 0.000331405754
Iter: 721 loss: 0.000331913063
Iter: 722 loss: 0.000331177551
Iter: 723 loss: 0.000330774754
Iter: 724 loss: 0.000331567368
Iter: 725 loss: 0.000330607611
Iter: 726 loss: 0.000330171199
Iter: 727 loss: 0.00033272861
Iter: 728 loss: 0.000330115552
Iter: 729 loss: 0.000329615257
Iter: 730 loss: 0.000328755879
Iter: 731 loss: 0.000328755
Iter: 732 loss: 0.000328962342
Iter: 733 loss: 0.00032840221
Iter: 734 loss: 0.000328109192
Iter: 735 loss: 0.00032902055
Iter: 736 loss: 0.00032802223
Iter: 737 loss: 0.000327724556
Iter: 738 loss: 0.000327237212
Iter: 739 loss: 0.00032723404
Iter: 740 loss: 0.000326853362
Iter: 741 loss: 0.000328126538
Iter: 742 loss: 0.00032674885
Iter: 743 loss: 0.000326332112
Iter: 744 loss: 0.000326622394
Iter: 745 loss: 0.000326072681
Iter: 746 loss: 0.000325525703
Iter: 747 loss: 0.000327289046
Iter: 748 loss: 0.000325370027
Iter: 749 loss: 0.000324890279
Iter: 750 loss: 0.000325971283
Iter: 751 loss: 0.000324709
Iter: 752 loss: 0.000324090885
Iter: 753 loss: 0.000324968074
Iter: 754 loss: 0.000323787041
Iter: 755 loss: 0.000323069369
Iter: 756 loss: 0.000322969834
Iter: 757 loss: 0.000322463049
Iter: 758 loss: 0.000321540778
Iter: 759 loss: 0.000329838193
Iter: 760 loss: 0.000321497966
Iter: 761 loss: 0.000320654479
Iter: 762 loss: 0.000322353968
Iter: 763 loss: 0.000320310384
Iter: 764 loss: 0.000319794461
Iter: 765 loss: 0.000323500892
Iter: 766 loss: 0.000319750921
Iter: 767 loss: 0.000319268322
Iter: 768 loss: 0.000324346242
Iter: 769 loss: 0.000319254701
Iter: 770 loss: 0.000318976614
Iter: 771 loss: 0.000318638748
Iter: 772 loss: 0.000318606326
Iter: 773 loss: 0.000318219361
Iter: 774 loss: 0.000317936472
Iter: 775 loss: 0.000317805272
Iter: 776 loss: 0.000317082333
Iter: 777 loss: 0.000319309474
Iter: 778 loss: 0.000316870864
Iter: 779 loss: 0.000316077087
Iter: 780 loss: 0.000317484315
Iter: 781 loss: 0.000315725658
Iter: 782 loss: 0.000314791454
Iter: 783 loss: 0.000316463585
Iter: 784 loss: 0.000314384059
Iter: 785 loss: 0.000313492026
Iter: 786 loss: 0.000319388404
Iter: 787 loss: 0.000313398632
Iter: 788 loss: 0.000312737713
Iter: 789 loss: 0.000312682794
Iter: 790 loss: 0.000312191551
Iter: 791 loss: 0.000311294
Iter: 792 loss: 0.000313895347
Iter: 793 loss: 0.000311014883
Iter: 794 loss: 0.000310116913
Iter: 795 loss: 0.000317196478
Iter: 796 loss: 0.000310053758
Iter: 797 loss: 0.000309437106
Iter: 798 loss: 0.000311054813
Iter: 799 loss: 0.000309231458
Iter: 800 loss: 0.000309078721
Iter: 801 loss: 0.000308894902
Iter: 802 loss: 0.000308712129
Iter: 803 loss: 0.000308313232
Iter: 804 loss: 0.00031414954
Iter: 805 loss: 0.000308294198
Iter: 806 loss: 0.000307760551
Iter: 807 loss: 0.000306940405
Iter: 808 loss: 0.00030692789
Iter: 809 loss: 0.00030591205
Iter: 810 loss: 0.000311496318
Iter: 811 loss: 0.000305768888
Iter: 812 loss: 0.000304736372
Iter: 813 loss: 0.000309140596
Iter: 814 loss: 0.000304514
Iter: 815 loss: 0.00030377775
Iter: 816 loss: 0.000305501395
Iter: 817 loss: 0.000303505
Iter: 818 loss: 0.000302768109
Iter: 819 loss: 0.000304327521
Iter: 820 loss: 0.000302476517
Iter: 821 loss: 0.000301610678
Iter: 822 loss: 0.000302519416
Iter: 823 loss: 0.000301129534
Iter: 824 loss: 0.000300172
Iter: 825 loss: 0.000301900291
Iter: 826 loss: 0.000299756706
Iter: 827 loss: 0.000298716419
Iter: 828 loss: 0.000304985268
Iter: 829 loss: 0.000298585917
Iter: 830 loss: 0.000297751947
Iter: 831 loss: 0.000302259083
Iter: 832 loss: 0.000297628314
Iter: 833 loss: 0.000297700957
Iter: 834 loss: 0.000297394465
Iter: 835 loss: 0.000297188642
Iter: 836 loss: 0.000296605343
Iter: 837 loss: 0.000299499108
Iter: 838 loss: 0.000296410813
Iter: 839 loss: 0.00029553083
Iter: 840 loss: 0.000297748804
Iter: 841 loss: 0.000295224309
Iter: 842 loss: 0.000294538098
Iter: 843 loss: 0.000294467551
Iter: 844 loss: 0.000293967838
Iter: 845 loss: 0.000293197052
Iter: 846 loss: 0.00030261057
Iter: 847 loss: 0.000293187099
Iter: 848 loss: 0.000292626733
Iter: 849 loss: 0.000292858749
Iter: 850 loss: 0.000292239361
Iter: 851 loss: 0.000291431323
Iter: 852 loss: 0.000293555582
Iter: 853 loss: 0.000291157863
Iter: 854 loss: 0.000290295982
Iter: 855 loss: 0.000292545737
Iter: 856 loss: 0.00029000247
Iter: 857 loss: 0.000289289892
Iter: 858 loss: 0.000289549498
Iter: 859 loss: 0.000288788637
Iter: 860 loss: 0.000287966395
Iter: 861 loss: 0.000292326265
Iter: 862 loss: 0.000287837232
Iter: 863 loss: 0.000287196483
Iter: 864 loss: 0.00029101246
Iter: 865 loss: 0.000287115341
Iter: 866 loss: 0.000286769209
Iter: 867 loss: 0.000291357836
Iter: 868 loss: 0.000286766794
Iter: 869 loss: 0.000286325463
Iter: 870 loss: 0.000285938819
Iter: 871 loss: 0.000285823888
Iter: 872 loss: 0.000285467395
Iter: 873 loss: 0.000285083632
Iter: 874 loss: 0.000285021553
Iter: 875 loss: 0.000284232839
Iter: 876 loss: 0.00028418249
Iter: 877 loss: 0.000283583591
Iter: 878 loss: 0.000282893423
Iter: 879 loss: 0.000289696269
Iter: 880 loss: 0.000282867753
Iter: 881 loss: 0.000282194931
Iter: 882 loss: 0.000283529371
Iter: 883 loss: 0.000281917979
Iter: 884 loss: 0.000281332759
Iter: 885 loss: 0.000281657733
Iter: 886 loss: 0.000280949345
Iter: 887 loss: 0.000280217268
Iter: 888 loss: 0.00028468
Iter: 889 loss: 0.000280128414
Iter: 890 loss: 0.00027951
Iter: 891 loss: 0.000279564207
Iter: 892 loss: 0.000279030297
Iter: 893 loss: 0.000278298889
Iter: 894 loss: 0.000280570472
Iter: 895 loss: 0.000278083811
Iter: 896 loss: 0.000277367537
Iter: 897 loss: 0.000280600856
Iter: 898 loss: 0.000277229352
Iter: 899 loss: 0.000276894163
Iter: 900 loss: 0.000276859326
Iter: 901 loss: 0.00027648703
Iter: 902 loss: 0.00027724239
Iter: 903 loss: 0.00027633732
Iter: 904 loss: 0.000276051869
Iter: 905 loss: 0.000275322032
Iter: 906 loss: 0.000281749119
Iter: 907 loss: 0.000275204
Iter: 908 loss: 0.000274489925
Iter: 909 loss: 0.000277198153
Iter: 910 loss: 0.000274317805
Iter: 911 loss: 0.000273569021
Iter: 912 loss: 0.000274557446
Iter: 913 loss: 0.00027318942
Iter: 914 loss: 0.00027244931
Iter: 915 loss: 0.000274537771
Iter: 916 loss: 0.000272215082
Iter: 917 loss: 0.00027125451
Iter: 918 loss: 0.000276247825
Iter: 919 loss: 0.000271101191
Iter: 920 loss: 0.000270564575
Iter: 921 loss: 0.000270414981
Iter: 922 loss: 0.00027008864
Iter: 923 loss: 0.000269396813
Iter: 924 loss: 0.000273989
Iter: 925 loss: 0.000269325101
Iter: 926 loss: 0.000268663309
Iter: 927 loss: 0.000269408571
Iter: 928 loss: 0.000268306292
Iter: 929 loss: 0.000267638214
Iter: 930 loss: 0.000266850489
Iter: 931 loss: 0.000266764517
Iter: 932 loss: 0.000266099349
Iter: 933 loss: 0.00026602688
Iter: 934 loss: 0.000265719747
Iter: 935 loss: 0.000265696668
Iter: 936 loss: 0.000265317736
Iter: 937 loss: 0.000264736853
Iter: 938 loss: 0.000264728151
Iter: 939 loss: 0.000264361268
Iter: 940 loss: 0.000264199858
Iter: 941 loss: 0.000264013855
Iter: 942 loss: 0.000263372727
Iter: 943 loss: 0.000262929243
Iter: 944 loss: 0.000262697431
Iter: 945 loss: 0.000262015732
Iter: 946 loss: 0.000270034565
Iter: 947 loss: 0.000262003974
Iter: 948 loss: 0.000261429523
Iter: 949 loss: 0.000261649635
Iter: 950 loss: 0.000261028559
Iter: 951 loss: 0.000260478962
Iter: 952 loss: 0.000268703618
Iter: 953 loss: 0.00026047873
Iter: 954 loss: 0.000260065892
Iter: 955 loss: 0.000259367109
Iter: 956 loss: 0.000259365304
Iter: 957 loss: 0.000258643617
Iter: 958 loss: 0.000263511611
Iter: 959 loss: 0.000258569664
Iter: 960 loss: 0.000257803535
Iter: 961 loss: 0.000259896333
Iter: 962 loss: 0.000257551932
Iter: 963 loss: 0.000256984582
Iter: 964 loss: 0.000256610569
Iter: 965 loss: 0.000256396248
Iter: 966 loss: 0.000256286614
Iter: 967 loss: 0.000256068481
Iter: 968 loss: 0.000255706196
Iter: 969 loss: 0.000256508181
Iter: 970 loss: 0.000255569932
Iter: 971 loss: 0.000255315274
Iter: 972 loss: 0.000254957675
Iter: 973 loss: 0.000254943618
Iter: 974 loss: 0.000254497631
Iter: 975 loss: 0.000254066224
Iter: 976 loss: 0.000253967562
Iter: 977 loss: 0.000253379694
Iter: 978 loss: 0.000256771134
Iter: 979 loss: 0.000253300357
Iter: 980 loss: 0.00025260853
Iter: 981 loss: 0.000253561593
Iter: 982 loss: 0.000252265454
Iter: 983 loss: 0.000251681078
Iter: 984 loss: 0.000254500628
Iter: 985 loss: 0.000251575
Iter: 986 loss: 0.000250898942
Iter: 987 loss: 0.000252256286
Iter: 988 loss: 0.000250623969
Iter: 989 loss: 0.000249970064
Iter: 990 loss: 0.000250417681
Iter: 991 loss: 0.000249558128
Iter: 992 loss: 0.000248990778
Iter: 993 loss: 0.000252274389
Iter: 994 loss: 0.00024891505
Iter: 995 loss: 0.000248275232
Iter: 996 loss: 0.000248408236
Iter: 997 loss: 0.000247800257
Iter: 998 loss: 0.000247037446
Iter: 999 loss: 0.00025315996
Iter: 1000 loss: 0.000246987271
Iter: 1001 loss: 0.000246823591
Iter: 1002 loss: 0.000246771029
Iter: 1003 loss: 0.00024646477
Iter: 1004 loss: 0.000245664851
Iter: 1005 loss: 0.000251904799
Iter: 1006 loss: 0.000245512
Iter: 1007 loss: 0.000245085306
Iter: 1008 loss: 0.000245561125
Iter: 1009 loss: 0.000244852679
Iter: 1010 loss: 0.000244104944
Iter: 1011 loss: 0.000243839037
Iter: 1012 loss: 0.000243417046
Iter: 1013 loss: 0.000242657436
Iter: 1014 loss: 0.000244343304
Iter: 1015 loss: 0.00024236631
Iter: 1016 loss: 0.000241693706
Iter: 1017 loss: 0.000248762139
Iter: 1018 loss: 0.000241676418
Iter: 1019 loss: 0.00024109651
Iter: 1020 loss: 0.00024170753
Iter: 1021 loss: 0.000240774665
Iter: 1022 loss: 0.000240183712
Iter: 1023 loss: 0.000244995463
Iter: 1024 loss: 0.000240146343
Iter: 1025 loss: 0.000239717861
Iter: 1026 loss: 0.000240396432
Iter: 1027 loss: 0.000239516623
Iter: 1028 loss: 0.000239103014
Iter: 1029 loss: 0.000238185952
Iter: 1030 loss: 0.000251506222
Iter: 1031 loss: 0.000238141627
Iter: 1032 loss: 0.000237743312
Iter: 1033 loss: 0.000237633532
Iter: 1034 loss: 0.000237245651
Iter: 1035 loss: 0.000236863692
Iter: 1036 loss: 0.000236780659
Iter: 1037 loss: 0.000237233209
Iter: 1038 loss: 0.000236605862
Iter: 1039 loss: 0.000236400461
Iter: 1040 loss: 0.000235942105
Iter: 1041 loss: 0.000242425915
Iter: 1042 loss: 0.000235917585
Iter: 1043 loss: 0.000235579195
Iter: 1044 loss: 0.000235205167
Iter: 1045 loss: 0.000235151369
Iter: 1046 loss: 0.000234530133
Iter: 1047 loss: 0.000235426865
Iter: 1048 loss: 0.000234226711
Iter: 1049 loss: 0.000233663319
Iter: 1050 loss: 0.000241309986
Iter: 1051 loss: 0.000233660787
Iter: 1052 loss: 0.000233190018
Iter: 1053 loss: 0.000232762119
Iter: 1054 loss: 0.000232644394
Iter: 1055 loss: 0.00023220708
Iter: 1056 loss: 0.000238057808
Iter: 1057 loss: 0.000232205057
Iter: 1058 loss: 0.000231759419
Iter: 1059 loss: 0.000232424543
Iter: 1060 loss: 0.000231545433
Iter: 1061 loss: 0.000231105194
Iter: 1062 loss: 0.000231998885
Iter: 1063 loss: 0.000230926293
Iter: 1064 loss: 0.000230391772
Iter: 1065 loss: 0.000231211889
Iter: 1066 loss: 0.000230140577
Iter: 1067 loss: 0.000229591751
Iter: 1068 loss: 0.000230124861
Iter: 1069 loss: 0.000229280529
Iter: 1070 loss: 0.000228757272
Iter: 1071 loss: 0.000234360021
Iter: 1072 loss: 0.000228743855
Iter: 1073 loss: 0.000228405435
Iter: 1074 loss: 0.000228390782
Iter: 1075 loss: 0.000228238496
Iter: 1076 loss: 0.000227862125
Iter: 1077 loss: 0.000231617276
Iter: 1078 loss: 0.000227814628
Iter: 1079 loss: 0.000227400451
Iter: 1080 loss: 0.000226927019
Iter: 1081 loss: 0.000226868346
Iter: 1082 loss: 0.000226270087
Iter: 1083 loss: 0.000229746656
Iter: 1084 loss: 0.000226191187
Iter: 1085 loss: 0.000225675903
Iter: 1086 loss: 0.000227588796
Iter: 1087 loss: 0.000225550175
Iter: 1088 loss: 0.000225176613
Iter: 1089 loss: 0.000228016987
Iter: 1090 loss: 0.000225147727
Iter: 1091 loss: 0.00022477156
Iter: 1092 loss: 0.000224404852
Iter: 1093 loss: 0.000224323478
Iter: 1094 loss: 0.000223886775
Iter: 1095 loss: 0.00022758657
Iter: 1096 loss: 0.00022386093
Iter: 1097 loss: 0.000223454874
Iter: 1098 loss: 0.000223493247
Iter: 1099 loss: 0.000223141964
Iter: 1100 loss: 0.000222678442
Iter: 1101 loss: 0.00022404507
Iter: 1102 loss: 0.000222537288
Iter: 1103 loss: 0.000222023009
Iter: 1104 loss: 0.000223513227
Iter: 1105 loss: 0.000221864088
Iter: 1106 loss: 0.000222059156
Iter: 1107 loss: 0.000221724302
Iter: 1108 loss: 0.000221590279
Iter: 1109 loss: 0.00022125282
Iter: 1110 loss: 0.000224298186
Iter: 1111 loss: 0.000221202106
Iter: 1112 loss: 0.000220850925
Iter: 1113 loss: 0.000221844661
Iter: 1114 loss: 0.000220738293
Iter: 1115 loss: 0.00022046169
Iter: 1116 loss: 0.000219979032
Iter: 1117 loss: 0.000219978567
Iter: 1118 loss: 0.000219394118
Iter: 1119 loss: 0.00021973229
Iter: 1120 loss: 0.000219015405
Iter: 1121 loss: 0.000218433677
Iter: 1122 loss: 0.000220295144
Iter: 1123 loss: 0.000218268062
Iter: 1124 loss: 0.0002178055
Iter: 1125 loss: 0.000222027738
Iter: 1126 loss: 0.000217784604
Iter: 1127 loss: 0.000217325185
Iter: 1128 loss: 0.00022016294
Iter: 1129 loss: 0.000217271183
Iter: 1130 loss: 0.000216939152
Iter: 1131 loss: 0.000220011425
Iter: 1132 loss: 0.000216924818
Iter: 1133 loss: 0.00021672924
Iter: 1134 loss: 0.000216425295
Iter: 1135 loss: 0.000216421642
Iter: 1136 loss: 0.000216011162
Iter: 1137 loss: 0.000218556146
Iter: 1138 loss: 0.000215962486
Iter: 1139 loss: 0.000215679582
Iter: 1140 loss: 0.000218538873
Iter: 1141 loss: 0.000215671345
Iter: 1142 loss: 0.00021534902
Iter: 1143 loss: 0.000216669316
Iter: 1144 loss: 0.000215278269
Iter: 1145 loss: 0.000215153021
Iter: 1146 loss: 0.000214851956
Iter: 1147 loss: 0.000218032714
Iter: 1148 loss: 0.000214818749
Iter: 1149 loss: 0.000214397442
Iter: 1150 loss: 0.000215090869
Iter: 1151 loss: 0.000214203857
Iter: 1152 loss: 0.000213722451
Iter: 1153 loss: 0.000214500949
Iter: 1154 loss: 0.000213500884
Iter: 1155 loss: 0.000212970335
Iter: 1156 loss: 0.000213627849
Iter: 1157 loss: 0.000212695581
Iter: 1158 loss: 0.000212339946
Iter: 1159 loss: 0.000212334824
Iter: 1160 loss: 0.000212031213
Iter: 1161 loss: 0.000211627805
Iter: 1162 loss: 0.000211604696
Iter: 1163 loss: 0.000211221501
Iter: 1164 loss: 0.000211303646
Iter: 1165 loss: 0.00021093688
Iter: 1166 loss: 0.000210922124
Iter: 1167 loss: 0.000210728293
Iter: 1168 loss: 0.000210497295
Iter: 1169 loss: 0.000210079452
Iter: 1170 loss: 0.000220065267
Iter: 1171 loss: 0.000210079597
Iter: 1172 loss: 0.000209931895
Iter: 1173 loss: 0.000209890582
Iter: 1174 loss: 0.000209779959
Iter: 1175 loss: 0.000209773963
Iter: 1176 loss: 0.000209713238
Iter: 1177 loss: 0.000209531776
Iter: 1178 loss: 0.000210073864
Iter: 1179 loss: 0.000209440303
Iter: 1180 loss: 0.000209141959
Iter: 1181 loss: 0.000209509279
Iter: 1182 loss: 0.000208985643
Iter: 1183 loss: 0.000208636236
Iter: 1184 loss: 0.00020853171
Iter: 1185 loss: 0.000208322803
Iter: 1186 loss: 0.000207876161
Iter: 1187 loss: 0.00021087403
Iter: 1188 loss: 0.000207831792
Iter: 1189 loss: 0.000207432182
Iter: 1190 loss: 0.000208694983
Iter: 1191 loss: 0.000207316887
Iter: 1192 loss: 0.000206953613
Iter: 1193 loss: 0.000207511446
Iter: 1194 loss: 0.000206782162
Iter: 1195 loss: 0.000206405559
Iter: 1196 loss: 0.000206323763
Iter: 1197 loss: 0.000206079509
Iter: 1198 loss: 0.000205582342
Iter: 1199 loss: 0.00020969515
Iter: 1200 loss: 0.000205552569
Iter: 1201 loss: 0.000205208518
Iter: 1202 loss: 0.000208526719
Iter: 1203 loss: 0.000205195684
Iter: 1204 loss: 0.000204958866
Iter: 1205 loss: 0.000205099655
Iter: 1206 loss: 0.000204806303
Iter: 1207 loss: 0.000205166027
Iter: 1208 loss: 0.000204735697
Iter: 1209 loss: 0.000204686949
Iter: 1210 loss: 0.000204535565
Iter: 1211 loss: 0.000204819444
Iter: 1212 loss: 0.000204436161
Iter: 1213 loss: 0.000204121505
Iter: 1214 loss: 0.000204346405
Iter: 1215 loss: 0.000203927149
Iter: 1216 loss: 0.000203631
Iter: 1217 loss: 0.000204828335
Iter: 1218 loss: 0.000203565083
Iter: 1219 loss: 0.000203305535
Iter: 1220 loss: 0.000203260657
Iter: 1221 loss: 0.000203083924
Iter: 1222 loss: 0.000202744952
Iter: 1223 loss: 0.000204819196
Iter: 1224 loss: 0.000202703988
Iter: 1225 loss: 0.000202404131
Iter: 1226 loss: 0.000203942735
Iter: 1227 loss: 0.000202355441
Iter: 1228 loss: 0.000202127776
Iter: 1229 loss: 0.0002021564
Iter: 1230 loss: 0.000201953691
Iter: 1231 loss: 0.000201638817
Iter: 1232 loss: 0.000203118325
Iter: 1233 loss: 0.000201581337
Iter: 1234 loss: 0.000201295043
Iter: 1235 loss: 0.000201195158
Iter: 1236 loss: 0.000201033894
Iter: 1237 loss: 0.000200665367
Iter: 1238 loss: 0.000204169846
Iter: 1239 loss: 0.00020065179
Iter: 1240 loss: 0.000200709765
Iter: 1241 loss: 0.000200543
Iter: 1242 loss: 0.000200426584
Iter: 1243 loss: 0.000200192706
Iter: 1244 loss: 0.000204618322
Iter: 1245 loss: 0.000200189388
Iter: 1246 loss: 0.000199999689
Iter: 1247 loss: 0.000199667615
Iter: 1248 loss: 0.000199668313
Iter: 1249 loss: 0.00019939203
Iter: 1250 loss: 0.000203518197
Iter: 1251 loss: 0.000199392
Iter: 1252 loss: 0.000199185713
Iter: 1253 loss: 0.000198849593
Iter: 1254 loss: 0.000198847352
Iter: 1255 loss: 0.000198488648
Iter: 1256 loss: 0.000199165137
Iter: 1257 loss: 0.000198337802
Iter: 1258 loss: 0.000198074937
Iter: 1259 loss: 0.000201558127
Iter: 1260 loss: 0.00019807354
Iter: 1261 loss: 0.000197841437
Iter: 1262 loss: 0.000197801826
Iter: 1263 loss: 0.000197643225
Iter: 1264 loss: 0.000197386384
Iter: 1265 loss: 0.000198014095
Iter: 1266 loss: 0.000197294838
Iter: 1267 loss: 0.0001969234
Iter: 1268 loss: 0.000196974608
Iter: 1269 loss: 0.000196641195
Iter: 1270 loss: 0.000196323352
Iter: 1271 loss: 0.0001982416
Iter: 1272 loss: 0.000196284236
Iter: 1273 loss: 0.000196178895
Iter: 1274 loss: 0.000196139808
Iter: 1275 loss: 0.000195970322
Iter: 1276 loss: 0.000196143839
Iter: 1277 loss: 0.00019587556
Iter: 1278 loss: 0.000195762681
Iter: 1279 loss: 0.000195547531
Iter: 1280 loss: 0.000200193928
Iter: 1281 loss: 0.000195546454
Iter: 1282 loss: 0.000195295026
Iter: 1283 loss: 0.000195341359
Iter: 1284 loss: 0.000195106521
Iter: 1285 loss: 0.000194753229
Iter: 1286 loss: 0.000197188434
Iter: 1287 loss: 0.000194719323
Iter: 1288 loss: 0.000194458145
Iter: 1289 loss: 0.00019463335
Iter: 1290 loss: 0.000194292807
Iter: 1291 loss: 0.00019394196
Iter: 1292 loss: 0.000193813175
Iter: 1293 loss: 0.000193618442
Iter: 1294 loss: 0.000193325293
Iter: 1295 loss: 0.000193306973
Iter: 1296 loss: 0.000193072337
Iter: 1297 loss: 0.000192877342
Iter: 1298 loss: 0.000192810607
Iter: 1299 loss: 0.000192385138
Iter: 1300 loss: 0.000193636064
Iter: 1301 loss: 0.00019225385
Iter: 1302 loss: 0.000191872707
Iter: 1303 loss: 0.000192570908
Iter: 1304 loss: 0.000191708474
Iter: 1305 loss: 0.000191388623
Iter: 1306 loss: 0.000194763939
Iter: 1307 loss: 0.000191381449
Iter: 1308 loss: 0.000191150481
Iter: 1309 loss: 0.000191148283
Iter: 1310 loss: 0.000191023733
Iter: 1311 loss: 0.000190704421
Iter: 1312 loss: 0.000193401822
Iter: 1313 loss: 0.000190650186
Iter: 1314 loss: 0.000190385559
Iter: 1315 loss: 0.000190884835
Iter: 1316 loss: 0.00019027284
Iter: 1317 loss: 0.000189897473
Iter: 1318 loss: 0.000189860613
Iter: 1319 loss: 0.000189585757
Iter: 1320 loss: 0.000189212107
Iter: 1321 loss: 0.000189210798
Iter: 1322 loss: 0.00018895512
Iter: 1323 loss: 0.00018846929
Iter: 1324 loss: 0.000198994196
Iter: 1325 loss: 0.000188467297
Iter: 1326 loss: 0.000188064208
Iter: 1327 loss: 0.000188064689
Iter: 1328 loss: 0.000187749189
Iter: 1329 loss: 0.000189018698
Iter: 1330 loss: 0.000187678379
Iter: 1331 loss: 0.000187375903
Iter: 1332 loss: 0.000187107653
Iter: 1333 loss: 0.000187030178
Iter: 1334 loss: 0.00018658863
Iter: 1335 loss: 0.000188815233
Iter: 1336 loss: 0.000186514808
Iter: 1337 loss: 0.000186084071
Iter: 1338 loss: 0.000186460558
Iter: 1339 loss: 0.000185831334
Iter: 1340 loss: 0.000186527293
Iter: 1341 loss: 0.00018572509
Iter: 1342 loss: 0.000185633748
Iter: 1343 loss: 0.000185378332
Iter: 1344 loss: 0.000186673933
Iter: 1345 loss: 0.000185294761
Iter: 1346 loss: 0.000184904784
Iter: 1347 loss: 0.000185319921
Iter: 1348 loss: 0.000184689823
Iter: 1349 loss: 0.000184408927
Iter: 1350 loss: 0.000185768629
Iter: 1351 loss: 0.000184358185
Iter: 1352 loss: 0.000184097051
Iter: 1353 loss: 0.00018423381
Iter: 1354 loss: 0.00018392413
Iter: 1355 loss: 0.000183578959
Iter: 1356 loss: 0.000186029705
Iter: 1357 loss: 0.000183548487
Iter: 1358 loss: 0.000183307173
Iter: 1359 loss: 0.000183080439
Iter: 1360 loss: 0.0001830244
Iter: 1361 loss: 0.000182733405
Iter: 1362 loss: 0.000185267985
Iter: 1363 loss: 0.000182718475
Iter: 1364 loss: 0.000182386662
Iter: 1365 loss: 0.000182383053
Iter: 1366 loss: 0.00018211978
Iter: 1367 loss: 0.000181737632
Iter: 1368 loss: 0.000181945099
Iter: 1369 loss: 0.000181485768
Iter: 1370 loss: 0.000181147741
Iter: 1371 loss: 0.000181212032
Iter: 1372 loss: 0.000180895149
Iter: 1373 loss: 0.000181460025
Iter: 1374 loss: 0.000180800271
Iter: 1375 loss: 0.000180698873
Iter: 1376 loss: 0.0001804489
Iter: 1377 loss: 0.00018289435
Iter: 1378 loss: 0.000180415736
Iter: 1379 loss: 0.000180120376
Iter: 1380 loss: 0.00018035181
Iter: 1381 loss: 0.000179941184
Iter: 1382 loss: 0.00017954444
Iter: 1383 loss: 0.000180624484
Iter: 1384 loss: 0.000179413793
Iter: 1385 loss: 0.000179124618
Iter: 1386 loss: 0.000179134207
Iter: 1387 loss: 0.000178896298
Iter: 1388 loss: 0.000178640388
Iter: 1389 loss: 0.000180994422
Iter: 1390 loss: 0.000178630056
Iter: 1391 loss: 0.000178381684
Iter: 1392 loss: 0.000178487622
Iter: 1393 loss: 0.000178210961
Iter: 1394 loss: 0.00017799405
Iter: 1395 loss: 0.00017819379
Iter: 1396 loss: 0.00017786806
Iter: 1397 loss: 0.000177645881
Iter: 1398 loss: 0.000177552225
Iter: 1399 loss: 0.000177437149
Iter: 1400 loss: 0.000177227412
Iter: 1401 loss: 0.000177227601
Iter: 1402 loss: 0.000177066686
Iter: 1403 loss: 0.0001768824
Iter: 1404 loss: 0.000176859874
Iter: 1405 loss: 0.000176771428
Iter: 1406 loss: 0.000176718022
Iter: 1407 loss: 0.000176556554
Iter: 1408 loss: 0.000176757472
Iter: 1409 loss: 0.000176473346
Iter: 1410 loss: 0.000176344503
Iter: 1411 loss: 0.000176060872
Iter: 1412 loss: 0.00018026933
Iter: 1413 loss: 0.000176048386
Iter: 1414 loss: 0.000175738882
Iter: 1415 loss: 0.000176644535
Iter: 1416 loss: 0.000175644047
Iter: 1417 loss: 0.000175433059
Iter: 1418 loss: 0.000178426242
Iter: 1419 loss: 0.000175433015
Iter: 1420 loss: 0.000175284542
Iter: 1421 loss: 0.000174955901
Iter: 1422 loss: 0.000179689596
Iter: 1423 loss: 0.000174939603
Iter: 1424 loss: 0.000174726418
Iter: 1425 loss: 0.000174718036
Iter: 1426 loss: 0.000174513567
Iter: 1427 loss: 0.000174698638
Iter: 1428 loss: 0.000174393863
Iter: 1429 loss: 0.000174175759
Iter: 1430 loss: 0.000175294583
Iter: 1431 loss: 0.000174140121
Iter: 1432 loss: 0.000174008484
Iter: 1433 loss: 0.000175992143
Iter: 1434 loss: 0.000174008339
Iter: 1435 loss: 0.000173897555
Iter: 1436 loss: 0.000173824839
Iter: 1437 loss: 0.000173782435
Iter: 1438 loss: 0.000173575783
Iter: 1439 loss: 0.000173666558
Iter: 1440 loss: 0.000173433989
Iter: 1441 loss: 0.000173397391
Iter: 1442 loss: 0.000173348992
Iter: 1443 loss: 0.000173242355
Iter: 1444 loss: 0.000173030799
Iter: 1445 loss: 0.000177191949
Iter: 1446 loss: 0.0001730285
Iter: 1447 loss: 0.000172858068
Iter: 1448 loss: 0.00017283429
Iter: 1449 loss: 0.000172713975
Iter: 1450 loss: 0.000172511427
Iter: 1451 loss: 0.000172769127
Iter: 1452 loss: 0.000172407425
Iter: 1453 loss: 0.000172152737
Iter: 1454 loss: 0.000172892876
Iter: 1455 loss: 0.000172073313
Iter: 1456 loss: 0.000171794061
Iter: 1457 loss: 0.000173099092
Iter: 1458 loss: 0.000171742315
Iter: 1459 loss: 0.000171504973
Iter: 1460 loss: 0.000171376101
Iter: 1461 loss: 0.000171268737
Iter: 1462 loss: 0.00017099196
Iter: 1463 loss: 0.000172470187
Iter: 1464 loss: 0.000170949977
Iter: 1465 loss: 0.000170755884
Iter: 1466 loss: 0.000172942295
Iter: 1467 loss: 0.000170752435
Iter: 1468 loss: 0.000170539395
Iter: 1469 loss: 0.000170889034
Iter: 1470 loss: 0.000170441373
Iter: 1471 loss: 0.00017022129
Iter: 1472 loss: 0.000171322987
Iter: 1473 loss: 0.000170184008
Iter: 1474 loss: 0.000170069252
Iter: 1475 loss: 0.000170656625
Iter: 1476 loss: 0.000170050713
Iter: 1477 loss: 0.000169914216
Iter: 1478 loss: 0.0001706326
Iter: 1479 loss: 0.000169893261
Iter: 1480 loss: 0.00016983501
Iter: 1481 loss: 0.000169665902
Iter: 1482 loss: 0.000170411266
Iter: 1483 loss: 0.000169602645
Iter: 1484 loss: 0.000169371953
Iter: 1485 loss: 0.000170136351
Iter: 1486 loss: 0.000169309264
Iter: 1487 loss: 0.000169080406
Iter: 1488 loss: 0.000169271545
Iter: 1489 loss: 0.000168944563
Iter: 1490 loss: 0.000168746716
Iter: 1491 loss: 0.000171612395
Iter: 1492 loss: 0.00016874609
Iter: 1493 loss: 0.00016858388
Iter: 1494 loss: 0.00016842199
Iter: 1495 loss: 0.000168388535
Iter: 1496 loss: 0.000168133469
Iter: 1497 loss: 0.000168864921
Iter: 1498 loss: 0.000168052749
Iter: 1499 loss: 0.000167825143
Iter: 1500 loss: 0.000168962011
Iter: 1501 loss: 0.000167786726
Iter: 1502 loss: 0.000167601567
Iter: 1503 loss: 0.000169700725
Iter: 1504 loss: 0.000167599312
Iter: 1505 loss: 0.00016746606
Iter: 1506 loss: 0.000168641564
Iter: 1507 loss: 0.000167458522
Iter: 1508 loss: 0.000167393882
Iter: 1509 loss: 0.000167330101
Iter: 1510 loss: 0.000167316568
Iter: 1511 loss: 0.000167193561
Iter: 1512 loss: 0.000168481231
Iter: 1513 loss: 0.000167190068
Iter: 1514 loss: 0.000167122969
Iter: 1515 loss: 0.000167030666
Iter: 1516 loss: 0.00016702697
Iter: 1517 loss: 0.000166910613
Iter: 1518 loss: 0.000167006132
Iter: 1519 loss: 0.000166841244
Iter: 1520 loss: 0.000166699989
Iter: 1521 loss: 0.000166575395
Iter: 1522 loss: 0.000166537764
Iter: 1523 loss: 0.000166315047
Iter: 1524 loss: 0.000168125247
Iter: 1525 loss: 0.000166300844
Iter: 1526 loss: 0.000166125275
Iter: 1527 loss: 0.00016614428
Iter: 1528 loss: 0.000165991121
Iter: 1529 loss: 0.000165803664
Iter: 1530 loss: 0.000166836515
Iter: 1531 loss: 0.000165776495
Iter: 1532 loss: 0.000165594334
Iter: 1533 loss: 0.000166147016
Iter: 1534 loss: 0.000165539313
Iter: 1535 loss: 0.000165376696
Iter: 1536 loss: 0.000166032551
Iter: 1537 loss: 0.000165339792
Iter: 1538 loss: 0.000165280508
Iter: 1539 loss: 0.000165263671
Iter: 1540 loss: 0.000165208301
Iter: 1541 loss: 0.000165392805
Iter: 1542 loss: 0.000165192527
Iter: 1543 loss: 0.000165139849
Iter: 1544 loss: 0.000165341058
Iter: 1545 loss: 0.00016512716
Iter: 1546 loss: 0.000165072241
Iter: 1547 loss: 0.00016497742
Iter: 1548 loss: 0.000164976911
Iter: 1549 loss: 0.000164862606
Iter: 1550 loss: 0.000165120364
Iter: 1551 loss: 0.000164818601
Iter: 1552 loss: 0.000164706827
Iter: 1553 loss: 0.000164746103
Iter: 1554 loss: 0.000164628247
Iter: 1555 loss: 0.00016447746
Iter: 1556 loss: 0.000164887184
Iter: 1557 loss: 0.000164427722
Iter: 1558 loss: 0.000164265599
Iter: 1559 loss: 0.000164402765
Iter: 1560 loss: 0.000164168945
Iter: 1561 loss: 0.000164016179
Iter: 1562 loss: 0.000164635654
Iter: 1563 loss: 0.000163982229
Iter: 1564 loss: 0.000163800752
Iter: 1565 loss: 0.000164313475
Iter: 1566 loss: 0.000163743651
Iter: 1567 loss: 0.000163597142
Iter: 1568 loss: 0.000164074736
Iter: 1569 loss: 0.000163556106
Iter: 1570 loss: 0.000163464909
Iter: 1571 loss: 0.000163464807
Iter: 1572 loss: 0.000163381221
Iter: 1573 loss: 0.00016385151
Iter: 1574 loss: 0.000163370263
Iter: 1575 loss: 0.00016330264
Iter: 1576 loss: 0.000163469187
Iter: 1577 loss: 0.000163278193
Iter: 1578 loss: 0.000163203047
Iter: 1579 loss: 0.000163195713
Iter: 1580 loss: 0.000163140852
Iter: 1581 loss: 0.000163061559
Iter: 1582 loss: 0.000163134449
Iter: 1583 loss: 0.000163015589
Iter: 1584 loss: 0.00016292301
Iter: 1585 loss: 0.000162905693
Iter: 1586 loss: 0.00016284312
Iter: 1587 loss: 0.000162697936
Iter: 1588 loss: 0.000163284247
Iter: 1589 loss: 0.000162665849
Iter: 1590 loss: 0.000162530501
Iter: 1591 loss: 0.00016267944
Iter: 1592 loss: 0.000162457349
Iter: 1593 loss: 0.000162331737
Iter: 1594 loss: 0.000162810538
Iter: 1595 loss: 0.00016230176
Iter: 1596 loss: 0.000162168712
Iter: 1597 loss: 0.000162426644
Iter: 1598 loss: 0.0001621134
Iter: 1599 loss: 0.000161996606
Iter: 1600 loss: 0.000162075812
Iter: 1601 loss: 0.000161924167
Iter: 1602 loss: 0.000161804666
Iter: 1603 loss: 0.000163652818
Iter: 1604 loss: 0.000161804477
Iter: 1605 loss: 0.000161734177
Iter: 1606 loss: 0.000161733115
Iter: 1607 loss: 0.000161687014
Iter: 1608 loss: 0.000161787058
Iter: 1609 loss: 0.00016166878
Iter: 1610 loss: 0.000161618431
Iter: 1611 loss: 0.000161598757
Iter: 1612 loss: 0.000161571661
Iter: 1613 loss: 0.0001615082
Iter: 1614 loss: 0.0001614801
Iter: 1615 loss: 0.000161447402
Iter: 1616 loss: 0.000161342556
Iter: 1617 loss: 0.000161497373
Iter: 1618 loss: 0.000161292104
Iter: 1619 loss: 0.000161184798
Iter: 1620 loss: 0.000161460484
Iter: 1621 loss: 0.00016114836
Iter: 1622 loss: 0.000161036558
Iter: 1623 loss: 0.000161330187
Iter: 1624 loss: 0.000160999058
Iter: 1625 loss: 0.000160895928
Iter: 1626 loss: 0.000161121701
Iter: 1627 loss: 0.000160856434
Iter: 1628 loss: 0.000160739495
Iter: 1629 loss: 0.000160939875
Iter: 1630 loss: 0.000160686832
Iter: 1631 loss: 0.00016057225
Iter: 1632 loss: 0.000160740368
Iter: 1633 loss: 0.000160517375
Iter: 1634 loss: 0.000160379161
Iter: 1635 loss: 0.000161066069
Iter: 1636 loss: 0.000160355
Iter: 1637 loss: 0.000160246709
Iter: 1638 loss: 0.000160478361
Iter: 1639 loss: 0.000160204698
Iter: 1640 loss: 0.00016028469
Iter: 1641 loss: 0.00016016388
Iter: 1642 loss: 0.000160133728
Iter: 1643 loss: 0.000160076626
Iter: 1644 loss: 0.000161293807
Iter: 1645 loss: 0.000160076903
Iter: 1646 loss: 0.000160013267
Iter: 1647 loss: 0.000159967036
Iter: 1648 loss: 0.000159946212
Iter: 1649 loss: 0.000159852701
Iter: 1650 loss: 0.000160124036
Iter: 1651 loss: 0.000159823277
Iter: 1652 loss: 0.000159734889
Iter: 1653 loss: 0.000159862233
Iter: 1654 loss: 0.000159691335
Iter: 1655 loss: 0.000159590229
Iter: 1656 loss: 0.000159816918
Iter: 1657 loss: 0.000159552219
Iter: 1658 loss: 0.000159448377
Iter: 1659 loss: 0.000159558898
Iter: 1660 loss: 0.000159391391
Iter: 1661 loss: 0.000159273419
Iter: 1662 loss: 0.000159889256
Iter: 1663 loss: 0.000159254792
Iter: 1664 loss: 0.000159155286
Iter: 1665 loss: 0.000159261297
Iter: 1666 loss: 0.000159100833
Iter: 1667 loss: 0.000158991941
Iter: 1668 loss: 0.000159905379
Iter: 1669 loss: 0.000158985815
Iter: 1670 loss: 0.000158902054
Iter: 1671 loss: 0.000158880677
Iter: 1672 loss: 0.000158828028
Iter: 1673 loss: 0.000158872703
Iter: 1674 loss: 0.000158789713
Iter: 1675 loss: 0.000158750947
Iter: 1676 loss: 0.000158709037
Iter: 1677 loss: 0.000158702605
Iter: 1678 loss: 0.000158653289
Iter: 1679 loss: 0.000158594834
Iter: 1680 loss: 0.000158588227
Iter: 1681 loss: 0.000158501934
Iter: 1682 loss: 0.000158638024
Iter: 1683 loss: 0.000158461058
Iter: 1684 loss: 0.000158363226
Iter: 1685 loss: 0.000158422947
Iter: 1686 loss: 0.000158300187
Iter: 1687 loss: 0.000158174167
Iter: 1688 loss: 0.000158894109
Iter: 1689 loss: 0.000158157098
Iter: 1690 loss: 0.00015805944
Iter: 1691 loss: 0.000158115625
Iter: 1692 loss: 0.000157995382
Iter: 1693 loss: 0.000157881877
Iter: 1694 loss: 0.000158099021
Iter: 1695 loss: 0.000157834118
Iter: 1696 loss: 0.000157713512
Iter: 1697 loss: 0.00015840464
Iter: 1698 loss: 0.000157697592
Iter: 1699 loss: 0.000157607894
Iter: 1700 loss: 0.000157962437
Iter: 1701 loss: 0.000157587667
Iter: 1702 loss: 0.000157497387
Iter: 1703 loss: 0.00015761127
Iter: 1704 loss: 0.000157451301
Iter: 1705 loss: 0.000157388058
Iter: 1706 loss: 0.00015738669
Iter: 1707 loss: 0.00015731233
Iter: 1708 loss: 0.000157553251
Iter: 1709 loss: 0.000157291463
Iter: 1710 loss: 0.000157253075
Iter: 1711 loss: 0.000157173286
Iter: 1712 loss: 0.000158528885
Iter: 1713 loss: 0.000157171424
Iter: 1714 loss: 0.000157070783
Iter: 1715 loss: 0.000157234274
Iter: 1716 loss: 0.000157025235
Iter: 1717 loss: 0.000156922208
Iter: 1718 loss: 0.000157057162
Iter: 1719 loss: 0.000156869792
Iter: 1720 loss: 0.000156740251
Iter: 1721 loss: 0.00015711975
Iter: 1722 loss: 0.000156700553
Iter: 1723 loss: 0.000156585782
Iter: 1724 loss: 0.000157005445
Iter: 1725 loss: 0.000156556809
Iter: 1726 loss: 0.000156447437
Iter: 1727 loss: 0.000156521448
Iter: 1728 loss: 0.000156379261
Iter: 1729 loss: 0.000156250462
Iter: 1730 loss: 0.000156515234
Iter: 1731 loss: 0.000156198963
Iter: 1732 loss: 0.000156075926
Iter: 1733 loss: 0.000157200469
Iter: 1734 loss: 0.00015607044
Iter: 1735 loss: 0.000155978079
Iter: 1736 loss: 0.00015607469
Iter: 1737 loss: 0.000155927133
Iter: 1738 loss: 0.000155853631
Iter: 1739 loss: 0.00015585302
Iter: 1740 loss: 0.000155786896
Iter: 1741 loss: 0.000156372058
Iter: 1742 loss: 0.000155783564
Iter: 1743 loss: 0.000155752219
Iter: 1744 loss: 0.000155669055
Iter: 1745 loss: 0.000156308946
Iter: 1746 loss: 0.000155652815
Iter: 1747 loss: 0.000155564849
Iter: 1748 loss: 0.000156087888
Iter: 1749 loss: 0.000155553309
Iter: 1750 loss: 0.000155482936
Iter: 1751 loss: 0.000155438785
Iter: 1752 loss: 0.000155410293
Iter: 1753 loss: 0.000155303846
Iter: 1754 loss: 0.000156007329
Iter: 1755 loss: 0.000155292495
Iter: 1756 loss: 0.000155204121
Iter: 1757 loss: 0.000155337155
Iter: 1758 loss: 0.000155161455
Iter: 1759 loss: 0.000155056128
Iter: 1760 loss: 0.00015522234
Iter: 1761 loss: 0.000155006943
Iter: 1762 loss: 0.000154884518
Iter: 1763 loss: 0.000155027054
Iter: 1764 loss: 0.000154819078
Iter: 1765 loss: 0.000154681184
Iter: 1766 loss: 0.000155375019
Iter: 1767 loss: 0.000154657871
Iter: 1768 loss: 0.000154533947
Iter: 1769 loss: 0.000155049827
Iter: 1770 loss: 0.000154507085
Iter: 1771 loss: 0.000154412919
Iter: 1772 loss: 0.000154992216
Iter: 1773 loss: 0.000154401307
Iter: 1774 loss: 0.000154327179
Iter: 1775 loss: 0.000154326437
Iter: 1776 loss: 0.000154289519
Iter: 1777 loss: 0.000154184949
Iter: 1778 loss: 0.000154653739
Iter: 1779 loss: 0.000154146415
Iter: 1780 loss: 0.000154001114
Iter: 1781 loss: 0.000154290872
Iter: 1782 loss: 0.000153941917
Iter: 1783 loss: 0.000153783651
Iter: 1784 loss: 0.000154151814
Iter: 1785 loss: 0.000153725516
Iter: 1786 loss: 0.000153565983
Iter: 1787 loss: 0.000153605113
Iter: 1788 loss: 0.000153449393
Iter: 1789 loss: 0.000153240922
Iter: 1790 loss: 0.00015468616
Iter: 1791 loss: 0.000153220826
Iter: 1792 loss: 0.000153045883
Iter: 1793 loss: 0.0001531179
Iter: 1794 loss: 0.000152925233
Iter: 1795 loss: 0.000152740817
Iter: 1796 loss: 0.000153310946
Iter: 1797 loss: 0.000152686189
Iter: 1798 loss: 0.000152475841
Iter: 1799 loss: 0.000152949011
Iter: 1800 loss: 0.000152395776
Iter: 1801 loss: 0.00015221347
Iter: 1802 loss: 0.000153193032
Iter: 1803 loss: 0.000152185836
Iter: 1804 loss: 0.000152021079
Iter: 1805 loss: 0.000152615641
Iter: 1806 loss: 0.000151979038
Iter: 1807 loss: 0.000152001681
Iter: 1808 loss: 0.000151912027
Iter: 1809 loss: 0.000151874847
Iter: 1810 loss: 0.000151760949
Iter: 1811 loss: 0.000152017979
Iter: 1812 loss: 0.000151693326
Iter: 1813 loss: 0.000151527958
Iter: 1814 loss: 0.000152421184
Iter: 1815 loss: 0.000151502813
Iter: 1816 loss: 0.000151378394
Iter: 1817 loss: 0.000151633154
Iter: 1818 loss: 0.000151328088
Iter: 1819 loss: 0.000151177184
Iter: 1820 loss: 0.000151166401
Iter: 1821 loss: 0.000151053187
Iter: 1822 loss: 0.000150883701
Iter: 1823 loss: 0.000152293534
Iter: 1824 loss: 0.000150873122
Iter: 1825 loss: 0.000150710825
Iter: 1826 loss: 0.000150823529
Iter: 1827 loss: 0.000150609616
Iter: 1828 loss: 0.000150446402
Iter: 1829 loss: 0.000150613399
Iter: 1830 loss: 0.000150356194
Iter: 1831 loss: 0.000150161912
Iter: 1832 loss: 0.000151307235
Iter: 1833 loss: 0.000150136868
Iter: 1834 loss: 0.000149970918
Iter: 1835 loss: 0.000150285152
Iter: 1836 loss: 0.000149900763
Iter: 1837 loss: 0.000149730913
Iter: 1838 loss: 0.000150707987
Iter: 1839 loss: 0.000149707674
Iter: 1840 loss: 0.000149754109
Iter: 1841 loss: 0.00014965079
Iter: 1842 loss: 0.000149604894
Iter: 1843 loss: 0.000149462983
Iter: 1844 loss: 0.000149744941
Iter: 1845 loss: 0.000149373984
Iter: 1846 loss: 0.000149213185
Iter: 1847 loss: 0.000150074979
Iter: 1848 loss: 0.000149189611
Iter: 1849 loss: 0.000149046857
Iter: 1850 loss: 0.000149209256
Iter: 1851 loss: 0.000148969237
Iter: 1852 loss: 0.000148778112
Iter: 1853 loss: 0.000148957566
Iter: 1854 loss: 0.000148669147
Iter: 1855 loss: 0.000148455278
Iter: 1856 loss: 0.000149244646
Iter: 1857 loss: 0.000148403022
Iter: 1858 loss: 0.000148204548
Iter: 1859 loss: 0.000149143452
Iter: 1860 loss: 0.000148168241
Iter: 1861 loss: 0.000147990082
Iter: 1862 loss: 0.000148012012
Iter: 1863 loss: 0.000147853076
Iter: 1864 loss: 0.000147613173
Iter: 1865 loss: 0.000148104271
Iter: 1866 loss: 0.000147516053
Iter: 1867 loss: 0.000147324652
Iter: 1868 loss: 0.00014935268
Iter: 1869 loss: 0.000147319981
Iter: 1870 loss: 0.000147153405
Iter: 1871 loss: 0.000147181578
Iter: 1872 loss: 0.000147028506
Iter: 1873 loss: 0.000147142506
Iter: 1874 loss: 0.000146953709
Iter: 1875 loss: 0.000146882638
Iter: 1876 loss: 0.000146738908
Iter: 1877 loss: 0.000149404048
Iter: 1878 loss: 0.000146736478
Iter: 1879 loss: 0.000146624428
Iter: 1880 loss: 0.00014649739
Iter: 1881 loss: 0.000146481121
Iter: 1882 loss: 0.000146283011
Iter: 1883 loss: 0.000147510596
Iter: 1884 loss: 0.000146259757
Iter: 1885 loss: 0.000146065024
Iter: 1886 loss: 0.000145977509
Iter: 1887 loss: 0.000145879589
Iter: 1888 loss: 0.000145637605
Iter: 1889 loss: 0.000146820414
Iter: 1890 loss: 0.000145595302
Iter: 1891 loss: 0.000145393613
Iter: 1892 loss: 0.000145922779
Iter: 1893 loss: 0.000145325612
Iter: 1894 loss: 0.000145146594
Iter: 1895 loss: 0.000145875048
Iter: 1896 loss: 0.000145107493
Iter: 1897 loss: 0.000144923746
Iter: 1898 loss: 0.000144886522
Iter: 1899 loss: 0.000144764577
Iter: 1900 loss: 0.000144542908
Iter: 1901 loss: 0.000145157348
Iter: 1902 loss: 0.000144471414
Iter: 1903 loss: 0.000144234597
Iter: 1904 loss: 0.000145226499
Iter: 1905 loss: 0.00014418349
Iter: 1906 loss: 0.000144013233
Iter: 1907 loss: 0.000144392427
Iter: 1908 loss: 0.000143948884
Iter: 1909 loss: 0.00014363548
Iter: 1910 loss: 0.000144507387
Iter: 1911 loss: 0.000143533733
Iter: 1912 loss: 0.000143422629
Iter: 1913 loss: 0.000143252
Iter: 1914 loss: 0.000143249359
Iter: 1915 loss: 0.000143096637
Iter: 1916 loss: 0.000143224839
Iter: 1917 loss: 0.000143006473
Iter: 1918 loss: 0.000142782432
Iter: 1919 loss: 0.000143752055
Iter: 1920 loss: 0.00014273703
Iter: 1921 loss: 0.000142561461
Iter: 1922 loss: 0.000142639794
Iter: 1923 loss: 0.000142441888
Iter: 1924 loss: 0.000142219244
Iter: 1925 loss: 0.000143332349
Iter: 1926 loss: 0.000142181671
Iter: 1927 loss: 0.00014201233
Iter: 1928 loss: 0.00014274806
Iter: 1929 loss: 0.000141977929
Iter: 1930 loss: 0.000141809462
Iter: 1931 loss: 0.000142104749
Iter: 1932 loss: 0.00014173481
Iter: 1933 loss: 0.00014155492
Iter: 1934 loss: 0.000141834869
Iter: 1935 loss: 0.000141470227
Iter: 1936 loss: 0.000141293509
Iter: 1937 loss: 0.000142397417
Iter: 1938 loss: 0.000141272816
Iter: 1939 loss: 0.000141129553
Iter: 1940 loss: 0.00014265925
Iter: 1941 loss: 0.00014112542
Iter: 1942 loss: 0.000141032855
Iter: 1943 loss: 0.000141030629
Iter: 1944 loss: 0.000140986958
Iter: 1945 loss: 0.000140846241
Iter: 1946 loss: 0.000140968681
Iter: 1947 loss: 0.000140729768
Iter: 1948 loss: 0.000140451681
Iter: 1949 loss: 0.00014098268
Iter: 1950 loss: 0.0001403348
Iter: 1951 loss: 0.000140070086
Iter: 1952 loss: 0.000141905737
Iter: 1953 loss: 0.000140045173
Iter: 1954 loss: 0.000139814947
Iter: 1955 loss: 0.000140242846
Iter: 1956 loss: 0.000139716343
Iter: 1957 loss: 0.000139528027
Iter: 1958 loss: 0.000139803582
Iter: 1959 loss: 0.000139436597
Iter: 1960 loss: 0.000139212789
Iter: 1961 loss: 0.000140105985
Iter: 1962 loss: 0.000139161581
Iter: 1963 loss: 0.000138942705
Iter: 1964 loss: 0.000139471726
Iter: 1965 loss: 0.000138863528
Iter: 1966 loss: 0.000138666059
Iter: 1967 loss: 0.000139434356
Iter: 1968 loss: 0.000138620424
Iter: 1969 loss: 0.000138444433
Iter: 1970 loss: 0.00013851258
Iter: 1971 loss: 0.000138321688
Iter: 1972 loss: 0.000138196192
Iter: 1973 loss: 0.000138186442
Iter: 1974 loss: 0.000138117961
Iter: 1975 loss: 0.00013811182
Iter: 1976 loss: 0.000138057891
Iter: 1977 loss: 0.000137897849
Iter: 1978 loss: 0.000138409683
Iter: 1979 loss: 0.000137820374
Iter: 1980 loss: 0.000137639639
Iter: 1981 loss: 0.000138124917
Iter: 1982 loss: 0.000137579525
Iter: 1983 loss: 0.000137379684
Iter: 1984 loss: 0.000137943745
Iter: 1985 loss: 0.000137316703
Iter: 1986 loss: 0.000137153052
Iter: 1987 loss: 0.000138310075
Iter: 1988 loss: 0.000137138282
Iter: 1989 loss: 0.000137009949
Iter: 1990 loss: 0.000136862844
Iter: 1991 loss: 0.000136844508
Iter: 1992 loss: 0.000136667673
Iter: 1993 loss: 0.000138215284
Iter: 1994 loss: 0.000136658433
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/k4
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0
+ date
Tue Oct 27 20:42:05 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d52583c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d525758c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d52583bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47278f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47290268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d472b7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d472c1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d472c1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d471e76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d4720f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d471cb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d471e7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d471e79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47175f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47237840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47112ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d470a52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d470a5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47082b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d470bde18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d4703b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46fe7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d47022950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46fa6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46fcbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46f84d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46f847b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46f84510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46f4a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46f4a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46eee8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46eb6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46e680d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46e24730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46e5ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d46dfc7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00227011298
Iter: 2 loss: 0.00226112106
Iter: 3 loss: 0.00222749845
Iter: 4 loss: 0.00211602449
Iter: 5 loss: 0.00302672898
Iter: 6 loss: 0.00209472841
Iter: 7 loss: 0.00202998566
Iter: 8 loss: 0.00247491058
Iter: 9 loss: 0.00202369969
Iter: 10 loss: 0.00198253035
Iter: 11 loss: 0.00224848301
Iter: 12 loss: 0.00197813776
Iter: 13 loss: 0.00196091132
Iter: 14 loss: 0.00196035206
Iter: 15 loss: 0.0019469643
Iter: 16 loss: 0.0019367421
Iter: 17 loss: 0.00208337838
Iter: 18 loss: 0.00193672394
Iter: 19 loss: 0.00193002133
Iter: 20 loss: 0.00199649087
Iter: 21 loss: 0.00192979816
Iter: 22 loss: 0.00192693109
Iter: 23 loss: 0.00192599755
Iter: 24 loss: 0.0019243327
Iter: 25 loss: 0.0019221463
Iter: 26 loss: 0.00193698029
Iter: 27 loss: 0.00192193151
Iter: 28 loss: 0.00192124862
Iter: 29 loss: 0.00192113314
Iter: 30 loss: 0.00192065653
Iter: 31 loss: 0.00192040321
Iter: 32 loss: 0.00192018715
Iter: 33 loss: 0.00191984489
Iter: 34 loss: 0.00192229403
Iter: 35 loss: 0.00191981462
Iter: 36 loss: 0.00191966235
Iter: 37 loss: 0.00191965955
Iter: 38 loss: 0.00191958575
Iter: 39 loss: 0.00191955653
Iter: 40 loss: 0.00191951625
Iter: 41 loss: 0.00191945373
Iter: 42 loss: 0.00191972847
Iter: 43 loss: 0.00191944151
Iter: 44 loss: 0.00191941881
Iter: 45 loss: 0.00191941822
Iter: 46 loss: 0.00191940204
Iter: 47 loss: 0.00191949075
Iter: 48 loss: 0.00191939925
Iter: 49 loss: 0.00191939261
Iter: 50 loss: 0.00191939203
Iter: 51 loss: 0.00191938644
Iter: 52 loss: 0.00191938353
Iter: 53 loss: 0.00191938307
Iter: 54 loss: 0.00191938
Iter: 55 loss: 0.00191939226
Iter: 56 loss: 0.00191937911
Iter: 57 loss: 0.00191937783
Iter: 58 loss: 0.00191937969
Iter: 59 loss: 0.00191937736
Iter: 60 loss: 0.0019193762
Iter: 61 loss: 0.00191938202
Iter: 62 loss: 0.00191937608
Iter: 63 loss: 0.00191937562
Iter: 64 loss: 0.00191938179
Iter: 65 loss: 0.00191937573
Iter: 66 loss: 0.00191937597
Iter: 67 loss: 0.00191937701
Iter: 68 loss: 0.00191937585
Iter: 69 loss: 0.00191937527
Iter: 70 loss: 0.00191937538
Iter: 71 loss: 0.00191937492
Iter: 72 loss: 0.00191937503
Iter: 73 loss: 0.00191937573
Iter: 74 loss: 0.0019193748
Iter: 75 loss: 0.0019193755
Iter: 76 loss: 0.00191937538
Iter: 77 loss: 0.00191937492
Iter: 78 loss: 0.00191937445
Iter: 79 loss: 0.00191937492
Iter: 80 loss: 0.00191937503
Iter: 81 loss: 0.00191937503
Iter: 82 loss: 0.00191937515
Iter: 83 loss: 0.00191937445
Iter: 84 loss: 0.00191937492
Iter: 85 loss: 0.00191937457
Iter: 86 loss: 0.00191937492
Iter: 87 loss: 0.00191937503
Iter: 88 loss: 0.00191937503
Iter: 89 loss: 0.00191937503
Iter: 90 loss: 0.00191937503
Iter: 91 loss: 0.00191937527
Iter: 92 loss: 0.0019193748
Iter: 93 loss: 0.00191937503
Iter: 94 loss: 0.00191937538
Iter: 95 loss: 0.0019193748
Iter: 96 loss: 0.00191937503
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4
+ date
Tue Oct 27 20:42:51 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc287d62268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc287d64048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2652ea598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265308d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc26525f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc26525fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265233d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2651f3158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265206e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2651f3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265162bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265175f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265120620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2650d3bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc26510b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265099950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265099840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc26504f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc26501f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc265045158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2650458c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264ff8b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264fb46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264fc2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264f4f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264f689d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264f468c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264f46840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264eeed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264ea0ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264e50840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264e79840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264e79ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264e15378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264e15268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc264e3e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0282985084
Iter: 2 loss: 0.0271925759
Iter: 3 loss: 0.0231020432
Iter: 4 loss: 0.0098899249
Iter: 5 loss: 0.176315635
Iter: 6 loss: 0.00824925117
Iter: 7 loss: 0.003659
Iter: 8 loss: 0.00365730212
Iter: 9 loss: 0.00293462863
Iter: 10 loss: 0.00271893386
Iter: 11 loss: 0.00244490639
Iter: 12 loss: 0.00304338359
Iter: 13 loss: 0.00233945856
Iter: 14 loss: 0.00221742503
Iter: 15 loss: 0.00347099104
Iter: 16 loss: 0.00221361383
Iter: 17 loss: 0.00214839773
Iter: 18 loss: 0.00271417177
Iter: 19 loss: 0.00214501703
Iter: 20 loss: 0.00211736979
Iter: 21 loss: 0.00217728573
Iter: 22 loss: 0.00210651476
Iter: 23 loss: 0.00208758633
Iter: 24 loss: 0.00226523378
Iter: 25 loss: 0.00208681659
Iter: 26 loss: 0.00207646238
Iter: 27 loss: 0.0020917987
Iter: 28 loss: 0.00207150308
Iter: 29 loss: 0.00206566276
Iter: 30 loss: 0.00207784772
Iter: 31 loss: 0.00206332258
Iter: 32 loss: 0.0020599016
Iter: 33 loss: 0.00210352335
Iter: 34 loss: 0.00205987506
Iter: 35 loss: 0.00205755
Iter: 36 loss: 0.0020626178
Iter: 37 loss: 0.00205665617
Iter: 38 loss: 0.00205509039
Iter: 39 loss: 0.00205844454
Iter: 40 loss: 0.00205447618
Iter: 41 loss: 0.00205352483
Iter: 42 loss: 0.00205777679
Iter: 43 loss: 0.00205333647
Iter: 44 loss: 0.00205280213
Iter: 45 loss: 0.00205617258
Iter: 46 loss: 0.00205274159
Iter: 47 loss: 0.00205245847
Iter: 48 loss: 0.00205430086
Iter: 49 loss: 0.00205242774
Iter: 50 loss: 0.00205227314
Iter: 51 loss: 0.0020542061
Iter: 52 loss: 0.0020522722
Iter: 53 loss: 0.0020521821
Iter: 54 loss: 0.00205243449
Iter: 55 loss: 0.00205215346
Iter: 56 loss: 0.00205209479
Iter: 57 loss: 0.00205238629
Iter: 58 loss: 0.00205208454
Iter: 59 loss: 0.00205205055
Iter: 60 loss: 0.00205250946
Iter: 61 loss: 0.00205205055
Iter: 62 loss: 0.00205203
Iter: 63 loss: 0.00205205218
Iter: 64 loss: 0.00205201935
Iter: 65 loss: 0.00205200259
Iter: 66 loss: 0.00205211202
Iter: 67 loss: 0.00205200072
Iter: 68 loss: 0.00205199141
Iter: 69 loss: 0.00205203542
Iter: 70 loss: 0.00205198955
Iter: 71 loss: 0.00205198303
Iter: 72 loss: 0.00205201
Iter: 73 loss: 0.0020519821
Iter: 74 loss: 0.00205197744
Iter: 75 loss: 0.00205198675
Iter: 76 loss: 0.00205197628
Iter: 77 loss: 0.00205197348
Iter: 78 loss: 0.00205198675
Iter: 79 loss: 0.00205197348
Iter: 80 loss: 0.00205197232
Iter: 81 loss: 0.00205197185
Iter: 82 loss: 0.00205197092
Iter: 83 loss: 0.00205197139
Iter: 84 loss: 0.00205197046
Iter: 85 loss: 0.00205196952
Iter: 86 loss: 0.00205197232
Iter: 87 loss: 0.00205196976
Iter: 88 loss: 0.00205196906
Iter: 89 loss: 0.00205197278
Iter: 90 loss: 0.00205196906
Iter: 91 loss: 0.00205196906
Iter: 92 loss: 0.00205197022
Iter: 93 loss: 0.00205196906
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8
+ date
Tue Oct 27 20:43:39 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39e09471e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39e0930a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39e0930ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc0db950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc0dbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc104268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc05b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc07d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc00c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc01f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39bc00c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a07518c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0751378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a06fed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0735400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0735268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a06c0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a06ea950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0642840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a06c0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a066ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0617ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a05d7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a057e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a057eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a05af378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a05718c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a051d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a05211e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a04ccae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0487488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a049d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a049d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0453730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0453488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39a0435268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0211923309
Iter: 2 loss: 0.0202511065
Iter: 3 loss: 0.0168830864
Iter: 4 loss: 0.014746774
Iter: 5 loss: 0.012079047
Iter: 6 loss: 0.00713323429
Iter: 7 loss: 0.0830341876
Iter: 8 loss: 0.00681796297
Iter: 9 loss: 0.00373428036
Iter: 10 loss: 0.00370213669
Iter: 11 loss: 0.00307386043
Iter: 12 loss: 0.00672550127
Iter: 13 loss: 0.00295294495
Iter: 14 loss: 0.00272109965
Iter: 15 loss: 0.00271954224
Iter: 16 loss: 0.00257339654
Iter: 17 loss: 0.0027454698
Iter: 18 loss: 0.00249665231
Iter: 19 loss: 0.00238791504
Iter: 20 loss: 0.0027519837
Iter: 21 loss: 0.00235673832
Iter: 22 loss: 0.00229194527
Iter: 23 loss: 0.00263419747
Iter: 24 loss: 0.0022815112
Iter: 25 loss: 0.00224391976
Iter: 26 loss: 0.00247807801
Iter: 27 loss: 0.00223952136
Iter: 28 loss: 0.00221762876
Iter: 29 loss: 0.0023167748
Iter: 30 loss: 0.00221332302
Iter: 31 loss: 0.00220150733
Iter: 32 loss: 0.00225840043
Iter: 33 loss: 0.0021993909
Iter: 34 loss: 0.00219185464
Iter: 35 loss: 0.00222389074
Iter: 36 loss: 0.00219028466
Iter: 37 loss: 0.00218552724
Iter: 38 loss: 0.00221101707
Iter: 39 loss: 0.00218479685
Iter: 40 loss: 0.0021817903
Iter: 41 loss: 0.00219512149
Iter: 42 loss: 0.00218119519
Iter: 43 loss: 0.0021792273
Iter: 44 loss: 0.00219184929
Iter: 45 loss: 0.00217900658
Iter: 46 loss: 0.00217738282
Iter: 47 loss: 0.00218352722
Iter: 48 loss: 0.00217699818
Iter: 49 loss: 0.0021758643
Iter: 50 loss: 0.00217677536
Iter: 51 loss: 0.0021751821
Iter: 52 loss: 0.00217391923
Iter: 53 loss: 0.00218018121
Iter: 54 loss: 0.0021737034
Iter: 55 loss: 0.00217289571
Iter: 56 loss: 0.00218028715
Iter: 57 loss: 0.00217285985
Iter: 58 loss: 0.00217221305
Iter: 59 loss: 0.00217275694
Iter: 60 loss: 0.00217182818
Iter: 61 loss: 0.00217126543
Iter: 62 loss: 0.00217216834
Iter: 63 loss: 0.00217100536
Iter: 64 loss: 0.00217050361
Iter: 65 loss: 0.00217206823
Iter: 66 loss: 0.00217035762
Iter: 67 loss: 0.00216995133
Iter: 68 loss: 0.0021717255
Iter: 69 loss: 0.00216986821
Iter: 70 loss: 0.00216958206
Iter: 71 loss: 0.00217128894
Iter: 72 loss: 0.00216954551
Iter: 73 loss: 0.00216935878
Iter: 74 loss: 0.00217034854
Iter: 75 loss: 0.00216932967
Iter: 76 loss: 0.00216920278
Iter: 77 loss: 0.00216966774
Iter: 78 loss: 0.00216917228
Iter: 79 loss: 0.00216909219
Iter: 80 loss: 0.00217020046
Iter: 81 loss: 0.00216909219
Iter: 82 loss: 0.00216903747
Iter: 83 loss: 0.00216917717
Iter: 84 loss: 0.00216901861
Iter: 85 loss: 0.00216897367
Iter: 86 loss: 0.00216904515
Iter: 87 loss: 0.00216895342
Iter: 88 loss: 0.00216892082
Iter: 89 loss: 0.00216906494
Iter: 90 loss: 0.00216891477
Iter: 91 loss: 0.00216889591
Iter: 92 loss: 0.00216917577
Iter: 93 loss: 0.00216889568
Iter: 94 loss: 0.00216888287
Iter: 95 loss: 0.00216889451
Iter: 96 loss: 0.00216887565
Iter: 97 loss: 0.00216886448
Iter: 98 loss: 0.00216889428
Iter: 99 loss: 0.00216886052
Iter: 100 loss: 0.00216885237
Iter: 101 loss: 0.00216887658
Iter: 102 loss: 0.00216884911
Iter: 103 loss: 0.00216884329
Iter: 104 loss: 0.00216887449
Iter: 105 loss: 0.00216884236
Iter: 106 loss: 0.00216883887
Iter: 107 loss: 0.00216885516
Iter: 108 loss: 0.00216883793
Iter: 109 loss: 0.00216883514
Iter: 110 loss: 0.00216884958
Iter: 111 loss: 0.00216883444
Iter: 112 loss: 0.00216883258
Iter: 113 loss: 0.00216884189
Iter: 114 loss: 0.00216883258
Iter: 115 loss: 0.00216883118
Iter: 116 loss: 0.00216884026
Iter: 117 loss: 0.00216883142
Iter: 118 loss: 0.00216883095
Iter: 119 loss: 0.00216883677
Iter: 120 loss: 0.00216883048
Iter: 121 loss: 0.00216883048
Iter: 122 loss: 0.00216882979
Iter: 123 loss: 0.00216882955
Iter: 124 loss: 0.00216882932
Iter: 125 loss: 0.00216883235
Iter: 126 loss: 0.00216882979
Iter: 127 loss: 0.00216882909
Iter: 128 loss: 0.00216883165
Iter: 129 loss: 0.00216882909
Iter: 130 loss: 0.00216882932
Iter: 131 loss: 0.00216882955
Iter: 132 loss: 0.00216882909
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2
+ date
Tue Oct 27 20:44:36 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd1e0c0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd1e0d7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd1e0d7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf86f4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf86f4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf871c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf86698c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf869d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8626268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8626b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf864f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf85b36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf85b32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8564950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf85982f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8547400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf85b3840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf84ea400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8516ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf84b3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf85162f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8482ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf843e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf83ea598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf83eaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf84196a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf83d8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8381488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8396268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf832bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf82e9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf82e9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf830f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf82bb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8275950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf8296268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0228397809
Iter: 2 loss: 0.0203363113
Iter: 3 loss: 0.013659386
Iter: 4 loss: 4835.22656
Iter: 5 loss: 0.0807638913
Iter: 6 loss: 0.02149776
Iter: 7 loss: 0.0370483883
Iter: 8 loss: 0.0132827265
Iter: 9 loss: 0.0132755022
Iter: 10 loss: 0.0102006122
Iter: 11 loss: 0.0116155893
Iter: 12 loss: 0.00770988734
Iter: 13 loss: 0.00492152199
Iter: 14 loss: 0.00491420226
Iter: 15 loss: 0.00389455725
Iter: 16 loss: 0.0146988109
Iter: 17 loss: 0.00383342849
Iter: 18 loss: 0.00331728486
Iter: 19 loss: 0.0166578218
Iter: 20 loss: 0.0033167568
Iter: 21 loss: 0.00309031364
Iter: 22 loss: 0.00360629847
Iter: 23 loss: 0.00300856587
Iter: 24 loss: 0.00282636075
Iter: 25 loss: 0.00501195155
Iter: 26 loss: 0.00281954231
Iter: 27 loss: 0.00272648456
Iter: 28 loss: 0.00293783285
Iter: 29 loss: 0.00269255438
Iter: 30 loss: 0.00261433586
Iter: 31 loss: 0.0027827383
Iter: 32 loss: 0.00258217566
Iter: 33 loss: 0.00250609545
Iter: 34 loss: 0.00274113426
Iter: 35 loss: 0.0024834706
Iter: 36 loss: 0.00242782524
Iter: 37 loss: 0.00274152355
Iter: 38 loss: 0.00241949363
Iter: 39 loss: 0.00238406681
Iter: 40 loss: 0.00246197148
Iter: 41 loss: 0.00237014634
Iter: 42 loss: 0.0023391631
Iter: 43 loss: 0.00246420223
Iter: 44 loss: 0.00233225804
Iter: 45 loss: 0.00231302017
Iter: 46 loss: 0.00241856277
Iter: 47 loss: 0.00231016334
Iter: 48 loss: 0.00229620608
Iter: 49 loss: 0.00235925079
Iter: 50 loss: 0.00229345215
Iter: 51 loss: 0.00228579273
Iter: 52 loss: 0.00234021293
Iter: 53 loss: 0.00228507537
Iter: 54 loss: 0.00228051795
Iter: 55 loss: 0.00231663
Iter: 56 loss: 0.00228021364
Iter: 57 loss: 0.00227695378
Iter: 58 loss: 0.00229682727
Iter: 59 loss: 0.00227654306
Iter: 60 loss: 0.00227421499
Iter: 61 loss: 0.00228072749
Iter: 62 loss: 0.00227347831
Iter: 63 loss: 0.002271445
Iter: 64 loss: 0.00227581151
Iter: 65 loss: 0.00227064965
Iter: 66 loss: 0.00226871041
Iter: 67 loss: 0.00227117958
Iter: 68 loss: 0.00226771389
Iter: 69 loss: 0.00226596277
Iter: 70 loss: 0.00226915418
Iter: 71 loss: 0.00226520887
Iter: 72 loss: 0.00226339465
Iter: 73 loss: 0.00226813019
Iter: 74 loss: 0.00226277765
Iter: 75 loss: 0.00226109871
Iter: 76 loss: 0.00226918096
Iter: 77 loss: 0.00226079905
Iter: 78 loss: 0.00225949474
Iter: 79 loss: 0.00226316554
Iter: 80 loss: 0.0022590789
Iter: 81 loss: 0.00225793314
Iter: 82 loss: 0.00226180232
Iter: 83 loss: 0.00225762301
Iter: 84 loss: 0.00225655781
Iter: 85 loss: 0.00225810427
Iter: 86 loss: 0.00225604
Iter: 87 loss: 0.00225504767
Iter: 88 loss: 0.00226060324
Iter: 89 loss: 0.00225490704
Iter: 90 loss: 0.00225409679
Iter: 91 loss: 0.00225753547
Iter: 92 loss: 0.00225392822
Iter: 93 loss: 0.00225329655
Iter: 94 loss: 0.00225869613
Iter: 95 loss: 0.00225326046
Iter: 96 loss: 0.00225273357
Iter: 97 loss: 0.00225562928
Iter: 98 loss: 0.0022526586
Iter: 99 loss: 0.0022523154
Iter: 100 loss: 0.00225219829
Iter: 101 loss: 0.00225200178
Iter: 102 loss: 0.00225151377
Iter: 103 loss: 0.00225451519
Iter: 104 loss: 0.00225145603
Iter: 105 loss: 0.00225110026
Iter: 106 loss: 0.00225105626
Iter: 107 loss: 0.00225080224
Iter: 108 loss: 0.00225038407
Iter: 109 loss: 0.00225180108
Iter: 110 loss: 0.00225027138
Iter: 111 loss: 0.00224989769
Iter: 112 loss: 0.00225079944
Iter: 113 loss: 0.00224976102
Iter: 114 loss: 0.00224945531
Iter: 115 loss: 0.00225090655
Iter: 116 loss: 0.00224939967
Iter: 117 loss: 0.00224916358
Iter: 118 loss: 0.00225025904
Iter: 119 loss: 0.0022491198
Iter: 120 loss: 0.00224894169
Iter: 121 loss: 0.00224950281
Iter: 122 loss: 0.00224889023
Iter: 123 loss: 0.00224874169
Iter: 124 loss: 0.00224912632
Iter: 125 loss: 0.00224869163
Iter: 126 loss: 0.00224856986
Iter: 127 loss: 0.00224918663
Iter: 128 loss: 0.00224854983
Iter: 129 loss: 0.00224846462
Iter: 130 loss: 0.00224874634
Iter: 131 loss: 0.00224844087
Iter: 132 loss: 0.00224839593
Iter: 133 loss: 0.00224838965
Iter: 134 loss: 0.00224835705
Iter: 135 loss: 0.00224834029
Iter: 136 loss: 0.00224832469
Iter: 137 loss: 0.00224828557
Iter: 138 loss: 0.00224837847
Iter: 139 loss: 0.00224827067
Iter: 140 loss: 0.00224823575
Iter: 141 loss: 0.00224847859
Iter: 142 loss: 0.00224823132
Iter: 143 loss: 0.00224820664
Iter: 144 loss: 0.00224824948
Iter: 145 loss: 0.002248195
Iter: 146 loss: 0.00224817218
Iter: 147 loss: 0.00224821083
Iter: 148 loss: 0.00224816147
Iter: 149 loss: 0.00224813959
Iter: 150 loss: 0.00224819593
Iter: 151 loss: 0.00224813214
Iter: 152 loss: 0.00224811397
Iter: 153 loss: 0.00224817
Iter: 154 loss: 0.00224810932
Iter: 155 loss: 0.00224809535
Iter: 156 loss: 0.0022481631
Iter: 157 loss: 0.00224809139
Iter: 158 loss: 0.00224808278
Iter: 159 loss: 0.00224813563
Iter: 160 loss: 0.00224808115
Iter: 161 loss: 0.00224807463
Iter: 162 loss: 0.00224810885
Iter: 163 loss: 0.00224807207
Iter: 164 loss: 0.00224806741
Iter: 165 loss: 0.00224808
Iter: 166 loss: 0.00224806508
Iter: 167 loss: 0.00224806
Iter: 168 loss: 0.00224807183
Iter: 169 loss: 0.00224805903
Iter: 170 loss: 0.00224805623
Iter: 171 loss: 0.00224805577
Iter: 172 loss: 0.00224805367
Iter: 173 loss: 0.00224806555
Iter: 174 loss: 0.00224805297
Iter: 175 loss: 0.00224805204
Iter: 176 loss: 0.00224805111
Iter: 177 loss: 0.00224805018
Iter: 178 loss: 0.00224804855
Iter: 179 loss: 0.00224805414
Iter: 180 loss: 0.00224804925
Iter: 181 loss: 0.00224804785
Iter: 182 loss: 0.00224806042
Iter: 183 loss: 0.00224804692
Iter: 184 loss: 0.00224804552
Iter: 185 loss: 0.00224804692
Iter: 186 loss: 0.00224804599
Iter: 187 loss: 0.00224804459
Iter: 188 loss: 0.00224804715
Iter: 189 loss: 0.00224804436
Iter: 190 loss: 0.00224804319
Iter: 191 loss: 0.00224804413
Iter: 192 loss: 0.00224804319
Iter: 193 loss: 0.0022480425
Iter: 194 loss: 0.00224804645
Iter: 195 loss: 0.0022480418
Iter: 196 loss: 0.0022480418
Iter: 197 loss: 0.00224804319
Iter: 198 loss: 0.0022480418
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6
+ date
Tue Oct 27 20:45:49 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e80f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e812c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e812d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e76cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e6bb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e6728c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e695c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e695488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e65a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e6127b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e5d5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e5cef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e5707b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e5d5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e545b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e4fa2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e4fa620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e51e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e4e6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e48af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e499620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e45a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e415598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e415510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e3b8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e3b81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e3a6048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e3a6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e359048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e300730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e2b2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e2b2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e2d6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e2d6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e2a2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6e2a10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0322238654
Iter: 2 loss: 0.0209694728
Iter: 3 loss: 3343.15967
Iter: 4 loss: 0.0209694542
Iter: 5 loss: 0.0314718448
Iter: 6 loss: 0.0189339407
Iter: 7 loss: 0.0142838918
Iter: 8 loss: 0.0139867635
Iter: 9 loss: 0.0110776797
Iter: 10 loss: 0.0345083252
Iter: 11 loss: 0.0106423087
Iter: 12 loss: 0.00786316209
Iter: 13 loss: 0.0351064205
Iter: 14 loss: 0.00770596182
Iter: 15 loss: 0.00644904841
Iter: 16 loss: 0.0104469638
Iter: 17 loss: 0.00619763741
Iter: 18 loss: 0.0053686928
Iter: 19 loss: 0.00593331875
Iter: 20 loss: 0.00473611848
Iter: 21 loss: 0.0042555891
Iter: 22 loss: 0.0117443604
Iter: 23 loss: 0.00423501944
Iter: 24 loss: 0.00385742402
Iter: 25 loss: 0.0054892879
Iter: 26 loss: 0.00377908023
Iter: 27 loss: 0.00358880637
Iter: 28 loss: 0.00364364637
Iter: 29 loss: 0.00344944745
Iter: 30 loss: 0.00316951447
Iter: 31 loss: 0.00469649397
Iter: 32 loss: 0.0031173334
Iter: 33 loss: 0.00297869463
Iter: 34 loss: 0.00466267066
Iter: 35 loss: 0.00297697913
Iter: 36 loss: 0.00288651465
Iter: 37 loss: 0.00312719541
Iter: 38 loss: 0.00285454514
Iter: 39 loss: 0.00279403245
Iter: 40 loss: 0.00297270343
Iter: 41 loss: 0.00277558179
Iter: 42 loss: 0.00273011206
Iter: 43 loss: 0.00288477447
Iter: 44 loss: 0.00271703769
Iter: 45 loss: 0.0026765191
Iter: 46 loss: 0.00279954495
Iter: 47 loss: 0.00266394392
Iter: 48 loss: 0.00262752501
Iter: 49 loss: 0.00282675447
Iter: 50 loss: 0.00262215966
Iter: 51 loss: 0.00259754527
Iter: 52 loss: 0.00264333677
Iter: 53 loss: 0.00258714799
Iter: 54 loss: 0.00256383559
Iter: 55 loss: 0.00264914613
Iter: 56 loss: 0.0025577026
Iter: 57 loss: 0.00253799302
Iter: 58 loss: 0.00272362726
Iter: 59 loss: 0.00253728731
Iter: 60 loss: 0.00251573045
Iter: 61 loss: 0.00253559463
Iter: 62 loss: 0.002502969
Iter: 63 loss: 0.0024845982
Iter: 64 loss: 0.00249623181
Iter: 65 loss: 0.00247293292
Iter: 66 loss: 0.00245426875
Iter: 67 loss: 0.00252495334
Iter: 68 loss: 0.0024496594
Iter: 69 loss: 0.00243274611
Iter: 70 loss: 0.00250887685
Iter: 71 loss: 0.00242954423
Iter: 72 loss: 0.0024143965
Iter: 73 loss: 0.00251585129
Iter: 74 loss: 0.00241273828
Iter: 75 loss: 0.00240243599
Iter: 76 loss: 0.00244143093
Iter: 77 loss: 0.00240001595
Iter: 78 loss: 0.00239104684
Iter: 79 loss: 0.00240705349
Iter: 80 loss: 0.00238708081
Iter: 81 loss: 0.00237850426
Iter: 82 loss: 0.00240264647
Iter: 83 loss: 0.00237571867
Iter: 84 loss: 0.00236825389
Iter: 85 loss: 0.00239442522
Iter: 86 loss: 0.0023662888
Iter: 87 loss: 0.00235982263
Iter: 88 loss: 0.00237451517
Iter: 89 loss: 0.00235737674
Iter: 90 loss: 0.00235347799
Iter: 91 loss: 0.00235326518
Iter: 92 loss: 0.00235039042
Iter: 93 loss: 0.00236107572
Iter: 94 loss: 0.0023497
Iter: 95 loss: 0.00234760623
Iter: 96 loss: 0.00234682695
Iter: 97 loss: 0.00234566675
Iter: 98 loss: 0.00234314869
Iter: 99 loss: 0.00234528119
Iter: 100 loss: 0.00234165462
Iter: 101 loss: 0.00233911863
Iter: 102 loss: 0.00236300146
Iter: 103 loss: 0.00233901013
Iter: 104 loss: 0.00233733607
Iter: 105 loss: 0.00234536408
Iter: 106 loss: 0.00233704108
Iter: 107 loss: 0.0023355335
Iter: 108 loss: 0.00234143
Iter: 109 loss: 0.00233517867
Iter: 110 loss: 0.0023339754
Iter: 111 loss: 0.00233611604
Iter: 112 loss: 0.00233345083
Iter: 113 loss: 0.00233216234
Iter: 114 loss: 0.00233524735
Iter: 115 loss: 0.00233169622
Iter: 116 loss: 0.00233048922
Iter: 117 loss: 0.00233313581
Iter: 118 loss: 0.00233002263
Iter: 119 loss: 0.00232889596
Iter: 120 loss: 0.00233221776
Iter: 121 loss: 0.00232855
Iter: 122 loss: 0.00232766196
Iter: 123 loss: 0.00233479962
Iter: 124 loss: 0.00232760608
Iter: 125 loss: 0.00232691504
Iter: 126 loss: 0.00233330764
Iter: 127 loss: 0.00232688338
Iter: 128 loss: 0.00232643681
Iter: 129 loss: 0.00232623401
Iter: 130 loss: 0.0023260098
Iter: 131 loss: 0.0023253723
Iter: 132 loss: 0.00232577627
Iter: 133 loss: 0.00232496485
Iter: 134 loss: 0.00232421211
Iter: 135 loss: 0.0023262559
Iter: 136 loss: 0.00232396508
Iter: 137 loss: 0.0023233667
Iter: 138 loss: 0.00232927268
Iter: 139 loss: 0.00232334551
Iter: 140 loss: 0.00232289406
Iter: 141 loss: 0.00232425635
Iter: 142 loss: 0.00232275878
Iter: 143 loss: 0.00232228963
Iter: 144 loss: 0.00232296716
Iter: 145 loss: 0.00232206145
Iter: 146 loss: 0.00232157088
Iter: 147 loss: 0.00232284633
Iter: 148 loss: 0.00232140487
Iter: 149 loss: 0.00232094782
Iter: 150 loss: 0.00232237112
Iter: 151 loss: 0.00232081348
Iter: 152 loss: 0.00232035574
Iter: 153 loss: 0.002320525
Iter: 154 loss: 0.00232003583
Iter: 155 loss: 0.00231955294
Iter: 156 loss: 0.0023232908
Iter: 157 loss: 0.00231951708
Iter: 158 loss: 0.00231928
Iter: 159 loss: 0.00231927447
Iter: 160 loss: 0.00231905188
Iter: 161 loss: 0.00231879693
Iter: 162 loss: 0.00231876597
Iter: 163 loss: 0.00231845281
Iter: 164 loss: 0.00231938437
Iter: 165 loss: 0.00231835758
Iter: 166 loss: 0.00231807842
Iter: 167 loss: 0.00231826585
Iter: 168 loss: 0.00231790077
Iter: 169 loss: 0.00231760158
Iter: 170 loss: 0.00231928122
Iter: 171 loss: 0.00231755944
Iter: 172 loss: 0.00231728097
Iter: 173 loss: 0.00231860392
Iter: 174 loss: 0.00231723115
Iter: 175 loss: 0.00231701322
Iter: 176 loss: 0.00231780484
Iter: 177 loss: 0.00231695804
Iter: 178 loss: 0.00231676619
Iter: 179 loss: 0.00231680949
Iter: 180 loss: 0.00231662393
Iter: 181 loss: 0.00231636735
Iter: 182 loss: 0.0023174989
Iter: 183 loss: 0.00231631566
Iter: 184 loss: 0.00231609913
Iter: 185 loss: 0.00231638527
Iter: 186 loss: 0.0023159897
Iter: 187 loss: 0.00231576059
Iter: 188 loss: 0.00231658178
Iter: 189 loss: 0.00231570238
Iter: 190 loss: 0.00231552403
Iter: 191 loss: 0.00231676223
Iter: 192 loss: 0.00231550774
Iter: 193 loss: 0.00231531
Iter: 194 loss: 0.00231611356
Iter: 195 loss: 0.00231526745
Iter: 196 loss: 0.00231515407
Iter: 197 loss: 0.00231504976
Iter: 198 loss: 0.00231502252
Iter: 199 loss: 0.00231481041
Iter: 200 loss: 0.0023152004
Iter: 201 loss: 0.00231471937
Iter: 202 loss: 0.00231452053
Iter: 203 loss: 0.00231483206
Iter: 204 loss: 0.002314426
Iter: 205 loss: 0.00231425045
Iter: 206 loss: 0.00231691683
Iter: 207 loss: 0.00231425045
Iter: 208 loss: 0.00231413054
Iter: 209 loss: 0.0023142416
Iter: 210 loss: 0.00231406139
Iter: 211 loss: 0.00231389701
Iter: 212 loss: 0.00231405534
Iter: 213 loss: 0.00231380365
Iter: 214 loss: 0.00231364183
Iter: 215 loss: 0.00231439178
Iter: 216 loss: 0.00231361366
Iter: 217 loss: 0.00231346348
Iter: 218 loss: 0.00231366791
Iter: 219 loss: 0.00231338781
Iter: 220 loss: 0.00231323857
Iter: 221 loss: 0.00231368
Iter: 222 loss: 0.00231319363
Iter: 223 loss: 0.00231305463
Iter: 224 loss: 0.00231357687
Iter: 225 loss: 0.00231302064
Iter: 226 loss: 0.00231292425
Iter: 227 loss: 0.00231292192
Iter: 228 loss: 0.00231285719
Iter: 229 loss: 0.00231274078
Iter: 230 loss: 0.00231540203
Iter: 231 loss: 0.00231274
Iter: 232 loss: 0.00231262506
Iter: 233 loss: 0.00231315056
Iter: 234 loss: 0.00231260341
Iter: 235 loss: 0.00231250119
Iter: 236 loss: 0.00231263065
Iter: 237 loss: 0.00231244927
Iter: 238 loss: 0.00231235567
Iter: 239 loss: 0.00231305487
Iter: 240 loss: 0.00231234846
Iter: 241 loss: 0.00231226813
Iter: 242 loss: 0.00231259922
Iter: 243 loss: 0.00231225044
Iter: 244 loss: 0.00231217709
Iter: 245 loss: 0.00231225369
Iter: 246 loss: 0.00231213588
Iter: 247 loss: 0.00231205858
Iter: 248 loss: 0.00231226673
Iter: 249 loss: 0.00231203204
Iter: 250 loss: 0.00231196382
Iter: 251 loss: 0.00231227046
Iter: 252 loss: 0.00231195148
Iter: 253 loss: 0.0023118942
Iter: 254 loss: 0.0023119573
Iter: 255 loss: 0.00231186254
Iter: 256 loss: 0.00231179735
Iter: 257 loss: 0.00231195521
Iter: 258 loss: 0.00231177127
Iter: 259 loss: 0.00231173867
Iter: 260 loss: 0.00231173262
Iter: 261 loss: 0.00231170049
Iter: 262 loss: 0.00231169211
Iter: 263 loss: 0.00231167162
Iter: 264 loss: 0.0023116346
Iter: 265 loss: 0.00231162878
Iter: 266 loss: 0.00231160317
Iter: 267 loss: 0.00231156056
Iter: 268 loss: 0.00231181621
Iter: 269 loss: 0.00231155427
Iter: 270 loss: 0.00231151981
Iter: 271 loss: 0.00231159618
Iter: 272 loss: 0.00231150771
Iter: 273 loss: 0.0023114779
Iter: 274 loss: 0.00231177034
Iter: 275 loss: 0.00231147651
Iter: 276 loss: 0.00231145322
Iter: 277 loss: 0.00231148233
Iter: 278 loss: 0.00231144181
Iter: 279 loss: 0.0023114183
Iter: 280 loss: 0.0023114814
Iter: 281 loss: 0.00231141085
Iter: 282 loss: 0.00231139269
Iter: 283 loss: 0.00231143343
Iter: 284 loss: 0.00231138431
Iter: 285 loss: 0.00231136126
Iter: 286 loss: 0.00231143017
Iter: 287 loss: 0.00231135474
Iter: 288 loss: 0.00231133774
Iter: 289 loss: 0.00231136754
Iter: 290 loss: 0.00231132982
Iter: 291 loss: 0.00231131678
Iter: 292 loss: 0.00231131678
Iter: 293 loss: 0.00231130607
Iter: 294 loss: 0.00231134286
Iter: 295 loss: 0.00231130328
Iter: 296 loss: 0.0023112949
Iter: 297 loss: 0.00231128978
Iter: 298 loss: 0.00231128675
Iter: 299 loss: 0.00231127674
Iter: 300 loss: 0.00231129024
Iter: 301 loss: 0.00231127231
Iter: 302 loss: 0.00231126091
Iter: 303 loss: 0.00231132167
Iter: 304 loss: 0.00231125858
Iter: 305 loss: 0.00231125113
Iter: 306 loss: 0.00231129164
Iter: 307 loss: 0.00231124973
Iter: 308 loss: 0.00231124344
Iter: 309 loss: 0.00231127441
Iter: 310 loss: 0.00231124205
Iter: 311 loss: 0.00231123692
Iter: 312 loss: 0.00231124
Iter: 313 loss: 0.0023112332
Iter: 314 loss: 0.00231122761
Iter: 315 loss: 0.00231124181
Iter: 316 loss: 0.00231122528
Iter: 317 loss: 0.002311219
Iter: 318 loss: 0.00231124554
Iter: 319 loss: 0.00231121806
Iter: 320 loss: 0.00231121387
Iter: 321 loss: 0.00231122
Iter: 322 loss: 0.00231121015
Iter: 323 loss: 0.00231120759
Iter: 324 loss: 0.00231123064
Iter: 325 loss: 0.00231120642
Iter: 326 loss: 0.00231120363
Iter: 327 loss: 0.00231120363
Iter: 328 loss: 0.0023112013
Iter: 329 loss: 0.00231119897
Iter: 330 loss: 0.0023111992
Iter: 331 loss: 0.00231119571
Iter: 332 loss: 0.0023112
Iter: 333 loss: 0.00231119338
Iter: 334 loss: 0.00231119106
Iter: 335 loss: 0.0023112006
Iter: 336 loss: 0.00231118943
Iter: 337 loss: 0.0023111871
Iter: 338 loss: 0.00231120037
Iter: 339 loss: 0.0023111864
Iter: 340 loss: 0.00231118407
Iter: 341 loss: 0.00231120223
Iter: 342 loss: 0.00231118407
Iter: 343 loss: 0.00231118244
Iter: 344 loss: 0.00231118291
Iter: 345 loss: 0.00231117988
Iter: 346 loss: 0.00231117941
Iter: 347 loss: 0.0023111843
Iter: 348 loss: 0.00231117802
Iter: 349 loss: 0.00231117615
Iter: 350 loss: 0.00231118081
Iter: 351 loss: 0.00231117522
Iter: 352 loss: 0.00231117452
Iter: 353 loss: 0.00231118151
Iter: 354 loss: 0.00231117266
Iter: 355 loss: 0.00231117243
Iter: 356 loss: 0.00231117429
Iter: 357 loss: 0.00231117103
Iter: 358 loss: 0.00231117103
Iter: 359 loss: 0.00231116964
Iter: 360 loss: 0.00231116987
Iter: 361 loss: 0.00231116754
Iter: 362 loss: 0.0023111687
Iter: 363 loss: 0.00231116707
Iter: 364 loss: 0.00231117033
Iter: 365 loss: 0.00231116731
Iter: 366 loss: 0.00231116614
Iter: 367 loss: 0.00231116824
Iter: 368 loss: 0.00231116544
Iter: 369 loss: 0.00231116475
Iter: 370 loss: 0.00231116964
Iter: 371 loss: 0.00231116498
Iter: 372 loss: 0.00231116265
Iter: 373 loss: 0.0023111694
Iter: 374 loss: 0.00231116312
Iter: 375 loss: 0.00231116358
Iter: 376 loss: 0.00231116451
Iter: 377 loss: 0.00231116405
Iter: 378 loss: 0.00231116312
Iter: 379 loss: 0.00231116265
Iter: 380 loss: 0.00231116195
Iter: 381 loss: 0.00231116149
Iter: 382 loss: 0.00231116358
Iter: 383 loss: 0.00231116172
Iter: 384 loss: 0.00231116032
Iter: 385 loss: 0.00231116358
Iter: 386 loss: 0.00231116056
Iter: 387 loss: 0.00231115962
Iter: 388 loss: 0.00231116079
Iter: 389 loss: 0.00231116056
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2
+ date
Tue Oct 27 20:47:44 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a816c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ceac0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ceac0ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ceac01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a81022f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a810b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a807a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a807a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a80a92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76a807a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7690118b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7690118510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7690118268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76900f6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f769008dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f769008dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76900516a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f769005f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7644728598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f769005fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76447538c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f764470bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76446c3048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76446ce7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76446727b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7644695488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7644655730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76445fd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7644609158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76445af8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76445e29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f764456d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76445847b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7644594598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76445549d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7644554c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0626096949
Iter: 2 loss: 983.762695
Iter: 3 loss: 1516.7373
Iter: 4 loss: 0.0626079366
Iter: 5 loss: 0.0410294533
Iter: 6 loss: 0.0470776297
Iter: 7 loss: 310.401184
Iter: 8 loss: 0.047077436
Iter: 9 loss: 1502.18457
Iter: 10 loss: 0.0470773429
Iter: 11 loss: 0.0554208681
Iter: 12 loss: 0.0438524336
Iter: 13 loss: 0.0363000035
Iter: 14 loss: 0.0362067968
Iter: 15 loss: 0.0315245651
Iter: 16 loss: 0.136337608
Iter: 17 loss: 0.0310336985
Iter: 18 loss: 0.0279151723
Iter: 19 loss: 0.0240318812
Iter: 20 loss: 0.0198227055
Iter: 21 loss: 0.0197710618
Iter: 22 loss: 0.01801477
Iter: 23 loss: 0.0240219701
Iter: 24 loss: 0.0179194417
Iter: 25 loss: 0.0170013793
Iter: 26 loss: 0.0214349069
Iter: 27 loss: 0.0167570077
Iter: 28 loss: 0.0152802058
Iter: 29 loss: 0.0196442585
Iter: 30 loss: 0.0146807171
Iter: 31 loss: 0.0131993219
Iter: 32 loss: 0.0170225538
Iter: 33 loss: 0.0126685444
Iter: 34 loss: 0.011036057
Iter: 35 loss: 0.0206448864
Iter: 36 loss: 0.010769438
Iter: 37 loss: 0.00911733
Iter: 38 loss: 0.0578812584
Iter: 39 loss: 0.00906671211
Iter: 40 loss: 0.00796513166
Iter: 41 loss: 0.00796394795
Iter: 42 loss: 0.00723615941
Iter: 43 loss: 0.00784145668
Iter: 44 loss: 0.00678663095
Iter: 45 loss: 0.00627073506
Iter: 46 loss: 0.0082152
Iter: 47 loss: 0.00615091203
Iter: 48 loss: 0.00573494751
Iter: 49 loss: 0.00715626543
Iter: 50 loss: 0.00559904426
Iter: 51 loss: 0.00541659351
Iter: 52 loss: 0.00537682651
Iter: 53 loss: 0.00525603816
Iter: 54 loss: 0.00750561152
Iter: 55 loss: 0.00525552686
Iter: 56 loss: 0.00515153725
Iter: 57 loss: 0.005136183
Iter: 58 loss: 0.00506542297
Iter: 59 loss: 0.00483548082
Iter: 60 loss: 0.00510318
Iter: 61 loss: 0.00470431708
Iter: 62 loss: 0.0044478504
Iter: 63 loss: 0.00658116955
Iter: 64 loss: 0.00442692265
Iter: 65 loss: 0.00413961802
Iter: 66 loss: 0.00650178175
Iter: 67 loss: 0.0041164197
Iter: 68 loss: 0.00395521289
Iter: 69 loss: 0.00580808893
Iter: 70 loss: 0.00395201053
Iter: 71 loss: 0.00380917289
Iter: 72 loss: 0.0043705157
Iter: 73 loss: 0.00377265248
Iter: 74 loss: 0.00365965371
Iter: 75 loss: 0.00392967835
Iter: 76 loss: 0.00361831347
Iter: 77 loss: 0.00350601133
Iter: 78 loss: 0.00442930032
Iter: 79 loss: 0.00349660194
Iter: 80 loss: 0.00341244787
Iter: 81 loss: 0.00366114592
Iter: 82 loss: 0.00338689
Iter: 83 loss: 0.00332020689
Iter: 84 loss: 0.00363527867
Iter: 85 loss: 0.00330732204
Iter: 86 loss: 0.00330736395
Iter: 87 loss: 0.00328759057
Iter: 88 loss: 0.00326660718
Iter: 89 loss: 0.00324129919
Iter: 90 loss: 0.00323853409
Iter: 91 loss: 0.00320565235
Iter: 92 loss: 0.00322397891
Iter: 93 loss: 0.00318392948
Iter: 94 loss: 0.00314501068
Iter: 95 loss: 0.00322061428
Iter: 96 loss: 0.00312828226
Iter: 97 loss: 0.00309619121
Iter: 98 loss: 0.00353154098
Iter: 99 loss: 0.00309603522
Iter: 100 loss: 0.00307505578
Iter: 101 loss: 0.00308309216
Iter: 102 loss: 0.00306038745
Iter: 103 loss: 0.00303906458
Iter: 104 loss: 0.00309094158
Iter: 105 loss: 0.00303117046
Iter: 106 loss: 0.00300869811
Iter: 107 loss: 0.00314300973
Iter: 108 loss: 0.00300583174
Iter: 109 loss: 0.00299027143
Iter: 110 loss: 0.00314608775
Iter: 111 loss: 0.00298965233
Iter: 112 loss: 0.00297678891
Iter: 113 loss: 0.00298632053
Iter: 114 loss: 0.00296890293
Iter: 115 loss: 0.00295269024
Iter: 116 loss: 0.00300994352
Iter: 117 loss: 0.00294846483
Iter: 118 loss: 0.00293812039
Iter: 119 loss: 0.00298785861
Iter: 120 loss: 0.00293637766
Iter: 121 loss: 0.00292748981
Iter: 122 loss: 0.00292747049
Iter: 123 loss: 0.00292319804
Iter: 124 loss: 0.00291296048
Iter: 125 loss: 0.00302928151
Iter: 126 loss: 0.00291194674
Iter: 127 loss: 0.00290024281
Iter: 128 loss: 0.002944696
Iter: 129 loss: 0.00289741321
Iter: 130 loss: 0.00288536493
Iter: 131 loss: 0.00293733669
Iter: 132 loss: 0.00288284454
Iter: 133 loss: 0.00287245098
Iter: 134 loss: 0.00288345059
Iter: 135 loss: 0.00286666094
Iter: 136 loss: 0.00285456423
Iter: 137 loss: 0.00288971467
Iter: 138 loss: 0.00285092951
Iter: 139 loss: 0.00284053804
Iter: 140 loss: 0.00284163072
Iter: 141 loss: 0.00283249142
Iter: 142 loss: 0.00282032718
Iter: 143 loss: 0.00295179617
Iter: 144 loss: 0.00282007549
Iter: 145 loss: 0.00281148171
Iter: 146 loss: 0.00286484323
Iter: 147 loss: 0.00281038182
Iter: 148 loss: 0.00280278502
Iter: 149 loss: 0.00279691815
Iter: 150 loss: 0.00279449834
Iter: 151 loss: 0.00278690015
Iter: 152 loss: 0.00286729028
Iter: 153 loss: 0.00278668175
Iter: 154 loss: 0.00278229686
Iter: 155 loss: 0.00278224656
Iter: 156 loss: 0.00277773663
Iter: 157 loss: 0.0027678872
Iter: 158 loss: 0.00292189349
Iter: 159 loss: 0.00276749069
Iter: 160 loss: 0.00276067248
Iter: 161 loss: 0.00276182266
Iter: 162 loss: 0.00275553809
Iter: 163 loss: 0.00274725235
Iter: 164 loss: 0.00283175148
Iter: 165 loss: 0.00274697971
Iter: 166 loss: 0.00274040573
Iter: 167 loss: 0.0027504256
Iter: 168 loss: 0.00273727323
Iter: 169 loss: 0.00272921519
Iter: 170 loss: 0.00274687307
Iter: 171 loss: 0.00272605522
Iter: 172 loss: 0.00271835038
Iter: 173 loss: 0.00273819407
Iter: 174 loss: 0.00271569728
Iter: 175 loss: 0.00270798104
Iter: 176 loss: 0.00270729931
Iter: 177 loss: 0.00270159869
Iter: 178 loss: 0.002694458
Iter: 179 loss: 0.00269431411
Iter: 180 loss: 0.00268746377
Iter: 181 loss: 0.00269449968
Iter: 182 loss: 0.0026836074
Iter: 183 loss: 0.0026776623
Iter: 184 loss: 0.00269134506
Iter: 185 loss: 0.0026754532
Iter: 186 loss: 0.00267061358
Iter: 187 loss: 0.00272875885
Iter: 188 loss: 0.00267053372
Iter: 189 loss: 0.00266565685
Iter: 190 loss: 0.00267757918
Iter: 191 loss: 0.00266395
Iter: 192 loss: 0.00266122
Iter: 193 loss: 0.00265487842
Iter: 194 loss: 0.00273433747
Iter: 195 loss: 0.0026543932
Iter: 196 loss: 0.00264669466
Iter: 197 loss: 0.00266443985
Iter: 198 loss: 0.0026438213
Iter: 199 loss: 0.00263761217
Iter: 200 loss: 0.00270297169
Iter: 201 loss: 0.00263745035
Iter: 202 loss: 0.00263202703
Iter: 203 loss: 0.00264052348
Iter: 204 loss: 0.00262949173
Iter: 205 loss: 0.00262459833
Iter: 206 loss: 0.00264586834
Iter: 207 loss: 0.00262358272
Iter: 208 loss: 0.00261926209
Iter: 209 loss: 0.00262598088
Iter: 210 loss: 0.00261724181
Iter: 211 loss: 0.00261320639
Iter: 212 loss: 0.00262393174
Iter: 213 loss: 0.00261183921
Iter: 214 loss: 0.00260759424
Iter: 215 loss: 0.00263105938
Iter: 216 loss: 0.00260699913
Iter: 217 loss: 0.00260342308
Iter: 218 loss: 0.00262778928
Iter: 219 loss: 0.00260305987
Iter: 220 loss: 0.00260134134
Iter: 221 loss: 0.00261028064
Iter: 222 loss: 0.00260107685
Iter: 223 loss: 0.00259902049
Iter: 224 loss: 0.00260440819
Iter: 225 loss: 0.00259831198
Iter: 226 loss: 0.00259646634
Iter: 227 loss: 0.00259370031
Iter: 228 loss: 0.00259364117
Iter: 229 loss: 0.00259068562
Iter: 230 loss: 0.00259106234
Iter: 231 loss: 0.00258842576
Iter: 232 loss: 0.00258577988
Iter: 233 loss: 0.00262219389
Iter: 234 loss: 0.00258577
Iter: 235 loss: 0.00258344738
Iter: 236 loss: 0.00258897245
Iter: 237 loss: 0.00258260034
Iter: 238 loss: 0.0025804881
Iter: 239 loss: 0.0025878835
Iter: 240 loss: 0.00257993955
Iter: 241 loss: 0.0025782343
Iter: 242 loss: 0.00258229906
Iter: 243 loss: 0.00257761171
Iter: 244 loss: 0.00257570203
Iter: 245 loss: 0.00257877563
Iter: 246 loss: 0.00257482147
Iter: 247 loss: 0.00257330155
Iter: 248 loss: 0.0025893827
Iter: 249 loss: 0.00257326
Iter: 250 loss: 0.00257214089
Iter: 251 loss: 0.00257799379
Iter: 252 loss: 0.00257196603
Iter: 253 loss: 0.00257111969
Iter: 254 loss: 0.00257357885
Iter: 255 loss: 0.00257085357
Iter: 256 loss: 0.0025699148
Iter: 257 loss: 0.00257680751
Iter: 258 loss: 0.00256983936
Iter: 259 loss: 0.00256921374
Iter: 260 loss: 0.0025683397
Iter: 261 loss: 0.00256830547
Iter: 262 loss: 0.00256731873
Iter: 263 loss: 0.00256736577
Iter: 264 loss: 0.00256654341
Iter: 265 loss: 0.00256515574
Iter: 266 loss: 0.00256701815
Iter: 267 loss: 0.00256445957
Iter: 268 loss: 0.00256324047
Iter: 269 loss: 0.00258156378
Iter: 270 loss: 0.00256323861
Iter: 271 loss: 0.00256221509
Iter: 272 loss: 0.00256226887
Iter: 273 loss: 0.00256141042
Iter: 274 loss: 0.00256011542
Iter: 275 loss: 0.00256566796
Iter: 276 loss: 0.00255984953
Iter: 277 loss: 0.00255878503
Iter: 278 loss: 0.00256056665
Iter: 279 loss: 0.00255830213
Iter: 280 loss: 0.00255722669
Iter: 281 loss: 0.00256258389
Iter: 282 loss: 0.00255704625
Iter: 283 loss: 0.00255634356
Iter: 284 loss: 0.00256605865
Iter: 285 loss: 0.00255634123
Iter: 286 loss: 0.00255584065
Iter: 287 loss: 0.00255678175
Iter: 288 loss: 0.00255563064
Iter: 289 loss: 0.00255515683
Iter: 290 loss: 0.00255964417
Iter: 291 loss: 0.00255513773
Iter: 292 loss: 0.00255479291
Iter: 293 loss: 0.00255444902
Iter: 294 loss: 0.00255437777
Iter: 295 loss: 0.0025537964
Iter: 296 loss: 0.00255295332
Iter: 297 loss: 0.00255292794
Iter: 298 loss: 0.00255195191
Iter: 299 loss: 0.00255736429
Iter: 300 loss: 0.00255181221
Iter: 301 loss: 0.00255100243
Iter: 302 loss: 0.00255415309
Iter: 303 loss: 0.0025508157
Iter: 304 loss: 0.00254993537
Iter: 305 loss: 0.00255310652
Iter: 306 loss: 0.00254971371
Iter: 307 loss: 0.00254901149
Iter: 308 loss: 0.00255030347
Iter: 309 loss: 0.00254870951
Iter: 310 loss: 0.00254799961
Iter: 311 loss: 0.0025509051
Iter: 312 loss: 0.00254784618
Iter: 313 loss: 0.0025472932
Iter: 314 loss: 0.00254881056
Iter: 315 loss: 0.00254711136
Iter: 316 loss: 0.0025466287
Iter: 317 loss: 0.00255099731
Iter: 318 loss: 0.00254660705
Iter: 319 loss: 0.00254626689
Iter: 320 loss: 0.00254830346
Iter: 321 loss: 0.00254622288
Iter: 322 loss: 0.00254599657
Iter: 323 loss: 0.00254751812
Iter: 324 loss: 0.00254597608
Iter: 325 loss: 0.00254575815
Iter: 326 loss: 0.00254542939
Iter: 327 loss: 0.00254542474
Iter: 328 loss: 0.00254499167
Iter: 329 loss: 0.00254513649
Iter: 330 loss: 0.0025446876
Iter: 331 loss: 0.00254422496
Iter: 332 loss: 0.00254498026
Iter: 333 loss: 0.00254401239
Iter: 334 loss: 0.00254359818
Iter: 335 loss: 0.00254661869
Iter: 336 loss: 0.00254356163
Iter: 337 loss: 0.00254320865
Iter: 338 loss: 0.00254485151
Iter: 339 loss: 0.00254314393
Iter: 340 loss: 0.00254281564
Iter: 341 loss: 0.00254296511
Iter: 342 loss: 0.00254259259
Iter: 343 loss: 0.00254222052
Iter: 344 loss: 0.00254399865
Iter: 345 loss: 0.0025421544
Iter: 346 loss: 0.0025418452
Iter: 347 loss: 0.00254278909
Iter: 348 loss: 0.00254175253
Iter: 349 loss: 0.00254151504
Iter: 350 loss: 0.00254365685
Iter: 351 loss: 0.00254150224
Iter: 352 loss: 0.00254129944
Iter: 353 loss: 0.00254241168
Iter: 354 loss: 0.00254127
Iter: 355 loss: 0.00254112203
Iter: 356 loss: 0.00254174042
Iter: 357 loss: 0.00254108943
Iter: 358 loss: 0.00254092435
Iter: 359 loss: 0.00254086172
Iter: 360 loss: 0.00254077069
Iter: 361 loss: 0.00254056766
Iter: 362 loss: 0.00254054135
Iter: 363 loss: 0.00254039676
Iter: 364 loss: 0.00254012574
Iter: 365 loss: 0.00254059583
Iter: 366 loss: 0.00254000537
Iter: 367 loss: 0.00253973855
Iter: 368 loss: 0.00254050014
Iter: 369 loss: 0.00253965613
Iter: 370 loss: 0.00253941421
Iter: 371 loss: 0.0025414261
Iter: 372 loss: 0.0025394
Iter: 373 loss: 0.00253918697
Iter: 374 loss: 0.00253935577
Iter: 375 loss: 0.00253905682
Iter: 376 loss: 0.00253879535
Iter: 377 loss: 0.0025392198
Iter: 378 loss: 0.00253867684
Iter: 379 loss: 0.00253844867
Iter: 380 loss: 0.0025404878
Iter: 381 loss: 0.00253843749
Iter: 382 loss: 0.00253828522
Iter: 383 loss: 0.00253882422
Iter: 384 loss: 0.0025382475
Iter: 385 loss: 0.00253811036
Iter: 386 loss: 0.00253953855
Iter: 387 loss: 0.00253810734
Iter: 388 loss: 0.00253802352
Iter: 389 loss: 0.00253828918
Iter: 390 loss: 0.00253799837
Iter: 391 loss: 0.00253789453
Iter: 392 loss: 0.0025378624
Iter: 393 loss: 0.00253780186
Iter: 394 loss: 0.00253766356
Iter: 395 loss: 0.00253762491
Iter: 396 loss: 0.00253753923
Iter: 397 loss: 0.00253737299
Iter: 398 loss: 0.00253784959
Iter: 399 loss: 0.00253731851
Iter: 400 loss: 0.0025371518
Iter: 401 loss: 0.00253733527
Iter: 402 loss: 0.00253705913
Iter: 403 loss: 0.00253688823
Iter: 404 loss: 0.00253840676
Iter: 405 loss: 0.00253687915
Iter: 406 loss: 0.00253672851
Iter: 407 loss: 0.002537027
Iter: 408 loss: 0.00253666332
Iter: 409 loss: 0.00253652316
Iter: 410 loss: 0.0025368114
Iter: 411 loss: 0.00253646402
Iter: 412 loss: 0.00253634457
Iter: 413 loss: 0.00253708591
Iter: 414 loss: 0.00253633037
Iter: 415 loss: 0.00253623701
Iter: 416 loss: 0.00253668241
Iter: 417 loss: 0.00253621908
Iter: 418 loss: 0.00253615482
Iter: 419 loss: 0.00253706565
Iter: 420 loss: 0.00253615389
Iter: 421 loss: 0.00253611221
Iter: 422 loss: 0.00253619417
Iter: 423 loss: 0.00253609614
Iter: 424 loss: 0.0025360377
Iter: 425 loss: 0.00253604678
Iter: 426 loss: 0.00253599556
Iter: 427 loss: 0.00253592641
Iter: 428 loss: 0.00253592897
Iter: 429 loss: 0.00253587263
Iter: 430 loss: 0.00253578927
Iter: 431 loss: 0.00253584399
Iter: 432 loss: 0.00253573433
Iter: 433 loss: 0.00253563048
Iter: 434 loss: 0.00253605377
Iter: 435 loss: 0.0025356086
Iter: 436 loss: 0.00253552315
Iter: 437 loss: 0.00253577204
Iter: 438 loss: 0.0025354973
Iter: 439 loss: 0.00253539439
Iter: 440 loss: 0.00253582373
Iter: 441 loss: 0.00253537367
Iter: 442 loss: 0.00253529148
Iter: 443 loss: 0.00253536412
Iter: 444 loss: 0.00253524352
Iter: 445 loss: 0.00253516622
Iter: 446 loss: 0.00253572618
Iter: 447 loss: 0.00253516017
Iter: 448 loss: 0.00253510196
Iter: 449 loss: 0.00253529684
Iter: 450 loss: 0.00253508426
Iter: 451 loss: 0.00253503793
Iter: 452 loss: 0.00253573013
Iter: 453 loss: 0.00253503723
Iter: 454 loss: 0.00253500417
Iter: 455 loss: 0.00253507495
Iter: 456 loss: 0.00253499253
Iter: 457 loss: 0.00253495038
Iter: 458 loss: 0.00253498601
Iter: 459 loss: 0.0025349271
Iter: 460 loss: 0.00253488729
Iter: 461 loss: 0.00253485888
Iter: 462 loss: 0.00253484212
Iter: 463 loss: 0.00253477483
Iter: 464 loss: 0.00253481255
Iter: 465 loss: 0.00253472943
Iter: 466 loss: 0.00253464654
Iter: 467 loss: 0.00253492128
Iter: 468 loss: 0.00253462489
Iter: 469 loss: 0.00253454456
Iter: 470 loss: 0.00253476598
Iter: 471 loss: 0.00253451802
Iter: 472 loss: 0.00253443466
Iter: 473 loss: 0.00253498787
Iter: 474 loss: 0.00253442605
Iter: 475 loss: 0.00253435923
Iter: 476 loss: 0.00253438414
Iter: 477 loss: 0.0025343122
Iter: 478 loss: 0.00253424514
Iter: 479 loss: 0.00253457855
Iter: 480 loss: 0.0025342321
Iter: 481 loss: 0.00253416877
Iter: 482 loss: 0.00253444863
Iter: 483 loss: 0.00253415806
Iter: 484 loss: 0.00253411545
Iter: 485 loss: 0.00253473362
Iter: 486 loss: 0.00253411639
Iter: 487 loss: 0.00253408821
Iter: 488 loss: 0.00253415573
Iter: 489 loss: 0.00253407564
Iter: 490 loss: 0.00253404025
Iter: 491 loss: 0.0025340654
Iter: 492 loss: 0.00253401883
Iter: 493 loss: 0.00253397552
Iter: 494 loss: 0.00253393827
Iter: 495 loss: 0.00253392896
Iter: 496 loss: 0.00253385678
Iter: 497 loss: 0.00253398926
Iter: 498 loss: 0.00253382791
Iter: 499 loss: 0.00253375666
Iter: 500 loss: 0.00253388053
Iter: 501 loss: 0.00253372313
Iter: 502 loss: 0.00253364723
Iter: 503 loss: 0.00253392849
Iter: 504 loss: 0.00253362954
Iter: 505 loss: 0.00253355806
Iter: 506 loss: 0.00253408635
Iter: 507 loss: 0.00253355317
Iter: 508 loss: 0.00253349729
Iter: 509 loss: 0.00253353221
Iter: 510 loss: 0.0025334612
Iter: 511 loss: 0.0025334
Iter: 512 loss: 0.00253355247
Iter: 513 loss: 0.00253337878
Iter: 514 loss: 0.00253331545
Iter: 515 loss: 0.00253372057
Iter: 516 loss: 0.00253330753
Iter: 517 loss: 0.00253326958
Iter: 518 loss: 0.00253380509
Iter: 519 loss: 0.00253327144
Iter: 520 loss: 0.00253324304
Iter: 521 loss: 0.00253331871
Iter: 522 loss: 0.00253323559
Iter: 523 loss: 0.00253320439
Iter: 524 loss: 0.00253322674
Iter: 525 loss: 0.0025331853
Iter: 526 loss: 0.00253314944
Iter: 527 loss: 0.00253312383
Iter: 528 loss: 0.00253311079
Iter: 529 loss: 0.00253305933
Iter: 530 loss: 0.00253316038
Iter: 531 loss: 0.00253303768
Iter: 532 loss: 0.00253298157
Iter: 533 loss: 0.00253306865
Iter: 534 loss: 0.00253295456
Iter: 535 loss: 0.00253289519
Iter: 536 loss: 0.0025330761
Iter: 537 loss: 0.00253287749
Iter: 538 loss: 0.00253281789
Iter: 539 loss: 0.00253324769
Iter: 540 loss: 0.0025328151
Iter: 541 loss: 0.0025327648
Iter: 542 loss: 0.00253279414
Iter: 543 loss: 0.00253273174
Iter: 544 loss: 0.002532674
Iter: 545 loss: 0.00253280369
Iter: 546 loss: 0.00253265165
Iter: 547 loss: 0.00253260043
Iter: 548 loss: 0.00253302767
Iter: 549 loss: 0.0025325953
Iter: 550 loss: 0.00253256271
Iter: 551 loss: 0.00253292895
Iter: 552 loss: 0.00253256201
Iter: 553 loss: 0.00253253477
Iter: 554 loss: 0.00253263582
Iter: 555 loss: 0.00253253
Iter: 556 loss: 0.00253250403
Iter: 557 loss: 0.00253251893
Iter: 558 loss: 0.00253248936
Iter: 559 loss: 0.00253245863
Iter: 560 loss: 0.00253244909
Iter: 561 loss: 0.00253243232
Iter: 562 loss: 0.00253239134
Iter: 563 loss: 0.0025324286
Iter: 564 loss: 0.00253236736
Iter: 565 loss: 0.00253231474
Iter: 566 loss: 0.00253240415
Iter: 567 loss: 0.00253228983
Iter: 568 loss: 0.00253223255
Iter: 569 loss: 0.00253236573
Iter: 570 loss: 0.00253221206
Iter: 571 loss: 0.00253215758
Iter: 572 loss: 0.0025326754
Iter: 573 loss: 0.00253215362
Iter: 574 loss: 0.00253210869
Iter: 575 loss: 0.00253212219
Iter: 576 loss: 0.00253207609
Iter: 577 loss: 0.00253201928
Iter: 578 loss: 0.00253215339
Iter: 579 loss: 0.00253199926
Iter: 580 loss: 0.0025319485
Iter: 581 loss: 0.0025323485
Iter: 582 loss: 0.00253194477
Iter: 583 loss: 0.00253191404
Iter: 584 loss: 0.00253226585
Iter: 585 loss: 0.00253191381
Iter: 586 loss: 0.00253189029
Iter: 587 loss: 0.00253199413
Iter: 588 loss: 0.00253188377
Iter: 589 loss: 0.00253186491
Iter: 590 loss: 0.0025318712
Iter: 591 loss: 0.00253184931
Iter: 592 loss: 0.00253182184
Iter: 593 loss: 0.00253181299
Iter: 594 loss: 0.00253179716
Iter: 595 loss: 0.00253175851
Iter: 596 loss: 0.00253177318
Iter: 597 loss: 0.00253173127
Iter: 598 loss: 0.00253167748
Iter: 599 loss: 0.0025318258
Iter: 600 loss: 0.00253166212
Iter: 601 loss: 0.00253161159
Iter: 602 loss: 0.00253170682
Iter: 603 loss: 0.00253159204
Iter: 604 loss: 0.00253154384
Iter: 605 loss: 0.00253195129
Iter: 606 loss: 0.00253154058
Iter: 607 loss: 0.00253149634
Iter: 608 loss: 0.00253154337
Iter: 609 loss: 0.00253147213
Iter: 610 loss: 0.00253142952
Iter: 611 loss: 0.00253151706
Iter: 612 loss: 0.00253141113
Iter: 613 loss: 0.00253136922
Iter: 614 loss: 0.00253167
Iter: 615 loss: 0.0025313634
Iter: 616 loss: 0.00253133639
Iter: 617 loss: 0.00253163907
Iter: 618 loss: 0.00253133709
Iter: 619 loss: 0.00253131683
Iter: 620 loss: 0.00253142836
Iter: 621 loss: 0.00253131287
Iter: 622 loss: 0.00253129657
Iter: 623 loss: 0.00253130076
Iter: 624 loss: 0.00253128447
Iter: 625 loss: 0.00253126118
Iter: 626 loss: 0.00253125164
Iter: 627 loss: 0.00253124023
Iter: 628 loss: 0.00253120577
Iter: 629 loss: 0.00253121927
Iter: 630 loss: 0.00253118249
Iter: 631 loss: 0.00253113871
Iter: 632 loss: 0.00253128656
Iter: 633 loss: 0.00253112847
Iter: 634 loss: 0.00253108726
Iter: 635 loss: 0.00253114803
Iter: 636 loss: 0.00253107026
Iter: 637 loss: 0.00253102579
Iter: 638 loss: 0.0025313478
Iter: 639 loss: 0.00253102323
Iter: 640 loss: 0.00253098691
Iter: 641 loss: 0.00253106328
Iter: 642 loss: 0.00253097317
Iter: 643 loss: 0.00253093848
Iter: 644 loss: 0.00253096782
Iter: 645 loss: 0.00253091566
Iter: 646 loss: 0.00253087794
Iter: 647 loss: 0.00253119296
Iter: 648 loss: 0.00253087655
Iter: 649 loss: 0.00253085373
Iter: 650 loss: 0.00253110891
Iter: 651 loss: 0.00253085094
Iter: 652 loss: 0.0025308365
Iter: 653 loss: 0.00253093406
Iter: 654 loss: 0.00253083603
Iter: 655 loss: 0.0025308223
Iter: 656 loss: 0.00253082067
Iter: 657 loss: 0.00253080949
Iter: 658 loss: 0.00253078854
Iter: 659 loss: 0.00253077713
Iter: 660 loss: 0.00253076805
Iter: 661 loss: 0.00253073731
Iter: 662 loss: 0.00253076479
Iter: 663 loss: 0.00253071869
Iter: 664 loss: 0.00253068283
Iter: 665 loss: 0.00253077643
Iter: 666 loss: 0.00253067049
Iter: 667 loss: 0.00253063207
Iter: 668 loss: 0.00253068726
Iter: 669 loss: 0.00253061368
Iter: 670 loss: 0.00253057433
Iter: 671 loss: 0.00253086793
Iter: 672 loss: 0.00253057224
Iter: 673 loss: 0.00253053661
Iter: 674 loss: 0.00253063533
Iter: 675 loss: 0.0025305266
Iter: 676 loss: 0.00253049517
Iter: 677 loss: 0.00253050332
Iter: 678 loss: 0.00253047259
Iter: 679 loss: 0.00253043603
Iter: 680 loss: 0.00253075501
Iter: 681 loss: 0.0025304351
Iter: 682 loss: 0.00253041415
Iter: 683 loss: 0.00253066304
Iter: 684 loss: 0.00253041205
Iter: 685 loss: 0.00253039855
Iter: 686 loss: 0.00253049145
Iter: 687 loss: 0.00253039645
Iter: 688 loss: 0.00253038481
Iter: 689 loss: 0.00253038062
Iter: 690 loss: 0.00253037317
Iter: 691 loss: 0.00253035268
Iter: 692 loss: 0.00253035035
Iter: 693 loss: 0.00253033522
Iter: 694 loss: 0.00253031054
Iter: 695 loss: 0.0025303287
Iter: 696 loss: 0.00253029238
Iter: 697 loss: 0.00253025908
Iter: 698 loss: 0.0025303443
Iter: 699 loss: 0.00253024814
Iter: 700 loss: 0.00253021414
Iter: 701 loss: 0.00253026513
Iter: 702 loss: 0.00253020017
Iter: 703 loss: 0.00253016315
Iter: 704 loss: 0.00253041764
Iter: 705 loss: 0.00253016199
Iter: 706 loss: 0.00253013056
Iter: 707 loss: 0.00253022485
Iter: 708 loss: 0.00253012194
Iter: 709 loss: 0.002530094
Iter: 710 loss: 0.00253011333
Iter: 711 loss: 0.00253007933
Iter: 712 loss: 0.0025300514
Iter: 713 loss: 0.00253025442
Iter: 714 loss: 0.00253004907
Iter: 715 loss: 0.00253003184
Iter: 716 loss: 0.0025302507
Iter: 717 loss: 0.00253003254
Iter: 718 loss: 0.00253001787
Iter: 719 loss: 0.0025300961
Iter: 720 loss: 0.00253001694
Iter: 721 loss: 0.00253000809
Iter: 722 loss: 0.00253000483
Iter: 723 loss: 0.00253000017
Iter: 724 loss: 0.00252998224
Iter: 725 loss: 0.0025299862
Iter: 726 loss: 0.00252997177
Iter: 727 loss: 0.00252995081
Iter: 728 loss: 0.00252996059
Iter: 729 loss: 0.00252993777
Iter: 730 loss: 0.00252991193
Iter: 731 loss: 0.00252999342
Iter: 732 loss: 0.00252990564
Iter: 733 loss: 0.0025298812
Iter: 734 loss: 0.0025299103
Iter: 735 loss: 0.00252986699
Iter: 736 loss: 0.00252984324
Iter: 737 loss: 0.00253002602
Iter: 738 loss: 0.00252983952
Iter: 739 loss: 0.00252981717
Iter: 740 loss: 0.0025298968
Iter: 741 loss: 0.00252981181
Iter: 742 loss: 0.00252979202
Iter: 743 loss: 0.00252980134
Iter: 744 loss: 0.00252977852
Iter: 745 loss: 0.00252975873
Iter: 746 loss: 0.00252991822
Iter: 747 loss: 0.0025297564
Iter: 748 loss: 0.00252974266
Iter: 749 loss: 0.00252990588
Iter: 750 loss: 0.00252974173
Iter: 751 loss: 0.00252973451
Iter: 752 loss: 0.00252979062
Iter: 753 loss: 0.00252973149
Iter: 754 loss: 0.00252972683
Iter: 755 loss: 0.00252972217
Iter: 756 loss: 0.00252971845
Iter: 757 loss: 0.00252970774
Iter: 758 loss: 0.00252971
Iter: 759 loss: 0.00252970029
Iter: 760 loss: 0.00252968632
Iter: 761 loss: 0.00252968934
Iter: 762 loss: 0.00252967584
Iter: 763 loss: 0.00252965605
Iter: 764 loss: 0.00252971146
Iter: 765 loss: 0.00252965116
Iter: 766 loss: 0.00252963486
Iter: 767 loss: 0.00252965512
Iter: 768 loss: 0.00252962508
Iter: 769 loss: 0.00252960506
Iter: 770 loss: 0.00252972194
Iter: 771 loss: 0.00252960157
Iter: 772 loss: 0.00252958201
Iter: 773 loss: 0.00252965791
Iter: 774 loss: 0.00252957945
Iter: 775 loss: 0.00252956478
Iter: 776 loss: 0.00252957689
Iter: 777 loss: 0.00252955453
Iter: 778 loss: 0.00252954
Iter: 779 loss: 0.00252963835
Iter: 780 loss: 0.00252953894
Iter: 781 loss: 0.00252952683
Iter: 782 loss: 0.00252965186
Iter: 783 loss: 0.00252952846
Iter: 784 loss: 0.00252952124
Iter: 785 loss: 0.00252956548
Iter: 786 loss: 0.00252952
Iter: 787 loss: 0.00252951263
Iter: 788 loss: 0.00252951309
Iter: 789 loss: 0.0025295103
Iter: 790 loss: 0.00252950122
Iter: 791 loss: 0.00252950401
Iter: 792 loss: 0.0025294933
Iter: 793 loss: 0.00252948375
Iter: 794 loss: 0.00252948236
Iter: 795 loss: 0.00252947467
Iter: 796 loss: 0.00252945884
Iter: 797 loss: 0.00252951193
Iter: 798 loss: 0.00252945535
Iter: 799 loss: 0.00252944115
Iter: 800 loss: 0.00252946327
Iter: 801 loss: 0.00252943533
Iter: 802 loss: 0.00252942136
Iter: 803 loss: 0.00252948655
Iter: 804 loss: 0.00252941763
Iter: 805 loss: 0.00252940226
Iter: 806 loss: 0.00252949027
Iter: 807 loss: 0.0025294004
Iter: 808 loss: 0.00252939
Iter: 809 loss: 0.00252939761
Iter: 810 loss: 0.00252938317
Iter: 811 loss: 0.00252937153
Iter: 812 loss: 0.00252942089
Iter: 813 loss: 0.0025293685
Iter: 814 loss: 0.00252936129
Iter: 815 loss: 0.00252947817
Iter: 816 loss: 0.00252935942
Iter: 817 loss: 0.00252935546
Iter: 818 loss: 0.00252939528
Iter: 819 loss: 0.00252935616
Iter: 820 loss: 0.00252935104
Iter: 821 loss: 0.00252935
Iter: 822 loss: 0.00252934825
Iter: 823 loss: 0.0025293408
Iter: 824 loss: 0.00252934336
Iter: 825 loss: 0.00252933544
Iter: 826 loss: 0.00252932683
Iter: 827 loss: 0.00252932822
Iter: 828 loss: 0.00252932147
Iter: 829 loss: 0.00252931
Iter: 830 loss: 0.00252935337
Iter: 831 loss: 0.00252930797
Iter: 832 loss: 0.00252929889
Iter: 833 loss: 0.00252930401
Iter: 834 loss: 0.00252929097
Iter: 835 loss: 0.00252927979
Iter: 836 loss: 0.00252934219
Iter: 837 loss: 0.00252927793
Iter: 838 loss: 0.00252926955
Iter: 839 loss: 0.00252933358
Iter: 840 loss: 0.00252926722
Iter: 841 loss: 0.00252925837
Iter: 842 loss: 0.00252926024
Iter: 843 loss: 0.00252925279
Iter: 844 loss: 0.00252924208
Iter: 845 loss: 0.00252928142
Iter: 846 loss: 0.00252923905
Iter: 847 loss: 0.00252923369
Iter: 848 loss: 0.00252923416
Iter: 849 loss: 0.00252922904
Iter: 850 loss: 0.00252925884
Iter: 851 loss: 0.00252922927
Iter: 852 loss: 0.00252922438
Iter: 853 loss: 0.00252922298
Iter: 854 loss: 0.00252922159
Iter: 855 loss: 0.00252921437
Iter: 856 loss: 0.00252921879
Iter: 857 loss: 0.00252921274
Iter: 858 loss: 0.00252920529
Iter: 859 loss: 0.00252920762
Iter: 860 loss: 0.0025292004
Iter: 861 loss: 0.00252919458
Iter: 862 loss: 0.00252921926
Iter: 863 loss: 0.00252919132
Iter: 864 loss: 0.0025291834
Iter: 865 loss: 0.00252918713
Iter: 866 loss: 0.00252917828
Iter: 867 loss: 0.0025291685
Iter: 868 loss: 0.00252922066
Iter: 869 loss: 0.00252916547
Iter: 870 loss: 0.00252915779
Iter: 871 loss: 0.00252921134
Iter: 872 loss: 0.00252915593
Iter: 873 loss: 0.00252914801
Iter: 874 loss: 0.00252915034
Iter: 875 loss: 0.00252914266
Iter: 876 loss: 0.00252913358
Iter: 877 loss: 0.00252917362
Iter: 878 loss: 0.00252913311
Iter: 879 loss: 0.00252912752
Iter: 880 loss: 0.00252912682
Iter: 881 loss: 0.0025291231
Iter: 882 loss: 0.00252914731
Iter: 883 loss: 0.00252912357
Iter: 884 loss: 0.00252911961
Iter: 885 loss: 0.00252911961
Iter: 886 loss: 0.00252911774
Iter: 887 loss: 0.00252911332
Iter: 888 loss: 0.00252911728
Iter: 889 loss: 0.00252910913
Iter: 890 loss: 0.00252910634
Iter: 891 loss: 0.00252910424
Iter: 892 loss: 0.00252910145
Iter: 893 loss: 0.00252909469
Iter: 894 loss: 0.00252911099
Iter: 895 loss: 0.00252909283
Iter: 896 loss: 0.00252908631
Iter: 897 loss: 0.00252909074
Iter: 898 loss: 0.00252908259
Iter: 899 loss: 0.0025290749
Iter: 900 loss: 0.00252911309
Iter: 901 loss: 0.00252907025
Iter: 902 loss: 0.00252906606
Iter: 903 loss: 0.00252911262
Iter: 904 loss: 0.00252906512
Iter: 905 loss: 0.00252905791
Iter: 906 loss: 0.00252905954
Iter: 907 loss: 0.00252905348
Iter: 908 loss: 0.00252904743
Iter: 909 loss: 0.0025290749
Iter: 910 loss: 0.00252904557
Iter: 911 loss: 0.00252903975
Iter: 912 loss: 0.00252903951
Iter: 913 loss: 0.00252903788
Iter: 914 loss: 0.00252905767
Iter: 915 loss: 0.00252903835
Iter: 916 loss: 0.00252903532
Iter: 917 loss: 0.00252903509
Iter: 918 loss: 0.00252903276
Iter: 919 loss: 0.0025290302
Iter: 920 loss: 0.00252903276
Iter: 921 loss: 0.00252902764
Iter: 922 loss: 0.00252902484
Iter: 923 loss: 0.00252902368
Iter: 924 loss: 0.00252902112
Iter: 925 loss: 0.00252901739
Iter: 926 loss: 0.00252902741
Iter: 927 loss: 0.00252901437
Iter: 928 loss: 0.00252900925
Iter: 929 loss: 0.0025290139
Iter: 930 loss: 0.00252900668
Iter: 931 loss: 0.00252900086
Iter: 932 loss: 0.00252902694
Iter: 933 loss: 0.002529
Iter: 934 loss: 0.00252899295
Iter: 935 loss: 0.0025290295
Iter: 936 loss: 0.00252899225
Iter: 937 loss: 0.00252898922
Iter: 938 loss: 0.00252898922
Iter: 939 loss: 0.00252898433
Iter: 940 loss: 0.00252897921
Iter: 941 loss: 0.00252899807
Iter: 942 loss: 0.00252897711
Iter: 943 loss: 0.00252897386
Iter: 944 loss: 0.00252897618
Iter: 945 loss: 0.00252897176
Iter: 946 loss: 0.00252898759
Iter: 947 loss: 0.00252897083
Iter: 948 loss: 0.00252897013
Iter: 949 loss: 0.00252897013
Iter: 950 loss: 0.00252897013
Iter: 951 loss: 0.00252896594
Iter: 952 loss: 0.00252896803
Iter: 953 loss: 0.00252896524
Iter: 954 loss: 0.00252896221
Iter: 955 loss: 0.00252896035
Iter: 956 loss: 0.00252895895
Iter: 957 loss: 0.002528955
Iter: 958 loss: 0.00252896291
Iter: 959 loss: 0.00252895383
Iter: 960 loss: 0.00252894871
Iter: 961 loss: 0.00252895453
Iter: 962 loss: 0.00252894708
Iter: 963 loss: 0.00252894079
Iter: 964 loss: 0.00252896035
Iter: 965 loss: 0.00252894033
Iter: 966 loss: 0.00252893427
Iter: 967 loss: 0.0025289692
Iter: 968 loss: 0.00252893567
Iter: 969 loss: 0.00252893148
Iter: 970 loss: 0.00252893427
Iter: 971 loss: 0.00252892962
Iter: 972 loss: 0.00252892496
Iter: 973 loss: 0.00252893637
Iter: 974 loss: 0.00252892356
Iter: 975 loss: 0.0025289217
Iter: 976 loss: 0.0025289217
Iter: 977 loss: 0.00252891821
Iter: 978 loss: 0.00252893101
Iter: 979 loss: 0.00252892077
Iter: 980 loss: 0.00252891867
Iter: 981 loss: 0.00252891798
Iter: 982 loss: 0.00252891681
Iter: 983 loss: 0.00252891472
Iter: 984 loss: 0.00252891472
Iter: 985 loss: 0.00252891332
Iter: 986 loss: 0.00252891169
Iter: 987 loss: 0.00252890983
Iter: 988 loss: 0.00252890913
Iter: 989 loss: 0.0025289054
Iter: 990 loss: 0.00252891565
Iter: 991 loss: 0.0025289047
Iter: 992 loss: 0.00252890098
Iter: 993 loss: 0.0025289054
Iter: 994 loss: 0.00252889935
Iter: 995 loss: 0.00252889423
Iter: 996 loss: 0.00252890703
Iter: 997 loss: 0.00252889353
Iter: 998 loss: 0.00252889167
Iter: 999 loss: 0.00252892124
Iter: 1000 loss: 0.0025288905
Iter: 1001 loss: 0.00252888841
Iter: 1002 loss: 0.00252888957
Iter: 1003 loss: 0.00252888585
Iter: 1004 loss: 0.00252888259
Iter: 1005 loss: 0.00252889027
Iter: 1006 loss: 0.00252888212
Iter: 1007 loss: 0.00252887886
Iter: 1008 loss: 0.00252887886
Iter: 1009 loss: 0.00252887816
Iter: 1010 loss: 0.00252888794
Iter: 1011 loss: 0.00252887886
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4
+ date
Tue Oct 27 20:51:58 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c6d036268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c6d016048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c6d0167b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c6d016620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c2922d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c291de2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c2919fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c2919fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c04257268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c04257d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c042769d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c041d98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c041d9ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0419c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c041a9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c041a9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c041a9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0419c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c04122b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c040eff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0410e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c040b7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0407e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0401b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0401b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3c0401b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf0685620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf0634510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf06341e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf05df9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf05969d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf0596378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf05b36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf05c0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf05889d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bf053b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.222015679
Iter: 2 loss: 8410.0625
Iter: 3 loss: 13416.2227
Iter: 4 loss: 2406.75464
Iter: 5 loss: 616.934
Iter: 6 loss: 616.796265
Iter: 7 loss: 0.222013801
Iter: 8 loss: 150.944962
Iter: 9 loss: 0.221977144
Iter: 10 loss: 0.147275448
Iter: 11 loss: 0.194174096
Iter: 12 loss: 0.155426875
Iter: 13 loss: 0.142304078
Iter: 14 loss: 0.137812316
Iter: 15 loss: 92.5724716
Iter: 16 loss: 0.137811124
Iter: 17 loss: 0.136417091
Iter: 18 loss: 0.120371871
Iter: 19 loss: 73.5150604
Iter: 20 loss: 0.537021399
Iter: 21 loss: 0.136169627
Iter: 22 loss: 0.121353492
Iter: 23 loss: 0.121298462
Iter: 24 loss: 0.135450423
Iter: 25 loss: 0.116364822
Iter: 26 loss: 0.0991767421
Iter: 27 loss: 0.183003545
Iter: 28 loss: 0.0976305306
Iter: 29 loss: 0.0932549164
Iter: 30 loss: 0.478825212
Iter: 31 loss: 0.0932459
Iter: 32 loss: 0.0852756277
Iter: 33 loss: 0.781857967
Iter: 34 loss: 0.0852711
Iter: 35 loss: 0.0862416327
Iter: 36 loss: 0.0816808194
Iter: 37 loss: 0.0777817667
Iter: 38 loss: 0.0957286507
Iter: 39 loss: 0.0773090869
Iter: 40 loss: 0.0755234733
Iter: 41 loss: 0.0742169768
Iter: 42 loss: 0.0737092197
Iter: 43 loss: 0.068632327
Iter: 44 loss: 0.0931315944
Iter: 45 loss: 0.0683637932
Iter: 46 loss: 0.0659211278
Iter: 47 loss: 0.123930007
Iter: 48 loss: 0.0658708885
Iter: 49 loss: 0.0637344122
Iter: 50 loss: 0.0637342259
Iter: 51 loss: 0.0618741661
Iter: 52 loss: 0.0644583553
Iter: 53 loss: 0.0612763166
Iter: 54 loss: 0.0597518086
Iter: 55 loss: 0.0618884638
Iter: 56 loss: 0.0587848201
Iter: 57 loss: 0.0578011647
Iter: 58 loss: 0.0774995238
Iter: 59 loss: 0.0577905327
Iter: 60 loss: 0.0568762757
Iter: 61 loss: 0.0560706854
Iter: 62 loss: 0.0558837727
Iter: 63 loss: 0.0548997819
Iter: 64 loss: 0.0556074679
Iter: 65 loss: 0.0541891865
Iter: 66 loss: 0.0516300164
Iter: 67 loss: 0.0720339864
Iter: 68 loss: 0.051152654
Iter: 69 loss: 0.0488140509
Iter: 70 loss: 0.115027606
Iter: 71 loss: 0.0488118678
Iter: 72 loss: 0.0477802
Iter: 73 loss: 0.048351977
Iter: 74 loss: 0.0472088344
Iter: 75 loss: 0.0461561978
Iter: 76 loss: 0.0486759841
Iter: 77 loss: 0.0457188301
Iter: 78 loss: 0.0447976887
Iter: 79 loss: 0.0446898565
Iter: 80 loss: 0.0437607057
Iter: 81 loss: 0.0437461659
Iter: 82 loss: 0.0425405651
Iter: 83 loss: 0.0498351268
Iter: 84 loss: 0.0423979722
Iter: 85 loss: 0.0415861234
Iter: 86 loss: 0.0424138866
Iter: 87 loss: 0.0411523
Iter: 88 loss: 0.0403833725
Iter: 89 loss: 0.0463910252
Iter: 90 loss: 0.0402608886
Iter: 91 loss: 0.0394794345
Iter: 92 loss: 0.0523634031
Iter: 93 loss: 0.0394726954
Iter: 94 loss: 0.0385556445
Iter: 95 loss: 0.0591333807
Iter: 96 loss: 0.0385478251
Iter: 97 loss: 0.0378412902
Iter: 98 loss: 0.0405950285
Iter: 99 loss: 0.0376188643
Iter: 100 loss: 0.0366224051
Iter: 101 loss: 0.0396170728
Iter: 102 loss: 0.0363819078
Iter: 103 loss: 0.0356029309
Iter: 104 loss: 0.0408781096
Iter: 105 loss: 0.0354965851
Iter: 106 loss: 0.0350000337
Iter: 107 loss: 0.0371707566
Iter: 108 loss: 0.0349437594
Iter: 109 loss: 0.0347376689
Iter: 110 loss: 0.0351623744
Iter: 111 loss: 0.0346625037
Iter: 112 loss: 0.0342771411
Iter: 113 loss: 0.0345762298
Iter: 114 loss: 0.0340241306
Iter: 115 loss: 0.0332028195
Iter: 116 loss: 0.033139389
Iter: 117 loss: 0.03266415
Iter: 118 loss: 0.0334692299
Iter: 119 loss: 0.032411404
Iter: 120 loss: 0.0319828317
Iter: 121 loss: 0.0322819874
Iter: 122 loss: 0.0317237973
Iter: 123 loss: 0.0310951211
Iter: 124 loss: 0.0310287587
Iter: 125 loss: 0.030534355
Iter: 126 loss: 0.033773005
Iter: 127 loss: 0.0304842368
Iter: 128 loss: 0.0297808107
Iter: 129 loss: 0.0297445431
Iter: 130 loss: 0.0289852358
Iter: 131 loss: 0.0340767764
Iter: 132 loss: 0.028841015
Iter: 133 loss: 0.0285210982
Iter: 134 loss: 0.0294627212
Iter: 135 loss: 0.028432237
Iter: 136 loss: 0.0291415155
Iter: 137 loss: 0.0283059552
Iter: 138 loss: 0.0281525459
Iter: 139 loss: 0.0283695348
Iter: 140 loss: 0.0280744806
Iter: 141 loss: 0.027830869
Iter: 142 loss: 0.0275805723
Iter: 143 loss: 0.0275275297
Iter: 144 loss: 0.0267697889
Iter: 145 loss: 0.0357589945
Iter: 146 loss: 0.0267492719
Iter: 147 loss: 0.0261072516
Iter: 148 loss: 0.0265108068
Iter: 149 loss: 0.0256699696
Iter: 150 loss: 0.0248602908
Iter: 151 loss: 0.0267115887
Iter: 152 loss: 0.0245786291
Iter: 153 loss: 0.0242666118
Iter: 154 loss: 0.0241763256
Iter: 155 loss: 0.0238297842
Iter: 156 loss: 0.0239814203
Iter: 157 loss: 0.023612624
Iter: 158 loss: 0.0231220163
Iter: 159 loss: 0.0248544551
Iter: 160 loss: 0.0229890291
Iter: 161 loss: 0.0226543527
Iter: 162 loss: 0.0227316506
Iter: 163 loss: 0.0224086419
Iter: 164 loss: 0.0219888911
Iter: 165 loss: 0.0227752868
Iter: 166 loss: 0.0218051858
Iter: 167 loss: 0.0222873297
Iter: 168 loss: 0.0216444843
Iter: 169 loss: 0.0213299841
Iter: 170 loss: 0.0218259171
Iter: 171 loss: 0.0211677626
Iter: 172 loss: 0.021025585
Iter: 173 loss: 0.0212981
Iter: 174 loss: 0.0209642872
Iter: 175 loss: 0.0205799546
Iter: 176 loss: 0.020577047
Iter: 177 loss: 0.0200954136
Iter: 178 loss: 0.0219468642
Iter: 179 loss: 0.01997035
Iter: 180 loss: 0.0196181424
Iter: 181 loss: 0.0195478
Iter: 182 loss: 0.0206760447
Iter: 183 loss: 0.0194054805
Iter: 184 loss: 0.0192988757
Iter: 185 loss: 0.0195464
Iter: 186 loss: 0.0192542
Iter: 187 loss: 0.0191177707
Iter: 188 loss: 0.0190852247
Iter: 189 loss: 0.0189975277
Iter: 190 loss: 0.018893443
Iter: 191 loss: 0.0188584719
Iter: 192 loss: 0.0187987257
Iter: 193 loss: 0.0186545
Iter: 194 loss: 0.0187129322
Iter: 195 loss: 0.0185525753
Iter: 196 loss: 0.0184604209
Iter: 197 loss: 0.0184567887
Iter: 198 loss: 0.0183831602
Iter: 199 loss: 0.0183693487
Iter: 200 loss: 0.0182983205
Iter: 201 loss: 0.0182455555
Iter: 202 loss: 0.0183543414
Iter: 203 loss: 0.0182237253
Iter: 204 loss: 0.0179967452
Iter: 205 loss: 0.0176570527
Iter: 206 loss: 0.0176492091
Iter: 207 loss: 0.0173707791
Iter: 208 loss: 0.0173655096
Iter: 209 loss: 0.0172460154
Iter: 210 loss: 0.0172179416
Iter: 211 loss: 0.0171411131
Iter: 212 loss: 0.0169804711
Iter: 213 loss: 0.0174845979
Iter: 214 loss: 0.0169301983
Iter: 215 loss: 0.0167009197
Iter: 216 loss: 0.0177272521
Iter: 217 loss: 0.0166638084
Iter: 218 loss: 0.0165093746
Iter: 219 loss: 0.0165038519
Iter: 220 loss: 0.0163849816
Iter: 221 loss: 0.0162591338
Iter: 222 loss: 0.0160522275
Iter: 223 loss: 0.0160513557
Iter: 224 loss: 0.0158414543
Iter: 225 loss: 0.0159832798
Iter: 226 loss: 0.0157030206
Iter: 227 loss: 0.0159017164
Iter: 228 loss: 0.0156000229
Iter: 229 loss: 0.0154919457
Iter: 230 loss: 0.016330149
Iter: 231 loss: 0.0154865859
Iter: 232 loss: 0.0154003613
Iter: 233 loss: 0.0155751454
Iter: 234 loss: 0.0153649943
Iter: 235 loss: 0.0152392862
Iter: 236 loss: 0.0153213246
Iter: 237 loss: 0.0151584605
Iter: 238 loss: 0.0150380479
Iter: 239 loss: 0.0152069665
Iter: 240 loss: 0.0149778193
Iter: 241 loss: 0.0148607362
Iter: 242 loss: 0.0148578035
Iter: 243 loss: 0.0147403656
Iter: 244 loss: 0.0147454441
Iter: 245 loss: 0.0146445921
Iter: 246 loss: 0.0145245092
Iter: 247 loss: 0.0146060269
Iter: 248 loss: 0.0144522889
Iter: 249 loss: 0.0143728834
Iter: 250 loss: 0.0143136494
Iter: 251 loss: 0.0142874811
Iter: 252 loss: 0.0141949616
Iter: 253 loss: 0.0144299129
Iter: 254 loss: 0.0141604431
Iter: 255 loss: 0.0140395211
Iter: 256 loss: 0.0142780226
Iter: 257 loss: 0.0139884129
Iter: 258 loss: 0.0139338393
Iter: 259 loss: 0.0138652837
Iter: 260 loss: 0.0137591977
Iter: 261 loss: 0.0147357238
Iter: 262 loss: 0.0137558244
Iter: 263 loss: 0.0136424704
Iter: 264 loss: 0.0146575067
Iter: 265 loss: 0.0136356708
Iter: 266 loss: 0.0135839256
Iter: 267 loss: 0.0134836202
Iter: 268 loss: 0.0155641986
Iter: 269 loss: 0.0134829562
Iter: 270 loss: 0.013366526
Iter: 271 loss: 0.0136958845
Iter: 272 loss: 0.0133238202
Iter: 273 loss: 0.0132565377
Iter: 274 loss: 0.0131999804
Iter: 275 loss: 0.0131806731
Iter: 276 loss: 0.0130868666
Iter: 277 loss: 0.0130768027
Iter: 278 loss: 0.0129740806
Iter: 279 loss: 0.0143407546
Iter: 280 loss: 0.012972435
Iter: 281 loss: 0.0128660919
Iter: 282 loss: 0.0130998259
Iter: 283 loss: 0.0128290942
Iter: 284 loss: 0.01276033
Iter: 285 loss: 0.0128204785
Iter: 286 loss: 0.0127179921
Iter: 287 loss: 0.0126570771
Iter: 288 loss: 0.0125600891
Iter: 289 loss: 0.0125592668
Iter: 290 loss: 0.0124408472
Iter: 291 loss: 0.0136084426
Iter: 292 loss: 0.0124369897
Iter: 293 loss: 0.0123250671
Iter: 294 loss: 0.012597464
Iter: 295 loss: 0.0122833084
Iter: 296 loss: 0.0120947212
Iter: 297 loss: 0.0134314364
Iter: 298 loss: 0.0120783066
Iter: 299 loss: 0.0119793676
Iter: 300 loss: 0.0119785126
Iter: 301 loss: 0.0119433142
Iter: 302 loss: 0.0118840076
Iter: 303 loss: 0.0118837822
Iter: 304 loss: 0.0117763905
Iter: 305 loss: 0.011594289
Iter: 306 loss: 0.0115938131
Iter: 307 loss: 0.0114238104
Iter: 308 loss: 0.01283429
Iter: 309 loss: 0.0114084929
Iter: 310 loss: 0.0113214329
Iter: 311 loss: 0.011236744
Iter: 312 loss: 0.011218451
Iter: 313 loss: 0.011232432
Iter: 314 loss: 0.0111139473
Iter: 315 loss: 0.0110003501
Iter: 316 loss: 0.0118587166
Iter: 317 loss: 0.0109905135
Iter: 318 loss: 0.0109733529
Iter: 319 loss: 0.0109579209
Iter: 320 loss: 0.0109536648
Iter: 321 loss: 0.0108777527
Iter: 322 loss: 0.0108194398
Iter: 323 loss: 0.0107951062
Iter: 324 loss: 0.0107105467
Iter: 325 loss: 0.0107105076
Iter: 326 loss: 0.0106625278
Iter: 327 loss: 0.0106624477
Iter: 328 loss: 0.0106257042
Iter: 329 loss: 0.0105578806
Iter: 330 loss: 0.0122674592
Iter: 331 loss: 0.0105578117
Iter: 332 loss: 0.0104879355
Iter: 333 loss: 0.0104622077
Iter: 334 loss: 0.0103833955
Iter: 335 loss: 0.0105268098
Iter: 336 loss: 0.0103500672
Iter: 337 loss: 0.010313048
Iter: 338 loss: 0.0102554327
Iter: 339 loss: 0.0102544967
Iter: 340 loss: 0.0102095418
Iter: 341 loss: 0.0101187574
Iter: 342 loss: 0.0119060557
Iter: 343 loss: 0.0101175234
Iter: 344 loss: 0.0100465342
Iter: 345 loss: 0.0102252504
Iter: 346 loss: 0.0100210588
Iter: 347 loss: 0.00996104069
Iter: 348 loss: 0.00998588931
Iter: 349 loss: 0.00992066227
Iter: 350 loss: 0.0100069707
Iter: 351 loss: 0.00988606364
Iter: 352 loss: 0.00985739566
Iter: 353 loss: 0.00984050054
Iter: 354 loss: 0.00982853677
Iter: 355 loss: 0.00978586
Iter: 356 loss: 0.00971868448
Iter: 357 loss: 0.00971777085
Iter: 358 loss: 0.00970642734
Iter: 359 loss: 0.00965864584
Iter: 360 loss: 0.0095981732
Iter: 361 loss: 0.00973563828
Iter: 362 loss: 0.00957551412
Iter: 363 loss: 0.00952438358
Iter: 364 loss: 0.00952202827
Iter: 365 loss: 0.00946252048
Iter: 366 loss: 0.0093925
Iter: 367 loss: 0.00938516483
Iter: 368 loss: 0.00933507644
Iter: 369 loss: 0.00997972675
Iter: 370 loss: 0.0093349861
Iter: 371 loss: 0.00928514823
Iter: 372 loss: 0.0092840232
Iter: 373 loss: 0.0092737712
Iter: 374 loss: 0.0092494851
Iter: 375 loss: 0.00951169059
Iter: 376 loss: 0.00924716331
Iter: 377 loss: 0.00919531379
Iter: 378 loss: 0.00912237
Iter: 379 loss: 0.00911936816
Iter: 380 loss: 0.00899898913
Iter: 381 loss: 0.0106554963
Iter: 382 loss: 0.00899877865
Iter: 383 loss: 0.00894711446
Iter: 384 loss: 0.0093528945
Iter: 385 loss: 0.00894371606
Iter: 386 loss: 0.00886313617
Iter: 387 loss: 0.00890877098
Iter: 388 loss: 0.00881044
Iter: 389 loss: 0.00871587172
Iter: 390 loss: 0.00924141519
Iter: 391 loss: 0.00870197639
Iter: 392 loss: 0.00863000751
Iter: 393 loss: 0.00893003121
Iter: 394 loss: 0.00861487444
Iter: 395 loss: 0.00857406668
Iter: 396 loss: 0.00852771848
Iter: 397 loss: 0.00852214359
Iter: 398 loss: 0.00844172481
Iter: 399 loss: 0.00894454587
Iter: 400 loss: 0.00843108073
Iter: 401 loss: 0.00839364529
Iter: 402 loss: 0.00890697166
Iter: 403 loss: 0.00839333
Iter: 404 loss: 0.0083786184
Iter: 405 loss: 0.00837755296
Iter: 406 loss: 0.00836669561
Iter: 407 loss: 0.00833942275
Iter: 408 loss: 0.00860372093
Iter: 409 loss: 0.0083355289
Iter: 410 loss: 0.00829178281
Iter: 411 loss: 0.0088346852
Iter: 412 loss: 0.00829144288
Iter: 413 loss: 0.00825147703
Iter: 414 loss: 0.00823350251
Iter: 415 loss: 0.00821384229
Iter: 416 loss: 0.00815572403
Iter: 417 loss: 0.0082349265
Iter: 418 loss: 0.0081276
Iter: 419 loss: 0.00806786399
Iter: 420 loss: 0.00797509588
Iter: 421 loss: 0.00797353219
Iter: 422 loss: 0.0079354886
Iter: 423 loss: 0.00808385387
Iter: 424 loss: 0.00792706758
Iter: 425 loss: 0.00790479872
Iter: 426 loss: 0.00785253383
Iter: 427 loss: 0.00839829445
Iter: 428 loss: 0.00784774683
Iter: 429 loss: 0.00778644718
Iter: 430 loss: 0.00791232847
Iter: 431 loss: 0.00776039436
Iter: 432 loss: 0.00771666178
Iter: 433 loss: 0.007677936
Iter: 434 loss: 0.00766638666
Iter: 435 loss: 0.00776012335
Iter: 436 loss: 0.00765088806
Iter: 437 loss: 0.00763834314
Iter: 438 loss: 0.00782160275
Iter: 439 loss: 0.00763828447
Iter: 440 loss: 0.00762397656
Iter: 441 loss: 0.00769430492
Iter: 442 loss: 0.00762170879
Iter: 443 loss: 0.00760330027
Iter: 444 loss: 0.00758366194
Iter: 445 loss: 0.00758044142
Iter: 446 loss: 0.00754868472
Iter: 447 loss: 0.00748191867
Iter: 448 loss: 0.00865555555
Iter: 449 loss: 0.00748023437
Iter: 450 loss: 0.007438689
Iter: 451 loss: 0.00743092317
Iter: 452 loss: 0.00740847131
Iter: 453 loss: 0.00745021
Iter: 454 loss: 0.00739870546
Iter: 455 loss: 0.0073684603
Iter: 456 loss: 0.00751772709
Iter: 457 loss: 0.00736332731
Iter: 458 loss: 0.00732105598
Iter: 459 loss: 0.00735570164
Iter: 460 loss: 0.00729514286
Iter: 461 loss: 0.00726813078
Iter: 462 loss: 0.00722306781
Iter: 463 loss: 0.00722289179
Iter: 464 loss: 0.007155261
Iter: 465 loss: 0.00720321387
Iter: 466 loss: 0.00711356197
Iter: 467 loss: 0.00706603331
Iter: 468 loss: 0.00714480784
Iter: 469 loss: 0.00704442663
Iter: 470 loss: 0.00701265316
Iter: 471 loss: 0.00702092145
Iter: 472 loss: 0.0069897566
Iter: 473 loss: 0.0069918083
Iter: 474 loss: 0.00697284564
Iter: 475 loss: 0.00696399249
Iter: 476 loss: 0.00694743171
Iter: 477 loss: 0.00732194632
Iter: 478 loss: 0.00694740703
Iter: 479 loss: 0.00690353289
Iter: 480 loss: 0.00694328081
Iter: 481 loss: 0.00687752198
Iter: 482 loss: 0.00683331303
Iter: 483 loss: 0.00680900831
Iter: 484 loss: 0.00678934157
Iter: 485 loss: 0.00672410242
Iter: 486 loss: 0.00690442417
Iter: 487 loss: 0.00670294277
Iter: 488 loss: 0.0066452045
Iter: 489 loss: 0.00682719052
Iter: 490 loss: 0.00662787771
Iter: 491 loss: 0.00659539457
Iter: 492 loss: 0.00686031207
Iter: 493 loss: 0.00659369491
Iter: 494 loss: 0.00656501
Iter: 495 loss: 0.00651429407
Iter: 496 loss: 0.00651428336
Iter: 497 loss: 0.00649080845
Iter: 498 loss: 0.00646539871
Iter: 499 loss: 0.00646166829
Iter: 500 loss: 0.00643128529
Iter: 501 loss: 0.00644439459
Iter: 502 loss: 0.00640993565
Iter: 503 loss: 0.00639921054
Iter: 504 loss: 0.00638607237
Iter: 505 loss: 0.00638486911
Iter: 506 loss: 0.00634799711
Iter: 507 loss: 0.00631044805
Iter: 508 loss: 0.00630347431
Iter: 509 loss: 0.0062659597
Iter: 510 loss: 0.00626271171
Iter: 511 loss: 0.00621563
Iter: 512 loss: 0.0062155067
Iter: 513 loss: 0.00618074369
Iter: 514 loss: 0.00654804148
Iter: 515 loss: 0.00617959443
Iter: 516 loss: 0.00616012421
Iter: 517 loss: 0.00615074672
Iter: 518 loss: 0.00614144374
Iter: 519 loss: 0.00612390321
Iter: 520 loss: 0.00612185337
Iter: 521 loss: 0.00610907795
Iter: 522 loss: 0.00608893391
Iter: 523 loss: 0.00606071111
Iter: 524 loss: 0.00605957676
Iter: 525 loss: 0.00601344509
Iter: 526 loss: 0.00605472922
Iter: 527 loss: 0.00598597666
Iter: 528 loss: 0.00598190073
Iter: 529 loss: 0.00597322499
Iter: 530 loss: 0.00596680213
Iter: 531 loss: 0.00595722627
Iter: 532 loss: 0.00595698599
Iter: 533 loss: 0.00594056491
Iter: 534 loss: 0.0059146015
Iter: 535 loss: 0.00591432117
Iter: 536 loss: 0.00588413794
Iter: 537 loss: 0.00587780587
Iter: 538 loss: 0.00584362447
Iter: 539 loss: 0.0058814669
Iter: 540 loss: 0.00582547579
Iter: 541 loss: 0.00579468673
Iter: 542 loss: 0.0057942858
Iter: 543 loss: 0.00577811152
Iter: 544 loss: 0.00580653455
Iter: 545 loss: 0.00577097852
Iter: 546 loss: 0.00575093878
Iter: 547 loss: 0.00575092435
Iter: 548 loss: 0.00574142206
Iter: 549 loss: 0.00580436783
Iter: 550 loss: 0.0057404926
Iter: 551 loss: 0.0057321866
Iter: 552 loss: 0.00570652355
Iter: 553 loss: 0.00576520339
Iter: 554 loss: 0.00569099467
Iter: 555 loss: 0.00564493844
Iter: 556 loss: 0.00575468503
Iter: 557 loss: 0.00562800933
Iter: 558 loss: 0.00566322682
Iter: 559 loss: 0.00561617129
Iter: 560 loss: 0.00560434069
Iter: 561 loss: 0.00564633403
Iter: 562 loss: 0.00560106337
Iter: 563 loss: 0.00559319416
Iter: 564 loss: 0.00556839444
Iter: 565 loss: 0.00561413076
Iter: 566 loss: 0.00555147463
Iter: 567 loss: 0.00549506396
Iter: 568 loss: 0.00566031039
Iter: 569 loss: 0.00547752
Iter: 570 loss: 0.00543281063
Iter: 571 loss: 0.0056322189
Iter: 572 loss: 0.00542296655
Iter: 573 loss: 0.00539154373
Iter: 574 loss: 0.0054437709
Iter: 575 loss: 0.00537693594
Iter: 576 loss: 0.00535724685
Iter: 577 loss: 0.00535715371
Iter: 578 loss: 0.00533403596
Iter: 579 loss: 0.00535816373
Iter: 580 loss: 0.00532128569
Iter: 581 loss: 0.00529115088
Iter: 582 loss: 0.00540737
Iter: 583 loss: 0.00528371474
Iter: 584 loss: 0.00525328796
Iter: 585 loss: 0.00553752389
Iter: 586 loss: 0.00525220204
Iter: 587 loss: 0.0052376641
Iter: 588 loss: 0.00522064557
Iter: 589 loss: 0.00521877874
Iter: 590 loss: 0.00521216821
Iter: 591 loss: 0.00520879123
Iter: 592 loss: 0.00518897735
Iter: 593 loss: 0.0054627927
Iter: 594 loss: 0.00518882
Iter: 595 loss: 0.00518336799
Iter: 596 loss: 0.0051734224
Iter: 597 loss: 0.00541544799
Iter: 598 loss: 0.00517342333
Iter: 599 loss: 0.00515333
Iter: 600 loss: 0.00513797859
Iter: 601 loss: 0.00513140857
Iter: 602 loss: 0.00510115875
Iter: 603 loss: 0.00505288271
Iter: 604 loss: 0.0050523933
Iter: 605 loss: 0.00497755222
Iter: 606 loss: 0.00531039
Iter: 607 loss: 0.0049632811
Iter: 608 loss: 0.00494014658
Iter: 609 loss: 0.0049087638
Iter: 610 loss: 0.00490696449
Iter: 611 loss: 0.00490666
Iter: 612 loss: 0.00489429571
Iter: 613 loss: 0.00488739694
Iter: 614 loss: 0.00488978252
Iter: 615 loss: 0.00488254754
Iter: 616 loss: 0.00486932788
Iter: 617 loss: 0.00484173186
Iter: 618 loss: 0.00533396844
Iter: 619 loss: 0.00484109111
Iter: 620 loss: 0.00486107636
Iter: 621 loss: 0.00482847961
Iter: 622 loss: 0.00482927263
Iter: 623 loss: 0.00482388027
Iter: 624 loss: 0.00482104206
Iter: 625 loss: 0.0048387805
Iter: 626 loss: 0.00482070632
Iter: 627 loss: 0.00481816847
Iter: 628 loss: 0.00480974559
Iter: 629 loss: 0.00480914721
Iter: 630 loss: 0.00480074901
Iter: 631 loss: 0.00478350464
Iter: 632 loss: 0.00490486855
Iter: 633 loss: 0.00478200428
Iter: 634 loss: 0.00476556
Iter: 635 loss: 0.00500635
Iter: 636 loss: 0.00476555573
Iter: 637 loss: 0.00474919472
Iter: 638 loss: 0.00471963128
Iter: 639 loss: 0.00547110382
Iter: 640 loss: 0.00471963082
Iter: 641 loss: 0.00469363388
Iter: 642 loss: 0.00465777144
Iter: 643 loss: 0.00465618772
Iter: 644 loss: 0.00462580798
Iter: 645 loss: 0.00462292973
Iter: 646 loss: 0.00461335154
Iter: 647 loss: 0.00460994802
Iter: 648 loss: 0.00460443087
Iter: 649 loss: 0.00458923029
Iter: 650 loss: 0.00467625307
Iter: 651 loss: 0.00458491733
Iter: 652 loss: 0.00456431275
Iter: 653 loss: 0.00457439478
Iter: 654 loss: 0.00455055386
Iter: 655 loss: 0.00454084
Iter: 656 loss: 0.00454041641
Iter: 657 loss: 0.00453301566
Iter: 658 loss: 0.00452724565
Iter: 659 loss: 0.00452534342
Iter: 660 loss: 0.00452271849
Iter: 661 loss: 0.00451893965
Iter: 662 loss: 0.00451882184
Iter: 663 loss: 0.00450280914
Iter: 664 loss: 0.00451105647
Iter: 665 loss: 0.00449206308
Iter: 666 loss: 0.00447381753
Iter: 667 loss: 0.00469001476
Iter: 668 loss: 0.00447357818
Iter: 669 loss: 0.00445950311
Iter: 670 loss: 0.004473079
Iter: 671 loss: 0.00445149373
Iter: 672 loss: 0.00443606079
Iter: 673 loss: 0.00440802472
Iter: 674 loss: 0.00511068059
Iter: 675 loss: 0.00440801587
Iter: 676 loss: 0.00438908534
Iter: 677 loss: 0.00440336624
Iter: 678 loss: 0.00437739585
Iter: 679 loss: 0.00436225953
Iter: 680 loss: 0.00434251362
Iter: 681 loss: 0.00434124283
Iter: 682 loss: 0.00432298193
Iter: 683 loss: 0.00458284654
Iter: 684 loss: 0.00432294374
Iter: 685 loss: 0.00431997422
Iter: 686 loss: 0.00431831554
Iter: 687 loss: 0.00431465684
Iter: 688 loss: 0.00435768347
Iter: 689 loss: 0.00431462936
Iter: 690 loss: 0.00431197742
Iter: 691 loss: 0.00432573678
Iter: 692 loss: 0.00431154575
Iter: 693 loss: 0.00430856179
Iter: 694 loss: 0.00429901108
Iter: 695 loss: 0.00430703536
Iter: 696 loss: 0.00429112092
Iter: 697 loss: 0.00426550675
Iter: 698 loss: 0.00432637613
Iter: 699 loss: 0.00425627176
Iter: 700 loss: 0.0042263167
Iter: 701 loss: 0.00459589
Iter: 702 loss: 0.00422601681
Iter: 703 loss: 0.00421207864
Iter: 704 loss: 0.00424146047
Iter: 705 loss: 0.00420653261
Iter: 706 loss: 0.00418751454
Iter: 707 loss: 0.00420563528
Iter: 708 loss: 0.00417645276
Iter: 709 loss: 0.00418496085
Iter: 710 loss: 0.00416964572
Iter: 711 loss: 0.004166333
Iter: 712 loss: 0.00415969454
Iter: 713 loss: 0.00428894721
Iter: 714 loss: 0.00415959954
Iter: 715 loss: 0.00414513657
Iter: 716 loss: 0.00417720573
Iter: 717 loss: 0.00413948391
Iter: 718 loss: 0.0041401526
Iter: 719 loss: 0.00412850361
Iter: 720 loss: 0.00412483653
Iter: 721 loss: 0.00415998232
Iter: 722 loss: 0.00412467308
Iter: 723 loss: 0.00412244303
Iter: 724 loss: 0.00411743717
Iter: 725 loss: 0.00418329425
Iter: 726 loss: 0.00411714474
Iter: 727 loss: 0.00411138218
Iter: 728 loss: 0.00410947111
Iter: 729 loss: 0.00410611322
Iter: 730 loss: 0.00410066033
Iter: 731 loss: 0.00409876136
Iter: 732 loss: 0.00409565866
Iter: 733 loss: 0.00408642599
Iter: 734 loss: 0.00406891666
Iter: 735 loss: 0.00444239331
Iter: 736 loss: 0.0040688524
Iter: 737 loss: 0.00405323785
Iter: 738 loss: 0.00421328377
Iter: 739 loss: 0.00405267114
Iter: 740 loss: 0.00403878279
Iter: 741 loss: 0.00402565952
Iter: 742 loss: 0.004022446
Iter: 743 loss: 0.00401278
Iter: 744 loss: 0.00401263777
Iter: 745 loss: 0.00400484912
Iter: 746 loss: 0.00398700638
Iter: 747 loss: 0.00420665881
Iter: 748 loss: 0.00398574863
Iter: 749 loss: 0.00397340441
Iter: 750 loss: 0.0040065418
Iter: 751 loss: 0.00396921
Iter: 752 loss: 0.00396530051
Iter: 753 loss: 0.00396428443
Iter: 754 loss: 0.00396185089
Iter: 755 loss: 0.00395623781
Iter: 756 loss: 0.00395456329
Iter: 757 loss: 0.00395114627
Iter: 758 loss: 0.0039432859
Iter: 759 loss: 0.00394807
Iter: 760 loss: 0.00393821765
Iter: 761 loss: 0.00393335149
Iter: 762 loss: 0.00392938266
Iter: 763 loss: 0.00392217468
Iter: 764 loss: 0.00392501615
Iter: 765 loss: 0.0039171963
Iter: 766 loss: 0.00390526722
Iter: 767 loss: 0.00393448956
Iter: 768 loss: 0.0039009708
Iter: 769 loss: 0.00389333628
Iter: 770 loss: 0.00388913136
Iter: 771 loss: 0.00388580468
Iter: 772 loss: 0.00387694919
Iter: 773 loss: 0.00390195497
Iter: 774 loss: 0.00387407653
Iter: 775 loss: 0.00386420754
Iter: 776 loss: 0.00389979151
Iter: 777 loss: 0.00386172626
Iter: 778 loss: 0.00385564845
Iter: 779 loss: 0.00389530463
Iter: 780 loss: 0.00385493878
Iter: 781 loss: 0.00384984445
Iter: 782 loss: 0.00386186223
Iter: 783 loss: 0.00384798367
Iter: 784 loss: 0.00385150593
Iter: 785 loss: 0.00384603254
Iter: 786 loss: 0.00384411938
Iter: 787 loss: 0.00384315569
Iter: 788 loss: 0.0038422849
Iter: 789 loss: 0.00383937079
Iter: 790 loss: 0.00383111113
Iter: 791 loss: 0.00387232285
Iter: 792 loss: 0.00382830971
Iter: 793 loss: 0.00381330377
Iter: 794 loss: 0.00387493451
Iter: 795 loss: 0.00380988955
Iter: 796 loss: 0.00379281724
Iter: 797 loss: 0.00401420146
Iter: 798 loss: 0.0037926943
Iter: 799 loss: 0.00378740672
Iter: 800 loss: 0.00377763761
Iter: 801 loss: 0.00400427915
Iter: 802 loss: 0.0037776432
Iter: 803 loss: 0.00376717839
Iter: 804 loss: 0.0038475513
Iter: 805 loss: 0.00376637047
Iter: 806 loss: 0.00376030593
Iter: 807 loss: 0.00377445458
Iter: 808 loss: 0.00375804352
Iter: 809 loss: 0.00375247747
Iter: 810 loss: 0.00375073333
Iter: 811 loss: 0.00374747929
Iter: 812 loss: 0.00374234375
Iter: 813 loss: 0.00374149391
Iter: 814 loss: 0.00373675721
Iter: 815 loss: 0.00374470185
Iter: 816 loss: 0.00373460888
Iter: 817 loss: 0.00373762148
Iter: 818 loss: 0.00373328803
Iter: 819 loss: 0.00373209291
Iter: 820 loss: 0.00373204611
Iter: 821 loss: 0.00373113342
Iter: 822 loss: 0.00372743
Iter: 823 loss: 0.00372000621
Iter: 824 loss: 0.00386189274
Iter: 825 loss: 0.00371991424
Iter: 826 loss: 0.00371750956
Iter: 827 loss: 0.00371631095
Iter: 828 loss: 0.00371311326
Iter: 829 loss: 0.0037244691
Iter: 830 loss: 0.00371231092
Iter: 831 loss: 0.00371020241
Iter: 832 loss: 0.00370324799
Iter: 833 loss: 0.00370398327
Iter: 834 loss: 0.00369627029
Iter: 835 loss: 0.0036967136
Iter: 836 loss: 0.00369173149
Iter: 837 loss: 0.00368688791
Iter: 838 loss: 0.00372825656
Iter: 839 loss: 0.00368662016
Iter: 840 loss: 0.00368346856
Iter: 841 loss: 0.00367901544
Iter: 842 loss: 0.00367885153
Iter: 843 loss: 0.00367478235
Iter: 844 loss: 0.00367452158
Iter: 845 loss: 0.00367094879
Iter: 846 loss: 0.003667688
Iter: 847 loss: 0.00366679253
Iter: 848 loss: 0.00367211853
Iter: 849 loss: 0.00366508379
Iter: 850 loss: 0.00366401812
Iter: 851 loss: 0.00366186444
Iter: 852 loss: 0.00370198255
Iter: 853 loss: 0.0036618358
Iter: 854 loss: 0.00365646789
Iter: 855 loss: 0.00364682125
Iter: 856 loss: 0.00389282033
Iter: 857 loss: 0.0036468287
Iter: 858 loss: 0.00367792416
Iter: 859 loss: 0.00364321633
Iter: 860 loss: 0.00364052178
Iter: 861 loss: 0.0036405127
Iter: 862 loss: 0.0036386759
Iter: 863 loss: 0.00363404467
Iter: 864 loss: 0.00367604382
Iter: 865 loss: 0.00363337621
Iter: 866 loss: 0.0036279012
Iter: 867 loss: 0.00362474145
Iter: 868 loss: 0.00362240779
Iter: 869 loss: 0.00361277978
Iter: 870 loss: 0.0036301529
Iter: 871 loss: 0.00360862538
Iter: 872 loss: 0.00360626122
Iter: 873 loss: 0.00360483257
Iter: 874 loss: 0.00360294478
Iter: 875 loss: 0.00360214943
Iter: 876 loss: 0.00360116339
Iter: 877 loss: 0.00359606976
Iter: 878 loss: 0.00360640557
Iter: 879 loss: 0.00359399524
Iter: 880 loss: 0.0035942914
Iter: 881 loss: 0.00359093398
Iter: 882 loss: 0.00358964968
Iter: 883 loss: 0.0035939482
Iter: 884 loss: 0.00358928903
Iter: 885 loss: 0.00358513882
Iter: 886 loss: 0.00357987499
Iter: 887 loss: 0.00357946474
Iter: 888 loss: 0.003576471
Iter: 889 loss: 0.00357565074
Iter: 890 loss: 0.00357305235
Iter: 891 loss: 0.00356604392
Iter: 892 loss: 0.00361383869
Iter: 893 loss: 0.00356435846
Iter: 894 loss: 0.00355969928
Iter: 895 loss: 0.00355969975
Iter: 896 loss: 0.00355834374
Iter: 897 loss: 0.00355734164
Iter: 898 loss: 0.00355689717
Iter: 899 loss: 0.0035535288
Iter: 900 loss: 0.00354541442
Iter: 901 loss: 0.00363336736
Iter: 902 loss: 0.00354456343
Iter: 903 loss: 0.00353479479
Iter: 904 loss: 0.00353746046
Iter: 905 loss: 0.00352770556
Iter: 906 loss: 0.00351295923
Iter: 907 loss: 0.00354468939
Iter: 908 loss: 0.00350709353
Iter: 909 loss: 0.00350666442
Iter: 910 loss: 0.00350140105
Iter: 911 loss: 0.00349912373
Iter: 912 loss: 0.00350592937
Iter: 913 loss: 0.0034984434
Iter: 914 loss: 0.00349510554
Iter: 915 loss: 0.00348650687
Iter: 916 loss: 0.00355789741
Iter: 917 loss: 0.00348500768
Iter: 918 loss: 0.00348013733
Iter: 919 loss: 0.00349969743
Iter: 920 loss: 0.0034790379
Iter: 921 loss: 0.00347731682
Iter: 922 loss: 0.00347588351
Iter: 923 loss: 0.00347539759
Iter: 924 loss: 0.00347242551
Iter: 925 loss: 0.00350721413
Iter: 926 loss: 0.00347239664
Iter: 927 loss: 0.00346945482
Iter: 928 loss: 0.00348442164
Iter: 929 loss: 0.00346897286
Iter: 930 loss: 0.00346512813
Iter: 931 loss: 0.00345675042
Iter: 932 loss: 0.00358871697
Iter: 933 loss: 0.00345641142
Iter: 934 loss: 0.00344625395
Iter: 935 loss: 0.00346521335
Iter: 936 loss: 0.00344197871
Iter: 937 loss: 0.00343839359
Iter: 938 loss: 0.00343197444
Iter: 939 loss: 0.00359340059
Iter: 940 loss: 0.00343197817
Iter: 941 loss: 0.00342130358
Iter: 942 loss: 0.00347529445
Iter: 943 loss: 0.00341944164
Iter: 944 loss: 0.00341289677
Iter: 945 loss: 0.00346471206
Iter: 946 loss: 0.00341241783
Iter: 947 loss: 0.00341458758
Iter: 948 loss: 0.00341107347
Iter: 949 loss: 0.00340972538
Iter: 950 loss: 0.00340729975
Iter: 951 loss: 0.00346690789
Iter: 952 loss: 0.00340730697
Iter: 953 loss: 0.00340559077
Iter: 954 loss: 0.00340462895
Iter: 955 loss: 0.00340386597
Iter: 956 loss: 0.00339947687
Iter: 957 loss: 0.00339199603
Iter: 958 loss: 0.00339198834
Iter: 959 loss: 0.00338147045
Iter: 960 loss: 0.0034311777
Iter: 961 loss: 0.00337953074
Iter: 962 loss: 0.0033761065
Iter: 963 loss: 0.00337606063
Iter: 964 loss: 0.00337298936
Iter: 965 loss: 0.00337649789
Iter: 966 loss: 0.00337132812
Iter: 967 loss: 0.00336702075
Iter: 968 loss: 0.00343051809
Iter: 969 loss: 0.0033670105
Iter: 970 loss: 0.00336488
Iter: 971 loss: 0.00336399185
Iter: 972 loss: 0.00336287636
Iter: 973 loss: 0.00336044631
Iter: 974 loss: 0.00335663697
Iter: 975 loss: 0.00335659762
Iter: 976 loss: 0.00335429609
Iter: 977 loss: 0.00335354963
Iter: 978 loss: 0.00335221738
Iter: 979 loss: 0.00335018197
Iter: 980 loss: 0.00334996078
Iter: 981 loss: 0.00334848417
Iter: 982 loss: 0.00334544154
Iter: 983 loss: 0.00334597798
Iter: 984 loss: 0.00334317028
Iter: 985 loss: 0.00333777536
Iter: 986 loss: 0.00335077173
Iter: 987 loss: 0.00333586
Iter: 988 loss: 0.00333179487
Iter: 989 loss: 0.00332632521
Iter: 990 loss: 0.00332602765
Iter: 991 loss: 0.00331925624
Iter: 992 loss: 0.00333207054
Iter: 993 loss: 0.00331635331
Iter: 994 loss: 0.00330883
Iter: 995 loss: 0.00335080922
Iter: 996 loss: 0.00330771739
Iter: 997 loss: 0.00331234885
Iter: 998 loss: 0.00330436276
Iter: 999 loss: 0.00330320885
Iter: 1000 loss: 0.00330343191
Iter: 1001 loss: 0.00330234622
Iter: 1002 loss: 0.00330100069
Iter: 1003 loss: 0.0033005951
Iter: 1004 loss: 0.00329978671
Iter: 1005 loss: 0.00329842558
Iter: 1006 loss: 0.00329522742
Iter: 1007 loss: 0.00333279604
Iter: 1008 loss: 0.0032949592
Iter: 1009 loss: 0.00329050934
Iter: 1010 loss: 0.00329558807
Iter: 1011 loss: 0.00328812189
Iter: 1012 loss: 0.00328670838
Iter: 1013 loss: 0.00328542897
Iter: 1014 loss: 0.00328308577
Iter: 1015 loss: 0.00330240512
Iter: 1016 loss: 0.0032829321
Iter: 1017 loss: 0.00328181242
Iter: 1018 loss: 0.00327971391
Iter: 1019 loss: 0.00332562532
Iter: 1020 loss: 0.00327971205
Iter: 1021 loss: 0.00327753276
Iter: 1022 loss: 0.00327644567
Iter: 1023 loss: 0.00327542657
Iter: 1024 loss: 0.00327251619
Iter: 1025 loss: 0.00327682425
Iter: 1026 loss: 0.00327112922
Iter: 1027 loss: 0.00326799066
Iter: 1028 loss: 0.00326090516
Iter: 1029 loss: 0.00335667189
Iter: 1030 loss: 0.00326048722
Iter: 1031 loss: 0.00326573709
Iter: 1032 loss: 0.00325863296
Iter: 1033 loss: 0.00325718988
Iter: 1034 loss: 0.003270366
Iter: 1035 loss: 0.00325712934
Iter: 1036 loss: 0.00325631816
Iter: 1037 loss: 0.00325478404
Iter: 1038 loss: 0.00328712352
Iter: 1039 loss: 0.00325477798
Iter: 1040 loss: 0.00325284759
Iter: 1041 loss: 0.00324901938
Iter: 1042 loss: 0.00332345162
Iter: 1043 loss: 0.00324897631
Iter: 1044 loss: 0.00324666104
Iter: 1045 loss: 0.00325057562
Iter: 1046 loss: 0.00324560935
Iter: 1047 loss: 0.00324282283
Iter: 1048 loss: 0.00324929273
Iter: 1049 loss: 0.00324178883
Iter: 1050 loss: 0.00323972665
Iter: 1051 loss: 0.0032651443
Iter: 1052 loss: 0.00323969917
Iter: 1053 loss: 0.00323806331
Iter: 1054 loss: 0.00324278139
Iter: 1055 loss: 0.00323756598
Iter: 1056 loss: 0.00323594129
Iter: 1057 loss: 0.0032330323
Iter: 1058 loss: 0.00330381235
Iter: 1059 loss: 0.003233033
Iter: 1060 loss: 0.00322718499
Iter: 1061 loss: 0.00322197424
Iter: 1062 loss: 0.00322049251
Iter: 1063 loss: 0.00321715954
Iter: 1064 loss: 0.00321436813
Iter: 1065 loss: 0.00321109709
Iter: 1066 loss: 0.00323305465
Iter: 1067 loss: 0.00321076182
Iter: 1068 loss: 0.00320880581
Iter: 1069 loss: 0.00321283983
Iter: 1070 loss: 0.0032080235
Iter: 1071 loss: 0.00320592197
Iter: 1072 loss: 0.00320756412
Iter: 1073 loss: 0.0032046414
Iter: 1074 loss: 0.00320048048
Iter: 1075 loss: 0.00320876576
Iter: 1076 loss: 0.00319876894
Iter: 1077 loss: 0.00319536263
Iter: 1078 loss: 0.00319615682
Iter: 1079 loss: 0.0031928469
Iter: 1080 loss: 0.00319150696
Iter: 1081 loss: 0.003191364
Iter: 1082 loss: 0.00318989158
Iter: 1083 loss: 0.00321275811
Iter: 1084 loss: 0.00318988925
Iter: 1085 loss: 0.00318917911
Iter: 1086 loss: 0.00318836374
Iter: 1087 loss: 0.00318825757
Iter: 1088 loss: 0.00318690715
Iter: 1089 loss: 0.00318537792
Iter: 1090 loss: 0.00318518281
Iter: 1091 loss: 0.00318343798
Iter: 1092 loss: 0.00318042329
Iter: 1093 loss: 0.0031804163
Iter: 1094 loss: 0.00317736506
Iter: 1095 loss: 0.00318473903
Iter: 1096 loss: 0.00317626935
Iter: 1097 loss: 0.00317465141
Iter: 1098 loss: 0.00317450985
Iter: 1099 loss: 0.00317338784
Iter: 1100 loss: 0.00317337597
Iter: 1101 loss: 0.0031724826
Iter: 1102 loss: 0.00317053124
Iter: 1103 loss: 0.00318157231
Iter: 1104 loss: 0.0031702756
Iter: 1105 loss: 0.00316871423
Iter: 1106 loss: 0.00316756871
Iter: 1107 loss: 0.00316704065
Iter: 1108 loss: 0.00316504203
Iter: 1109 loss: 0.00316420943
Iter: 1110 loss: 0.00316316774
Iter: 1111 loss: 0.00316000101
Iter: 1112 loss: 0.00315379677
Iter: 1113 loss: 0.00328009529
Iter: 1114 loss: 0.00315376651
Iter: 1115 loss: 0.00315986131
Iter: 1116 loss: 0.00315078301
Iter: 1117 loss: 0.00314902468
Iter: 1118 loss: 0.00315126148
Iter: 1119 loss: 0.00314812
Iter: 1120 loss: 0.0031468384
Iter: 1121 loss: 0.00314526679
Iter: 1122 loss: 0.00314512919
Iter: 1123 loss: 0.00314304675
Iter: 1124 loss: 0.00313750911
Iter: 1125 loss: 0.00317800883
Iter: 1126 loss: 0.00313631957
Iter: 1127 loss: 0.00313261058
Iter: 1128 loss: 0.00312846643
Iter: 1129 loss: 0.00312790787
Iter: 1130 loss: 0.00313172303
Iter: 1131 loss: 0.00312611554
Iter: 1132 loss: 0.0031248515
Iter: 1133 loss: 0.00312333088
Iter: 1134 loss: 0.00312318699
Iter: 1135 loss: 0.00312297372
Iter: 1136 loss: 0.00311993388
Iter: 1137 loss: 0.00311612571
Iter: 1138 loss: 0.00312760659
Iter: 1139 loss: 0.00311496179
Iter: 1140 loss: 0.00311367586
Iter: 1141 loss: 0.00310990587
Iter: 1142 loss: 0.00312364521
Iter: 1143 loss: 0.00310824811
Iter: 1144 loss: 0.00310460292
Iter: 1145 loss: 0.00310707628
Iter: 1146 loss: 0.00310230628
Iter: 1147 loss: 0.00310030789
Iter: 1148 loss: 0.00311541278
Iter: 1149 loss: 0.00310015935
Iter: 1150 loss: 0.00309792114
Iter: 1151 loss: 0.00309668249
Iter: 1152 loss: 0.00309569109
Iter: 1153 loss: 0.00309379678
Iter: 1154 loss: 0.0031033135
Iter: 1155 loss: 0.00309349783
Iter: 1156 loss: 0.00309236255
Iter: 1157 loss: 0.00309166545
Iter: 1158 loss: 0.00309121143
Iter: 1159 loss: 0.00309014926
Iter: 1160 loss: 0.00308803981
Iter: 1161 loss: 0.00312802149
Iter: 1162 loss: 0.00308801327
Iter: 1163 loss: 0.00308506237
Iter: 1164 loss: 0.003086827
Iter: 1165 loss: 0.00308316341
Iter: 1166 loss: 0.00308004371
Iter: 1167 loss: 0.00307150953
Iter: 1168 loss: 0.00312212948
Iter: 1169 loss: 0.00306918658
Iter: 1170 loss: 0.00307554519
Iter: 1171 loss: 0.00306627085
Iter: 1172 loss: 0.00306350901
Iter: 1173 loss: 0.00306350505
Iter: 1174 loss: 0.00306237489
Iter: 1175 loss: 0.0030585276
Iter: 1176 loss: 0.00305618206
Iter: 1177 loss: 0.0030537229
Iter: 1178 loss: 0.00304782856
Iter: 1179 loss: 0.00304385088
Iter: 1180 loss: 0.00304166856
Iter: 1181 loss: 0.00305056782
Iter: 1182 loss: 0.00304060965
Iter: 1183 loss: 0.00303967716
Iter: 1184 loss: 0.00303898426
Iter: 1185 loss: 0.00303867552
Iter: 1186 loss: 0.00303715
Iter: 1187 loss: 0.00303679029
Iter: 1188 loss: 0.00303582102
Iter: 1189 loss: 0.00303969858
Iter: 1190 loss: 0.00303504523
Iter: 1191 loss: 0.00303393602
Iter: 1192 loss: 0.00303134974
Iter: 1193 loss: 0.00306310318
Iter: 1194 loss: 0.00303114485
Iter: 1195 loss: 0.00303028803
Iter: 1196 loss: 0.00302975206
Iter: 1197 loss: 0.00302941026
Iter: 1198 loss: 0.00302745402
Iter: 1199 loss: 0.00302597112
Iter: 1200 loss: 0.00302534387
Iter: 1201 loss: 0.00302318321
Iter: 1202 loss: 0.00302297156
Iter: 1203 loss: 0.00302177365
Iter: 1204 loss: 0.00303300936
Iter: 1205 loss: 0.00302172313
Iter: 1206 loss: 0.00302039436
Iter: 1207 loss: 0.00301948353
Iter: 1208 loss: 0.00301899901
Iter: 1209 loss: 0.00301752542
Iter: 1210 loss: 0.00301409094
Iter: 1211 loss: 0.00305571477
Iter: 1212 loss: 0.00301381014
Iter: 1213 loss: 0.00301390421
Iter: 1214 loss: 0.00301200105
Iter: 1215 loss: 0.00301093282
Iter: 1216 loss: 0.00301188417
Iter: 1217 loss: 0.00301029696
Iter: 1218 loss: 0.00300895912
Iter: 1219 loss: 0.00300598936
Iter: 1220 loss: 0.00304828165
Iter: 1221 loss: 0.00300583709
Iter: 1222 loss: 0.0030043337
Iter: 1223 loss: 0.00300098257
Iter: 1224 loss: 0.00304843206
Iter: 1225 loss: 0.00300082704
Iter: 1226 loss: 0.00300332555
Iter: 1227 loss: 0.00299999444
Iter: 1228 loss: 0.00299927313
Iter: 1229 loss: 0.00299842097
Iter: 1230 loss: 0.0029983297
Iter: 1231 loss: 0.00299664633
Iter: 1232 loss: 0.00299460976
Iter: 1233 loss: 0.00299441
Iter: 1234 loss: 0.00299117574
Iter: 1235 loss: 0.00299101742
Iter: 1236 loss: 0.00298925559
Iter: 1237 loss: 0.00300036091
Iter: 1238 loss: 0.00298904721
Iter: 1239 loss: 0.00298781483
Iter: 1240 loss: 0.00299749617
Iter: 1241 loss: 0.00298772799
Iter: 1242 loss: 0.00298554846
Iter: 1243 loss: 0.00298505789
Iter: 1244 loss: 0.00298365252
Iter: 1245 loss: 0.00298031652
Iter: 1246 loss: 0.00298032025
Iter: 1247 loss: 0.00298021873
Iter: 1248 loss: 0.00297896611
Iter: 1249 loss: 0.00297844
Iter: 1250 loss: 0.00297667459
Iter: 1251 loss: 0.00297559309
Iter: 1252 loss: 0.00297446456
Iter: 1253 loss: 0.00297187478
Iter: 1254 loss: 0.00297333603
Iter: 1255 loss: 0.00297018792
Iter: 1256 loss: 0.00296871201
Iter: 1257 loss: 0.00297478191
Iter: 1258 loss: 0.00296839094
Iter: 1259 loss: 0.00296720257
Iter: 1260 loss: 0.00297931768
Iter: 1261 loss: 0.00296716508
Iter: 1262 loss: 0.00296652131
Iter: 1263 loss: 0.0029657823
Iter: 1264 loss: 0.00296568708
Iter: 1265 loss: 0.00296482304
Iter: 1266 loss: 0.0029630803
Iter: 1267 loss: 0.00299533
Iter: 1268 loss: 0.00296305725
Iter: 1269 loss: 0.00296137948
Iter: 1270 loss: 0.00295797572
Iter: 1271 loss: 0.00302113732
Iter: 1272 loss: 0.00295792567
Iter: 1273 loss: 0.00295509514
Iter: 1274 loss: 0.00295430468
Iter: 1275 loss: 0.00295257615
Iter: 1276 loss: 0.0029489398
Iter: 1277 loss: 0.00295778224
Iter: 1278 loss: 0.00294763292
Iter: 1279 loss: 0.00294561032
Iter: 1280 loss: 0.00294550462
Iter: 1281 loss: 0.00295465556
Iter: 1282 loss: 0.00294482335
Iter: 1283 loss: 0.00294426084
Iter: 1284 loss: 0.00294272276
Iter: 1285 loss: 0.00295089092
Iter: 1286 loss: 0.00294224126
Iter: 1287 loss: 0.00294197397
Iter: 1288 loss: 0.0029412203
Iter: 1289 loss: 0.00294040656
Iter: 1290 loss: 0.0029404
Iter: 1291 loss: 0.00294005312
Iter: 1292 loss: 0.00293988828
Iter: 1293 loss: 0.00293971668
Iter: 1294 loss: 0.00293891481
Iter: 1295 loss: 0.00293834321
Iter: 1296 loss: 0.00293805776
Iter: 1297 loss: 0.00293620024
Iter: 1298 loss: 0.00293242279
Iter: 1299 loss: 0.00300045963
Iter: 1300 loss: 0.0029323583
Iter: 1301 loss: 0.00292957202
Iter: 1302 loss: 0.00292955525
Iter: 1303 loss: 0.00292786281
Iter: 1304 loss: 0.00292670121
Iter: 1305 loss: 0.00292607187
Iter: 1306 loss: 0.00292476639
Iter: 1307 loss: 0.00292397174
Iter: 1308 loss: 0.00292343693
Iter: 1309 loss: 0.00292203273
Iter: 1310 loss: 0.00292038126
Iter: 1311 loss: 0.00292020617
Iter: 1312 loss: 0.00291775796
Iter: 1313 loss: 0.00291328947
Iter: 1314 loss: 0.00301774149
Iter: 1315 loss: 0.00291329389
Iter: 1316 loss: 0.0029085509
Iter: 1317 loss: 0.00292422087
Iter: 1318 loss: 0.00290723378
Iter: 1319 loss: 0.00290448172
Iter: 1320 loss: 0.00290420465
Iter: 1321 loss: 0.00290244538
Iter: 1322 loss: 0.00290230848
Iter: 1323 loss: 0.00290105212
Iter: 1324 loss: 0.0029079481
Iter: 1325 loss: 0.00290087657
Iter: 1326 loss: 0.00290014106
Iter: 1327 loss: 0.00289818551
Iter: 1328 loss: 0.00291269971
Iter: 1329 loss: 0.00289776945
Iter: 1330 loss: 0.00289552426
Iter: 1331 loss: 0.0029084133
Iter: 1332 loss: 0.00289521134
Iter: 1333 loss: 0.00289359665
Iter: 1334 loss: 0.00289024133
Iter: 1335 loss: 0.00294938521
Iter: 1336 loss: 0.00289016776
Iter: 1337 loss: 0.0028929445
Iter: 1338 loss: 0.00288889743
Iter: 1339 loss: 0.00288794818
Iter: 1340 loss: 0.00289623253
Iter: 1341 loss: 0.00288789649
Iter: 1342 loss: 0.00288733118
Iter: 1343 loss: 0.00288541662
Iter: 1344 loss: 0.00288343662
Iter: 1345 loss: 0.00288267946
Iter: 1346 loss: 0.00287982821
Iter: 1347 loss: 0.00287980447
Iter: 1348 loss: 0.00287798606
Iter: 1349 loss: 0.00287377043
Iter: 1350 loss: 0.00292630447
Iter: 1351 loss: 0.00287343515
Iter: 1352 loss: 0.00287147053
Iter: 1353 loss: 0.00288027339
Iter: 1354 loss: 0.00287109287
Iter: 1355 loss: 0.00287077925
Iter: 1356 loss: 0.00287000462
Iter: 1357 loss: 0.00287777488
Iter: 1358 loss: 0.00286991149
Iter: 1359 loss: 0.00286863768
Iter: 1360 loss: 0.00286785397
Iter: 1361 loss: 0.0028673429
Iter: 1362 loss: 0.00286525
Iter: 1363 loss: 0.00286739133
Iter: 1364 loss: 0.00286408048
Iter: 1365 loss: 0.00286220596
Iter: 1366 loss: 0.00287773903
Iter: 1367 loss: 0.0028620977
Iter: 1368 loss: 0.00286053494
Iter: 1369 loss: 0.002869257
Iter: 1370 loss: 0.00286031188
Iter: 1371 loss: 0.00285855029
Iter: 1372 loss: 0.00285621593
Iter: 1373 loss: 0.0028560753
Iter: 1374 loss: 0.00286512217
Iter: 1375 loss: 0.00285512814
Iter: 1376 loss: 0.00285462849
Iter: 1377 loss: 0.00285356073
Iter: 1378 loss: 0.00287005305
Iter: 1379 loss: 0.00285352464
Iter: 1380 loss: 0.00285087782
Iter: 1381 loss: 0.00285078492
Iter: 1382 loss: 0.00284873275
Iter: 1383 loss: 0.00284516253
Iter: 1384 loss: 0.00287632341
Iter: 1385 loss: 0.00284496928
Iter: 1386 loss: 0.00284326123
Iter: 1387 loss: 0.00284314016
Iter: 1388 loss: 0.00284151337
Iter: 1389 loss: 0.00285166409
Iter: 1390 loss: 0.002841332
Iter: 1391 loss: 0.00284073921
Iter: 1392 loss: 0.00283901673
Iter: 1393 loss: 0.00284552877
Iter: 1394 loss: 0.00283827446
Iter: 1395 loss: 0.00283680577
Iter: 1396 loss: 0.00283906842
Iter: 1397 loss: 0.0028361117
Iter: 1398 loss: 0.00283570448
Iter: 1399 loss: 0.00283472566
Iter: 1400 loss: 0.00284551131
Iter: 1401 loss: 0.00283463136
Iter: 1402 loss: 0.00283342367
Iter: 1403 loss: 0.00283236057
Iter: 1404 loss: 0.00283204671
Iter: 1405 loss: 0.0028307545
Iter: 1406 loss: 0.00282896915
Iter: 1407 loss: 0.00282889418
Iter: 1408 loss: 0.00282758754
Iter: 1409 loss: 0.00282749091
Iter: 1410 loss: 0.00282580545
Iter: 1411 loss: 0.00284716161
Iter: 1412 loss: 0.00282578962
Iter: 1413 loss: 0.00282449182
Iter: 1414 loss: 0.0028211039
Iter: 1415 loss: 0.002847492
Iter: 1416 loss: 0.00282045733
Iter: 1417 loss: 0.00281743333
Iter: 1418 loss: 0.00281718234
Iter: 1419 loss: 0.00281502632
Iter: 1420 loss: 0.0028146673
Iter: 1421 loss: 0.00281317765
Iter: 1422 loss: 0.00281285541
Iter: 1423 loss: 0.00281175063
Iter: 1424 loss: 0.00281054014
Iter: 1425 loss: 0.00282317121
Iter: 1426 loss: 0.00281051779
Iter: 1427 loss: 0.00281020976
Iter: 1428 loss: 0.00280987
Iter: 1429 loss: 0.00280982628
Iter: 1430 loss: 0.00280915853
Iter: 1431 loss: 0.00281145936
Iter: 1432 loss: 0.00280899042
Iter: 1433 loss: 0.00280829426
Iter: 1434 loss: 0.00280739833
Iter: 1435 loss: 0.00280733034
Iter: 1436 loss: 0.00280575128
Iter: 1437 loss: 0.00280780159
Iter: 1438 loss: 0.00280494499
Iter: 1439 loss: 0.00280396291
Iter: 1440 loss: 0.00280293077
Iter: 1441 loss: 0.00280275848
Iter: 1442 loss: 0.00280107022
Iter: 1443 loss: 0.00280592
Iter: 1444 loss: 0.00280054612
Iter: 1445 loss: 0.00279945601
Iter: 1446 loss: 0.00281303702
Iter: 1447 loss: 0.0027994446
Iter: 1448 loss: 0.00279851118
Iter: 1449 loss: 0.00279758195
Iter: 1450 loss: 0.00279739662
Iter: 1451 loss: 0.00279565551
Iter: 1452 loss: 0.00280276197
Iter: 1453 loss: 0.00279527204
Iter: 1454 loss: 0.00279414235
Iter: 1455 loss: 0.00279383152
Iter: 1456 loss: 0.00279313885
Iter: 1457 loss: 0.00279374677
Iter: 1458 loss: 0.00279263081
Iter: 1459 loss: 0.00279236259
Iter: 1460 loss: 0.00279158261
Iter: 1461 loss: 0.00279494352
Iter: 1462 loss: 0.00279128109
Iter: 1463 loss: 0.00279231579
Iter: 1464 loss: 0.00279001566
Iter: 1465 loss: 0.00278770598
Iter: 1466 loss: 0.00278847106
Iter: 1467 loss: 0.00278607244
Iter: 1468 loss: 0.0027852389
Iter: 1469 loss: 0.002785597
Iter: 1470 loss: 0.00278467173
Iter: 1471 loss: 0.00278322
Iter: 1472 loss: 0.00278571644
Iter: 1473 loss: 0.00278258021
Iter: 1474 loss: 0.0027814256
Iter: 1475 loss: 0.00278100418
Iter: 1476 loss: 0.0027803604
Iter: 1477 loss: 0.00277844304
Iter: 1478 loss: 0.00278486335
Iter: 1479 loss: 0.00277791917
Iter: 1480 loss: 0.00277605071
Iter: 1481 loss: 0.00280010421
Iter: 1482 loss: 0.00277604209
Iter: 1483 loss: 0.00277542137
Iter: 1484 loss: 0.0027766868
Iter: 1485 loss: 0.00277516712
Iter: 1486 loss: 0.00277454359
Iter: 1487 loss: 0.00277406117
Iter: 1488 loss: 0.00277386839
Iter: 1489 loss: 0.002773955
Iter: 1490 loss: 0.00277321972
Iter: 1491 loss: 0.00277223019
Iter: 1492 loss: 0.00276923785
Iter: 1493 loss: 0.00277880253
Iter: 1494 loss: 0.00276779803
Iter: 1495 loss: 0.00276692095
Iter: 1496 loss: 0.00277987542
Iter: 1497 loss: 0.00276692351
Iter: 1498 loss: 0.00276608486
Iter: 1499 loss: 0.00276644155
Iter: 1500 loss: 0.00276551466
Iter: 1501 loss: 0.00276464317
Iter: 1502 loss: 0.00276412535
Iter: 1503 loss: 0.00276376074
Iter: 1504 loss: 0.00276159286
Iter: 1505 loss: 0.00277252495
Iter: 1506 loss: 0.00276122685
Iter: 1507 loss: 0.00275915954
Iter: 1508 loss: 0.00276595936
Iter: 1509 loss: 0.00275858305
Iter: 1510 loss: 0.00275688153
Iter: 1511 loss: 0.00275684102
Iter: 1512 loss: 0.00275566103
Iter: 1513 loss: 0.00276506785
Iter: 1514 loss: 0.00275558094
Iter: 1515 loss: 0.00275450782
Iter: 1516 loss: 0.00275442703
Iter: 1517 loss: 0.00275362935
Iter: 1518 loss: 0.00275229267
Iter: 1519 loss: 0.00275785755
Iter: 1520 loss: 0.00275200536
Iter: 1521 loss: 0.0027512447
Iter: 1522 loss: 0.00275691506
Iter: 1523 loss: 0.00275118602
Iter: 1524 loss: 0.00275035016
Iter: 1525 loss: 0.00275150547
Iter: 1526 loss: 0.00274992152
Iter: 1527 loss: 0.00274951197
Iter: 1528 loss: 0.00275017042
Iter: 1529 loss: 0.00274931826
Iter: 1530 loss: 0.00274859159
Iter: 1531 loss: 0.00275137136
Iter: 1532 loss: 0.00274842139
Iter: 1533 loss: 0.00274808612
Iter: 1534 loss: 0.00274702907
Iter: 1535 loss: 0.00274782814
Iter: 1536 loss: 0.00274613197
Iter: 1537 loss: 0.00274430495
Iter: 1538 loss: 0.00274903
Iter: 1539 loss: 0.00274368562
Iter: 1540 loss: 0.00274284836
Iter: 1541 loss: 0.00274134148
Iter: 1542 loss: 0.00277837622
Iter: 1543 loss: 0.00274133869
Iter: 1544 loss: 0.00273965648
Iter: 1545 loss: 0.00274142972
Iter: 1546 loss: 0.00273873331
Iter: 1547 loss: 0.0027377787
Iter: 1548 loss: 0.00274515059
Iter: 1549 loss: 0.00273771095
Iter: 1550 loss: 0.0027365142
Iter: 1551 loss: 0.00273885671
Iter: 1552 loss: 0.0027360227
Iter: 1553 loss: 0.00273477146
Iter: 1554 loss: 0.0027422735
Iter: 1555 loss: 0.00273462199
Iter: 1556 loss: 0.00273388717
Iter: 1557 loss: 0.00273388694
Iter: 1558 loss: 0.00273351511
Iter: 1559 loss: 0.00273269415
Iter: 1560 loss: 0.00274518412
Iter: 1561 loss: 0.00273266807
Iter: 1562 loss: 0.00273166969
Iter: 1563 loss: 0.00273428904
Iter: 1564 loss: 0.00273133349
Iter: 1565 loss: 0.00273168087
Iter: 1566 loss: 0.00273070554
Iter: 1567 loss: 0.00273037143
Iter: 1568 loss: 0.00272920332
Iter: 1569 loss: 0.00272833928
Iter: 1570 loss: 0.00272769411
Iter: 1571 loss: 0.00272611761
Iter: 1572 loss: 0.00272744708
Iter: 1573 loss: 0.00272517512
Iter: 1574 loss: 0.0027239034
Iter: 1575 loss: 0.00272103376
Iter: 1576 loss: 0.00276078517
Iter: 1577 loss: 0.00272088218
Iter: 1578 loss: 0.00271906448
Iter: 1579 loss: 0.00272225263
Iter: 1580 loss: 0.0027182675
Iter: 1581 loss: 0.00271639228
Iter: 1582 loss: 0.00271925423
Iter: 1583 loss: 0.0027155045
Iter: 1584 loss: 0.00271371077
Iter: 1585 loss: 0.00271887798
Iter: 1586 loss: 0.00271315477
Iter: 1587 loss: 0.00271187117
Iter: 1588 loss: 0.00271102274
Iter: 1589 loss: 0.00271054311
Iter: 1590 loss: 0.00270998245
Iter: 1591 loss: 0.002709541
Iter: 1592 loss: 0.00270809093
Iter: 1593 loss: 0.00270852959
Iter: 1594 loss: 0.00270705228
Iter: 1595 loss: 0.0027058241
Iter: 1596 loss: 0.0027045121
Iter: 1597 loss: 0.00270429533
Iter: 1598 loss: 0.00270378031
Iter: 1599 loss: 0.00270365505
Iter: 1600 loss: 0.00270272279
Iter: 1601 loss: 0.00270206877
Iter: 1602 loss: 0.00270173652
Iter: 1603 loss: 0.00270119356
Iter: 1604 loss: 0.00270115118
Iter: 1605 loss: 0.0027007563
Iter: 1606 loss: 0.00269995979
Iter: 1607 loss: 0.00269811461
Iter: 1608 loss: 0.00272058928
Iter: 1609 loss: 0.00269796723
Iter: 1610 loss: 0.00269599771
Iter: 1611 loss: 0.00271651149
Iter: 1612 loss: 0.0026959423
Iter: 1613 loss: 0.00269441213
Iter: 1614 loss: 0.00270556589
Iter: 1615 loss: 0.0026942871
Iter: 1616 loss: 0.00269290176
Iter: 1617 loss: 0.00269448431
Iter: 1618 loss: 0.00269216462
Iter: 1619 loss: 0.00269059138
Iter: 1620 loss: 0.00269238581
Iter: 1621 loss: 0.0026897504
Iter: 1622 loss: 0.00268862769
Iter: 1623 loss: 0.0026886086
Iter: 1624 loss: 0.00268705329
Iter: 1625 loss: 0.00268750405
Iter: 1626 loss: 0.00268593361
Iter: 1627 loss: 0.00268461974
Iter: 1628 loss: 0.002687125
Iter: 1629 loss: 0.0026840549
Iter: 1630 loss: 0.00268336246
Iter: 1631 loss: 0.00268335314
Iter: 1632 loss: 0.00268253172
Iter: 1633 loss: 0.00268384349
Iter: 1634 loss: 0.00268215127
Iter: 1635 loss: 0.0026817685
Iter: 1636 loss: 0.0026808558
Iter: 1637 loss: 0.00269169779
Iter: 1638 loss: 0.00268078269
Iter: 1639 loss: 0.00267907325
Iter: 1640 loss: 0.00267698802
Iter: 1641 loss: 0.00267678779
Iter: 1642 loss: 0.00267528254
Iter: 1643 loss: 0.00269380375
Iter: 1644 loss: 0.00267526135
Iter: 1645 loss: 0.0026740008
Iter: 1646 loss: 0.00267372234
Iter: 1647 loss: 0.00267290859
Iter: 1648 loss: 0.00267209718
Iter: 1649 loss: 0.00267205294
Iter: 1650 loss: 0.00267130253
Iter: 1651 loss: 0.00266991043
Iter: 1652 loss: 0.00270158029
Iter: 1653 loss: 0.00266990694
Iter: 1654 loss: 0.00266900565
Iter: 1655 loss: 0.00266881427
Iter: 1656 loss: 0.00266752648
Iter: 1657 loss: 0.00267561758
Iter: 1658 loss: 0.00266736676
Iter: 1659 loss: 0.00266721286
Iter: 1660 loss: 0.00266678911
Iter: 1661 loss: 0.00267018331
Iter: 1662 loss: 0.00266670366
Iter: 1663 loss: 0.00266577024
Iter: 1664 loss: 0.00266349339
Iter: 1665 loss: 0.00268798321
Iter: 1666 loss: 0.0026632431
Iter: 1667 loss: 0.00266239373
Iter: 1668 loss: 0.00266226917
Iter: 1669 loss: 0.00266114296
Iter: 1670 loss: 0.00266380678
Iter: 1671 loss: 0.00266071875
Iter: 1672 loss: 0.00265957182
Iter: 1673 loss: 0.00265828543
Iter: 1674 loss: 0.00265810918
Iter: 1675 loss: 0.00265676458
Iter: 1676 loss: 0.00267630862
Iter: 1677 loss: 0.00265676621
Iter: 1678 loss: 0.00265597505
Iter: 1679 loss: 0.0026548407
Iter: 1680 loss: 0.00265480718
Iter: 1681 loss: 0.00265312847
Iter: 1682 loss: 0.00266424636
Iter: 1683 loss: 0.00265294313
Iter: 1684 loss: 0.00265099271
Iter: 1685 loss: 0.00265221065
Iter: 1686 loss: 0.00264974637
Iter: 1687 loss: 0.00265068421
Iter: 1688 loss: 0.00264909072
Iter: 1689 loss: 0.00264855591
Iter: 1690 loss: 0.00264854869
Iter: 1691 loss: 0.00264825765
Iter: 1692 loss: 0.00264751352
Iter: 1693 loss: 0.00265389541
Iter: 1694 loss: 0.00264739571
Iter: 1695 loss: 0.00264547719
Iter: 1696 loss: 0.00264566322
Iter: 1697 loss: 0.00264400686
Iter: 1698 loss: 0.0026426143
Iter: 1699 loss: 0.00264261616
Iter: 1700 loss: 0.00264122477
Iter: 1701 loss: 0.0026431845
Iter: 1702 loss: 0.00264054793
Iter: 1703 loss: 0.00263952487
Iter: 1704 loss: 0.00264039077
Iter: 1705 loss: 0.00263891928
Iter: 1706 loss: 0.00263813301
Iter: 1707 loss: 0.0026385067
Iter: 1708 loss: 0.00263761147
Iter: 1709 loss: 0.0026363316
Iter: 1710 loss: 0.00263605779
Iter: 1711 loss: 0.00263522426
Iter: 1712 loss: 0.00263361563
Iter: 1713 loss: 0.00263361726
Iter: 1714 loss: 0.00263207383
Iter: 1715 loss: 0.00263413182
Iter: 1716 loss: 0.00263129408
Iter: 1717 loss: 0.00263036601
Iter: 1718 loss: 0.00262871734
Iter: 1719 loss: 0.0026287064
Iter: 1720 loss: 0.00263065728
Iter: 1721 loss: 0.00262832479
Iter: 1722 loss: 0.00262817158
Iter: 1723 loss: 0.00262844376
Iter: 1724 loss: 0.00262810243
Iter: 1725 loss: 0.0026272221
Iter: 1726 loss: 0.0026272675
Iter: 1727 loss: 0.00262653152
Iter: 1728 loss: 0.00262602395
Iter: 1729 loss: 0.00262586656
Iter: 1730 loss: 0.00262550404
Iter: 1731 loss: 0.00262514665
Iter: 1732 loss: 0.00262507121
Iter: 1733 loss: 0.00262433197
Iter: 1734 loss: 0.00262213149
Iter: 1735 loss: 0.00262963679
Iter: 1736 loss: 0.00262109097
Iter: 1737 loss: 0.00261948211
Iter: 1738 loss: 0.00261940504
Iter: 1739 loss: 0.00261716917
Iter: 1740 loss: 0.00261643692
Iter: 1741 loss: 0.00261514494
Iter: 1742 loss: 0.00261327694
Iter: 1743 loss: 0.00261895196
Iter: 1744 loss: 0.00261271372
Iter: 1745 loss: 0.00261100428
Iter: 1746 loss: 0.00261601899
Iter: 1747 loss: 0.00261047552
Iter: 1748 loss: 0.00260866527
Iter: 1749 loss: 0.00262826914
Iter: 1750 loss: 0.00260861497
Iter: 1751 loss: 0.00260859169
Iter: 1752 loss: 0.00260833
Iter: 1753 loss: 0.00260801148
Iter: 1754 loss: 0.00260700192
Iter: 1755 loss: 0.0026081875
Iter: 1756 loss: 0.00260623358
Iter: 1757 loss: 0.00260443473
Iter: 1758 loss: 0.00261246646
Iter: 1759 loss: 0.00260409201
Iter: 1760 loss: 0.00260320213
Iter: 1761 loss: 0.00260312157
Iter: 1762 loss: 0.00260229246
Iter: 1763 loss: 0.00260273414
Iter: 1764 loss: 0.0026017474
Iter: 1765 loss: 0.00260110595
Iter: 1766 loss: 0.0025995872
Iter: 1767 loss: 0.00261744088
Iter: 1768 loss: 0.00259944843
Iter: 1769 loss: 0.00259833946
Iter: 1770 loss: 0.00259861303
Iter: 1771 loss: 0.00259752059
Iter: 1772 loss: 0.00259696459
Iter: 1773 loss: 0.00259603863
Iter: 1774 loss: 0.00259603304
Iter: 1775 loss: 0.00259566517
Iter: 1776 loss: 0.00259665074
Iter: 1777 loss: 0.0025955434
Iter: 1778 loss: 0.00259541045
Iter: 1779 loss: 0.00259504048
Iter: 1780 loss: 0.00259672012
Iter: 1781 loss: 0.00259490823
Iter: 1782 loss: 0.00259373127
Iter: 1783 loss: 0.0025940733
Iter: 1784 loss: 0.00259288168
Iter: 1785 loss: 0.00259103859
Iter: 1786 loss: 0.0026060082
Iter: 1787 loss: 0.00259091775
Iter: 1788 loss: 0.00258982508
Iter: 1789 loss: 0.00259504467
Iter: 1790 loss: 0.00258963509
Iter: 1791 loss: 0.00258903555
Iter: 1792 loss: 0.00259699021
Iter: 1793 loss: 0.00258903182
Iter: 1794 loss: 0.00258853892
Iter: 1795 loss: 0.00258853892
Iter: 1796 loss: 0.00258816732
Iter: 1797 loss: 0.00258859806
Iter: 1798 loss: 0.00258797081
Iter: 1799 loss: 0.00258764089
Iter: 1800 loss: 0.00258658431
Iter: 1801 loss: 0.00258755358
Iter: 1802 loss: 0.00258571468
Iter: 1803 loss: 0.00258440152
Iter: 1804 loss: 0.00258710282
Iter: 1805 loss: 0.0025838716
Iter: 1806 loss: 0.00258333771
Iter: 1807 loss: 0.00258171977
Iter: 1808 loss: 0.00258630095
Iter: 1809 loss: 0.00258087437
Iter: 1810 loss: 0.00258162105
Iter: 1811 loss: 0.00258007855
Iter: 1812 loss: 0.00257968111
Iter: 1813 loss: 0.00258018961
Iter: 1814 loss: 0.0025794683
Iter: 1815 loss: 0.00257904897
Iter: 1816 loss: 0.00257795397
Iter: 1817 loss: 0.00258668303
Iter: 1818 loss: 0.00257775304
Iter: 1819 loss: 0.00257819518
Iter: 1820 loss: 0.00257652323
Iter: 1821 loss: 0.00257577701
Iter: 1822 loss: 0.00257365406
Iter: 1823 loss: 0.00258369884
Iter: 1824 loss: 0.00257288525
Iter: 1825 loss: 0.00257075438
Iter: 1826 loss: 0.00258383015
Iter: 1827 loss: 0.00257050246
Iter: 1828 loss: 0.00256838859
Iter: 1829 loss: 0.00257123122
Iter: 1830 loss: 0.00256733224
Iter: 1831 loss: 0.00256562931
Iter: 1832 loss: 0.00258004107
Iter: 1833 loss: 0.00256551802
Iter: 1834 loss: 0.00256464258
Iter: 1835 loss: 0.00256333523
Iter: 1836 loss: 0.00256330939
Iter: 1837 loss: 0.00256267376
Iter: 1838 loss: 0.00256241951
Iter: 1839 loss: 0.00256081624
Iter: 1840 loss: 0.00256265979
Iter: 1841 loss: 0.00255995663
Iter: 1842 loss: 0.00255924324
Iter: 1843 loss: 0.0025606025
Iter: 1844 loss: 0.00255894801
Iter: 1845 loss: 0.00255849119
Iter: 1846 loss: 0.00255771074
Iter: 1847 loss: 0.00255770702
Iter: 1848 loss: 0.00255643483
Iter: 1849 loss: 0.00255630212
Iter: 1850 loss: 0.00255459943
Iter: 1851 loss: 0.00256056548
Iter: 1852 loss: 0.0025541652
Iter: 1853 loss: 0.00255307835
Iter: 1854 loss: 0.00255141361
Iter: 1855 loss: 0.00255138
Iter: 1856 loss: 0.00255032349
Iter: 1857 loss: 0.00255072047
Iter: 1858 loss: 0.00254957844
Iter: 1859 loss: 0.00254894537
Iter: 1860 loss: 0.0025481109
Iter: 1861 loss: 0.00254806504
Iter: 1862 loss: 0.00256775855
Iter: 1863 loss: 0.00254750066
Iter: 1864 loss: 0.00254696608
Iter: 1865 loss: 0.00254632882
Iter: 1866 loss: 0.00254625455
Iter: 1867 loss: 0.00254505221
Iter: 1868 loss: 0.00255081384
Iter: 1869 loss: 0.00254483474
Iter: 1870 loss: 0.00254589785
Iter: 1871 loss: 0.00254450506
Iter: 1872 loss: 0.00254435651
Iter: 1873 loss: 0.00254400889
Iter: 1874 loss: 0.0025477563
Iter: 1875 loss: 0.00254396698
Iter: 1876 loss: 0.00254274253
Iter: 1877 loss: 0.00254562544
Iter: 1878 loss: 0.002542309
Iter: 1879 loss: 0.00254133809
Iter: 1880 loss: 0.0025474485
Iter: 1881 loss: 0.00254122261
Iter: 1882 loss: 0.00254089618
Iter: 1883 loss: 0.00254017441
Iter: 1884 loss: 0.00255102199
Iter: 1885 loss: 0.00254014507
Iter: 1886 loss: 0.00253948802
Iter: 1887 loss: 0.00253822235
Iter: 1888 loss: 0.00256514
Iter: 1889 loss: 0.00253821281
Iter: 1890 loss: 0.00253721024
Iter: 1891 loss: 0.00253719883
Iter: 1892 loss: 0.00253631501
Iter: 1893 loss: 0.0025363
Iter: 1894 loss: 0.00253559602
Iter: 1895 loss: 0.00253504
Iter: 1896 loss: 0.00253803539
Iter: 1897 loss: 0.00253495667
Iter: 1898 loss: 0.00253474084
Iter: 1899 loss: 0.0025340151
Iter: 1900 loss: 0.00253351545
Iter: 1901 loss: 0.00253308844
Iter: 1902 loss: 0.00253123324
Iter: 1903 loss: 0.00253799837
Iter: 1904 loss: 0.0025307727
Iter: 1905 loss: 0.00253059762
Iter: 1906 loss: 0.0025304039
Iter: 1907 loss: 0.00252982229
Iter: 1908 loss: 0.00252886629
Iter: 1909 loss: 0.00252885791
Iter: 1910 loss: 0.00252741622
Iter: 1911 loss: 0.00252521411
Iter: 1912 loss: 0.00252517359
Iter: 1913 loss: 0.00252498314
Iter: 1914 loss: 0.00252407114
Iter: 1915 loss: 0.00252336334
Iter: 1916 loss: 0.00252370583
Iter: 1917 loss: 0.00252288394
Iter: 1918 loss: 0.00252158777
Iter: 1919 loss: 0.0025179293
Iter: 1920 loss: 0.00253643049
Iter: 1921 loss: 0.00251672557
Iter: 1922 loss: 0.00251477
Iter: 1923 loss: 0.0025304358
Iter: 1924 loss: 0.00251462637
Iter: 1925 loss: 0.00251346128
Iter: 1926 loss: 0.00251836353
Iter: 1927 loss: 0.00251321075
Iter: 1928 loss: 0.00251341
Iter: 1929 loss: 0.00251273718
Iter: 1930 loss: 0.00251240353
Iter: 1931 loss: 0.00251140143
Iter: 1932 loss: 0.00251506525
Iter: 1933 loss: 0.00251096417
Iter: 1934 loss: 0.00250830967
Iter: 1935 loss: 0.00251425873
Iter: 1936 loss: 0.00250728778
Iter: 1937 loss: 0.00250612199
Iter: 1938 loss: 0.00251328875
Iter: 1939 loss: 0.00250598136
Iter: 1940 loss: 0.00250515644
Iter: 1941 loss: 0.00250999746
Iter: 1942 loss: 0.00250505097
Iter: 1943 loss: 0.00250461977
Iter: 1944 loss: 0.00250374759
Iter: 1945 loss: 0.00251940149
Iter: 1946 loss: 0.00250372617
Iter: 1947 loss: 0.00250306982
Iter: 1948 loss: 0.00250957161
Iter: 1949 loss: 0.00250305096
Iter: 1950 loss: 0.00250267098
Iter: 1951 loss: 0.00250494294
Iter: 1952 loss: 0.0025026293
Iter: 1953 loss: 0.00250229286
Iter: 1954 loss: 0.00250157458
Iter: 1955 loss: 0.00251297187
Iter: 1956 loss: 0.00250155525
Iter: 1957 loss: 0.00250058481
Iter: 1958 loss: 0.00249945675
Iter: 1959 loss: 0.0024993266
Iter: 1960 loss: 0.00249770097
Iter: 1961 loss: 0.00250015361
Iter: 1962 loss: 0.00249692868
Iter: 1963 loss: 0.002496131
Iter: 1964 loss: 0.00249599665
Iter: 1965 loss: 0.00249543879
Iter: 1966 loss: 0.00249539642
Iter: 1967 loss: 0.00249523018
Iter: 1968 loss: 0.0024946332
Iter: 1969 loss: 0.00249310723
Iter: 1970 loss: 0.00252212118
Iter: 1971 loss: 0.00249307742
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8
+ date
Tue Oct 27 20:59:45 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92147241e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f921473fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f921473fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92004e3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92004391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92003ef2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200416f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92003c7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92003d82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92003c7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200398950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200354f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92002fe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200416950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92002ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92002ce950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200297488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200297d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92001fd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f920021b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200294488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92001da598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f920016f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92001a2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92001396a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200139f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f920010d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f920010dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f920010d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f920010d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f92000307b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200051048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200051b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ffff4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9200027a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91fffdb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.173162833
Iter: 2 loss: 11.500679
Iter: 3 loss: 11.4815636
Iter: 4 loss: 6.89104939
Iter: 5 loss: 6.88066816
Iter: 6 loss: 4.34290409
Iter: 7 loss: 4.33594561
Iter: 8 loss: 2.84939814
Iter: 9 loss: 2.8444705
Iter: 10 loss: 1.94350076
Iter: 11 loss: 1.93967152
Iter: 12 loss: 1.36412835
Iter: 13 loss: 1.36078787
Iter: 14 loss: 0.969773531
Iter: 15 loss: 0.966458201
Iter: 16 loss: 0.682276249
Iter: 17 loss: 0.678475738
Iter: 18 loss: 0.460295528
Iter: 19 loss: 0.455818862
Iter: 20 loss: 0.296191931
Iter: 21 loss: 0.291847825
Iter: 22 loss: 0.186536551
Iter: 23 loss: 0.183024883
Iter: 24 loss: 0.120659567
Iter: 25 loss: 0.118585452
Iter: 26 loss: 0.115773186
Iter: 27 loss: 0.104662091
Iter: 28 loss: 0.0915918052
Iter: 29 loss: 0.0807827711
Iter: 30 loss: 835.456726
Iter: 31 loss: 0.0807826594
Iter: 32 loss: 0.0734941363
Iter: 33 loss: 0.0727458
Iter: 34 loss: 0.0722853094
Iter: 35 loss: 0.0676824
Iter: 36 loss: 0.164178118
Iter: 37 loss: 0.065715678
Iter: 38 loss: 0.114295349
Iter: 39 loss: 0.0566483773
Iter: 40 loss: 0.0566612408
Iter: 41 loss: 0.0475268289
Iter: 42 loss: 0.0472221375
Iter: 43 loss: 0.0432839394
Iter: 44 loss: 0.0954319388
Iter: 45 loss: 0.0427161083
Iter: 46 loss: 0.0404436663
Iter: 47 loss: 0.040341083
Iter: 48 loss: 0.0377889052
Iter: 49 loss: 0.0333687179
Iter: 50 loss: 0.0892944932
Iter: 51 loss: 0.0333393663
Iter: 52 loss: 0.0310729779
Iter: 53 loss: 0.0271773264
Iter: 54 loss: 0.0270682499
Iter: 55 loss: 0.0232859347
Iter: 56 loss: 0.046792008
Iter: 57 loss: 0.0223687477
Iter: 58 loss: 0.0176321249
Iter: 59 loss: 0.0382903479
Iter: 60 loss: 0.0170392059
Iter: 61 loss: 0.0149791315
Iter: 62 loss: 0.0309860446
Iter: 63 loss: 0.0149035752
Iter: 64 loss: 0.0132722668
Iter: 65 loss: 0.013575159
Iter: 66 loss: 0.0121321743
Iter: 67 loss: 0.0112562161
Iter: 68 loss: 0.0141510554
Iter: 69 loss: 0.0110938847
Iter: 70 loss: 0.0105328765
Iter: 71 loss: 0.0108259358
Iter: 72 loss: 0.0101198582
Iter: 73 loss: 0.00953093544
Iter: 74 loss: 0.010564439
Iter: 75 loss: 0.00927304663
Iter: 76 loss: 0.00885017402
Iter: 77 loss: 0.00970308
Iter: 78 loss: 0.00870083086
Iter: 79 loss: 0.00835539307
Iter: 80 loss: 0.00830056705
Iter: 81 loss: 0.00806248281
Iter: 82 loss: 0.0160854515
Iter: 83 loss: 0.00789187
Iter: 84 loss: 0.0075682262
Iter: 85 loss: 0.0107120946
Iter: 86 loss: 0.00754406117
Iter: 87 loss: 0.00733499741
Iter: 88 loss: 0.0076401229
Iter: 89 loss: 0.00724495575
Iter: 90 loss: 0.00711007463
Iter: 91 loss: 0.00685775466
Iter: 92 loss: 0.0121774534
Iter: 93 loss: 0.00685706642
Iter: 94 loss: 0.00648289453
Iter: 95 loss: 0.00731783034
Iter: 96 loss: 0.00634769443
Iter: 97 loss: 0.00614676531
Iter: 98 loss: 0.00608206168
Iter: 99 loss: 0.00586918369
Iter: 100 loss: 0.00596909784
Iter: 101 loss: 0.00572712068
Iter: 102 loss: 0.00552838296
Iter: 103 loss: 0.00654724892
Iter: 104 loss: 0.00549605116
Iter: 105 loss: 0.00529844174
Iter: 106 loss: 0.00568532152
Iter: 107 loss: 0.00521939434
Iter: 108 loss: 0.00504418137
Iter: 109 loss: 0.0062237056
Iter: 110 loss: 0.00502097653
Iter: 111 loss: 0.00490930444
Iter: 112 loss: 0.00484538544
Iter: 113 loss: 0.00479867589
Iter: 114 loss: 0.00467334036
Iter: 115 loss: 0.00478820037
Iter: 116 loss: 0.00460015144
Iter: 117 loss: 0.00448586326
Iter: 118 loss: 0.00453385618
Iter: 119 loss: 0.00440941937
Iter: 120 loss: 0.0043375059
Iter: 121 loss: 0.00504253805
Iter: 122 loss: 0.00433338806
Iter: 123 loss: 0.00426310394
Iter: 124 loss: 0.00439794548
Iter: 125 loss: 0.00423555821
Iter: 126 loss: 0.00418155221
Iter: 127 loss: 0.00417911448
Iter: 128 loss: 0.0041376981
Iter: 129 loss: 0.00407727202
Iter: 130 loss: 0.0040034228
Iter: 131 loss: 0.00399663299
Iter: 132 loss: 0.00387355639
Iter: 133 loss: 0.00464896811
Iter: 134 loss: 0.00386065803
Iter: 135 loss: 0.00377932843
Iter: 136 loss: 0.0041004247
Iter: 137 loss: 0.0037622808
Iter: 138 loss: 0.00369620975
Iter: 139 loss: 0.0037289348
Iter: 140 loss: 0.00365266204
Iter: 141 loss: 0.00359916547
Iter: 142 loss: 0.00446364749
Iter: 143 loss: 0.00359891891
Iter: 144 loss: 0.00355980382
Iter: 145 loss: 0.0035522962
Iter: 146 loss: 0.0035266988
Iter: 147 loss: 0.00349487737
Iter: 148 loss: 0.00348894065
Iter: 149 loss: 0.00346743176
Iter: 150 loss: 0.00340681733
Iter: 151 loss: 0.00352342
Iter: 152 loss: 0.00338147767
Iter: 153 loss: 0.00332935224
Iter: 154 loss: 0.00358475442
Iter: 155 loss: 0.00332156336
Iter: 156 loss: 0.00330299931
Iter: 157 loss: 0.0032971
Iter: 158 loss: 0.00328482036
Iter: 159 loss: 0.00327109918
Iter: 160 loss: 0.00326920184
Iter: 161 loss: 0.00323073915
Iter: 162 loss: 0.00319259497
Iter: 163 loss: 0.00318470062
Iter: 164 loss: 0.00311492942
Iter: 165 loss: 0.00311434409
Iter: 166 loss: 0.00307559408
Iter: 167 loss: 0.00323310657
Iter: 168 loss: 0.00306709297
Iter: 169 loss: 0.00303313369
Iter: 170 loss: 0.00305636041
Iter: 171 loss: 0.00301169278
Iter: 172 loss: 0.0029810667
Iter: 173 loss: 0.00325490604
Iter: 174 loss: 0.00297948206
Iter: 175 loss: 0.00295213819
Iter: 176 loss: 0.00310039404
Iter: 177 loss: 0.00294821034
Iter: 178 loss: 0.00293694
Iter: 179 loss: 0.00293595297
Iter: 180 loss: 0.00292936224
Iter: 181 loss: 0.00291030109
Iter: 182 loss: 0.00299146236
Iter: 183 loss: 0.00290282443
Iter: 184 loss: 0.00287966686
Iter: 185 loss: 0.00311796204
Iter: 186 loss: 0.00287914439
Iter: 187 loss: 0.00286594662
Iter: 188 loss: 0.00294573512
Iter: 189 loss: 0.00286417478
Iter: 190 loss: 0.0028461013
Iter: 191 loss: 0.00291589857
Iter: 192 loss: 0.00284224
Iter: 193 loss: 0.00282504922
Iter: 194 loss: 0.0028205812
Iter: 195 loss: 0.00280985283
Iter: 196 loss: 0.0027956916
Iter: 197 loss: 0.00277813384
Iter: 198 loss: 0.00277664233
Iter: 199 loss: 0.00275483821
Iter: 200 loss: 0.00280434405
Iter: 201 loss: 0.00274665095
Iter: 202 loss: 0.00273249438
Iter: 203 loss: 0.00283972174
Iter: 204 loss: 0.00273137586
Iter: 205 loss: 0.00272075087
Iter: 206 loss: 0.00275287591
Iter: 207 loss: 0.00271750614
Iter: 208 loss: 0.00270795543
Iter: 209 loss: 0.00272737537
Iter: 210 loss: 0.00270419335
Iter: 211 loss: 0.00269891415
Iter: 212 loss: 0.00269837165
Iter: 213 loss: 0.0026924219
Iter: 214 loss: 0.00268610567
Iter: 215 loss: 0.0026850577
Iter: 216 loss: 0.00267487508
Iter: 217 loss: 0.00269924523
Iter: 218 loss: 0.0026712562
Iter: 219 loss: 0.00266367337
Iter: 220 loss: 0.00267667184
Iter: 221 loss: 0.002660356
Iter: 222 loss: 0.00264869654
Iter: 223 loss: 0.00271858671
Iter: 224 loss: 0.00264714542
Iter: 225 loss: 0.00264378753
Iter: 226 loss: 0.00263763452
Iter: 227 loss: 0.00277518714
Iter: 228 loss: 0.00263762986
Iter: 229 loss: 0.00263030082
Iter: 230 loss: 0.00267410441
Iter: 231 loss: 0.00262935786
Iter: 232 loss: 0.00262375642
Iter: 233 loss: 0.00262150262
Iter: 234 loss: 0.00261853077
Iter: 235 loss: 0.00261099171
Iter: 236 loss: 0.00261961669
Iter: 237 loss: 0.00260692695
Iter: 238 loss: 0.00259957
Iter: 239 loss: 0.00259955646
Iter: 240 loss: 0.00259516691
Iter: 241 loss: 0.00259840651
Iter: 242 loss: 0.00259248028
Iter: 243 loss: 0.00258612586
Iter: 244 loss: 0.00261132815
Iter: 245 loss: 0.00258465763
Iter: 246 loss: 0.00258395099
Iter: 247 loss: 0.00258143106
Iter: 248 loss: 0.00257968623
Iter: 249 loss: 0.00257539703
Iter: 250 loss: 0.0026183431
Iter: 251 loss: 0.00257487362
Iter: 252 loss: 0.00256969268
Iter: 253 loss: 0.00262278551
Iter: 254 loss: 0.0025695283
Iter: 255 loss: 0.00257149618
Iter: 256 loss: 0.00256606657
Iter: 257 loss: 0.00256459322
Iter: 258 loss: 0.00256111217
Iter: 259 loss: 0.00260193
Iter: 260 loss: 0.00256080017
Iter: 261 loss: 0.00255550398
Iter: 262 loss: 0.00256149704
Iter: 263 loss: 0.00255267
Iter: 264 loss: 0.00254713651
Iter: 265 loss: 0.00262048841
Iter: 266 loss: 0.00254709879
Iter: 267 loss: 0.00254410319
Iter: 268 loss: 0.00253789872
Iter: 269 loss: 0.00264316238
Iter: 270 loss: 0.00253776
Iter: 271 loss: 0.00253378414
Iter: 272 loss: 0.00257302914
Iter: 273 loss: 0.00253364304
Iter: 274 loss: 0.00253038108
Iter: 275 loss: 0.00253067142
Iter: 276 loss: 0.0025278437
Iter: 277 loss: 0.00252390932
Iter: 278 loss: 0.00252515054
Iter: 279 loss: 0.00252110651
Iter: 280 loss: 0.00251832791
Iter: 281 loss: 0.00251930812
Iter: 282 loss: 0.00251636142
Iter: 283 loss: 0.00251361495
Iter: 284 loss: 0.00252389838
Iter: 285 loss: 0.00251296768
Iter: 286 loss: 0.00251187221
Iter: 287 loss: 0.00250950293
Iter: 288 loss: 0.00254609645
Iter: 289 loss: 0.00250940677
Iter: 290 loss: 0.00250663608
Iter: 291 loss: 0.0025027974
Iter: 292 loss: 0.00250263442
Iter: 293 loss: 0.00249756174
Iter: 294 loss: 0.00250051985
Iter: 295 loss: 0.00249427371
Iter: 296 loss: 0.00249009207
Iter: 297 loss: 0.00254052714
Iter: 298 loss: 0.00249003642
Iter: 299 loss: 0.00248617935
Iter: 300 loss: 0.00249398849
Iter: 301 loss: 0.0024846131
Iter: 302 loss: 0.0024818494
Iter: 303 loss: 0.00248911418
Iter: 304 loss: 0.00248092925
Iter: 305 loss: 0.00247752364
Iter: 306 loss: 0.00248863641
Iter: 307 loss: 0.00247658184
Iter: 308 loss: 0.00247379858
Iter: 309 loss: 0.00247052964
Iter: 310 loss: 0.00247016666
Iter: 311 loss: 0.00246738084
Iter: 312 loss: 0.00248248223
Iter: 313 loss: 0.00246697012
Iter: 314 loss: 0.00246443041
Iter: 315 loss: 0.00246297591
Iter: 316 loss: 0.00246189348
Iter: 317 loss: 0.00246117311
Iter: 318 loss: 0.0024597689
Iter: 319 loss: 0.00245897425
Iter: 320 loss: 0.00245670485
Iter: 321 loss: 0.00246702135
Iter: 322 loss: 0.00245587272
Iter: 323 loss: 0.00245269178
Iter: 324 loss: 0.00245148223
Iter: 325 loss: 0.00244974392
Iter: 326 loss: 0.00244603818
Iter: 327 loss: 0.00244861096
Iter: 328 loss: 0.00244372548
Iter: 329 loss: 0.00243954686
Iter: 330 loss: 0.00243939622
Iter: 331 loss: 0.00243724789
Iter: 332 loss: 0.00243494
Iter: 333 loss: 0.00243457244
Iter: 334 loss: 0.00243142759
Iter: 335 loss: 0.00244057039
Iter: 336 loss: 0.00243044
Iter: 337 loss: 0.00242718309
Iter: 338 loss: 0.0024317652
Iter: 339 loss: 0.00242556888
Iter: 340 loss: 0.00242254185
Iter: 341 loss: 0.00245545
Iter: 342 loss: 0.00242247246
Iter: 343 loss: 0.00242007338
Iter: 344 loss: 0.00242573256
Iter: 345 loss: 0.00241920538
Iter: 346 loss: 0.00241704
Iter: 347 loss: 0.00241282582
Iter: 348 loss: 0.00250178296
Iter: 349 loss: 0.00241279742
Iter: 350 loss: 0.00241179275
Iter: 351 loss: 0.0024115839
Iter: 352 loss: 0.00241030054
Iter: 353 loss: 0.00240776688
Iter: 354 loss: 0.00245788461
Iter: 355 loss: 0.00240773987
Iter: 356 loss: 0.00240469421
Iter: 357 loss: 0.00240237219
Iter: 358 loss: 0.0024013822
Iter: 359 loss: 0.00239744363
Iter: 360 loss: 0.00241278298
Iter: 361 loss: 0.00239655026
Iter: 362 loss: 0.00239315443
Iter: 363 loss: 0.00242005754
Iter: 364 loss: 0.00239293
Iter: 365 loss: 0.0023908508
Iter: 366 loss: 0.0024091783
Iter: 367 loss: 0.00239074184
Iter: 368 loss: 0.00238911016
Iter: 369 loss: 0.00238750479
Iter: 370 loss: 0.00238716323
Iter: 371 loss: 0.00238409778
Iter: 372 loss: 0.00239880709
Iter: 373 loss: 0.00238353969
Iter: 374 loss: 0.00238057692
Iter: 375 loss: 0.00238329032
Iter: 376 loss: 0.00237883884
Iter: 377 loss: 0.002376555
Iter: 378 loss: 0.00237654569
Iter: 379 loss: 0.00237458339
Iter: 380 loss: 0.00238443934
Iter: 381 loss: 0.00237426721
Iter: 382 loss: 0.00237296754
Iter: 383 loss: 0.002373653
Iter: 384 loss: 0.00237210258
Iter: 385 loss: 0.00236992794
Iter: 386 loss: 0.00237556081
Iter: 387 loss: 0.00236919383
Iter: 388 loss: 0.00236804737
Iter: 389 loss: 0.00236490509
Iter: 390 loss: 0.00238398556
Iter: 391 loss: 0.00236405572
Iter: 392 loss: 0.00236075418
Iter: 393 loss: 0.002388397
Iter: 394 loss: 0.0023605586
Iter: 395 loss: 0.00235812296
Iter: 396 loss: 0.00236003846
Iter: 397 loss: 0.00235665264
Iter: 398 loss: 0.00235407823
Iter: 399 loss: 0.00237245159
Iter: 400 loss: 0.00235385518
Iter: 401 loss: 0.00235137949
Iter: 402 loss: 0.00235477812
Iter: 403 loss: 0.00235014642
Iter: 404 loss: 0.00234714104
Iter: 405 loss: 0.00236092578
Iter: 406 loss: 0.00234657479
Iter: 407 loss: 0.00234454195
Iter: 408 loss: 0.00234822
Iter: 409 loss: 0.00234365673
Iter: 410 loss: 0.00234146276
Iter: 411 loss: 0.00233971979
Iter: 412 loss: 0.00233904691
Iter: 413 loss: 0.00233583897
Iter: 414 loss: 0.00234962441
Iter: 415 loss: 0.00233517494
Iter: 416 loss: 0.00233962247
Iter: 417 loss: 0.00233439798
Iter: 418 loss: 0.00233395607
Iter: 419 loss: 0.00233343896
Iter: 420 loss: 0.00233337935
Iter: 421 loss: 0.0023324457
Iter: 422 loss: 0.00233056326
Iter: 423 loss: 0.00236603757
Iter: 424 loss: 0.00233053393
Iter: 425 loss: 0.00232843542
Iter: 426 loss: 0.00234677712
Iter: 427 loss: 0.00232832227
Iter: 428 loss: 0.00232688244
Iter: 429 loss: 0.00232416065
Iter: 430 loss: 0.00238428311
Iter: 431 loss: 0.00232415553
Iter: 432 loss: 0.00232205912
Iter: 433 loss: 0.00234068651
Iter: 434 loss: 0.0023219625
Iter: 435 loss: 0.00232051546
Iter: 436 loss: 0.0023209746
Iter: 437 loss: 0.0023194782
Iter: 438 loss: 0.00231735385
Iter: 439 loss: 0.00232042442
Iter: 440 loss: 0.00231632032
Iter: 441 loss: 0.00231412309
Iter: 442 loss: 0.00232655485
Iter: 443 loss: 0.00231380505
Iter: 444 loss: 0.0023122183
Iter: 445 loss: 0.00231629284
Iter: 446 loss: 0.00231167045
Iter: 447 loss: 0.00231042551
Iter: 448 loss: 0.00230905972
Iter: 449 loss: 0.00230886112
Iter: 450 loss: 0.00230722036
Iter: 451 loss: 0.00232185679
Iter: 452 loss: 0.00230713072
Iter: 453 loss: 0.0023057689
Iter: 454 loss: 0.00230576214
Iter: 455 loss: 0.0023052278
Iter: 456 loss: 0.00230372511
Iter: 457 loss: 0.00231144624
Iter: 458 loss: 0.00230323174
Iter: 459 loss: 0.00230170321
Iter: 460 loss: 0.00231506932
Iter: 461 loss: 0.00230162591
Iter: 462 loss: 0.00230044406
Iter: 463 loss: 0.00229942962
Iter: 464 loss: 0.00229911087
Iter: 465 loss: 0.00229721
Iter: 466 loss: 0.00231148209
Iter: 467 loss: 0.00229705451
Iter: 468 loss: 0.00229561306
Iter: 469 loss: 0.00229481375
Iter: 470 loss: 0.00229417719
Iter: 471 loss: 0.0022925837
Iter: 472 loss: 0.0023141047
Iter: 473 loss: 0.00229257904
Iter: 474 loss: 0.00229192851
Iter: 475 loss: 0.00229077856
Iter: 476 loss: 0.00229078392
Iter: 477 loss: 0.00228898553
Iter: 478 loss: 0.00230213441
Iter: 479 loss: 0.00228883466
Iter: 480 loss: 0.00228734245
Iter: 481 loss: 0.00229287148
Iter: 482 loss: 0.00228696782
Iter: 483 loss: 0.00228623906
Iter: 484 loss: 0.00228476804
Iter: 485 loss: 0.00231172121
Iter: 486 loss: 0.00228474848
Iter: 487 loss: 0.00228305534
Iter: 488 loss: 0.00229196437
Iter: 489 loss: 0.00228278479
Iter: 490 loss: 0.00228170818
Iter: 491 loss: 0.00228165044
Iter: 492 loss: 0.00228109863
Iter: 493 loss: 0.00227939431
Iter: 494 loss: 0.00228267559
Iter: 495 loss: 0.00227829674
Iter: 496 loss: 0.00227662455
Iter: 497 loss: 0.00229582051
Iter: 498 loss: 0.00227659894
Iter: 499 loss: 0.00227528368
Iter: 500 loss: 0.0022739619
Iter: 501 loss: 0.00227369554
Iter: 502 loss: 0.00227268296
Iter: 503 loss: 0.00227344
Iter: 504 loss: 0.00227205292
Iter: 505 loss: 0.00227144873
Iter: 506 loss: 0.00227005593
Iter: 507 loss: 0.00228757085
Iter: 508 loss: 0.00226995908
Iter: 509 loss: 0.00226905872
Iter: 510 loss: 0.00226905337
Iter: 511 loss: 0.00226769177
Iter: 512 loss: 0.00226960704
Iter: 513 loss: 0.00226701796
Iter: 514 loss: 0.0022648857
Iter: 515 loss: 0.00227457308
Iter: 516 loss: 0.00226447172
Iter: 517 loss: 0.00226322
Iter: 518 loss: 0.00226116227
Iter: 519 loss: 0.00226115226
Iter: 520 loss: 0.00225983141
Iter: 521 loss: 0.00225983025
Iter: 522 loss: 0.00225876737
Iter: 523 loss: 0.00226445962
Iter: 524 loss: 0.00225860788
Iter: 525 loss: 0.00225813827
Iter: 526 loss: 0.002257674
Iter: 527 loss: 0.00225719577
Iter: 528 loss: 0.00225826586
Iter: 529 loss: 0.0022570088
Iter: 530 loss: 0.00225674408
Iter: 531 loss: 0.00225611427
Iter: 532 loss: 0.00226302608
Iter: 533 loss: 0.00225605164
Iter: 534 loss: 0.00225493172
Iter: 535 loss: 0.00225680461
Iter: 536 loss: 0.00225442671
Iter: 537 loss: 0.00225281529
Iter: 538 loss: 0.00225856877
Iter: 539 loss: 0.00225240551
Iter: 540 loss: 0.00225042831
Iter: 541 loss: 0.00225447118
Iter: 542 loss: 0.00224963063
Iter: 543 loss: 0.00224793027
Iter: 544 loss: 0.00224932795
Iter: 545 loss: 0.00224691117
Iter: 546 loss: 0.00224550534
Iter: 547 loss: 0.00225756061
Iter: 548 loss: 0.00224543037
Iter: 549 loss: 0.00224415958
Iter: 550 loss: 0.00224672491
Iter: 551 loss: 0.00224364409
Iter: 552 loss: 0.00224272977
Iter: 553 loss: 0.00225647446
Iter: 554 loss: 0.00224272814
Iter: 555 loss: 0.00224192766
Iter: 556 loss: 0.00224147853
Iter: 557 loss: 0.00224113301
Iter: 558 loss: 0.00224019727
Iter: 559 loss: 0.00224316982
Iter: 560 loss: 0.00223992765
Iter: 561 loss: 0.00223951507
Iter: 562 loss: 0.00223944848
Iter: 563 loss: 0.00223887339
Iter: 564 loss: 0.00223794486
Iter: 565 loss: 0.00223793788
Iter: 566 loss: 0.00223730342
Iter: 567 loss: 0.00223581144
Iter: 568 loss: 0.00225318456
Iter: 569 loss: 0.00223567802
Iter: 570 loss: 0.00223417417
Iter: 571 loss: 0.00224305014
Iter: 572 loss: 0.00223398209
Iter: 573 loss: 0.00223306986
Iter: 574 loss: 0.00224032393
Iter: 575 loss: 0.00223300676
Iter: 576 loss: 0.00223213853
Iter: 577 loss: 0.0022327085
Iter: 578 loss: 0.00223158579
Iter: 579 loss: 0.00223065261
Iter: 580 loss: 0.00223173713
Iter: 581 loss: 0.00223015738
Iter: 582 loss: 0.00222924398
Iter: 583 loss: 0.00223195227
Iter: 584 loss: 0.00222896226
Iter: 585 loss: 0.00222814153
Iter: 586 loss: 0.00223370153
Iter: 587 loss: 0.002228064
Iter: 588 loss: 0.00222742395
Iter: 589 loss: 0.00223335414
Iter: 590 loss: 0.0022274009
Iter: 591 loss: 0.00222687144
Iter: 592 loss: 0.0022278605
Iter: 593 loss: 0.00222664513
Iter: 594 loss: 0.00222630939
Iter: 595 loss: 0.00222630473
Iter: 596 loss: 0.00222595921
Iter: 597 loss: 0.00222607167
Iter: 598 loss: 0.00222571567
Iter: 599 loss: 0.00222547911
Iter: 600 loss: 0.00222505955
Iter: 601 loss: 0.00222505908
Iter: 602 loss: 0.00222452311
Iter: 603 loss: 0.00222447421
Iter: 604 loss: 0.00222408
Iter: 605 loss: 0.0022234628
Iter: 606 loss: 0.00222522253
Iter: 607 loss: 0.00222327048
Iter: 608 loss: 0.00222244696
Iter: 609 loss: 0.00222611474
Iter: 610 loss: 0.00222228607
Iter: 611 loss: 0.00222168979
Iter: 612 loss: 0.00222194567
Iter: 613 loss: 0.00222127838
Iter: 614 loss: 0.00222044508
Iter: 615 loss: 0.00222124951
Iter: 616 loss: 0.00221996685
Iter: 617 loss: 0.00221917545
Iter: 618 loss: 0.00222388143
Iter: 619 loss: 0.00221907138
Iter: 620 loss: 0.00221825903
Iter: 621 loss: 0.00222130935
Iter: 622 loss: 0.00221806043
Iter: 623 loss: 0.00221751141
Iter: 624 loss: 0.00221750932
Iter: 625 loss: 0.00221727812
Iter: 626 loss: 0.00222024182
Iter: 627 loss: 0.00221727765
Iter: 628 loss: 0.00221702689
Iter: 629 loss: 0.0022170369
Iter: 630 loss: 0.00221683038
Iter: 631 loss: 0.00221655052
Iter: 632 loss: 0.00221597543
Iter: 633 loss: 0.00222623954
Iter: 634 loss: 0.00221596798
Iter: 635 loss: 0.00221536728
Iter: 636 loss: 0.00221675821
Iter: 637 loss: 0.00221514981
Iter: 638 loss: 0.00221452885
Iter: 639 loss: 0.00221433281
Iter: 640 loss: 0.00221397169
Iter: 641 loss: 0.00221316982
Iter: 642 loss: 0.00222296757
Iter: 643 loss: 0.00221316377
Iter: 644 loss: 0.00221249787
Iter: 645 loss: 0.00221336912
Iter: 646 loss: 0.0022121612
Iter: 647 loss: 0.00221154466
Iter: 648 loss: 0.00221160939
Iter: 649 loss: 0.00221106969
Iter: 650 loss: 0.00221034349
Iter: 651 loss: 0.00221336796
Iter: 652 loss: 0.00221018889
Iter: 653 loss: 0.00220955908
Iter: 654 loss: 0.00221533934
Iter: 655 loss: 0.00220952975
Iter: 656 loss: 0.00220926176
Iter: 657 loss: 0.0022092564
Iter: 658 loss: 0.00220912229
Iter: 659 loss: 0.00221095537
Iter: 660 loss: 0.00220912439
Iter: 661 loss: 0.00220899144
Iter: 662 loss: 0.00220893486
Iter: 663 loss: 0.00220886432
Iter: 664 loss: 0.00220865896
Iter: 665 loss: 0.00220824522
Iter: 666 loss: 0.00221613748
Iter: 667 loss: 0.00220823893
Iter: 668 loss: 0.00220783404
Iter: 669 loss: 0.00220946432
Iter: 670 loss: 0.00220774673
Iter: 671 loss: 0.00220737839
Iter: 672 loss: 0.00220699818
Iter: 673 loss: 0.00220693275
Iter: 674 loss: 0.00220656954
Iter: 675 loss: 0.00220655464
Iter: 676 loss: 0.00220624893
Iter: 677 loss: 0.00220642332
Iter: 678 loss: 0.00220605405
Iter: 679 loss: 0.00220569689
Iter: 680 loss: 0.00220596232
Iter: 681 loss: 0.00220547942
Iter: 682 loss: 0.00220510666
Iter: 683 loss: 0.00220537535
Iter: 684 loss: 0.00220487872
Iter: 685 loss: 0.00220458116
Iter: 686 loss: 0.00220456906
Iter: 687 loss: 0.0022043949
Iter: 688 loss: 0.00220692111
Iter: 689 loss: 0.0022043935
Iter: 690 loss: 0.0022042885
Iter: 691 loss: 0.00220517255
Iter: 692 loss: 0.00220427965
Iter: 693 loss: 0.00220416021
Iter: 694 loss: 0.0022041765
Iter: 695 loss: 0.00220406987
Iter: 696 loss: 0.00220391387
Iter: 697 loss: 0.00220366544
Iter: 698 loss: 0.00220366078
Iter: 699 loss: 0.00220338674
Iter: 700 loss: 0.00220386405
Iter: 701 loss: 0.00220326637
Iter: 702 loss: 0.00220298138
Iter: 703 loss: 0.00220333552
Iter: 704 loss: 0.00220282981
Iter: 705 loss: 0.00220257184
Iter: 706 loss: 0.00220414251
Iter: 707 loss: 0.0022025404
Iter: 708 loss: 0.00220231339
Iter: 709 loss: 0.00220338581
Iter: 710 loss: 0.00220227172
Iter: 711 loss: 0.00220205123
Iter: 712 loss: 0.00220190361
Iter: 713 loss: 0.00220182119
Iter: 714 loss: 0.00220152829
Iter: 715 loss: 0.00220195297
Iter: 716 loss: 0.00220138673
Iter: 717 loss: 0.00220108987
Iter: 718 loss: 0.0022040261
Iter: 719 loss: 0.00220107939
Iter: 720 loss: 0.00220090244
Iter: 721 loss: 0.00220353017
Iter: 722 loss: 0.00220090197
Iter: 723 loss: 0.00220078393
Iter: 724 loss: 0.00220194366
Iter: 725 loss: 0.0022007809
Iter: 726 loss: 0.00220066
Iter: 727 loss: 0.00220074761
Iter: 728 loss: 0.00220058113
Iter: 729 loss: 0.00220045447
Iter: 730 loss: 0.0022002717
Iter: 731 loss: 0.00220026774
Iter: 732 loss: 0.00220004865
Iter: 733 loss: 0.00220018486
Iter: 734 loss: 0.00219990825
Iter: 735 loss: 0.00219964655
Iter: 736 loss: 0.00220043864
Iter: 737 loss: 0.00219957088
Iter: 738 loss: 0.00219936087
Iter: 739 loss: 0.00219954411
Iter: 740 loss: 0.00219924143
Iter: 741 loss: 0.00219898112
Iter: 742 loss: 0.0022013702
Iter: 743 loss: 0.00219897134
Iter: 744 loss: 0.00219876925
Iter: 745 loss: 0.00219870545
Iter: 746 loss: 0.00219858671
Iter: 747 loss: 0.00219831616
Iter: 748 loss: 0.00219866144
Iter: 749 loss: 0.00219818065
Iter: 750 loss: 0.0021979236
Iter: 751 loss: 0.00220030406
Iter: 752 loss: 0.00219791429
Iter: 753 loss: 0.00219773059
Iter: 754 loss: 0.00219935668
Iter: 755 loss: 0.00219771918
Iter: 756 loss: 0.0021976009
Iter: 757 loss: 0.00219954643
Iter: 758 loss: 0.00219760067
Iter: 759 loss: 0.00219749613
Iter: 760 loss: 0.00219757482
Iter: 761 loss: 0.00219743024
Iter: 762 loss: 0.0021973229
Iter: 763 loss: 0.00219719065
Iter: 764 loss: 0.00219717901
Iter: 765 loss: 0.0021970165
Iter: 766 loss: 0.00219703908
Iter: 767 loss: 0.00219689775
Iter: 768 loss: 0.00219666795
Iter: 769 loss: 0.00219714316
Iter: 770 loss: 0.00219657598
Iter: 771 loss: 0.00219635479
Iter: 772 loss: 0.00219652685
Iter: 773 loss: 0.00219622138
Iter: 774 loss: 0.00219596783
Iter: 775 loss: 0.0021986959
Iter: 776 loss: 0.00219596061
Iter: 777 loss: 0.00219575921
Iter: 778 loss: 0.0021957322
Iter: 779 loss: 0.00219559111
Iter: 780 loss: 0.00219531683
Iter: 781 loss: 0.00219551101
Iter: 782 loss: 0.00219514617
Iter: 783 loss: 0.00219489168
Iter: 784 loss: 0.00219808659
Iter: 785 loss: 0.00219488749
Iter: 786 loss: 0.00219471753
Iter: 787 loss: 0.00219613523
Iter: 788 loss: 0.00219470426
Iter: 789 loss: 0.0021946074
Iter: 790 loss: 0.00219460507
Iter: 791 loss: 0.00219452451
Iter: 792 loss: 0.00219459971
Iter: 793 loss: 0.00219447585
Iter: 794 loss: 0.00219438807
Iter: 795 loss: 0.00219427352
Iter: 796 loss: 0.00219426677
Iter: 797 loss: 0.0021941145
Iter: 798 loss: 0.00219414057
Iter: 799 loss: 0.00219400087
Iter: 800 loss: 0.00219380599
Iter: 801 loss: 0.00219438458
Iter: 802 loss: 0.00219374336
Iter: 803 loss: 0.00219356315
Iter: 804 loss: 0.00219361
Iter: 805 loss: 0.00219342904
Iter: 806 loss: 0.00219323067
Iter: 807 loss: 0.00219612592
Iter: 808 loss: 0.00219323114
Iter: 809 loss: 0.00219307235
Iter: 810 loss: 0.0021930139
Iter: 811 loss: 0.00219292333
Iter: 812 loss: 0.00219270028
Iter: 813 loss: 0.00219286419
Iter: 814 loss: 0.00219256524
Iter: 815 loss: 0.00219238363
Iter: 816 loss: 0.00219438132
Iter: 817 loss: 0.00219238317
Iter: 818 loss: 0.00219225744
Iter: 819 loss: 0.00219368096
Iter: 820 loss: 0.00219225511
Iter: 821 loss: 0.00219218712
Iter: 822 loss: 0.00219218968
Iter: 823 loss: 0.00219213404
Iter: 824 loss: 0.00219217548
Iter: 825 loss: 0.00219209958
Iter: 826 loss: 0.00219203299
Iter: 827 loss: 0.00219193799
Iter: 828 loss: 0.00219193986
Iter: 829 loss: 0.00219181227
Iter: 830 loss: 0.0021918118
Iter: 831 loss: 0.00219170819
Iter: 832 loss: 0.00219154474
Iter: 833 loss: 0.00219211471
Iter: 834 loss: 0.00219149934
Iter: 835 loss: 0.00219135056
Iter: 836 loss: 0.00219137664
Iter: 837 loss: 0.0021912388
Iter: 838 loss: 0.00219108583
Iter: 839 loss: 0.00219338178
Iter: 840 loss: 0.00219108281
Iter: 841 loss: 0.00219095126
Iter: 842 loss: 0.00219092332
Iter: 843 loss: 0.00219084416
Iter: 844 loss: 0.00219066767
Iter: 845 loss: 0.002190853
Iter: 846 loss: 0.00219056988
Iter: 847 loss: 0.00219042134
Iter: 848 loss: 0.00219131913
Iter: 849 loss: 0.00219040317
Iter: 850 loss: 0.00219030678
Iter: 851 loss: 0.00219030795
Iter: 852 loss: 0.00219025603
Iter: 853 loss: 0.00219025463
Iter: 854 loss: 0.00219021202
Iter: 855 loss: 0.00219025
Iter: 856 loss: 0.0021901885
Iter: 857 loss: 0.00219013751
Iter: 858 loss: 0.00219004881
Iter: 859 loss: 0.00219216314
Iter: 860 loss: 0.00219004904
Iter: 861 loss: 0.00218993519
Iter: 862 loss: 0.0021899417
Iter: 863 loss: 0.00218984718
Iter: 864 loss: 0.00218970282
Iter: 865 loss: 0.00219016662
Iter: 866 loss: 0.00218966207
Iter: 867 loss: 0.0021895261
Iter: 868 loss: 0.00218958082
Iter: 869 loss: 0.00218943553
Iter: 870 loss: 0.0021893112
Iter: 871 loss: 0.00219115941
Iter: 872 loss: 0.00218930934
Iter: 873 loss: 0.00218920456
Iter: 874 loss: 0.00218916894
Iter: 875 loss: 0.00218910561
Iter: 876 loss: 0.00218896
Iter: 877 loss: 0.00218916265
Iter: 878 loss: 0.00218888978
Iter: 879 loss: 0.00218876591
Iter: 880 loss: 0.00218914682
Iter: 881 loss: 0.00218873331
Iter: 882 loss: 0.00218864856
Iter: 883 loss: 0.00218864484
Iter: 884 loss: 0.0021886006
Iter: 885 loss: 0.00218926533
Iter: 886 loss: 0.00218859967
Iter: 887 loss: 0.00218856195
Iter: 888 loss: 0.00218862388
Iter: 889 loss: 0.00218853913
Iter: 890 loss: 0.00218850095
Iter: 891 loss: 0.00218842039
Iter: 892 loss: 0.00219012168
Iter: 893 loss: 0.00218841899
Iter: 894 loss: 0.0021883212
Iter: 895 loss: 0.0021883829
Iter: 896 loss: 0.00218825624
Iter: 897 loss: 0.00218814751
Iter: 898 loss: 0.00218846719
Iter: 899 loss: 0.00218811608
Iter: 900 loss: 0.00218801061
Iter: 901 loss: 0.00218804786
Iter: 902 loss: 0.0021879361
Iter: 903 loss: 0.00218784064
Iter: 904 loss: 0.00218917057
Iter: 905 loss: 0.00218784343
Iter: 906 loss: 0.00218775542
Iter: 907 loss: 0.00218774844
Iter: 908 loss: 0.00218768558
Iter: 909 loss: 0.00218757568
Iter: 910 loss: 0.00218769163
Iter: 911 loss: 0.00218751561
Iter: 912 loss: 0.00218741037
Iter: 913 loss: 0.00218760408
Iter: 914 loss: 0.0021873652
Iter: 915 loss: 0.00218730513
Iter: 916 loss: 0.00218729302
Iter: 917 loss: 0.00218725391
Iter: 918 loss: 0.00218770932
Iter: 919 loss: 0.0021872553
Iter: 920 loss: 0.00218721898
Iter: 921 loss: 0.00218729395
Iter: 922 loss: 0.00218720222
Iter: 923 loss: 0.00218716566
Iter: 924 loss: 0.00218709046
Iter: 925 loss: 0.00218850444
Iter: 926 loss: 0.0021870872
Iter: 927 loss: 0.00218699826
Iter: 928 loss: 0.00218714355
Iter: 929 loss: 0.00218695961
Iter: 930 loss: 0.00218687695
Iter: 931 loss: 0.00218704878
Iter: 932 loss: 0.00218684739
Iter: 933 loss: 0.00218675891
Iter: 934 loss: 0.00218680827
Iter: 935 loss: 0.00218670489
Iter: 936 loss: 0.00218662014
Iter: 937 loss: 0.00218753144
Iter: 938 loss: 0.00218661828
Iter: 939 loss: 0.00218653586
Iter: 940 loss: 0.00218655728
Iter: 941 loss: 0.00218648324
Iter: 942 loss: 0.00218638522
Iter: 943 loss: 0.00218650233
Iter: 944 loss: 0.00218633516
Iter: 945 loss: 0.00218624552
Iter: 946 loss: 0.00218635122
Iter: 947 loss: 0.00218619592
Iter: 948 loss: 0.0021861631
Iter: 949 loss: 0.00218613842
Iter: 950 loss: 0.00218610605
Iter: 951 loss: 0.00218642177
Iter: 952 loss: 0.00218610419
Iter: 953 loss: 0.00218607159
Iter: 954 loss: 0.0021861447
Iter: 955 loss: 0.00218605902
Iter: 956 loss: 0.00218603062
Iter: 957 loss: 0.00218596868
Iter: 958 loss: 0.00218723645
Iter: 959 loss: 0.00218596892
Iter: 960 loss: 0.00218590163
Iter: 961 loss: 0.00218602782
Iter: 962 loss: 0.00218587602
Iter: 963 loss: 0.00218581758
Iter: 964 loss: 0.00218588952
Iter: 965 loss: 0.00218578847
Iter: 966 loss: 0.00218571955
Iter: 967 loss: 0.00218575518
Iter: 968 loss: 0.00218567438
Iter: 969 loss: 0.00218560407
Iter: 970 loss: 0.00218622526
Iter: 971 loss: 0.00218559708
Iter: 972 loss: 0.00218552933
Iter: 973 loss: 0.00218558824
Iter: 974 loss: 0.00218548696
Iter: 975 loss: 0.00218541175
Iter: 976 loss: 0.00218548579
Iter: 977 loss: 0.00218536472
Iter: 978 loss: 0.00218527927
Iter: 979 loss: 0.00218532351
Iter: 980 loss: 0.00218522153
Iter: 981 loss: 0.00218520081
Iter: 982 loss: 0.0021851724
Iter: 983 loss: 0.00218514
Iter: 984 loss: 0.00218537357
Iter: 985 loss: 0.00218513911
Iter: 986 loss: 0.00218510628
Iter: 987 loss: 0.0021852334
Iter: 988 loss: 0.00218510069
Iter: 989 loss: 0.00218507508
Iter: 990 loss: 0.00218502479
Iter: 991 loss: 0.00218502525
Iter: 992 loss: 0.00218497589
Iter: 993 loss: 0.0021850958
Iter: 994 loss: 0.00218495633
Iter: 995 loss: 0.00218490837
Iter: 996 loss: 0.00218490977
Iter: 997 loss: 0.00218487042
Iter: 998 loss: 0.00218479615
Iter: 999 loss: 0.00218487415
Iter: 1000 loss: 0.00218475331
Iter: 1001 loss: 0.00218468625
Iter: 1002 loss: 0.00218522083
Iter: 1003 loss: 0.00218467554
Iter: 1004 loss: 0.0021846029
Iter: 1005 loss: 0.00218468672
Iter: 1006 loss: 0.00218456192
Iter: 1007 loss: 0.00218448415
Iter: 1008 loss: 0.00218456
Iter: 1009 loss: 0.00218443945
Iter: 1010 loss: 0.00218435097
Iter: 1011 loss: 0.00218437356
Iter: 1012 loss: 0.00218428764
Iter: 1013 loss: 0.00218429882
Iter: 1014 loss: 0.00218424294
Iter: 1015 loss: 0.00218420802
Iter: 1016 loss: 0.00218440918
Iter: 1017 loss: 0.00218420429
Iter: 1018 loss: 0.00218417728
Iter: 1019 loss: 0.00218427274
Iter: 1020 loss: 0.0021841689
Iter: 1021 loss: 0.00218414
Iter: 1022 loss: 0.00218409766
Iter: 1023 loss: 0.00218409556
Iter: 1024 loss: 0.00218404061
Iter: 1025 loss: 0.00218417589
Iter: 1026 loss: 0.00218402548
Iter: 1027 loss: 0.00218397588
Iter: 1028 loss: 0.00218396494
Iter: 1029 loss: 0.00218393072
Iter: 1030 loss: 0.00218384736
Iter: 1031 loss: 0.00218397309
Iter: 1032 loss: 0.00218380452
Iter: 1033 loss: 0.00218372978
Iter: 1034 loss: 0.00218428043
Iter: 1035 loss: 0.00218372024
Iter: 1036 loss: 0.00218365365
Iter: 1037 loss: 0.00218375656
Iter: 1038 loss: 0.00218361686
Iter: 1039 loss: 0.00218354259
Iter: 1040 loss: 0.00218357844
Iter: 1041 loss: 0.00218349276
Iter: 1042 loss: 0.00218340429
Iter: 1043 loss: 0.00218340917
Iter: 1044 loss: 0.0021833356
Iter: 1045 loss: 0.00218334119
Iter: 1046 loss: 0.00218329369
Iter: 1047 loss: 0.00218326272
Iter: 1048 loss: 0.00218353793
Iter: 1049 loss: 0.00218325946
Iter: 1050 loss: 0.00218323292
Iter: 1051 loss: 0.00218328787
Iter: 1052 loss: 0.00218322617
Iter: 1053 loss: 0.00218319474
Iter: 1054 loss: 0.00218314468
Iter: 1055 loss: 0.00218314538
Iter: 1056 loss: 0.00218309322
Iter: 1057 loss: 0.00218315958
Iter: 1058 loss: 0.00218306761
Iter: 1059 loss: 0.00218300428
Iter: 1060 loss: 0.00218297821
Iter: 1061 loss: 0.00218295027
Iter: 1062 loss: 0.00218284642
Iter: 1063 loss: 0.00218310347
Iter: 1064 loss: 0.00218281057
Iter: 1065 loss: 0.0021827321
Iter: 1066 loss: 0.00218320102
Iter: 1067 loss: 0.00218272605
Iter: 1068 loss: 0.00218264619
Iter: 1069 loss: 0.00218282943
Iter: 1070 loss: 0.00218261615
Iter: 1071 loss: 0.00218254654
Iter: 1072 loss: 0.00218261895
Iter: 1073 loss: 0.00218250812
Iter: 1074 loss: 0.0021824271
Iter: 1075 loss: 0.00218243618
Iter: 1076 loss: 0.00218236493
Iter: 1077 loss: 0.00218233373
Iter: 1078 loss: 0.00218232116
Iter: 1079 loss: 0.00218228577
Iter: 1080 loss: 0.00218267809
Iter: 1081 loss: 0.00218228414
Iter: 1082 loss: 0.00218226435
Iter: 1083 loss: 0.00218232069
Iter: 1084 loss: 0.00218225061
Iter: 1085 loss: 0.00218221778
Iter: 1086 loss: 0.00218218053
Iter: 1087 loss: 0.0021821768
Iter: 1088 loss: 0.00218213513
Iter: 1089 loss: 0.00218215026
Iter: 1090 loss: 0.00218210439
Iter: 1091 loss: 0.00218204
Iter: 1092 loss: 0.00218204083
Iter: 1093 loss: 0.00218198961
Iter: 1094 loss: 0.00218189508
Iter: 1095 loss: 0.00218220521
Iter: 1096 loss: 0.00218187249
Iter: 1097 loss: 0.00218180381
Iter: 1098 loss: 0.00218209741
Iter: 1099 loss: 0.00218179077
Iter: 1100 loss: 0.00218171673
Iter: 1101 loss: 0.00218201429
Iter: 1102 loss: 0.00218169857
Iter: 1103 loss: 0.00218164013
Iter: 1104 loss: 0.00218167179
Iter: 1105 loss: 0.00218159845
Iter: 1106 loss: 0.00218151184
Iter: 1107 loss: 0.00218155514
Iter: 1108 loss: 0.0021814534
Iter: 1109 loss: 0.00218140101
Iter: 1110 loss: 0.00218140054
Iter: 1111 loss: 0.00218135561
Iter: 1112 loss: 0.00218200893
Iter: 1113 loss: 0.00218135724
Iter: 1114 loss: 0.00218132674
Iter: 1115 loss: 0.00218138634
Iter: 1116 loss: 0.00218131184
Iter: 1117 loss: 0.00218127854
Iter: 1118 loss: 0.00218124222
Iter: 1119 loss: 0.00218123081
Iter: 1120 loss: 0.0021811882
Iter: 1121 loss: 0.00218119798
Iter: 1122 loss: 0.00218115794
Iter: 1123 loss: 0.00218109181
Iter: 1124 loss: 0.00218109833
Iter: 1125 loss: 0.00218104245
Iter: 1126 loss: 0.00218096026
Iter: 1127 loss: 0.00218130159
Iter: 1128 loss: 0.00218094233
Iter: 1129 loss: 0.00218088087
Iter: 1130 loss: 0.00218100334
Iter: 1131 loss: 0.00218085083
Iter: 1132 loss: 0.00218077819
Iter: 1133 loss: 0.00218128716
Iter: 1134 loss: 0.00218076631
Iter: 1135 loss: 0.00218071952
Iter: 1136 loss: 0.00218069274
Iter: 1137 loss: 0.00218066946
Iter: 1138 loss: 0.00218057842
Iter: 1139 loss: 0.00218066527
Iter: 1140 loss: 0.00218053209
Iter: 1141 loss: 0.00218045386
Iter: 1142 loss: 0.00218126411
Iter: 1143 loss: 0.00218045525
Iter: 1144 loss: 0.00218041264
Iter: 1145 loss: 0.00218040822
Iter: 1146 loss: 0.00218037772
Iter: 1147 loss: 0.00218043663
Iter: 1148 loss: 0.00218036794
Iter: 1149 loss: 0.00218033209
Iter: 1150 loss: 0.00218030671
Iter: 1151 loss: 0.0021802946
Iter: 1152 loss: 0.00218025618
Iter: 1153 loss: 0.00218024873
Iter: 1154 loss: 0.00218022033
Iter: 1155 loss: 0.00218015257
Iter: 1156 loss: 0.00218020566
Iter: 1157 loss: 0.00218011113
Iter: 1158 loss: 0.00218004128
Iter: 1159 loss: 0.00218030438
Iter: 1160 loss: 0.00218002219
Iter: 1161 loss: 0.00217995467
Iter: 1162 loss: 0.00218003429
Iter: 1163 loss: 0.00217992091
Iter: 1164 loss: 0.00217984803
Iter: 1165 loss: 0.00218056329
Iter: 1166 loss: 0.00217984384
Iter: 1167 loss: 0.00217979099
Iter: 1168 loss: 0.00217970787
Iter: 1169 loss: 0.00217970647
Iter: 1170 loss: 0.00217958353
Iter: 1171 loss: 0.00217991672
Iter: 1172 loss: 0.00217954931
Iter: 1173 loss: 0.00217946852
Iter: 1174 loss: 0.00218024827
Iter: 1175 loss: 0.00217946526
Iter: 1176 loss: 0.00217943871
Iter: 1177 loss: 0.00217942847
Iter: 1178 loss: 0.00217939774
Iter: 1179 loss: 0.0021794592
Iter: 1180 loss: 0.00217939261
Iter: 1181 loss: 0.00217936514
Iter: 1182 loss: 0.00217934488
Iter: 1183 loss: 0.00217933254
Iter: 1184 loss: 0.00217929576
Iter: 1185 loss: 0.00217926595
Iter: 1186 loss: 0.00217925617
Iter: 1187 loss: 0.00217918912
Iter: 1188 loss: 0.00217925897
Iter: 1189 loss: 0.00217915326
Iter: 1190 loss: 0.00217908225
Iter: 1191 loss: 0.00217930856
Iter: 1192 loss: 0.0021790613
Iter: 1193 loss: 0.00217899727
Iter: 1194 loss: 0.00217907457
Iter: 1195 loss: 0.00217896
Iter: 1196 loss: 0.00217888691
Iter: 1197 loss: 0.00217957306
Iter: 1198 loss: 0.00217888388
Iter: 1199 loss: 0.0021788266
Iter: 1200 loss: 0.00217874907
Iter: 1201 loss: 0.00217874721
Iter: 1202 loss: 0.00217863452
Iter: 1203 loss: 0.00217900844
Iter: 1204 loss: 0.00217860518
Iter: 1205 loss: 0.00217853789
Iter: 1206 loss: 0.00217905664
Iter: 1207 loss: 0.00217852788
Iter: 1208 loss: 0.00217851717
Iter: 1209 loss: 0.00217849575
Iter: 1210 loss: 0.00217847526
Iter: 1211 loss: 0.00217852788
Iter: 1212 loss: 0.00217846921
Iter: 1213 loss: 0.00217844755
Iter: 1214 loss: 0.00217842893
Iter: 1215 loss: 0.00217842287
Iter: 1216 loss: 0.00217839051
Iter: 1217 loss: 0.00217835815
Iter: 1218 loss: 0.00217834767
Iter: 1219 loss: 0.00217828923
Iter: 1220 loss: 0.00217838539
Iter: 1221 loss: 0.00217825896
Iter: 1222 loss: 0.00217820192
Iter: 1223 loss: 0.00217829039
Iter: 1224 loss: 0.00217817072
Iter: 1225 loss: 0.00217809249
Iter: 1226 loss: 0.00217823079
Iter: 1227 loss: 0.00217805896
Iter: 1228 loss: 0.00217799214
Iter: 1229 loss: 0.0021785982
Iter: 1230 loss: 0.00217799144
Iter: 1231 loss: 0.00217792811
Iter: 1232 loss: 0.00217786897
Iter: 1233 loss: 0.00217786059
Iter: 1234 loss: 0.00217776466
Iter: 1235 loss: 0.00217809784
Iter: 1236 loss: 0.00217774417
Iter: 1237 loss: 0.00217768434
Iter: 1238 loss: 0.00217792951
Iter: 1239 loss: 0.00217767106
Iter: 1240 loss: 0.00217766338
Iter: 1241 loss: 0.00217764056
Iter: 1242 loss: 0.00217761938
Iter: 1243 loss: 0.00217767595
Iter: 1244 loss: 0.00217761449
Iter: 1245 loss: 0.00217759446
Iter: 1246 loss: 0.00217757165
Iter: 1247 loss: 0.00217757211
Iter: 1248 loss: 0.00217753393
Iter: 1249 loss: 0.00217749411
Iter: 1250 loss: 0.00217749155
Iter: 1251 loss: 0.00217742613
Iter: 1252 loss: 0.00217753439
Iter: 1253 loss: 0.00217739982
Iter: 1254 loss: 0.0021773323
Iter: 1255 loss: 0.00217741239
Iter: 1256 loss: 0.00217730273
Iter: 1257 loss: 0.00217722426
Iter: 1258 loss: 0.0021774
Iter: 1259 loss: 0.00217719376
Iter: 1260 loss: 0.00217712671
Iter: 1261 loss: 0.00217764778
Iter: 1262 loss: 0.00217712019
Iter: 1263 loss: 0.00217705499
Iter: 1264 loss: 0.00217703148
Iter: 1265 loss: 0.00217699306
Iter: 1266 loss: 0.00217691623
Iter: 1267 loss: 0.0021771621
Iter: 1268 loss: 0.00217689271
Iter: 1269 loss: 0.00217683078
Iter: 1270 loss: 0.00217688968
Iter: 1271 loss: 0.00217679748
Iter: 1272 loss: 0.00217684126
Iter: 1273 loss: 0.00217677
Iter: 1274 loss: 0.00217674626
Iter: 1275 loss: 0.00217684708
Iter: 1276 loss: 0.00217674207
Iter: 1277 loss: 0.00217672205
Iter: 1278 loss: 0.00217669434
Iter: 1279 loss: 0.00217669271
Iter: 1280 loss: 0.00217664847
Iter: 1281 loss: 0.00217663404
Iter: 1282 loss: 0.00217660633
Iter: 1283 loss: 0.00217654742
Iter: 1284 loss: 0.00217666407
Iter: 1285 loss: 0.00217652
Iter: 1286 loss: 0.00217645289
Iter: 1287 loss: 0.00217648642
Iter: 1288 loss: 0.00217641401
Iter: 1289 loss: 0.00217632717
Iter: 1290 loss: 0.00217660586
Iter: 1291 loss: 0.0021762969
Iter: 1292 loss: 0.0021762359
Iter: 1293 loss: 0.00217663171
Iter: 1294 loss: 0.00217622845
Iter: 1295 loss: 0.00217616186
Iter: 1296 loss: 0.00217615068
Iter: 1297 loss: 0.0021761118
Iter: 1298 loss: 0.00217602775
Iter: 1299 loss: 0.00217639422
Iter: 1300 loss: 0.00217601238
Iter: 1301 loss: 0.00217595114
Iter: 1302 loss: 0.00217601936
Iter: 1303 loss: 0.00217591738
Iter: 1304 loss: 0.00217591366
Iter: 1305 loss: 0.00217588665
Iter: 1306 loss: 0.00217586057
Iter: 1307 loss: 0.00217592251
Iter: 1308 loss: 0.00217585638
Iter: 1309 loss: 0.00217583636
Iter: 1310 loss: 0.00217580958
Iter: 1311 loss: 0.00217580888
Iter: 1312 loss: 0.00217576534
Iter: 1313 loss: 0.00217574602
Iter: 1314 loss: 0.00217572786
Iter: 1315 loss: 0.00217567757
Iter: 1316 loss: 0.00217573205
Iter: 1317 loss: 0.00217564846
Iter: 1318 loss: 0.00217558956
Iter: 1319 loss: 0.00217564707
Iter: 1320 loss: 0.00217555696
Iter: 1321 loss: 0.00217549666
Iter: 1322 loss: 0.00217571342
Iter: 1323 loss: 0.00217547501
Iter: 1324 loss: 0.0021754324
Iter: 1325 loss: 0.00217569526
Iter: 1326 loss: 0.00217542262
Iter: 1327 loss: 0.00217537582
Iter: 1328 loss: 0.00217535812
Iter: 1329 loss: 0.00217532972
Iter: 1330 loss: 0.00217526359
Iter: 1331 loss: 0.00217544753
Iter: 1332 loss: 0.00217524264
Iter: 1333 loss: 0.00217518723
Iter: 1334 loss: 0.00217519118
Iter: 1335 loss: 0.00217514602
Iter: 1336 loss: 0.0021751821
Iter: 1337 loss: 0.00217511971
Iter: 1338 loss: 0.00217510317
Iter: 1339 loss: 0.00217519328
Iter: 1340 loss: 0.00217509945
Iter: 1341 loss: 0.00217508827
Iter: 1342 loss: 0.00217506383
Iter: 1343 loss: 0.00217506289
Iter: 1344 loss: 0.00217503333
Iter: 1345 loss: 0.00217503542
Iter: 1346 loss: 0.00217501144
Iter: 1347 loss: 0.00217497069
Iter: 1348 loss: 0.00217501214
Iter: 1349 loss: 0.00217495044
Iter: 1350 loss: 0.00217490364
Iter: 1351 loss: 0.00217489852
Iter: 1352 loss: 0.00217486336
Iter: 1353 loss: 0.00217479258
Iter: 1354 loss: 0.00217504776
Iter: 1355 loss: 0.00217477418
Iter: 1356 loss: 0.00217471668
Iter: 1357 loss: 0.00217500399
Iter: 1358 loss: 0.0021747055
Iter: 1359 loss: 0.00217464147
Iter: 1360 loss: 0.00217469037
Iter: 1361 loss: 0.00217460236
Iter: 1362 loss: 0.00217452506
Iter: 1363 loss: 0.00217466522
Iter: 1364 loss: 0.00217448967
Iter: 1365 loss: 0.00217443099
Iter: 1366 loss: 0.00217456231
Iter: 1367 loss: 0.00217440655
Iter: 1368 loss: 0.00217439
Iter: 1369 loss: 0.00217437372
Iter: 1370 loss: 0.00217434391
Iter: 1371 loss: 0.00217456394
Iter: 1372 loss: 0.00217434275
Iter: 1373 loss: 0.00217432179
Iter: 1374 loss: 0.00217431574
Iter: 1375 loss: 0.0021743048
Iter: 1376 loss: 0.00217427569
Iter: 1377 loss: 0.00217428664
Iter: 1378 loss: 0.00217425567
Iter: 1379 loss: 0.00217421865
Iter: 1380 loss: 0.00217419071
Iter: 1381 loss: 0.00217418117
Iter: 1382 loss: 0.00217412598
Iter: 1383 loss: 0.00217424869
Iter: 1384 loss: 0.00217410596
Iter: 1385 loss: 0.00217403518
Iter: 1386 loss: 0.00217405194
Iter: 1387 loss: 0.00217398186
Iter: 1388 loss: 0.00217391178
Iter: 1389 loss: 0.00217443123
Iter: 1390 loss: 0.00217390619
Iter: 1391 loss: 0.00217383518
Iter: 1392 loss: 0.00217388128
Iter: 1393 loss: 0.00217379653
Iter: 1394 loss: 0.0021737027
Iter: 1395 loss: 0.0021740566
Iter: 1396 loss: 0.00217368
Iter: 1397 loss: 0.00217362191
Iter: 1398 loss: 0.00217370619
Iter: 1399 loss: 0.00217359117
Iter: 1400 loss: 0.002173563
Iter: 1401 loss: 0.00217355276
Iter: 1402 loss: 0.00217352482
Iter: 1403 loss: 0.0021737488
Iter: 1404 loss: 0.00217352295
Iter: 1405 loss: 0.00217349944
Iter: 1406 loss: 0.00217351224
Iter: 1407 loss: 0.0021734864
Iter: 1408 loss: 0.00217346172
Iter: 1409 loss: 0.00217345683
Iter: 1410 loss: 0.00217344356
Iter: 1411 loss: 0.00217340211
Iter: 1412 loss: 0.00217337301
Iter: 1413 loss: 0.00217336
Iter: 1414 loss: 0.00217330502
Iter: 1415 loss: 0.00217343355
Iter: 1416 loss: 0.00217328244
Iter: 1417 loss: 0.00217321259
Iter: 1418 loss: 0.00217329618
Iter: 1419 loss: 0.00217317394
Iter: 1420 loss: 0.00217311387
Iter: 1421 loss: 0.00217339513
Iter: 1422 loss: 0.00217310572
Iter: 1423 loss: 0.00217303797
Iter: 1424 loss: 0.00217309
Iter: 1425 loss: 0.00217299815
Iter: 1426 loss: 0.00217292854
Iter: 1427 loss: 0.00217339816
Iter: 1428 loss: 0.00217291713
Iter: 1429 loss: 0.00217286963
Iter: 1430 loss: 0.00217288965
Iter: 1431 loss: 0.00217283913
Iter: 1432 loss: 0.00217280723
Iter: 1433 loss: 0.0021728056
Iter: 1434 loss: 0.00217277883
Iter: 1435 loss: 0.00217295717
Iter: 1436 loss: 0.00217277789
Iter: 1437 loss: 0.00217275927
Iter: 1438 loss: 0.0021727616
Iter: 1439 loss: 0.00217274902
Iter: 1440 loss: 0.00217272411
Iter: 1441 loss: 0.00217270129
Iter: 1442 loss: 0.00217269803
Iter: 1443 loss: 0.00217264541
Iter: 1444 loss: 0.00217265449
Iter: 1445 loss: 0.00217260863
Iter: 1446 loss: 0.00217255345
Iter: 1447 loss: 0.00217262236
Iter: 1448 loss: 0.00217252132
Iter: 1449 loss: 0.00217244448
Iter: 1450 loss: 0.00217267452
Iter: 1451 loss: 0.0021724219
Iter: 1452 loss: 0.00217236625
Iter: 1453 loss: 0.00217253272
Iter: 1454 loss: 0.00217235391
Iter: 1455 loss: 0.00217228266
Iter: 1456 loss: 0.00217241794
Iter: 1457 loss: 0.00217226171
Iter: 1458 loss: 0.00217219815
Iter: 1459 loss: 0.00217245449
Iter: 1460 loss: 0.00217218348
Iter: 1461 loss: 0.00217213761
Iter: 1462 loss: 0.00217219745
Iter: 1463 loss: 0.00217211782
Iter: 1464 loss: 0.00217208965
Iter: 1465 loss: 0.00217208872
Iter: 1466 loss: 0.0021720659
Iter: 1467 loss: 0.00217235
Iter: 1468 loss: 0.0021720659
Iter: 1469 loss: 0.00217205053
Iter: 1470 loss: 0.00217203866
Iter: 1471 loss: 0.00217203633
Iter: 1472 loss: 0.00217201211
Iter: 1473 loss: 0.00217199558
Iter: 1474 loss: 0.00217198837
Iter: 1475 loss: 0.00217193877
Iter: 1476 loss: 0.0021719567
Iter: 1477 loss: 0.00217190734
Iter: 1478 loss: 0.00217185402
Iter: 1479 loss: 0.00217187963
Iter: 1480 loss: 0.00217182119
Iter: 1481 loss: 0.00217174739
Iter: 1482 loss: 0.00217208359
Iter: 1483 loss: 0.00217173342
Iter: 1484 loss: 0.0021716794
Iter: 1485 loss: 0.00217174203
Iter: 1486 loss: 0.00217165565
Iter: 1487 loss: 0.00217159698
Iter: 1488 loss: 0.00217194762
Iter: 1489 loss: 0.00217158766
Iter: 1490 loss: 0.00217153109
Iter: 1491 loss: 0.00217157276
Iter: 1492 loss: 0.00217149686
Iter: 1493 loss: 0.0021714475
Iter: 1494 loss: 0.00217174366
Iter: 1495 loss: 0.00217143563
Iter: 1496 loss: 0.00217139977
Iter: 1497 loss: 0.00217160676
Iter: 1498 loss: 0.00217139395
Iter: 1499 loss: 0.00217136694
Iter: 1500 loss: 0.00217136554
Iter: 1501 loss: 0.00217135064
Iter: 1502 loss: 0.00217133714
Iter: 1503 loss: 0.00217133202
Iter: 1504 loss: 0.00217130687
Iter: 1505 loss: 0.00217131246
Iter: 1506 loss: 0.00217128964
Iter: 1507 loss: 0.0021712468
Iter: 1508 loss: 0.0021712468
Iter: 1509 loss: 0.00217121467
Iter: 1510 loss: 0.00217117
Iter: 1511 loss: 0.00217124377
Iter: 1512 loss: 0.00217114692
Iter: 1513 loss: 0.00217110035
Iter: 1514 loss: 0.00217125425
Iter: 1515 loss: 0.00217108103
Iter: 1516 loss: 0.00217103446
Iter: 1517 loss: 0.00217111968
Iter: 1518 loss: 0.00217101048
Iter: 1519 loss: 0.00217096531
Iter: 1520 loss: 0.00217112433
Iter: 1521 loss: 0.00217095297
Iter: 1522 loss: 0.00217089709
Iter: 1523 loss: 0.00217102608
Iter: 1524 loss: 0.00217087497
Iter: 1525 loss: 0.00217083283
Iter: 1526 loss: 0.00217103655
Iter: 1527 loss: 0.00217082631
Iter: 1528 loss: 0.00217078812
Iter: 1529 loss: 0.00217108126
Iter: 1530 loss: 0.00217078347
Iter: 1531 loss: 0.00217076461
Iter: 1532 loss: 0.00217076205
Iter: 1533 loss: 0.00217075
Iter: 1534 loss: 0.00217073574
Iter: 1535 loss: 0.00217073271
Iter: 1536 loss: 0.0021707085
Iter: 1537 loss: 0.00217070477
Iter: 1538 loss: 0.00217068475
Iter: 1539 loss: 0.00217064191
Iter: 1540 loss: 0.00217069988
Iter: 1541 loss: 0.00217061769
Iter: 1542 loss: 0.00217058184
Iter: 1543 loss: 0.00217058323
Iter: 1544 loss: 0.00217054808
Iter: 1545 loss: 0.00217050104
Iter: 1546 loss: 0.00217076018
Iter: 1547 loss: 0.00217048987
Iter: 1548 loss: 0.00217044726
Iter: 1549 loss: 0.00217046728
Iter: 1550 loss: 0.00217041862
Iter: 1551 loss: 0.00217037043
Iter: 1552 loss: 0.0021705504
Iter: 1553 loss: 0.00217035506
Iter: 1554 loss: 0.00217030058
Iter: 1555 loss: 0.00217042211
Iter: 1556 loss: 0.00217028242
Iter: 1557 loss: 0.00217023282
Iter: 1558 loss: 0.00217039883
Iter: 1559 loss: 0.00217021955
Iter: 1560 loss: 0.00217017904
Iter: 1561 loss: 0.00217072479
Iter: 1562 loss: 0.00217018253
Iter: 1563 loss: 0.00217015692
Iter: 1564 loss: 0.00217015669
Iter: 1565 loss: 0.00217014458
Iter: 1566 loss: 0.00217012386
Iter: 1567 loss: 0.00217012526
Iter: 1568 loss: 0.00217009266
Iter: 1569 loss: 0.00217012363
Iter: 1570 loss: 0.00217007566
Iter: 1571 loss: 0.00217004307
Iter: 1572 loss: 0.00217007054
Iter: 1573 loss: 0.00217002537
Iter: 1574 loss: 0.00216998486
Iter: 1575 loss: 0.00216999138
Iter: 1576 loss: 0.00216995273
Iter: 1577 loss: 0.00216990476
Iter: 1578 loss: 0.00217012
Iter: 1579 loss: 0.00216989638
Iter: 1580 loss: 0.00216984749
Iter: 1581 loss: 0.00216993503
Iter: 1582 loss: 0.0021698284
Iter: 1583 loss: 0.00216977904
Iter: 1584 loss: 0.00216989964
Iter: 1585 loss: 0.00216976786
Iter: 1586 loss: 0.00216970965
Iter: 1587 loss: 0.00216995412
Iter: 1588 loss: 0.00216969801
Iter: 1589 loss: 0.0021696575
Iter: 1590 loss: 0.00216969056
Iter: 1591 loss: 0.0021696391
Iter: 1592 loss: 0.00216960022
Iter: 1593 loss: 0.00216960232
Iter: 1594 loss: 0.0021695774
Iter: 1595 loss: 0.00216957694
Iter: 1596 loss: 0.0021695625
Iter: 1597 loss: 0.00216954667
Iter: 1598 loss: 0.00216954574
Iter: 1599 loss: 0.00216952153
Iter: 1600 loss: 0.00216953829
Iter: 1601 loss: 0.00216950709
Iter: 1602 loss: 0.00216947589
Iter: 1603 loss: 0.00216948753
Iter: 1604 loss: 0.00216945377
Iter: 1605 loss: 0.00216941349
Iter: 1606 loss: 0.0021694242
Iter: 1607 loss: 0.00216938159
Iter: 1608 loss: 0.00216933386
Iter: 1609 loss: 0.00216947286
Iter: 1610 loss: 0.00216931803
Iter: 1611 loss: 0.00216925819
Iter: 1612 loss: 0.0021694107
Iter: 1613 loss: 0.00216924166
Iter: 1614 loss: 0.00216918811
Iter: 1615 loss: 0.0021692575
Iter: 1616 loss: 0.00216916017
Iter: 1617 loss: 0.00216909684
Iter: 1618 loss: 0.00216960977
Iter: 1619 loss: 0.00216908986
Iter: 1620 loss: 0.00216904795
Iter: 1621 loss: 0.00216905121
Iter: 1622 loss: 0.00216901023
Iter: 1623 loss: 0.00216897205
Iter: 1624 loss: 0.00216959231
Iter: 1625 loss: 0.00216897158
Iter: 1626 loss: 0.00216895062
Iter: 1627 loss: 0.00216894574
Iter: 1628 loss: 0.0021689306
Iter: 1629 loss: 0.00216891128
Iter: 1630 loss: 0.00216891197
Iter: 1631 loss: 0.00216888334
Iter: 1632 loss: 0.00216894969
Iter: 1633 loss: 0.00216887239
Iter: 1634 loss: 0.00216884445
Iter: 1635 loss: 0.00216882862
Iter: 1636 loss: 0.00216881977
Iter: 1637 loss: 0.00216877181
Iter: 1638 loss: 0.00216878275
Iter: 1639 loss: 0.00216873712
Iter: 1640 loss: 0.00216868147
Iter: 1641 loss: 0.00216883305
Iter: 1642 loss: 0.00216866727
Iter: 1643 loss: 0.0021686072
Iter: 1644 loss: 0.0021688221
Iter: 1645 loss: 0.00216859113
Iter: 1646 loss: 0.00216854154
Iter: 1647 loss: 0.00216857623
Iter: 1648 loss: 0.00216851
Iter: 1649 loss: 0.00216845749
Iter: 1650 loss: 0.00216898322
Iter: 1651 loss: 0.00216845237
Iter: 1652 loss: 0.00216840883
Iter: 1653 loss: 0.00216841302
Iter: 1654 loss: 0.00216837297
Iter: 1655 loss: 0.00216832547
Iter: 1656 loss: 0.00216857088
Iter: 1657 loss: 0.002168315
Iter: 1658 loss: 0.00216828752
Iter: 1659 loss: 0.00216828194
Iter: 1660 loss: 0.00216826517
Iter: 1661 loss: 0.00216824
Iter: 1662 loss: 0.00216824072
Iter: 1663 loss: 0.00216820394
Iter: 1664 loss: 0.0021682959
Iter: 1665 loss: 0.00216819067
Iter: 1666 loss: 0.00216815807
Iter: 1667 loss: 0.0021681264
Iter: 1668 loss: 0.00216812105
Iter: 1669 loss: 0.00216805283
Iter: 1670 loss: 0.00216807565
Iter: 1671 loss: 0.00216800952
Iter: 1672 loss: 0.00216794037
Iter: 1673 loss: 0.00216815015
Iter: 1674 loss: 0.00216791872
Iter: 1675 loss: 0.00216784887
Iter: 1676 loss: 0.00216813106
Iter: 1677 loss: 0.00216783211
Iter: 1678 loss: 0.00216777832
Iter: 1679 loss: 0.00216782722
Iter: 1680 loss: 0.00216774573
Iter: 1681 loss: 0.00216768542
Iter: 1682 loss: 0.00216816273
Iter: 1683 loss: 0.00216768216
Iter: 1684 loss: 0.00216762861
Iter: 1685 loss: 0.00216767844
Iter: 1686 loss: 0.00216759858
Iter: 1687 loss: 0.00216755387
Iter: 1688 loss: 0.00216780556
Iter: 1689 loss: 0.00216754875
Iter: 1690 loss: 0.00216752617
Iter: 1691 loss: 0.00216752547
Iter: 1692 loss: 0.00216750894
Iter: 1693 loss: 0.0021674931
Iter: 1694 loss: 0.00216749124
Iter: 1695 loss: 0.00216746423
Iter: 1696 loss: 0.00216751662
Iter: 1697 loss: 0.00216745446
Iter: 1698 loss: 0.00216742698
Iter: 1699 loss: 0.00216740347
Iter: 1700 loss: 0.00216739392
Iter: 1701 loss: 0.00216733245
Iter: 1702 loss: 0.00216740044
Iter: 1703 loss: 0.00216730521
Iter: 1704 loss: 0.00216724956
Iter: 1705 loss: 0.00216740975
Iter: 1706 loss: 0.00216723303
Iter: 1707 loss: 0.00216717669
Iter: 1708 loss: 0.00216746144
Iter: 1709 loss: 0.0021671704
Iter: 1710 loss: 0.00216712803
Iter: 1711 loss: 0.00216716225
Iter: 1712 loss: 0.00216710148
Iter: 1713 loss: 0.00216705119
Iter: 1714 loss: 0.00216732686
Iter: 1715 loss: 0.00216704723
Iter: 1716 loss: 0.00216699508
Iter: 1717 loss: 0.00216702442
Iter: 1718 loss: 0.00216696761
Iter: 1719 loss: 0.00216692407
Iter: 1720 loss: 0.00216747122
Iter: 1721 loss: 0.00216692104
Iter: 1722 loss: 0.00216690963
Iter: 1723 loss: 0.00216690195
Iter: 1724 loss: 0.00216688751
Iter: 1725 loss: 0.00216686958
Iter: 1726 loss: 0.00216731
Iter: 1727 loss: 0.00216686912
Iter: 1728 loss: 0.0021668463
Iter: 1729 loss: 0.0021668952
Iter: 1730 loss: 0.00216683955
Iter: 1731 loss: 0.00216681254
Iter: 1732 loss: 0.00216678437
Iter: 1733 loss: 0.00216678157
Iter: 1734 loss: 0.00216673152
Iter: 1735 loss: 0.00216685375
Iter: 1736 loss: 0.00216671103
Iter: 1737 loss: 0.00216666865
Iter: 1738 loss: 0.00216673547
Iter: 1739 loss: 0.0021666442
Iter: 1740 loss: 0.00216659741
Iter: 1741 loss: 0.00216689124
Iter: 1742 loss: 0.00216658902
Iter: 1743 loss: 0.00216655061
Iter: 1744 loss: 0.00216658297
Iter: 1745 loss: 0.00216652965
Iter: 1746 loss: 0.00216648146
Iter: 1747 loss: 0.00216674106
Iter: 1748 loss: 0.00216647796
Iter: 1749 loss: 0.00216643093
Iter: 1750 loss: 0.00216641719
Iter: 1751 loss: 0.00216639205
Iter: 1752 loss: 0.00216632569
Iter: 1753 loss: 0.00216639
Iter: 1754 loss: 0.00216629193
Iter: 1755 loss: 0.00216635922
Iter: 1756 loss: 0.00216625491
Iter: 1757 loss: 0.00216623745
Iter: 1758 loss: 0.00216620881
Iter: 1759 loss: 0.00216666888
Iter: 1760 loss: 0.00216620462
Iter: 1761 loss: 0.00216616
Iter: 1762 loss: 0.00216625188
Iter: 1763 loss: 0.00216614339
Iter: 1764 loss: 0.00216610241
Iter: 1765 loss: 0.00216605142
Iter: 1766 loss: 0.0021660442
Iter: 1767 loss: 0.00216596853
Iter: 1768 loss: 0.00216625165
Iter: 1769 loss: 0.00216594967
Iter: 1770 loss: 0.00216589146
Iter: 1771 loss: 0.0021659676
Iter: 1772 loss: 0.00216586026
Iter: 1773 loss: 0.00216579763
Iter: 1774 loss: 0.0021661697
Iter: 1775 loss: 0.00216579065
Iter: 1776 loss: 0.00216573663
Iter: 1777 loss: 0.00216580648
Iter: 1778 loss: 0.00216571358
Iter: 1779 loss: 0.00216566236
Iter: 1780 loss: 0.00216599135
Iter: 1781 loss: 0.00216565351
Iter: 1782 loss: 0.00216560927
Iter: 1783 loss: 0.00216564536
Iter: 1784 loss: 0.00216558063
Iter: 1785 loss: 0.00216552243
Iter: 1786 loss: 0.00216538948
Iter: 1787 loss: 0.00216693012
Iter: 1788 loss: 0.002165379
Iter: 1789 loss: 0.00216623908
Iter: 1790 loss: 0.00216535269
Iter: 1791 loss: 0.00216534245
Iter: 1792 loss: 0.00216531847
Iter: 1793 loss: 0.00216577156
Iter: 1794 loss: 0.00216531521
Iter: 1795 loss: 0.00216529355
Iter: 1796 loss: 0.00216540066
Iter: 1797 loss: 0.0021652868
Iter: 1798 loss: 0.00216526445
Iter: 1799 loss: 0.00216524187
Iter: 1800 loss: 0.00216523255
Iter: 1801 loss: 0.00216520205
Iter: 1802 loss: 0.00216534501
Iter: 1803 loss: 0.00216519972
Iter: 1804 loss: 0.00216517784
Iter: 1805 loss: 0.00216521649
Iter: 1806 loss: 0.00216516573
Iter: 1807 loss: 0.00216514082
Iter: 1808 loss: 0.00216520135
Iter: 1809 loss: 0.00216513127
Iter: 1810 loss: 0.00216510496
Iter: 1811 loss: 0.00216514198
Iter: 1812 loss: 0.0021650868
Iter: 1813 loss: 0.00216504931
Iter: 1814 loss: 0.00216512335
Iter: 1815 loss: 0.00216503604
Iter: 1816 loss: 0.00216499227
Iter: 1817 loss: 0.00216501253
Iter: 1818 loss: 0.002164962
Iter: 1819 loss: 0.00216490729
Iter: 1820 loss: 0.00216484745
Iter: 1821 loss: 0.00216483697
Iter: 1822 loss: 0.00216480903
Iter: 1823 loss: 0.00216483884
Iter: 1824 loss: 0.00216479227
Iter: 1825 loss: 0.00216478831
Iter: 1826 loss: 0.00216477574
Iter: 1827 loss: 0.00216475595
Iter: 1828 loss: 0.00216483511
Iter: 1829 loss: 0.00216475595
Iter: 1830 loss: 0.00216474873
Iter: 1831 loss: 0.00216474547
Iter: 1832 loss: 0.00216474058
Iter: 1833 loss: 0.00216473825
Iter: 1834 loss: 0.00216472801
Iter: 1835 loss: 0.0021648
Iter: 1836 loss: 0.00216472382
Iter: 1837 loss: 0.00216469774
Iter: 1838 loss: 0.00216467027
Iter: 1839 loss: 0.00216466282
Iter: 1840 loss: 0.00216462719
Iter: 1841 loss: 0.00216510985
Iter: 1842 loss: 0.00216462836
Iter: 1843 loss: 0.00216460461
Iter: 1844 loss: 0.00216458063
Iter: 1845 loss: 0.00216457271
Iter: 1846 loss: 0.00216453383
Iter: 1847 loss: 0.00216484792
Iter: 1848 loss: 0.0021645315
Iter: 1849 loss: 0.00216451
Iter: 1850 loss: 0.00216459483
Iter: 1851 loss: 0.00216450286
Iter: 1852 loss: 0.00216448097
Iter: 1853 loss: 0.00216449611
Iter: 1854 loss: 0.00216446444
Iter: 1855 loss: 0.00216443813
Iter: 1856 loss: 0.00216445629
Iter: 1857 loss: 0.0021644251
Iter: 1858 loss: 0.00216441206
Iter: 1859 loss: 0.002164406
Iter: 1860 loss: 0.00216438412
Iter: 1861 loss: 0.00216452312
Iter: 1862 loss: 0.00216438249
Iter: 1863 loss: 0.00216437387
Iter: 1864 loss: 0.00216435501
Iter: 1865 loss: 0.0021647159
Iter: 1866 loss: 0.00216435175
Iter: 1867 loss: 0.00216433709
Iter: 1868 loss: 0.00216434617
Iter: 1869 loss: 0.00216432381
Iter: 1870 loss: 0.00216429937
Iter: 1871 loss: 0.00216427608
Iter: 1872 loss: 0.00216427026
Iter: 1873 loss: 0.00216424116
Iter: 1874 loss: 0.00216461834
Iter: 1875 loss: 0.00216424209
Iter: 1876 loss: 0.00216421857
Iter: 1877 loss: 0.00216432381
Iter: 1878 loss: 0.00216421345
Iter: 1879 loss: 0.0021641925
Iter: 1880 loss: 0.00216422346
Iter: 1881 loss: 0.00216418691
Iter: 1882 loss: 0.00216416572
Iter: 1883 loss: 0.0021642386
Iter: 1884 loss: 0.00216415757
Iter: 1885 loss: 0.00216414267
Iter: 1886 loss: 0.00216416
Iter: 1887 loss: 0.00216413359
Iter: 1888 loss: 0.00216410379
Iter: 1889 loss: 0.00216417224
Iter: 1890 loss: 0.00216409378
Iter: 1891 loss: 0.00216406677
Iter: 1892 loss: 0.00216416502
Iter: 1893 loss: 0.00216405909
Iter: 1894 loss: 0.00216405839
Iter: 1895 loss: 0.00216404628
Iter: 1896 loss: 0.0021640386
Iter: 1897 loss: 0.00216401555
Iter: 1898 loss: 0.00216407329
Iter: 1899 loss: 0.00216400577
Iter: 1900 loss: 0.00216398435
Iter: 1901 loss: 0.00216416176
Iter: 1902 loss: 0.00216398505
Iter: 1903 loss: 0.00216397131
Iter: 1904 loss: 0.00216399
Iter: 1905 loss: 0.00216396805
Iter: 1906 loss: 0.00216394966
Iter: 1907 loss: 0.00216395874
Iter: 1908 loss: 0.00216394104
Iter: 1909 loss: 0.00216392614
Iter: 1910 loss: 0.00216392474
Iter: 1911 loss: 0.00216391217
Iter: 1912 loss: 0.00216388376
Iter: 1913 loss: 0.00216384232
Iter: 1914 loss: 0.00216384232
Iter: 1915 loss: 0.00216381694
Iter: 1916 loss: 0.00216381298
Iter: 1917 loss: 0.00216379156
Iter: 1918 loss: 0.0021638209
Iter: 1919 loss: 0.00216378248
Iter: 1920 loss: 0.00216376805
Iter: 1921 loss: 0.00216394779
Iter: 1922 loss: 0.00216376758
Iter: 1923 loss: 0.00216376036
Iter: 1924 loss: 0.00216380786
Iter: 1925 loss: 0.00216375897
Iter: 1926 loss: 0.00216375431
Iter: 1927 loss: 0.00216375361
Iter: 1928 loss: 0.00216375128
Iter: 1929 loss: 0.00216374081
Iter: 1930 loss: 0.0021637578
Iter: 1931 loss: 0.00216373568
Iter: 1932 loss: 0.00216372637
Iter: 1933 loss: 0.0021637138
Iter: 1934 loss: 0.00216371519
Iter: 1935 loss: 0.00216370262
Iter: 1936 loss: 0.00216368353
Iter: 1937 loss: 0.0021636819
Iter: 1938 loss: 0.00216367189
Iter: 1939 loss: 0.00216368446
Iter: 1940 loss: 0.00216366583
Iter: 1941 loss: 0.00216366025
Iter: 1942 loss: 0.00216364511
Iter: 1943 loss: 0.00216368656
Iter: 1944 loss: 0.00216363976
Iter: 1945 loss: 0.00216362253
Iter: 1946 loss: 0.00216372102
Iter: 1947 loss: 0.00216362253
Iter: 1948 loss: 0.00216361554
Iter: 1949 loss: 0.00216360018
Iter: 1950 loss: 0.00216360157
Iter: 1951 loss: 0.0021635904
Iter: 1952 loss: 0.00216357084
Iter: 1953 loss: 0.00216393988
Iter: 1954 loss: 0.00216357177
Iter: 1955 loss: 0.00216355687
Iter: 1956 loss: 0.00216354337
Iter: 1957 loss: 0.00216353871
Iter: 1958 loss: 0.00216352521
Iter: 1959 loss: 0.00216353498
Iter: 1960 loss: 0.00216352148
Iter: 1961 loss: 0.00216350658
Iter: 1962 loss: 0.00216352101
Iter: 1963 loss: 0.00216349773
Iter: 1964 loss: 0.00216349075
Iter: 1965 loss: 0.0021636656
Iter: 1966 loss: 0.00216349121
Iter: 1967 loss: 0.00216348143
Iter: 1968 loss: 0.00216347119
Iter: 1969 loss: 0.00216347445
Iter: 1970 loss: 0.002163467
Iter: 1971 loss: 0.00216346327
Iter: 1972 loss: 0.00216345512
Iter: 1973 loss: 0.00216346188
Iter: 1974 loss: 0.00216345116
Iter: 1975 loss: 0.00216343766
Iter: 1976 loss: 0.0021634635
Iter: 1977 loss: 0.00216343114
Iter: 1978 loss: 0.00216342113
Iter: 1979 loss: 0.00216342788
Iter: 1980 loss: 0.00216340972
Iter: 1981 loss: 0.00216339738
Iter: 1982 loss: 0.00216360413
Iter: 1983 loss: 0.00216339622
Iter: 1984 loss: 0.00216338737
Iter: 1985 loss: 0.002163433
Iter: 1986 loss: 0.00216338458
Iter: 1987 loss: 0.00216338271
Iter: 1988 loss: 0.00216339668
Iter: 1989 loss: 0.00216337875
Iter: 1990 loss: 0.00216337387
Iter: 1991 loss: 0.0021633727
Iter: 1992 loss: 0.00216336874
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3
+ date
Tue Oct 27 21:07:35 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi -1 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1f484de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1b2b19488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1b2b19e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1b2a69e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c14a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c14a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c0b58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c0e5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c0e5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c099d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c05b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb18c066f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb17009f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1700ad7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1700add90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb17009f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb170032a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1700adea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb170032ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc788f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc7a27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc75d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc71c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc6ba510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc6ba400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc6ba268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc6ac9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc655950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc6ac510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc6ac2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc5bd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc5de378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc5de840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc582ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc5a7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0fc564510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0402047858
Iter: 2 loss: 1.80971789
Iter: 3 loss: 1.76477635
Iter: 4 loss: 1.16264653
Iter: 5 loss: 1.12992883
Iter: 6 loss: 0.754682064
Iter: 7 loss: 0.725226283
Iter: 8 loss: 0.469578892
Iter: 9 loss: 0.439107
Iter: 10 loss: 0.260946572
Iter: 11 loss: 0.230273694
Iter: 12 loss: 0.117398202
Iter: 13 loss: 0.0945225209
Iter: 14 loss: 0.0408483371
Iter: 15 loss: 0.0325163
Iter: 16 loss: 0.0261786692
Iter: 17 loss: 0.0179632343
Iter: 18 loss: 0.0168530308
Iter: 19 loss: 0.0258809179
Iter: 20 loss: 0.0152212046
Iter: 21 loss: 0.0122886263
Iter: 22 loss: 0.0120461881
Iter: 23 loss: 0.0100176502
Iter: 24 loss: 0.0364389755
Iter: 25 loss: 0.00979371
Iter: 26 loss: 0.00691529084
Iter: 27 loss: 0.0176127087
Iter: 28 loss: 0.00674931239
Iter: 29 loss: 0.00628642365
Iter: 30 loss: 0.0071399468
Iter: 31 loss: 0.0060490747
Iter: 32 loss: 0.00575809786
Iter: 33 loss: 0.0056016231
Iter: 34 loss: 0.00547135342
Iter: 35 loss: 0.00483537372
Iter: 36 loss: 0.00495276367
Iter: 37 loss: 0.00441205688
Iter: 38 loss: 0.00400107633
Iter: 39 loss: 0.00477526337
Iter: 40 loss: 0.00381358434
Iter: 41 loss: 0.00343836169
Iter: 42 loss: 0.00482598227
Iter: 43 loss: 0.00334351324
Iter: 44 loss: 0.00318483822
Iter: 45 loss: 0.00372423371
Iter: 46 loss: 0.00315109151
Iter: 47 loss: 0.00308185769
Iter: 48 loss: 0.00304332888
Iter: 49 loss: 0.00301190931
Iter: 50 loss: 0.00294208713
Iter: 51 loss: 0.00290427776
Iter: 52 loss: 0.00287409592
Iter: 53 loss: 0.00277422578
Iter: 54 loss: 0.00345646776
Iter: 55 loss: 0.00276720943
Iter: 56 loss: 0.00269458164
Iter: 57 loss: 0.00285655865
Iter: 58 loss: 0.0026660366
Iter: 59 loss: 0.00262372568
Iter: 60 loss: 0.00259696459
Iter: 61 loss: 0.00258105295
Iter: 62 loss: 0.00259767426
Iter: 63 loss: 0.00255746907
Iter: 64 loss: 0.00253419043
Iter: 65 loss: 0.00255453913
Iter: 66 loss: 0.00252093887
Iter: 67 loss: 0.00249076984
Iter: 68 loss: 0.00246871
Iter: 69 loss: 0.00245855493
Iter: 70 loss: 0.00242462289
Iter: 71 loss: 0.00244340883
Iter: 72 loss: 0.00240257615
Iter: 73 loss: 0.0023682313
Iter: 74 loss: 0.00264248415
Iter: 75 loss: 0.00236631045
Iter: 76 loss: 0.00234304089
Iter: 77 loss: 0.00236575585
Iter: 78 loss: 0.00232965406
Iter: 79 loss: 0.00230388902
Iter: 80 loss: 0.00239866
Iter: 81 loss: 0.0022979877
Iter: 82 loss: 0.00227939337
Iter: 83 loss: 0.00231785467
Iter: 84 loss: 0.00227175443
Iter: 85 loss: 0.00225405279
Iter: 86 loss: 0.00239330088
Iter: 87 loss: 0.00225307094
Iter: 88 loss: 0.00224321615
Iter: 89 loss: 0.00226359256
Iter: 90 loss: 0.00223921565
Iter: 91 loss: 0.00222932594
Iter: 92 loss: 0.00222607842
Iter: 93 loss: 0.00222044415
Iter: 94 loss: 0.00221216539
Iter: 95 loss: 0.00234032189
Iter: 96 loss: 0.00221216143
Iter: 97 loss: 0.00220471644
Iter: 98 loss: 0.00223185075
Iter: 99 loss: 0.0022029127
Iter: 100 loss: 0.00219672034
Iter: 101 loss: 0.00219500647
Iter: 102 loss: 0.00219120318
Iter: 103 loss: 0.00218453258
Iter: 104 loss: 0.00218431652
Iter: 105 loss: 0.00217914255
Iter: 106 loss: 0.00217281096
Iter: 107 loss: 0.00223080744
Iter: 108 loss: 0.00217254669
Iter: 109 loss: 0.00216777
Iter: 110 loss: 0.0021814825
Iter: 111 loss: 0.00216625538
Iter: 112 loss: 0.00216190517
Iter: 113 loss: 0.00216395943
Iter: 114 loss: 0.00215899409
Iter: 115 loss: 0.00215529511
Iter: 116 loss: 0.00221032649
Iter: 117 loss: 0.00215528719
Iter: 118 loss: 0.0021523966
Iter: 119 loss: 0.00215565832
Iter: 120 loss: 0.00215086201
Iter: 121 loss: 0.00214786
Iter: 122 loss: 0.00217576022
Iter: 123 loss: 0.00214772066
Iter: 124 loss: 0.00214588316
Iter: 125 loss: 0.00214596721
Iter: 126 loss: 0.00214444078
Iter: 127 loss: 0.0021423744
Iter: 128 loss: 0.00215618778
Iter: 129 loss: 0.00214215857
Iter: 130 loss: 0.00214046892
Iter: 131 loss: 0.00215907581
Iter: 132 loss: 0.00214043586
Iter: 133 loss: 0.00213930407
Iter: 134 loss: 0.00213798368
Iter: 135 loss: 0.00213783258
Iter: 136 loss: 0.0021360484
Iter: 137 loss: 0.00214088801
Iter: 138 loss: 0.00213546306
Iter: 139 loss: 0.00213388307
Iter: 140 loss: 0.00213423185
Iter: 141 loss: 0.00213271845
Iter: 142 loss: 0.00213076826
Iter: 143 loss: 0.00213570753
Iter: 144 loss: 0.00213008979
Iter: 145 loss: 0.00212833239
Iter: 146 loss: 0.00214373088
Iter: 147 loss: 0.00212824461
Iter: 148 loss: 0.00212687859
Iter: 149 loss: 0.00212957826
Iter: 150 loss: 0.00212631607
Iter: 151 loss: 0.00212515565
Iter: 152 loss: 0.00213347445
Iter: 153 loss: 0.00212505902
Iter: 154 loss: 0.00212414493
Iter: 155 loss: 0.00213093031
Iter: 156 loss: 0.00212406716
Iter: 157 loss: 0.00212333305
Iter: 158 loss: 0.00212349067
Iter: 159 loss: 0.00212278962
Iter: 160 loss: 0.00212195842
Iter: 161 loss: 0.00212192372
Iter: 162 loss: 0.00212128367
Iter: 163 loss: 0.0021204853
Iter: 164 loss: 0.00212044432
Iter: 165 loss: 0.00211982755
Iter: 166 loss: 0.00211963896
Iter: 167 loss: 0.00211927062
Iter: 168 loss: 0.00211837888
Iter: 169 loss: 0.0021182443
Iter: 170 loss: 0.00211762381
Iter: 171 loss: 0.0021166082
Iter: 172 loss: 0.00211834069
Iter: 173 loss: 0.00211615115
Iter: 174 loss: 0.00211508339
Iter: 175 loss: 0.00212160102
Iter: 176 loss: 0.00211495254
Iter: 177 loss: 0.00211409014
Iter: 178 loss: 0.00211406988
Iter: 179 loss: 0.0021133949
Iter: 180 loss: 0.00211224332
Iter: 181 loss: 0.00212283642
Iter: 182 loss: 0.0021121907
Iter: 183 loss: 0.00211140676
Iter: 184 loss: 0.00211636676
Iter: 185 loss: 0.00211132132
Iter: 186 loss: 0.00211081933
Iter: 187 loss: 0.00211460516
Iter: 188 loss: 0.00211078022
Iter: 189 loss: 0.00211033132
Iter: 190 loss: 0.00211040513
Iter: 191 loss: 0.00210999371
Iter: 192 loss: 0.00210937252
Iter: 193 loss: 0.00210882956
Iter: 194 loss: 0.00210866588
Iter: 195 loss: 0.0021081646
Iter: 196 loss: 0.00210810034
Iter: 197 loss: 0.00210759696
Iter: 198 loss: 0.00210755295
Iter: 199 loss: 0.00210717833
Iter: 200 loss: 0.00210659672
Iter: 201 loss: 0.00210781046
Iter: 202 loss: 0.00210636738
Iter: 203 loss: 0.00210581487
Iter: 204 loss: 0.00210540229
Iter: 205 loss: 0.00210522232
Iter: 206 loss: 0.00210439647
Iter: 207 loss: 0.00210794364
Iter: 208 loss: 0.00210422743
Iter: 209 loss: 0.00210345443
Iter: 210 loss: 0.00210716692
Iter: 211 loss: 0.00210331636
Iter: 212 loss: 0.00210265769
Iter: 213 loss: 0.0021035606
Iter: 214 loss: 0.00210233056
Iter: 215 loss: 0.00210174173
Iter: 216 loss: 0.00211024424
Iter: 217 loss: 0.00210173987
Iter: 218 loss: 0.00210133637
Iter: 219 loss: 0.00210286956
Iter: 220 loss: 0.00210124161
Iter: 221 loss: 0.00210078619
Iter: 222 loss: 0.00210111216
Iter: 223 loss: 0.0021005068
Iter: 224 loss: 0.00209999201
Iter: 225 loss: 0.002100026
Iter: 226 loss: 0.00209959038
Iter: 227 loss: 0.00209911889
Iter: 228 loss: 0.00210533338
Iter: 229 loss: 0.00209911959
Iter: 230 loss: 0.00209867698
Iter: 231 loss: 0.00210004067
Iter: 232 loss: 0.00209854916
Iter: 233 loss: 0.00209818361
Iter: 234 loss: 0.00209793844
Iter: 235 loss: 0.0020978027
Iter: 236 loss: 0.0020972339
Iter: 237 loss: 0.00209833519
Iter: 238 loss: 0.00209699711
Iter: 239 loss: 0.00209639594
Iter: 240 loss: 0.00209692516
Iter: 241 loss: 0.00209604506
Iter: 242 loss: 0.00209544599
Iter: 243 loss: 0.00209846534
Iter: 244 loss: 0.00209534285
Iter: 245 loss: 0.00209477125
Iter: 246 loss: 0.00209735706
Iter: 247 loss: 0.00209466228
Iter: 248 loss: 0.00209422712
Iter: 249 loss: 0.00209611515
Iter: 250 loss: 0.00209414074
Iter: 251 loss: 0.00209375
Iter: 252 loss: 0.00209661573
Iter: 253 loss: 0.00209371606
Iter: 254 loss: 0.00209339708
Iter: 255 loss: 0.00209398521
Iter: 256 loss: 0.00209325738
Iter: 257 loss: 0.00209291093
Iter: 258 loss: 0.00209277123
Iter: 259 loss: 0.0020925831
Iter: 260 loss: 0.00209223432
Iter: 261 loss: 0.00209468324
Iter: 262 loss: 0.00209220336
Iter: 263 loss: 0.00209183013
Iter: 264 loss: 0.00209352863
Iter: 265 loss: 0.00209175749
Iter: 266 loss: 0.00209144712
Iter: 267 loss: 0.00209126435
Iter: 268 loss: 0.0020911363
Iter: 269 loss: 0.00209072232
Iter: 270 loss: 0.00209142733
Iter: 271 loss: 0.00209053559
Iter: 272 loss: 0.00209009531
Iter: 273 loss: 0.00209130673
Iter: 274 loss: 0.00208995095
Iter: 275 loss: 0.00208954513
Iter: 276 loss: 0.00208975398
Iter: 277 loss: 0.00208927458
Iter: 278 loss: 0.00208877982
Iter: 279 loss: 0.00209258986
Iter: 280 loss: 0.00208874512
Iter: 281 loss: 0.00208833208
Iter: 282 loss: 0.00208983244
Iter: 283 loss: 0.00208822731
Iter: 284 loss: 0.00208792975
Iter: 285 loss: 0.00209144
Iter: 286 loss: 0.00208792556
Iter: 287 loss: 0.00208769273
Iter: 288 loss: 0.00208793464
Iter: 289 loss: 0.00208756281
Iter: 290 loss: 0.00208729738
Iter: 291 loss: 0.00208756374
Iter: 292 loss: 0.00208714721
Iter: 293 loss: 0.00208689598
Iter: 294 loss: 0.00208745431
Iter: 295 loss: 0.00208679866
Iter: 296 loss: 0.00208652765
Iter: 297 loss: 0.00208988436
Iter: 298 loss: 0.00208652602
Iter: 299 loss: 0.00208635209
Iter: 300 loss: 0.00208618864
Iter: 301 loss: 0.0020861472
Iter: 302 loss: 0.00208588294
Iter: 303 loss: 0.00208630646
Iter: 304 loss: 0.00208575744
Iter: 305 loss: 0.0020854855
Iter: 306 loss: 0.00208594371
Iter: 307 loss: 0.00208535953
Iter: 308 loss: 0.00208504731
Iter: 309 loss: 0.00208569737
Iter: 310 loss: 0.00208492158
Iter: 311 loss: 0.00208459888
Iter: 312 loss: 0.00208561216
Iter: 313 loss: 0.00208450458
Iter: 314 loss: 0.00208423054
Iter: 315 loss: 0.00208672462
Iter: 316 loss: 0.00208421727
Iter: 317 loss: 0.00208401866
Iter: 318 loss: 0.00208522961
Iter: 319 loss: 0.00208399235
Iter: 320 loss: 0.00208380958
Iter: 321 loss: 0.00208419189
Iter: 322 loss: 0.0020837374
Iter: 323 loss: 0.00208356674
Iter: 324 loss: 0.00208368292
Iter: 325 loss: 0.00208345847
Iter: 326 loss: 0.00208326336
Iter: 327 loss: 0.00208367268
Iter: 328 loss: 0.00208318792
Iter: 329 loss: 0.00208305474
Iter: 330 loss: 0.00208305195
Iter: 331 loss: 0.0020829495
Iter: 332 loss: 0.0020827651
Iter: 333 loss: 0.00208712043
Iter: 334 loss: 0.00208276603
Iter: 335 loss: 0.00208255788
Iter: 336 loss: 0.00208317023
Iter: 337 loss: 0.00208249222
Iter: 338 loss: 0.00208227406
Iter: 339 loss: 0.00208236463
Iter: 340 loss: 0.00208212202
Iter: 341 loss: 0.00208188128
Iter: 342 loss: 0.00208291179
Iter: 343 loss: 0.00208182982
Iter: 344 loss: 0.00208161399
Iter: 345 loss: 0.00208227942
Iter: 346 loss: 0.00208154926
Iter: 347 loss: 0.0020813623
Iter: 348 loss: 0.00208240654
Iter: 349 loss: 0.00208133715
Iter: 350 loss: 0.00208117859
Iter: 351 loss: 0.00208238722
Iter: 352 loss: 0.00208116672
Iter: 353 loss: 0.00208104355
Iter: 354 loss: 0.00208142749
Iter: 355 loss: 0.00208100514
Iter: 356 loss: 0.00208089361
Iter: 357 loss: 0.00208088127
Iter: 358 loss: 0.00208079955
Iter: 359 loss: 0.00208065193
Iter: 360 loss: 0.00208106311
Iter: 361 loss: 0.00208060397
Iter: 362 loss: 0.00208050152
Iter: 363 loss: 0.00208050152
Iter: 364 loss: 0.00208041607
Iter: 365 loss: 0.00208027614
Iter: 366 loss: 0.00208027312
Iter: 367 loss: 0.00208012667
Iter: 368 loss: 0.00208043796
Iter: 369 loss: 0.00208006753
Iter: 370 loss: 0.00207990292
Iter: 371 loss: 0.00208026031
Iter: 372 loss: 0.00207983772
Iter: 373 loss: 0.00207969639
Iter: 374 loss: 0.00207987474
Iter: 375 loss: 0.00207962422
Iter: 376 loss: 0.00207945914
Iter: 377 loss: 0.00208022143
Iter: 378 loss: 0.00207942748
Iter: 379 loss: 0.00207928265
Iter: 380 loss: 0.00207988685
Iter: 381 loss: 0.00207925076
Iter: 382 loss: 0.0020791518
Iter: 383 loss: 0.00208059419
Iter: 384 loss: 0.00207915134
Iter: 385 loss: 0.0020790766
Iter: 386 loss: 0.00207920698
Iter: 387 loss: 0.00207904633
Iter: 388 loss: 0.00207896531
Iter: 389 loss: 0.00207896973
Iter: 390 loss: 0.00207890244
Iter: 391 loss: 0.00207879674
Iter: 392 loss: 0.00207900582
Iter: 393 loss: 0.00207875296
Iter: 394 loss: 0.00207867753
Iter: 395 loss: 0.0020786766
Iter: 396 loss: 0.00207860884
Iter: 397 loss: 0.00207856647
Iter: 398 loss: 0.00207854179
Iter: 399 loss: 0.00207846146
Iter: 400 loss: 0.00207849033
Iter: 401 loss: 0.00207840442
Iter: 402 loss: 0.00207830267
Iter: 403 loss: 0.00207875064
Iter: 404 loss: 0.00207828125
Iter: 405 loss: 0.00207819184
Iter: 406 loss: 0.002078183
Iter: 407 loss: 0.00207811687
Iter: 408 loss: 0.00207799347
Iter: 409 loss: 0.00207841676
Iter: 410 loss: 0.00207796041
Iter: 411 loss: 0.00207785331
Iter: 412 loss: 0.00207880279
Iter: 413 loss: 0.00207784539
Iter: 414 loss: 0.0020777802
Iter: 415 loss: 0.00207830593
Iter: 416 loss: 0.00207777414
Iter: 417 loss: 0.00207771175
Iter: 418 loss: 0.00207785051
Iter: 419 loss: 0.0020776873
Iter: 420 loss: 0.0020776228
Iter: 421 loss: 0.002077654
Iter: 422 loss: 0.00207758253
Iter: 423 loss: 0.0020775022
Iter: 424 loss: 0.00207765028
Iter: 425 loss: 0.00207746914
Iter: 426 loss: 0.0020774249
Iter: 427 loss: 0.00207742117
Iter: 428 loss: 0.0020773788
Iter: 429 loss: 0.00207734923
Iter: 430 loss: 0.00207733479
Iter: 431 loss: 0.00207727402
Iter: 432 loss: 0.00207726774
Iter: 433 loss: 0.00207722513
Iter: 434 loss: 0.00207714667
Iter: 435 loss: 0.00207745587
Iter: 436 loss: 0.00207712874
Iter: 437 loss: 0.0020770519
Iter: 438 loss: 0.00207710871
Iter: 439 loss: 0.00207700324
Iter: 440 loss: 0.00207690941
Iter: 441 loss: 0.00207701256
Iter: 442 loss: 0.00207685819
Iter: 443 loss: 0.0020767746
Iter: 444 loss: 0.0020779476
Iter: 445 loss: 0.00207677414
Iter: 446 loss: 0.00207671709
Iter: 447 loss: 0.0020770214
Iter: 448 loss: 0.00207670685
Iter: 449 loss: 0.00207665097
Iter: 450 loss: 0.00207691779
Iter: 451 loss: 0.00207664329
Iter: 452 loss: 0.00207659882
Iter: 453 loss: 0.00207658834
Iter: 454 loss: 0.00207656226
Iter: 455 loss: 0.0020765
Iter: 456 loss: 0.00207671523
Iter: 457 loss: 0.00207648473
Iter: 458 loss: 0.0020764526
Iter: 459 loss: 0.0020764526
Iter: 460 loss: 0.00207642186
Iter: 461 loss: 0.00207640463
Iter: 462 loss: 0.0020763902
Iter: 463 loss: 0.00207634829
Iter: 464 loss: 0.00207635062
Iter: 465 loss: 0.00207631383
Iter: 466 loss: 0.00207625749
Iter: 467 loss: 0.00207641674
Iter: 468 loss: 0.00207624026
Iter: 469 loss: 0.00207618531
Iter: 470 loss: 0.00207628217
Iter: 471 loss: 0.00207616063
Iter: 472 loss: 0.00207609893
Iter: 473 loss: 0.002076176
Iter: 474 loss: 0.00207606587
Iter: 475 loss: 0.00207600463
Iter: 476 loss: 0.0020764377
Iter: 477 loss: 0.00207600091
Iter: 478 loss: 0.00207595713
Iter: 479 loss: 0.00207637949
Iter: 480 loss: 0.00207595527
Iter: 481 loss: 0.00207592244
Iter: 482 loss: 0.00207606331
Iter: 483 loss: 0.00207591616
Iter: 484 loss: 0.00207588635
Iter: 485 loss: 0.00207586982
Iter: 486 loss: 0.00207585655
Iter: 487 loss: 0.00207581744
Iter: 488 loss: 0.00207598088
Iter: 489 loss: 0.00207580766
Iter: 490 loss: 0.00207577925
Iter: 491 loss: 0.0020760335
Iter: 492 loss: 0.00207577832
Iter: 493 loss: 0.00207574945
Iter: 494 loss: 0.00207577785
Iter: 495 loss: 0.00207573408
Iter: 496 loss: 0.00207570521
Iter: 497 loss: 0.002075681
Iter: 498 loss: 0.00207567192
Iter: 499 loss: 0.00207562884
Iter: 500 loss: 0.00207582396
Iter: 501 loss: 0.00207562186
Iter: 502 loss: 0.00207558298
Iter: 503 loss: 0.00207560905
Iter: 504 loss: 0.00207556
Iter: 505 loss: 0.00207551243
Iter: 506 loss: 0.00207566051
Iter: 507 loss: 0.00207549776
Iter: 508 loss: 0.00207545562
Iter: 509 loss: 0.0020755874
Iter: 510 loss: 0.00207544374
Iter: 511 loss: 0.00207541557
Iter: 512 loss: 0.00207541487
Iter: 513 loss: 0.00207539299
Iter: 514 loss: 0.00207546307
Iter: 515 loss: 0.00207538507
Iter: 516 loss: 0.00207536155
Iter: 517 loss: 0.00207536668
Iter: 518 loss: 0.00207534409
Iter: 519 loss: 0.00207531778
Iter: 520 loss: 0.00207535457
Iter: 521 loss: 0.00207530311
Iter: 522 loss: 0.00207527541
Iter: 523 loss: 0.00207551266
Iter: 524 loss: 0.00207527541
Iter: 525 loss: 0.00207524979
Iter: 526 loss: 0.00207532966
Iter: 527 loss: 0.00207524211
Iter: 528 loss: 0.00207522046
Iter: 529 loss: 0.00207518926
Iter: 530 loss: 0.00207518809
Iter: 531 loss: 0.00207515433
Iter: 532 loss: 0.00207533408
Iter: 533 loss: 0.00207514898
Iter: 534 loss: 0.00207511545
Iter: 535 loss: 0.00207512872
Iter: 536 loss: 0.00207509333
Iter: 537 loss: 0.00207505492
Iter: 538 loss: 0.00207516225
Iter: 539 loss: 0.00207504025
Iter: 540 loss: 0.00207500369
Iter: 541 loss: 0.00207516318
Iter: 542 loss: 0.00207499508
Iter: 543 loss: 0.00207496667
Iter: 544 loss: 0.00207517575
Iter: 545 loss: 0.00207496504
Iter: 546 loss: 0.0020749364
Iter: 547 loss: 0.00207509776
Iter: 548 loss: 0.00207493454
Iter: 549 loss: 0.00207491266
Iter: 550 loss: 0.00207491661
Iter: 551 loss: 0.00207489636
Iter: 552 loss: 0.00207486982
Iter: 553 loss: 0.00207488681
Iter: 554 loss: 0.00207485212
Iter: 555 loss: 0.00207482418
Iter: 556 loss: 0.00207509776
Iter: 557 loss: 0.00207482232
Iter: 558 loss: 0.00207479578
Iter: 559 loss: 0.00207489054
Iter: 560 loss: 0.00207479
Iter: 561 loss: 0.0020747683
Iter: 562 loss: 0.00207474502
Iter: 563 loss: 0.00207474316
Iter: 564 loss: 0.00207471312
Iter: 565 loss: 0.00207478274
Iter: 566 loss: 0.00207470357
Iter: 567 loss: 0.00207466912
Iter: 568 loss: 0.00207475713
Iter: 569 loss: 0.00207465747
Iter: 570 loss: 0.00207462395
Iter: 571 loss: 0.00207465468
Iter: 572 loss: 0.00207460579
Iter: 573 loss: 0.00207457
Iter: 574 loss: 0.00207470916
Iter: 575 loss: 0.00207456
Iter: 576 loss: 0.00207453035
Iter: 577 loss: 0.00207478879
Iter: 578 loss: 0.00207452849
Iter: 579 loss: 0.00207450544
Iter: 580 loss: 0.00207473198
Iter: 581 loss: 0.00207450613
Iter: 582 loss: 0.00207448914
Iter: 583 loss: 0.00207447982
Iter: 584 loss: 0.00207447377
Iter: 585 loss: 0.00207444793
Iter: 586 loss: 0.0020744917
Iter: 587 loss: 0.00207443815
Iter: 588 loss: 0.00207441393
Iter: 589 loss: 0.00207452709
Iter: 590 loss: 0.00207441114
Iter: 591 loss: 0.00207438809
Iter: 592 loss: 0.00207452662
Iter: 593 loss: 0.00207438739
Iter: 594 loss: 0.00207436876
Iter: 595 loss: 0.00207435805
Iter: 596 loss: 0.00207435107
Iter: 597 loss: 0.00207433151
Iter: 598 loss: 0.00207435922
Iter: 599 loss: 0.00207432057
Iter: 600 loss: 0.00207429659
Iter: 601 loss: 0.00207435153
Iter: 602 loss: 0.00207428518
Iter: 603 loss: 0.00207425794
Iter: 604 loss: 0.00207431847
Iter: 605 loss: 0.00207424536
Iter: 606 loss: 0.00207421719
Iter: 607 loss: 0.00207422767
Iter: 608 loss: 0.002074196
Iter: 609 loss: 0.00207416923
Iter: 610 loss: 0.00207416876
Iter: 611 loss: 0.00207414944
Iter: 612 loss: 0.0020743059
Iter: 613 loss: 0.00207414851
Iter: 614 loss: 0.00207413128
Iter: 615 loss: 0.00207413314
Iter: 616 loss: 0.00207411801
Iter: 617 loss: 0.00207409868
Iter: 618 loss: 0.00207410729
Iter: 619 loss: 0.00207408448
Iter: 620 loss: 0.00207406096
Iter: 621 loss: 0.00207420113
Iter: 622 loss: 0.00207405654
Iter: 623 loss: 0.00207403605
Iter: 624 loss: 0.00207422
Iter: 625 loss: 0.00207403488
Iter: 626 loss: 0.00207402115
Iter: 627 loss: 0.00207400578
Iter: 628 loss: 0.00207400112
Iter: 629 loss: 0.00207398343
Iter: 630 loss: 0.00207401556
Iter: 631 loss: 0.00207397249
Iter: 632 loss: 0.00207394641
Iter: 633 loss: 0.00207397551
Iter: 634 loss: 0.00207393174
Iter: 635 loss: 0.00207389914
Iter: 636 loss: 0.00207402417
Iter: 637 loss: 0.002073891
Iter: 638 loss: 0.00207386236
Iter: 639 loss: 0.00207388168
Iter: 640 loss: 0.00207384443
Iter: 641 loss: 0.00207380974
Iter: 642 loss: 0.00207397877
Iter: 643 loss: 0.00207380508
Iter: 644 loss: 0.00207378552
Iter: 645 loss: 0.00207378459
Iter: 646 loss: 0.00207377016
Iter: 647 loss: 0.00207376084
Iter: 648 loss: 0.00207375525
Iter: 649 loss: 0.00207373174
Iter: 650 loss: 0.00207374385
Iter: 651 loss: 0.00207371963
Iter: 652 loss: 0.00207369402
Iter: 653 loss: 0.00207385747
Iter: 654 loss: 0.00207369402
Iter: 655 loss: 0.0020736712
Iter: 656 loss: 0.00207379833
Iter: 657 loss: 0.00207366841
Iter: 658 loss: 0.00207365397
Iter: 659 loss: 0.00207365258
Iter: 660 loss: 0.0020736414
Iter: 661 loss: 0.00207362045
Iter: 662 loss: 0.00207360508
Iter: 663 loss: 0.00207359856
Iter: 664 loss: 0.00207356364
Iter: 665 loss: 0.00207370892
Iter: 666 loss: 0.00207355735
Iter: 667 loss: 0.00207352452
Iter: 668 loss: 0.00207359763
Iter: 669 loss: 0.00207351521
Iter: 670 loss: 0.00207348424
Iter: 671 loss: 0.00207353709
Iter: 672 loss: 0.0020734705
Iter: 673 loss: 0.00207343698
Iter: 674 loss: 0.00207353476
Iter: 675 loss: 0.0020734265
Iter: 676 loss: 0.00207341043
Iter: 677 loss: 0.00207340787
Iter: 678 loss: 0.00207339
Iter: 679 loss: 0.0020733797
Iter: 680 loss: 0.00207337365
Iter: 681 loss: 0.00207335129
Iter: 682 loss: 0.00207339204
Iter: 683 loss: 0.00207333965
Iter: 684 loss: 0.0020733159
Iter: 685 loss: 0.00207337085
Iter: 686 loss: 0.00207330822
Iter: 687 loss: 0.0020732882
Iter: 688 loss: 0.00207354804
Iter: 689 loss: 0.00207328843
Iter: 690 loss: 0.00207327539
Iter: 691 loss: 0.00207326049
Iter: 692 loss: 0.002073257
Iter: 693 loss: 0.00207323232
Iter: 694 loss: 0.00207324466
Iter: 695 loss: 0.00207321555
Iter: 696 loss: 0.00207318366
Iter: 697 loss: 0.00207321532
Iter: 698 loss: 0.00207316596
Iter: 699 loss: 0.0020731315
Iter: 700 loss: 0.00207341556
Iter: 701 loss: 0.00207312987
Iter: 702 loss: 0.0020731024
Iter: 703 loss: 0.00207309937
Iter: 704 loss: 0.00207308
Iter: 705 loss: 0.00207304698
Iter: 706 loss: 0.00207315478
Iter: 707 loss: 0.00207303884
Iter: 708 loss: 0.00207301741
Iter: 709 loss: 0.00207301765
Iter: 710 loss: 0.00207299693
Iter: 711 loss: 0.00207301928
Iter: 712 loss: 0.00207298622
Iter: 713 loss: 0.00207296782
Iter: 714 loss: 0.00207296479
Iter: 715 loss: 0.00207295292
Iter: 716 loss: 0.00207292708
Iter: 717 loss: 0.00207306608
Iter: 718 loss: 0.00207292405
Iter: 719 loss: 0.00207290705
Iter: 720 loss: 0.0020730691
Iter: 721 loss: 0.00207290566
Iter: 722 loss: 0.00207288912
Iter: 723 loss: 0.00207287935
Iter: 724 loss: 0.00207287353
Iter: 725 loss: 0.00207285164
Iter: 726 loss: 0.00207286701
Iter: 727 loss: 0.0020728386
Iter: 728 loss: 0.00207280787
Iter: 729 loss: 0.00207285816
Iter: 730 loss: 0.00207279576
Iter: 731 loss: 0.00207276875
Iter: 732 loss: 0.0020728847
Iter: 733 loss: 0.0020727627
Iter: 734 loss: 0.00207273592
Iter: 735 loss: 0.00207280973
Iter: 736 loss: 0.0020727287
Iter: 737 loss: 0.00207270076
Iter: 738 loss: 0.0020727138
Iter: 739 loss: 0.00207268191
Iter: 740 loss: 0.00207265979
Iter: 741 loss: 0.00207300484
Iter: 742 loss: 0.00207265792
Iter: 743 loss: 0.00207263324
Iter: 744 loss: 0.00207271823
Iter: 745 loss: 0.00207262579
Iter: 746 loss: 0.00207260833
Iter: 747 loss: 0.0020726095
Iter: 748 loss: 0.00207259366
Iter: 749 loss: 0.00207257178
Iter: 750 loss: 0.00207263418
Iter: 751 loss: 0.00207256665
Iter: 752 loss: 0.00207254873
Iter: 753 loss: 0.00207281299
Iter: 754 loss: 0.00207254803
Iter: 755 loss: 0.00207253546
Iter: 756 loss: 0.00207251636
Iter: 757 loss: 0.00207251403
Iter: 758 loss: 0.00207248889
Iter: 759 loss: 0.00207252754
Iter: 760 loss: 0.00207247515
Iter: 761 loss: 0.00207244931
Iter: 762 loss: 0.00207248121
Iter: 763 loss: 0.00207243743
Iter: 764 loss: 0.00207241136
Iter: 765 loss: 0.00207257
Iter: 766 loss: 0.00207240693
Iter: 767 loss: 0.00207238365
Iter: 768 loss: 0.00207239226
Iter: 769 loss: 0.00207236828
Iter: 770 loss: 0.00207233196
Iter: 771 loss: 0.0020724216
Iter: 772 loss: 0.00207232288
Iter: 773 loss: 0.00207229261
Iter: 774 loss: 0.00207244465
Iter: 775 loss: 0.00207228493
Iter: 776 loss: 0.00207226072
Iter: 777 loss: 0.00207225978
Iter: 778 loss: 0.00207224721
Iter: 779 loss: 0.0020722223
Iter: 780 loss: 0.00207281206
Iter: 781 loss: 0.00207222067
Iter: 782 loss: 0.00207219715
Iter: 783 loss: 0.00207238
Iter: 784 loss: 0.00207219413
Iter: 785 loss: 0.00207217573
Iter: 786 loss: 0.0020723152
Iter: 787 loss: 0.00207217177
Iter: 788 loss: 0.00207215291
Iter: 789 loss: 0.00207216525
Iter: 790 loss: 0.00207214
Iter: 791 loss: 0.00207212241
Iter: 792 loss: 0.00207211659
Iter: 793 loss: 0.00207210425
Iter: 794 loss: 0.00207207818
Iter: 795 loss: 0.00207218598
Iter: 796 loss: 0.00207207212
Iter: 797 loss: 0.00207205047
Iter: 798 loss: 0.00207205769
Iter: 799 loss: 0.0020720344
Iter: 800 loss: 0.00207200623
Iter: 801 loss: 0.0020721443
Iter: 802 loss: 0.00207200088
Iter: 803 loss: 0.00207197131
Iter: 804 loss: 0.0020720046
Iter: 805 loss: 0.00207195361
Iter: 806 loss: 0.00207192497
Iter: 807 loss: 0.00207202532
Iter: 808 loss: 0.00207191752
Iter: 809 loss: 0.00207189657
Iter: 810 loss: 0.00207189471
Iter: 811 loss: 0.00207188446
Iter: 812 loss: 0.00207186257
Iter: 813 loss: 0.00207186304
Iter: 814 loss: 0.00207184
Iter: 815 loss: 0.002071911
Iter: 816 loss: 0.00207183394
Iter: 817 loss: 0.00207181531
Iter: 818 loss: 0.00207204628
Iter: 819 loss: 0.00207181484
Iter: 820 loss: 0.0020718
Iter: 821 loss: 0.00207180879
Iter: 822 loss: 0.00207178877
Iter: 823 loss: 0.00207177037
Iter: 824 loss: 0.00207176572
Iter: 825 loss: 0.00207175547
Iter: 826 loss: 0.00207173149
Iter: 827 loss: 0.00207176828
Iter: 828 loss: 0.00207172101
Iter: 829 loss: 0.0020716968
Iter: 830 loss: 0.00207178947
Iter: 831 loss: 0.00207169144
Iter: 832 loss: 0.00207166607
Iter: 833 loss: 0.00207168376
Iter: 834 loss: 0.0020716479
Iter: 835 loss: 0.0020716188
Iter: 836 loss: 0.00207171147
Iter: 837 loss: 0.00207161228
Iter: 838 loss: 0.00207158038
Iter: 839 loss: 0.00207174942
Iter: 840 loss: 0.00207157759
Iter: 841 loss: 0.00207156129
Iter: 842 loss: 0.00207182765
Iter: 843 loss: 0.00207155943
Iter: 844 loss: 0.00207154313
Iter: 845 loss: 0.00207152823
Iter: 846 loss: 0.00207152381
Iter: 847 loss: 0.00207150681
Iter: 848 loss: 0.00207151938
Iter: 849 loss: 0.00207149633
Iter: 850 loss: 0.00207147794
Iter: 851 loss: 0.00207176525
Iter: 852 loss: 0.0020714784
Iter: 853 loss: 0.0020714635
Iter: 854 loss: 0.00207151123
Iter: 855 loss: 0.00207145815
Iter: 856 loss: 0.00207144674
Iter: 857 loss: 0.00207142369
Iter: 858 loss: 0.00207142439
Iter: 859 loss: 0.00207140041
Iter: 860 loss: 0.0020714784
Iter: 861 loss: 0.00207139435
Iter: 862 loss: 0.0020713727
Iter: 863 loss: 0.00207143649
Iter: 864 loss: 0.00207136292
Iter: 865 loss: 0.00207134173
Iter: 866 loss: 0.00207136082
Iter: 867 loss: 0.00207132939
Iter: 868 loss: 0.00207130332
Iter: 869 loss: 0.00207144092
Iter: 870 loss: 0.00207130052
Iter: 871 loss: 0.0020712777
Iter: 872 loss: 0.0020713429
Iter: 873 loss: 0.00207127072
Iter: 874 loss: 0.00207125954
Iter: 875 loss: 0.00207125978
Iter: 876 loss: 0.00207124557
Iter: 877 loss: 0.00207123626
Iter: 878 loss: 0.00207123207
Iter: 879 loss: 0.0020712167
Iter: 880 loss: 0.00207122485
Iter: 881 loss: 0.00207120739
Iter: 882 loss: 0.0020711883
Iter: 883 loss: 0.00207131286
Iter: 884 loss: 0.00207118806
Iter: 885 loss: 0.00207117
Iter: 886 loss: 0.00207125768
Iter: 887 loss: 0.00207116571
Iter: 888 loss: 0.0020711543
Iter: 889 loss: 0.00207114965
Iter: 890 loss: 0.00207114359
Iter: 891 loss: 0.00207112683
Iter: 892 loss: 0.00207113195
Iter: 893 loss: 0.00207111193
Iter: 894 loss: 0.00207109191
Iter: 895 loss: 0.00207114895
Iter: 896 loss: 0.00207108445
Iter: 897 loss: 0.00207106583
Iter: 898 loss: 0.00207118271
Iter: 899 loss: 0.00207106071
Iter: 900 loss: 0.00207104301
Iter: 901 loss: 0.00207104697
Iter: 902 loss: 0.00207103183
Iter: 903 loss: 0.00207100948
Iter: 904 loss: 0.00207109749
Iter: 905 loss: 0.00207100436
Iter: 906 loss: 0.00207099179
Iter: 907 loss: 0.00207099156
Iter: 908 loss: 0.00207097875
Iter: 909 loss: 0.00207099761
Iter: 910 loss: 0.0020709727
Iter: 911 loss: 0.00207096199
Iter: 912 loss: 0.00207095034
Iter: 913 loss: 0.00207094802
Iter: 914 loss: 0.00207093265
Iter: 915 loss: 0.00207101647
Iter: 916 loss: 0.00207093102
Iter: 917 loss: 0.00207091565
Iter: 918 loss: 0.00207104022
Iter: 919 loss: 0.00207091356
Iter: 920 loss: 0.00207090541
Iter: 921 loss: 0.00207090471
Iter: 922 loss: 0.00207089912
Iter: 923 loss: 0.00207088422
Iter: 924 loss: 0.00207088166
Iter: 925 loss: 0.00207087444
Iter: 926 loss: 0.00207085814
Iter: 927 loss: 0.00207090098
Iter: 928 loss: 0.00207085232
Iter: 929 loss: 0.00207083393
Iter: 930 loss: 0.00207092473
Iter: 931 loss: 0.00207083393
Iter: 932 loss: 0.00207081973
Iter: 933 loss: 0.00207082368
Iter: 934 loss: 0.00207080808
Iter: 935 loss: 0.00207079249
Iter: 936 loss: 0.00207087421
Iter: 937 loss: 0.00207078969
Iter: 938 loss: 0.00207077805
Iter: 939 loss: 0.00207077712
Iter: 940 loss: 0.00207076664
Iter: 941 loss: 0.00207079109
Iter: 942 loss: 0.00207076268
Iter: 943 loss: 0.00207075337
Iter: 944 loss: 0.00207074499
Iter: 945 loss: 0.00207074266
Iter: 946 loss: 0.00207072729
Iter: 947 loss: 0.00207078271
Iter: 948 loss: 0.00207072566
Iter: 949 loss: 0.00207071425
Iter: 950 loss: 0.00207071519
Iter: 951 loss: 0.00207070797
Iter: 952 loss: 0.00207070052
Iter: 953 loss: 0.00207069819
Iter: 954 loss: 0.00207068864
Iter: 955 loss: 0.0020707
Iter: 956 loss: 0.00207068096
Iter: 957 loss: 0.00207066722
Iter: 958 loss: 0.00207069656
Iter: 959 loss: 0.00207066163
Iter: 960 loss: 0.0020706472
Iter: 961 loss: 0.00207065837
Iter: 962 loss: 0.00207063858
Iter: 963 loss: 0.00207062159
Iter: 964 loss: 0.0020707387
Iter: 965 loss: 0.00207062159
Iter: 966 loss: 0.00207060785
Iter: 967 loss: 0.00207062275
Iter: 968 loss: 0.00207059924
Iter: 969 loss: 0.0020705869
Iter: 970 loss: 0.00207067234
Iter: 971 loss: 0.00207058433
Iter: 972 loss: 0.00207057013
Iter: 973 loss: 0.00207066862
Iter: 974 loss: 0.00207057036
Iter: 975 loss: 0.00207056245
Iter: 976 loss: 0.00207055034
Iter: 977 loss: 0.00207055104
Iter: 978 loss: 0.00207053847
Iter: 979 loss: 0.00207059085
Iter: 980 loss: 0.00207053474
Iter: 981 loss: 0.00207052776
Iter: 982 loss: 0.00207052752
Iter: 983 loss: 0.00207052147
Iter: 984 loss: 0.00207051332
Iter: 985 loss: 0.00207051239
Iter: 986 loss: 0.00207050191
Iter: 987 loss: 0.00207050564
Iter: 988 loss: 0.00207049539
Iter: 989 loss: 0.00207048282
Iter: 990 loss: 0.00207054918
Iter: 991 loss: 0.00207047909
Iter: 992 loss: 0.00207046838
Iter: 993 loss: 0.00207047
Iter: 994 loss: 0.0020704614
Iter: 995 loss: 0.00207044696
Iter: 996 loss: 0.00207051728
Iter: 997 loss: 0.00207044603
Iter: 998 loss: 0.00207043579
Iter: 999 loss: 0.00207046536
Iter: 1000 loss: 0.00207042973
Iter: 1001 loss: 0.00207041926
Iter: 1002 loss: 0.00207046256
Iter: 1003 loss: 0.0020704167
Iter: 1004 loss: 0.00207040901
Iter: 1005 loss: 0.00207040785
Iter: 1006 loss: 0.00207040366
Iter: 1007 loss: 0.00207039528
Iter: 1008 loss: 0.00207039714
Iter: 1009 loss: 0.0020703862
Iter: 1010 loss: 0.00207039644
Iter: 1011 loss: 0.00207038107
Iter: 1012 loss: 0.00207037712
Iter: 1013 loss: 0.00207037432
Iter: 1014 loss: 0.00207037083
Iter: 1015 loss: 0.00207036594
Iter: 1016 loss: 0.00207036524
Iter: 1017 loss: 0.00207035593
Iter: 1018 loss: 0.00207035244
Iter: 1019 loss: 0.00207034894
Iter: 1020 loss: 0.0020703359
Iter: 1021 loss: 0.00207038224
Iter: 1022 loss: 0.00207033521
Iter: 1023 loss: 0.0020703238
Iter: 1024 loss: 0.00207037106
Iter: 1025 loss: 0.00207032403
Iter: 1026 loss: 0.00207031332
Iter: 1027 loss: 0.00207031728
Iter: 1028 loss: 0.0020703082
Iter: 1029 loss: 0.00207029795
Iter: 1030 loss: 0.00207031937
Iter: 1031 loss: 0.00207029283
Iter: 1032 loss: 0.00207028305
Iter: 1033 loss: 0.00207039248
Iter: 1034 loss: 0.00207028561
Iter: 1035 loss: 0.00207027746
Iter: 1036 loss: 0.00207033427
Iter: 1037 loss: 0.00207027816
Iter: 1038 loss: 0.00207027467
Iter: 1039 loss: 0.00207027211
Iter: 1040 loss: 0.00207026675
Iter: 1041 loss: 0.00207026047
Iter: 1042 loss: 0.00207025418
Iter: 1043 loss: 0.00207025209
Iter: 1044 loss: 0.00207025162
Iter: 1045 loss: 0.00207025
Iter: 1046 loss: 0.00207024394
Iter: 1047 loss: 0.00207023928
Iter: 1048 loss: 0.00207023718
Iter: 1049 loss: 0.00207023183
Iter: 1050 loss: 0.00207023462
Iter: 1051 loss: 0.00207022578
Iter: 1052 loss: 0.00207021809
Iter: 1053 loss: 0.00207024161
Iter: 1054 loss: 0.00207021437
Iter: 1055 loss: 0.00207020668
Iter: 1056 loss: 0.00207024254
Iter: 1057 loss: 0.00207020435
Iter: 1058 loss: 0.00207019737
Iter: 1059 loss: 0.00207020435
Iter: 1060 loss: 0.00207019411
Iter: 1061 loss: 0.0020701848
Iter: 1062 loss: 0.00207019644
Iter: 1063 loss: 0.00207018107
Iter: 1064 loss: 0.00207017176
Iter: 1065 loss: 0.00207024161
Iter: 1066 loss: 0.00207017036
Iter: 1067 loss: 0.00207016524
Iter: 1068 loss: 0.00207016384
Iter: 1069 loss: 0.00207016151
Iter: 1070 loss: 0.00207016058
Iter: 1071 loss: 0.00207015709
Iter: 1072 loss: 0.00207014987
Iter: 1073 loss: 0.00207015313
Iter: 1074 loss: 0.00207014615
Iter: 1075 loss: 0.00207014102
Iter: 1076 loss: 0.00207022019
Iter: 1077 loss: 0.00207014079
Iter: 1078 loss: 0.00207013777
Iter: 1079 loss: 0.00207014102
Iter: 1080 loss: 0.00207013381
Iter: 1081 loss: 0.00207012938
Iter: 1082 loss: 0.00207012519
Iter: 1083 loss: 0.0020701238
Iter: 1084 loss: 0.00207011611
Iter: 1085 loss: 0.00207016151
Iter: 1086 loss: 0.00207011634
Iter: 1087 loss: 0.00207010959
Iter: 1088 loss: 0.00207010936
Iter: 1089 loss: 0.00207010517
Iter: 1090 loss: 0.00207009865
Iter: 1091 loss: 0.00207016082
Iter: 1092 loss: 0.00207009749
Iter: 1093 loss: 0.00207009027
Iter: 1094 loss: 0.00207009935
Iter: 1095 loss: 0.00207008654
Iter: 1096 loss: 0.00207008026
Iter: 1097 loss: 0.00207008678
Iter: 1098 loss: 0.00207007676
Iter: 1099 loss: 0.00207007281
Iter: 1100 loss: 0.00207007281
Iter: 1101 loss: 0.00207006745
Iter: 1102 loss: 0.00207006675
Iter: 1103 loss: 0.00207006396
Iter: 1104 loss: 0.0020700579
Iter: 1105 loss: 0.00207006745
Iter: 1106 loss: 0.00207005488
Iter: 1107 loss: 0.00207005162
Iter: 1108 loss: 0.00207008026
Iter: 1109 loss: 0.00207005045
Iter: 1110 loss: 0.00207004417
Iter: 1111 loss: 0.00207006373
Iter: 1112 loss: 0.00207004393
Iter: 1113 loss: 0.00207004067
Iter: 1114 loss: 0.00207003439
Iter: 1115 loss: 0.00207017083
Iter: 1116 loss: 0.00207003346
Iter: 1117 loss: 0.00207002671
Iter: 1118 loss: 0.00207007769
Iter: 1119 loss: 0.0020700274
Iter: 1120 loss: 0.00207002135
Iter: 1121 loss: 0.00207001762
Iter: 1122 loss: 0.00207001809
Iter: 1123 loss: 0.00207000808
Iter: 1124 loss: 0.00207008258
Iter: 1125 loss: 0.00207001064
Iter: 1126 loss: 0.00207000296
Iter: 1127 loss: 0.00207000924
Iter: 1128 loss: 0.00207
Iter: 1129 loss: 0.00206999388
Iter: 1130 loss: 0.00207000249
Iter: 1131 loss: 0.00206999388
Iter: 1132 loss: 0.00206998829
Iter: 1133 loss: 0.00206998759
Iter: 1134 loss: 0.0020699841
Iter: 1135 loss: 0.00206998619
Iter: 1136 loss: 0.0020699813
Iter: 1137 loss: 0.00206997688
Iter: 1138 loss: 0.00206997897
Iter: 1139 loss: 0.00206997525
Iter: 1140 loss: 0.00206996896
Iter: 1141 loss: 0.00206998549
Iter: 1142 loss: 0.00206996594
Iter: 1143 loss: 0.00206996175
Iter: 1144 loss: 0.00207001
Iter: 1145 loss: 0.00206996175
Iter: 1146 loss: 0.00206995965
Iter: 1147 loss: 0.00206995453
Iter: 1148 loss: 0.00206995476
Iter: 1149 loss: 0.00206995197
Iter: 1150 loss: 0.00206996151
Iter: 1151 loss: 0.00206994871
Iter: 1152 loss: 0.00206994335
Iter: 1153 loss: 0.00206995429
Iter: 1154 loss: 0.00206994242
Iter: 1155 loss: 0.0020699352
Iter: 1156 loss: 0.00206994731
Iter: 1157 loss: 0.00206993427
Iter: 1158 loss: 0.00206992845
Iter: 1159 loss: 0.00206994638
Iter: 1160 loss: 0.00206992752
Iter: 1161 loss: 0.00206992216
Iter: 1162 loss: 0.00206993823
Iter: 1163 loss: 0.00206992123
Iter: 1164 loss: 0.00206991541
Iter: 1165 loss: 0.00206992961
Iter: 1166 loss: 0.00206991495
Iter: 1167 loss: 0.00206991052
Iter: 1168 loss: 0.00206996896
Iter: 1169 loss: 0.00206991239
Iter: 1170 loss: 0.00206990959
Iter: 1171 loss: 0.00206990447
Iter: 1172 loss: 0.00206997572
Iter: 1173 loss: 0.00206990307
Iter: 1174 loss: 0.00206989981
Iter: 1175 loss: 0.00206993287
Iter: 1176 loss: 0.00206989911
Iter: 1177 loss: 0.00206989655
Iter: 1178 loss: 0.00206989748
Iter: 1179 loss: 0.00206989283
Iter: 1180 loss: 0.00206989143
Iter: 1181 loss: 0.00206989213
Iter: 1182 loss: 0.00206988933
Iter: 1183 loss: 0.00206988724
Iter: 1184 loss: 0.00206988445
Iter: 1185 loss: 0.00206988188
Iter: 1186 loss: 0.00206990261
Iter: 1187 loss: 0.00206988119
Iter: 1188 loss: 0.00206987653
Iter: 1189 loss: 0.00206989399
Iter: 1190 loss: 0.0020698749
Iter: 1191 loss: 0.00206987141
Iter: 1192 loss: 0.0020698749
Iter: 1193 loss: 0.00206987
Iter: 1194 loss: 0.00206986582
Iter: 1195 loss: 0.00206988631
Iter: 1196 loss: 0.00206986396
Iter: 1197 loss: 0.00206986163
Iter: 1198 loss: 0.00206987234
Iter: 1199 loss: 0.00206986186
Iter: 1200 loss: 0.0020698586
Iter: 1201 loss: 0.00206985883
Iter: 1202 loss: 0.00206985697
Iter: 1203 loss: 0.00206985464
Iter: 1204 loss: 0.0020699231
Iter: 1205 loss: 0.00206985581
Iter: 1206 loss: 0.00206985045
Iter: 1207 loss: 0.00206985325
Iter: 1208 loss: 0.00206985
Iter: 1209 loss: 0.00206984929
Iter: 1210 loss: 0.00206984812
Iter: 1211 loss: 0.00206984673
Iter: 1212 loss: 0.00206984533
Iter: 1213 loss: 0.0020698437
Iter: 1214 loss: 0.00206984254
Iter: 1215 loss: 0.0020698451
Iter: 1216 loss: 0.0020698416
Iter: 1217 loss: 0.00206984021
Iter: 1218 loss: 0.00206984067
Iter: 1219 loss: 0.00206983648
Iter: 1220 loss: 0.00206983346
Iter: 1221 loss: 0.00206984743
Iter: 1222 loss: 0.00206983322
Iter: 1223 loss: 0.00206982903
Iter: 1224 loss: 0.00206984906
Iter: 1225 loss: 0.0020698295
Iter: 1226 loss: 0.00206982763
Iter: 1227 loss: 0.00206982857
Iter: 1228 loss: 0.00206982484
Iter: 1229 loss: 0.00206982205
Iter: 1230 loss: 0.00206982857
Iter: 1231 loss: 0.00206982158
Iter: 1232 loss: 0.00206981925
Iter: 1233 loss: 0.00206981972
Iter: 1234 loss: 0.00206981832
Iter: 1235 loss: 0.00206981809
Iter: 1236 loss: 0.00206981692
Iter: 1237 loss: 0.00206981692
Iter: 1238 loss: 0.00206981436
Iter: 1239 loss: 0.0020698146
Iter: 1240 loss: 0.0020698132
Iter: 1241 loss: 0.00206981273
Iter: 1242 loss: 0.00206981157
Iter: 1243 loss: 0.00206981
Iter: 1244 loss: 0.00206980947
Iter: 1245 loss: 0.00206980715
Iter: 1246 loss: 0.00206980808
Iter: 1247 loss: 0.00206980621
Iter: 1248 loss: 0.00206980319
Iter: 1249 loss: 0.00206981087
Iter: 1250 loss: 0.00206980389
Iter: 1251 loss: 0.00206980202
Iter: 1252 loss: 0.00206980505
Iter: 1253 loss: 0.00206980249
Iter: 1254 loss: 0.00206980109
Iter: 1255 loss: 0.00206980505
Iter: 1256 loss: 0.0020697983
Iter: 1257 loss: 0.00206979457
Iter: 1258 loss: 0.00206980482
Iter: 1259 loss: 0.00206979341
Iter: 1260 loss: 0.00206979271
Iter: 1261 loss: 0.00206979876
Iter: 1262 loss: 0.00206979224
Iter: 1263 loss: 0.00206979178
Iter: 1264 loss: 0.00206981
Iter: 1265 loss: 0.00206979178
Iter: 1266 loss: 0.00206978922
Iter: 1267 loss: 0.00206979434
Iter: 1268 loss: 0.00206978922
Iter: 1269 loss: 0.00206978689
Iter: 1270 loss: 0.00206978596
Iter: 1271 loss: 0.00206981669
Iter: 1272 loss: 0.00206978526
Iter: 1273 loss: 0.00206978503
Iter: 1274 loss: 0.00206980063
Iter: 1275 loss: 0.00206978433
Iter: 1276 loss: 0.0020697834
Iter: 1277 loss: 0.00206978712
Iter: 1278 loss: 0.00206978433
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/k3
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0
+ date
Tue Oct 27 21:12:47 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ec1b51d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ec1b779d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ec1b51c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7dda4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7ddd71e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7ddd7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7ddd7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7ddd7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7ddd76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e5848ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e7dd37e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58456ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e583fa598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58456730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e5841ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e583faa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58323598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58323510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e582f7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e582f7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58338c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58262950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e582a0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58231f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58231ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58203840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e582030d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e581b8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58203730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e5816d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58133a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58133c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e581339d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e5810ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e580d4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e58067ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00540518202
Iter: 2 loss: 0.00538668782
Iter: 3 loss: 0.00533113815
Iter: 4 loss: 0.00549482368
Iter: 5 loss: 0.00530285807
Iter: 6 loss: 0.00527658453
Iter: 7 loss: 0.00527497288
Iter: 8 loss: 0.00527169462
Iter: 9 loss: 0.00527226366
Iter: 10 loss: 0.005269235
Iter: 11 loss: 0.00526905851
Iter: 12 loss: 0.00526887644
Iter: 13 loss: 0.0052686967
Iter: 14 loss: 0.00526947156
Iter: 15 loss: 0.00526865944
Iter: 16 loss: 0.0052686464
Iter: 17 loss: 0.00526877772
Iter: 18 loss: 0.00526864408
Iter: 19 loss: 0.00526863802
Iter: 20 loss: 0.00526872
Iter: 21 loss: 0.00526863756
Iter: 22 loss: 0.00526863756
Iter: 23 loss: 0.00526863849
Iter: 24 loss: 0.00526863709
Iter: 25 loss: 0.00526863709
Iter: 26 loss: 0.00526863616
Iter: 27 loss: 0.00526863709
Iter: 28 loss: 0.00526863663
Iter: 29 loss: 0.00526863616
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4
+ date
Tue Oct 27 21:13:11 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240f9dc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2450f05730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2450f05ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2450f052f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240f8ff6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240f9148c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23e8063f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d01180d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d0136ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d0136e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d0091b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d00a2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d004d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d004dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23d005ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f238473a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f238474e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23846ec158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23846bb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23846dc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23846dc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2384696ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2384650048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f238465cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23845f9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23846039d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23845c1c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23845c19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2384589d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23845396a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23844f1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f238450c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f238450cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23844ac378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23844ac268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23844d86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0320068374
Iter: 2 loss: 0.027672248
Iter: 3 loss: 0.0148518849
Iter: 4 loss: 0.0549619272
Iter: 5 loss: 0.0082843639
Iter: 6 loss: 0.0073146387
Iter: 7 loss: 0.00691404659
Iter: 8 loss: 0.00641195616
Iter: 9 loss: 0.0124280704
Iter: 10 loss: 0.0063963742
Iter: 11 loss: 0.00628501689
Iter: 12 loss: 0.00666982029
Iter: 13 loss: 0.00625581387
Iter: 14 loss: 0.00623289589
Iter: 15 loss: 0.00622464903
Iter: 16 loss: 0.00621248968
Iter: 17 loss: 0.00623233896
Iter: 18 loss: 0.00620694598
Iter: 19 loss: 0.00620395178
Iter: 20 loss: 0.00620394
Iter: 21 loss: 0.00620307727
Iter: 22 loss: 0.00620304793
Iter: 23 loss: 0.00620290264
Iter: 24 loss: 0.00620325096
Iter: 25 loss: 0.00620285282
Iter: 26 loss: 0.00620282255
Iter: 27 loss: 0.00620282162
Iter: 28 loss: 0.00620280625
Iter: 29 loss: 0.00620290218
Iter: 30 loss: 0.00620280532
Iter: 31 loss: 0.00620280206
Iter: 32 loss: 0.00620280812
Iter: 33 loss: 0.0062028016
Iter: 34 loss: 0.00620280206
Iter: 35 loss: 0.00620280486
Iter: 36 loss: 0.0062028
Iter: 37 loss: 0.00620280067
Iter: 38 loss: 0.00620280253
Iter: 39 loss: 0.0062028
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8
+ date
Tue Oct 27 21:13:40 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff702a78268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff702afbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff702afbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc121f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc1211e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc1217b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc099620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc0998c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc0541e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc054ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6dc0736a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c009f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c009f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c00d2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c00d2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c0071510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c0044400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c0044ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62878d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6287b1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6287b17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff628768598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff628724730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6286ca488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6286ca950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6286ec488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6286b18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6286b1c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6286b1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62860cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6285c0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6285df488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6285dfc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62858fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6285aea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6285686a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.025906451
Iter: 2 loss: 0.0223352108
Iter: 3 loss: 0.0141066983
Iter: 4 loss: 1.09212828
Iter: 5 loss: 0.0140927732
Iter: 6 loss: 0.00918467902
Iter: 7 loss: 0.0449902192
Iter: 8 loss: 0.00861666724
Iter: 9 loss: 0.0076504508
Iter: 10 loss: 0.00755492132
Iter: 11 loss: 0.00740295183
Iter: 12 loss: 0.00829750486
Iter: 13 loss: 0.00738126785
Iter: 14 loss: 0.00728815328
Iter: 15 loss: 0.00750046549
Iter: 16 loss: 0.00725233089
Iter: 17 loss: 0.00718966685
Iter: 18 loss: 0.00749590388
Iter: 19 loss: 0.00717907259
Iter: 20 loss: 0.00715820584
Iter: 21 loss: 0.00732599944
Iter: 22 loss: 0.00715679908
Iter: 23 loss: 0.00715136807
Iter: 24 loss: 0.00715129822
Iter: 25 loss: 0.00714974059
Iter: 26 loss: 0.0071533625
Iter: 27 loss: 0.00714916643
Iter: 28 loss: 0.00714890379
Iter: 29 loss: 0.00715282792
Iter: 30 loss: 0.0071489024
Iter: 31 loss: 0.00714881159
Iter: 32 loss: 0.00714999158
Iter: 33 loss: 0.00714881252
Iter: 34 loss: 0.0071487776
Iter: 35 loss: 0.0071488549
Iter: 36 loss: 0.00714876689
Iter: 37 loss: 0.00714875851
Iter: 38 loss: 0.0071488237
Iter: 39 loss: 0.00714875665
Iter: 40 loss: 0.00714875385
Iter: 41 loss: 0.0071487762
Iter: 42 loss: 0.00714875292
Iter: 43 loss: 0.00714875385
Iter: 44 loss: 0.00714875199
Iter: 45 loss: 0.00714875199
Iter: 46 loss: 0.00714875478
Iter: 47 loss: 0.00714875339
Iter: 48 loss: 0.00714875292
Iter: 49 loss: 0.00714875385
Iter: 50 loss: 0.00714875292
Iter: 51 loss: 0.00714875245
Iter: 52 loss: 0.00714875
Iter: 53 loss: 0.00714875199
Iter: 54 loss: 0.00714875339
Iter: 55 loss: 0.00714875199
Iter: 56 loss: 0.00714875199
Iter: 57 loss: 0.00714875
Iter: 58 loss: 0.00714875245
Iter: 59 loss: 0.00714875152
Iter: 60 loss: 0.00714875245
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2
+ date
Tue Oct 27 21:14:11 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi0.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdba86b2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbebbd3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbebbcdb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdba866eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdba85ba488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdba85d5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb803dac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb803827b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80391268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80391048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb802fc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8030ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb802ab7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb802c27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb802c2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80251730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80251598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80254d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80221b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb801bef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb801dd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb801948c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8014e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80159bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb800f7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb801038c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb800cc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80088950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb800880d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb80035b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb604157b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb60437730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb604198c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb60419ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb603fe510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb603b4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0278809369
Iter: 2 loss: 0.0215421207
Iter: 3 loss: 0.0242233798
Iter: 4 loss: 0.0161553472
Iter: 5 loss: 0.0120785087
Iter: 6 loss: 0.20303759
Iter: 7 loss: 0.0120701678
Iter: 8 loss: 0.00921676867
Iter: 9 loss: 0.0259364247
Iter: 10 loss: 0.00879173167
Iter: 11 loss: 0.00809716247
Iter: 12 loss: 0.00923482329
Iter: 13 loss: 0.00776689965
Iter: 14 loss: 0.00759294396
Iter: 15 loss: 0.0101819579
Iter: 16 loss: 0.00759222033
Iter: 17 loss: 0.00751279108
Iter: 18 loss: 0.00766250119
Iter: 19 loss: 0.00747828791
Iter: 20 loss: 0.00739663048
Iter: 21 loss: 0.0078513464
Iter: 22 loss: 0.00738500059
Iter: 23 loss: 0.00735371187
Iter: 24 loss: 0.00770204095
Iter: 25 loss: 0.00735311396
Iter: 26 loss: 0.00734303799
Iter: 27 loss: 0.00736913877
Iter: 28 loss: 0.00733955763
Iter: 29 loss: 0.00733504351
Iter: 30 loss: 0.00735294865
Iter: 31 loss: 0.0073340307
Iter: 32 loss: 0.0073326882
Iter: 33 loss: 0.00734376535
Iter: 34 loss: 0.00733260484
Iter: 35 loss: 0.00733225141
Iter: 36 loss: 0.00733577274
Iter: 37 loss: 0.00733224303
Iter: 38 loss: 0.00733207818
Iter: 39 loss: 0.007333396
Iter: 40 loss: 0.00733206514
Iter: 41 loss: 0.00733201485
Iter: 42 loss: 0.00733232033
Iter: 43 loss: 0.00733200973
Iter: 44 loss: 0.00733198132
Iter: 45 loss: 0.00733230123
Iter: 46 loss: 0.00733198225
Iter: 47 loss: 0.00733196782
Iter: 48 loss: 0.00733199203
Iter: 49 loss: 0.0073319627
Iter: 50 loss: 0.00733195618
Iter: 51 loss: 0.00733199529
Iter: 52 loss: 0.00733195618
Iter: 53 loss: 0.00733195478
Iter: 54 loss: 0.00733197
Iter: 55 loss: 0.00733195478
Iter: 56 loss: 0.00733195525
Iter: 57 loss: 0.00733196
Iter: 58 loss: 0.00733195525
Iter: 59 loss: 0.00733195385
Iter: 60 loss: 0.00733195199
Iter: 61 loss: 0.00733195338
Iter: 62 loss: 0.00733195292
Iter: 63 loss: 0.00733195152
Iter: 64 loss: 0.00733195338
Iter: 65 loss: 0.00733195338
Iter: 66 loss: 0.00733195432
Iter: 67 loss: 0.00733195245
Iter: 68 loss: 0.00733195245
Iter: 69 loss: 0.00733195338
Iter: 70 loss: 0.00733195292
Iter: 71 loss: 0.00733195292
Iter: 72 loss: 0.00733195385
Iter: 73 loss: 0.00733195152
Iter: 74 loss: 0.00733195292
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6
+ date
Tue Oct 27 21:14:42 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258a17268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa27c44fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa27c44fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2589e6e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25893e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25893e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258921f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2588b8048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2589219d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2588b8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258894e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258861f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2587fb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2588b8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2587d18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2587d1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25879e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2587350d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258703510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258721048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258721950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2586dd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258697730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25863d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25863d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258663510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25862c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2585d27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2585d2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258585730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258537a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258537400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa258554378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25856a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa25852ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2584e5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0369964465
Iter: 2 loss: 0.0201029535
Iter: 3 loss: 2961.66895
Iter: 4 loss: 0.0201029535
Iter: 5 loss: 0.0170559771
Iter: 6 loss: 0.0158523191
Iter: 7 loss: 0.0128380712
Iter: 8 loss: 0.0223348178
Iter: 9 loss: 0.0117106698
Iter: 10 loss: 0.00919582602
Iter: 11 loss: 0.0289926026
Iter: 12 loss: 0.0090224091
Iter: 13 loss: 0.00842151884
Iter: 14 loss: 0.00787509605
Iter: 15 loss: 0.00771021
Iter: 16 loss: 0.00747714704
Iter: 17 loss: 0.00746823568
Iter: 18 loss: 0.00737970741
Iter: 19 loss: 0.00808636844
Iter: 20 loss: 0.00737273507
Iter: 21 loss: 0.0073066256
Iter: 22 loss: 0.00733177736
Iter: 23 loss: 0.00726027414
Iter: 24 loss: 0.00717390375
Iter: 25 loss: 0.00755682867
Iter: 26 loss: 0.007156746
Iter: 27 loss: 0.00709784636
Iter: 28 loss: 0.00714031514
Iter: 29 loss: 0.00706070242
Iter: 30 loss: 0.00701406179
Iter: 31 loss: 0.00718783773
Iter: 32 loss: 0.00700273551
Iter: 33 loss: 0.00698576868
Iter: 34 loss: 0.00723521458
Iter: 35 loss: 0.00698575703
Iter: 36 loss: 0.00698087458
Iter: 37 loss: 0.0069996058
Iter: 38 loss: 0.00697970297
Iter: 39 loss: 0.00697688339
Iter: 40 loss: 0.00698421802
Iter: 41 loss: 0.00697592739
Iter: 42 loss: 0.00697494578
Iter: 43 loss: 0.00699050957
Iter: 44 loss: 0.00697494671
Iter: 45 loss: 0.00697435811
Iter: 46 loss: 0.00697702821
Iter: 47 loss: 0.00697424449
Iter: 48 loss: 0.00697398093
Iter: 49 loss: 0.00697449315
Iter: 50 loss: 0.00697387
Iter: 51 loss: 0.00697371829
Iter: 52 loss: 0.00697440188
Iter: 53 loss: 0.00697368663
Iter: 54 loss: 0.00697360374
Iter: 55 loss: 0.00697422074
Iter: 56 loss: 0.00697359443
Iter: 57 loss: 0.00697354041
Iter: 58 loss: 0.00697378861
Iter: 59 loss: 0.00697352923
Iter: 60 loss: 0.00697349478
Iter: 61 loss: 0.00697372342
Iter: 62 loss: 0.00697349198
Iter: 63 loss: 0.00697347382
Iter: 64 loss: 0.0069735474
Iter: 65 loss: 0.00697347056
Iter: 66 loss: 0.00697345752
Iter: 67 loss: 0.0069735162
Iter: 68 loss: 0.00697345519
Iter: 69 loss: 0.00697344914
Iter: 70 loss: 0.00697346916
Iter: 71 loss: 0.00697344635
Iter: 72 loss: 0.00697344402
Iter: 73 loss: 0.00697347103
Iter: 74 loss: 0.00697344169
Iter: 75 loss: 0.00697344
Iter: 76 loss: 0.00697344961
Iter: 77 loss: 0.00697343657
Iter: 78 loss: 0.00697343796
Iter: 79 loss: 0.00697343703
Iter: 80 loss: 0.00697343703
Iter: 81 loss: 0.00697343657
Iter: 82 loss: 0.0069734361
Iter: 83 loss: 0.00697343796
Iter: 84 loss: 0.0069734375
Iter: 85 loss: 0.00697343331
Iter: 86 loss: 0.00697343517
Iter: 87 loss: 0.00697344029
Iter: 88 loss: 0.00697343517
Iter: 89 loss: 0.0069734375
Iter: 90 loss: 0.00697343564
Iter: 91 loss: 0.0069734361
Iter: 92 loss: 0.00697343424
Iter: 93 loss: 0.00697343517
Iter: 94 loss: 0.00697343517
Iter: 95 loss: 0.00697343284
Iter: 96 loss: 0.00697343657
Iter: 97 loss: 0.0069734361
Iter: 98 loss: 0.00697343471
Iter: 99 loss: 0.00697343517
Iter: 100 loss: 0.00697343284
Iter: 101 loss: 0.00697343564
Iter: 102 loss: 0.00697343517
Iter: 103 loss: 0.00697343517
Iter: 104 loss: 0.00697343377
Iter: 105 loss: 0.00697343331
Iter: 106 loss: 0.00697343424
Iter: 107 loss: 0.00697343424
Iter: 108 loss: 0.00697343517
Iter: 109 loss: 0.00697343424
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2
+ date
Tue Oct 27 21:15:15 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi1.6/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61f554a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61f55c67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61f55d2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d056e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d056eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d059e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d04ed8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0511840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d04ed378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d04bef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0483a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d049f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d049f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d03e6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d03f78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d03f7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d03ab2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d03f77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0328840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0355158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0355730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d03076a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d02c2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d02cf840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d026e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d02902f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0253598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d02042f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0204048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d01ae7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d01e29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d01e22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d018d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d018d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0151b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61d0151ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0671747178
Iter: 2 loss: 2221.79272
Iter: 3 loss: 0.0317858346
Iter: 4 loss: 0.033767432
Iter: 5 loss: 0.0992502496
Iter: 6 loss: 0.0315427482
Iter: 7 loss: 0.0257378537
Iter: 8 loss: 0.0243518837
Iter: 9 loss: 0.0208471864
Iter: 10 loss: 0.0601964
Iter: 11 loss: 0.0204603709
Iter: 12 loss: 0.0162556767
Iter: 13 loss: 0.0454097837
Iter: 14 loss: 0.0157298557
Iter: 15 loss: 0.0139839705
Iter: 16 loss: 0.0178437158
Iter: 17 loss: 0.0134677198
Iter: 18 loss: 0.0126274768
Iter: 19 loss: 0.0115132416
Iter: 20 loss: 0.0114009529
Iter: 21 loss: 0.0106272008
Iter: 22 loss: 0.0114744026
Iter: 23 loss: 0.0102036241
Iter: 24 loss: 0.00926960167
Iter: 25 loss: 0.0126383994
Iter: 26 loss: 0.00899543241
Iter: 27 loss: 0.00860068202
Iter: 28 loss: 0.0135803884
Iter: 29 loss: 0.00859158207
Iter: 30 loss: 0.00831744634
Iter: 31 loss: 0.00924434699
Iter: 32 loss: 0.00823074766
Iter: 33 loss: 0.00809626374
Iter: 34 loss: 0.00869221613
Iter: 35 loss: 0.00806963816
Iter: 36 loss: 0.007998107
Iter: 37 loss: 0.00829832256
Iter: 38 loss: 0.00798155554
Iter: 39 loss: 0.00794975087
Iter: 40 loss: 0.00798464
Iter: 41 loss: 0.00793230254
Iter: 42 loss: 0.00789496861
Iter: 43 loss: 0.0079493029
Iter: 44 loss: 0.00787694
Iter: 45 loss: 0.00782005582
Iter: 46 loss: 0.00785689894
Iter: 47 loss: 0.00778306182
Iter: 48 loss: 0.00771337375
Iter: 49 loss: 0.00781085249
Iter: 50 loss: 0.00767819164
Iter: 51 loss: 0.0076247924
Iter: 52 loss: 0.00794621
Iter: 53 loss: 0.00761773717
Iter: 54 loss: 0.00759039726
Iter: 55 loss: 0.00786245801
Iter: 56 loss: 0.00758960657
Iter: 57 loss: 0.00757602602
Iter: 58 loss: 0.00757439714
Iter: 59 loss: 0.00756675564
Iter: 60 loss: 0.00755946618
Iter: 61 loss: 0.00755776325
Iter: 62 loss: 0.00754835876
Iter: 63 loss: 0.00757890288
Iter: 64 loss: 0.00754569797
Iter: 65 loss: 0.00753824
Iter: 66 loss: 0.00757253543
Iter: 67 loss: 0.00753681222
Iter: 68 loss: 0.00753060449
Iter: 69 loss: 0.00754199
Iter: 70 loss: 0.00752792694
Iter: 71 loss: 0.00752417091
Iter: 72 loss: 0.00752411876
Iter: 73 loss: 0.00752213364
Iter: 74 loss: 0.00752943195
Iter: 75 loss: 0.00752164377
Iter: 76 loss: 0.00752043119
Iter: 77 loss: 0.0075239297
Iter: 78 loss: 0.00752005074
Iter: 79 loss: 0.00751896249
Iter: 80 loss: 0.0075193611
Iter: 81 loss: 0.00751819648
Iter: 82 loss: 0.00751750125
Iter: 83 loss: 0.0075220475
Iter: 84 loss: 0.00751742488
Iter: 85 loss: 0.00751692057
Iter: 86 loss: 0.00751921302
Iter: 87 loss: 0.00751681952
Iter: 88 loss: 0.00751648704
Iter: 89 loss: 0.00751755433
Iter: 90 loss: 0.00751639158
Iter: 91 loss: 0.00751616387
Iter: 92 loss: 0.00751755945
Iter: 93 loss: 0.00751613732
Iter: 94 loss: 0.00751607725
Iter: 95 loss: 0.00751606189
Iter: 96 loss: 0.0075159925
Iter: 97 loss: 0.00751619181
Iter: 98 loss: 0.00751596875
Iter: 99 loss: 0.0075159343
Iter: 100 loss: 0.00751586491
Iter: 101 loss: 0.00751725817
Iter: 102 loss: 0.00751586398
Iter: 103 loss: 0.0075157946
Iter: 104 loss: 0.00751615083
Iter: 105 loss: 0.00751578249
Iter: 106 loss: 0.00751573546
Iter: 107 loss: 0.00751591939
Iter: 108 loss: 0.00751572568
Iter: 109 loss: 0.00751568936
Iter: 110 loss: 0.00751618901
Iter: 111 loss: 0.00751568796
Iter: 112 loss: 0.0075156684
Iter: 113 loss: 0.00751566933
Iter: 114 loss: 0.00751565397
Iter: 115 loss: 0.00751562975
Iter: 116 loss: 0.00751577877
Iter: 117 loss: 0.00751562696
Iter: 118 loss: 0.00751561346
Iter: 119 loss: 0.00751561299
Iter: 120 loss: 0.00751559902
Iter: 121 loss: 0.00751558784
Iter: 122 loss: 0.00751568284
Iter: 123 loss: 0.00751558691
Iter: 124 loss: 0.00751557946
Iter: 125 loss: 0.00751562975
Iter: 126 loss: 0.0075155776
Iter: 127 loss: 0.00751556875
Iter: 128 loss: 0.00751558365
Iter: 129 loss: 0.00751556456
Iter: 130 loss: 0.00751556
Iter: 131 loss: 0.00751561252
Iter: 132 loss: 0.00751555851
Iter: 133 loss: 0.00751555851
Iter: 134 loss: 0.00751555804
Iter: 135 loss: 0.00751555385
Iter: 136 loss: 0.00751555339
Iter: 137 loss: 0.00751558086
Iter: 138 loss: 0.00751554919
Iter: 139 loss: 0.0075155478
Iter: 140 loss: 0.00751555804
Iter: 141 loss: 0.00751554547
Iter: 142 loss: 0.00751554547
Iter: 143 loss: 0.00751556782
Iter: 144 loss: 0.00751554407
Iter: 145 loss: 0.00751554221
Iter: 146 loss: 0.00751555618
Iter: 147 loss: 0.00751554081
Iter: 148 loss: 0.00751553942
Iter: 149 loss: 0.00751554267
Iter: 150 loss: 0.00751554035
Iter: 151 loss: 0.00751553662
Iter: 152 loss: 0.00751553802
Iter: 153 loss: 0.00751553848
Iter: 154 loss: 0.00751553755
Iter: 155 loss: 0.00751554966
Iter: 156 loss: 0.00751553895
Iter: 157 loss: 0.00751553755
Iter: 158 loss: 0.00751554035
Iter: 159 loss: 0.00751553755
Iter: 160 loss: 0.00751553429
Iter: 161 loss: 0.00751553848
Iter: 162 loss: 0.00751553662
Iter: 163 loss: 0.00751553383
Iter: 164 loss: 0.00751553895
Iter: 165 loss: 0.00751553662
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4
+ date
Tue Oct 27 21:15:51 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc41d028158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc460d2ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc460d2ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc460d2a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc41cf34488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc41cf34a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f87a5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f87a57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f87d82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f87d8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f877b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f86f2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f86f2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f86a88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f86df950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f86df598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f86848c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8695598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f85f2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8670c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f861a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f85ccf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8588950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f852a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f852a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8555730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f851d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f84c2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f851d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8472e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8427840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8427400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8438620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f8427598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f841b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3f83d1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.226364598
Iter: 2 loss: 14869.2471
Iter: 3 loss: 1635.53577
Iter: 4 loss: 0.226364136
Iter: 5 loss: 1724.85645
Iter: 6 loss: 518.19458
Iter: 7 loss: 0.226358712
Iter: 8 loss: 0.0941617787
Iter: 9 loss: 0.0941599905
Iter: 10 loss: 1279.65991
Iter: 11 loss: 0.0941581503
Iter: 12 loss: 0.135245532
Iter: 13 loss: 0.090792805
Iter: 14 loss: 0.101709098
Iter: 15 loss: 0.0858538747
Iter: 16 loss: 0.085346356
Iter: 17 loss: 0.0806680173
Iter: 18 loss: 0.0762918219
Iter: 19 loss: 0.0762566328
Iter: 20 loss: 0.0721211731
Iter: 21 loss: 0.0750292763
Iter: 22 loss: 0.0698735118
Iter: 23 loss: 0.0653269142
Iter: 24 loss: 0.0602717251
Iter: 25 loss: 0.0599762127
Iter: 26 loss: 0.0541782379
Iter: 27 loss: 0.140766293
Iter: 28 loss: 0.0536344573
Iter: 29 loss: 0.0500971153
Iter: 30 loss: 0.343321919
Iter: 31 loss: 0.0500957221
Iter: 32 loss: 0.0481078252
Iter: 33 loss: 0.0480409786
Iter: 34 loss: 0.0463846847
Iter: 35 loss: 0.0429248586
Iter: 36 loss: 0.0560069829
Iter: 37 loss: 0.04219345
Iter: 38 loss: 0.0405827761
Iter: 39 loss: 0.0445114896
Iter: 40 loss: 0.0399453864
Iter: 41 loss: 0.0359459668
Iter: 42 loss: 0.064872779
Iter: 43 loss: 0.0352048501
Iter: 44 loss: 0.0329736546
Iter: 45 loss: 0.0422971025
Iter: 46 loss: 0.0325965695
Iter: 47 loss: 0.0307998657
Iter: 48 loss: 0.0311373174
Iter: 49 loss: 0.0293712839
Iter: 50 loss: 0.0277641062
Iter: 51 loss: 0.0562396087
Iter: 52 loss: 0.0277340934
Iter: 53 loss: 0.027209606
Iter: 54 loss: 0.0271410979
Iter: 55 loss: 0.0267392211
Iter: 56 loss: 0.0265629757
Iter: 57 loss: 0.0263583548
Iter: 58 loss: 0.0258063525
Iter: 59 loss: 0.0272839591
Iter: 60 loss: 0.0255858749
Iter: 61 loss: 0.0250785537
Iter: 62 loss: 0.0241751242
Iter: 63 loss: 0.0241750386
Iter: 64 loss: 0.0231623016
Iter: 65 loss: 0.0250219554
Iter: 66 loss: 0.0226757657
Iter: 67 loss: 0.0225298218
Iter: 68 loss: 0.0222709458
Iter: 69 loss: 0.0217113011
Iter: 70 loss: 0.0231546536
Iter: 71 loss: 0.0214960948
Iter: 72 loss: 0.0210814513
Iter: 73 loss: 0.0222021416
Iter: 74 loss: 0.0209573116
Iter: 75 loss: 0.020613322
Iter: 76 loss: 0.0205433108
Iter: 77 loss: 0.020336587
Iter: 78 loss: 0.019913001
Iter: 79 loss: 0.019554358
Iter: 80 loss: 0.0194136258
Iter: 81 loss: 0.0188676529
Iter: 82 loss: 0.0178946387
Iter: 83 loss: 0.0178946257
Iter: 84 loss: 0.016890537
Iter: 85 loss: 0.0283406805
Iter: 86 loss: 0.0168602262
Iter: 87 loss: 0.0170831736
Iter: 88 loss: 0.0164975878
Iter: 89 loss: 0.015880052
Iter: 90 loss: 0.0180612095
Iter: 91 loss: 0.0157379489
Iter: 92 loss: 0.0154303759
Iter: 93 loss: 0.0167780649
Iter: 94 loss: 0.0153473653
Iter: 95 loss: 0.0151853254
Iter: 96 loss: 0.0153260957
Iter: 97 loss: 0.0150827253
Iter: 98 loss: 0.0147580635
Iter: 99 loss: 0.0147967488
Iter: 100 loss: 0.0145029807
Iter: 101 loss: 0.0143720713
Iter: 102 loss: 0.0143616488
Iter: 103 loss: 0.0142638069
Iter: 104 loss: 0.0142002273
Iter: 105 loss: 0.01416675
Iter: 106 loss: 0.0140157975
Iter: 107 loss: 0.0158756897
Iter: 108 loss: 0.014014
Iter: 109 loss: 0.0138929076
Iter: 110 loss: 0.0139569892
Iter: 111 loss: 0.0138150314
Iter: 112 loss: 0.0137226945
Iter: 113 loss: 0.0135338902
Iter: 114 loss: 0.0176848937
Iter: 115 loss: 0.0135313347
Iter: 116 loss: 0.0134421661
Iter: 117 loss: 0.0136729758
Iter: 118 loss: 0.013411277
Iter: 119 loss: 0.0133646531
Iter: 120 loss: 0.0133299539
Iter: 121 loss: 0.0133136939
Iter: 122 loss: 0.0132828737
Iter: 123 loss: 0.0133261401
Iter: 124 loss: 0.0132674454
Iter: 125 loss: 0.0132487435
Iter: 126 loss: 0.0132301198
Iter: 127 loss: 0.0132262446
Iter: 128 loss: 0.0131813623
Iter: 129 loss: 0.0134606091
Iter: 130 loss: 0.0131766861
Iter: 131 loss: 0.013114864
Iter: 132 loss: 0.0135304611
Iter: 133 loss: 0.0131093068
Iter: 134 loss: 0.0130836666
Iter: 135 loss: 0.0131024178
Iter: 136 loss: 0.0130678471
Iter: 137 loss: 0.0130461324
Iter: 138 loss: 0.0130461007
Iter: 139 loss: 0.0130306268
Iter: 140 loss: 0.0130282287
Iter: 141 loss: 0.0130174346
Iter: 142 loss: 0.0130127221
Iter: 143 loss: 0.0130057912
Iter: 144 loss: 0.0129939308
Iter: 145 loss: 0.0130167622
Iter: 146 loss: 0.0129890619
Iter: 147 loss: 0.0129805105
Iter: 148 loss: 0.012955687
Iter: 149 loss: 0.0130620124
Iter: 150 loss: 0.0129459044
Iter: 151 loss: 0.0129300095
Iter: 152 loss: 0.0130451
Iter: 153 loss: 0.0129284887
Iter: 154 loss: 0.0129229426
Iter: 155 loss: 0.0129207456
Iter: 156 loss: 0.012912564
Iter: 157 loss: 0.0128944498
Iter: 158 loss: 0.0131702814
Iter: 159 loss: 0.0128936172
Iter: 160 loss: 0.0128803644
Iter: 161 loss: 0.0128998263
Iter: 162 loss: 0.0128738023
Iter: 163 loss: 0.0128590446
Iter: 164 loss: 0.0129710427
Iter: 165 loss: 0.0128579326
Iter: 166 loss: 0.0128464121
Iter: 167 loss: 0.0128395213
Iter: 168 loss: 0.012834792
Iter: 169 loss: 0.0128213353
Iter: 170 loss: 0.0128213102
Iter: 171 loss: 0.0128066931
Iter: 172 loss: 0.0128847305
Iter: 173 loss: 0.0128045287
Iter: 174 loss: 0.012796184
Iter: 175 loss: 0.0128362859
Iter: 176 loss: 0.0127947237
Iter: 177 loss: 0.0127976974
Iter: 178 loss: 0.0127904741
Iter: 179 loss: 0.0127883377
Iter: 180 loss: 0.0127840228
Iter: 181 loss: 0.0128643792
Iter: 182 loss: 0.0127839502
Iter: 183 loss: 0.0127771469
Iter: 184 loss: 0.0127632171
Iter: 185 loss: 0.0130176172
Iter: 186 loss: 0.0127629694
Iter: 187 loss: 0.0127520077
Iter: 188 loss: 0.012812254
Iter: 189 loss: 0.0127504077
Iter: 190 loss: 0.0127467578
Iter: 191 loss: 0.0127439527
Iter: 192 loss: 0.0127409911
Iter: 193 loss: 0.0127335824
Iter: 194 loss: 0.0128039336
Iter: 195 loss: 0.012732571
Iter: 196 loss: 0.0127271693
Iter: 197 loss: 0.0127237923
Iter: 198 loss: 0.0127216298
Iter: 199 loss: 0.0127149047
Iter: 200 loss: 0.0127079654
Iter: 201 loss: 0.0127066802
Iter: 202 loss: 0.01270149
Iter: 203 loss: 0.0126898391
Iter: 204 loss: 0.0128539372
Iter: 205 loss: 0.0126892189
Iter: 206 loss: 0.0126773305
Iter: 207 loss: 0.0127416775
Iter: 208 loss: 0.0126755768
Iter: 209 loss: 0.012669622
Iter: 210 loss: 0.0127235465
Iter: 211 loss: 0.0126693146
Iter: 212 loss: 0.0126657821
Iter: 213 loss: 0.012654948
Iter: 214 loss: 0.0126811182
Iter: 215 loss: 0.0126486113
Iter: 216 loss: 0.0126535594
Iter: 217 loss: 0.0126434918
Iter: 218 loss: 0.0126391044
Iter: 219 loss: 0.0126468502
Iter: 220 loss: 0.0126371533
Iter: 221 loss: 0.012631082
Iter: 222 loss: 0.0126349516
Iter: 223 loss: 0.0126271918
Iter: 224 loss: 0.0126425363
Iter: 225 loss: 0.0126246139
Iter: 226 loss: 0.0126233706
Iter: 227 loss: 0.0126200765
Iter: 228 loss: 0.0126447752
Iter: 229 loss: 0.0126193929
Iter: 230 loss: 0.0126155261
Iter: 231 loss: 0.0126148881
Iter: 232 loss: 0.0126122143
Iter: 233 loss: 0.0126088122
Iter: 234 loss: 0.012606604
Iter: 235 loss: 0.0126052648
Iter: 236 loss: 0.0126029067
Iter: 237 loss: 0.0126106609
Iter: 238 loss: 0.012602251
Iter: 239 loss: 0.0125972442
Iter: 240 loss: 0.01260293
Iter: 241 loss: 0.0125945499
Iter: 242 loss: 0.0125856232
Iter: 243 loss: 0.0125875883
Iter: 244 loss: 0.012579049
Iter: 245 loss: 0.0125610549
Iter: 246 loss: 0.0125827957
Iter: 247 loss: 0.0125514939
Iter: 248 loss: 0.0125464452
Iter: 249 loss: 0.0125464471
Iter: 250 loss: 0.0125401234
Iter: 251 loss: 0.0125820059
Iter: 252 loss: 0.0125394464
Iter: 253 loss: 0.0125355348
Iter: 254 loss: 0.0125546791
Iter: 255 loss: 0.0125348438
Iter: 256 loss: 0.0125319567
Iter: 257 loss: 0.0125394082
Iter: 258 loss: 0.0125309806
Iter: 259 loss: 0.0125258956
Iter: 260 loss: 0.0125401709
Iter: 261 loss: 0.0125242341
Iter: 262 loss: 0.0125215799
Iter: 263 loss: 0.0125138965
Iter: 264 loss: 0.0125454087
Iter: 265 loss: 0.0125108548
Iter: 266 loss: 0.0125105819
Iter: 267 loss: 0.0125059169
Iter: 268 loss: 0.0125029217
Iter: 269 loss: 0.0124975145
Iter: 270 loss: 0.0126281278
Iter: 271 loss: 0.012497508
Iter: 272 loss: 0.0124874404
Iter: 273 loss: 0.01250921
Iter: 274 loss: 0.0124836136
Iter: 275 loss: 0.0124730729
Iter: 276 loss: 0.012516628
Iter: 277 loss: 0.0124707641
Iter: 278 loss: 0.0124591403
Iter: 279 loss: 0.0124570783
Iter: 280 loss: 0.0124492431
Iter: 281 loss: 0.0124431215
Iter: 282 loss: 0.0125212781
Iter: 283 loss: 0.0124430861
Iter: 284 loss: 0.0124387238
Iter: 285 loss: 0.0124702426
Iter: 286 loss: 0.0124383457
Iter: 287 loss: 0.0124351904
Iter: 288 loss: 0.012426977
Iter: 289 loss: 0.0124897901
Iter: 290 loss: 0.0124253687
Iter: 291 loss: 0.0124229286
Iter: 292 loss: 0.0124220494
Iter: 293 loss: 0.0124200201
Iter: 294 loss: 0.0124233942
Iter: 295 loss: 0.0124191158
Iter: 296 loss: 0.0124182291
Iter: 297 loss: 0.0124180233
Iter: 298 loss: 0.0124174505
Iter: 299 loss: 0.0124159092
Iter: 300 loss: 0.0124142114
Iter: 301 loss: 0.0124139609
Iter: 302 loss: 0.0124113634
Iter: 303 loss: 0.0124424277
Iter: 304 loss: 0.0124113224
Iter: 305 loss: 0.0124094132
Iter: 306 loss: 0.0124050006
Iter: 307 loss: 0.0124610094
Iter: 308 loss: 0.0124046989
Iter: 309 loss: 0.0123996725
Iter: 310 loss: 0.0123925451
Iter: 311 loss: 0.0123922788
Iter: 312 loss: 0.012382553
Iter: 313 loss: 0.0124660572
Iter: 314 loss: 0.0123819914
Iter: 315 loss: 0.0123768933
Iter: 316 loss: 0.0124277845
Iter: 317 loss: 0.0123767359
Iter: 318 loss: 0.0123722125
Iter: 319 loss: 0.0124121783
Iter: 320 loss: 0.0123719936
Iter: 321 loss: 0.0123692388
Iter: 322 loss: 0.0123668928
Iter: 323 loss: 0.0123661291
Iter: 324 loss: 0.0123652127
Iter: 325 loss: 0.0123648
Iter: 326 loss: 0.0123636452
Iter: 327 loss: 0.0123790652
Iter: 328 loss: 0.0123636406
Iter: 329 loss: 0.0123632886
Iter: 330 loss: 0.012362171
Iter: 331 loss: 0.0123627279
Iter: 332 loss: 0.0123611595
Iter: 333 loss: 0.0123584094
Iter: 334 loss: 0.0123728076
Iter: 335 loss: 0.0123579837
Iter: 336 loss: 0.0123568904
Iter: 337 loss: 0.012356014
Iter: 338 loss: 0.0123556778
Iter: 339 loss: 0.0123528522
Iter: 340 loss: 0.0123674441
Iter: 341 loss: 0.0123523884
Iter: 342 loss: 0.0123506095
Iter: 343 loss: 0.0123534091
Iter: 344 loss: 0.0123497862
Iter: 345 loss: 0.0123482924
Iter: 346 loss: 0.012349382
Iter: 347 loss: 0.0123473657
Iter: 348 loss: 0.0123457145
Iter: 349 loss: 0.012360232
Iter: 350 loss: 0.0123456325
Iter: 351 loss: 0.0123447701
Iter: 352 loss: 0.0123495068
Iter: 353 loss: 0.0123446565
Iter: 354 loss: 0.0123438137
Iter: 355 loss: 0.0123451212
Iter: 356 loss: 0.0123434197
Iter: 357 loss: 0.0123429373
Iter: 358 loss: 0.012341735
Iter: 359 loss: 0.0123540573
Iter: 360 loss: 0.0123415869
Iter: 361 loss: 0.0123439636
Iter: 362 loss: 0.0123412628
Iter: 363 loss: 0.0123411361
Iter: 364 loss: 0.0123407692
Iter: 365 loss: 0.01234286
Iter: 366 loss: 0.0123406583
Iter: 367 loss: 0.012340134
Iter: 368 loss: 0.0123401098
Iter: 369 loss: 0.0123393796
Iter: 370 loss: 0.0123395203
Iter: 371 loss: 0.0123388264
Iter: 372 loss: 0.0123384036
Iter: 373 loss: 0.0123409675
Iter: 374 loss: 0.0123383477
Iter: 375 loss: 0.0123381456
Iter: 376 loss: 0.01233833
Iter: 377 loss: 0.0123380236
Iter: 378 loss: 0.0123376008
Iter: 379 loss: 0.0123371668
Iter: 380 loss: 0.0123370774
Iter: 381 loss: 0.0123364022
Iter: 382 loss: 0.0123400968
Iter: 383 loss: 0.0123362895
Iter: 384 loss: 0.0123357493
Iter: 385 loss: 0.0123367729
Iter: 386 loss: 0.0123355091
Iter: 387 loss: 0.0123348888
Iter: 388 loss: 0.0123348348
Iter: 389 loss: 0.0123346215
Iter: 390 loss: 0.012334127
Iter: 391 loss: 0.0123404991
Iter: 392 loss: 0.0123340935
Iter: 393 loss: 0.012333598
Iter: 394 loss: 0.0123335924
Iter: 395 loss: 0.0123334862
Iter: 396 loss: 0.012333177
Iter: 397 loss: 0.0123348124
Iter: 398 loss: 0.012333082
Iter: 399 loss: 0.0123326024
Iter: 400 loss: 0.0123328688
Iter: 401 loss: 0.0123322848
Iter: 402 loss: 0.0123320054
Iter: 403 loss: 0.0123312762
Iter: 404 loss: 0.0123368539
Iter: 405 loss: 0.0123311318
Iter: 406 loss: 0.0123306783
Iter: 407 loss: 0.0123306718
Iter: 408 loss: 0.0123304836
Iter: 409 loss: 0.0123304911
Iter: 410 loss: 0.0123302788
Iter: 411 loss: 0.0123301959
Iter: 412 loss: 0.0123300739
Iter: 413 loss: 0.0123298829
Iter: 414 loss: 0.0123297023
Iter: 415 loss: 0.0123296576
Iter: 416 loss: 0.0123294154
Iter: 417 loss: 0.0123319328
Iter: 418 loss: 0.0123294238
Iter: 419 loss: 0.0123292962
Iter: 420 loss: 0.0123292822
Iter: 421 loss: 0.0123292152
Iter: 422 loss: 0.0123293046
Iter: 423 loss: 0.0123291807
Iter: 424 loss: 0.0123291425
Iter: 425 loss: 0.0123291351
Iter: 426 loss: 0.012329109
Iter: 427 loss: 0.0123290364
Iter: 428 loss: 0.0123299295
Iter: 429 loss: 0.0123290289
Iter: 430 loss: 0.0123289293
Iter: 431 loss: 0.0123292208
Iter: 432 loss: 0.0123288967
Iter: 433 loss: 0.0123288287
Iter: 434 loss: 0.0123286461
Iter: 435 loss: 0.0123302219
Iter: 436 loss: 0.012328608
Iter: 437 loss: 0.0123284031
Iter: 438 loss: 0.0123290559
Iter: 439 loss: 0.0123283491
Iter: 440 loss: 0.0123281684
Iter: 441 loss: 0.0123294126
Iter: 442 loss: 0.0123281386
Iter: 443 loss: 0.0123280045
Iter: 444 loss: 0.0123300226
Iter: 445 loss: 0.0123279989
Iter: 446 loss: 0.0123279216
Iter: 447 loss: 0.0123277586
Iter: 448 loss: 0.0123309568
Iter: 449 loss: 0.0123277502
Iter: 450 loss: 0.012327563
Iter: 451 loss: 0.0123281535
Iter: 452 loss: 0.0123275043
Iter: 453 loss: 0.012327468
Iter: 454 loss: 0.0123274336
Iter: 455 loss: 0.0123273674
Iter: 456 loss: 0.0123276636
Iter: 457 loss: 0.0123273581
Iter: 458 loss: 0.0123273237
Iter: 459 loss: 0.0123275286
Iter: 460 loss: 0.012327319
Iter: 461 loss: 0.0123272724
Iter: 462 loss: 0.0123272371
Iter: 463 loss: 0.0123272222
Iter: 464 loss: 0.01232717
Iter: 465 loss: 0.012327509
Iter: 466 loss: 0.0123271551
Iter: 467 loss: 0.0123271365
Iter: 468 loss: 0.0123271067
Iter: 469 loss: 0.0123270964
Iter: 470 loss: 0.012327062
Iter: 471 loss: 0.0123270052
Iter: 472 loss: 0.0123270079
Iter: 473 loss: 0.0123269558
Iter: 474 loss: 0.0123272855
Iter: 475 loss: 0.0123269539
Iter: 476 loss: 0.0123269148
Iter: 477 loss: 0.0123269111
Iter: 478 loss: 0.0123268943
Iter: 479 loss: 0.0123268329
Iter: 480 loss: 0.0123272603
Iter: 481 loss: 0.0123268291
Iter: 482 loss: 0.0123267584
Iter: 483 loss: 0.0123269679
Iter: 484 loss: 0.0123267407
Iter: 485 loss: 0.0123267109
Iter: 486 loss: 0.0123267118
Iter: 487 loss: 0.0123266783
Iter: 488 loss: 0.0123269437
Iter: 489 loss: 0.0123266764
Iter: 490 loss: 0.0123266466
Iter: 491 loss: 0.0123267639
Iter: 492 loss: 0.0123266475
Iter: 493 loss: 0.0123266196
Iter: 494 loss: 0.0123266317
Iter: 495 loss: 0.0123266075
Iter: 496 loss: 0.0123265907
Iter: 497 loss: 0.0123265898
Iter: 498 loss: 0.0123265795
Iter: 499 loss: 0.012326533
Iter: 500 loss: 0.012326478
Iter: 501 loss: 0.0123275779
Iter: 502 loss: 0.0123264743
Iter: 503 loss: 0.0123263951
Iter: 504 loss: 0.0123263858
Iter: 505 loss: 0.0123263281
Iter: 506 loss: 0.0123262098
Iter: 507 loss: 0.0123260543
Iter: 508 loss: 0.0123260422
Iter: 509 loss: 0.0123261884
Iter: 510 loss: 0.0123259835
Iter: 511 loss: 0.0123259379
Iter: 512 loss: 0.0123258978
Iter: 513 loss: 0.0123258904
Iter: 514 loss: 0.0123258373
Iter: 515 loss: 0.012325909
Iter: 516 loss: 0.012325814
Iter: 517 loss: 0.012325801
Iter: 518 loss: 0.0123257823
Iter: 519 loss: 0.0123257805
Iter: 520 loss: 0.0123257563
Iter: 521 loss: 0.0123257348
Iter: 522 loss: 0.012325732
Iter: 523 loss: 0.0123256948
Iter: 524 loss: 0.0123258242
Iter: 525 loss: 0.0123256724
Iter: 526 loss: 0.0123256594
Iter: 527 loss: 0.0123256389
Iter: 528 loss: 0.0123256352
Iter: 529 loss: 0.012325624
Iter: 530 loss: 0.012325624
Iter: 531 loss: 0.0123256044
Iter: 532 loss: 0.0123256706
Iter: 533 loss: 0.0123255905
Iter: 534 loss: 0.0123255905
Iter: 535 loss: 0.0123255737
Iter: 536 loss: 0.0123256287
Iter: 537 loss: 0.0123255691
Iter: 538 loss: 0.0123255486
Iter: 539 loss: 0.0123255495
Iter: 540 loss: 0.0123255346
Iter: 541 loss: 0.0123255234
Iter: 542 loss: 0.0123255458
Iter: 543 loss: 0.0123255262
Iter: 544 loss: 0.0123255122
Iter: 545 loss: 0.0123254992
Iter: 546 loss: 0.0123255011
Iter: 547 loss: 0.0123255439
Iter: 548 loss: 0.0123254824
Iter: 549 loss: 0.0123254862
Iter: 550 loss: 0.0123255318
Iter: 551 loss: 0.0123254769
Iter: 552 loss: 0.012325475
Iter: 553 loss: 0.0123254508
Iter: 554 loss: 0.012325475
Iter: 555 loss: 0.0123254582
Iter: 556 loss: 0.0123254443
Iter: 557 loss: 0.0123254787
Iter: 558 loss: 0.0123254396
Iter: 559 loss: 0.0123254228
Iter: 560 loss: 0.0123255718
Iter: 561 loss: 0.0123254173
Iter: 562 loss: 0.0123254154
Iter: 563 loss: 0.0123254405
Iter: 564 loss: 0.0123254163
Iter: 565 loss: 0.0123254061
Iter: 566 loss: 0.0123254219
Iter: 567 loss: 0.0123253949
Iter: 568 loss: 0.0123253884
Iter: 569 loss: 0.0123254023
Iter: 570 loss: 0.0123253893
Iter: 571 loss: 0.0123254005
Iter: 572 loss: 0.0123253772
Iter: 573 loss: 0.0123255076
Iter: 574 loss: 0.0123253837
Iter: 575 loss: 0.0123253558
Iter: 576 loss: 0.0123253651
Iter: 577 loss: 0.0123253539
Iter: 578 loss: 0.0123254675
Iter: 579 loss: 0.0123253474
Iter: 580 loss: 0.0123253353
Iter: 581 loss: 0.0123253139
Iter: 582 loss: 0.0123256287
Iter: 583 loss: 0.0123253241
Iter: 584 loss: 0.0123253362
Iter: 585 loss: 0.0123253232
Iter: 586 loss: 0.0123253074
Iter: 587 loss: 0.0123253129
Iter: 588 loss: 0.0123253632
Iter: 589 loss: 0.0123253064
Iter: 590 loss: 0.0123252925
Iter: 591 loss: 0.0123252915
Iter: 592 loss: 0.0123252887
Iter: 593 loss: 0.0123252776
Iter: 594 loss: 0.0123252738
Iter: 595 loss: 0.0123252766
Iter: 596 loss: 0.0123252645
Iter: 597 loss: 0.0123253074
Iter: 598 loss: 0.0123252757
Iter: 599 loss: 0.0123252664
Iter: 600 loss: 0.0123252701
Iter: 601 loss: 0.0123252636
Iter: 602 loss: 0.0123252776
Iter: 603 loss: 0.0123252682
Iter: 604 loss: 0.012325258
Iter: 605 loss: 0.012325258
Iter: 606 loss: 0.0123252859
Iter: 607 loss: 0.0123252645
Iter: 608 loss: 0.0123252571
Iter: 609 loss: 0.0123252627
Iter: 610 loss: 0.0123252571
Iter: 611 loss: 0.0123252552
Iter: 612 loss: 0.0123252515
Iter: 613 loss: 0.0123252477
Iter: 614 loss: 0.012325244
Iter: 615 loss: 0.0123252645
Iter: 616 loss: 0.0123252403
Iter: 617 loss: 0.0123252505
Iter: 618 loss: 0.0123252366
Iter: 619 loss: 0.012325245
Iter: 620 loss: 0.0123252356
Iter: 621 loss: 0.0123253223
Iter: 622 loss: 0.0123252347
Iter: 623 loss: 0.0123252412
Iter: 624 loss: 0.0123252422
Iter: 625 loss: 0.0123252254
Iter: 626 loss: 0.012325231
Iter: 627 loss: 0.0123252235
Iter: 628 loss: 0.0123252254
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8
+ date
Tue Oct 27 21:16:59 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db568158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db561620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db561d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db426f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db446840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db3dc2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db3a28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db406048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db361158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db361a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db389730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db2e38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db2e3840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db317378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db2bfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db3171e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db280400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db2bf620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db1ef950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db1f6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db218598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db2186a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db18e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db12b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db136598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db148158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db1169d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db116ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db116950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db1167b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db0277b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db047158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76db0470d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ae371510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ae3a39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ae371400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.170295671
Iter: 2 loss: 9.73308182
Iter: 3 loss: 9.2282629
Iter: 4 loss: 4.47059727
Iter: 5 loss: 4.33697
Iter: 6 loss: 2.38442612
Iter: 7 loss: 2.32403588
Iter: 8 loss: 1.34837496
Iter: 9 loss: 1.31340122
Iter: 10 loss: 0.776911855
Iter: 11 loss: 0.75316155
Iter: 12 loss: 0.434962392
Iter: 13 loss: 0.416564763
Iter: 14 loss: 0.223913431
Iter: 15 loss: 0.210748687
Iter: 16 loss: 0.107371025
Iter: 17 loss: 0.101107419
Iter: 18 loss: 0.0946088433
Iter: 19 loss: 0.0706668198
Iter: 20 loss: 457.795715
Iter: 21 loss: 0.0706656277
Iter: 22 loss: 353.115173
Iter: 23 loss: 0.809724033
Iter: 24 loss: 0.0504281297
Iter: 25 loss: 0.0505397208
Iter: 26 loss: 0.049335137
Iter: 27 loss: 0.0462046638
Iter: 28 loss: 0.0405339189
Iter: 29 loss: 0.572967887
Iter: 30 loss: 0.040510051
Iter: 31 loss: 0.0345547833
Iter: 32 loss: 0.0402410366
Iter: 33 loss: 0.0324803069
Iter: 34 loss: 0.0296892766
Iter: 35 loss: 0.0279488023
Iter: 36 loss: 0.0265311226
Iter: 37 loss: 0.0243535377
Iter: 38 loss: 0.0252579525
Iter: 39 loss: 0.0229859203
Iter: 40 loss: 0.0198342223
Iter: 41 loss: 0.0208970718
Iter: 42 loss: 0.0177730806
Iter: 43 loss: 0.0164107345
Iter: 44 loss: 0.0217234232
Iter: 45 loss: 0.0159739833
Iter: 46 loss: 0.0154761663
Iter: 47 loss: 0.0168341845
Iter: 48 loss: 0.0153024793
Iter: 49 loss: 0.0149607714
Iter: 50 loss: 0.0161853191
Iter: 51 loss: 0.0148844188
Iter: 52 loss: 0.0147923101
Iter: 53 loss: 0.0147318617
Iter: 54 loss: 0.0146974167
Iter: 55 loss: 0.0145655796
Iter: 56 loss: 0.0145394243
Iter: 57 loss: 0.0144521538
Iter: 58 loss: 0.0143695641
Iter: 59 loss: 0.0145320017
Iter: 60 loss: 0.0143368812
Iter: 61 loss: 0.0142732337
Iter: 62 loss: 0.0143803442
Iter: 63 loss: 0.0142450817
Iter: 64 loss: 0.0141836777
Iter: 65 loss: 0.0143227261
Iter: 66 loss: 0.0141604636
Iter: 67 loss: 0.0141146714
Iter: 68 loss: 0.0145631041
Iter: 69 loss: 0.0141136516
Iter: 70 loss: 0.0140766017
Iter: 71 loss: 0.0140911704
Iter: 72 loss: 0.0140509624
Iter: 73 loss: 0.01402131
Iter: 74 loss: 0.0140525475
Iter: 75 loss: 0.0140053108
Iter: 76 loss: 0.0139859244
Iter: 77 loss: 0.0140217505
Iter: 78 loss: 0.0139776589
Iter: 79 loss: 0.0139647499
Iter: 80 loss: 0.0140990987
Iter: 81 loss: 0.0139644528
Iter: 82 loss: 0.0139569659
Iter: 83 loss: 0.0139567507
Iter: 84 loss: 0.0139494855
Iter: 85 loss: 0.0139397178
Iter: 86 loss: 0.0139391962
Iter: 87 loss: 0.0139315147
Iter: 88 loss: 0.0139696021
Iter: 89 loss: 0.0139302481
Iter: 90 loss: 0.0139243565
Iter: 91 loss: 0.0139829218
Iter: 92 loss: 0.0139241628
Iter: 93 loss: 0.0139201079
Iter: 94 loss: 0.0139214089
Iter: 95 loss: 0.0139172282
Iter: 96 loss: 0.0139120463
Iter: 97 loss: 0.0139170662
Iter: 98 loss: 0.013909094
Iter: 99 loss: 0.0139035704
Iter: 100 loss: 0.0139402375
Iter: 101 loss: 0.0139029734
Iter: 102 loss: 0.0139007326
Iter: 103 loss: 0.0139001282
Iter: 104 loss: 0.0138987126
Iter: 105 loss: 0.0138947275
Iter: 106 loss: 0.0139156086
Iter: 107 loss: 0.0138934422
Iter: 108 loss: 0.0138888191
Iter: 109 loss: 0.0139005855
Iter: 110 loss: 0.0138872154
Iter: 111 loss: 0.0138837136
Iter: 112 loss: 0.0138838096
Iter: 113 loss: 0.0138809308
Iter: 114 loss: 0.0138767399
Iter: 115 loss: 0.0138912974
Iter: 116 loss: 0.0138756447
Iter: 117 loss: 0.0138717638
Iter: 118 loss: 0.013900212
Iter: 119 loss: 0.0138714239
Iter: 120 loss: 0.0138677387
Iter: 121 loss: 0.0138846599
Iter: 122 loss: 0.0138670411
Iter: 123 loss: 0.0138650471
Iter: 124 loss: 0.0138632748
Iter: 125 loss: 0.0138627607
Iter: 126 loss: 0.0138608189
Iter: 127 loss: 0.0138604138
Iter: 128 loss: 0.013859055
Iter: 129 loss: 0.0138575695
Iter: 130 loss: 0.0138573488
Iter: 131 loss: 0.013855366
Iter: 132 loss: 0.0138572659
Iter: 133 loss: 0.0138542354
Iter: 134 loss: 0.0138534075
Iter: 135 loss: 0.0138532361
Iter: 136 loss: 0.0138520906
Iter: 137 loss: 0.0138531942
Iter: 138 loss: 0.013851434
Iter: 139 loss: 0.0138506638
Iter: 140 loss: 0.0138520682
Iter: 141 loss: 0.0138503257
Iter: 142 loss: 0.0138496244
Iter: 143 loss: 0.0138485357
Iter: 144 loss: 0.0138485171
Iter: 145 loss: 0.0138468295
Iter: 146 loss: 0.013853455
Iter: 147 loss: 0.0138464477
Iter: 148 loss: 0.0138450926
Iter: 149 loss: 0.0138454959
Iter: 150 loss: 0.0138441185
Iter: 151 loss: 0.0138428733
Iter: 152 loss: 0.0138428612
Iter: 153 loss: 0.0138419066
Iter: 154 loss: 0.0138443271
Iter: 155 loss: 0.0138415685
Iter: 156 loss: 0.0138406325
Iter: 157 loss: 0.013840694
Iter: 158 loss: 0.0138398949
Iter: 159 loss: 0.0138389366
Iter: 160 loss: 0.0138541944
Iter: 161 loss: 0.0138389347
Iter: 162 loss: 0.0138383973
Iter: 163 loss: 0.0138378097
Iter: 164 loss: 0.0138377268
Iter: 165 loss: 0.0138373021
Iter: 166 loss: 0.0138372853
Iter: 167 loss: 0.0138369007
Iter: 168 loss: 0.0138399303
Iter: 169 loss: 0.0138368746
Iter: 170 loss: 0.0138366902
Iter: 171 loss: 0.0138363726
Iter: 172 loss: 0.0138363782
Iter: 173 loss: 0.0138358939
Iter: 174 loss: 0.0138362451
Iter: 175 loss: 0.0138356043
Iter: 176 loss: 0.0138351414
Iter: 177 loss: 0.0138358325
Iter: 178 loss: 0.0138349235
Iter: 179 loss: 0.0138344718
Iter: 180 loss: 0.0138381356
Iter: 181 loss: 0.0138344457
Iter: 182 loss: 0.0138341896
Iter: 183 loss: 0.0138340779
Iter: 184 loss: 0.0138339503
Iter: 185 loss: 0.013833845
Iter: 186 loss: 0.0138337612
Iter: 187 loss: 0.0138336327
Iter: 188 loss: 0.0138334725
Iter: 189 loss: 0.013833452
Iter: 190 loss: 0.0138333179
Iter: 191 loss: 0.0138333151
Iter: 192 loss: 0.013833222
Iter: 193 loss: 0.0138334353
Iter: 194 loss: 0.0138331847
Iter: 195 loss: 0.0138330972
Iter: 196 loss: 0.0138331056
Iter: 197 loss: 0.0138330292
Iter: 198 loss: 0.0138329957
Iter: 199 loss: 0.0138329659
Iter: 200 loss: 0.013832924
Iter: 201 loss: 0.0138328252
Iter: 202 loss: 0.0138335293
Iter: 203 loss: 0.0138328038
Iter: 204 loss: 0.0138326669
Iter: 205 loss: 0.0138331596
Iter: 206 loss: 0.013832639
Iter: 207 loss: 0.013832517
Iter: 208 loss: 0.0138326203
Iter: 209 loss: 0.0138324406
Iter: 210 loss: 0.013832327
Iter: 211 loss: 0.013832625
Iter: 212 loss: 0.0138322888
Iter: 213 loss: 0.0138321891
Iter: 214 loss: 0.0138328802
Iter: 215 loss: 0.013832178
Iter: 216 loss: 0.0138321081
Iter: 217 loss: 0.0138322609
Iter: 218 loss: 0.0138320811
Iter: 219 loss: 0.013832001
Iter: 220 loss: 0.0138328485
Iter: 221 loss: 0.0138319954
Iter: 222 loss: 0.0138319638
Iter: 223 loss: 0.0138319479
Iter: 224 loss: 0.013831934
Iter: 225 loss: 0.0138318809
Iter: 226 loss: 0.0138321808
Iter: 227 loss: 0.0138318734
Iter: 228 loss: 0.0138318446
Iter: 229 loss: 0.013831839
Iter: 230 loss: 0.0138318166
Iter: 231 loss: 0.0138318148
Iter: 232 loss: 0.0138318
Iter: 233 loss: 0.0138317756
Iter: 234 loss: 0.0138317412
Iter: 235 loss: 0.0138322692
Iter: 236 loss: 0.0138317393
Iter: 237 loss: 0.0138317067
Iter: 238 loss: 0.0138318
Iter: 239 loss: 0.0138316937
Iter: 240 loss: 0.0138316583
Iter: 241 loss: 0.0138318222
Iter: 242 loss: 0.0138316583
Iter: 243 loss: 0.0138316331
Iter: 244 loss: 0.013831648
Iter: 245 loss: 0.013831621
Iter: 246 loss: 0.0138315987
Iter: 247 loss: 0.01383169
Iter: 248 loss: 0.0138315884
Iter: 249 loss: 0.0138315745
Iter: 250 loss: 0.0138317011
Iter: 251 loss: 0.0138315652
Iter: 252 loss: 0.013831554
Iter: 253 loss: 0.0138315521
Iter: 254 loss: 0.0138315428
Iter: 255 loss: 0.0138315381
Iter: 256 loss: 0.0138315335
Iter: 257 loss: 0.013831526
Iter: 258 loss: 0.0138316303
Iter: 259 loss: 0.0138315279
Iter: 260 loss: 0.0138315186
Iter: 261 loss: 0.0138315139
Iter: 262 loss: 0.0138315149
Iter: 263 loss: 0.013831513
Iter: 264 loss: 0.0138315065
Iter: 265 loss: 0.0138315018
Iter: 266 loss: 0.0138314981
Iter: 267 loss: 0.0138314962
Iter: 268 loss: 0.0138314907
Iter: 269 loss: 0.0138314879
Iter: 270 loss: 0.0138314841
Iter: 271 loss: 0.0138314757
Iter: 272 loss: 0.0138315633
Iter: 273 loss: 0.0138314804
Iter: 274 loss: 0.0138314767
Iter: 275 loss: 0.0138314646
Iter: 276 loss: 0.0138316564
Iter: 277 loss: 0.0138314646
Iter: 278 loss: 0.0138314534
Iter: 279 loss: 0.0138315465
Iter: 280 loss: 0.0138314543
Iter: 281 loss: 0.0138314525
Iter: 282 loss: 0.0138314841
Iter: 283 loss: 0.0138314497
Iter: 284 loss: 0.0138314441
Iter: 285 loss: 0.0138314879
Iter: 286 loss: 0.0138314413
Iter: 287 loss: 0.0138314441
Iter: 288 loss: 0.0138314487
Iter: 289 loss: 0.0138314413
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3
+ date
Tue Oct 27 21:17:43 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi2.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi -1 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe559d6d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe559d98a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe559d98e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe559d98620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe517f80268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe517f80b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe517f801e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0541ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0563268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0518730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f04d38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f04daf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f047f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f047ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0451ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0487c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f040b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f03beea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0380620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f038af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f039d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0334c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0334e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f039d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f02c1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f02e2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f02a7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f02502f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0250378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f02501e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f022d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f01d06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f01d0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f022d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f0181c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4f01590d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0461724401
Iter: 2 loss: 1.25621212
Iter: 3 loss: 1.03575158
Iter: 4 loss: 0.560348451
Iter: 5 loss: 0.450715542
Iter: 6 loss: 0.223218262
Iter: 7 loss: 0.160096884
Iter: 8 loss: 0.0629138201
Iter: 9 loss: 0.0413809456
Iter: 10 loss: 0.0284241177
Iter: 11 loss: 0.081139423
Iter: 12 loss: 0.0241141245
Iter: 13 loss: 0.0740258396
Iter: 14 loss: 0.0210160054
Iter: 15 loss: 0.0195925012
Iter: 16 loss: 0.0155837294
Iter: 17 loss: 0.0144676305
Iter: 18 loss: 0.0143104773
Iter: 19 loss: 0.0138936397
Iter: 20 loss: 0.0130813867
Iter: 21 loss: 0.0290821902
Iter: 22 loss: 0.0130741112
Iter: 23 loss: 0.0125160441
Iter: 24 loss: 0.0160800647
Iter: 25 loss: 0.0124955978
Iter: 26 loss: 0.012410108
Iter: 27 loss: 0.0122209992
Iter: 28 loss: 0.0158136077
Iter: 29 loss: 0.0122140404
Iter: 30 loss: 0.0120454328
Iter: 31 loss: 0.0121030975
Iter: 32 loss: 0.0119301006
Iter: 33 loss: 0.0117422491
Iter: 34 loss: 0.0123553611
Iter: 35 loss: 0.0116951596
Iter: 36 loss: 0.0115883369
Iter: 37 loss: 0.0119132539
Iter: 38 loss: 0.0115580615
Iter: 39 loss: 0.0115115382
Iter: 40 loss: 0.011723429
Iter: 41 loss: 0.0115025928
Iter: 42 loss: 0.0114744678
Iter: 43 loss: 0.0114694731
Iter: 44 loss: 0.0114507023
Iter: 45 loss: 0.0114247892
Iter: 46 loss: 0.0115329642
Iter: 47 loss: 0.0114194388
Iter: 48 loss: 0.0114087202
Iter: 49 loss: 0.0115272254
Iter: 50 loss: 0.0114085246
Iter: 51 loss: 0.0114030056
Iter: 52 loss: 0.0114204604
Iter: 53 loss: 0.0114014391
Iter: 54 loss: 0.0113976821
Iter: 55 loss: 0.0114372158
Iter: 56 loss: 0.0113975871
Iter: 57 loss: 0.0113961119
Iter: 58 loss: 0.0114033548
Iter: 59 loss: 0.0113958651
Iter: 60 loss: 0.0113948863
Iter: 61 loss: 0.0114003122
Iter: 62 loss: 0.0113947503
Iter: 63 loss: 0.0113940183
Iter: 64 loss: 0.0113940183
Iter: 65 loss: 0.0113936868
Iter: 66 loss: 0.0113927536
Iter: 67 loss: 0.0113973375
Iter: 68 loss: 0.0113924388
Iter: 69 loss: 0.0113912635
Iter: 70 loss: 0.0113961417
Iter: 71 loss: 0.0113910101
Iter: 72 loss: 0.0113901338
Iter: 73 loss: 0.0113925338
Iter: 74 loss: 0.0113898469
Iter: 75 loss: 0.0113892276
Iter: 76 loss: 0.0113950828
Iter: 77 loss: 0.0113892024
Iter: 78 loss: 0.0113887321
Iter: 79 loss: 0.0113908593
Iter: 80 loss: 0.0113886446
Iter: 81 loss: 0.0113883577
Iter: 82 loss: 0.0113892183
Iter: 83 loss: 0.011388272
Iter: 84 loss: 0.0113880113
Iter: 85 loss: 0.0113886306
Iter: 86 loss: 0.0113879126
Iter: 87 loss: 0.0113877049
Iter: 88 loss: 0.0113884835
Iter: 89 loss: 0.0113876555
Iter: 90 loss: 0.0113874655
Iter: 91 loss: 0.0113880308
Iter: 92 loss: 0.0113874096
Iter: 93 loss: 0.011387283
Iter: 94 loss: 0.0113889407
Iter: 95 loss: 0.011387283
Iter: 96 loss: 0.011387229
Iter: 97 loss: 0.0113872262
Iter: 98 loss: 0.0113871731
Iter: 99 loss: 0.0113870353
Iter: 100 loss: 0.0113878027
Iter: 101 loss: 0.0113869887
Iter: 102 loss: 0.011386849
Iter: 103 loss: 0.011387093
Iter: 104 loss: 0.0113867866
Iter: 105 loss: 0.0113866385
Iter: 106 loss: 0.0113872569
Iter: 107 loss: 0.0113866087
Iter: 108 loss: 0.0113864932
Iter: 109 loss: 0.0113868667
Iter: 110 loss: 0.0113864653
Iter: 111 loss: 0.0113863852
Iter: 112 loss: 0.0113873444
Iter: 113 loss: 0.0113863824
Iter: 114 loss: 0.0113863293
Iter: 115 loss: 0.0113863871
Iter: 116 loss: 0.0113862995
Iter: 117 loss: 0.0113862539
Iter: 118 loss: 0.0113865882
Iter: 119 loss: 0.0113862483
Iter: 120 loss: 0.0113862157
Iter: 121 loss: 0.0113862501
Iter: 122 loss: 0.0113862026
Iter: 123 loss: 0.011386171
Iter: 124 loss: 0.0113862809
Iter: 125 loss: 0.0113861617
Iter: 126 loss: 0.0113861356
Iter: 127 loss: 0.0113862865
Iter: 128 loss: 0.0113861281
Iter: 129 loss: 0.0113861226
Iter: 130 loss: 0.0113861207
Iter: 131 loss: 0.0113861067
Iter: 132 loss: 0.0113861
Iter: 133 loss: 0.0113860974
Iter: 134 loss: 0.0113860834
Iter: 135 loss: 0.0113860695
Iter: 136 loss: 0.0113860667
Iter: 137 loss: 0.0113860536
Iter: 138 loss: 0.011386117
Iter: 139 loss: 0.0113860499
Iter: 140 loss: 0.011386035
Iter: 141 loss: 0.0113861198
Iter: 142 loss: 0.0113860313
Iter: 143 loss: 0.0113860229
Iter: 144 loss: 0.0113860583
Iter: 145 loss: 0.0113860182
Iter: 146 loss: 0.0113860145
Iter: 147 loss: 0.0113860657
Iter: 148 loss: 0.0113860099
Iter: 149 loss: 0.0113860052
Iter: 150 loss: 0.0113860127
Iter: 151 loss: 0.0113860033
Iter: 152 loss: 0.0113859987
Iter: 153 loss: 0.011386021
Iter: 154 loss: 0.0113859978
Iter: 155 loss: 0.0113859922
Iter: 156 loss: 0.0113859978
Iter: 157 loss: 0.0113859912
Iter: 158 loss: 0.0113859866
Iter: 159 loss: 0.0113860071
Iter: 160 loss: 0.0113859857
Iter: 161 loss: 0.0113859847
Iter: 162 loss: 0.0113859866
Iter: 163 loss: 0.0113859819
Iter: 164 loss: 0.0113859847
Iter: 165 loss: 0.0113859829
Iter: 166 loss: 0.0113859782
Iter: 167 loss: 0.0113859791
Iter: 168 loss: 0.0113859773
Iter: 169 loss: 0.0113859754
Iter: 170 loss: 0.0113859801
Iter: 171 loss: 0.0113859782
Iter: 172 loss: 0.0113859773
Iter: 173 loss: 0.0113859875
Iter: 174 loss: 0.0113859745
Iter: 175 loss: 0.0113859773
Iter: 176 loss: 0.0113859791
Iter: 177 loss: 0.0113859735
Iter: 178 loss: 0.0113859717
Iter: 179 loss: 0.0113859791
Iter: 180 loss: 0.0113859735
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi-1_phi3/k2
+ for fn in f1 f2
+ case $fn in
+ OPT=--alpha
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0
+ date
Tue Oct 27 21:18:21 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi -2 --alpha 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30644b1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30644b1e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30644e0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f308c7150d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f308c70a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064473f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306444f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30644376a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306444f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306438be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306438ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30643ea9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30643b7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064351ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30642e0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30642ebe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30642ff7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30642e06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064294bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064261378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30642617b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30641c5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30641ff8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064193f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064193ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306415ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064176ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064176bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064128598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306415e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30640c6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30640c69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3064047488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306407ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f306407e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30507bef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00252855173
Iter: 2 loss: 0.0025175577
Iter: 3 loss: 0.00247440464
Iter: 4 loss: 0.00227838289
Iter: 5 loss: 0.00179919973
Iter: 6 loss: 0.0134920012
Iter: 7 loss: 0.00179748
Iter: 8 loss: 0.00141197979
Iter: 9 loss: 0.00600162242
Iter: 10 loss: 0.00140089
Iter: 11 loss: 0.00118501671
Iter: 12 loss: 0.00150194042
Iter: 13 loss: 0.00108005805
Iter: 14 loss: 0.00091555214
Iter: 15 loss: 0.000915472105
Iter: 16 loss: 0.000799370813
Iter: 17 loss: 0.00080888276
Iter: 18 loss: 0.000708649284
Iter: 19 loss: 0.000600853935
Iter: 20 loss: 0.000852427
Iter: 21 loss: 0.000560502929
Iter: 22 loss: 0.000492478139
Iter: 23 loss: 0.00157875475
Iter: 24 loss: 0.00049247162
Iter: 25 loss: 0.000436223403
Iter: 26 loss: 0.000598017
Iter: 27 loss: 0.000418570475
Iter: 28 loss: 0.000380037294
Iter: 29 loss: 0.000379299687
Iter: 30 loss: 0.000348931
Iter: 31 loss: 0.000311760115
Iter: 32 loss: 0.000644016312
Iter: 33 loss: 0.000309919
Iter: 34 loss: 0.000282575667
Iter: 35 loss: 0.000506145298
Iter: 36 loss: 0.000280851556
Iter: 37 loss: 0.000262628513
Iter: 38 loss: 0.000254304265
Iter: 39 loss: 0.000245231378
Iter: 40 loss: 0.000226047341
Iter: 41 loss: 0.000344527
Iter: 42 loss: 0.000223730982
Iter: 43 loss: 0.000208675177
Iter: 44 loss: 0.000347875524
Iter: 45 loss: 0.000208047772
Iter: 46 loss: 0.000198524227
Iter: 47 loss: 0.000193325846
Iter: 48 loss: 0.000189096987
Iter: 49 loss: 0.000178578193
Iter: 50 loss: 0.000262129237
Iter: 51 loss: 0.000177839858
Iter: 52 loss: 0.000169259787
Iter: 53 loss: 0.000203367585
Iter: 54 loss: 0.000167349455
Iter: 55 loss: 0.000161009928
Iter: 56 loss: 0.000173673732
Iter: 57 loss: 0.000158423805
Iter: 58 loss: 0.000152460823
Iter: 59 loss: 0.000206879122
Iter: 60 loss: 0.000152185268
Iter: 61 loss: 0.000148408086
Iter: 62 loss: 0.000145041937
Iter: 63 loss: 0.000144076417
Iter: 64 loss: 0.00013908383
Iter: 65 loss: 0.000160213225
Iter: 66 loss: 0.000138034578
Iter: 67 loss: 0.00013486328
Iter: 68 loss: 0.000134847098
Iter: 69 loss: 0.000132540081
Iter: 70 loss: 0.000130674351
Iter: 71 loss: 0.000129985972
Iter: 72 loss: 0.000127009494
Iter: 73 loss: 0.000132229616
Iter: 74 loss: 0.000125696621
Iter: 75 loss: 0.000123042089
Iter: 76 loss: 0.00014144351
Iter: 77 loss: 0.000122791476
Iter: 78 loss: 0.000120767792
Iter: 79 loss: 0.000140456439
Iter: 80 loss: 0.000120695098
Iter: 81 loss: 0.000119288132
Iter: 82 loss: 0.00011826487
Iter: 83 loss: 0.000117784584
Iter: 84 loss: 0.000116023257
Iter: 85 loss: 0.000123235513
Iter: 86 loss: 0.000115636867
Iter: 87 loss: 0.000114170689
Iter: 88 loss: 0.000130910601
Iter: 89 loss: 0.000114145812
Iter: 90 loss: 0.000113163958
Iter: 91 loss: 0.000112335169
Iter: 92 loss: 0.000112060618
Iter: 93 loss: 0.000110723457
Iter: 94 loss: 0.000117155432
Iter: 95 loss: 0.000110484136
Iter: 96 loss: 0.000109314897
Iter: 97 loss: 0.000117093812
Iter: 98 loss: 0.000109196153
Iter: 99 loss: 0.000108353648
Iter: 100 loss: 0.000108983018
Iter: 101 loss: 0.00010783771
Iter: 102 loss: 0.000107005792
Iter: 103 loss: 0.000115854054
Iter: 104 loss: 0.000106984844
Iter: 105 loss: 0.000106310908
Iter: 106 loss: 0.000105998581
Iter: 107 loss: 0.000105665516
Iter: 108 loss: 0.000104813771
Iter: 109 loss: 0.000105551815
Iter: 110 loss: 0.000104312829
Iter: 111 loss: 0.000103460654
Iter: 112 loss: 0.00010938746
Iter: 113 loss: 0.000103381011
Iter: 114 loss: 0.000102696715
Iter: 115 loss: 0.00010951572
Iter: 116 loss: 0.000102674734
Iter: 117 loss: 0.000102211518
Iter: 118 loss: 0.000101643847
Iter: 119 loss: 0.000101592464
Iter: 120 loss: 0.000100858182
Iter: 121 loss: 0.000102673977
Iter: 122 loss: 0.000100598714
Iter: 123 loss: 0.000100004938
Iter: 124 loss: 0.000105601517
Iter: 125 loss: 9.99809854e-05
Iter: 126 loss: 9.94504517e-05
Iter: 127 loss: 0.000101947335
Iter: 128 loss: 9.93535941e-05
Iter: 129 loss: 9.89755863e-05
Iter: 130 loss: 9.86324158e-05
Iter: 131 loss: 9.85388e-05
Iter: 132 loss: 9.80618061e-05
Iter: 133 loss: 0.000102508799
Iter: 134 loss: 9.80419718e-05
Iter: 135 loss: 9.76085212e-05
Iter: 136 loss: 9.91295092e-05
Iter: 137 loss: 9.74957657e-05
Iter: 138 loss: 9.71671761e-05
Iter: 139 loss: 9.73632632e-05
Iter: 140 loss: 9.6955e-05
Iter: 141 loss: 9.65634099e-05
Iter: 142 loss: 9.97751777e-05
Iter: 143 loss: 9.65393192e-05
Iter: 144 loss: 9.62499616e-05
Iter: 145 loss: 9.61816e-05
Iter: 146 loss: 9.59966e-05
Iter: 147 loss: 9.56844669e-05
Iter: 148 loss: 9.91931302e-05
Iter: 149 loss: 9.56785661e-05
Iter: 150 loss: 9.54027637e-05
Iter: 151 loss: 9.557046e-05
Iter: 152 loss: 9.52254e-05
Iter: 153 loss: 9.49386886e-05
Iter: 154 loss: 9.49882815e-05
Iter: 155 loss: 9.47236113e-05
Iter: 156 loss: 9.43896739e-05
Iter: 157 loss: 9.56171e-05
Iter: 158 loss: 9.43071791e-05
Iter: 159 loss: 9.40832251e-05
Iter: 160 loss: 9.40830287e-05
Iter: 161 loss: 9.38878075e-05
Iter: 162 loss: 9.38674639e-05
Iter: 163 loss: 9.3725379e-05
Iter: 164 loss: 9.35020289e-05
Iter: 165 loss: 9.36654687e-05
Iter: 166 loss: 9.33645497e-05
Iter: 167 loss: 9.31178365e-05
Iter: 168 loss: 9.39995225e-05
Iter: 169 loss: 9.30548704e-05
Iter: 170 loss: 9.28845111e-05
Iter: 171 loss: 9.28836234e-05
Iter: 172 loss: 9.2753311e-05
Iter: 173 loss: 9.26683424e-05
Iter: 174 loss: 9.2618182e-05
Iter: 175 loss: 9.24475316e-05
Iter: 176 loss: 9.27442888e-05
Iter: 177 loss: 9.23719563e-05
Iter: 178 loss: 9.22202453e-05
Iter: 179 loss: 9.38607409e-05
Iter: 180 loss: 9.22168911e-05
Iter: 181 loss: 9.20933526e-05
Iter: 182 loss: 9.23012703e-05
Iter: 183 loss: 9.20377643e-05
Iter: 184 loss: 9.19352606e-05
Iter: 185 loss: 9.24610067e-05
Iter: 186 loss: 9.1918846e-05
Iter: 187 loss: 9.18160513e-05
Iter: 188 loss: 9.20103048e-05
Iter: 189 loss: 9.17726284e-05
Iter: 190 loss: 9.16813296e-05
Iter: 191 loss: 9.16703721e-05
Iter: 192 loss: 9.16048375e-05
Iter: 193 loss: 9.15005221e-05
Iter: 194 loss: 9.21524188e-05
Iter: 195 loss: 9.14885e-05
Iter: 196 loss: 9.14020638e-05
Iter: 197 loss: 9.21849205e-05
Iter: 198 loss: 9.13982221e-05
Iter: 199 loss: 9.13427e-05
Iter: 200 loss: 9.12921823e-05
Iter: 201 loss: 9.12785617e-05
Iter: 202 loss: 9.1203663e-05
Iter: 203 loss: 9.15962373e-05
Iter: 204 loss: 9.11919342e-05
Iter: 205 loss: 9.11342358e-05
Iter: 206 loss: 9.17993166e-05
Iter: 207 loss: 9.11334064e-05
Iter: 208 loss: 9.10930321e-05
Iter: 209 loss: 9.10623e-05
Iter: 210 loss: 9.10492381e-05
Iter: 211 loss: 9.09936862e-05
Iter: 212 loss: 9.10858071e-05
Iter: 213 loss: 9.09683e-05
Iter: 214 loss: 9.09201772e-05
Iter: 215 loss: 9.12695614e-05
Iter: 216 loss: 9.09161827e-05
Iter: 217 loss: 9.08787188e-05
Iter: 218 loss: 9.12611358e-05
Iter: 219 loss: 9.08778e-05
Iter: 220 loss: 9.0853544e-05
Iter: 221 loss: 9.08302827e-05
Iter: 222 loss: 9.08249785e-05
Iter: 223 loss: 9.07933936e-05
Iter: 224 loss: 9.0956295e-05
Iter: 225 loss: 9.07884532e-05
Iter: 226 loss: 9.0761343e-05
Iter: 227 loss: 9.09846567e-05
Iter: 228 loss: 9.07597714e-05
Iter: 229 loss: 9.07422509e-05
Iter: 230 loss: 9.07508947e-05
Iter: 231 loss: 9.07303765e-05
Iter: 232 loss: 9.0710193e-05
Iter: 233 loss: 9.0886635e-05
Iter: 234 loss: 9.07091e-05
Iter: 235 loss: 9.06947e-05
Iter: 236 loss: 9.06830683e-05
Iter: 237 loss: 9.06786881e-05
Iter: 238 loss: 9.06592468e-05
Iter: 239 loss: 9.0706948e-05
Iter: 240 loss: 9.06521454e-05
Iter: 241 loss: 9.06358255e-05
Iter: 242 loss: 9.07325739e-05
Iter: 243 loss: 9.06336354e-05
Iter: 244 loss: 9.06208224e-05
Iter: 245 loss: 9.07757785e-05
Iter: 246 loss: 9.06207861e-05
Iter: 247 loss: 9.06124478e-05
Iter: 248 loss: 9.06040805e-05
Iter: 249 loss: 9.06025525e-05
Iter: 250 loss: 9.05908819e-05
Iter: 251 loss: 9.06254136e-05
Iter: 252 loss: 9.05875277e-05
Iter: 253 loss: 9.05794222e-05
Iter: 254 loss: 9.05794368e-05
Iter: 255 loss: 9.05728302e-05
Iter: 256 loss: 9.05700217e-05
Iter: 257 loss: 9.05666e-05
Iter: 258 loss: 9.05589404e-05
Iter: 259 loss: 9.05761117e-05
Iter: 260 loss: 9.05561e-05
Iter: 261 loss: 9.05504639e-05
Iter: 262 loss: 9.06351488e-05
Iter: 263 loss: 9.0550333e-05
Iter: 264 loss: 9.05453344e-05
Iter: 265 loss: 9.05473862e-05
Iter: 266 loss: 9.05421402e-05
Iter: 267 loss: 9.05371e-05
Iter: 268 loss: 9.05430643e-05
Iter: 269 loss: 9.05344496e-05
Iter: 270 loss: 9.05300112e-05
Iter: 271 loss: 9.05808556e-05
Iter: 272 loss: 9.05299385e-05
Iter: 273 loss: 9.05262568e-05
Iter: 274 loss: 9.0529611e-05
Iter: 275 loss: 9.05241468e-05
Iter: 276 loss: 9.05208581e-05
Iter: 277 loss: 9.05420311e-05
Iter: 278 loss: 9.05205743e-05
Iter: 279 loss: 9.05174384e-05
Iter: 280 loss: 9.0522517e-05
Iter: 281 loss: 9.05160123e-05
Iter: 282 loss: 9.05133347e-05
Iter: 283 loss: 9.05140478e-05
Iter: 284 loss: 9.05113557e-05
Iter: 285 loss: 9.05082707e-05
Iter: 286 loss: 9.05173365e-05
Iter: 287 loss: 9.05073248e-05
Iter: 288 loss: 9.05050401e-05
Iter: 289 loss: 9.05290653e-05
Iter: 290 loss: 9.05049528e-05
Iter: 291 loss: 9.05029e-05
Iter: 292 loss: 9.05127235e-05
Iter: 293 loss: 9.05024644e-05
Iter: 294 loss: 9.05013e-05
Iter: 295 loss: 9.04999e-05
Iter: 296 loss: 9.0499685e-05
Iter: 297 loss: 9.04977205e-05
Iter: 298 loss: 9.05053384e-05
Iter: 299 loss: 9.04973567e-05
Iter: 300 loss: 9.04959597e-05
Iter: 301 loss: 9.05155102e-05
Iter: 302 loss: 9.04959597e-05
Iter: 303 loss: 9.04947956e-05
Iter: 304 loss: 9.04963963e-05
Iter: 305 loss: 9.04942863e-05
Iter: 306 loss: 9.04933113e-05
Iter: 307 loss: 9.04933258e-05
Iter: 308 loss: 9.04925691e-05
Iter: 309 loss: 9.04915796e-05
Iter: 310 loss: 9.05029301e-05
Iter: 311 loss: 9.04915214e-05
Iter: 312 loss: 9.04907e-05
Iter: 313 loss: 9.04929184e-05
Iter: 314 loss: 9.04904e-05
Iter: 315 loss: 9.0489877e-05
Iter: 316 loss: 9.04905683e-05
Iter: 317 loss: 9.04894e-05
Iter: 318 loss: 9.04886183e-05
Iter: 319 loss: 9.04941335e-05
Iter: 320 loss: 9.04885237e-05
Iter: 321 loss: 9.04880872e-05
Iter: 322 loss: 9.04881599e-05
Iter: 323 loss: 9.04877234e-05
Iter: 324 loss: 9.04871267e-05
Iter: 325 loss: 9.04924746e-05
Iter: 326 loss: 9.04871267e-05
Iter: 327 loss: 9.04867629e-05
Iter: 328 loss: 9.04870685e-05
Iter: 329 loss: 9.04864064e-05
Iter: 330 loss: 9.04859626e-05
Iter: 331 loss: 9.04862e-05
Iter: 332 loss: 9.04857952e-05
Iter: 333 loss: 9.0485235e-05
Iter: 334 loss: 9.04866902e-05
Iter: 335 loss: 9.04851404e-05
Iter: 336 loss: 9.04848e-05
Iter: 337 loss: 9.04847111e-05
Iter: 338 loss: 9.04844637e-05
Iter: 339 loss: 9.04845438e-05
Iter: 340 loss: 9.04843328e-05
Iter: 341 loss: 9.04840126e-05
Iter: 342 loss: 9.04841218e-05
Iter: 343 loss: 9.04838671e-05
Iter: 344 loss: 9.04835106e-05
Iter: 345 loss: 9.04855e-05
Iter: 346 loss: 9.04834887e-05
Iter: 347 loss: 9.04832559e-05
Iter: 348 loss: 9.04863045e-05
Iter: 349 loss: 9.04833214e-05
Iter: 350 loss: 9.04832123e-05
Iter: 351 loss: 9.04830595e-05
Iter: 352 loss: 9.0483e-05
Iter: 353 loss: 9.04828339e-05
Iter: 354 loss: 9.04839253e-05
Iter: 355 loss: 9.04828776e-05
Iter: 356 loss: 9.04826811e-05
Iter: 357 loss: 9.04837434e-05
Iter: 358 loss: 9.04826884e-05
Iter: 359 loss: 9.04825865e-05
Iter: 360 loss: 9.04826447e-05
Iter: 361 loss: 9.04825574e-05
Iter: 362 loss: 9.04823683e-05
Iter: 363 loss: 9.04831395e-05
Iter: 364 loss: 9.04823683e-05
Iter: 365 loss: 9.04822082e-05
Iter: 366 loss: 9.04822518e-05
Iter: 367 loss: 9.04822082e-05
Iter: 368 loss: 9.04821281e-05
Iter: 369 loss: 9.04821936e-05
Iter: 370 loss: 9.04820699e-05
Iter: 371 loss: 9.04820336e-05
Iter: 372 loss: 9.04830886e-05
Iter: 373 loss: 9.04821136e-05
Iter: 374 loss: 9.04819317e-05
Iter: 375 loss: 9.04820336e-05
Iter: 376 loss: 9.04819e-05
Iter: 377 loss: 9.04818589e-05
Iter: 378 loss: 9.04819608e-05
Iter: 379 loss: 9.0481808e-05
Iter: 380 loss: 9.04817425e-05
Iter: 381 loss: 9.04820772e-05
Iter: 382 loss: 9.0481728e-05
Iter: 383 loss: 9.0481728e-05
Iter: 384 loss: 9.04824337e-05
Iter: 385 loss: 9.04817425e-05
Iter: 386 loss: 9.04815606e-05
Iter: 387 loss: 9.0481517e-05
Iter: 388 loss: 9.04816e-05
Iter: 389 loss: 9.04815461e-05
Iter: 390 loss: 9.04816698e-05
Iter: 391 loss: 9.04815461e-05
Iter: 392 loss: 9.04815388e-05
Iter: 393 loss: 9.04819535e-05
Iter: 394 loss: 9.04814951e-05
Iter: 395 loss: 9.04814297e-05
Iter: 396 loss: 9.04815679e-05
Iter: 397 loss: 9.04815242e-05
Iter: 398 loss: 9.04814951e-05
Iter: 399 loss: 9.04814515e-05
Iter: 400 loss: 9.0481386e-05
Iter: 401 loss: 9.04813714e-05
Iter: 402 loss: 9.04816261e-05
Iter: 403 loss: 9.04813132e-05
Iter: 404 loss: 9.04814e-05
Iter: 405 loss: 9.04813714e-05
Iter: 406 loss: 9.04814078e-05
Iter: 407 loss: 9.04813787e-05
Iter: 408 loss: 9.04812769e-05
Iter: 409 loss: 9.04813496e-05
Iter: 410 loss: 9.04813642e-05
Iter: 411 loss: 9.04813642e-05
Iter: 412 loss: 9.04813205e-05
Iter: 413 loss: 9.04814224e-05
Iter: 414 loss: 9.04813496e-05
Iter: 415 loss: 9.04813423e-05
Iter: 416 loss: 9.04813787e-05
Iter: 417 loss: 9.04813787e-05
Iter: 418 loss: 9.04814369e-05
Iter: 419 loss: 9.04814078e-05
Iter: 420 loss: 9.04813933e-05
Iter: 421 loss: 9.04814e-05
Iter: 422 loss: 9.04814e-05
Iter: 423 loss: 9.04814078e-05
Iter: 424 loss: 9.04814078e-05
Iter: 425 loss: 9.04813933e-05
Iter: 426 loss: 9.04814078e-05
Iter: 427 loss: 9.04813933e-05
Iter: 428 loss: 9.04814e-05
Iter: 429 loss: 9.04814e-05
Iter: 430 loss: 9.04814078e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.4
+ date
Tue Oct 27 21:24:20 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi -2 --alpha 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabc46598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabc46048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabb239d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabb32510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabb400d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabb32ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba9d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fabb40e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba63620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba209d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba80730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab9dd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba09400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba09510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1faba09e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab963730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab96e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab9342f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab8e0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab8d5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab88d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab88d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab8af6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab87d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab8816a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab837f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab7ce378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab7da1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab79d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab75a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab7bd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab788c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab78bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab78bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1fab776ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f8c4e0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0558476485
Iter: 2 loss: 0.0546952039
Iter: 3 loss: 0.0502556264
Iter: 4 loss: 0.0320946425
Iter: 5 loss: 0.107532814
Iter: 6 loss: 0.0236861892
Iter: 7 loss: 0.00886686
Iter: 8 loss: 0.00855546817
Iter: 9 loss: 0.00527568441
Iter: 10 loss: 0.00517606363
Iter: 11 loss: 0.00350591494
Iter: 12 loss: 0.0127634909
Iter: 13 loss: 0.00327878306
Iter: 14 loss: 0.00244541978
Iter: 15 loss: 0.00640367623
Iter: 16 loss: 0.00224496401
Iter: 17 loss: 0.00174266542
Iter: 18 loss: 0.00696707331
Iter: 19 loss: 0.00172991247
Iter: 20 loss: 0.00138932397
Iter: 21 loss: 0.00244958163
Iter: 22 loss: 0.00129044917
Iter: 23 loss: 0.00106941385
Iter: 24 loss: 0.00213625957
Iter: 25 loss: 0.00102768932
Iter: 26 loss: 0.000872790697
Iter: 27 loss: 0.00136879436
Iter: 28 loss: 0.000829377794
Iter: 29 loss: 0.000714409631
Iter: 30 loss: 0.0012452841
Iter: 31 loss: 0.000692588161
Iter: 32 loss: 0.000614526158
Iter: 33 loss: 0.00124832965
Iter: 34 loss: 0.000609157432
Iter: 35 loss: 0.000553741469
Iter: 36 loss: 0.000645525753
Iter: 37 loss: 0.000528790813
Iter: 38 loss: 0.000480917108
Iter: 39 loss: 0.000589111063
Iter: 40 loss: 0.000462814
Iter: 41 loss: 0.000425605045
Iter: 42 loss: 0.000645458
Iter: 43 loss: 0.000420718716
Iter: 44 loss: 0.000393060734
Iter: 45 loss: 0.000559435
Iter: 46 loss: 0.000389646535
Iter: 47 loss: 0.000367983826
Iter: 48 loss: 0.000424815516
Iter: 49 loss: 0.00036067568
Iter: 50 loss: 0.000343628868
Iter: 51 loss: 0.000425222068
Iter: 52 loss: 0.000340440252
Iter: 53 loss: 0.000324779219
Iter: 54 loss: 0.000397415482
Iter: 55 loss: 0.000321885629
Iter: 56 loss: 0.000310650095
Iter: 57 loss: 0.000318756647
Iter: 58 loss: 0.000303733599
Iter: 59 loss: 0.000292309094
Iter: 60 loss: 0.000338145532
Iter: 61 loss: 0.000289695105
Iter: 62 loss: 0.00028023019
Iter: 63 loss: 0.000322645705
Iter: 64 loss: 0.000278360676
Iter: 65 loss: 0.000270341348
Iter: 66 loss: 0.000298096274
Iter: 67 loss: 0.000268243748
Iter: 68 loss: 0.00026143
Iter: 69 loss: 0.000273547135
Iter: 70 loss: 0.000258417567
Iter: 71 loss: 0.000252057274
Iter: 72 loss: 0.00027696375
Iter: 73 loss: 0.000250594458
Iter: 74 loss: 0.000245366769
Iter: 75 loss: 0.00025832915
Iter: 76 loss: 0.000243515358
Iter: 77 loss: 0.000239160508
Iter: 78 loss: 0.000274003833
Iter: 79 loss: 0.000238872366
Iter: 80 loss: 0.000235272033
Iter: 81 loss: 0.000241884773
Iter: 82 loss: 0.000233720362
Iter: 83 loss: 0.000230453705
Iter: 84 loss: 0.000239137735
Iter: 85 loss: 0.000229362733
Iter: 86 loss: 0.000226517601
Iter: 87 loss: 0.000243786722
Iter: 88 loss: 0.000226164411
Iter: 89 loss: 0.000223802199
Iter: 90 loss: 0.000233322658
Iter: 91 loss: 0.000223279087
Iter: 92 loss: 0.000221283262
Iter: 93 loss: 0.000223975629
Iter: 94 loss: 0.000220279588
Iter: 95 loss: 0.00021827218
Iter: 96 loss: 0.000222747098
Iter: 97 loss: 0.000217508612
Iter: 98 loss: 0.000215691442
Iter: 99 loss: 0.000223862764
Iter: 100 loss: 0.000215336317
Iter: 101 loss: 0.000213795865
Iter: 102 loss: 0.00022072508
Iter: 103 loss: 0.000213496009
Iter: 104 loss: 0.000212213854
Iter: 105 loss: 0.000213719439
Iter: 106 loss: 0.000211532781
Iter: 107 loss: 0.000210232058
Iter: 108 loss: 0.000212877247
Iter: 109 loss: 0.00020970573
Iter: 110 loss: 0.000208563913
Iter: 111 loss: 0.000217174224
Iter: 112 loss: 0.0002084757
Iter: 113 loss: 0.000207512494
Iter: 114 loss: 0.000210516795
Iter: 115 loss: 0.000207231904
Iter: 116 loss: 0.00020641314
Iter: 117 loss: 0.000207826524
Iter: 118 loss: 0.000206048047
Iter: 119 loss: 0.000205245247
Iter: 120 loss: 0.000207716977
Iter: 121 loss: 0.000205008633
Iter: 122 loss: 0.000204326017
Iter: 123 loss: 0.000210416241
Iter: 124 loss: 0.000204292621
Iter: 125 loss: 0.000203770032
Iter: 126 loss: 0.000204505195
Iter: 127 loss: 0.000203512784
Iter: 128 loss: 0.000202992349
Iter: 129 loss: 0.000205051212
Iter: 130 loss: 0.000202873111
Iter: 131 loss: 0.000202416821
Iter: 132 loss: 0.000203206611
Iter: 133 loss: 0.000202213807
Iter: 134 loss: 0.00020175743
Iter: 135 loss: 0.000203250427
Iter: 136 loss: 0.000201630726
Iter: 137 loss: 0.000201208662
Iter: 138 loss: 0.000202204334
Iter: 139 loss: 0.000201053728
Iter: 140 loss: 0.000200662471
Iter: 141 loss: 0.000201237388
Iter: 142 loss: 0.000200473965
Iter: 143 loss: 0.000200097653
Iter: 144 loss: 0.000202149968
Iter: 145 loss: 0.000200042356
Iter: 146 loss: 0.000199733448
Iter: 147 loss: 0.00020169263
Iter: 148 loss: 0.000199698465
Iter: 149 loss: 0.000199447153
Iter: 150 loss: 0.000199617367
Iter: 151 loss: 0.000199289731
Iter: 152 loss: 0.000199029571
Iter: 153 loss: 0.000199624948
Iter: 154 loss: 0.00019893235
Iter: 155 loss: 0.000198685477
Iter: 156 loss: 0.000200192197
Iter: 157 loss: 0.000198655252
Iter: 158 loss: 0.000198465044
Iter: 159 loss: 0.000199716509
Iter: 160 loss: 0.000198445108
Iter: 161 loss: 0.000198297
Iter: 162 loss: 0.000198426176
Iter: 163 loss: 0.000198210284
Iter: 164 loss: 0.000198046604
Iter: 165 loss: 0.000198872498
Iter: 166 loss: 0.000198019523
Iter: 167 loss: 0.000197880552
Iter: 168 loss: 0.00019804074
Iter: 169 loss: 0.00019780625
Iter: 170 loss: 0.00019766677
Iter: 171 loss: 0.000198149763
Iter: 172 loss: 0.000197630157
Iter: 173 loss: 0.000197503512
Iter: 174 loss: 0.00019775203
Iter: 175 loss: 0.000197451212
Iter: 176 loss: 0.000197324538
Iter: 177 loss: 0.000197662885
Iter: 178 loss: 0.000197282818
Iter: 179 loss: 0.000197172092
Iter: 180 loss: 0.00019780024
Iter: 181 loss: 0.000197156871
Iter: 182 loss: 0.000197062327
Iter: 183 loss: 0.000197437534
Iter: 184 loss: 0.000197040659
Iter: 185 loss: 0.00019696368
Iter: 186 loss: 0.000197048503
Iter: 187 loss: 0.000196921348
Iter: 188 loss: 0.000196840032
Iter: 189 loss: 0.000197184636
Iter: 190 loss: 0.000196822861
Iter: 191 loss: 0.000196752371
Iter: 192 loss: 0.000197036672
Iter: 193 loss: 0.000196736597
Iter: 194 loss: 0.000196678215
Iter: 195 loss: 0.000196937064
Iter: 196 loss: 0.000196666573
Iter: 197 loss: 0.000196614608
Iter: 198 loss: 0.000196746085
Iter: 199 loss: 0.000196596593
Iter: 200 loss: 0.000196548266
Iter: 201 loss: 0.000196721201
Iter: 202 loss: 0.000196535868
Iter: 203 loss: 0.000196490582
Iter: 204 loss: 0.000196571636
Iter: 205 loss: 0.000196470908
Iter: 206 loss: 0.000196427136
Iter: 207 loss: 0.000196475827
Iter: 208 loss: 0.000196403387
Iter: 209 loss: 0.000196358422
Iter: 210 loss: 0.00019653645
Iter: 211 loss: 0.000196348235
Iter: 212 loss: 0.000196310779
Iter: 213 loss: 0.000196524794
Iter: 214 loss: 0.000196305846
Iter: 215 loss: 0.000196273642
Iter: 216 loss: 0.0001963627
Iter: 217 loss: 0.000196262845
Iter: 218 loss: 0.000196233101
Iter: 219 loss: 0.000196252222
Iter: 220 loss: 0.000196214154
Iter: 221 loss: 0.000196182635
Iter: 222 loss: 0.000196329769
Iter: 223 loss: 0.000196176901
Iter: 224 loss: 0.000196149078
Iter: 225 loss: 0.000196294408
Iter: 226 loss: 0.000196144829
Iter: 227 loss: 0.000196122506
Iter: 228 loss: 0.000196182606
Iter: 229 loss: 0.000196115114
Iter: 230 loss: 0.000196094508
Iter: 231 loss: 0.000196174966
Iter: 232 loss: 0.000196089721
Iter: 233 loss: 0.000196071866
Iter: 234 loss: 0.000196130277
Iter: 235 loss: 0.000196066743
Iter: 236 loss: 0.000196050678
Iter: 237 loss: 0.000196117748
Iter: 238 loss: 0.000196047
Iter: 239 loss: 0.000196033172
Iter: 240 loss: 0.000196040535
Iter: 241 loss: 0.000196023961
Iter: 242 loss: 0.000196008172
Iter: 243 loss: 0.000196033303
Iter: 244 loss: 0.000196000954
Iter: 245 loss: 0.000195984961
Iter: 246 loss: 0.000196073146
Iter: 247 loss: 0.000195983012
Iter: 248 loss: 0.00019597073
Iter: 249 loss: 0.000196045337
Iter: 250 loss: 0.000195969245
Iter: 251 loss: 0.000195959045
Iter: 252 loss: 0.000195964501
Iter: 253 loss: 0.000195952685
Iter: 254 loss: 0.000195941888
Iter: 255 loss: 0.000195970322
Iter: 256 loss: 0.000195938352
Iter: 257 loss: 0.00019592882
Iter: 258 loss: 0.000195989618
Iter: 259 loss: 0.00019592786
Iter: 260 loss: 0.000195920147
Iter: 261 loss: 0.000195949542
Iter: 262 loss: 0.000195918183
Iter: 263 loss: 0.00019591162
Iter: 264 loss: 0.000195923596
Iter: 265 loss: 0.000195908957
Iter: 266 loss: 0.000195902336
Iter: 267 loss: 0.000195936154
Iter: 268 loss: 0.000195901463
Iter: 269 loss: 0.000195896107
Iter: 270 loss: 0.000195916291
Iter: 271 loss: 0.000195894507
Iter: 272 loss: 0.000195889923
Iter: 273 loss: 0.000195899702
Iter: 274 loss: 0.000195887871
Iter: 275 loss: 0.000195883054
Iter: 276 loss: 0.00019588985
Iter: 277 loss: 0.000195880682
Iter: 278 loss: 0.000195875793
Iter: 279 loss: 0.000195897883
Iter: 280 loss: 0.00019587492
Iter: 281 loss: 0.000195870933
Iter: 282 loss: 0.000195886008
Iter: 283 loss: 0.000195869827
Iter: 284 loss: 0.000195866101
Iter: 285 loss: 0.000195870147
Iter: 286 loss: 0.000195864181
Iter: 287 loss: 0.000195860324
Iter: 288 loss: 0.000195868488
Iter: 289 loss: 0.000195858855
Iter: 290 loss: 0.000195855449
Iter: 291 loss: 0.000195876375
Iter: 292 loss: 0.000195855071
Iter: 293 loss: 0.000195851928
Iter: 294 loss: 0.000195863424
Iter: 295 loss: 0.000195851491
Iter: 296 loss: 0.000195848901
Iter: 297 loss: 0.000195857137
Iter: 298 loss: 0.00019584829
Iter: 299 loss: 0.000195846049
Iter: 300 loss: 0.000195851084
Iter: 301 loss: 0.000195845234
Iter: 302 loss: 0.000195843095
Iter: 303 loss: 0.000195851026
Iter: 304 loss: 0.000195842731
Iter: 305 loss: 0.000195840752
Iter: 306 loss: 0.000195852088
Iter: 307 loss: 0.000195840636
Iter: 308 loss: 0.000195839
Iter: 309 loss: 0.00019583937
Iter: 310 loss: 0.000195837958
Iter: 311 loss: 0.000195836474
Iter: 312 loss: 0.000195843269
Iter: 313 loss: 0.000195836095
Iter: 314 loss: 0.000195834495
Iter: 315 loss: 0.000195840868
Iter: 316 loss: 0.000195834175
Iter: 317 loss: 0.00019583285
Iter: 318 loss: 0.000195834175
Iter: 319 loss: 0.000195832094
Iter: 320 loss: 0.000195830668
Iter: 321 loss: 0.000195834597
Iter: 322 loss: 0.000195830115
Iter: 323 loss: 0.000195829125
Iter: 324 loss: 0.000195833738
Iter: 325 loss: 0.000195828557
Iter: 326 loss: 0.000195827539
Iter: 327 loss: 0.000195831439
Iter: 328 loss: 0.000195827146
Iter: 329 loss: 0.000195826171
Iter: 330 loss: 0.000195829984
Iter: 331 loss: 0.000195825793
Iter: 332 loss: 0.00019582505
Iter: 333 loss: 0.000195828572
Iter: 334 loss: 0.000195824861
Iter: 335 loss: 0.000195823988
Iter: 336 loss: 0.000195825094
Iter: 337 loss: 0.000195823493
Iter: 338 loss: 0.000195822882
Iter: 339 loss: 0.00019582751
Iter: 340 loss: 0.000195822795
Iter: 341 loss: 0.000195822213
Iter: 342 loss: 0.000195825109
Iter: 343 loss: 0.00019582198
Iter: 344 loss: 0.000195821543
Iter: 345 loss: 0.000195821514
Iter: 346 loss: 0.000195821194
Iter: 347 loss: 0.000195820554
Iter: 348 loss: 0.000195825458
Iter: 349 loss: 0.000195820598
Iter: 350 loss: 0.000195819957
Iter: 351 loss: 0.000195820176
Iter: 352 loss: 0.00019581955
Iter: 353 loss: 0.000195819157
Iter: 354 loss: 0.000195820554
Iter: 355 loss: 0.000195819099
Iter: 356 loss: 0.000195818575
Iter: 357 loss: 0.000195820947
Iter: 358 loss: 0.000195818458
Iter: 359 loss: 0.000195818022
Iter: 360 loss: 0.000195819724
Iter: 361 loss: 0.000195817891
Iter: 362 loss: 0.000195817527
Iter: 363 loss: 0.000195818313
Iter: 364 loss: 0.00019581744
Iter: 365 loss: 0.000195817178
Iter: 366 loss: 0.000195818313
Iter: 367 loss: 0.00019581712
Iter: 368 loss: 0.00019581677
Iter: 369 loss: 0.000195817527
Iter: 370 loss: 0.000195816683
Iter: 371 loss: 0.000195816247
Iter: 372 loss: 0.00019581728
Iter: 373 loss: 0.000195816276
Iter: 374 loss: 0.000195816014
Iter: 375 loss: 0.000195817905
Iter: 376 loss: 0.000195816101
Iter: 377 loss: 0.00019581581
Iter: 378 loss: 0.000195816
Iter: 379 loss: 0.000195815534
Iter: 380 loss: 0.000195815461
Iter: 381 loss: 0.000195815926
Iter: 382 loss: 0.000195815315
Iter: 383 loss: 0.000195815082
Iter: 384 loss: 0.00019581613
Iter: 385 loss: 0.00019581517
Iter: 386 loss: 0.000195814937
Iter: 387 loss: 0.000195814893
Iter: 388 loss: 0.000195814529
Iter: 389 loss: 0.000195814428
Iter: 390 loss: 0.000195815199
Iter: 391 loss: 0.000195814559
Iter: 392 loss: 0.000195814355
Iter: 393 loss: 0.000195815082
Iter: 394 loss: 0.000195814311
Iter: 395 loss: 0.000195814195
Iter: 396 loss: 0.000195814733
Iter: 397 loss: 0.000195814209
Iter: 398 loss: 0.000195814035
Iter: 399 loss: 0.000195814529
Iter: 400 loss: 0.000195813889
Iter: 401 loss: 0.000195813787
Iter: 402 loss: 0.000195814093
Iter: 403 loss: 0.000195813773
Iter: 404 loss: 0.000195813685
Iter: 405 loss: 0.000195814122
Iter: 406 loss: 0.000195813787
Iter: 407 loss: 0.00019581354
Iter: 408 loss: 0.000195814151
Iter: 409 loss: 0.000195813438
Iter: 410 loss: 0.000195813569
Iter: 411 loss: 0.000195813744
Iter: 412 loss: 0.00019581338
Iter: 413 loss: 0.000195813249
Iter: 414 loss: 0.000195813278
Iter: 415 loss: 0.000195813118
Iter: 416 loss: 0.000195813103
Iter: 417 loss: 0.000195813554
Iter: 418 loss: 0.000195813162
Iter: 419 loss: 0.000195812871
Iter: 420 loss: 0.000195813103
Iter: 421 loss: 0.000195813089
Iter: 422 loss: 0.000195812929
Iter: 423 loss: 0.000195813278
Iter: 424 loss: 0.000195812929
Iter: 425 loss: 0.000195812783
Iter: 426 loss: 0.000195813147
Iter: 427 loss: 0.000195812827
Iter: 428 loss: 0.000195812987
Iter: 429 loss: 0.000195813176
Iter: 430 loss: 0.000195812812
Iter: 431 loss: 0.000195812929
Iter: 432 loss: 0.000195813191
Iter: 433 loss: 0.000195812841
Iter: 434 loss: 0.000195812885
Iter: 435 loss: 0.000195812754
Iter: 436 loss: 0.000195812696
Iter: 437 loss: 0.000195812696
Iter: 438 loss: 0.000195812681
Iter: 439 loss: 0.000195812827
Iter: 440 loss: 0.000195812565
Iter: 441 loss: 0.000195812754
Iter: 442 loss: 0.000195812609
Iter: 443 loss: 0.000195812594
Iter: 444 loss: 0.000195812798
Iter: 445 loss: 0.000195812478
Iter: 446 loss: 0.00019581271
Iter: 447 loss: 0.000195812609
Iter: 448 loss: 0.000195812609
Iter: 449 loss: 0.000195812609
Iter: 450 loss: 0.00019581255
Iter: 451 loss: 0.000195812492
Iter: 452 loss: 0.000195812667
Iter: 453 loss: 0.00019581255
Iter: 454 loss: 0.000195812521
Iter: 455 loss: 0.000195812579
Iter: 456 loss: 0.000195812609
Iter: 457 loss: 0.000195812638
Iter: 458 loss: 0.000195812609
Iter: 459 loss: 0.000195812667
Iter: 460 loss: 0.000195812696
Iter: 461 loss: 0.000195812652
Iter: 462 loss: 0.000195812667
Iter: 463 loss: 0.000195812667
Iter: 464 loss: 0.000195812681
Iter: 465 loss: 0.000195812681
Iter: 466 loss: 0.000195812681
Iter: 467 loss: 0.000195812667
Iter: 468 loss: 0.000195812681
Iter: 469 loss: 0.000195812681
Iter: 470 loss: 0.000195812667
Iter: 471 loss: 0.000195812681
Iter: 472 loss: 0.000195812565
Iter: 473 loss: 0.00019581306
Iter: 474 loss: 0.000195812667
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.8
+ date
Tue Oct 27 21:31:11 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi -2 --alpha 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi-2_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0867d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0867df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0868a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f086650d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08665840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08608400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f085c6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f085c69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f085c6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f085367b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08536bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f084f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08522400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08522598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f084c9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08483598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0848b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0848bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08483730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08416488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f083c20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f083c2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08416e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0839e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f083a5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08344d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f082fe510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f082fe9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f082e98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f082749d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08274d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0829a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f0829a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08247b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f08247598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f081a8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0366998464
Iter: 2 loss: 0.035327144
Iter: 3 loss: 0.0302121043
Iter: 4 loss: 0.0222452674
Iter: 5 loss: 0.020851247
Iter: 6 loss: 0.0138379177
Iter: 7 loss: 0.0131670497
Iter: 8 loss: 0.00809055381
Iter: 9 loss: 0.213154122
Iter: 10 loss: 0.00806396641
Iter: 11 loss: 0.00556970667
Iter: 12 loss: 0.0684978515
Iter: 13 loss: 0.0055535743
Iter: 14 loss: 0.00436934084
Iter: 15 loss: 0.0156935565
Iter: 16 loss: 0.00435256632
Iter: 17 loss: 0.00351934833
Iter: 18 loss: 0.00836152118
Iter: 19 loss: 0.00331586553
Iter: 20 loss: 0.00273888768
Iter: 21 loss: 0.0063521415
Iter: 22 loss: 0.00265352731
Iter: 23 loss: 0.00220914837
Iter: 24 loss: 0.00489021558
Iter: 25 loss: 0.00215550885
Iter: 26 loss: 0.00183747581
Iter: 27 loss: 0.00408189185
Iter: 28 loss: 0.00181249029
Iter: 29 loss: 0.00164963317
Iter: 30 loss: 0.00180444284
Iter: 31 loss: 0.00154990936
Iter: 32 loss: 0.0014051972
Iter: 33 loss: 0.00192109635
Iter: 34 loss: 0.0013659338
Iter: 35 loss: 0.00124327559
Iter: 36 loss: 0.00172366621
Iter: 37 loss: 0.00121590623
Iter: 38 loss: 0.00112117874
Iter: 39 loss: 0.00148273213
Iter: 40 loss: 0.0010969555
Iter: 41 loss: 0.00102548487
Iter: 42 loss: 0.00111264642
Iter: 43 loss: 0.000988180516
Iter: 44 loss: 0.000922057254
Iter: 45 loss: 0.00149814319
Iter: 46 loss: 0.000917753
Iter: 47 loss: 0.00086797867
Iter: 48 loss: 0.00105481525
Iter: 49 loss: 0.000855695223
Iter: 50 loss: 0.000816301
Iter: 51 loss: 0.00103236327
Iter: 52 loss: 0.000810921891
Iter: 53 loss: 0.000779907801
Iter: 54 loss: 0.000869801152
Iter: 55 loss: 0.000769753358
Iter: 56 loss: 0.000742981327
Iter: 57 loss: 0.000778337475
Iter: 58 loss: 0.000729423948
Iter: 59 loss: 0.000701303943
Iter: 60 loss: 0.000773177191
Iter: 61 loss: 0.000691421446
Iter: 62 loss: 0.000667492568
Iter: 63 loss: 0.000770599
Iter: 64 loss: 0.000662488397
Iter: 65 loss: 0.000642731553
Iter: 66 loss: 0.000736657879
Iter: 67 loss: 0.000639281701
Iter: 68 loss: 0.000623151427
Iter: 69 loss: 0.000711881206
Iter: 70 loss: 0.000620702049
Iter: 71 loss: 0.000607426628
Iter: 72 loss: 0.000634677883
Iter: 73 loss: 0.000602063956
Iter: 74 loss: 0.000589887495
Iter: 75 loss: 0.000609792536
Iter: 76 loss: 0.000584330119
Iter: 77 loss: 0.000572621124
Iter: 78 loss: 0.00065110554
Iter: 79 loss: 0.000571320299
Iter: 80 loss: 0.00056189578
Iter: 81 loss: 0.000594499405
Iter: 82 loss: 0.000559458393
Iter: 83 loss: 0.000551764155
Iter: 84 loss: 0.000569266616
Iter: 85 loss: 0.000548839744
Iter: 86 loss: 0.000541521295
Iter: 87 loss: 0.000593877747
Iter: 88 loss: 0.000540910172
Iter: 89 loss: 0.00053474243
Iter: 90 loss: 0.000536275969
Iter: 91 loss: 0.00053022767
Iter: 92 loss: 0.000523483439
Iter: 93 loss: 0.000539419125
Iter: 94 loss: 0.000521024107
Iter: 95 loss: 0.000514516723
Iter: 96 loss: 0.00054373435
Iter: 97 loss: 0.00051324477
Iter: 98 loss: 0.000507592398
Iter: 99 loss: 0.000519411755
Iter: 100 loss: 0.00050534308
Iter: 101 loss: 0.000499849
Iter: 102 loss: 0.000512666302
Iter: 103 loss: 0.000497834641
Iter: 104 loss: 0.000492966734
Iter: 105 loss: 0.000536236272
Iter: 106 loss: 0.000492715859
Iter: 107 loss: 0.000488594291
Iter: 108 loss: 0.00049359788
Iter: 109 loss: 0.000486438134
Iter: 110 loss: 0.000482286123
Iter: 111 loss: 0.000490709674
Iter: 112 loss: 0.000480604765
Iter: 113 loss: 0.000476822781
Iter: 114 loss: 0.000489435275
Iter: 115 loss: 0.000475781271
Iter: 116 loss: 0.000472307322
Iter: 117 loss: 0.00049525575
