+ RUN=3
+ export CUDA_VISIBLE_DEVICES=3
+ CUDA_VISIBLE_DEVICES=3
+ LAYERS=300_300_300_1
+ case $RUN in
+ PSI=0
+ OPTIONS='			 --optimizer adam 				 --n_pairs 50000 				 --batch_size 5000 				 --max_epochs 200 				 --learning_rate 0.001 				 --decay_rate 0.98 				 --loss_func weighted_MSE 
'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output80
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output81
+ for fn in f1
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL='--load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0
+ date
Mon Nov  2 08:23:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4
+ date
Mon Nov  2 08:23:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8
+ date
Mon Nov  2 08:23:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0568bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca055b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca05ef730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0525598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca05251e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca05ef7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0525048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca04117b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0411840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02db1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca04850d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0467d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03acbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca047f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03a5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca00fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca047f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca031cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0326d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca031c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03f4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca01e41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03f4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0063f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0065620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0286c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0286488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca01701e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bf0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02b5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bfe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc5473e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca022c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca00b5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 8.216926e-05
test_loss: 7.9119265e-05
train_loss: 2.7157625e-05
test_loss: 2.6379157e-05
train_loss: 1.4953286e-05
test_loss: 1.4993718e-05
train_loss: 1.05363615e-05
test_loss: 1.0222612e-05
train_loss: 7.1873988e-06
test_loss: 7.733457e-06
train_loss: 6.15719e-06
test_loss: 6.1828973e-06
train_loss: 5.1035304e-06
test_loss: 5.3403587e-06
train_loss: 4.720052e-06
test_loss: 4.726378e-06
train_loss: 4.075523e-06
test_loss: 4.2897727e-06
train_loss: 3.7766736e-06
test_loss: 4.027294e-06
train_loss: 3.6861602e-06
test_loss: 3.7895384e-06
train_loss: 3.5211422e-06
test_loss: 3.5783332e-06
train_loss: 3.2120652e-06
test_loss: 3.4376385e-06
train_loss: 3.3228562e-06
test_loss: 3.3004135e-06
train_loss: 3.094392e-06
test_loss: 3.1880309e-06
train_loss: 2.931721e-06
test_loss: 3.1044915e-06
train_loss: 2.9443454e-06
test_loss: 3.0290498e-06
train_loss: 2.8592808e-06
test_loss: 3.0059382e-06
train_loss: 2.708738e-06
test_loss: 2.9309165e-06
train_loss: 2.7724677e-06
test_loss: 2.8165919e-06
train_loss: 2.621251e-06
test_loss: 2.8030465e-06
train_loss: 2.7403785e-06
test_loss: 2.7565186e-06
train_loss: 2.6872394e-06
test_loss: 2.7237386e-06
train_loss: 2.595432e-06
test_loss: 2.6609316e-06
train_loss: 2.4806632e-06
test_loss: 2.6381865e-06
train_loss: 2.5350553e-06
test_loss: 2.5687307e-06
train_loss: 2.4390886e-06
test_loss: 2.5763616e-06
train_loss: 2.3225546e-06
test_loss: 2.5463219e-06
train_loss: 2.2953095e-06
test_loss: 2.5223248e-06
train_loss: 2.3330615e-06
test_loss: 2.4701158e-06
train_loss: 2.4471733e-06
test_loss: 2.4822061e-06
train_loss: 2.3267357e-06
test_loss: 2.4499882e-06
train_loss: 2.3122766e-06
test_loss: 2.4284932e-06
train_loss: 2.4472533e-06
test_loss: 2.4035364e-06
train_loss: 2.246581e-06
test_loss: 2.4002218e-06
train_loss: 2.357249e-06
test_loss: 2.4214437e-06
train_loss: 2.4301955e-06
test_loss: 2.374118e-06
train_loss: 2.3189266e-06
test_loss: 2.359728e-06
train_loss: 2.289785e-06
test_loss: 2.3541777e-06
train_loss: 2.1633332e-06
test_loss: 2.3399703e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bddbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6be30ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6be24268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd817b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd81ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd81488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd81c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc658c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc65400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc3d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc31268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59a38f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59a38d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bcccd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599caf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599a7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59a09c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bccc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599a7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c598b1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c598c5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c598fc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5985bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5985ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5985ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5986bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5986b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597f51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597b8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597d8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5970bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c596aaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597b8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c596e1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59768f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.17011234e-06
Iter: 2 loss: 2.15406317e-06
Iter: 3 loss: 2.15337104e-06
Iter: 4 loss: 2.1448966e-06
Iter: 5 loss: 2.15142973e-06
Iter: 6 loss: 2.13972817e-06
Iter: 7 loss: 2.13671274e-06
Iter: 8 loss: 2.14291913e-06
Iter: 9 loss: 2.13551289e-06
Iter: 10 loss: 2.13391581e-06
Iter: 11 loss: 2.13378053e-06
Iter: 12 loss: 2.13271051e-06
Iter: 13 loss: 2.13317253e-06
Iter: 14 loss: 2.13196654e-06
Iter: 15 loss: 2.13077374e-06
Iter: 16 loss: 2.13500152e-06
Iter: 17 loss: 2.13045541e-06
Iter: 18 loss: 2.1293049e-06
Iter: 19 loss: 2.1348842e-06
Iter: 20 loss: 2.12909663e-06
Iter: 21 loss: 2.12823443e-06
Iter: 22 loss: 2.12647797e-06
Iter: 23 loss: 2.1596652e-06
Iter: 24 loss: 2.12644909e-06
Iter: 25 loss: 2.12590544e-06
Iter: 26 loss: 2.12536497e-06
Iter: 27 loss: 2.12483656e-06
Iter: 28 loss: 2.12354212e-06
Iter: 29 loss: 2.13603221e-06
Iter: 30 loss: 2.12335976e-06
Iter: 31 loss: 2.12233954e-06
Iter: 32 loss: 2.12578948e-06
Iter: 33 loss: 2.12207e-06
Iter: 34 loss: 2.12122632e-06
Iter: 35 loss: 2.12377108e-06
Iter: 36 loss: 2.12095438e-06
Iter: 37 loss: 2.12008808e-06
Iter: 38 loss: 2.12124542e-06
Iter: 39 loss: 2.11964607e-06
Iter: 40 loss: 2.11898396e-06
Iter: 41 loss: 2.12543182e-06
Iter: 42 loss: 2.11896304e-06
Iter: 43 loss: 2.11884844e-06
Iter: 44 loss: 2.11869497e-06
Iter: 45 loss: 2.11853512e-06
Iter: 46 loss: 2.118054e-06
Iter: 47 loss: 2.12348732e-06
Iter: 48 loss: 2.11800307e-06
Iter: 49 loss: 2.1176952e-06
Iter: 50 loss: 2.12048462e-06
Iter: 51 loss: 2.11768793e-06
Iter: 52 loss: 2.11726592e-06
Iter: 53 loss: 2.11751058e-06
Iter: 54 loss: 2.11698853e-06
Iter: 55 loss: 2.11654833e-06
Iter: 56 loss: 2.11650286e-06
Iter: 57 loss: 2.11619772e-06
Iter: 58 loss: 2.11576548e-06
Iter: 59 loss: 2.11574798e-06
Iter: 60 loss: 2.11553015e-06
Iter: 61 loss: 2.11511269e-06
Iter: 62 loss: 2.11511588e-06
Iter: 63 loss: 2.1148519e-06
Iter: 64 loss: 2.11482234e-06
Iter: 65 loss: 2.11462975e-06
Iter: 66 loss: 2.11456063e-06
Iter: 67 loss: 2.11446263e-06
Iter: 68 loss: 2.11413953e-06
Iter: 69 loss: 2.11388692e-06
Iter: 70 loss: 2.1138087e-06
Iter: 71 loss: 2.11336669e-06
Iter: 72 loss: 2.11328552e-06
Iter: 73 loss: 2.11301517e-06
Iter: 74 loss: 2.11241331e-06
Iter: 75 loss: 2.11649694e-06
Iter: 76 loss: 2.11235511e-06
Iter: 77 loss: 2.11235647e-06
Iter: 78 loss: 2.11216638e-06
Iter: 79 loss: 2.11202041e-06
Iter: 80 loss: 2.11173779e-06
Iter: 81 loss: 2.11749057e-06
Iter: 82 loss: 2.11174256e-06
Iter: 83 loss: 2.11152474e-06
Iter: 84 loss: 2.11238194e-06
Iter: 85 loss: 2.11147108e-06
Iter: 86 loss: 2.11117413e-06
Iter: 87 loss: 2.11260385e-06
Iter: 88 loss: 2.11112956e-06
Iter: 89 loss: 2.11096039e-06
Iter: 90 loss: 2.11051861e-06
Iter: 91 loss: 2.11355655e-06
Iter: 92 loss: 2.11041743e-06
Iter: 93 loss: 2.11000656e-06
Iter: 94 loss: 2.10997632e-06
Iter: 95 loss: 2.10973622e-06
Iter: 96 loss: 2.10947064e-06
Iter: 97 loss: 2.10943881e-06
Iter: 98 loss: 2.10919643e-06
Iter: 99 loss: 2.10917347e-06
Iter: 100 loss: 2.1090234e-06
Iter: 101 loss: 2.10887515e-06
Iter: 102 loss: 2.10884e-06
Iter: 103 loss: 2.10862027e-06
Iter: 104 loss: 2.10926601e-06
Iter: 105 loss: 2.10856751e-06
Iter: 106 loss: 2.10839153e-06
Iter: 107 loss: 2.10828057e-06
Iter: 108 loss: 2.10821781e-06
Iter: 109 loss: 2.10802932e-06
Iter: 110 loss: 2.10803182e-06
Iter: 111 loss: 2.10783628e-06
Iter: 112 loss: 2.10747066e-06
Iter: 113 loss: 2.11511815e-06
Iter: 114 loss: 2.10745202e-06
Iter: 115 loss: 2.10708049e-06
Iter: 116 loss: 2.10726284e-06
Iter: 117 loss: 2.10681742e-06
Iter: 118 loss: 2.10672943e-06
Iter: 119 loss: 2.10658e-06
Iter: 120 loss: 2.10643566e-06
Iter: 121 loss: 2.1061428e-06
Iter: 122 loss: 2.11339716e-06
Iter: 123 loss: 2.10613689e-06
Iter: 124 loss: 2.10590201e-06
Iter: 125 loss: 2.10767985e-06
Iter: 126 loss: 2.10588519e-06
Iter: 127 loss: 2.10556664e-06
Iter: 128 loss: 2.1057258e-06
Iter: 129 loss: 2.10535518e-06
Iter: 130 loss: 2.10513213e-06
Iter: 131 loss: 2.106995e-06
Iter: 132 loss: 2.1051e-06
Iter: 133 loss: 2.1048786e-06
Iter: 134 loss: 2.10483245e-06
Iter: 135 loss: 2.10468261e-06
Iter: 136 loss: 2.10443864e-06
Iter: 137 loss: 2.10507778e-06
Iter: 138 loss: 2.1043561e-06
Iter: 139 loss: 2.10410735e-06
Iter: 140 loss: 2.10396888e-06
Iter: 141 loss: 2.10385224e-06
Iter: 142 loss: 2.10355802e-06
Iter: 143 loss: 2.10594135e-06
Iter: 144 loss: 2.10353846e-06
Iter: 145 loss: 2.10330336e-06
Iter: 146 loss: 2.10546682e-06
Iter: 147 loss: 2.10329881e-06
Iter: 148 loss: 2.10311759e-06
Iter: 149 loss: 2.10264966e-06
Iter: 150 loss: 2.10671351e-06
Iter: 151 loss: 2.10258531e-06
Iter: 152 loss: 2.10217195e-06
Iter: 153 loss: 2.10216535e-06
Iter: 154 loss: 2.10173403e-06
Iter: 155 loss: 2.10233884e-06
Iter: 156 loss: 2.1015353e-06
Iter: 157 loss: 2.1012645e-06
Iter: 158 loss: 2.10143367e-06
Iter: 159 loss: 2.10107419e-06
Iter: 160 loss: 2.10075154e-06
Iter: 161 loss: 2.10415806e-06
Iter: 162 loss: 2.10074e-06
Iter: 163 loss: 2.1005385e-06
Iter: 164 loss: 2.10058124e-06
Iter: 165 loss: 2.10035569e-06
Iter: 166 loss: 2.10010262e-06
Iter: 167 loss: 2.10216376e-06
Iter: 168 loss: 2.10009807e-06
Iter: 169 loss: 2.09993527e-06
Iter: 170 loss: 2.09972882e-06
Iter: 171 loss: 2.09970267e-06
Iter: 172 loss: 2.09934433e-06
Iter: 173 loss: 2.09977043e-06
Iter: 174 loss: 2.09916652e-06
Iter: 175 loss: 2.09874929e-06
Iter: 176 loss: 2.09957e-06
Iter: 177 loss: 2.09857535e-06
Iter: 178 loss: 2.09839072e-06
Iter: 179 loss: 2.09835616e-06
Iter: 180 loss: 2.0981397e-06
Iter: 181 loss: 2.09775408e-06
Iter: 182 loss: 2.10442704e-06
Iter: 183 loss: 2.09773157e-06
Iter: 184 loss: 2.09744553e-06
Iter: 185 loss: 2.10159942e-06
Iter: 186 loss: 2.09745576e-06
Iter: 187 loss: 2.09719337e-06
Iter: 188 loss: 2.09855261e-06
Iter: 189 loss: 2.09715358e-06
Iter: 190 loss: 2.09696645e-06
Iter: 191 loss: 2.09660402e-06
Iter: 192 loss: 2.10314283e-06
Iter: 193 loss: 2.09661403e-06
Iter: 194 loss: 2.09632026e-06
Iter: 195 loss: 2.09631071e-06
Iter: 196 loss: 2.09610857e-06
Iter: 197 loss: 2.09594623e-06
Iter: 198 loss: 2.09588848e-06
Iter: 199 loss: 2.09556674e-06
Iter: 200 loss: 2.09813265e-06
Iter: 201 loss: 2.09555378e-06
Iter: 202 loss: 2.0953612e-06
Iter: 203 loss: 2.09516884e-06
Iter: 204 loss: 2.09513428e-06
Iter: 205 loss: 2.09483642e-06
Iter: 206 loss: 2.09625773e-06
Iter: 207 loss: 2.09481504e-06
Iter: 208 loss: 2.09455266e-06
Iter: 209 loss: 2.09457016e-06
Iter: 210 loss: 2.09432437e-06
Iter: 211 loss: 2.09407131e-06
Iter: 212 loss: 2.09721202e-06
Iter: 213 loss: 2.09405903e-06
Iter: 214 loss: 2.09371024e-06
Iter: 215 loss: 2.09338987e-06
Iter: 216 loss: 2.09331779e-06
Iter: 217 loss: 2.09288373e-06
Iter: 218 loss: 2.09385689e-06
Iter: 219 loss: 2.09275822e-06
Iter: 220 loss: 2.0924108e-06
Iter: 221 loss: 2.09588893e-06
Iter: 222 loss: 2.09239238e-06
Iter: 223 loss: 2.09219752e-06
Iter: 224 loss: 2.09182963e-06
Iter: 225 loss: 2.10023609e-06
Iter: 226 loss: 2.09182554e-06
Iter: 227 loss: 2.09155451e-06
Iter: 228 loss: 2.09153268e-06
Iter: 229 loss: 2.09122732e-06
Iter: 230 loss: 2.09115e-06
Iter: 231 loss: 2.09097357e-06
Iter: 232 loss: 2.09070504e-06
Iter: 233 loss: 2.09463883e-06
Iter: 234 loss: 2.09071231e-06
Iter: 235 loss: 2.09049176e-06
Iter: 236 loss: 2.09006885e-06
Iter: 237 loss: 2.09761e-06
Iter: 238 loss: 2.09007e-06
Iter: 239 loss: 2.08960955e-06
Iter: 240 loss: 2.09253062e-06
Iter: 241 loss: 2.08955225e-06
Iter: 242 loss: 2.08915526e-06
Iter: 243 loss: 2.09023642e-06
Iter: 244 loss: 2.08904385e-06
Iter: 245 loss: 2.08873257e-06
Iter: 246 loss: 2.08849815e-06
Iter: 247 loss: 2.08841129e-06
Iter: 248 loss: 2.08842334e-06
Iter: 249 loss: 2.08819756e-06
Iter: 250 loss: 2.08803431e-06
Iter: 251 loss: 2.08747974e-06
Iter: 252 loss: 2.09055315e-06
Iter: 253 loss: 2.08730626e-06
Iter: 254 loss: 2.0871305e-06
Iter: 255 loss: 2.08701636e-06
Iter: 256 loss: 2.08668484e-06
Iter: 257 loss: 2.08655456e-06
Iter: 258 loss: 2.08640859e-06
Iter: 259 loss: 2.08611823e-06
Iter: 260 loss: 2.08661231e-06
Iter: 261 loss: 2.08598317e-06
Iter: 262 loss: 2.08571623e-06
Iter: 263 loss: 2.08910842e-06
Iter: 264 loss: 2.08569941e-06
Iter: 265 loss: 2.08555912e-06
Iter: 266 loss: 2.08551705e-06
Iter: 267 loss: 2.08540087e-06
Iter: 268 loss: 2.08510346e-06
Iter: 269 loss: 2.0857874e-06
Iter: 270 loss: 2.08497931e-06
Iter: 271 loss: 2.08472966e-06
Iter: 272 loss: 2.0844202e-06
Iter: 273 loss: 2.08438632e-06
Iter: 274 loss: 2.08403708e-06
Iter: 275 loss: 2.08724964e-06
Iter: 276 loss: 2.08401298e-06
Iter: 277 loss: 2.08368056e-06
Iter: 278 loss: 2.083445e-06
Iter: 279 loss: 2.08333586e-06
Iter: 280 loss: 2.08301708e-06
Iter: 281 loss: 2.0859984e-06
Iter: 282 loss: 2.08298366e-06
Iter: 283 loss: 2.08279312e-06
Iter: 284 loss: 2.08278129e-06
Iter: 285 loss: 2.08259394e-06
Iter: 286 loss: 2.08213328e-06
Iter: 287 loss: 2.08476695e-06
Iter: 288 loss: 2.08200481e-06
Iter: 289 loss: 2.08181018e-06
Iter: 290 loss: 2.08166693e-06
Iter: 291 loss: 2.08140455e-06
Iter: 292 loss: 2.08084316e-06
Iter: 293 loss: 2.08904908e-06
Iter: 294 loss: 2.08085658e-06
Iter: 295 loss: 2.08051915e-06
Iter: 296 loss: 2.08052438e-06
Iter: 297 loss: 2.08021493e-06
Iter: 298 loss: 2.08094525e-06
Iter: 299 loss: 2.08010897e-06
Iter: 300 loss: 2.07994708e-06
Iter: 301 loss: 2.08111851e-06
Iter: 302 loss: 2.07993253e-06
Iter: 303 loss: 2.07976336e-06
Iter: 304 loss: 2.07959101e-06
Iter: 305 loss: 2.07956805e-06
Iter: 306 loss: 2.07936296e-06
Iter: 307 loss: 2.07946096e-06
Iter: 308 loss: 2.07920698e-06
Iter: 309 loss: 2.07883272e-06
Iter: 310 loss: 2.07987614e-06
Iter: 311 loss: 2.07874837e-06
Iter: 312 loss: 2.07838457e-06
Iter: 313 loss: 2.07820653e-06
Iter: 314 loss: 2.07802464e-06
Iter: 315 loss: 2.07754215e-06
Iter: 316 loss: 2.0793866e-06
Iter: 317 loss: 2.07742687e-06
Iter: 318 loss: 2.07701828e-06
Iter: 319 loss: 2.07882044e-06
Iter: 320 loss: 2.07695211e-06
Iter: 321 loss: 2.07676203e-06
Iter: 322 loss: 2.07676476e-06
Iter: 323 loss: 2.07654216e-06
Iter: 324 loss: 2.07621633e-06
Iter: 325 loss: 2.07622634e-06
Iter: 326 loss: 2.07597259e-06
Iter: 327 loss: 2.07837934e-06
Iter: 328 loss: 2.07595735e-06
Iter: 329 loss: 2.07568883e-06
Iter: 330 loss: 2.07589915e-06
Iter: 331 loss: 2.07554376e-06
Iter: 332 loss: 2.07537778e-06
Iter: 333 loss: 2.07648532e-06
Iter: 334 loss: 2.07530866e-06
Iter: 335 loss: 2.07510493e-06
Iter: 336 loss: 2.07528774e-06
Iter: 337 loss: 2.0749942e-06
Iter: 338 loss: 2.07481708e-06
Iter: 339 loss: 2.07521271e-06
Iter: 340 loss: 2.07472613e-06
Iter: 341 loss: 2.07455378e-06
Iter: 342 loss: 2.07599032e-06
Iter: 343 loss: 2.07451944e-06
Iter: 344 loss: 2.07436187e-06
Iter: 345 loss: 2.07417315e-06
Iter: 346 loss: 2.0741677e-06
Iter: 347 loss: 2.07384892e-06
Iter: 348 loss: 2.07410721e-06
Iter: 349 loss: 2.073627e-06
Iter: 350 loss: 2.07320977e-06
Iter: 351 loss: 2.07314633e-06
Iter: 352 loss: 2.07287167e-06
Iter: 353 loss: 2.07238395e-06
Iter: 354 loss: 2.07557423e-06
Iter: 355 loss: 2.07231119e-06
Iter: 356 loss: 2.0721634e-06
Iter: 357 loss: 2.07208905e-06
Iter: 358 loss: 2.07191852e-06
Iter: 359 loss: 2.07167795e-06
Iter: 360 loss: 2.07165249e-06
Iter: 361 loss: 2.07140738e-06
Iter: 362 loss: 2.07302082e-06
Iter: 363 loss: 2.07137282e-06
Iter: 364 loss: 2.07105495e-06
Iter: 365 loss: 2.0709731e-06
Iter: 366 loss: 2.07078187e-06
Iter: 367 loss: 2.07052494e-06
Iter: 368 loss: 2.07316702e-06
Iter: 369 loss: 2.07050471e-06
Iter: 370 loss: 2.07021094e-06
Iter: 371 loss: 2.07010271e-06
Iter: 372 loss: 2.06997197e-06
Iter: 373 loss: 2.06968502e-06
Iter: 374 loss: 2.07107769e-06
Iter: 375 loss: 2.06961431e-06
Iter: 376 loss: 2.06932714e-06
Iter: 377 loss: 2.07018638e-06
Iter: 378 loss: 2.06920458e-06
Iter: 379 loss: 2.06898903e-06
Iter: 380 loss: 2.06904565e-06
Iter: 381 loss: 2.06882169e-06
Iter: 382 loss: 2.0684804e-06
Iter: 383 loss: 2.06859795e-06
Iter: 384 loss: 2.06822688e-06
Iter: 385 loss: 2.06777395e-06
Iter: 386 loss: 2.06794539e-06
Iter: 387 loss: 2.06746654e-06
Iter: 388 loss: 2.06696291e-06
Iter: 389 loss: 2.07090511e-06
Iter: 390 loss: 2.06694813e-06
Iter: 391 loss: 2.06659251e-06
Iter: 392 loss: 2.06659797e-06
Iter: 393 loss: 2.06642972e-06
Iter: 394 loss: 2.06619666e-06
Iter: 395 loss: 2.06618597e-06
Iter: 396 loss: 2.06592381e-06
Iter: 397 loss: 2.06592131e-06
Iter: 398 loss: 2.06576146e-06
Iter: 399 loss: 2.06539903e-06
Iter: 400 loss: 2.07359017e-06
Iter: 401 loss: 2.06540221e-06
Iter: 402 loss: 2.06514392e-06
Iter: 403 loss: 2.06513096e-06
Iter: 404 loss: 2.06494815e-06
Iter: 405 loss: 2.06461709e-06
Iter: 406 loss: 2.06461482e-06
Iter: 407 loss: 2.06426421e-06
Iter: 408 loss: 2.06870845e-06
Iter: 409 loss: 2.0642633e-06
Iter: 410 loss: 2.06398772e-06
Iter: 411 loss: 2.06353798e-06
Iter: 412 loss: 2.06352115e-06
Iter: 413 loss: 2.06307641e-06
Iter: 414 loss: 2.06529103e-06
Iter: 415 loss: 2.06298091e-06
Iter: 416 loss: 2.06252889e-06
Iter: 417 loss: 2.06252616e-06
Iter: 418 loss: 2.06215282e-06
Iter: 419 loss: 2.06164805e-06
Iter: 420 loss: 2.06324103e-06
Iter: 421 loss: 2.0615289e-06
Iter: 422 loss: 2.06114782e-06
Iter: 423 loss: 2.06651703e-06
Iter: 424 loss: 2.06114714e-06
Iter: 425 loss: 2.06076515e-06
Iter: 426 loss: 2.06047025e-06
Iter: 427 loss: 2.06032519e-06
Iter: 428 loss: 2.05990136e-06
Iter: 429 loss: 2.06324967e-06
Iter: 430 loss: 2.05986385e-06
Iter: 431 loss: 2.05944957e-06
Iter: 432 loss: 2.05965e-06
Iter: 433 loss: 2.05913148e-06
Iter: 434 loss: 2.05873357e-06
Iter: 435 loss: 2.06088725e-06
Iter: 436 loss: 2.05867013e-06
Iter: 437 loss: 2.05823835e-06
Iter: 438 loss: 2.05861193e-06
Iter: 439 loss: 2.05795914e-06
Iter: 440 loss: 2.05757806e-06
Iter: 441 loss: 2.05875176e-06
Iter: 442 loss: 2.05746051e-06
Iter: 443 loss: 2.05697597e-06
Iter: 444 loss: 2.05786182e-06
Iter: 445 loss: 2.05675406e-06
Iter: 446 loss: 2.05628703e-06
Iter: 447 loss: 2.05574133e-06
Iter: 448 loss: 2.05568017e-06
Iter: 449 loss: 2.05494757e-06
Iter: 450 loss: 2.06109144e-06
Iter: 451 loss: 2.05492461e-06
Iter: 452 loss: 2.05442529e-06
Iter: 453 loss: 2.05423612e-06
Iter: 454 loss: 2.05398032e-06
Iter: 455 loss: 2.05356832e-06
Iter: 456 loss: 2.0535681e-06
Iter: 457 loss: 2.0531329e-06
Iter: 458 loss: 2.05408696e-06
Iter: 459 loss: 2.05297579e-06
Iter: 460 loss: 2.05264314e-06
Iter: 461 loss: 2.05279275e-06
Iter: 462 loss: 2.05239053e-06
Iter: 463 loss: 2.05187189e-06
Iter: 464 loss: 2.05533797e-06
Iter: 465 loss: 2.05184097e-06
Iter: 466 loss: 2.05146284e-06
Iter: 467 loss: 2.05112497e-06
Iter: 468 loss: 2.05103811e-06
Iter: 469 loss: 2.05042465e-06
Iter: 470 loss: 2.05721039e-06
Iter: 471 loss: 2.05043489e-06
Iter: 472 loss: 2.05011747e-06
Iter: 473 loss: 2.04996059e-06
Iter: 474 loss: 2.04979528e-06
Iter: 475 loss: 2.04946809e-06
Iter: 476 loss: 2.04947719e-06
Iter: 477 loss: 2.04928119e-06
Iter: 478 loss: 2.04890603e-06
Iter: 479 loss: 2.05727201e-06
Iter: 480 loss: 2.04890443e-06
Iter: 481 loss: 2.04841035e-06
Iter: 482 loss: 2.04972412e-06
Iter: 483 loss: 2.04825164e-06
Iter: 484 loss: 2.04760818e-06
Iter: 485 loss: 2.04797311e-06
Iter: 486 loss: 2.04721e-06
Iter: 487 loss: 2.04639446e-06
Iter: 488 loss: 2.04657272e-06
Iter: 489 loss: 2.04579419e-06
Iter: 490 loss: 2.04618277e-06
Iter: 491 loss: 2.04539833e-06
Iter: 492 loss: 2.04514959e-06
Iter: 493 loss: 2.04468256e-06
Iter: 494 loss: 2.05404308e-06
Iter: 495 loss: 2.04469166e-06
Iter: 496 loss: 2.04431217e-06
Iter: 497 loss: 2.04431285e-06
Iter: 498 loss: 2.04406319e-06
Iter: 499 loss: 2.04376238e-06
Iter: 500 loss: 2.043726e-06
Iter: 501 loss: 2.04342177e-06
Iter: 502 loss: 2.04342041e-06
Iter: 503 loss: 2.04316075e-06
Iter: 504 loss: 2.04277057e-06
Iter: 505 loss: 2.04274966e-06
Iter: 506 loss: 2.04233811e-06
Iter: 507 loss: 2.04664548e-06
Iter: 508 loss: 2.04231469e-06
Iter: 509 loss: 2.04189064e-06
Iter: 510 loss: 2.0417383e-06
Iter: 511 loss: 2.0414609e-06
Iter: 512 loss: 2.0410273e-06
Iter: 513 loss: 2.04144e-06
Iter: 514 loss: 2.04076105e-06
Iter: 515 loss: 2.04028788e-06
Iter: 516 loss: 2.04316621e-06
Iter: 517 loss: 2.04024127e-06
Iter: 518 loss: 2.03987111e-06
Iter: 519 loss: 2.03978016e-06
Iter: 520 loss: 2.03951367e-06
Iter: 521 loss: 2.03921127e-06
Iter: 522 loss: 2.04469598e-06
Iter: 523 loss: 2.03920604e-06
Iter: 524 loss: 2.03881655e-06
Iter: 525 loss: 2.03867512e-06
Iter: 526 loss: 2.03843661e-06
Iter: 527 loss: 2.03804666e-06
Iter: 528 loss: 2.03978334e-06
Iter: 529 loss: 2.03797867e-06
Iter: 530 loss: 2.0375046e-06
Iter: 531 loss: 2.03844274e-06
Iter: 532 loss: 2.03732429e-06
Iter: 533 loss: 2.03703485e-06
Iter: 534 loss: 2.03838408e-06
Iter: 535 loss: 2.03697141e-06
Iter: 536 loss: 2.03668287e-06
Iter: 537 loss: 2.0372288e-06
Iter: 538 loss: 2.03657464e-06
Iter: 539 loss: 2.03627496e-06
Iter: 540 loss: 2.03635818e-06
Iter: 541 loss: 2.03607397e-06
Iter: 542 loss: 2.03569698e-06
Iter: 543 loss: 2.03876334e-06
Iter: 544 loss: 2.03566719e-06
Iter: 545 loss: 2.03540139e-06
Iter: 546 loss: 2.03492755e-06
Iter: 547 loss: 2.04635785e-06
Iter: 548 loss: 2.03493437e-06
Iter: 549 loss: 2.03434729e-06
Iter: 550 loss: 2.03662171e-06
Iter: 551 loss: 2.03419404e-06
Iter: 552 loss: 2.03367881e-06
Iter: 553 loss: 2.03580066e-06
Iter: 554 loss: 2.03356421e-06
Iter: 555 loss: 2.03328e-06
Iter: 556 loss: 2.03423e-06
Iter: 557 loss: 2.03320837e-06
Iter: 558 loss: 2.03286345e-06
Iter: 559 loss: 2.03689433e-06
Iter: 560 loss: 2.03286322e-06
Iter: 561 loss: 2.03269019e-06
Iter: 562 loss: 2.03229297e-06
Iter: 563 loss: 2.03843342e-06
Iter: 564 loss: 2.03229229e-06
Iter: 565 loss: 2.03200898e-06
Iter: 566 loss: 2.03196259e-06
Iter: 567 loss: 2.03178638e-06
Iter: 568 loss: 2.0313546e-06
Iter: 569 loss: 2.03700984e-06
Iter: 570 loss: 2.03131731e-06
Iter: 571 loss: 2.03087393e-06
Iter: 572 loss: 2.03086665e-06
Iter: 573 loss: 2.03059676e-06
Iter: 574 loss: 2.0303155e-06
Iter: 575 loss: 2.0302748e-06
Iter: 576 loss: 2.02996489e-06
Iter: 577 loss: 2.02996648e-06
Iter: 578 loss: 2.02969886e-06
Iter: 579 loss: 2.02941874e-06
Iter: 580 loss: 2.02938872e-06
Iter: 581 loss: 2.02904016e-06
Iter: 582 loss: 2.02944875e-06
Iter: 583 loss: 2.02884803e-06
Iter: 584 loss: 2.02841693e-06
Iter: 585 loss: 2.03036279e-06
Iter: 586 loss: 2.02831961e-06
Iter: 587 loss: 2.02788715e-06
Iter: 588 loss: 2.02731849e-06
Iter: 589 loss: 2.02725278e-06
Iter: 590 loss: 2.02670458e-06
Iter: 591 loss: 2.03292893e-06
Iter: 592 loss: 2.02671185e-06
Iter: 593 loss: 2.0263617e-06
Iter: 594 loss: 2.02635965e-06
Iter: 595 loss: 2.02621845e-06
Iter: 596 loss: 2.02593537e-06
Iter: 597 loss: 2.03081368e-06
Iter: 598 loss: 2.02590581e-06
Iter: 599 loss: 2.02557658e-06
Iter: 600 loss: 2.02558567e-06
Iter: 601 loss: 2.02538649e-06
Iter: 602 loss: 2.02501155e-06
Iter: 603 loss: 2.03246464e-06
Iter: 604 loss: 2.02500178e-06
Iter: 605 loss: 2.0246157e-06
Iter: 606 loss: 2.02457659e-06
Iter: 607 loss: 2.02437241e-06
Iter: 608 loss: 2.02392425e-06
Iter: 609 loss: 2.0314144e-06
Iter: 610 loss: 2.02389765e-06
Iter: 611 loss: 2.02365186e-06
Iter: 612 loss: 2.02359615e-06
Iter: 613 loss: 2.02337651e-06
Iter: 614 loss: 2.02304818e-06
Iter: 615 loss: 2.02305273e-06
Iter: 616 loss: 2.02271667e-06
Iter: 617 loss: 2.02278534e-06
Iter: 618 loss: 2.02249839e-06
Iter: 619 loss: 2.02204092e-06
Iter: 620 loss: 2.02473666e-06
Iter: 621 loss: 2.022e-06
Iter: 622 loss: 2.02156366e-06
Iter: 623 loss: 2.02197748e-06
Iter: 624 loss: 2.0213165e-06
Iter: 625 loss: 2.02092974e-06
Iter: 626 loss: 2.02243177e-06
Iter: 627 loss: 2.02084743e-06
Iter: 628 loss: 2.02055799e-06
Iter: 629 loss: 2.02053525e-06
Iter: 630 loss: 2.0204111e-06
Iter: 631 loss: 2.02005799e-06
Iter: 632 loss: 2.02324395e-06
Iter: 633 loss: 2.02001365e-06
Iter: 634 loss: 2.01987064e-06
Iter: 635 loss: 2.01977787e-06
Iter: 636 loss: 2.01961575e-06
Iter: 637 loss: 2.01921557e-06
Iter: 638 loss: 2.02357865e-06
Iter: 639 loss: 2.01916691e-06
Iter: 640 loss: 2.01893067e-06
Iter: 641 loss: 2.01888224e-06
Iter: 642 loss: 2.01870398e-06
Iter: 643 loss: 2.01829266e-06
Iter: 644 loss: 2.02499268e-06
Iter: 645 loss: 2.01829698e-06
Iter: 646 loss: 2.01807052e-06
Iter: 647 loss: 2.01805506e-06
Iter: 648 loss: 2.01783428e-06
Iter: 649 loss: 2.01757166e-06
Iter: 650 loss: 2.01755347e-06
Iter: 651 loss: 2.01723606e-06
Iter: 652 loss: 2.01740727e-06
Iter: 653 loss: 2.01703824e-06
Iter: 654 loss: 2.01680064e-06
Iter: 655 loss: 2.01660623e-06
Iter: 656 loss: 2.0165121e-06
Iter: 657 loss: 2.01607645e-06
Iter: 658 loss: 2.01726516e-06
Iter: 659 loss: 2.01591411e-06
Iter: 660 loss: 2.01548164e-06
Iter: 661 loss: 2.01985813e-06
Iter: 662 loss: 2.01545845e-06
Iter: 663 loss: 2.01520106e-06
Iter: 664 loss: 2.01479065e-06
Iter: 665 loss: 2.01478906e-06
Iter: 666 loss: 2.01450712e-06
Iter: 667 loss: 2.01448438e-06
Iter: 668 loss: 2.014237e-06
Iter: 669 loss: 2.01375769e-06
Iter: 670 loss: 2.0226164e-06
Iter: 671 loss: 2.01374451e-06
Iter: 672 loss: 2.01352896e-06
Iter: 673 loss: 2.01352032e-06
Iter: 674 loss: 2.0132602e-06
Iter: 675 loss: 2.01316243e-06
Iter: 676 loss: 2.01303828e-06
Iter: 677 loss: 2.01278749e-06
Iter: 678 loss: 2.01433022e-06
Iter: 679 loss: 2.01277612e-06
Iter: 680 loss: 2.0124653e-06
Iter: 681 loss: 2.01225816e-06
Iter: 682 loss: 2.01216653e-06
Iter: 683 loss: 2.01182775e-06
Iter: 684 loss: 2.01541889e-06
Iter: 685 loss: 2.01184412e-06
Iter: 686 loss: 2.01157263e-06
Iter: 687 loss: 2.01124226e-06
Iter: 688 loss: 2.01122202e-06
Iter: 689 loss: 2.01087141e-06
Iter: 690 loss: 2.01081957e-06
Iter: 691 loss: 2.01059242e-06
Iter: 692 loss: 2.01025114e-06
Iter: 693 loss: 2.01025796e-06
Iter: 694 loss: 2.00986301e-06
Iter: 695 loss: 2.01039074e-06
Iter: 696 loss: 2.0096852e-06
Iter: 697 loss: 2.00937029e-06
Iter: 698 loss: 2.00954446e-06
Iter: 699 loss: 2.00917657e-06
Iter: 700 loss: 2.00898444e-06
Iter: 701 loss: 2.00895556e-06
Iter: 702 loss: 2.00880186e-06
Iter: 703 loss: 2.00838235e-06
Iter: 704 loss: 2.01135208e-06
Iter: 705 loss: 2.00828958e-06
Iter: 706 loss: 2.00842032e-06
Iter: 707 loss: 2.00816271e-06
Iter: 708 loss: 2.00805448e-06
Iter: 709 loss: 2.00781096e-06
Iter: 710 loss: 2.0116513e-06
Iter: 711 loss: 2.00780141e-06
Iter: 712 loss: 2.00768409e-06
Iter: 713 loss: 2.00765407e-06
Iter: 714 loss: 2.0075413e-06
Iter: 715 loss: 2.00723071e-06
Iter: 716 loss: 2.01160219e-06
Iter: 717 loss: 2.00717113e-06
Iter: 718 loss: 2.0068685e-06
Iter: 719 loss: 2.00755176e-06
Iter: 720 loss: 2.00672162e-06
Iter: 721 loss: 2.00635941e-06
Iter: 722 loss: 2.00636578e-06
Iter: 723 loss: 2.00616887e-06
Iter: 724 loss: 2.00605382e-06
Iter: 725 loss: 2.0059822e-06
Iter: 726 loss: 2.00576687e-06
Iter: 727 loss: 2.00806221e-06
Iter: 728 loss: 2.00574596e-06
Iter: 729 loss: 2.00560726e-06
Iter: 730 loss: 2.00541717e-06
Iter: 731 loss: 2.00539034e-06
Iter: 732 loss: 2.00522982e-06
Iter: 733 loss: 2.00648878e-06
Iter: 734 loss: 2.00521777e-06
Iter: 735 loss: 2.00497379e-06
Iter: 736 loss: 2.00529394e-06
Iter: 737 loss: 2.0048617e-06
Iter: 738 loss: 2.00467366e-06
Iter: 739 loss: 2.00432396e-06
Iter: 740 loss: 2.00433442e-06
Iter: 741 loss: 2.00409886e-06
Iter: 742 loss: 2.00408022e-06
Iter: 743 loss: 2.00384716e-06
Iter: 744 loss: 2.00395971e-06
Iter: 745 loss: 2.00368777e-06
Iter: 746 loss: 2.00349041e-06
Iter: 747 loss: 2.00438217e-06
Iter: 748 loss: 2.00347267e-06
Iter: 749 loss: 2.00326576e-06
Iter: 750 loss: 2.00372551e-06
Iter: 751 loss: 2.00320073e-06
Iter: 752 loss: 2.00306181e-06
Iter: 753 loss: 2.00274599e-06
Iter: 754 loss: 2.00793784e-06
Iter: 755 loss: 2.00276509e-06
Iter: 756 loss: 2.00248201e-06
Iter: 757 loss: 2.00631325e-06
Iter: 758 loss: 2.00249906e-06
Iter: 759 loss: 2.00221984e-06
Iter: 760 loss: 2.00283785e-06
Iter: 761 loss: 2.00213844e-06
Iter: 762 loss: 2.00187196e-06
Iter: 763 loss: 2.00294335e-06
Iter: 764 loss: 2.00184331e-06
Iter: 765 loss: 2.00166e-06
Iter: 766 loss: 2.00139971e-06
Iter: 767 loss: 2.00139402e-06
Iter: 768 loss: 2.0011671e-06
Iter: 769 loss: 2.00413797e-06
Iter: 770 loss: 2.00117529e-06
Iter: 771 loss: 2.0009627e-06
Iter: 772 loss: 2.00222576e-06
Iter: 773 loss: 2.00093086e-06
Iter: 774 loss: 2.00082422e-06
Iter: 775 loss: 2.00048157e-06
Iter: 776 loss: 2.00252202e-06
Iter: 777 loss: 2.00038244e-06
Iter: 778 loss: 1.99991314e-06
Iter: 779 loss: 2.00126965e-06
Iter: 780 loss: 1.99976967e-06
Iter: 781 loss: 1.99931e-06
Iter: 782 loss: 2.0006978e-06
Iter: 783 loss: 1.99916735e-06
Iter: 784 loss: 1.99903957e-06
Iter: 785 loss: 1.99894885e-06
Iter: 786 loss: 1.99874444e-06
Iter: 787 loss: 1.99864712e-06
Iter: 788 loss: 1.99858096e-06
Iter: 789 loss: 1.99835381e-06
Iter: 790 loss: 1.99841725e-06
Iter: 791 loss: 1.99821875e-06
Iter: 792 loss: 1.99792476e-06
Iter: 793 loss: 2.0018274e-06
Iter: 794 loss: 1.99794567e-06
Iter: 795 loss: 1.99775604e-06
Iter: 796 loss: 1.99777014e-06
Iter: 797 loss: 1.99761212e-06
Iter: 798 loss: 1.99735678e-06
Iter: 799 loss: 1.99740089e-06
Iter: 800 loss: 1.99718079e-06
Iter: 801 loss: 1.9968827e-06
Iter: 802 loss: 1.99860915e-06
Iter: 803 loss: 1.99684246e-06
Iter: 804 loss: 1.99652209e-06
Iter: 805 loss: 1.9979334e-06
Iter: 806 loss: 1.99645638e-06
Iter: 807 loss: 1.99628676e-06
Iter: 808 loss: 1.99591477e-06
Iter: 809 loss: 2.00151862e-06
Iter: 810 loss: 1.995905e-06
Iter: 811 loss: 1.99574151e-06
Iter: 812 loss: 1.99570241e-06
Iter: 813 loss: 1.99544502e-06
Iter: 814 loss: 1.99489727e-06
Iter: 815 loss: 2.00346881e-06
Iter: 816 loss: 1.99489068e-06
Iter: 817 loss: 1.99439978e-06
Iter: 818 loss: 1.99524243e-06
Iter: 819 loss: 1.99416627e-06
Iter: 820 loss: 1.99375199e-06
Iter: 821 loss: 1.99373608e-06
Iter: 822 loss: 1.99344163e-06
Iter: 823 loss: 1.99324404e-06
Iter: 824 loss: 1.9931324e-06
Iter: 825 loss: 1.99287479e-06
Iter: 826 loss: 1.99543433e-06
Iter: 827 loss: 1.99286478e-06
Iter: 828 loss: 1.99262604e-06
Iter: 829 loss: 1.99310648e-06
Iter: 830 loss: 1.99252e-06
Iter: 831 loss: 1.99234137e-06
Iter: 832 loss: 1.99255919e-06
Iter: 833 loss: 1.99221404e-06
Iter: 834 loss: 1.99197439e-06
Iter: 835 loss: 1.99170881e-06
Iter: 836 loss: 1.99167403e-06
Iter: 837 loss: 1.99131273e-06
Iter: 838 loss: 1.99134365e-06
Iter: 839 loss: 1.99098122e-06
Iter: 840 loss: 1.99034957e-06
Iter: 841 loss: 2.00551403e-06
Iter: 842 loss: 1.99036185e-06
Iter: 843 loss: 1.98978705e-06
Iter: 844 loss: 1.99047417e-06
Iter: 845 loss: 1.98947919e-06
Iter: 846 loss: 1.98923362e-06
Iter: 847 loss: 1.98912198e-06
Iter: 848 loss: 1.9889444e-06
Iter: 849 loss: 1.98852558e-06
Iter: 850 loss: 1.99277724e-06
Iter: 851 loss: 1.98849193e-06
Iter: 852 loss: 1.98819498e-06
Iter: 853 loss: 1.99166516e-06
Iter: 854 loss: 1.98818498e-06
Iter: 855 loss: 1.98787166e-06
Iter: 856 loss: 1.98916223e-06
Iter: 857 loss: 1.98780958e-06
Iter: 858 loss: 1.98760517e-06
Iter: 859 loss: 1.98774342e-06
Iter: 860 loss: 1.98748126e-06
Iter: 861 loss: 1.9872009e-06
Iter: 862 loss: 1.98833959e-06
Iter: 863 loss: 1.98714952e-06
Iter: 864 loss: 1.98688804e-06
Iter: 865 loss: 1.98661837e-06
Iter: 866 loss: 1.98654766e-06
Iter: 867 loss: 1.9860945e-06
Iter: 868 loss: 1.9881129e-06
Iter: 869 loss: 1.98600492e-06
Iter: 870 loss: 1.98567386e-06
Iter: 871 loss: 1.98756061e-06
Iter: 872 loss: 1.98563771e-06
Iter: 873 loss: 1.98529915e-06
Iter: 874 loss: 1.98668158e-06
Iter: 875 loss: 1.98522503e-06
Iter: 876 loss: 1.98503471e-06
Iter: 877 loss: 1.98465068e-06
Iter: 878 loss: 1.9916979e-06
Iter: 879 loss: 1.98464068e-06
Iter: 880 loss: 1.9843751e-06
Iter: 881 loss: 1.9843726e-06
Iter: 882 loss: 1.98404882e-06
Iter: 883 loss: 1.98378302e-06
Iter: 884 loss: 1.98370708e-06
Iter: 885 loss: 1.98344219e-06
Iter: 886 loss: 1.98376483e-06
Iter: 887 loss: 1.98331691e-06
Iter: 888 loss: 1.98313023e-06
Iter: 889 loss: 1.98311045e-06
Iter: 890 loss: 1.9829854e-06
Iter: 891 loss: 1.98296607e-06
Iter: 892 loss: 1.98286943e-06
Iter: 893 loss: 1.98269754e-06
Iter: 894 loss: 1.98377188e-06
Iter: 895 loss: 1.98269254e-06
Iter: 896 loss: 1.98253338e-06
Iter: 897 loss: 1.98226098e-06
Iter: 898 loss: 1.98227212e-06
Iter: 899 loss: 1.98189696e-06
Iter: 900 loss: 1.98296539e-06
Iter: 901 loss: 1.98178577e-06
Iter: 902 loss: 1.9814529e-06
Iter: 903 loss: 1.98285488e-06
Iter: 904 loss: 1.98136695e-06
Iter: 905 loss: 1.98107136e-06
Iter: 906 loss: 1.98430962e-06
Iter: 907 loss: 1.9810409e-06
Iter: 908 loss: 1.98084763e-06
Iter: 909 loss: 1.98039334e-06
Iter: 910 loss: 1.98834732e-06
Iter: 911 loss: 1.9803872e-06
Iter: 912 loss: 1.98027351e-06
Iter: 913 loss: 1.98023963e-06
Iter: 914 loss: 1.98008433e-06
Iter: 915 loss: 1.98020712e-06
Iter: 916 loss: 1.98002022e-06
Iter: 917 loss: 1.97985696e-06
Iter: 918 loss: 1.97956365e-06
Iter: 919 loss: 1.98661132e-06
Iter: 920 loss: 1.97956797e-06
Iter: 921 loss: 1.97942654e-06
Iter: 922 loss: 1.97940562e-06
Iter: 923 loss: 1.97922191e-06
Iter: 924 loss: 1.97921e-06
Iter: 925 loss: 1.97905183e-06
Iter: 926 loss: 1.97887812e-06
Iter: 927 loss: 1.98074395e-06
Iter: 928 loss: 1.97887562e-06
Iter: 929 loss: 1.97871577e-06
Iter: 930 loss: 1.97855775e-06
Iter: 931 loss: 1.97851477e-06
Iter: 932 loss: 1.97829422e-06
Iter: 933 loss: 1.97893132e-06
Iter: 934 loss: 1.97824329e-06
Iter: 935 loss: 1.97802456e-06
Iter: 936 loss: 1.97812437e-06
Iter: 937 loss: 1.97786858e-06
Iter: 938 loss: 1.97757413e-06
Iter: 939 loss: 1.98157727e-06
Iter: 940 loss: 1.97755708e-06
Iter: 941 loss: 1.97736335e-06
Iter: 942 loss: 1.97720328e-06
Iter: 943 loss: 1.97713371e-06
Iter: 944 loss: 1.97692134e-06
Iter: 945 loss: 1.9772508e-06
Iter: 946 loss: 1.97680629e-06
Iter: 947 loss: 1.97655345e-06
Iter: 948 loss: 1.98032194e-06
Iter: 949 loss: 1.97655322e-06
Iter: 950 loss: 1.97644817e-06
Iter: 951 loss: 1.97621875e-06
Iter: 952 loss: 1.97622558e-06
Iter: 953 loss: 1.97601821e-06
Iter: 954 loss: 1.97685745e-06
Iter: 955 loss: 1.97600639e-06
Iter: 956 loss: 1.97574309e-06
Iter: 957 loss: 1.97761619e-06
Iter: 958 loss: 1.97576128e-06
Iter: 959 loss: 1.97562531e-06
Iter: 960 loss: 1.97579948e-06
Iter: 961 loss: 1.9755264e-06
Iter: 962 loss: 1.97530153e-06
Iter: 963 loss: 1.9753079e-06
Iter: 964 loss: 1.97514373e-06
Iter: 965 loss: 1.9748627e-06
Iter: 966 loss: 1.97515101e-06
Iter: 967 loss: 1.97470854e-06
Iter: 968 loss: 1.97442796e-06
Iter: 969 loss: 1.97492045e-06
Iter: 970 loss: 1.97430177e-06
Iter: 971 loss: 1.97402778e-06
Iter: 972 loss: 1.97403938e-06
Iter: 973 loss: 1.97381655e-06
Iter: 974 loss: 1.97393501e-06
Iter: 975 loss: 1.97365671e-06
Iter: 976 loss: 1.97345776e-06
Iter: 977 loss: 1.97328723e-06
Iter: 978 loss: 1.97320924e-06
Iter: 979 loss: 1.97299096e-06
Iter: 980 loss: 1.97298186e-06
Iter: 981 loss: 1.97274676e-06
Iter: 982 loss: 1.97234704e-06
Iter: 983 loss: 1.9811e-06
Iter: 984 loss: 1.97232566e-06
Iter: 985 loss: 1.97199415e-06
Iter: 986 loss: 1.97295e-06
Iter: 987 loss: 1.97184954e-06
Iter: 988 loss: 1.97169152e-06
Iter: 989 loss: 1.9716465e-06
Iter: 990 loss: 1.97148802e-06
Iter: 991 loss: 1.97142799e-06
Iter: 992 loss: 1.97133932e-06
Iter: 993 loss: 1.97113127e-06
Iter: 994 loss: 1.97320514e-06
Iter: 995 loss: 1.97112877e-06
Iter: 996 loss: 1.9709878e-06
Iter: 997 loss: 1.97070835e-06
Iter: 998 loss: 1.97538702e-06
Iter: 999 loss: 1.97066947e-06
Iter: 1000 loss: 1.97032409e-06
Iter: 1001 loss: 1.97159534e-06
Iter: 1002 loss: 1.97021245e-06
Iter: 1003 loss: 1.96983046e-06
Iter: 1004 loss: 1.97087138e-06
Iter: 1005 loss: 1.96971e-06
Iter: 1006 loss: 1.96931569e-06
Iter: 1007 loss: 1.97370173e-06
Iter: 1008 loss: 1.96934297e-06
Iter: 1009 loss: 1.9691106e-06
Iter: 1010 loss: 1.96887049e-06
Iter: 1011 loss: 1.96882047e-06
Iter: 1012 loss: 1.96858764e-06
Iter: 1013 loss: 1.96989322e-06
Iter: 1014 loss: 1.96853216e-06
Iter: 1015 loss: 1.96826204e-06
Iter: 1016 loss: 1.97020677e-06
Iter: 1017 loss: 1.96824817e-06
Iter: 1018 loss: 1.96809174e-06
Iter: 1019 loss: 1.96776864e-06
Iter: 1020 loss: 1.97182044e-06
Iter: 1021 loss: 1.96773954e-06
Iter: 1022 loss: 1.96741507e-06
Iter: 1023 loss: 1.97005829e-06
Iter: 1024 loss: 1.96740393e-06
Iter: 1025 loss: 1.96708879e-06
Iter: 1026 loss: 1.96863971e-06
Iter: 1027 loss: 1.96701149e-06
Iter: 1028 loss: 1.9667782e-06
Iter: 1029 loss: 1.9678223e-06
Iter: 1030 loss: 1.96674546e-06
Iter: 1031 loss: 1.96650967e-06
Iter: 1032 loss: 1.96653627e-06
Iter: 1033 loss: 1.966333e-06
Iter: 1034 loss: 1.96607107e-06
Iter: 1035 loss: 1.96600399e-06
Iter: 1036 loss: 1.9658537e-06
Iter: 1037 loss: 1.96551673e-06
Iter: 1038 loss: 1.96710198e-06
Iter: 1039 loss: 1.96546216e-06
Iter: 1040 loss: 1.9651643e-06
Iter: 1041 loss: 1.96747442e-06
Iter: 1042 loss: 1.96516567e-06
Iter: 1043 loss: 1.96488372e-06
Iter: 1044 loss: 1.96517e-06
Iter: 1045 loss: 1.96471296e-06
Iter: 1046 loss: 1.96445058e-06
Iter: 1047 loss: 1.96419478e-06
Iter: 1048 loss: 1.96413134e-06
Iter: 1049 loss: 1.96392443e-06
Iter: 1050 loss: 1.96389442e-06
Iter: 1051 loss: 1.96366318e-06
Iter: 1052 loss: 1.96351266e-06
Iter: 1053 loss: 1.96345763e-06
Iter: 1054 loss: 1.96324481e-06
Iter: 1055 loss: 1.96302904e-06
Iter: 1056 loss: 1.96297287e-06
Iter: 1057 loss: 1.96275346e-06
Iter: 1058 loss: 1.96617952e-06
Iter: 1059 loss: 1.96274323e-06
Iter: 1060 loss: 1.96246901e-06
Iter: 1061 loss: 1.96260271e-06
Iter: 1062 loss: 1.96228143e-06
Iter: 1063 loss: 1.9619556e-06
Iter: 1064 loss: 1.96368956e-06
Iter: 1065 loss: 1.96190786e-06
Iter: 1066 loss: 1.96158157e-06
Iter: 1067 loss: 1.96151177e-06
Iter: 1068 loss: 1.96127644e-06
Iter: 1069 loss: 1.96091628e-06
Iter: 1070 loss: 1.96105248e-06
Iter: 1071 loss: 1.96067185e-06
Iter: 1072 loss: 1.9602578e-06
Iter: 1073 loss: 1.96207384e-06
Iter: 1074 loss: 1.96017913e-06
Iter: 1075 loss: 1.95983966e-06
Iter: 1076 loss: 1.96408291e-06
Iter: 1077 loss: 1.95987059e-06
Iter: 1078 loss: 1.95955477e-06
Iter: 1079 loss: 1.95954158e-06
Iter: 1080 loss: 1.95933217e-06
Iter: 1081 loss: 1.95898792e-06
Iter: 1082 loss: 1.9587826e-06
Iter: 1083 loss: 1.95866323e-06
Iter: 1084 loss: 1.95825692e-06
Iter: 1085 loss: 1.95824646e-06
Iter: 1086 loss: 1.9579677e-06
Iter: 1087 loss: 1.95746247e-06
Iter: 1088 loss: 1.95745952e-06
Iter: 1089 loss: 1.95700477e-06
Iter: 1090 loss: 1.95761163e-06
Iter: 1091 loss: 1.95675966e-06
Iter: 1092 loss: 1.95646453e-06
Iter: 1093 loss: 1.95644816e-06
Iter: 1094 loss: 1.95618986e-06
Iter: 1095 loss: 1.95653502e-06
Iter: 1096 loss: 1.95601865e-06
Iter: 1097 loss: 1.95580697e-06
Iter: 1098 loss: 1.95753819e-06
Iter: 1099 loss: 1.95578878e-06
Iter: 1100 loss: 1.95553821e-06
Iter: 1101 loss: 1.95501957e-06
Iter: 1102 loss: 1.9648478e-06
Iter: 1103 loss: 1.95503026e-06
Iter: 1104 loss: 1.95439088e-06
Iter: 1105 loss: 1.95490247e-06
Iter: 1106 loss: 1.954033e-06
Iter: 1107 loss: 1.95341818e-06
Iter: 1108 loss: 1.95778875e-06
Iter: 1109 loss: 1.95337316e-06
Iter: 1110 loss: 1.95297434e-06
Iter: 1111 loss: 1.9591489e-06
Iter: 1112 loss: 1.95295274e-06
Iter: 1113 loss: 1.9526376e-06
Iter: 1114 loss: 1.95251096e-06
Iter: 1115 loss: 1.95233656e-06
Iter: 1116 loss: 1.95197185e-06
Iter: 1117 loss: 1.95281245e-06
Iter: 1118 loss: 1.95186612e-06
Iter: 1119 loss: 1.95154098e-06
Iter: 1120 loss: 1.95551934e-06
Iter: 1121 loss: 1.95152097e-06
Iter: 1122 loss: 1.95133248e-06
Iter: 1123 loss: 1.95087932e-06
Iter: 1124 loss: 1.9567442e-06
Iter: 1125 loss: 1.95085363e-06
Iter: 1126 loss: 1.95025018e-06
Iter: 1127 loss: 1.95061261e-06
Iter: 1128 loss: 1.94987297e-06
Iter: 1129 loss: 1.94941731e-06
Iter: 1130 loss: 1.94940503e-06
Iter: 1131 loss: 1.94893346e-06
Iter: 1132 loss: 1.94987206e-06
Iter: 1133 loss: 1.94876975e-06
Iter: 1134 loss: 1.9484612e-06
Iter: 1135 loss: 1.94984e-06
Iter: 1136 loss: 1.94837958e-06
Iter: 1137 loss: 1.9479869e-06
Iter: 1138 loss: 1.94783138e-06
Iter: 1139 loss: 1.94760742e-06
Iter: 1140 loss: 1.94715085e-06
Iter: 1141 loss: 1.94685163e-06
Iter: 1142 loss: 1.94666609e-06
Iter: 1143 loss: 1.94589074e-06
Iter: 1144 loss: 1.94863742e-06
Iter: 1145 loss: 1.94571817e-06
Iter: 1146 loss: 1.94513518e-06
Iter: 1147 loss: 1.94512495e-06
Iter: 1148 loss: 1.94467225e-06
Iter: 1149 loss: 1.94454333e-06
Iter: 1150 loss: 1.94427798e-06
Iter: 1151 loss: 1.94377208e-06
Iter: 1152 loss: 1.94483914e-06
Iter: 1153 loss: 1.94357017e-06
Iter: 1154 loss: 1.94318523e-06
Iter: 1155 loss: 1.9432091e-06
Iter: 1156 loss: 1.94295717e-06
Iter: 1157 loss: 1.94246786e-06
Iter: 1158 loss: 1.94969584e-06
Iter: 1159 loss: 1.94242193e-06
Iter: 1160 loss: 1.94187101e-06
Iter: 1161 loss: 1.94271229e-06
Iter: 1162 loss: 1.94159361e-06
Iter: 1163 loss: 1.94104587e-06
Iter: 1164 loss: 1.94748782e-06
Iter: 1165 loss: 1.94102404e-06
Iter: 1166 loss: 1.94034988e-06
Iter: 1167 loss: 1.94008885e-06
Iter: 1168 loss: 1.93971346e-06
Iter: 1169 loss: 1.93912e-06
Iter: 1170 loss: 1.94706217e-06
Iter: 1171 loss: 1.93913047e-06
Iter: 1172 loss: 1.93858682e-06
Iter: 1173 loss: 1.93807023e-06
Iter: 1174 loss: 1.93792675e-06
Iter: 1175 loss: 1.93730602e-06
Iter: 1176 loss: 1.93747e-06
Iter: 1177 loss: 1.93687401e-06
Iter: 1178 loss: 1.93623191e-06
Iter: 1179 loss: 1.94286554e-06
Iter: 1180 loss: 1.93621463e-06
Iter: 1181 loss: 1.93577694e-06
Iter: 1182 loss: 1.94093582e-06
Iter: 1183 loss: 1.9357808e-06
Iter: 1184 loss: 1.93547612e-06
Iter: 1185 loss: 1.93500591e-06
Iter: 1186 loss: 1.93497476e-06
Iter: 1187 loss: 1.93446544e-06
Iter: 1188 loss: 1.93720621e-06
Iter: 1189 loss: 1.93434335e-06
Iter: 1190 loss: 1.93378969e-06
Iter: 1191 loss: 1.93668257e-06
Iter: 1192 loss: 1.93368442e-06
Iter: 1193 loss: 1.93331971e-06
Iter: 1194 loss: 1.93262917e-06
Iter: 1195 loss: 1.94794893e-06
Iter: 1196 loss: 1.93261258e-06
Iter: 1197 loss: 1.93190635e-06
Iter: 1198 loss: 1.93523397e-06
Iter: 1199 loss: 1.93175038e-06
Iter: 1200 loss: 1.9312115e-06
Iter: 1201 loss: 1.93988217e-06
Iter: 1202 loss: 1.93119877e-06
Iter: 1203 loss: 1.93071742e-06
Iter: 1204 loss: 1.93003689e-06
Iter: 1205 loss: 1.9299855e-06
Iter: 1206 loss: 1.92948096e-06
Iter: 1207 loss: 1.92943276e-06
Iter: 1208 loss: 1.92907828e-06
Iter: 1209 loss: 1.92816e-06
Iter: 1210 loss: 1.93661162e-06
Iter: 1211 loss: 1.92799621e-06
Iter: 1212 loss: 1.92703624e-06
Iter: 1213 loss: 1.93086021e-06
Iter: 1214 loss: 1.92683501e-06
Iter: 1215 loss: 1.92628681e-06
Iter: 1216 loss: 1.92626521e-06
Iter: 1217 loss: 1.9257418e-06
Iter: 1218 loss: 1.92636e-06
Iter: 1219 loss: 1.92545122e-06
Iter: 1220 loss: 1.92493462e-06
Iter: 1221 loss: 1.92507105e-06
Iter: 1222 loss: 1.92458674e-06
Iter: 1223 loss: 1.92412858e-06
Iter: 1224 loss: 1.9241445e-06
Iter: 1225 loss: 1.9237491e-06
Iter: 1226 loss: 1.92332482e-06
Iter: 1227 loss: 1.92327707e-06
Iter: 1228 loss: 1.92261e-06
Iter: 1229 loss: 1.92218477e-06
Iter: 1230 loss: 1.92194216e-06
Iter: 1231 loss: 1.92125481e-06
Iter: 1232 loss: 1.92123753e-06
Iter: 1233 loss: 1.92059315e-06
Iter: 1234 loss: 1.92189123e-06
Iter: 1235 loss: 1.92032917e-06
Iter: 1236 loss: 1.91974414e-06
Iter: 1237 loss: 1.92086054e-06
Iter: 1238 loss: 1.91948811e-06
Iter: 1239 loss: 1.91859658e-06
Iter: 1240 loss: 1.92034076e-06
Iter: 1241 loss: 1.91823483e-06
Iter: 1242 loss: 1.91763638e-06
Iter: 1243 loss: 1.91671825e-06
Iter: 1244 loss: 1.91673485e-06
Iter: 1245 loss: 1.91565096e-06
Iter: 1246 loss: 1.92307448e-06
Iter: 1247 loss: 1.91555e-06
Iter: 1248 loss: 1.9149345e-06
Iter: 1249 loss: 1.91491176e-06
Iter: 1250 loss: 1.91452273e-06
Iter: 1251 loss: 1.91383378e-06
Iter: 1252 loss: 1.91383424e-06
Iter: 1253 loss: 1.9130805e-06
Iter: 1254 loss: 1.91660365e-06
Iter: 1255 loss: 1.91291792e-06
Iter: 1256 loss: 1.91221761e-06
Iter: 1257 loss: 1.91822301e-06
Iter: 1258 loss: 1.91217987e-06
Iter: 1259 loss: 1.91175286e-06
Iter: 1260 loss: 1.9112988e-06
Iter: 1261 loss: 1.91122808e-06
Iter: 1262 loss: 1.91061645e-06
Iter: 1263 loss: 1.91216236e-06
Iter: 1264 loss: 1.91041227e-06
Iter: 1265 loss: 1.90974606e-06
Iter: 1266 loss: 1.9159927e-06
Iter: 1267 loss: 1.90970786e-06
Iter: 1268 loss: 1.90921287e-06
Iter: 1269 loss: 1.90879518e-06
Iter: 1270 loss: 1.90864193e-06
Iter: 1271 loss: 1.90797437e-06
Iter: 1272 loss: 1.90798301e-06
Iter: 1273 loss: 1.90751575e-06
Iter: 1274 loss: 1.90649826e-06
Iter: 1275 loss: 1.92355628e-06
Iter: 1276 loss: 1.90647711e-06
Iter: 1277 loss: 1.90562048e-06
Iter: 1278 loss: 1.90761375e-06
Iter: 1279 loss: 1.90531966e-06
Iter: 1280 loss: 1.90480341e-06
Iter: 1281 loss: 1.90476612e-06
Iter: 1282 loss: 1.90422361e-06
Iter: 1283 loss: 1.90441438e-06
Iter: 1284 loss: 1.90385174e-06
Iter: 1285 loss: 1.9032866e-06
Iter: 1286 loss: 1.9032268e-06
Iter: 1287 loss: 1.90283527e-06
Iter: 1288 loss: 1.90218702e-06
Iter: 1289 loss: 1.91233767e-06
Iter: 1290 loss: 1.90218702e-06
Iter: 1291 loss: 1.90165565e-06
Iter: 1292 loss: 1.90147114e-06
Iter: 1293 loss: 1.90115543e-06
Iter: 1294 loss: 1.90060712e-06
Iter: 1295 loss: 1.90124342e-06
Iter: 1296 loss: 1.90029562e-06
Iter: 1297 loss: 1.8997971e-06
Iter: 1298 loss: 1.90712308e-06
Iter: 1299 loss: 1.89979664e-06
Iter: 1300 loss: 1.89935758e-06
Iter: 1301 loss: 1.89918489e-06
Iter: 1302 loss: 1.89892967e-06
Iter: 1303 loss: 1.89844422e-06
Iter: 1304 loss: 1.90297055e-06
Iter: 1305 loss: 1.89843149e-06
Iter: 1306 loss: 1.8978518e-06
Iter: 1307 loss: 1.8973825e-06
Iter: 1308 loss: 1.89722164e-06
Iter: 1309 loss: 1.89637092e-06
Iter: 1310 loss: 1.89526008e-06
Iter: 1311 loss: 1.89517687e-06
Iter: 1312 loss: 1.89404341e-06
Iter: 1313 loss: 1.91023241e-06
Iter: 1314 loss: 1.8940375e-06
Iter: 1315 loss: 1.89306797e-06
Iter: 1316 loss: 1.90151854e-06
Iter: 1317 loss: 1.89304137e-06
Iter: 1318 loss: 1.89248112e-06
Iter: 1319 loss: 1.89206162e-06
Iter: 1320 loss: 1.89190507e-06
Iter: 1321 loss: 1.89131219e-06
Iter: 1322 loss: 1.89695152e-06
Iter: 1323 loss: 1.89130674e-06
Iter: 1324 loss: 1.89068214e-06
Iter: 1325 loss: 1.89189859e-06
Iter: 1326 loss: 1.89042851e-06
Iter: 1327 loss: 1.88992203e-06
Iter: 1328 loss: 1.88963168e-06
Iter: 1329 loss: 1.88940589e-06
Iter: 1330 loss: 1.88871104e-06
Iter: 1331 loss: 1.89328148e-06
Iter: 1332 loss: 1.8886509e-06
Iter: 1333 loss: 1.8878859e-06
Iter: 1334 loss: 1.88881643e-06
Iter: 1335 loss: 1.88747742e-06
Iter: 1336 loss: 1.88667809e-06
Iter: 1337 loss: 1.88783713e-06
Iter: 1338 loss: 1.88625324e-06
Iter: 1339 loss: 1.88532476e-06
Iter: 1340 loss: 1.89448212e-06
Iter: 1341 loss: 1.88529793e-06
Iter: 1342 loss: 1.88481863e-06
Iter: 1343 loss: 1.8838557e-06
Iter: 1344 loss: 1.90118135e-06
Iter: 1345 loss: 1.88381273e-06
Iter: 1346 loss: 1.88269109e-06
Iter: 1347 loss: 1.88554554e-06
Iter: 1348 loss: 1.88231866e-06
Iter: 1349 loss: 1.88197225e-06
Iter: 1350 loss: 1.88172908e-06
Iter: 1351 loss: 1.88130412e-06
Iter: 1352 loss: 1.88058175e-06
Iter: 1353 loss: 1.89826596e-06
Iter: 1354 loss: 1.88057857e-06
Iter: 1355 loss: 1.8796718e-06
Iter: 1356 loss: 1.88127319e-06
Iter: 1357 loss: 1.87930209e-06
Iter: 1358 loss: 1.87850594e-06
Iter: 1359 loss: 1.87849059e-06
Iter: 1360 loss: 1.8780139e-06
Iter: 1361 loss: 1.87735236e-06
Iter: 1362 loss: 1.87733588e-06
Iter: 1363 loss: 1.87655291e-06
Iter: 1364 loss: 1.87927367e-06
Iter: 1365 loss: 1.87633782e-06
Iter: 1366 loss: 1.87561318e-06
Iter: 1367 loss: 1.8821022e-06
Iter: 1368 loss: 1.87557862e-06
Iter: 1369 loss: 1.87504656e-06
Iter: 1370 loss: 1.87457181e-06
Iter: 1371 loss: 1.87442674e-06
Iter: 1372 loss: 1.87383887e-06
Iter: 1373 loss: 1.87384035e-06
Iter: 1374 loss: 1.87337673e-06
Iter: 1375 loss: 1.87224009e-06
Iter: 1376 loss: 1.8862313e-06
Iter: 1377 loss: 1.8721521e-06
Iter: 1378 loss: 1.87080889e-06
Iter: 1379 loss: 1.872761e-06
Iter: 1380 loss: 1.870186e-06
Iter: 1381 loss: 1.86956345e-06
Iter: 1382 loss: 1.86942066e-06
Iter: 1383 loss: 1.86868715e-06
Iter: 1384 loss: 1.86876696e-06
Iter: 1385 loss: 1.86808984e-06
Iter: 1386 loss: 1.86740101e-06
Iter: 1387 loss: 1.8681535e-06
Iter: 1388 loss: 1.8670579e-06
Iter: 1389 loss: 1.8665487e-06
Iter: 1390 loss: 1.86651801e-06
Iter: 1391 loss: 1.86608554e-06
Iter: 1392 loss: 1.86583736e-06
Iter: 1393 loss: 1.86561647e-06
Iter: 1394 loss: 1.86505019e-06
Iter: 1395 loss: 1.86541e-06
Iter: 1396 loss: 1.86467707e-06
Iter: 1397 loss: 1.86397233e-06
Iter: 1398 loss: 1.87143223e-06
Iter: 1399 loss: 1.86397824e-06
Iter: 1400 loss: 1.86334853e-06
Iter: 1401 loss: 1.86278476e-06
Iter: 1402 loss: 1.86262503e-06
Iter: 1403 loss: 1.86201123e-06
Iter: 1404 loss: 1.87130399e-06
Iter: 1405 loss: 1.86199975e-06
Iter: 1406 loss: 1.86134298e-06
Iter: 1407 loss: 1.86115653e-06
Iter: 1408 loss: 1.86074431e-06
Iter: 1409 loss: 1.86007412e-06
Iter: 1410 loss: 1.85971658e-06
Iter: 1411 loss: 1.85942213e-06
Iter: 1412 loss: 1.85845101e-06
Iter: 1413 loss: 1.86363411e-06
Iter: 1414 loss: 1.85833153e-06
Iter: 1415 loss: 1.85734814e-06
Iter: 1416 loss: 1.86598049e-06
Iter: 1417 loss: 1.85729959e-06
Iter: 1418 loss: 1.85673161e-06
Iter: 1419 loss: 1.85586623e-06
Iter: 1420 loss: 1.85586259e-06
Iter: 1421 loss: 1.85496742e-06
Iter: 1422 loss: 1.86431748e-06
Iter: 1423 loss: 1.85493991e-06
Iter: 1424 loss: 1.85413012e-06
Iter: 1425 loss: 1.85709553e-06
Iter: 1426 loss: 1.85390138e-06
Iter: 1427 loss: 1.85336751e-06
Iter: 1428 loss: 1.85325052e-06
Iter: 1429 loss: 1.8529247e-06
Iter: 1430 loss: 1.85240606e-06
Iter: 1431 loss: 1.85933641e-06
Iter: 1432 loss: 1.85240197e-06
Iter: 1433 loss: 1.85196893e-06
Iter: 1434 loss: 1.85226349e-06
Iter: 1435 loss: 1.85167119e-06
Iter: 1436 loss: 1.85125464e-06
Iter: 1437 loss: 1.85176395e-06
Iter: 1438 loss: 1.85102544e-06
Iter: 1439 loss: 1.8503988e-06
Iter: 1440 loss: 1.85492752e-06
Iter: 1441 loss: 1.8503581e-06
Iter: 1442 loss: 1.85000897e-06
Iter: 1443 loss: 1.84926671e-06
Iter: 1444 loss: 1.86187208e-06
Iter: 1445 loss: 1.8492301e-06
Iter: 1446 loss: 1.84847e-06
Iter: 1447 loss: 1.85156364e-06
Iter: 1448 loss: 1.84826808e-06
Iter: 1449 loss: 1.84779901e-06
Iter: 1450 loss: 1.84778219e-06
Iter: 1451 loss: 1.84735427e-06
Iter: 1452 loss: 1.84652e-06
Iter: 1453 loss: 1.86174793e-06
Iter: 1454 loss: 1.84651435e-06
Iter: 1455 loss: 1.84581404e-06
Iter: 1456 loss: 1.85074566e-06
Iter: 1457 loss: 1.84575856e-06
Iter: 1458 loss: 1.84519558e-06
Iter: 1459 loss: 1.85094018e-06
Iter: 1460 loss: 1.84520059e-06
Iter: 1461 loss: 1.8448e-06
Iter: 1462 loss: 1.84438682e-06
Iter: 1463 loss: 1.84431394e-06
Iter: 1464 loss: 1.84384885e-06
Iter: 1465 loss: 1.84709279e-06
Iter: 1466 loss: 1.84378712e-06
Iter: 1467 loss: 1.84332646e-06
Iter: 1468 loss: 1.84526243e-06
Iter: 1469 loss: 1.84320345e-06
Iter: 1470 loss: 1.84287887e-06
Iter: 1471 loss: 1.84278338e-06
Iter: 1472 loss: 1.84257692e-06
Iter: 1473 loss: 1.84231556e-06
Iter: 1474 loss: 1.84227451e-06
Iter: 1475 loss: 1.84204828e-06
Iter: 1476 loss: 1.84143119e-06
Iter: 1477 loss: 1.84602197e-06
Iter: 1478 loss: 1.8413059e-06
Iter: 1479 loss: 1.84050521e-06
Iter: 1480 loss: 1.84204907e-06
Iter: 1481 loss: 1.84020075e-06
Iter: 1482 loss: 1.83972122e-06
Iter: 1483 loss: 1.83967268e-06
Iter: 1484 loss: 1.83916745e-06
Iter: 1485 loss: 1.8387442e-06
Iter: 1486 loss: 1.83857696e-06
Iter: 1487 loss: 1.83795396e-06
Iter: 1488 loss: 1.83858231e-06
Iter: 1489 loss: 1.83764143e-06
Iter: 1490 loss: 1.83724035e-06
Iter: 1491 loss: 1.83721909e-06
Iter: 1492 loss: 1.83687735e-06
Iter: 1493 loss: 1.83658062e-06
Iter: 1494 loss: 1.8365115e-06
Iter: 1495 loss: 1.83601082e-06
Iter: 1496 loss: 1.83691168e-06
Iter: 1497 loss: 1.83580687e-06
Iter: 1498 loss: 1.83536565e-06
Iter: 1499 loss: 1.84177361e-06
Iter: 1500 loss: 1.83535781e-06
Iter: 1501 loss: 1.8350853e-06
Iter: 1502 loss: 1.83468387e-06
Iter: 1503 loss: 1.83466545e-06
Iter: 1504 loss: 1.83429779e-06
Iter: 1505 loss: 1.83972929e-06
Iter: 1506 loss: 1.83430916e-06
Iter: 1507 loss: 1.83392535e-06
Iter: 1508 loss: 1.83392615e-06
Iter: 1509 loss: 1.83362795e-06
Iter: 1510 loss: 1.83335055e-06
Iter: 1511 loss: 1.83330849e-06
Iter: 1512 loss: 1.83312011e-06
Iter: 1513 loss: 1.83278348e-06
Iter: 1514 loss: 1.83608313e-06
Iter: 1515 loss: 1.83277575e-06
Iter: 1516 loss: 1.83240888e-06
Iter: 1517 loss: 1.83305508e-06
Iter: 1518 loss: 1.83222937e-06
Iter: 1519 loss: 1.83188399e-06
Iter: 1520 loss: 1.83136888e-06
Iter: 1521 loss: 1.83135762e-06
Iter: 1522 loss: 1.83090754e-06
Iter: 1523 loss: 1.8308865e-06
Iter: 1524 loss: 1.83042812e-06
Iter: 1525 loss: 1.83069187e-06
Iter: 1526 loss: 1.83013469e-06
Iter: 1527 loss: 1.82969688e-06
Iter: 1528 loss: 1.83032068e-06
Iter: 1529 loss: 1.82945314e-06
Iter: 1530 loss: 1.8291496e-06
Iter: 1531 loss: 1.82914914e-06
Iter: 1532 loss: 1.82892722e-06
Iter: 1533 loss: 1.82878853e-06
Iter: 1534 loss: 1.82870019e-06
Iter: 1535 loss: 1.82840756e-06
Iter: 1536 loss: 1.82954625e-06
Iter: 1537 loss: 1.82832252e-06
Iter: 1538 loss: 1.828e-06
Iter: 1539 loss: 1.82903887e-06
Iter: 1540 loss: 1.82788153e-06
Iter: 1541 loss: 1.82761016e-06
Iter: 1542 loss: 1.82717031e-06
Iter: 1543 loss: 1.82717235e-06
Iter: 1544 loss: 1.82667873e-06
Iter: 1545 loss: 1.82982922e-06
Iter: 1546 loss: 1.82665258e-06
Iter: 1547 loss: 1.82624092e-06
Iter: 1548 loss: 1.8312694e-06
Iter: 1549 loss: 1.82624103e-06
Iter: 1550 loss: 1.82601275e-06
Iter: 1551 loss: 1.82562349e-06
Iter: 1552 loss: 1.82563087e-06
Iter: 1553 loss: 1.82522854e-06
Iter: 1554 loss: 1.82735766e-06
Iter: 1555 loss: 1.8251751e-06
Iter: 1556 loss: 1.82468386e-06
Iter: 1557 loss: 1.82649137e-06
Iter: 1558 loss: 1.82456108e-06
Iter: 1559 loss: 1.82418171e-06
Iter: 1560 loss: 1.82397162e-06
Iter: 1561 loss: 1.82378972e-06
Iter: 1562 loss: 1.82325766e-06
Iter: 1563 loss: 1.82755e-06
Iter: 1564 loss: 1.82323515e-06
Iter: 1565 loss: 1.82274016e-06
Iter: 1566 loss: 1.82308338e-06
Iter: 1567 loss: 1.82237955e-06
Iter: 1568 loss: 1.82193025e-06
Iter: 1569 loss: 1.8228003e-06
Iter: 1570 loss: 1.82171607e-06
Iter: 1571 loss: 1.82130668e-06
Iter: 1572 loss: 1.8212977e-06
Iter: 1573 loss: 1.8210751e-06
Iter: 1574 loss: 1.82064946e-06
Iter: 1575 loss: 1.82863732e-06
Iter: 1576 loss: 1.82062854e-06
Iter: 1577 loss: 1.82014742e-06
Iter: 1578 loss: 1.82190774e-06
Iter: 1579 loss: 1.82006283e-06
Iter: 1580 loss: 1.81978385e-06
Iter: 1581 loss: 1.81976748e-06
Iter: 1582 loss: 1.81952907e-06
Iter: 1583 loss: 1.81907149e-06
Iter: 1584 loss: 1.82636472e-06
Iter: 1585 loss: 1.81904227e-06
Iter: 1586 loss: 1.81849259e-06
Iter: 1587 loss: 1.81992118e-06
Iter: 1588 loss: 1.81832866e-06
Iter: 1589 loss: 1.81783901e-06
Iter: 1590 loss: 1.81785435e-06
Iter: 1591 loss: 1.81748851e-06
Iter: 1592 loss: 1.81697726e-06
Iter: 1593 loss: 1.81696601e-06
Iter: 1594 loss: 1.81635414e-06
Iter: 1595 loss: 1.82044619e-06
Iter: 1596 loss: 1.81628161e-06
Iter: 1597 loss: 1.81571772e-06
Iter: 1598 loss: 1.81782434e-06
Iter: 1599 loss: 1.81553344e-06
Iter: 1600 loss: 1.81515429e-06
Iter: 1601 loss: 1.81498342e-06
Iter: 1602 loss: 1.81476082e-06
Iter: 1603 loss: 1.81440896e-06
Iter: 1604 loss: 1.81439236e-06
Iter: 1605 loss: 1.81413577e-06
Iter: 1606 loss: 1.81365976e-06
Iter: 1607 loss: 1.81365408e-06
Iter: 1608 loss: 1.8132024e-06
Iter: 1609 loss: 1.81386065e-06
Iter: 1610 loss: 1.81300379e-06
Iter: 1611 loss: 1.81277528e-06
Iter: 1612 loss: 1.81271639e-06
Iter: 1613 loss: 1.81248367e-06
Iter: 1614 loss: 1.81204769e-06
Iter: 1615 loss: 1.81204916e-06
Iter: 1616 loss: 1.81165933e-06
Iter: 1617 loss: 1.81207656e-06
Iter: 1618 loss: 1.81143116e-06
Iter: 1619 loss: 1.81109635e-06
Iter: 1620 loss: 1.81109681e-06
Iter: 1621 loss: 1.81077462e-06
Iter: 1622 loss: 1.81026178e-06
Iter: 1623 loss: 1.81024416e-06
Iter: 1624 loss: 1.80971688e-06
Iter: 1625 loss: 1.81305688e-06
Iter: 1626 loss: 1.80965401e-06
Iter: 1627 loss: 1.80916277e-06
Iter: 1628 loss: 1.8116441e-06
Iter: 1629 loss: 1.80910229e-06
Iter: 1630 loss: 1.80868119e-06
Iter: 1631 loss: 1.80827124e-06
Iter: 1632 loss: 1.80820962e-06
Iter: 1633 loss: 1.80789061e-06
Iter: 1634 loss: 1.80785287e-06
Iter: 1635 loss: 1.80752829e-06
Iter: 1636 loss: 1.80716836e-06
Iter: 1637 loss: 1.80712379e-06
Iter: 1638 loss: 1.80667939e-06
Iter: 1639 loss: 1.80673578e-06
Iter: 1640 loss: 1.80634106e-06
Iter: 1641 loss: 1.80606321e-06
Iter: 1642 loss: 1.80600182e-06
Iter: 1643 loss: 1.80569214e-06
Iter: 1644 loss: 1.80576149e-06
Iter: 1645 loss: 1.80543327e-06
Iter: 1646 loss: 1.80513916e-06
Iter: 1647 loss: 1.80517088e-06
Iter: 1648 loss: 1.80490019e-06
Iter: 1649 loss: 1.80469351e-06
Iter: 1650 loss: 1.80469715e-06
Iter: 1651 loss: 1.80444715e-06
Iter: 1652 loss: 1.80439042e-06
Iter: 1653 loss: 1.80423683e-06
Iter: 1654 loss: 1.80398365e-06
Iter: 1655 loss: 1.80421057e-06
Iter: 1656 loss: 1.80379016e-06
Iter: 1657 loss: 1.80341578e-06
Iter: 1658 loss: 1.8059601e-06
Iter: 1659 loss: 1.80336838e-06
Iter: 1660 loss: 1.80296615e-06
Iter: 1661 loss: 1.80239579e-06
Iter: 1662 loss: 1.8024142e-06
Iter: 1663 loss: 1.80186873e-06
Iter: 1664 loss: 1.80970221e-06
Iter: 1665 loss: 1.80187112e-06
Iter: 1666 loss: 1.80143172e-06
Iter: 1667 loss: 1.80269535e-06
Iter: 1668 loss: 1.80129086e-06
Iter: 1669 loss: 1.80106099e-06
Iter: 1670 loss: 1.80080212e-06
Iter: 1671 loss: 1.80078951e-06
Iter: 1672 loss: 1.80049074e-06
Iter: 1673 loss: 1.80425081e-06
Iter: 1674 loss: 1.80049767e-06
Iter: 1675 loss: 1.80023721e-06
Iter: 1676 loss: 1.80158372e-06
Iter: 1677 loss: 1.80018833e-06
Iter: 1678 loss: 1.80005759e-06
Iter: 1679 loss: 1.7997329e-06
Iter: 1680 loss: 1.80459938e-06
Iter: 1681 loss: 1.7997387e-06
Iter: 1682 loss: 1.7994189e-06
Iter: 1683 loss: 1.80322354e-06
Iter: 1684 loss: 1.79941935e-06
Iter: 1685 loss: 1.7991357e-06
Iter: 1686 loss: 1.80027496e-06
Iter: 1687 loss: 1.7990651e-06
Iter: 1688 loss: 1.79890822e-06
Iter: 1689 loss: 1.79877532e-06
Iter: 1690 loss: 1.79869915e-06
Iter: 1691 loss: 1.79844687e-06
Iter: 1692 loss: 1.80133122e-06
Iter: 1693 loss: 1.79845119e-06
Iter: 1694 loss: 1.79823235e-06
Iter: 1695 loss: 1.79803374e-06
Iter: 1696 loss: 1.79797712e-06
Iter: 1697 loss: 1.79768563e-06
Iter: 1698 loss: 1.79863707e-06
Iter: 1699 loss: 1.79758808e-06
Iter: 1700 loss: 1.79722599e-06
Iter: 1701 loss: 1.79942958e-06
Iter: 1702 loss: 1.7971845e-06
Iter: 1703 loss: 1.7969611e-06
Iter: 1704 loss: 1.79646804e-06
Iter: 1705 loss: 1.80569407e-06
Iter: 1706 loss: 1.79648919e-06
Iter: 1707 loss: 1.79608242e-06
Iter: 1708 loss: 1.80039547e-06
Iter: 1709 loss: 1.79607878e-06
Iter: 1710 loss: 1.79582753e-06
Iter: 1711 loss: 1.79583958e-06
Iter: 1712 loss: 1.79569133e-06
Iter: 1713 loss: 1.79537653e-06
Iter: 1714 loss: 1.79907749e-06
Iter: 1715 loss: 1.79536119e-06
Iter: 1716 loss: 1.79506776e-06
Iter: 1717 loss: 1.7975517e-06
Iter: 1718 loss: 1.79504809e-06
Iter: 1719 loss: 1.79480674e-06
Iter: 1720 loss: 1.79695598e-06
Iter: 1721 loss: 1.79480389e-06
Iter: 1722 loss: 1.7946013e-06
Iter: 1723 loss: 1.79430208e-06
Iter: 1724 loss: 1.79429912e-06
Iter: 1725 loss: 1.7940381e-06
Iter: 1726 loss: 1.79839196e-06
Iter: 1727 loss: 1.79403855e-06
Iter: 1728 loss: 1.79379833e-06
Iter: 1729 loss: 1.7938778e-06
Iter: 1730 loss: 1.793622e-06
Iter: 1731 loss: 1.7933545e-06
Iter: 1732 loss: 1.79348763e-06
Iter: 1733 loss: 1.79317794e-06
Iter: 1734 loss: 1.79294398e-06
Iter: 1735 loss: 1.79293477e-06
Iter: 1736 loss: 1.79275935e-06
Iter: 1737 loss: 1.79240135e-06
Iter: 1738 loss: 1.79778044e-06
Iter: 1739 loss: 1.79236895e-06
Iter: 1740 loss: 1.7920363e-06
Iter: 1741 loss: 1.79322569e-06
Iter: 1742 loss: 1.79192011e-06
Iter: 1743 loss: 1.79168455e-06
Iter: 1744 loss: 1.79165465e-06
Iter: 1745 loss: 1.79148219e-06
Iter: 1746 loss: 1.7911575e-06
Iter: 1747 loss: 1.79847393e-06
Iter: 1748 loss: 1.79115568e-06
Iter: 1749 loss: 1.79083963e-06
Iter: 1750 loss: 1.79155e-06
Iter: 1751 loss: 1.79074073e-06
Iter: 1752 loss: 1.79046765e-06
Iter: 1753 loss: 1.79045844e-06
Iter: 1754 loss: 1.79030349e-06
Iter: 1755 loss: 1.79003109e-06
Iter: 1756 loss: 1.79003439e-06
Iter: 1757 loss: 1.78979985e-06
Iter: 1758 loss: 1.79178971e-06
Iter: 1759 loss: 1.78977484e-06
Iter: 1760 loss: 1.78951097e-06
Iter: 1761 loss: 1.79005167e-06
Iter: 1762 loss: 1.78942946e-06
Iter: 1763 loss: 1.78916184e-06
Iter: 1764 loss: 1.78909e-06
Iter: 1765 loss: 1.7889613e-06
Iter: 1766 loss: 1.7887794e-06
Iter: 1767 loss: 1.78876087e-06
Iter: 1768 loss: 1.78857829e-06
Iter: 1769 loss: 1.78824075e-06
Iter: 1770 loss: 1.78823734e-06
Iter: 1771 loss: 1.7879147e-06
Iter: 1772 loss: 1.78818368e-06
Iter: 1773 loss: 1.78774098e-06
Iter: 1774 loss: 1.78752339e-06
Iter: 1775 loss: 1.78749656e-06
Iter: 1776 loss: 1.78726918e-06
Iter: 1777 loss: 1.78699065e-06
Iter: 1778 loss: 1.78695154e-06
Iter: 1779 loss: 1.7866023e-06
Iter: 1780 loss: 1.78642006e-06
Iter: 1781 loss: 1.78625089e-06
Iter: 1782 loss: 1.78612447e-06
Iter: 1783 loss: 1.78599316e-06
Iter: 1784 loss: 1.78579739e-06
Iter: 1785 loss: 1.78556866e-06
Iter: 1786 loss: 1.78552853e-06
Iter: 1787 loss: 1.78524624e-06
Iter: 1788 loss: 1.78607866e-06
Iter: 1789 loss: 1.78520929e-06
Iter: 1790 loss: 1.78492189e-06
Iter: 1791 loss: 1.78727203e-06
Iter: 1792 loss: 1.78489518e-06
Iter: 1793 loss: 1.78472521e-06
Iter: 1794 loss: 1.78454479e-06
Iter: 1795 loss: 1.78450773e-06
Iter: 1796 loss: 1.78428172e-06
Iter: 1797 loss: 1.78635037e-06
Iter: 1798 loss: 1.78427035e-06
Iter: 1799 loss: 1.78400023e-06
Iter: 1800 loss: 1.78411426e-06
Iter: 1801 loss: 1.78381401e-06
Iter: 1802 loss: 1.7835273e-06
Iter: 1803 loss: 1.78325536e-06
Iter: 1804 loss: 1.78318396e-06
Iter: 1805 loss: 1.78297682e-06
Iter: 1806 loss: 1.78294852e-06
Iter: 1807 loss: 1.78271421e-06
Iter: 1808 loss: 1.78287075e-06
Iter: 1809 loss: 1.78257801e-06
Iter: 1810 loss: 1.78233313e-06
Iter: 1811 loss: 1.78211621e-06
Iter: 1812 loss: 1.78209712e-06
Iter: 1813 loss: 1.78187827e-06
Iter: 1814 loss: 1.78187258e-06
Iter: 1815 loss: 1.7816501e-06
Iter: 1816 loss: 1.78168841e-06
Iter: 1817 loss: 1.7814873e-06
Iter: 1818 loss: 1.78120899e-06
Iter: 1819 loss: 1.78116284e-06
Iter: 1820 loss: 1.78098276e-06
Iter: 1821 loss: 1.7806633e-06
Iter: 1822 loss: 1.78068012e-06
Iter: 1823 loss: 1.7804357e-06
Iter: 1824 loss: 1.78021878e-06
Iter: 1825 loss: 1.78013795e-06
Iter: 1826 loss: 1.77985089e-06
Iter: 1827 loss: 1.78093842e-06
Iter: 1828 loss: 1.77978382e-06
Iter: 1829 loss: 1.77947607e-06
Iter: 1830 loss: 1.78244545e-06
Iter: 1831 loss: 1.77946799e-06
Iter: 1832 loss: 1.77931884e-06
Iter: 1833 loss: 1.7789921e-06
Iter: 1834 loss: 1.78550454e-06
Iter: 1835 loss: 1.77900097e-06
Iter: 1836 loss: 1.77870129e-06
Iter: 1837 loss: 1.78078426e-06
Iter: 1838 loss: 1.77868128e-06
Iter: 1839 loss: 1.77832317e-06
Iter: 1840 loss: 1.77985487e-06
Iter: 1841 loss: 1.77827019e-06
Iter: 1842 loss: 1.77804156e-06
Iter: 1843 loss: 1.77768857e-06
Iter: 1844 loss: 1.77768698e-06
Iter: 1845 loss: 1.77734796e-06
Iter: 1846 loss: 1.77944e-06
Iter: 1847 loss: 1.77730476e-06
Iter: 1848 loss: 1.77700747e-06
Iter: 1849 loss: 1.78053801e-06
Iter: 1850 loss: 1.77700292e-06
Iter: 1851 loss: 1.77683569e-06
Iter: 1852 loss: 1.77663037e-06
Iter: 1853 loss: 1.77661809e-06
Iter: 1854 loss: 1.77638242e-06
Iter: 1855 loss: 1.77976017e-06
Iter: 1856 loss: 1.77638617e-06
Iter: 1857 loss: 1.77619063e-06
Iter: 1858 loss: 1.77617812e-06
Iter: 1859 loss: 1.77602135e-06
Iter: 1860 loss: 1.77574975e-06
Iter: 1861 loss: 1.77550646e-06
Iter: 1862 loss: 1.77544052e-06
Iter: 1863 loss: 1.77514289e-06
Iter: 1864 loss: 1.77513402e-06
Iter: 1865 loss: 1.77489096e-06
Iter: 1866 loss: 1.77446373e-06
Iter: 1867 loss: 1.77447691e-06
Iter: 1868 loss: 1.77413187e-06
Iter: 1869 loss: 1.77532365e-06
Iter: 1870 loss: 1.77404604e-06
Iter: 1871 loss: 1.77380934e-06
Iter: 1872 loss: 1.77379206e-06
Iter: 1873 loss: 1.77365064e-06
Iter: 1874 loss: 1.77340485e-06
Iter: 1875 loss: 1.77921743e-06
Iter: 1876 loss: 1.7733845e-06
Iter: 1877 loss: 1.77312904e-06
Iter: 1878 loss: 1.77325501e-06
Iter: 1879 loss: 1.77292156e-06
Iter: 1880 loss: 1.7727491e-06
Iter: 1881 loss: 1.7727e-06
Iter: 1882 loss: 1.77254174e-06
Iter: 1883 loss: 1.77218249e-06
Iter: 1884 loss: 1.77854758e-06
Iter: 1885 loss: 1.77215986e-06
Iter: 1886 loss: 1.77182289e-06
Iter: 1887 loss: 1.77496759e-06
Iter: 1888 loss: 1.77182881e-06
Iter: 1889 loss: 1.77152936e-06
Iter: 1890 loss: 1.77244419e-06
Iter: 1891 loss: 1.77142e-06
Iter: 1892 loss: 1.77114782e-06
Iter: 1893 loss: 1.7708785e-06
Iter: 1894 loss: 1.77082347e-06
Iter: 1895 loss: 1.77050219e-06
Iter: 1896 loss: 1.77052425e-06
Iter: 1897 loss: 1.77019183e-06
Iter: 1898 loss: 1.77001493e-06
Iter: 1899 loss: 1.76987396e-06
Iter: 1900 loss: 1.76954302e-06
Iter: 1901 loss: 1.76964022e-06
Iter: 1902 loss: 1.76928233e-06
Iter: 1903 loss: 1.76909771e-06
Iter: 1904 loss: 1.76904246e-06
Iter: 1905 loss: 1.76883782e-06
Iter: 1906 loss: 1.76852336e-06
Iter: 1907 loss: 1.76851199e-06
Iter: 1908 loss: 1.76820936e-06
Iter: 1909 loss: 1.76846743e-06
Iter: 1910 loss: 1.76804485e-06
Iter: 1911 loss: 1.76778985e-06
Iter: 1912 loss: 1.76780782e-06
Iter: 1913 loss: 1.76754702e-06
Iter: 1914 loss: 1.76735534e-06
Iter: 1915 loss: 1.76724507e-06
Iter: 1916 loss: 1.76694698e-06
Iter: 1917 loss: 1.76744061e-06
Iter: 1918 loss: 1.76679964e-06
Iter: 1919 loss: 1.76647848e-06
Iter: 1920 loss: 1.77039806e-06
Iter: 1921 loss: 1.76647973e-06
Iter: 1922 loss: 1.76623439e-06
Iter: 1923 loss: 1.7659886e-06
Iter: 1924 loss: 1.76596291e-06
Iter: 1925 loss: 1.76565152e-06
Iter: 1926 loss: 1.76718561e-06
Iter: 1927 loss: 1.76559661e-06
Iter: 1928 loss: 1.7653017e-06
Iter: 1929 loss: 1.76761216e-06
Iter: 1930 loss: 1.76527772e-06
Iter: 1931 loss: 1.76509411e-06
Iter: 1932 loss: 1.76467609e-06
Iter: 1933 loss: 1.77026925e-06
Iter: 1934 loss: 1.76464596e-06
Iter: 1935 loss: 1.76424055e-06
Iter: 1936 loss: 1.76942592e-06
Iter: 1937 loss: 1.76423305e-06
Iter: 1938 loss: 1.76381104e-06
Iter: 1939 loss: 1.76474873e-06
Iter: 1940 loss: 1.76362641e-06
Iter: 1941 loss: 1.76332799e-06
Iter: 1942 loss: 1.76298261e-06
Iter: 1943 loss: 1.762956e-06
Iter: 1944 loss: 1.76253729e-06
Iter: 1945 loss: 1.76566539e-06
Iter: 1946 loss: 1.76251069e-06
Iter: 1947 loss: 1.76221624e-06
Iter: 1948 loss: 1.76222375e-06
Iter: 1949 loss: 1.76209096e-06
Iter: 1950 loss: 1.76182743e-06
Iter: 1951 loss: 1.76639492e-06
Iter: 1952 loss: 1.76181959e-06
Iter: 1953 loss: 1.76159438e-06
Iter: 1954 loss: 1.7615763e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2
+ date
Mon Nov  2 09:28:08 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 1.2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb050365598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb050359950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0503d67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05032b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05032b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0503d66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501f4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb050174598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501746a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501341e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501ab840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045e2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045e2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004615158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00460d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045e2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045ce9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00463eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004654b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00463e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004510620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0500621e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004510b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00455aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043db0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043dba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05009a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043dbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043dbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00453f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0042b0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004456f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.00015391581
test_loss: 0.00015114415
train_loss: 4.627009e-05
test_loss: 4.9310293e-05
train_loss: 2.6609345e-05
test_loss: 2.5978763e-05
train_loss: 1.7781349e-05
test_loss: 1.7543207e-05
train_loss: 1.31421675e-05
test_loss: 1.3268239e-05
train_loss: 1.0640626e-05
test_loss: 1.0947131e-05
train_loss: 9.185814e-06
test_loss: 9.156303e-06
train_loss: 8.137786e-06
test_loss: 8.093242e-06
train_loss: 7.0265496e-06
test_loss: 7.4031686e-06
train_loss: 6.440058e-06
test_loss: 6.6395896e-06
train_loss: 6.3274188e-06
test_loss: 6.157083e-06
train_loss: 5.8263954e-06
test_loss: 5.6566987e-06
train_loss: 5.382752e-06
test_loss: 5.365601e-06
train_loss: 4.9352707e-06
test_loss: 5.127628e-06
train_loss: 4.866726e-06
test_loss: 4.9099003e-06
train_loss: 4.5995453e-06
test_loss: 4.6651253e-06
train_loss: 4.23269e-06
test_loss: 4.547619e-06
train_loss: 4.3342066e-06
test_loss: 4.368615e-06
train_loss: 3.7521959e-06
test_loss: 4.232341e-06
train_loss: 3.928519e-06
test_loss: 4.1193866e-06
train_loss: 3.7182845e-06
test_loss: 4.0367295e-06
train_loss: 3.6721385e-06
test_loss: 3.8951425e-06
train_loss: 3.717274e-06
test_loss: 3.822197e-06
train_loss: 3.5353783e-06
test_loss: 3.7468478e-06
train_loss: 3.4097402e-06
test_loss: 3.6879705e-06
train_loss: 3.3099873e-06
test_loss: 3.5606954e-06
train_loss: 3.3987142e-06
test_loss: 3.549347e-06
train_loss: 3.2426663e-06
test_loss: 3.5272026e-06
train_loss: 3.4318496e-06
test_loss: 3.4346072e-06
train_loss: 3.0909482e-06
test_loss: 3.4095538e-06
train_loss: 3.2933904e-06
test_loss: 3.357889e-06
train_loss: 2.9852959e-06
test_loss: 3.3326874e-06
train_loss: 3.059511e-06
test_loss: 3.3025228e-06
train_loss: 3.1358145e-06
test_loss: 3.2705095e-06
train_loss: 3.1576765e-06
test_loss: 3.23205e-06
train_loss: 2.9916082e-06
test_loss: 3.1945135e-06
train_loss: 3.0333754e-06
test_loss: 3.1978602e-06
train_loss: 2.8467489e-06
test_loss: 3.1483755e-06
train_loss: 3.049747e-06
test_loss: 3.1262846e-06
train_loss: 3.002253e-06
test_loss: 3.13198e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7e3a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7e4eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b37d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b95158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b950d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b95400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d8fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7dc2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb034df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0356f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d567b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d59598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb02d7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d58510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0297f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb032af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0321488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb02a5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0356598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0321d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb01dc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb01dcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0177c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0133d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb01339d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0133730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0088ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0088488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb004e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb005f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb00617b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb00daea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0e903939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb005f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0e90393b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0e90310d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.91327729e-06
Iter: 2 loss: 2.87803186e-06
Iter: 3 loss: 3.38368181e-06
Iter: 4 loss: 2.87798184e-06
Iter: 5 loss: 2.86637692e-06
Iter: 6 loss: 2.95544487e-06
Iter: 7 loss: 2.86548425e-06
Iter: 8 loss: 2.85805163e-06
Iter: 9 loss: 2.87238436e-06
Iter: 10 loss: 2.85496935e-06
Iter: 11 loss: 2.85076021e-06
Iter: 12 loss: 2.90618709e-06
Iter: 13 loss: 2.85073293e-06
Iter: 14 loss: 2.84812768e-06
Iter: 15 loss: 2.85090027e-06
Iter: 16 loss: 2.84669363e-06
Iter: 17 loss: 2.84495536e-06
Iter: 18 loss: 2.85700344e-06
Iter: 19 loss: 2.84474868e-06
Iter: 20 loss: 2.84300722e-06
Iter: 21 loss: 2.84190855e-06
Iter: 22 loss: 2.84121597e-06
Iter: 23 loss: 2.83965164e-06
Iter: 24 loss: 2.84164298e-06
Iter: 25 loss: 2.83886425e-06
Iter: 26 loss: 2.83710597e-06
Iter: 27 loss: 2.86466434e-06
Iter: 28 loss: 2.83710551e-06
Iter: 29 loss: 2.83635472e-06
Iter: 30 loss: 2.83498412e-06
Iter: 31 loss: 2.86547538e-06
Iter: 32 loss: 2.83497798e-06
Iter: 33 loss: 2.83368627e-06
Iter: 34 loss: 2.83888767e-06
Iter: 35 loss: 2.83339705e-06
Iter: 36 loss: 2.83225927e-06
Iter: 37 loss: 2.83265103e-06
Iter: 38 loss: 2.83146892e-06
Iter: 39 loss: 2.83019767e-06
Iter: 40 loss: 2.83799704e-06
Iter: 41 loss: 2.83008626e-06
Iter: 42 loss: 2.8291231e-06
Iter: 43 loss: 2.8333086e-06
Iter: 44 loss: 2.82893e-06
Iter: 45 loss: 2.82880023e-06
Iter: 46 loss: 2.82853898e-06
Iter: 47 loss: 2.82824863e-06
Iter: 48 loss: 2.82766246e-06
Iter: 49 loss: 2.83978261e-06
Iter: 50 loss: 2.82767792e-06
Iter: 51 loss: 2.82716564e-06
Iter: 52 loss: 2.82717133e-06
Iter: 53 loss: 2.82679343e-06
Iter: 54 loss: 2.82601331e-06
Iter: 55 loss: 2.83959071e-06
Iter: 56 loss: 2.82600877e-06
Iter: 57 loss: 2.82552696e-06
Iter: 58 loss: 2.82551105e-06
Iter: 59 loss: 2.82507744e-06
Iter: 60 loss: 2.82412111e-06
Iter: 61 loss: 2.83965574e-06
Iter: 62 loss: 2.82412043e-06
Iter: 63 loss: 2.8233394e-06
Iter: 64 loss: 2.82932865e-06
Iter: 65 loss: 2.82330097e-06
Iter: 66 loss: 2.82264909e-06
Iter: 67 loss: 2.82675501e-06
Iter: 68 loss: 2.82257952e-06
Iter: 69 loss: 2.82212773e-06
Iter: 70 loss: 2.82481324e-06
Iter: 71 loss: 2.82205815e-06
Iter: 72 loss: 2.82173437e-06
Iter: 73 loss: 2.82115798e-06
Iter: 74 loss: 2.82115798e-06
Iter: 75 loss: 2.82060091e-06
Iter: 76 loss: 2.82075121e-06
Iter: 77 loss: 2.82018482e-06
Iter: 78 loss: 2.81950361e-06
Iter: 79 loss: 2.82251153e-06
Iter: 80 loss: 2.81937719e-06
Iter: 81 loss: 2.81911048e-06
Iter: 82 loss: 2.81899293e-06
Iter: 83 loss: 2.81871689e-06
Iter: 84 loss: 2.81820803e-06
Iter: 85 loss: 2.82558767e-06
Iter: 86 loss: 2.81815778e-06
Iter: 87 loss: 2.81751522e-06
Iter: 88 loss: 2.82585597e-06
Iter: 89 loss: 2.81749954e-06
Iter: 90 loss: 2.81715984e-06
Iter: 91 loss: 2.81688131e-06
Iter: 92 loss: 2.81676034e-06
Iter: 93 loss: 2.81634379e-06
Iter: 94 loss: 2.8224481e-06
Iter: 95 loss: 2.81631219e-06
Iter: 96 loss: 2.81603207e-06
Iter: 97 loss: 2.81559596e-06
Iter: 98 loss: 2.81559619e-06
Iter: 99 loss: 2.81522875e-06
Iter: 100 loss: 2.81742678e-06
Iter: 101 loss: 2.81516964e-06
Iter: 102 loss: 2.81473649e-06
Iter: 103 loss: 2.81623375e-06
Iter: 104 loss: 2.81460029e-06
Iter: 105 loss: 2.81415714e-06
Iter: 106 loss: 2.8149193e-06
Iter: 107 loss: 2.81398911e-06
Iter: 108 loss: 2.81351845e-06
Iter: 109 loss: 2.81285816e-06
Iter: 110 loss: 2.81283337e-06
Iter: 111 loss: 2.81201869e-06
Iter: 112 loss: 2.8157242e-06
Iter: 113 loss: 2.81188977e-06
Iter: 114 loss: 2.8113709e-06
Iter: 115 loss: 2.81662597e-06
Iter: 116 loss: 2.81131815e-06
Iter: 117 loss: 2.81076836e-06
Iter: 118 loss: 2.81391885e-06
Iter: 119 loss: 2.8106906e-06
Iter: 120 loss: 2.81045959e-06
Iter: 121 loss: 2.81052121e-06
Iter: 122 loss: 2.81025063e-06
Iter: 123 loss: 2.809737e-06
Iter: 124 loss: 2.8102645e-06
Iter: 125 loss: 2.80948234e-06
Iter: 126 loss: 2.80912877e-06
Iter: 127 loss: 2.80965196e-06
Iter: 128 loss: 2.80899667e-06
Iter: 129 loss: 2.80843051e-06
Iter: 130 loss: 2.80936683e-06
Iter: 131 loss: 2.80817721e-06
Iter: 132 loss: 2.80765062e-06
Iter: 133 loss: 2.80722043e-06
Iter: 134 loss: 2.80708264e-06
Iter: 135 loss: 2.80671384e-06
Iter: 136 loss: 2.80667791e-06
Iter: 137 loss: 2.80627955e-06
Iter: 138 loss: 2.80607765e-06
Iter: 139 loss: 2.80589325e-06
Iter: 140 loss: 2.80524728e-06
Iter: 141 loss: 2.80646213e-06
Iter: 142 loss: 2.80496852e-06
Iter: 143 loss: 2.80435506e-06
Iter: 144 loss: 2.80440372e-06
Iter: 145 loss: 2.80385984e-06
Iter: 146 loss: 2.8030604e-06
Iter: 147 loss: 2.80516042e-06
Iter: 148 loss: 2.80281529e-06
Iter: 149 loss: 2.80283439e-06
Iter: 150 loss: 2.80248105e-06
Iter: 151 loss: 2.80224344e-06
Iter: 152 loss: 2.8017912e-06
Iter: 153 loss: 2.81096641e-06
Iter: 154 loss: 2.80177551e-06
Iter: 155 loss: 2.80146514e-06
Iter: 156 loss: 2.80144582e-06
Iter: 157 loss: 2.80115592e-06
Iter: 158 loss: 2.80043946e-06
Iter: 159 loss: 2.80683344e-06
Iter: 160 loss: 2.80035033e-06
Iter: 161 loss: 2.79967867e-06
Iter: 162 loss: 2.79964979e-06
Iter: 163 loss: 2.79899677e-06
Iter: 164 loss: 2.79796154e-06
Iter: 165 loss: 2.7979454e-06
Iter: 166 loss: 2.79685128e-06
Iter: 167 loss: 2.79909636e-06
Iter: 168 loss: 2.79643223e-06
Iter: 169 loss: 2.7959004e-06
Iter: 170 loss: 2.79578762e-06
Iter: 171 loss: 2.79538949e-06
Iter: 172 loss: 2.79490587e-06
Iter: 173 loss: 2.79482947e-06
Iter: 174 loss: 2.79421215e-06
Iter: 175 loss: 2.79651977e-06
Iter: 176 loss: 2.79408687e-06
Iter: 177 loss: 2.79346045e-06
Iter: 178 loss: 2.79352298e-06
Iter: 179 loss: 2.79296273e-06
Iter: 180 loss: 2.79229653e-06
Iter: 181 loss: 2.79552614e-06
Iter: 182 loss: 2.79215146e-06
Iter: 183 loss: 2.7914441e-06
Iter: 184 loss: 2.79856522e-06
Iter: 185 loss: 2.79139022e-06
Iter: 186 loss: 2.7910246e-06
Iter: 187 loss: 2.7905096e-06
Iter: 188 loss: 2.79048595e-06
Iter: 189 loss: 2.78956554e-06
Iter: 190 loss: 2.79463211e-06
Iter: 191 loss: 2.78942821e-06
Iter: 192 loss: 2.7889896e-06
Iter: 193 loss: 2.78863604e-06
Iter: 194 loss: 2.78851712e-06
Iter: 195 loss: 2.78779817e-06
Iter: 196 loss: 2.79530468e-06
Iter: 197 loss: 2.78780203e-06
Iter: 198 loss: 2.78731227e-06
Iter: 199 loss: 2.78657103e-06
Iter: 200 loss: 2.78654329e-06
Iter: 201 loss: 2.78578614e-06
Iter: 202 loss: 2.78820789e-06
Iter: 203 loss: 2.78554853e-06
Iter: 204 loss: 2.78451807e-06
Iter: 205 loss: 2.79129154e-06
Iter: 206 loss: 2.78441485e-06
Iter: 207 loss: 2.78395555e-06
Iter: 208 loss: 2.78347579e-06
Iter: 209 loss: 2.78340804e-06
Iter: 210 loss: 2.78237667e-06
Iter: 211 loss: 2.78406083e-06
Iter: 212 loss: 2.7819242e-06
Iter: 213 loss: 2.78094785e-06
Iter: 214 loss: 2.78104403e-06
Iter: 215 loss: 2.78015955e-06
Iter: 216 loss: 2.77937193e-06
Iter: 217 loss: 2.77931213e-06
Iter: 218 loss: 2.77843537e-06
Iter: 219 loss: 2.77950039e-06
Iter: 220 loss: 2.77799859e-06
Iter: 221 loss: 2.7773458e-06
Iter: 222 loss: 2.77869412e-06
Iter: 223 loss: 2.77709387e-06
Iter: 224 loss: 2.77611207e-06
Iter: 225 loss: 2.77666413e-06
Iter: 226 loss: 2.77545587e-06
Iter: 227 loss: 2.77471e-06
Iter: 228 loss: 2.77530307e-06
Iter: 229 loss: 2.77426e-06
Iter: 230 loss: 2.773181e-06
Iter: 231 loss: 2.78114271e-06
Iter: 232 loss: 2.77310369e-06
Iter: 233 loss: 2.77255413e-06
Iter: 234 loss: 2.77163122e-06
Iter: 235 loss: 2.77164622e-06
Iter: 236 loss: 2.77105892e-06
Iter: 237 loss: 2.77102799e-06
Iter: 238 loss: 2.77035429e-06
Iter: 239 loss: 2.76959645e-06
Iter: 240 loss: 2.76950777e-06
Iter: 241 loss: 2.76854212e-06
Iter: 242 loss: 2.76862897e-06
Iter: 243 loss: 2.76782475e-06
Iter: 244 loss: 2.76635365e-06
Iter: 245 loss: 2.77433355e-06
Iter: 246 loss: 2.76611718e-06
Iter: 247 loss: 2.76504034e-06
Iter: 248 loss: 2.76683659e-06
Iter: 249 loss: 2.7645724e-06
Iter: 250 loss: 2.76407968e-06
Iter: 251 loss: 2.76397941e-06
Iter: 252 loss: 2.76338369e-06
Iter: 253 loss: 2.76230548e-06
Iter: 254 loss: 2.78625e-06
Iter: 255 loss: 2.76228684e-06
Iter: 256 loss: 2.76187302e-06
Iter: 257 loss: 2.76179435e-06
Iter: 258 loss: 2.76135574e-06
Iter: 259 loss: 2.76056244e-06
Iter: 260 loss: 2.77957815e-06
Iter: 261 loss: 2.76057335e-06
Iter: 262 loss: 2.75982075e-06
Iter: 263 loss: 2.7615597e-06
Iter: 264 loss: 2.75952152e-06
Iter: 265 loss: 2.75849561e-06
Iter: 266 loss: 2.76548781e-06
Iter: 267 loss: 2.75839875e-06
Iter: 268 loss: 2.75783941e-06
Iter: 269 loss: 2.75658863e-06
Iter: 270 loss: 2.77427444e-06
Iter: 271 loss: 2.75651746e-06
Iter: 272 loss: 2.75534239e-06
Iter: 273 loss: 2.77097888e-06
Iter: 274 loss: 2.75537059e-06
Iter: 275 loss: 2.75423599e-06
Iter: 276 loss: 2.75947059e-06
Iter: 277 loss: 2.75400612e-06
Iter: 278 loss: 2.75339835e-06
Iter: 279 loss: 2.75241678e-06
Iter: 280 loss: 2.75239654e-06
Iter: 281 loss: 2.75118373e-06
Iter: 282 loss: 2.75595448e-06
Iter: 283 loss: 2.75090429e-06
Iter: 284 loss: 2.75041543e-06
Iter: 285 loss: 2.75031834e-06
Iter: 286 loss: 2.74977901e-06
Iter: 287 loss: 2.75057528e-06
Iter: 288 loss: 2.74952708e-06
Iter: 289 loss: 2.74878084e-06
Iter: 290 loss: 2.74806507e-06
Iter: 291 loss: 2.74790455e-06
Iter: 292 loss: 2.74737795e-06
Iter: 293 loss: 2.74731633e-06
Iter: 294 loss: 2.74683316e-06
Iter: 295 loss: 2.74563672e-06
Iter: 296 loss: 2.7573933e-06
Iter: 297 loss: 2.74548e-06
Iter: 298 loss: 2.74448621e-06
Iter: 299 loss: 2.75507887e-06
Iter: 300 loss: 2.74443778e-06
Iter: 301 loss: 2.7434171e-06
Iter: 302 loss: 2.74648619e-06
Iter: 303 loss: 2.7431347e-06
Iter: 304 loss: 2.74224931e-06
Iter: 305 loss: 2.74108743e-06
Iter: 306 loss: 2.74101808e-06
Iter: 307 loss: 2.73995101e-06
Iter: 308 loss: 2.75362072e-06
Iter: 309 loss: 2.73993692e-06
Iter: 310 loss: 2.73878504e-06
Iter: 311 loss: 2.741966e-06
Iter: 312 loss: 2.73839532e-06
Iter: 313 loss: 2.73772e-06
Iter: 314 loss: 2.73640489e-06
Iter: 315 loss: 2.76101218e-06
Iter: 316 loss: 2.73639171e-06
Iter: 317 loss: 2.73518708e-06
Iter: 318 loss: 2.74489457e-06
Iter: 319 loss: 2.73508658e-06
Iter: 320 loss: 2.73465776e-06
Iter: 321 loss: 2.73449541e-06
Iter: 322 loss: 2.73402156e-06
Iter: 323 loss: 2.73311593e-06
Iter: 324 loss: 2.7510705e-06
Iter: 325 loss: 2.73310457e-06
Iter: 326 loss: 2.73198611e-06
Iter: 327 loss: 2.73888372e-06
Iter: 328 loss: 2.73183377e-06
Iter: 329 loss: 2.73096884e-06
Iter: 330 loss: 2.73589058e-06
Iter: 331 loss: 2.73085016e-06
Iter: 332 loss: 2.730191e-06
Iter: 333 loss: 2.7287349e-06
Iter: 334 loss: 2.7526562e-06
Iter: 335 loss: 2.72869102e-06
Iter: 336 loss: 2.72775696e-06
Iter: 337 loss: 2.72774287e-06
Iter: 338 loss: 2.72702891e-06
Iter: 339 loss: 2.73017918e-06
Iter: 340 loss: 2.72693751e-06
Iter: 341 loss: 2.72649959e-06
Iter: 342 loss: 2.72549141e-06
Iter: 343 loss: 2.73714204e-06
Iter: 344 loss: 2.72543184e-06
Iter: 345 loss: 2.72518355e-06
Iter: 346 loss: 2.7248916e-06
Iter: 347 loss: 2.72436705e-06
Iter: 348 loss: 2.72344278e-06
Iter: 349 loss: 2.72344028e-06
Iter: 350 loss: 2.7223773e-06
Iter: 351 loss: 2.72224702e-06
Iter: 352 loss: 2.72147963e-06
Iter: 353 loss: 2.72026682e-06
Iter: 354 loss: 2.72896523e-06
Iter: 355 loss: 2.72016086e-06
Iter: 356 loss: 2.71905947e-06
Iter: 357 loss: 2.73381283e-06
Iter: 358 loss: 2.7190772e-06
Iter: 359 loss: 2.71854287e-06
Iter: 360 loss: 2.71792578e-06
Iter: 361 loss: 2.71785325e-06
Iter: 362 loss: 2.71718204e-06
Iter: 363 loss: 2.71718659e-06
Iter: 364 loss: 2.71669114e-06
Iter: 365 loss: 2.71632643e-06
Iter: 366 loss: 2.7161966e-06
Iter: 367 loss: 2.71539739e-06
Iter: 368 loss: 2.71667113e-06
Iter: 369 loss: 2.71500949e-06
Iter: 370 loss: 2.71430258e-06
Iter: 371 loss: 2.719549e-06
Iter: 372 loss: 2.71421914e-06
Iter: 373 loss: 2.71348176e-06
Iter: 374 loss: 2.71407862e-06
Iter: 375 loss: 2.71301224e-06
Iter: 376 loss: 2.71232511e-06
Iter: 377 loss: 2.71148429e-06
Iter: 378 loss: 2.71141789e-06
Iter: 379 loss: 2.71112049e-06
Iter: 380 loss: 2.71080376e-06
Iter: 381 loss: 2.7103024e-06
Iter: 382 loss: 2.7090598e-06
Iter: 383 loss: 2.72345324e-06
Iter: 384 loss: 2.70896703e-06
Iter: 385 loss: 2.70771511e-06
Iter: 386 loss: 2.71077533e-06
Iter: 387 loss: 2.70727833e-06
Iter: 388 loss: 2.70612372e-06
Iter: 389 loss: 2.71231784e-06
Iter: 390 loss: 2.70594e-06
Iter: 391 loss: 2.70479313e-06
Iter: 392 loss: 2.71752197e-06
Iter: 393 loss: 2.70474447e-06
Iter: 394 loss: 2.70430178e-06
Iter: 395 loss: 2.70349506e-06
Iter: 396 loss: 2.72162242e-06
Iter: 397 loss: 2.70350711e-06
Iter: 398 loss: 2.7025842e-06
Iter: 399 loss: 2.71629165e-06
Iter: 400 loss: 2.70256396e-06
Iter: 401 loss: 2.70197097e-06
Iter: 402 loss: 2.70091664e-06
Iter: 403 loss: 2.72603847e-06
Iter: 404 loss: 2.70092096e-06
Iter: 405 loss: 2.69982866e-06
Iter: 406 loss: 2.71109093e-06
Iter: 407 loss: 2.69978773e-06
Iter: 408 loss: 2.69894463e-06
Iter: 409 loss: 2.70174883e-06
Iter: 410 loss: 2.6987002e-06
Iter: 411 loss: 2.69785141e-06
Iter: 412 loss: 2.69826273e-06
Iter: 413 loss: 2.69723023e-06
Iter: 414 loss: 2.69614907e-06
Iter: 415 loss: 2.69601014e-06
Iter: 416 loss: 2.69524617e-06
Iter: 417 loss: 2.6944108e-06
Iter: 418 loss: 2.69426096e-06
Iter: 419 loss: 2.69362226e-06
Iter: 420 loss: 2.69230213e-06
Iter: 421 loss: 2.71821773e-06
Iter: 422 loss: 2.69229e-06
Iter: 423 loss: 2.69100747e-06
Iter: 424 loss: 2.69171687e-06
Iter: 425 loss: 2.69014708e-06
Iter: 426 loss: 2.68971144e-06
Iter: 427 loss: 2.68948088e-06
Iter: 428 loss: 2.68869121e-06
Iter: 429 loss: 2.68856161e-06
Iter: 430 loss: 2.68797703e-06
Iter: 431 loss: 2.68712643e-06
Iter: 432 loss: 2.68758686e-06
Iter: 433 loss: 2.68657095e-06
Iter: 434 loss: 2.6856469e-06
Iter: 435 loss: 2.69877205e-06
Iter: 436 loss: 2.68564281e-06
Iter: 437 loss: 2.6849234e-06
Iter: 438 loss: 2.682993e-06
Iter: 439 loss: 2.69618249e-06
Iter: 440 loss: 2.68255462e-06
Iter: 441 loss: 2.68185886e-06
Iter: 442 loss: 2.68151121e-06
Iter: 443 loss: 2.68051576e-06
Iter: 444 loss: 2.67934661e-06
Iter: 445 loss: 2.67922246e-06
Iter: 446 loss: 2.67806e-06
Iter: 447 loss: 2.68833674e-06
Iter: 448 loss: 2.67802511e-06
Iter: 449 loss: 2.67715518e-06
Iter: 450 loss: 2.67759242e-06
Iter: 451 loss: 2.67654877e-06
Iter: 452 loss: 2.675627e-06
Iter: 453 loss: 2.69024667e-06
Iter: 454 loss: 2.67563928e-06
Iter: 455 loss: 2.67503901e-06
Iter: 456 loss: 2.67378437e-06
Iter: 457 loss: 2.69635098e-06
Iter: 458 loss: 2.67377482e-06
Iter: 459 loss: 2.67211794e-06
Iter: 460 loss: 2.67097448e-06
Iter: 461 loss: 2.67036239e-06
Iter: 462 loss: 2.66796565e-06
Iter: 463 loss: 2.6794678e-06
Iter: 464 loss: 2.66748248e-06
Iter: 465 loss: 2.66688448e-06
Iter: 466 loss: 2.66645793e-06
Iter: 467 loss: 2.66543179e-06
Iter: 468 loss: 2.66490861e-06
Iter: 469 loss: 2.66442157e-06
Iter: 470 loss: 2.66343477e-06
Iter: 471 loss: 2.66458846e-06
Iter: 472 loss: 2.66287589e-06
Iter: 473 loss: 2.66151028e-06
Iter: 474 loss: 2.67371752e-06
Iter: 475 loss: 2.66146571e-06
Iter: 476 loss: 2.660684e-06
Iter: 477 loss: 2.65920494e-06
Iter: 478 loss: 2.69085922e-06
Iter: 479 loss: 2.6591797e-06
Iter: 480 loss: 2.65843732e-06
Iter: 481 loss: 2.65834569e-06
Iter: 482 loss: 2.65750759e-06
Iter: 483 loss: 2.65623976e-06
Iter: 484 loss: 2.65619337e-06
Iter: 485 loss: 2.6548787e-06
Iter: 486 loss: 2.66519692e-06
Iter: 487 loss: 2.65481412e-06
Iter: 488 loss: 2.65366248e-06
Iter: 489 loss: 2.65621225e-06
Iter: 490 loss: 2.65324843e-06
Iter: 491 loss: 2.6519217e-06
Iter: 492 loss: 2.65744893e-06
Iter: 493 loss: 2.65164658e-06
Iter: 494 loss: 2.65061976e-06
Iter: 495 loss: 2.64848e-06
Iter: 496 loss: 2.68437952e-06
Iter: 497 loss: 2.64842765e-06
Iter: 498 loss: 2.64641358e-06
Iter: 499 loss: 2.6580733e-06
Iter: 500 loss: 2.646133e-06
Iter: 501 loss: 2.64495043e-06
Iter: 502 loss: 2.64490905e-06
Iter: 503 loss: 2.64364917e-06
Iter: 504 loss: 2.64551591e-06
Iter: 505 loss: 2.64305299e-06
Iter: 506 loss: 2.64224172e-06
Iter: 507 loss: 2.64148366e-06
Iter: 508 loss: 2.64128767e-06
Iter: 509 loss: 2.64046503e-06
Iter: 510 loss: 2.64041091e-06
Iter: 511 loss: 2.63976835e-06
Iter: 512 loss: 2.63852985e-06
Iter: 513 loss: 2.6618975e-06
Iter: 514 loss: 2.6385e-06
Iter: 515 loss: 2.6370717e-06
Iter: 516 loss: 2.63938659e-06
Iter: 517 loss: 2.6364703e-06
Iter: 518 loss: 2.63461516e-06
Iter: 519 loss: 2.65195558e-06
Iter: 520 loss: 2.63455786e-06
Iter: 521 loss: 2.63348284e-06
Iter: 522 loss: 2.63208494e-06
Iter: 523 loss: 2.63200468e-06
Iter: 524 loss: 2.63028119e-06
Iter: 525 loss: 2.65329822e-06
Iter: 526 loss: 2.6302821e-06
Iter: 527 loss: 2.62922708e-06
Iter: 528 loss: 2.63298216e-06
Iter: 529 loss: 2.62898016e-06
Iter: 530 loss: 2.62788535e-06
Iter: 531 loss: 2.62623325e-06
Iter: 532 loss: 2.6262112e-06
Iter: 533 loss: 2.62455887e-06
Iter: 534 loss: 2.62833328e-06
Iter: 535 loss: 2.62394747e-06
Iter: 536 loss: 2.62281e-06
Iter: 537 loss: 2.62275171e-06
Iter: 538 loss: 2.62136859e-06
Iter: 539 loss: 2.62080016e-06
Iter: 540 loss: 2.6200596e-06
Iter: 541 loss: 2.61875266e-06
Iter: 542 loss: 2.61894593e-06
Iter: 543 loss: 2.61774812e-06
Iter: 544 loss: 2.61642936e-06
Iter: 545 loss: 2.61638934e-06
Iter: 546 loss: 2.61545483e-06
Iter: 547 loss: 2.61351261e-06
Iter: 548 loss: 2.64576533e-06
Iter: 549 loss: 2.61346713e-06
Iter: 550 loss: 2.61193054e-06
Iter: 551 loss: 2.62364392e-06
Iter: 552 loss: 2.61183959e-06
Iter: 553 loss: 2.61040259e-06
Iter: 554 loss: 2.6198295e-06
Iter: 555 loss: 2.6102548e-06
Iter: 556 loss: 2.60939169e-06
Iter: 557 loss: 2.60944785e-06
Iter: 558 loss: 2.6086866e-06
Iter: 559 loss: 2.60770071e-06
Iter: 560 loss: 2.61805621e-06
Iter: 561 loss: 2.60768957e-06
Iter: 562 loss: 2.60685e-06
Iter: 563 loss: 2.60638217e-06
Iter: 564 loss: 2.60600245e-06
Iter: 565 loss: 2.60452953e-06
Iter: 566 loss: 2.60737033e-06
Iter: 567 loss: 2.60392972e-06
Iter: 568 loss: 2.60264528e-06
Iter: 569 loss: 2.60066872e-06
Iter: 570 loss: 2.60064e-06
Iter: 571 loss: 2.59920603e-06
Iter: 572 loss: 2.59910075e-06
Iter: 573 loss: 2.59733315e-06
Iter: 574 loss: 2.60102934e-06
Iter: 575 loss: 2.59664648e-06
Iter: 576 loss: 2.59551325e-06
Iter: 577 loss: 2.59433159e-06
Iter: 578 loss: 2.594119e-06
Iter: 579 loss: 2.59355e-06
Iter: 580 loss: 2.59327339e-06
Iter: 581 loss: 2.59254671e-06
Iter: 582 loss: 2.59118883e-06
Iter: 583 loss: 2.61881951e-06
Iter: 584 loss: 2.59116177e-06
Iter: 585 loss: 2.58992122e-06
Iter: 586 loss: 2.59255739e-06
Iter: 587 loss: 2.58945329e-06
Iter: 588 loss: 2.58835826e-06
Iter: 589 loss: 2.58837099e-06
Iter: 590 loss: 2.5876393e-06
Iter: 591 loss: 2.58683872e-06
Iter: 592 loss: 2.58670502e-06
Iter: 593 loss: 2.58591149e-06
Iter: 594 loss: 2.58591126e-06
Iter: 595 loss: 2.58515161e-06
Iter: 596 loss: 2.58460159e-06
Iter: 597 loss: 2.58434e-06
Iter: 598 loss: 2.58313207e-06
Iter: 599 loss: 2.5861425e-06
Iter: 600 loss: 2.58269665e-06
Iter: 601 loss: 2.58144928e-06
Iter: 602 loss: 2.58096179e-06
Iter: 603 loss: 2.58027103e-06
Iter: 604 loss: 2.5788886e-06
Iter: 605 loss: 2.59224907e-06
Iter: 606 loss: 2.57882084e-06
Iter: 607 loss: 2.57768966e-06
Iter: 608 loss: 2.59147214e-06
Iter: 609 loss: 2.57767465e-06
Iter: 610 loss: 2.57708962e-06
Iter: 611 loss: 2.57587135e-06
Iter: 612 loss: 2.59318517e-06
Iter: 613 loss: 2.57580814e-06
Iter: 614 loss: 2.57532474e-06
Iter: 615 loss: 2.57518468e-06
Iter: 616 loss: 2.57449892e-06
Iter: 617 loss: 2.57298598e-06
Iter: 618 loss: 2.5936688e-06
Iter: 619 loss: 2.57292709e-06
Iter: 620 loss: 2.57148758e-06
Iter: 621 loss: 2.57694023e-06
Iter: 622 loss: 2.57116926e-06
Iter: 623 loss: 2.56991143e-06
Iter: 624 loss: 2.584188e-06
Iter: 625 loss: 2.56990461e-06
Iter: 626 loss: 2.56886597e-06
Iter: 627 loss: 2.56722615e-06
Iter: 628 loss: 2.56720182e-06
Iter: 629 loss: 2.56610474e-06
Iter: 630 loss: 2.5660861e-06
Iter: 631 loss: 2.56505746e-06
Iter: 632 loss: 2.56435351e-06
Iter: 633 loss: 2.56403337e-06
Iter: 634 loss: 2.56292128e-06
Iter: 635 loss: 2.5683853e-06
Iter: 636 loss: 2.56270232e-06
Iter: 637 loss: 2.56153498e-06
Iter: 638 loss: 2.56049566e-06
Iter: 639 loss: 2.56025533e-06
Iter: 640 loss: 2.55908708e-06
Iter: 641 loss: 2.55907798e-06
Iter: 642 loss: 2.55794157e-06
Iter: 643 loss: 2.56290014e-06
Iter: 644 loss: 2.5577026e-06
Iter: 645 loss: 2.55690475e-06
Iter: 646 loss: 2.55511736e-06
Iter: 647 loss: 2.57975807e-06
Iter: 648 loss: 2.55501504e-06
Iter: 649 loss: 2.55491932e-06
Iter: 650 loss: 2.55422538e-06
Iter: 651 loss: 2.55358145e-06
Iter: 652 loss: 2.55212422e-06
Iter: 653 loss: 2.57294323e-06
Iter: 654 loss: 2.55204532e-06
Iter: 655 loss: 2.55063446e-06
Iter: 656 loss: 2.55644045e-06
Iter: 657 loss: 2.55034047e-06
Iter: 658 loss: 2.54897873e-06
Iter: 659 loss: 2.56287785e-06
Iter: 660 loss: 2.54895986e-06
Iter: 661 loss: 2.5480972e-06
Iter: 662 loss: 2.54663314e-06
Iter: 663 loss: 2.54663018e-06
Iter: 664 loss: 2.54528868e-06
Iter: 665 loss: 2.54525503e-06
Iter: 666 loss: 2.5443951e-06
Iter: 667 loss: 2.54375186e-06
Iter: 668 loss: 2.54348652e-06
Iter: 669 loss: 2.54238967e-06
Iter: 670 loss: 2.54490715e-06
Iter: 671 loss: 2.54196971e-06
Iter: 672 loss: 2.54062161e-06
Iter: 673 loss: 2.54267161e-06
Iter: 674 loss: 2.53995313e-06
Iter: 675 loss: 2.53915209e-06
Iter: 676 loss: 2.55037412e-06
Iter: 677 loss: 2.53917324e-06
Iter: 678 loss: 2.53810799e-06
Iter: 679 loss: 2.53741723e-06
Iter: 680 loss: 2.53704843e-06
Iter: 681 loss: 2.53582039e-06
Iter: 682 loss: 2.53531493e-06
Iter: 683 loss: 2.53466965e-06
Iter: 684 loss: 2.53348048e-06
Iter: 685 loss: 2.53340136e-06
Iter: 686 loss: 2.5325437e-06
Iter: 687 loss: 2.53101598e-06
Iter: 688 loss: 2.53100688e-06
Iter: 689 loss: 2.52954214e-06
Iter: 690 loss: 2.53260805e-06
Iter: 691 loss: 2.52896143e-06
Iter: 692 loss: 2.52792779e-06
Iter: 693 loss: 2.52786117e-06
Iter: 694 loss: 2.52726932e-06
Iter: 695 loss: 2.52615746e-06
Iter: 696 loss: 2.55032865e-06
Iter: 697 loss: 2.52614041e-06
Iter: 698 loss: 2.52518089e-06
Iter: 699 loss: 2.52516293e-06
Iter: 700 loss: 2.52437053e-06
Iter: 701 loss: 2.52304926e-06
Iter: 702 loss: 2.52304517e-06
Iter: 703 loss: 2.52148311e-06
Iter: 704 loss: 2.52497603e-06
Iter: 705 loss: 2.52094151e-06
Iter: 706 loss: 2.51925098e-06
Iter: 707 loss: 2.52577047e-06
Iter: 708 loss: 2.51889242e-06
Iter: 709 loss: 2.51787219e-06
Iter: 710 loss: 2.52511632e-06
Iter: 711 loss: 2.51776237e-06
Iter: 712 loss: 2.51655274e-06
Iter: 713 loss: 2.51983192e-06
Iter: 714 loss: 2.51616439e-06
Iter: 715 loss: 2.51532674e-06
Iter: 716 loss: 2.51432061e-06
Iter: 717 loss: 2.51425e-06
Iter: 718 loss: 2.51333313e-06
Iter: 719 loss: 2.51327265e-06
Iter: 720 loss: 2.51258916e-06
Iter: 721 loss: 2.51104484e-06
Iter: 722 loss: 2.53209464e-06
Iter: 723 loss: 2.51095116e-06
Iter: 724 loss: 2.50945595e-06
Iter: 725 loss: 2.51477172e-06
Iter: 726 loss: 2.5090676e-06
Iter: 727 loss: 2.50786275e-06
Iter: 728 loss: 2.5078507e-06
Iter: 729 loss: 2.50707512e-06
Iter: 730 loss: 2.5060026e-06
Iter: 731 loss: 2.50596668e-06
Iter: 732 loss: 2.50487051e-06
Iter: 733 loss: 2.52136033e-06
Iter: 734 loss: 2.50486096e-06
Iter: 735 loss: 2.50379912e-06
Iter: 736 loss: 2.50233234e-06
Iter: 737 loss: 2.50228277e-06
Iter: 738 loss: 2.50064909e-06
Iter: 739 loss: 2.50291896e-06
Iter: 740 loss: 2.49983896e-06
Iter: 741 loss: 2.49763252e-06
Iter: 742 loss: 2.50518406e-06
Iter: 743 loss: 2.49703885e-06
Iter: 744 loss: 2.49563686e-06
Iter: 745 loss: 2.49867571e-06
Iter: 746 loss: 2.49510595e-06
Iter: 747 loss: 2.49401683e-06
Iter: 748 loss: 2.49393634e-06
Iter: 749 loss: 2.49319419e-06
Iter: 750 loss: 2.49202026e-06
Iter: 751 loss: 2.49202822e-06
Iter: 752 loss: 2.49132063e-06
Iter: 753 loss: 2.49127902e-06
Iter: 754 loss: 2.49058758e-06
Iter: 755 loss: 2.48909896e-06
Iter: 756 loss: 2.51264692e-06
Iter: 757 loss: 2.48906372e-06
Iter: 758 loss: 2.48739252e-06
Iter: 759 loss: 2.48875176e-06
Iter: 760 loss: 2.48640117e-06
Iter: 761 loss: 2.48540164e-06
Iter: 762 loss: 2.48529886e-06
Iter: 763 loss: 2.48414381e-06
Iter: 764 loss: 2.48234664e-06
Iter: 765 loss: 2.48231208e-06
Iter: 766 loss: 2.4809608e-06
Iter: 767 loss: 2.49672303e-06
Iter: 768 loss: 2.48092761e-06
Iter: 769 loss: 2.4795404e-06
Iter: 770 loss: 2.48122319e-06
Iter: 771 loss: 2.47878188e-06
Iter: 772 loss: 2.47754087e-06
Iter: 773 loss: 2.47666367e-06
Iter: 774 loss: 2.47625712e-06
Iter: 775 loss: 2.47451885e-06
Iter: 776 loss: 2.4813171e-06
Iter: 777 loss: 2.47409821e-06
Iter: 778 loss: 2.47309254e-06
Iter: 779 loss: 2.4730623e-06
Iter: 780 loss: 2.47219714e-06
Iter: 781 loss: 2.4745575e-06
Iter: 782 loss: 2.4718961e-06
Iter: 783 loss: 2.47101661e-06
Iter: 784 loss: 2.46965806e-06
Iter: 785 loss: 2.46963327e-06
Iter: 786 loss: 2.46827426e-06
Iter: 787 loss: 2.48969491e-06
Iter: 788 loss: 2.4682779e-06
Iter: 789 loss: 2.46707123e-06
Iter: 790 loss: 2.46636955e-06
Iter: 791 loss: 2.46586615e-06
Iter: 792 loss: 2.46432387e-06
Iter: 793 loss: 2.46377613e-06
Iter: 794 loss: 2.4629071e-06
Iter: 795 loss: 2.4612641e-06
Iter: 796 loss: 2.47630942e-06
Iter: 797 loss: 2.46118952e-06
Iter: 798 loss: 2.45980732e-06
Iter: 799 loss: 2.47253e-06
Iter: 800 loss: 2.45976207e-06
Iter: 801 loss: 2.45883439e-06
Iter: 802 loss: 2.45740262e-06
Iter: 803 loss: 2.45737056e-06
Iter: 804 loss: 2.45646311e-06
Iter: 805 loss: 2.45637057e-06
Iter: 806 loss: 2.45550359e-06
Iter: 807 loss: 2.45359161e-06
Iter: 808 loss: 2.48120341e-06
Iter: 809 loss: 2.45350293e-06
Iter: 810 loss: 2.4516271e-06
Iter: 811 loss: 2.45692308e-06
Iter: 812 loss: 2.4510216e-06
Iter: 813 loss: 2.44956527e-06
Iter: 814 loss: 2.44953389e-06
Iter: 815 loss: 2.44820421e-06
Iter: 816 loss: 2.44982812e-06
Iter: 817 loss: 2.447508e-06
Iter: 818 loss: 2.44628063e-06
Iter: 819 loss: 2.44699777e-06
Iter: 820 loss: 2.44550051e-06
Iter: 821 loss: 2.4442711e-06
Iter: 822 loss: 2.4562969e-06
Iter: 823 loss: 2.44422654e-06
Iter: 824 loss: 2.44306716e-06
Iter: 825 loss: 2.44230273e-06
Iter: 826 loss: 2.44188095e-06
Iter: 827 loss: 2.44043713e-06
Iter: 828 loss: 2.44001308e-06
Iter: 829 loss: 2.43915406e-06
Iter: 830 loss: 2.43741215e-06
Iter: 831 loss: 2.45330921e-06
Iter: 832 loss: 2.43733984e-06
Iter: 833 loss: 2.43600425e-06
Iter: 834 loss: 2.45074921e-06
Iter: 835 loss: 2.43599561e-06
Iter: 836 loss: 2.43531645e-06
Iter: 837 loss: 2.43439922e-06
Iter: 838 loss: 2.43435306e-06
Iter: 839 loss: 2.43338059e-06
Iter: 840 loss: 2.43338377e-06
Iter: 841 loss: 2.43257182e-06
Iter: 842 loss: 2.43075965e-06
Iter: 843 loss: 2.45577553e-06
Iter: 844 loss: 2.43064665e-06
Iter: 845 loss: 2.42874285e-06
Iter: 846 loss: 2.43513068e-06
Iter: 847 loss: 2.42821e-06
Iter: 848 loss: 2.42651845e-06
Iter: 849 loss: 2.42651049e-06
Iter: 850 loss: 2.42534111e-06
Iter: 851 loss: 2.42468377e-06
Iter: 852 loss: 2.42418901e-06
Iter: 853 loss: 2.42281953e-06
Iter: 854 loss: 2.42927172e-06
Iter: 855 loss: 2.42257829e-06
Iter: 856 loss: 2.42153e-06
Iter: 857 loss: 2.43029695e-06
Iter: 858 loss: 2.42148371e-06
Iter: 859 loss: 2.42074793e-06
Iter: 860 loss: 2.41956946e-06
Iter: 861 loss: 2.41955127e-06
Iter: 862 loss: 2.41831231e-06
Iter: 863 loss: 2.42148371e-06
Iter: 864 loss: 2.41787893e-06
Iter: 865 loss: 2.4169176e-06
Iter: 866 loss: 2.42948636e-06
Iter: 867 loss: 2.41691851e-06
Iter: 868 loss: 2.41587281e-06
Iter: 869 loss: 2.41540965e-06
Iter: 870 loss: 2.4148485e-06
Iter: 871 loss: 2.41371026e-06
Iter: 872 loss: 2.41802104e-06
Iter: 873 loss: 2.4134406e-06
Iter: 874 loss: 2.41217322e-06
Iter: 875 loss: 2.41894918e-06
Iter: 876 loss: 2.41200814e-06
Iter: 877 loss: 2.41109683e-06
Iter: 878 loss: 2.4096471e-06
Iter: 879 loss: 2.40961754e-06
Iter: 880 loss: 2.40890904e-06
Iter: 881 loss: 2.40881081e-06
Iter: 882 loss: 2.40788768e-06
Iter: 883 loss: 2.40820145e-06
Iter: 884 loss: 2.4072433e-06
Iter: 885 loss: 2.40625832e-06
Iter: 886 loss: 2.40774716e-06
Iter: 887 loss: 2.40580357e-06
Iter: 888 loss: 2.40484906e-06
Iter: 889 loss: 2.4103856e-06
Iter: 890 loss: 2.40473719e-06
Iter: 891 loss: 2.40368308e-06
Iter: 892 loss: 2.40411782e-06
Iter: 893 loss: 2.40296868e-06
Iter: 894 loss: 2.40180088e-06
Iter: 895 loss: 2.40111876e-06
Iter: 896 loss: 2.4005908e-06
Iter: 897 loss: 2.39907558e-06
Iter: 898 loss: 2.40637792e-06
Iter: 899 loss: 2.39881956e-06
Iter: 900 loss: 2.39775773e-06
Iter: 901 loss: 2.39775591e-06
Iter: 902 loss: 2.39701876e-06
Iter: 903 loss: 2.39575957e-06
Iter: 904 loss: 2.39577957e-06
Iter: 905 loss: 2.39475e-06
Iter: 906 loss: 2.39474025e-06
Iter: 907 loss: 2.39383303e-06
Iter: 908 loss: 2.39375822e-06
Iter: 909 loss: 2.3931043e-06
Iter: 910 loss: 2.39217707e-06
Iter: 911 loss: 2.39225119e-06
Iter: 912 loss: 2.39149108e-06
Iter: 913 loss: 2.39103861e-06
Iter: 914 loss: 2.39077053e-06
Iter: 915 loss: 2.39028896e-06
Iter: 916 loss: 2.3893067e-06
Iter: 917 loss: 2.4077674e-06
Iter: 918 loss: 2.38927169e-06
Iter: 919 loss: 2.38835401e-06
Iter: 920 loss: 2.3962441e-06
Iter: 921 loss: 2.38827397e-06
Iter: 922 loss: 2.38750044e-06
Iter: 923 loss: 2.39034125e-06
Iter: 924 loss: 2.38729353e-06
Iter: 925 loss: 2.38650091e-06
Iter: 926 loss: 2.38598386e-06
Iter: 927 loss: 2.38567782e-06
Iter: 928 loss: 2.3846078e-06
Iter: 929 loss: 2.38442317e-06
Iter: 930 loss: 2.38366215e-06
Iter: 931 loss: 2.3824698e-06
Iter: 932 loss: 2.40119721e-06
Iter: 933 loss: 2.38246753e-06
Iter: 934 loss: 2.38132952e-06
Iter: 935 loss: 2.38383632e-06
Iter: 936 loss: 2.38088728e-06
Iter: 937 loss: 2.3800535e-06
Iter: 938 loss: 2.38005987e-06
Iter: 939 loss: 2.37935183e-06
Iter: 940 loss: 2.37830568e-06
Iter: 941 loss: 2.39362e-06
Iter: 942 loss: 2.37832228e-06
Iter: 943 loss: 2.37764857e-06
Iter: 944 loss: 2.37676477e-06
Iter: 945 loss: 2.37671725e-06
Iter: 946 loss: 2.37596851e-06
Iter: 947 loss: 2.38503389e-06
Iter: 948 loss: 2.37597669e-06
Iter: 949 loss: 2.3750938e-06
Iter: 950 loss: 2.37674703e-06
Iter: 951 loss: 2.37477798e-06
Iter: 952 loss: 2.37404e-06
Iter: 953 loss: 2.37358677e-06
Iter: 954 loss: 2.37334143e-06
Iter: 955 loss: 2.37237828e-06
Iter: 956 loss: 2.3839707e-06
Iter: 957 loss: 2.37233144e-06
Iter: 958 loss: 2.37162249e-06
Iter: 959 loss: 2.3721509e-06
Iter: 960 loss: 2.37118502e-06
Iter: 961 loss: 2.37032509e-06
Iter: 962 loss: 2.36962615e-06
Iter: 963 loss: 2.36936035e-06
Iter: 964 loss: 2.36823598e-06
Iter: 965 loss: 2.37211407e-06
Iter: 966 loss: 2.3679122e-06
Iter: 967 loss: 2.36717779e-06
Iter: 968 loss: 2.36715846e-06
Iter: 969 loss: 2.36657411e-06
Iter: 970 loss: 2.36583719e-06
Iter: 971 loss: 2.36580331e-06
Iter: 972 loss: 2.36509095e-06
Iter: 973 loss: 2.3720745e-06
Iter: 974 loss: 2.36504638e-06
Iter: 975 loss: 2.36426422e-06
Iter: 976 loss: 2.36446726e-06
Iter: 977 loss: 2.36368e-06
Iter: 978 loss: 2.36278197e-06
Iter: 979 loss: 2.36223059e-06
Iter: 980 loss: 2.36185042e-06
Iter: 981 loss: 2.36116512e-06
Iter: 982 loss: 2.36094866e-06
Iter: 983 loss: 2.36033679e-06
Iter: 984 loss: 2.3593434e-06
Iter: 985 loss: 2.35934044e-06
Iter: 986 loss: 2.35838547e-06
Iter: 987 loss: 2.36452843e-06
Iter: 988 loss: 2.35826337e-06
Iter: 989 loss: 2.35722132e-06
Iter: 990 loss: 2.35888456e-06
Iter: 991 loss: 2.35675202e-06
Iter: 992 loss: 2.3556338e-06
Iter: 993 loss: 2.35720063e-06
Iter: 994 loss: 2.35512198e-06
Iter: 995 loss: 2.35424204e-06
Iter: 996 loss: 2.35423704e-06
Iter: 997 loss: 2.35350308e-06
Iter: 998 loss: 2.35259768e-06
Iter: 999 loss: 2.36432879e-06
Iter: 1000 loss: 2.35258017e-06
Iter: 1001 loss: 2.35167977e-06
Iter: 1002 loss: 2.35357948e-06
Iter: 1003 loss: 2.35130483e-06
Iter: 1004 loss: 2.35061589e-06
Iter: 1005 loss: 2.35072844e-06
Iter: 1006 loss: 2.35013385e-06
Iter: 1007 loss: 2.34933873e-06
Iter: 1008 loss: 2.3607945e-06
Iter: 1009 loss: 2.3493526e-06
Iter: 1010 loss: 2.34880895e-06
Iter: 1011 loss: 2.34787149e-06
Iter: 1012 loss: 2.34786626e-06
Iter: 1013 loss: 2.34718664e-06
Iter: 1014 loss: 2.34718027e-06
Iter: 1015 loss: 2.34644085e-06
Iter: 1016 loss: 2.34667732e-06
Iter: 1017 loss: 2.34591653e-06
Iter: 1018 loss: 2.34511481e-06
Iter: 1019 loss: 2.34525851e-06
Iter: 1020 loss: 2.34458616e-06
Iter: 1021 loss: 2.34364279e-06
Iter: 1022 loss: 2.35449102e-06
Iter: 1023 loss: 2.34363142e-06
Iter: 1024 loss: 2.34291497e-06
Iter: 1025 loss: 2.34268191e-06
Iter: 1026 loss: 2.34229105e-06
Iter: 1027 loss: 2.34128106e-06
Iter: 1028 loss: 2.34205345e-06
Iter: 1029 loss: 2.34064601e-06
Iter: 1030 loss: 2.3397422e-06
Iter: 1031 loss: 2.34288518e-06
Iter: 1032 loss: 2.33949982e-06
Iter: 1033 loss: 2.3388543e-06
Iter: 1034 loss: 2.33886431e-06
Iter: 1035 loss: 2.33834908e-06
Iter: 1036 loss: 2.33728701e-06
Iter: 1037 loss: 2.35320908e-06
Iter: 1038 loss: 2.3372595e-06
Iter: 1039 loss: 2.33622382e-06
Iter: 1040 loss: 2.35027255e-06
Iter: 1041 loss: 2.33623973e-06
Iter: 1042 loss: 2.33525316e-06
Iter: 1043 loss: 2.33557557e-06
Iter: 1044 loss: 2.3345583e-06
Iter: 1045 loss: 2.33352262e-06
Iter: 1046 loss: 2.33365517e-06
Iter: 1047 loss: 2.33271021e-06
Iter: 1048 loss: 2.33159972e-06
Iter: 1049 loss: 2.33156698e-06
Iter: 1050 loss: 2.3308894e-06
Iter: 1051 loss: 2.32971843e-06
Iter: 1052 loss: 2.35779e-06
Iter: 1053 loss: 2.32971706e-06
Iter: 1054 loss: 2.32892717e-06
Iter: 1055 loss: 2.32893171e-06
Iter: 1056 loss: 2.32826142e-06
Iter: 1057 loss: 2.32892216e-06
Iter: 1058 loss: 2.32787306e-06
Iter: 1059 loss: 2.32722778e-06
Iter: 1060 loss: 2.3277189e-06
Iter: 1061 loss: 2.32680554e-06
Iter: 1062 loss: 2.32593584e-06
Iter: 1063 loss: 2.32529874e-06
Iter: 1064 loss: 2.32502316e-06
Iter: 1065 loss: 2.32378648e-06
Iter: 1066 loss: 2.33996934e-06
Iter: 1067 loss: 2.3237626e-06
Iter: 1068 loss: 2.32259436e-06
Iter: 1069 loss: 2.32404818e-06
Iter: 1070 loss: 2.32192292e-06
Iter: 1071 loss: 2.32100774e-06
Iter: 1072 loss: 2.32172397e-06
Iter: 1073 loss: 2.32047023e-06
Iter: 1074 loss: 2.31912145e-06
Iter: 1075 loss: 2.32747789e-06
Iter: 1076 loss: 2.31897411e-06
Iter: 1077 loss: 2.31811828e-06
Iter: 1078 loss: 2.31775584e-06
Iter: 1079 loss: 2.3173161e-06
Iter: 1080 loss: 2.31685431e-06
Iter: 1081 loss: 2.31674539e-06
Iter: 1082 loss: 2.31616013e-06
Iter: 1083 loss: 2.3151224e-06
Iter: 1084 loss: 2.34021354e-06
Iter: 1085 loss: 2.31513218e-06
Iter: 1086 loss: 2.31422564e-06
Iter: 1087 loss: 2.31900867e-06
Iter: 1088 loss: 2.31408967e-06
Iter: 1089 loss: 2.31325089e-06
Iter: 1090 loss: 2.31833246e-06
Iter: 1091 loss: 2.31314789e-06
Iter: 1092 loss: 2.31257036e-06
Iter: 1093 loss: 2.31239324e-06
Iter: 1094 loss: 2.31203308e-06
Iter: 1095 loss: 2.31120703e-06
Iter: 1096 loss: 2.31240961e-06
Iter: 1097 loss: 2.31080526e-06
Iter: 1098 loss: 2.31002878e-06
Iter: 1099 loss: 2.31243257e-06
Iter: 1100 loss: 2.30980459e-06
Iter: 1101 loss: 2.30895739e-06
Iter: 1102 loss: 2.31665149e-06
Iter: 1103 loss: 2.30890328e-06
Iter: 1104 loss: 2.30831074e-06
Iter: 1105 loss: 2.30736418e-06
Iter: 1106 loss: 2.30737191e-06
Iter: 1107 loss: 2.30661726e-06
Iter: 1108 loss: 2.3065918e-06
Iter: 1109 loss: 2.30594628e-06
Iter: 1110 loss: 2.30477963e-06
Iter: 1111 loss: 2.30478122e-06
Iter: 1112 loss: 2.3038242e-06
Iter: 1113 loss: 2.31612762e-06
Iter: 1114 loss: 2.30383466e-06
Iter: 1115 loss: 2.30297337e-06
Iter: 1116 loss: 2.30773367e-06
Iter: 1117 loss: 2.30285968e-06
Iter: 1118 loss: 2.30241221e-06
Iter: 1119 loss: 2.30184332e-06
Iter: 1120 loss: 2.30180467e-06
Iter: 1121 loss: 2.30118917e-06
Iter: 1122 loss: 2.30119122e-06
Iter: 1123 loss: 2.30069918e-06
Iter: 1124 loss: 2.30022056e-06
Iter: 1125 loss: 2.30011892e-06
Iter: 1126 loss: 2.29927e-06
Iter: 1127 loss: 2.30018759e-06
Iter: 1128 loss: 2.29878583e-06
Iter: 1129 loss: 2.29772354e-06
Iter: 1130 loss: 2.2987906e-06
Iter: 1131 loss: 2.29711213e-06
Iter: 1132 loss: 2.29631632e-06
Iter: 1133 loss: 2.29630336e-06
Iter: 1134 loss: 2.29557736e-06
Iter: 1135 loss: 2.2948991e-06
Iter: 1136 loss: 2.2947022e-06
Iter: 1137 loss: 2.2938334e-06
Iter: 1138 loss: 2.298043e-06
Iter: 1139 loss: 2.29367333e-06
Iter: 1140 loss: 2.29263287e-06
Iter: 1141 loss: 2.2952604e-06
Iter: 1142 loss: 2.29230091e-06
Iter: 1143 loss: 2.29157286e-06
Iter: 1144 loss: 2.29177476e-06
Iter: 1145 loss: 2.29109833e-06
Iter: 1146 loss: 2.29043235e-06
Iter: 1147 loss: 2.29040847e-06
Iter: 1148 loss: 2.28994531e-06
Iter: 1149 loss: 2.28889712e-06
Iter: 1150 loss: 2.30524483e-06
Iter: 1151 loss: 2.28889303e-06
Iter: 1152 loss: 2.28839e-06
Iter: 1153 loss: 2.28835643e-06
Iter: 1154 loss: 2.28786189e-06
Iter: 1155 loss: 2.28768477e-06
Iter: 1156 loss: 2.28745967e-06
Iter: 1157 loss: 2.28674139e-06
Iter: 1158 loss: 2.28680869e-06
Iter: 1159 loss: 2.28620888e-06
Iter: 1160 loss: 2.28515705e-06
Iter: 1161 loss: 2.28628323e-06
Iter: 1162 loss: 2.28457475e-06
Iter: 1163 loss: 2.28364979e-06
Iter: 1164 loss: 2.29500938e-06
Iter: 1165 loss: 2.28360886e-06
Iter: 1166 loss: 2.28278395e-06
Iter: 1167 loss: 2.28466752e-06
Iter: 1168 loss: 2.28248086e-06
Iter: 1169 loss: 2.28173758e-06
Iter: 1170 loss: 2.2816912e-06
Iter: 1171 loss: 2.281153e-06
Iter: 1172 loss: 2.28027238e-06
Iter: 1173 loss: 2.29172201e-06
Iter: 1174 loss: 2.28026965e-06
Iter: 1175 loss: 2.27969235e-06
Iter: 1176 loss: 2.27883584e-06
Iter: 1177 loss: 2.27884129e-06
Iter: 1178 loss: 2.2785207e-06
Iter: 1179 loss: 2.27833289e-06
Iter: 1180 loss: 2.27790179e-06
Iter: 1181 loss: 2.27721603e-06
Iter: 1182 loss: 2.27719033e-06
Iter: 1183 loss: 2.27651208e-06
Iter: 1184 loss: 2.27869805e-06
Iter: 1185 loss: 2.27631176e-06
Iter: 1186 loss: 2.27546207e-06
Iter: 1187 loss: 2.27883584e-06
Iter: 1188 loss: 2.27530109e-06
Iter: 1189 loss: 2.27461055e-06
Iter: 1190 loss: 2.27423425e-06
Iter: 1191 loss: 2.27393912e-06
Iter: 1192 loss: 2.27289456e-06
Iter: 1193 loss: 2.27485111e-06
Iter: 1194 loss: 2.27240707e-06
Iter: 1195 loss: 2.2714687e-06
Iter: 1196 loss: 2.27601572e-06
Iter: 1197 loss: 2.27131454e-06
Iter: 1198 loss: 2.27047735e-06
Iter: 1199 loss: 2.27816827e-06
Iter: 1200 loss: 2.27044643e-06
Iter: 1201 loss: 2.26986276e-06
Iter: 1202 loss: 2.2695574e-06
Iter: 1203 loss: 2.26927591e-06
Iter: 1204 loss: 2.26873362e-06
Iter: 1205 loss: 2.27698729e-06
Iter: 1206 loss: 2.26874818e-06
Iter: 1207 loss: 2.26822522e-06
Iter: 1208 loss: 2.26762586e-06
Iter: 1209 loss: 2.26757948e-06
Iter: 1210 loss: 2.26698967e-06
Iter: 1211 loss: 2.2738709e-06
Iter: 1212 loss: 2.26696852e-06
Iter: 1213 loss: 2.26634484e-06
Iter: 1214 loss: 2.2671943e-06
Iter: 1215 loss: 2.26598058e-06
Iter: 1216 loss: 2.26553539e-06
Iter: 1217 loss: 2.26534894e-06
Iter: 1218 loss: 2.26505e-06
Iter: 1219 loss: 2.26435282e-06
Iter: 1220 loss: 2.27191231e-06
Iter: 1221 loss: 2.26431257e-06
Iter: 1222 loss: 2.26372185e-06
Iter: 1223 loss: 2.26299289e-06
Iter: 1224 loss: 2.26291559e-06
Iter: 1225 loss: 2.2619738e-06
Iter: 1226 loss: 2.26537077e-06
Iter: 1227 loss: 2.26170937e-06
Iter: 1228 loss: 2.26092379e-06
Iter: 1229 loss: 2.26251905e-06
Iter: 1230 loss: 2.26058319e-06
Iter: 1231 loss: 2.26015163e-06
Iter: 1232 loss: 2.26011707e-06
Iter: 1233 loss: 2.25973e-06
Iter: 1234 loss: 2.25932968e-06
Iter: 1235 loss: 2.25925851e-06
Iter: 1236 loss: 2.25876e-06
Iter: 1237 loss: 2.262105e-06
Iter: 1238 loss: 2.25870394e-06
Iter: 1239 loss: 2.25814074e-06
Iter: 1240 loss: 2.2587476e-06
Iter: 1241 loss: 2.25787562e-06
Iter: 1242 loss: 2.25734811e-06
Iter: 1243 loss: 2.25774261e-06
Iter: 1244 loss: 2.25698341e-06
Iter: 1245 loss: 2.25629447e-06
Iter: 1246 loss: 2.26449038e-06
Iter: 1247 loss: 2.2562815e-06
Iter: 1248 loss: 2.25585973e-06
Iter: 1249 loss: 2.25502072e-06
Iter: 1250 loss: 2.26949624e-06
Iter: 1251 loss: 2.25500298e-06
Iter: 1252 loss: 2.25452709e-06
Iter: 1253 loss: 2.25444819e-06
Iter: 1254 loss: 2.25401777e-06
Iter: 1255 loss: 2.2541185e-06
Iter: 1256 loss: 2.25367785e-06
Iter: 1257 loss: 2.2532422e-06
Iter: 1258 loss: 2.25363056e-06
Iter: 1259 loss: 2.2529714e-06
Iter: 1260 loss: 2.25238387e-06
Iter: 1261 loss: 2.25277813e-06
Iter: 1262 loss: 2.25198482e-06
Iter: 1263 loss: 2.25139183e-06
Iter: 1264 loss: 2.25619624e-06
Iter: 1265 loss: 2.25137819e-06
Iter: 1266 loss: 2.25069903e-06
Iter: 1267 loss: 2.2526674e-06
Iter: 1268 loss: 2.2505028e-06
Iter: 1269 loss: 2.25003532e-06
Iter: 1270 loss: 2.25044141e-06
Iter: 1271 loss: 2.24976361e-06
Iter: 1272 loss: 2.24919e-06
Iter: 1273 loss: 2.25324902e-06
Iter: 1274 loss: 2.24911719e-06
Iter: 1275 loss: 2.24870791e-06
Iter: 1276 loss: 2.24839141e-06
Iter: 1277 loss: 2.2482327e-06
Iter: 1278 loss: 2.24786845e-06
Iter: 1279 loss: 2.2478057e-06
Iter: 1280 loss: 2.24750511e-06
Iter: 1281 loss: 2.24676523e-06
Iter: 1282 loss: 2.25644521e-06
Iter: 1283 loss: 2.24672613e-06
Iter: 1284 loss: 2.24605947e-06
Iter: 1285 loss: 2.25013378e-06
Iter: 1286 loss: 2.24592782e-06
Iter: 1287 loss: 2.24512814e-06
Iter: 1288 loss: 2.24762039e-06
Iter: 1289 loss: 2.244896e-06
Iter: 1290 loss: 2.24429823e-06
Iter: 1291 loss: 2.24458086e-06
Iter: 1292 loss: 2.24390874e-06
Iter: 1293 loss: 2.24330051e-06
Iter: 1294 loss: 2.24503174e-06
Iter: 1295 loss: 2.24315613e-06
Iter: 1296 loss: 2.24254291e-06
Iter: 1297 loss: 2.2427148e-06
Iter: 1298 loss: 2.24210225e-06
Iter: 1299 loss: 2.24146061e-06
Iter: 1300 loss: 2.24144515e-06
Iter: 1301 loss: 2.24099585e-06
Iter: 1302 loss: 2.24026508e-06
Iter: 1303 loss: 2.24025507e-06
Iter: 1304 loss: 2.23949701e-06
Iter: 1305 loss: 2.25002782e-06
Iter: 1306 loss: 2.23949723e-06
Iter: 1307 loss: 2.23890811e-06
Iter: 1308 loss: 2.23850316e-06
Iter: 1309 loss: 2.23827237e-06
Iter: 1310 loss: 2.23777761e-06
Iter: 1311 loss: 2.23776237e-06
Iter: 1312 loss: 2.23726602e-06
Iter: 1313 loss: 2.23681286e-06
Iter: 1314 loss: 2.23669031e-06
Iter: 1315 loss: 2.23611733e-06
Iter: 1316 loss: 2.23752363e-06
Iter: 1317 loss: 2.23595089e-06
Iter: 1318 loss: 2.23542384e-06
Iter: 1319 loss: 2.24070982e-06
Iter: 1320 loss: 2.23545112e-06
Iter: 1321 loss: 2.23513348e-06
Iter: 1322 loss: 2.23474854e-06
Iter: 1323 loss: 2.23470215e-06
Iter: 1324 loss: 2.23407596e-06
Iter: 1325 loss: 2.23477491e-06
Iter: 1326 loss: 2.2337515e-06
Iter: 1327 loss: 2.23292818e-06
Iter: 1328 loss: 2.23422421e-06
Iter: 1329 loss: 2.23254165e-06
Iter: 1330 loss: 2.2318809e-06
Iter: 1331 loss: 2.23188954e-06
Iter: 1332 loss: 2.23119196e-06
Iter: 1333 loss: 2.23062125e-06
Iter: 1334 loss: 2.23045663e-06
Iter: 1335 loss: 2.22974268e-06
Iter: 1336 loss: 2.23740449e-06
Iter: 1337 loss: 2.22974177e-06
Iter: 1338 loss: 2.22918879e-06
Iter: 1339 loss: 2.22990138e-06
Iter: 1340 loss: 2.22885046e-06
Iter: 1341 loss: 2.22839549e-06
Iter: 1342 loss: 2.23075017e-06
Iter: 1343 loss: 2.22830931e-06
Iter: 1344 loss: 2.22777794e-06
Iter: 1345 loss: 2.22884364e-06
Iter: 1346 loss: 2.22754852e-06
Iter: 1347 loss: 2.22713197e-06
Iter: 1348 loss: 2.2268564e-06
Iter: 1349 loss: 2.22670178e-06
Iter: 1350 loss: 2.22619155e-06
Iter: 1351 loss: 2.23370853e-06
Iter: 1352 loss: 2.22618041e-06
Iter: 1353 loss: 2.22575818e-06
Iter: 1354 loss: 2.22523045e-06
Iter: 1355 loss: 2.22520475e-06
Iter: 1356 loss: 2.22447625e-06
Iter: 1357 loss: 2.22633435e-06
Iter: 1358 loss: 2.22421249e-06
Iter: 1359 loss: 2.2235497e-06
Iter: 1360 loss: 2.22505787e-06
Iter: 1361 loss: 2.22328026e-06
Iter: 1362 loss: 2.2226e-06
Iter: 1363 loss: 2.22605786e-06
Iter: 1364 loss: 2.22247877e-06
Iter: 1365 loss: 2.22168865e-06
Iter: 1366 loss: 2.22531617e-06
Iter: 1367 loss: 2.2215736e-06
Iter: 1368 loss: 2.22109293e-06
Iter: 1369 loss: 2.22115114e-06
Iter: 1370 loss: 2.22074391e-06
Iter: 1371 loss: 2.21998835e-06
Iter: 1372 loss: 2.22379731e-06
Iter: 1373 loss: 2.21982282e-06
Iter: 1374 loss: 2.21930782e-06
Iter: 1375 loss: 2.21984237e-06
Iter: 1376 loss: 2.21900086e-06
Iter: 1377 loss: 2.21838582e-06
Iter: 1378 loss: 2.22532481e-06
Iter: 1379 loss: 2.21836899e-06
Iter: 1380 loss: 2.21799246e-06
Iter: 1381 loss: 2.21746473e-06
Iter: 1382 loss: 2.21745881e-06
Iter: 1383 loss: 2.21702021e-06
Iter: 1384 loss: 2.21699793e-06
Iter: 1385 loss: 2.21661094e-06
Iter: 1386 loss: 2.21631285e-06
Iter: 1387 loss: 2.21617029e-06
Iter: 1388 loss: 2.21559139e-06
Iter: 1389 loss: 2.21616665e-06
Iter: 1390 loss: 2.21525443e-06
Iter: 1391 loss: 2.21451501e-06
Iter: 1392 loss: 2.21577511e-06
Iter: 1393 loss: 2.21419327e-06
Iter: 1394 loss: 2.21338769e-06
Iter: 1395 loss: 2.21659911e-06
Iter: 1396 loss: 2.21321784e-06
Iter: 1397 loss: 2.21259461e-06
Iter: 1398 loss: 2.22192193e-06
Iter: 1399 loss: 2.21260461e-06
Iter: 1400 loss: 2.21220739e-06
Iter: 1401 loss: 2.21180744e-06
Iter: 1402 loss: 2.21174037e-06
Iter: 1403 loss: 2.21119444e-06
Iter: 1404 loss: 2.21821642e-06
Iter: 1405 loss: 2.21120627e-06
Iter: 1406 loss: 2.21084701e-06
Iter: 1407 loss: 2.21044411e-06
Iter: 1408 loss: 2.21033952e-06
Iter: 1409 loss: 2.20999345e-06
Iter: 1410 loss: 2.20995207e-06
Iter: 1411 loss: 2.2096674e-06
Iter: 1412 loss: 2.20919401e-06
Iter: 1413 loss: 2.22075505e-06
Iter: 1414 loss: 2.2091815e-06
Iter: 1415 loss: 2.20873972e-06
Iter: 1416 loss: 2.21338519e-06
Iter: 1417 loss: 2.20871948e-06
Iter: 1418 loss: 2.20833908e-06
Iter: 1419 loss: 2.20836523e-06
Iter: 1420 loss: 2.20802031e-06
Iter: 1421 loss: 2.20757e-06
Iter: 1422 loss: 2.20791435e-06
Iter: 1423 loss: 2.20728725e-06
Iter: 1424 loss: 2.20663651e-06
Iter: 1425 loss: 2.20724223e-06
Iter: 1426 loss: 2.20628749e-06
Iter: 1427 loss: 2.20544098e-06
Iter: 1428 loss: 2.20798688e-06
Iter: 1429 loss: 2.20520724e-06
Iter: 1430 loss: 2.20469929e-06
Iter: 1431 loss: 2.20466791e-06
Iter: 1432 loss: 2.20426023e-06
Iter: 1433 loss: 2.20389302e-06
Iter: 1434 loss: 2.20379343e-06
Iter: 1435 loss: 2.20339757e-06
Iter: 1436 loss: 2.2033978e-06
Iter: 1437 loss: 2.20309948e-06
Iter: 1438 loss: 2.20298443e-06
Iter: 1439 loss: 2.20281e-06
Iter: 1440 loss: 2.20252196e-06
Iter: 1441 loss: 2.20251832e-06
Iter: 1442 loss: 2.20224729e-06
Iter: 1443 loss: 2.20174752e-06
Iter: 1444 loss: 2.21393134e-06
Iter: 1445 loss: 2.20175207e-06
Iter: 1446 loss: 2.20129891e-06
Iter: 1447 loss: 2.20489846e-06
Iter: 1448 loss: 2.20122661e-06
Iter: 1449 loss: 2.20078141e-06
Iter: 1450 loss: 2.20088486e-06
Iter: 1451 loss: 2.20043739e-06
Iter: 1452 loss: 2.19984327e-06
Iter: 1453 loss: 2.19973936e-06
Iter: 1454 loss: 2.19932326e-06
Iter: 1455 loss: 2.19850517e-06
Iter: 1456 loss: 2.20274228e-06
Iter: 1457 loss: 2.19838171e-06
Iter: 1458 loss: 2.19781487e-06
Iter: 1459 loss: 2.20002676e-06
Iter: 1460 loss: 2.19765411e-06
Iter: 1461 loss: 2.19728463e-06
Iter: 1462 loss: 2.20136144e-06
Iter: 1463 loss: 2.19723961e-06
Iter: 1464 loss: 2.19685e-06
Iter: 1465 loss: 2.19694289e-06
Iter: 1466 loss: 2.19654748e-06
Iter: 1467 loss: 2.19617e-06
Iter: 1468 loss: 2.19804588e-06
Iter: 1469 loss: 2.19609979e-06
Iter: 1470 loss: 2.19565095e-06
Iter: 1471 loss: 2.19585536e-06
Iter: 1472 loss: 2.19536605e-06
Iter: 1473 loss: 2.19496042e-06
Iter: 1474 loss: 2.19919821e-06
Iter: 1475 loss: 2.19495541e-06
Iter: 1476 loss: 2.19456979e-06
Iter: 1477 loss: 2.19445883e-06
Iter: 1478 loss: 2.1941969e-06
Iter: 1479 loss: 2.19384719e-06
Iter: 1480 loss: 2.19559161e-06
Iter: 1481 loss: 2.19375238e-06
Iter: 1482 loss: 2.19335129e-06
Iter: 1483 loss: 2.1940225e-06
Iter: 1484 loss: 2.19314529e-06
Iter: 1485 loss: 2.19271305e-06
Iter: 1486 loss: 2.19252934e-06
Iter: 1487 loss: 2.19230014e-06
Iter: 1488 loss: 2.1917192e-06
Iter: 1489 loss: 2.19398862e-06
Iter: 1490 loss: 2.19160074e-06
Iter: 1491 loss: 2.19100593e-06
Iter: 1492 loss: 2.19171307e-06
Iter: 1493 loss: 2.19065578e-06
Iter: 1494 loss: 2.19010781e-06
Iter: 1495 loss: 2.19607841e-06
Iter: 1496 loss: 2.19007552e-06
Iter: 1497 loss: 2.18959644e-06
Iter: 1498 loss: 2.19174672e-06
Iter: 1499 loss: 2.18953301e-06
Iter: 1500 loss: 2.18921491e-06
Iter: 1501 loss: 2.18934565e-06
Iter: 1502 loss: 2.18901232e-06
Iter: 1503 loss: 2.18856258e-06
Iter: 1504 loss: 2.19089475e-06
Iter: 1505 loss: 2.18846935e-06
Iter: 1506 loss: 2.1882388e-06
Iter: 1507 loss: 2.18889613e-06
Iter: 1508 loss: 2.18815285e-06
Iter: 1509 loss: 2.18775267e-06
Iter: 1510 loss: 2.18860418e-06
Iter: 1511 loss: 2.18763535e-06
Iter: 1512 loss: 2.18734772e-06
Iter: 1513 loss: 2.18718401e-06
Iter: 1514 loss: 2.18701939e-06
Iter: 1515 loss: 2.18640389e-06
Iter: 1516 loss: 2.18860896e-06
Iter: 1517 loss: 2.18623882e-06
Iter: 1518 loss: 2.18567629e-06
Iter: 1519 loss: 2.18492414e-06
Iter: 1520 loss: 2.18486935e-06
Iter: 1521 loss: 2.18384707e-06
Iter: 1522 loss: 2.18810987e-06
Iter: 1523 loss: 2.18364403e-06
Iter: 1524 loss: 2.18288187e-06
Iter: 1525 loss: 2.18672267e-06
Iter: 1526 loss: 2.18274386e-06
Iter: 1527 loss: 2.18230821e-06
Iter: 1528 loss: 2.18546529e-06
Iter: 1529 loss: 2.18226069e-06
Iter: 1530 loss: 2.18184096e-06
Iter: 1531 loss: 2.18435093e-06
Iter: 1532 loss: 2.18179821e-06
Iter: 1533 loss: 2.18147807e-06
Iter: 1534 loss: 2.18121295e-06
Iter: 1535 loss: 2.18111245e-06
Iter: 1536 loss: 2.18064e-06
Iter: 1537 loss: 2.18542186e-06
Iter: 1538 loss: 2.18063315e-06
Iter: 1539 loss: 2.18028481e-06
Iter: 1540 loss: 2.18011064e-06
Iter: 1541 loss: 2.17994307e-06
Iter: 1542 loss: 2.179386e-06
Iter: 1543 loss: 2.18489072e-06
Iter: 1544 loss: 2.17935349e-06
Iter: 1545 loss: 2.17902152e-06
Iter: 1546 loss: 2.17849765e-06
Iter: 1547 loss: 2.17846332e-06
Iter: 1548 loss: 2.17788897e-06
Iter: 1549 loss: 2.18522837e-06
Iter: 1550 loss: 2.17786351e-06
Iter: 1551 loss: 2.17744309e-06
Iter: 1552 loss: 2.17698607e-06
Iter: 1553 loss: 2.17694014e-06
Iter: 1554 loss: 2.17629668e-06
Iter: 1555 loss: 2.17778552e-06
Iter: 1556 loss: 2.17607135e-06
Iter: 1557 loss: 2.17543607e-06
Iter: 1558 loss: 2.1774606e-06
Iter: 1559 loss: 2.17525212e-06
Iter: 1560 loss: 2.17468323e-06
Iter: 1561 loss: 2.17641218e-06
Iter: 1562 loss: 2.17448769e-06
Iter: 1563 loss: 2.17401839e-06
Iter: 1564 loss: 2.18023024e-06
Iter: 1565 loss: 2.17404886e-06
Iter: 1566 loss: 2.17367142e-06
Iter: 1567 loss: 2.17335037e-06
Iter: 1568 loss: 2.17324373e-06
Iter: 1569 loss: 2.17273396e-06
Iter: 1570 loss: 2.17718571e-06
Iter: 1571 loss: 2.17273191e-06
Iter: 1572 loss: 2.17227898e-06
Iter: 1573 loss: 2.17196043e-06
Iter: 1574 loss: 2.17178149e-06
Iter: 1575 loss: 2.171284e-06
Iter: 1576 loss: 2.17129445e-06
Iter: 1577 loss: 2.17087882e-06
Iter: 1578 loss: 2.17014735e-06
Iter: 1579 loss: 2.18534296e-06
Iter: 1580 loss: 2.17014144e-06
Iter: 1581 loss: 2.16963372e-06
Iter: 1582 loss: 2.16962553e-06
Iter: 1583 loss: 2.16925832e-06
Iter: 1584 loss: 2.16871899e-06
Iter: 1585 loss: 2.16869012e-06
Iter: 1586 loss: 2.16805438e-06
Iter: 1587 loss: 2.16900253e-06
Iter: 1588 loss: 2.16776562e-06
Iter: 1589 loss: 2.1671292e-06
Iter: 1590 loss: 2.17001025e-06
Iter: 1591 loss: 2.16700255e-06
Iter: 1592 loss: 2.16650687e-06
Iter: 1593 loss: 2.16769331e-06
Iter: 1594 loss: 2.16631315e-06
Iter: 1595 loss: 2.16585795e-06
Iter: 1596 loss: 2.17009892e-06
Iter: 1597 loss: 2.16581179e-06
Iter: 1598 loss: 2.16538456e-06
Iter: 1599 loss: 2.16549938e-06
Iter: 1600 loss: 2.16509261e-06
Iter: 1601 loss: 2.1645692e-06
Iter: 1602 loss: 2.16685817e-06
Iter: 1603 loss: 2.16448052e-06
Iter: 1604 loss: 2.1639969e-06
Iter: 1605 loss: 2.1646465e-06
Iter: 1606 loss: 2.16371927e-06
Iter: 1607 loss: 2.16333183e-06
Iter: 1608 loss: 2.16756371e-06
Iter: 1609 loss: 2.1633e-06
Iter: 1610 loss: 2.16286753e-06
Iter: 1611 loss: 2.16240255e-06
Iter: 1612 loss: 2.16232479e-06
Iter: 1613 loss: 2.16182821e-06
Iter: 1614 loss: 2.16591502e-06
Iter: 1615 loss: 2.16180024e-06
Iter: 1616 loss: 2.16126136e-06
Iter: 1617 loss: 2.16100352e-06
Iter: 1618 loss: 2.16076705e-06
Iter: 1619 loss: 2.16015314e-06
Iter: 1620 loss: 2.16111539e-06
Iter: 1621 loss: 2.159833e-06
Iter: 1622 loss: 2.15925456e-06
Iter: 1623 loss: 2.16147873e-06
Iter: 1624 loss: 2.1591211e-06
Iter: 1625 loss: 2.15858859e-06
Iter: 1626 loss: 2.15976661e-06
Iter: 1627 loss: 2.15837736e-06
Iter: 1628 loss: 2.15791079e-06
Iter: 1629 loss: 2.16311673e-06
Iter: 1630 loss: 2.15790624e-06
Iter: 1631 loss: 2.15747013e-06
Iter: 1632 loss: 2.15814e-06
Iter: 1633 loss: 2.15725595e-06
Iter: 1634 loss: 2.1568369e-06
Iter: 1635 loss: 2.15722457e-06
Iter: 1636 loss: 2.15657565e-06
Iter: 1637 loss: 2.15589534e-06
Iter: 1638 loss: 2.15772593e-06
Iter: 1639 loss: 2.15566706e-06
Iter: 1640 loss: 2.15503928e-06
Iter: 1641 loss: 2.15755e-06
Iter: 1642 loss: 2.15492537e-06
Iter: 1643 loss: 2.15421255e-06
Iter: 1644 loss: 2.15544082e-06
Iter: 1645 loss: 2.15390196e-06
Iter: 1646 loss: 2.1534297e-06
Iter: 1647 loss: 2.15426257e-06
Iter: 1648 loss: 2.1532046e-06
Iter: 1649 loss: 2.15256296e-06
Iter: 1650 loss: 2.15502769e-06
Iter: 1651 loss: 2.1524e-06
Iter: 1652 loss: 2.15200362e-06
Iter: 1653 loss: 2.15163845e-06
Iter: 1654 loss: 2.15151658e-06
Iter: 1655 loss: 2.15090904e-06
Iter: 1656 loss: 2.15283967e-06
Iter: 1657 loss: 2.15074533e-06
Iter: 1658 loss: 2.15011323e-06
Iter: 1659 loss: 2.1515973e-06
Iter: 1660 loss: 2.14988449e-06
Iter: 1661 loss: 2.14925967e-06
Iter: 1662 loss: 2.15335785e-06
Iter: 1663 loss: 2.14922761e-06
Iter: 1664 loss: 2.14859392e-06
Iter: 1665 loss: 2.15023488e-06
Iter: 1666 loss: 2.14840315e-06
Iter: 1667 loss: 2.14781e-06
Iter: 1668 loss: 2.14857255e-06
Iter: 1669 loss: 2.14751617e-06
Iter: 1670 loss: 2.14694091e-06
Iter: 1671 loss: 2.15148248e-06
Iter: 1672 loss: 2.14691931e-06
Iter: 1673 loss: 2.14654415e-06
Iter: 1674 loss: 2.14709803e-06
Iter: 1675 loss: 2.14634565e-06
Iter: 1676 loss: 2.14585816e-06
Iter: 1677 loss: 2.14833176e-06
Iter: 1678 loss: 2.1457713e-06
Iter: 1679 loss: 2.1454091e-06
Iter: 1680 loss: 2.14500346e-06
Iter: 1681 loss: 2.14494821e-06
Iter: 1682 loss: 2.14433862e-06
Iter: 1683 loss: 2.15155478e-06
Iter: 1684 loss: 2.14432566e-06
Iter: 1685 loss: 2.14397824e-06
Iter: 1686 loss: 2.14339343e-06
Iter: 1687 loss: 2.14339343e-06
Iter: 1688 loss: 2.14277588e-06
Iter: 1689 loss: 2.14568399e-06
Iter: 1690 loss: 2.14265083e-06
Iter: 1691 loss: 2.14211832e-06
Iter: 1692 loss: 2.14392253e-06
Iter: 1693 loss: 2.1419628e-06
Iter: 1694 loss: 2.14149168e-06
Iter: 1695 loss: 2.14351576e-06
Iter: 1696 loss: 2.1413739e-06
Iter: 1697 loss: 2.1408905e-06
Iter: 1698 loss: 2.14342708e-06
Iter: 1699 loss: 2.14082343e-06
Iter: 1700 loss: 2.14042529e-06
Iter: 1701 loss: 2.1406322e-06
Iter: 1702 loss: 2.14016018e-06
Iter: 1703 loss: 2.13964e-06
Iter: 1704 loss: 2.1423707e-06
Iter: 1705 loss: 2.13954581e-06
Iter: 1706 loss: 2.13909516e-06
Iter: 1707 loss: 2.1394444e-06
Iter: 1708 loss: 2.13882504e-06
Iter: 1709 loss: 2.1383114e-06
Iter: 1710 loss: 2.14445231e-06
Iter: 1711 loss: 2.1383089e-06
Iter: 1712 loss: 2.13799285e-06
Iter: 1713 loss: 2.13756357e-06
Iter: 1714 loss: 2.13752583e-06
Iter: 1715 loss: 2.13715703e-06
Iter: 1716 loss: 2.13713747e-06
Iter: 1717 loss: 2.13683143e-06
Iter: 1718 loss: 2.13627663e-06
Iter: 1719 loss: 2.14703596e-06
Iter: 1720 loss: 2.13624912e-06
Iter: 1721 loss: 2.13560475e-06
Iter: 1722 loss: 2.13773978e-06
Iter: 1723 loss: 2.13543e-06
Iter: 1724 loss: 2.13478324e-06
Iter: 1725 loss: 2.13642761e-06
Iter: 1726 loss: 2.1345586e-06
Iter: 1727 loss: 2.13384124e-06
Iter: 1728 loss: 2.13660724e-06
Iter: 1729 loss: 2.13371868e-06
Iter: 1730 loss: 2.13301018e-06
Iter: 1731 loss: 2.13925796e-06
Iter: 1732 loss: 2.13301064e-06
Iter: 1733 loss: 2.1324945e-06
Iter: 1734 loss: 2.13258386e-06
Iter: 1735 loss: 2.13213571e-06
Iter: 1736 loss: 2.13161775e-06
Iter: 1737 loss: 2.13589101e-06
Iter: 1738 loss: 2.13155977e-06
Iter: 1739 loss: 2.13115527e-06
Iter: 1740 loss: 2.13189446e-06
Iter: 1741 loss: 2.13100293e-06
Iter: 1742 loss: 2.1306837e-06
Iter: 1743 loss: 2.13480075e-06
Iter: 1744 loss: 2.13067597e-06
Iter: 1745 loss: 2.13044814e-06
Iter: 1746 loss: 2.13003909e-06
Iter: 1747 loss: 2.1300466e-06
Iter: 1748 loss: 2.1296737e-06
Iter: 1749 loss: 2.1343576e-06
Iter: 1750 loss: 2.12967461e-06
Iter: 1751 loss: 2.12930627e-06
Iter: 1752 loss: 2.12877217e-06
Iter: 1753 loss: 2.12877467e-06
Iter: 1754 loss: 2.12822488e-06
Iter: 1755 loss: 2.12904069e-06
Iter: 1756 loss: 2.12793202e-06
Iter: 1757 loss: 2.12724444e-06
Iter: 1758 loss: 2.12928717e-06
Iter: 1759 loss: 2.12701548e-06
Iter: 1760 loss: 2.12633222e-06
Iter: 1761 loss: 2.128088e-06
Iter: 1762 loss: 2.12608302e-06
Iter: 1763 loss: 2.12557734e-06
Iter: 1764 loss: 2.1255596e-06
Iter: 1765 loss: 2.12522082e-06
Iter: 1766 loss: 2.12511168e-06
Iter: 1767 loss: 2.12490431e-06
Iter: 1768 loss: 2.12448185e-06
Iter: 1769 loss: 2.12684313e-06
Iter: 1770 loss: 2.12439295e-06
Iter: 1771 loss: 2.12399186e-06
Iter: 1772 loss: 2.12480154e-06
Iter: 1773 loss: 2.12383475e-06
Iter: 1774 loss: 2.12351483e-06
Iter: 1775 loss: 2.12672694e-06
Iter: 1776 loss: 2.12350915e-06
Iter: 1777 loss: 2.12320242e-06
Iter: 1778 loss: 2.12286727e-06
Iter: 1779 loss: 2.12284635e-06
Iter: 1780 loss: 2.12243594e-06
Iter: 1781 loss: 2.12527266e-06
Iter: 1782 loss: 2.12242071e-06
Iter: 1783 loss: 2.12198461e-06
Iter: 1784 loss: 2.12189548e-06
Iter: 1785 loss: 2.12163604e-06
Iter: 1786 loss: 2.12115901e-06
Iter: 1787 loss: 2.12086411e-06
Iter: 1788 loss: 2.12067425e-06
Iter: 1789 loss: 2.11989254e-06
Iter: 1790 loss: 2.12302734e-06
Iter: 1791 loss: 2.119702e-06
Iter: 1792 loss: 2.11905262e-06
Iter: 1793 loss: 2.12148257e-06
Iter: 1794 loss: 2.11887937e-06
Iter: 1795 loss: 2.11845054e-06
Iter: 1796 loss: 2.12464192e-06
Iter: 1797 loss: 2.11844781e-06
Iter: 1798 loss: 2.1180233e-06
Iter: 1799 loss: 2.11822044e-06
Iter: 1800 loss: 2.11773295e-06
Iter: 1801 loss: 2.11733686e-06
Iter: 1802 loss: 2.11934434e-06
Iter: 1803 loss: 2.11727934e-06
Iter: 1804 loss: 2.11691463e-06
Iter: 1805 loss: 2.11794304e-06
Iter: 1806 loss: 2.1168039e-06
Iter: 1807 loss: 2.11649353e-06
Iter: 1808 loss: 2.11804763e-06
Iter: 1809 loss: 2.11645897e-06
Iter: 1810 loss: 2.11611041e-06
Iter: 1811 loss: 2.1161195e-06
Iter: 1812 loss: 2.11581664e-06
Iter: 1813 loss: 2.11547558e-06
Iter: 1814 loss: 2.1164044e-06
Iter: 1815 loss: 2.1153628e-06
Iter: 1816 loss: 2.11490556e-06
Iter: 1817 loss: 2.11637234e-06
Iter: 1818 loss: 2.11480142e-06
Iter: 1819 loss: 2.11448969e-06
Iter: 1820 loss: 2.11392239e-06
Iter: 1821 loss: 2.11391762e-06
Iter: 1822 loss: 2.11323095e-06
Iter: 1823 loss: 2.11633414e-06
Iter: 1824 loss: 2.1130852e-06
Iter: 1825 loss: 2.11242491e-06
Iter: 1826 loss: 2.1138087e-06
Iter: 1827 loss: 2.11215865e-06
Iter: 1828 loss: 2.11150495e-06
Iter: 1829 loss: 2.11540328e-06
Iter: 1830 loss: 2.11141059e-06
Iter: 1831 loss: 2.11085126e-06
Iter: 1832 loss: 2.11544852e-06
Iter: 1833 loss: 2.11079214e-06
Iter: 1834 loss: 2.11048473e-06
Iter: 1835 loss: 2.11070687e-06
Iter: 1836 loss: 2.11029919e-06
Iter: 1837 loss: 2.1098358e-06
Iter: 1838 loss: 2.11127826e-06
Iter: 1839 loss: 2.10973394e-06
Iter: 1840 loss: 2.10933013e-06
Iter: 1841 loss: 2.11058068e-06
Iter: 1842 loss: 2.10919984e-06
Iter: 1843 loss: 2.10875714e-06
Iter: 1844 loss: 2.11008592e-06
Iter: 1845 loss: 2.10858889e-06
Iter: 1846 loss: 2.1082169e-06
Iter: 1847 loss: 2.10781673e-06
Iter: 1848 loss: 2.10773987e-06
Iter: 1849 loss: 2.10700023e-06
Iter: 1850 loss: 2.1130968e-06
Iter: 1851 loss: 2.10697385e-06
Iter: 1852 loss: 2.1064202e-06
Iter: 1853 loss: 2.10545204e-06
Iter: 1854 loss: 2.12863574e-06
Iter: 1855 loss: 2.10544954e-06
Iter: 1856 loss: 2.10448343e-06
Iter: 1857 loss: 2.1088938e-06
Iter: 1858 loss: 2.10431472e-06
Iter: 1859 loss: 2.10350186e-06
Iter: 1860 loss: 2.10742519e-06
Iter: 1861 loss: 2.10336952e-06
Iter: 1862 loss: 2.10279472e-06
Iter: 1863 loss: 2.10491226e-06
Iter: 1864 loss: 2.10263352e-06
Iter: 1865 loss: 2.10221651e-06
Iter: 1866 loss: 2.10221515e-06
Iter: 1867 loss: 2.10192479e-06
Iter: 1868 loss: 2.10162125e-06
Iter: 1869 loss: 2.10156213e-06
Iter: 1870 loss: 2.10107237e-06
Iter: 1871 loss: 2.10441794e-06
Iter: 1872 loss: 2.10102644e-06
Iter: 1873 loss: 2.10057988e-06
Iter: 1874 loss: 2.10101962e-06
Iter: 1875 loss: 2.10034887e-06
Iter: 1876 loss: 2.0997727e-06
Iter: 1877 loss: 2.10291364e-06
Iter: 1878 loss: 2.0997029e-06
Iter: 1879 loss: 2.09927339e-06
Iter: 1880 loss: 2.09869131e-06
Iter: 1881 loss: 2.09863538e-06
Iter: 1882 loss: 2.09810196e-06
Iter: 1883 loss: 2.09811196e-06
Iter: 1884 loss: 2.09769178e-06
Iter: 1885 loss: 2.09707241e-06
Iter: 1886 loss: 2.09704535e-06
Iter: 1887 loss: 2.09631526e-06
Iter: 1888 loss: 2.09689051e-06
Iter: 1889 loss: 2.09588688e-06
Iter: 1890 loss: 2.09498876e-06
Iter: 1891 loss: 2.09945392e-06
Iter: 1892 loss: 2.09482141e-06
Iter: 1893 loss: 2.09407972e-06
Iter: 1894 loss: 2.09660448e-06
Iter: 1895 loss: 2.09385416e-06
Iter: 1896 loss: 2.09334576e-06
Iter: 1897 loss: 2.10118151e-06
Iter: 1898 loss: 2.09334326e-06
Iter: 1899 loss: 2.09293421e-06
Iter: 1900 loss: 2.09282757e-06
Iter: 1901 loss: 2.0925313e-06
Iter: 1902 loss: 2.09209065e-06
Iter: 1903 loss: 2.09586483e-06
Iter: 1904 loss: 2.09203586e-06
Iter: 1905 loss: 2.09158702e-06
Iter: 1906 loss: 2.09166592e-06
Iter: 1907 loss: 2.09127029e-06
Iter: 1908 loss: 2.09072869e-06
Iter: 1909 loss: 2.09579343e-06
Iter: 1910 loss: 2.09070868e-06
Iter: 1911 loss: 2.09025302e-06
Iter: 1912 loss: 2.08958181e-06
Iter: 1913 loss: 2.08956521e-06
Iter: 1914 loss: 2.08887445e-06
Iter: 1915 loss: 2.09567452e-06
Iter: 1916 loss: 2.08885194e-06
Iter: 1917 loss: 2.08813685e-06
Iter: 1918 loss: 2.08784923e-06
Iter: 1919 loss: 2.08747e-06
Iter: 1920 loss: 2.08669735e-06
Iter: 1921 loss: 2.08691654e-06
Iter: 1922 loss: 2.08611209e-06
Iter: 1923 loss: 2.08534766e-06
Iter: 1924 loss: 2.09091604e-06
Iter: 1925 loss: 2.08527354e-06
Iter: 1926 loss: 2.08471215e-06
Iter: 1927 loss: 2.08662777e-06
Iter: 1928 loss: 2.08454321e-06
Iter: 1929 loss: 2.08407027e-06
Iter: 1930 loss: 2.08728397e-06
Iter: 1931 loss: 2.08405527e-06
Iter: 1932 loss: 2.0835098e-06
Iter: 1933 loss: 2.08475944e-06
Iter: 1934 loss: 2.08333768e-06
Iter: 1935 loss: 2.08295728e-06
Iter: 1936 loss: 2.08353549e-06
Iter: 1937 loss: 2.0827556e-06
Iter: 1938 loss: 2.082126e-06
Iter: 1939 loss: 2.08326378e-06
Iter: 1940 loss: 2.0818693e-06
Iter: 1941 loss: 2.08132474e-06
Iter: 1942 loss: 2.08546953e-06
Iter: 1943 loss: 2.08128813e-06
Iter: 1944 loss: 2.08073152e-06
Iter: 1945 loss: 2.08022857e-06
Iter: 1946 loss: 2.08007418e-06
Iter: 1947 loss: 2.07934499e-06
Iter: 1948 loss: 2.082219e-06
Iter: 1949 loss: 2.07914854e-06
Iter: 1950 loss: 2.07833409e-06
Iter: 1951 loss: 2.08141364e-06
Iter: 1952 loss: 2.07812673e-06
Iter: 1953 loss: 2.07756511e-06
Iter: 1954 loss: 2.07686821e-06
Iter: 1955 loss: 2.07682979e-06
Iter: 1956 loss: 2.07603375e-06
Iter: 1957 loss: 2.07968401e-06
Iter: 1958 loss: 2.07586936e-06
Iter: 1959 loss: 2.075167e-06
Iter: 1960 loss: 2.07740368e-06
Iter: 1961 loss: 2.07495418e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6
+ date
Mon Nov  2 10:27:25 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 1.6 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c06c0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04f7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c06188c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c056e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c056e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03eab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03ea1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c041d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c041d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0330048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03308c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0396d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01b6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0498620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04bc598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04b6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04b6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0482ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0487d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0482268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01fb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01fbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c028af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c025e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0098c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0098a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0013378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c02f7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647b4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0003102277
test_loss: 0.00030856306
train_loss: 0.00010696893
test_loss: 0.00010296803
train_loss: 5.2176518e-05
test_loss: 5.5098833e-05
train_loss: 3.42468e-05
test_loss: 3.5562865e-05
train_loss: 2.4483e-05
test_loss: 2.5425008e-05
train_loss: 1.8542747e-05
test_loss: 1.9851323e-05
train_loss: 1.655989e-05
test_loss: 1.6219059e-05
train_loss: 1.3383284e-05
test_loss: 1.3703258e-05
train_loss: 1.142823e-05
test_loss: 1.1906918e-05
train_loss: 1.0442903e-05
test_loss: 1.0811771e-05
train_loss: 9.119788e-06
test_loss: 9.707376e-06
train_loss: 8.3646555e-06
test_loss: 9.0008025e-06
train_loss: 7.937836e-06
test_loss: 8.287357e-06
train_loss: 7.466826e-06
test_loss: 7.796926e-06
train_loss: 7.350961e-06
test_loss: 7.4859067e-06
train_loss: 6.5535387e-06
test_loss: 7.0123306e-06
train_loss: 6.3755106e-06
test_loss: 6.667846e-06
train_loss: 6.175044e-06
test_loss: 6.433241e-06
train_loss: 5.843612e-06
test_loss: 6.195071e-06
train_loss: 5.628615e-06
test_loss: 5.9760014e-06
train_loss: 5.4197535e-06
test_loss: 5.768735e-06
train_loss: 5.2629994e-06
test_loss: 5.58827e-06
train_loss: 5.1320912e-06
test_loss: 5.445861e-06
train_loss: 5.091033e-06
test_loss: 5.306619e-06
train_loss: 5.0066906e-06
test_loss: 5.2894256e-06
train_loss: 4.6057457e-06
test_loss: 5.0790177e-06
train_loss: 4.8179386e-06
test_loss: 5.002538e-06
train_loss: 4.4831518e-06
test_loss: 4.9071955e-06
train_loss: 4.6867863e-06
test_loss: 4.8003144e-06
train_loss: 4.4230337e-06
test_loss: 4.7096414e-06
train_loss: 4.130893e-06
test_loss: 4.6311507e-06
train_loss: 4.388346e-06
test_loss: 4.5277693e-06
train_loss: 4.4608782e-06
test_loss: 4.505902e-06
train_loss: 3.956608e-06
test_loss: 4.456349e-06
train_loss: 4.0571986e-06
test_loss: 4.3710916e-06
train_loss: 4.181527e-06
test_loss: 4.2984175e-06
train_loss: 4.207542e-06
test_loss: 4.2723514e-06
train_loss: 3.9278452e-06
test_loss: 4.2390107e-06
train_loss: 3.8112132e-06
test_loss: 4.182871e-06
train_loss: 3.8525436e-06
test_loss: 4.180134e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe662301d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500aca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500bed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500f6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500f6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500f62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe65002a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500288c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe650028400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe65000c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500112f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe650011488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ff95c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ffb0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ff47f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fee2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fef0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ff3d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe65000c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fec4048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fec4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fec4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fdadc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd5a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd5a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd5a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fdfad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fdfa7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd57158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fce52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fcfe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fc39ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fc50840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fce51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fc50bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fcc7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.89588649e-06
Iter: 2 loss: 3.85133808e-06
Iter: 3 loss: 3.85125395e-06
Iter: 4 loss: 3.83411498e-06
Iter: 5 loss: 3.8339781e-06
Iter: 6 loss: 3.82798953e-06
Iter: 7 loss: 3.82279177e-06
Iter: 8 loss: 3.82117696e-06
Iter: 9 loss: 3.81312634e-06
Iter: 10 loss: 3.86385773e-06
Iter: 11 loss: 3.81221162e-06
Iter: 12 loss: 3.80834e-06
Iter: 13 loss: 3.82286771e-06
Iter: 14 loss: 3.80738516e-06
Iter: 15 loss: 3.80409665e-06
Iter: 16 loss: 3.81270934e-06
Iter: 17 loss: 3.80292408e-06
Iter: 18 loss: 3.80055712e-06
Iter: 19 loss: 3.82350208e-06
Iter: 20 loss: 3.80044617e-06
Iter: 21 loss: 3.79909943e-06
Iter: 22 loss: 3.79738412e-06
Iter: 23 loss: 3.79726634e-06
Iter: 24 loss: 3.79546145e-06
Iter: 25 loss: 3.79544099e-06
Iter: 26 loss: 3.79414223e-06
Iter: 27 loss: 3.79271614e-06
Iter: 28 loss: 3.7924965e-06
Iter: 29 loss: 3.79081962e-06
Iter: 30 loss: 3.7935954e-06
Iter: 31 loss: 3.79001472e-06
Iter: 32 loss: 3.78859659e-06
Iter: 33 loss: 3.79505059e-06
Iter: 34 loss: 3.78832942e-06
Iter: 35 loss: 3.78725326e-06
Iter: 36 loss: 3.79182643e-06
Iter: 37 loss: 3.78698519e-06
Iter: 38 loss: 3.78596314e-06
Iter: 39 loss: 3.78575828e-06
Iter: 40 loss: 3.78504956e-06
Iter: 41 loss: 3.78483332e-06
Iter: 42 loss: 3.78415712e-06
Iter: 43 loss: 3.7838131e-06
Iter: 44 loss: 3.78266213e-06
Iter: 45 loss: 3.78473896e-06
Iter: 46 loss: 3.7819168e-06
Iter: 47 loss: 3.78073241e-06
Iter: 48 loss: 3.78071536e-06
Iter: 49 loss: 3.77967331e-06
Iter: 50 loss: 3.7810355e-06
Iter: 51 loss: 3.77908327e-06
Iter: 52 loss: 3.778272e-06
Iter: 53 loss: 3.78055211e-06
Iter: 54 loss: 3.7780344e-06
Iter: 55 loss: 3.77690048e-06
Iter: 56 loss: 3.77943707e-06
Iter: 57 loss: 3.776521e-06
Iter: 58 loss: 3.77580614e-06
Iter: 59 loss: 3.77859851e-06
Iter: 60 loss: 3.77565721e-06
Iter: 61 loss: 3.7749187e-06
Iter: 62 loss: 3.77577521e-06
Iter: 63 loss: 3.77454421e-06
Iter: 64 loss: 3.77358037e-06
Iter: 65 loss: 3.77518177e-06
Iter: 66 loss: 3.77314132e-06
Iter: 67 loss: 3.77215929e-06
Iter: 68 loss: 3.77562219e-06
Iter: 69 loss: 3.77191304e-06
Iter: 70 loss: 3.77110473e-06
Iter: 71 loss: 3.76973685e-06
Iter: 72 loss: 3.76973367e-06
Iter: 73 loss: 3.76820708e-06
Iter: 74 loss: 3.77394463e-06
Iter: 75 loss: 3.76779622e-06
Iter: 76 loss: 3.7665925e-06
Iter: 77 loss: 3.77916081e-06
Iter: 78 loss: 3.76656e-06
Iter: 79 loss: 3.7664131e-06
Iter: 80 loss: 3.76619573e-06
Iter: 81 loss: 3.76576736e-06
Iter: 82 loss: 3.76459093e-06
Iter: 83 loss: 3.77054698e-06
Iter: 84 loss: 3.76420439e-06
Iter: 85 loss: 3.76329422e-06
Iter: 86 loss: 3.76461685e-06
Iter: 87 loss: 3.76284652e-06
Iter: 88 loss: 3.76161233e-06
Iter: 89 loss: 3.7752302e-06
Iter: 90 loss: 3.76161233e-06
Iter: 91 loss: 3.76084427e-06
Iter: 92 loss: 3.76071557e-06
Iter: 93 loss: 3.76015851e-06
Iter: 94 loss: 3.75930495e-06
Iter: 95 loss: 3.76573212e-06
Iter: 96 loss: 3.75924401e-06
Iter: 97 loss: 3.75828267e-06
Iter: 98 loss: 3.75811487e-06
Iter: 99 loss: 3.75746458e-06
Iter: 100 loss: 3.75666468e-06
Iter: 101 loss: 3.76029811e-06
Iter: 102 loss: 3.75648801e-06
Iter: 103 loss: 3.75536456e-06
Iter: 104 loss: 3.75628497e-06
Iter: 105 loss: 3.75470518e-06
Iter: 106 loss: 3.75390096e-06
Iter: 107 loss: 3.75584113e-06
Iter: 108 loss: 3.75359491e-06
Iter: 109 loss: 3.75265245e-06
Iter: 110 loss: 3.75321179e-06
Iter: 111 loss: 3.75203945e-06
Iter: 112 loss: 3.75053742e-06
Iter: 113 loss: 3.75409e-06
Iter: 114 loss: 3.75000491e-06
Iter: 115 loss: 3.74872616e-06
Iter: 116 loss: 3.75248578e-06
Iter: 117 loss: 3.74835554e-06
Iter: 118 loss: 3.74690535e-06
Iter: 119 loss: 3.76735989e-06
Iter: 120 loss: 3.74693309e-06
Iter: 121 loss: 3.74649835e-06
Iter: 122 loss: 3.7453874e-06
Iter: 123 loss: 3.75276068e-06
Iter: 124 loss: 3.74510569e-06
Iter: 125 loss: 3.74364618e-06
Iter: 126 loss: 3.74759702e-06
Iter: 127 loss: 3.74317119e-06
Iter: 128 loss: 3.74223532e-06
Iter: 129 loss: 3.74216347e-06
Iter: 130 loss: 3.74147703e-06
Iter: 131 loss: 3.73997818e-06
Iter: 132 loss: 3.76347089e-06
Iter: 133 loss: 3.73993134e-06
Iter: 134 loss: 3.73880312e-06
Iter: 135 loss: 3.73879766e-06
Iter: 136 loss: 3.73778562e-06
Iter: 137 loss: 3.73742478e-06
Iter: 138 loss: 3.73686203e-06
Iter: 139 loss: 3.73560169e-06
Iter: 140 loss: 3.7374657e-06
Iter: 141 loss: 3.73496869e-06
Iter: 142 loss: 3.7337054e-06
Iter: 143 loss: 3.75027912e-06
Iter: 144 loss: 3.73372404e-06
Iter: 145 loss: 3.73284479e-06
Iter: 146 loss: 3.73101466e-06
Iter: 147 loss: 3.75766194e-06
Iter: 148 loss: 3.73092325e-06
Iter: 149 loss: 3.72939621e-06
Iter: 150 loss: 3.7383661e-06
Iter: 151 loss: 3.72922568e-06
Iter: 152 loss: 3.72760974e-06
Iter: 153 loss: 3.73269677e-06
Iter: 154 loss: 3.72712793e-06
Iter: 155 loss: 3.72545765e-06
Iter: 156 loss: 3.73051353e-06
Iter: 157 loss: 3.72497925e-06
Iter: 158 loss: 3.72399973e-06
Iter: 159 loss: 3.72387649e-06
Iter: 160 loss: 3.72322802e-06
Iter: 161 loss: 3.72125055e-06
Iter: 162 loss: 3.72629165e-06
Iter: 163 loss: 3.72013028e-06
Iter: 164 loss: 3.71791202e-06
Iter: 165 loss: 3.72600152e-06
Iter: 166 loss: 3.71736064e-06
Iter: 167 loss: 3.71494207e-06
Iter: 168 loss: 3.72354771e-06
Iter: 169 loss: 3.71433953e-06
Iter: 170 loss: 3.71364649e-06
Iter: 171 loss: 3.71338774e-06
Iter: 172 loss: 3.71251144e-06
Iter: 173 loss: 3.71056854e-06
Iter: 174 loss: 3.7387083e-06
Iter: 175 loss: 3.71045689e-06
Iter: 176 loss: 3.70921316e-06
Iter: 177 loss: 3.70918178e-06
Iter: 178 loss: 3.70795647e-06
Iter: 179 loss: 3.70717953e-06
Iter: 180 loss: 3.70674229e-06
Iter: 181 loss: 3.70513703e-06
Iter: 182 loss: 3.70886301e-06
Iter: 183 loss: 3.70452244e-06
Iter: 184 loss: 3.70320595e-06
Iter: 185 loss: 3.7195091e-06
Iter: 186 loss: 3.70314683e-06
Iter: 187 loss: 3.70199746e-06
Iter: 188 loss: 3.69927398e-06
Iter: 189 loss: 3.73146031e-06
Iter: 190 loss: 3.69904024e-06
Iter: 191 loss: 3.69712802e-06
Iter: 192 loss: 3.71982105e-06
Iter: 193 loss: 3.6971262e-06
Iter: 194 loss: 3.69581312e-06
Iter: 195 loss: 3.6958163e-06
Iter: 196 loss: 3.69486565e-06
Iter: 197 loss: 3.69431018e-06
Iter: 198 loss: 3.69396344e-06
Iter: 199 loss: 3.69279655e-06
Iter: 200 loss: 3.69191753e-06
Iter: 201 loss: 3.69154895e-06
Iter: 202 loss: 3.68948827e-06
Iter: 203 loss: 3.69092595e-06
Iter: 204 loss: 3.68817291e-06
Iter: 205 loss: 3.68561723e-06
Iter: 206 loss: 3.68805104e-06
Iter: 207 loss: 3.68415772e-06
Iter: 208 loss: 3.68284759e-06
Iter: 209 loss: 3.68230394e-06
Iter: 210 loss: 3.68118162e-06
Iter: 211 loss: 3.67967414e-06
Iter: 212 loss: 3.67959865e-06
Iter: 213 loss: 3.67808207e-06
Iter: 214 loss: 3.6951385e-06
Iter: 215 loss: 3.67810708e-06
Iter: 216 loss: 3.67665689e-06
Iter: 217 loss: 3.67627536e-06
Iter: 218 loss: 3.67536222e-06
Iter: 219 loss: 3.67360485e-06
Iter: 220 loss: 3.6745555e-06
Iter: 221 loss: 3.67248981e-06
Iter: 222 loss: 3.6702545e-06
Iter: 223 loss: 3.69651434e-06
Iter: 224 loss: 3.67024563e-06
Iter: 225 loss: 3.669e-06
Iter: 226 loss: 3.66688982e-06
Iter: 227 loss: 3.66689414e-06
Iter: 228 loss: 3.66665336e-06
Iter: 229 loss: 3.66574704e-06
Iter: 230 loss: 3.66462473e-06
Iter: 231 loss: 3.66278255e-06
Iter: 232 loss: 3.66280574e-06
Iter: 233 loss: 3.66129325e-06
Iter: 234 loss: 3.66454924e-06
Iter: 235 loss: 3.66066388e-06
Iter: 236 loss: 3.65867754e-06
Iter: 237 loss: 3.65923756e-06
Iter: 238 loss: 3.657251e-06
Iter: 239 loss: 3.65509209e-06
Iter: 240 loss: 3.65669666e-06
Iter: 241 loss: 3.65376104e-06
Iter: 242 loss: 3.65139886e-06
Iter: 243 loss: 3.65136907e-06
Iter: 244 loss: 3.64996731e-06
Iter: 245 loss: 3.64864263e-06
Iter: 246 loss: 3.64835068e-06
Iter: 247 loss: 3.64631046e-06
Iter: 248 loss: 3.65825736e-06
Iter: 249 loss: 3.64605512e-06
Iter: 250 loss: 3.64377979e-06
Iter: 251 loss: 3.64633115e-06
Iter: 252 loss: 3.6425065e-06
Iter: 253 loss: 3.6406841e-06
Iter: 254 loss: 3.63965432e-06
Iter: 255 loss: 3.63887102e-06
Iter: 256 loss: 3.63630716e-06
Iter: 257 loss: 3.67145685e-06
Iter: 258 loss: 3.63631898e-06
Iter: 259 loss: 3.63419167e-06
Iter: 260 loss: 3.63430172e-06
Iter: 261 loss: 3.63247e-06
Iter: 262 loss: 3.63130266e-06
Iter: 263 loss: 3.63128743e-06
Iter: 264 loss: 3.62974879e-06
Iter: 265 loss: 3.6272163e-06
Iter: 266 loss: 3.62722e-06
Iter: 267 loss: 3.62524816e-06
Iter: 268 loss: 3.62568881e-06
Iter: 269 loss: 3.62381843e-06
Iter: 270 loss: 3.62113428e-06
Iter: 271 loss: 3.63279901e-06
Iter: 272 loss: 3.62062701e-06
Iter: 273 loss: 3.61832326e-06
Iter: 274 loss: 3.62663855e-06
Iter: 275 loss: 3.61773823e-06
Iter: 276 loss: 3.615781e-06
Iter: 277 loss: 3.6191268e-06
Iter: 278 loss: 3.61492903e-06
Iter: 279 loss: 3.61278171e-06
Iter: 280 loss: 3.63944127e-06
Iter: 281 loss: 3.61276761e-06
Iter: 282 loss: 3.61155367e-06
Iter: 283 loss: 3.60854801e-06
Iter: 284 loss: 3.64099515e-06
Iter: 285 loss: 3.60823014e-06
Iter: 286 loss: 3.6070046e-06
Iter: 287 loss: 3.60634886e-06
Iter: 288 loss: 3.60514468e-06
Iter: 289 loss: 3.60281206e-06
Iter: 290 loss: 3.64741982e-06
Iter: 291 loss: 3.6027709e-06
Iter: 292 loss: 3.60043941e-06
Iter: 293 loss: 3.6149836e-06
Iter: 294 loss: 3.60013246e-06
Iter: 295 loss: 3.5982016e-06
Iter: 296 loss: 3.61606e-06
Iter: 297 loss: 3.59815181e-06
Iter: 298 loss: 3.59681735e-06
Iter: 299 loss: 3.59461387e-06
Iter: 300 loss: 3.59462115e-06
Iter: 301 loss: 3.59417618e-06
Iter: 302 loss: 3.59312753e-06
Iter: 303 loss: 3.59248497e-06
Iter: 304 loss: 3.59032583e-06
Iter: 305 loss: 3.59627688e-06
Iter: 306 loss: 3.58913599e-06
Iter: 307 loss: 3.58581792e-06
Iter: 308 loss: 3.59362139e-06
Iter: 309 loss: 3.58459056e-06
Iter: 310 loss: 3.58192028e-06
Iter: 311 loss: 3.60714853e-06
Iter: 312 loss: 3.58182751e-06
Iter: 313 loss: 3.579652e-06
Iter: 314 loss: 3.58376724e-06
Iter: 315 loss: 3.57871522e-06
Iter: 316 loss: 3.57686031e-06
Iter: 317 loss: 3.58304146e-06
Iter: 318 loss: 3.57637396e-06
Iter: 319 loss: 3.57423414e-06
Iter: 320 loss: 3.58790589e-06
Iter: 321 loss: 3.5739954e-06
Iter: 322 loss: 3.57214e-06
Iter: 323 loss: 3.56957753e-06
Iter: 324 loss: 3.56944884e-06
Iter: 325 loss: 3.56705823e-06
Iter: 326 loss: 3.60206e-06
Iter: 327 loss: 3.56711598e-06
Iter: 328 loss: 3.56470809e-06
Iter: 329 loss: 3.56286318e-06
Iter: 330 loss: 3.56215537e-06
Iter: 331 loss: 3.55954489e-06
Iter: 332 loss: 3.56626038e-06
Iter: 333 loss: 3.55868451e-06
Iter: 334 loss: 3.55547786e-06
Iter: 335 loss: 3.57490808e-06
Iter: 336 loss: 3.55511884e-06
Iter: 337 loss: 3.55322413e-06
Iter: 338 loss: 3.55509565e-06
Iter: 339 loss: 3.55212683e-06
Iter: 340 loss: 3.55048292e-06
Iter: 341 loss: 3.55044631e-06
Iter: 342 loss: 3.54938493e-06
Iter: 343 loss: 3.54634312e-06
Iter: 344 loss: 3.56390274e-06
Iter: 345 loss: 3.54555618e-06
Iter: 346 loss: 3.54242343e-06
Iter: 347 loss: 3.54269923e-06
Iter: 348 loss: 3.54000258e-06
Iter: 349 loss: 3.53582186e-06
Iter: 350 loss: 3.57747831e-06
Iter: 351 loss: 3.53561245e-06
Iter: 352 loss: 3.53215955e-06
Iter: 353 loss: 3.54121721e-06
Iter: 354 loss: 3.53101768e-06
Iter: 355 loss: 3.52841676e-06
Iter: 356 loss: 3.55090128e-06
Iter: 357 loss: 3.52828647e-06
Iter: 358 loss: 3.52579627e-06
Iter: 359 loss: 3.53112773e-06
Iter: 360 loss: 3.5248795e-06
Iter: 361 loss: 3.52285178e-06
Iter: 362 loss: 3.52077313e-06
Iter: 363 loss: 3.52039706e-06
Iter: 364 loss: 3.51731887e-06
Iter: 365 loss: 3.51732729e-06
Iter: 366 loss: 3.5153912e-06
Iter: 367 loss: 3.51409358e-06
Iter: 368 loss: 3.51337894e-06
Iter: 369 loss: 3.51090739e-06
Iter: 370 loss: 3.52043116e-06
Iter: 371 loss: 3.51031895e-06
Iter: 372 loss: 3.50743335e-06
Iter: 373 loss: 3.51878748e-06
Iter: 374 loss: 3.50682467e-06
Iter: 375 loss: 3.50476785e-06
Iter: 376 loss: 3.50910523e-06
Iter: 377 loss: 3.50396203e-06
Iter: 378 loss: 3.50054188e-06
Iter: 379 loss: 3.50630398e-06
Iter: 380 loss: 3.49898687e-06
Iter: 381 loss: 3.49733659e-06
Iter: 382 loss: 3.49508673e-06
Iter: 383 loss: 3.49498714e-06
Iter: 384 loss: 3.49174229e-06
Iter: 385 loss: 3.49506126e-06
Iter: 386 loss: 3.48993126e-06
Iter: 387 loss: 3.4869181e-06
Iter: 388 loss: 3.51811036e-06
Iter: 389 loss: 3.48683125e-06
Iter: 390 loss: 3.48427648e-06
Iter: 391 loss: 3.48883623e-06
Iter: 392 loss: 3.48318599e-06
Iter: 393 loss: 3.48114145e-06
Iter: 394 loss: 3.50771688e-06
Iter: 395 loss: 3.48113326e-06
Iter: 396 loss: 3.47922128e-06
Iter: 397 loss: 3.47702348e-06
Iter: 398 loss: 3.47673767e-06
Iter: 399 loss: 3.4739669e-06
Iter: 400 loss: 3.48433241e-06
Iter: 401 loss: 3.47327932e-06
Iter: 402 loss: 3.46985962e-06
Iter: 403 loss: 3.48113e-06
Iter: 404 loss: 3.4689208e-06
Iter: 405 loss: 3.46623233e-06
Iter: 406 loss: 3.46361185e-06
Iter: 407 loss: 3.46307615e-06
Iter: 408 loss: 3.4605373e-06
Iter: 409 loss: 3.4603936e-06
Iter: 410 loss: 3.45852277e-06
Iter: 411 loss: 3.45751e-06
Iter: 412 loss: 3.45666103e-06
Iter: 413 loss: 3.45517628e-06
Iter: 414 loss: 3.45509898e-06
Iter: 415 loss: 3.45335684e-06
Iter: 416 loss: 3.45192348e-06
Iter: 417 loss: 3.45142826e-06
Iter: 418 loss: 3.44944283e-06
Iter: 419 loss: 3.44516434e-06
Iter: 420 loss: 3.51089193e-06
Iter: 421 loss: 3.44503064e-06
Iter: 422 loss: 3.44095747e-06
Iter: 423 loss: 3.48050708e-06
Iter: 424 loss: 3.44081627e-06
Iter: 425 loss: 3.43705187e-06
Iter: 426 loss: 3.44227601e-06
Iter: 427 loss: 3.43516604e-06
Iter: 428 loss: 3.43161514e-06
Iter: 429 loss: 3.46731213e-06
Iter: 430 loss: 3.43152442e-06
Iter: 431 loss: 3.42959152e-06
Iter: 432 loss: 3.44773184e-06
Iter: 433 loss: 3.42952444e-06
Iter: 434 loss: 3.42786097e-06
Iter: 435 loss: 3.42557041e-06
Iter: 436 loss: 3.42543262e-06
Iter: 437 loss: 3.42328053e-06
Iter: 438 loss: 3.43622423e-06
Iter: 439 loss: 3.42303315e-06
Iter: 440 loss: 3.42052226e-06
Iter: 441 loss: 3.42568319e-06
Iter: 442 loss: 3.41947e-06
Iter: 443 loss: 3.41724149e-06
Iter: 444 loss: 3.4170539e-06
Iter: 445 loss: 3.41539453e-06
Iter: 446 loss: 3.41296277e-06
Iter: 447 loss: 3.44636055e-06
Iter: 448 loss: 3.41295231e-06
Iter: 449 loss: 3.4107336e-06
Iter: 450 loss: 3.41119767e-06
Iter: 451 loss: 3.40907809e-06
Iter: 452 loss: 3.40688962e-06
Iter: 453 loss: 3.40685506e-06
Iter: 454 loss: 3.40562679e-06
Iter: 455 loss: 3.40258885e-06
Iter: 456 loss: 3.43436909e-06
Iter: 457 loss: 3.4022537e-06
Iter: 458 loss: 3.39937446e-06
Iter: 459 loss: 3.40458678e-06
Iter: 460 loss: 3.39809912e-06
Iter: 461 loss: 3.39510507e-06
Iter: 462 loss: 3.40928273e-06
Iter: 463 loss: 3.39454823e-06
Iter: 464 loss: 3.39170242e-06
Iter: 465 loss: 3.40136944e-06
Iter: 466 loss: 3.3909655e-06
Iter: 467 loss: 3.38831569e-06
Iter: 468 loss: 3.39554981e-06
Iter: 469 loss: 3.38746804e-06
Iter: 470 loss: 3.3846743e-06
Iter: 471 loss: 3.40633619e-06
Iter: 472 loss: 3.3844849e-06
Iter: 473 loss: 3.38226437e-06
Iter: 474 loss: 3.38154405e-06
Iter: 475 loss: 3.38026257e-06
Iter: 476 loss: 3.37827373e-06
Iter: 477 loss: 3.40040106e-06
Iter: 478 loss: 3.37821893e-06
Iter: 479 loss: 3.37613392e-06
Iter: 480 loss: 3.3734857e-06
Iter: 481 loss: 3.3733063e-06
Iter: 482 loss: 3.37037454e-06
Iter: 483 loss: 3.38658901e-06
Iter: 484 loss: 3.36997846e-06
Iter: 485 loss: 3.36672656e-06
Iter: 486 loss: 3.37642587e-06
Iter: 487 loss: 3.36576568e-06
Iter: 488 loss: 3.36387689e-06
Iter: 489 loss: 3.39196185e-06
Iter: 490 loss: 3.36389121e-06
Iter: 491 loss: 3.36206585e-06
Iter: 492 loss: 3.3609665e-06
Iter: 493 loss: 3.36020958e-06
Iter: 494 loss: 3.35809955e-06
Iter: 495 loss: 3.35361074e-06
Iter: 496 loss: 3.42678686e-06
Iter: 497 loss: 3.3534584e-06
Iter: 498 loss: 3.3497713e-06
Iter: 499 loss: 3.34977608e-06
Iter: 500 loss: 3.34668698e-06
Iter: 501 loss: 3.34751303e-06
Iter: 502 loss: 3.3444735e-06
Iter: 503 loss: 3.3410829e-06
Iter: 504 loss: 3.37428e-06
Iter: 505 loss: 3.34094966e-06
Iter: 506 loss: 3.33845446e-06
Iter: 507 loss: 3.35217e-06
Iter: 508 loss: 3.3381375e-06
Iter: 509 loss: 3.33590947e-06
Iter: 510 loss: 3.3340998e-06
Iter: 511 loss: 3.33350727e-06
Iter: 512 loss: 3.33056596e-06
Iter: 513 loss: 3.35967025e-06
Iter: 514 loss: 3.33048274e-06
Iter: 515 loss: 3.32805166e-06
Iter: 516 loss: 3.32973968e-06
Iter: 517 loss: 3.32649506e-06
Iter: 518 loss: 3.32405898e-06
Iter: 519 loss: 3.32671698e-06
Iter: 520 loss: 3.32274567e-06
Iter: 521 loss: 3.3197266e-06
Iter: 522 loss: 3.34859442e-06
Iter: 523 loss: 3.31958768e-06
Iter: 524 loss: 3.31831552e-06
Iter: 525 loss: 3.3347992e-06
Iter: 526 loss: 3.3183419e-06
Iter: 527 loss: 3.31702427e-06
Iter: 528 loss: 3.31375327e-06
Iter: 529 loss: 3.34126639e-06
Iter: 530 loss: 3.31315e-06
Iter: 531 loss: 3.30961939e-06
Iter: 532 loss: 3.31505294e-06
Iter: 533 loss: 3.30788816e-06
Iter: 534 loss: 3.30397233e-06
Iter: 535 loss: 3.31666661e-06
Iter: 536 loss: 3.30286548e-06
Iter: 537 loss: 3.29901013e-06
Iter: 538 loss: 3.31651017e-06
Iter: 539 loss: 3.29831073e-06
Iter: 540 loss: 3.29490513e-06
Iter: 541 loss: 3.3082315e-06
Iter: 542 loss: 3.29416321e-06
Iter: 543 loss: 3.29107206e-06
Iter: 544 loss: 3.3137876e-06
Iter: 545 loss: 3.29084287e-06
Iter: 546 loss: 3.2886569e-06
Iter: 547 loss: 3.28742317e-06
Iter: 548 loss: 3.28647729e-06
Iter: 549 loss: 3.28319402e-06
Iter: 550 loss: 3.30188686e-06
Iter: 551 loss: 3.2827561e-06
Iter: 552 loss: 3.2794178e-06
Iter: 553 loss: 3.2813432e-06
Iter: 554 loss: 3.27727366e-06
Iter: 555 loss: 3.27386374e-06
Iter: 556 loss: 3.28033957e-06
Iter: 557 loss: 3.27241014e-06
Iter: 558 loss: 3.26806162e-06
Iter: 559 loss: 3.29702084e-06
Iter: 560 loss: 3.26760619e-06
Iter: 561 loss: 3.26517511e-06
Iter: 562 loss: 3.29690147e-06
Iter: 563 loss: 3.26519284e-06
Iter: 564 loss: 3.26352074e-06
Iter: 565 loss: 3.25981591e-06
Iter: 566 loss: 3.31556544e-06
Iter: 567 loss: 3.2596763e-06
Iter: 568 loss: 3.25599558e-06
Iter: 569 loss: 3.25716928e-06
Iter: 570 loss: 3.25336669e-06
Iter: 571 loss: 3.24960047e-06
Iter: 572 loss: 3.27990711e-06
Iter: 573 loss: 3.24938765e-06
Iter: 574 loss: 3.24596112e-06
Iter: 575 loss: 3.25200381e-06
Iter: 576 loss: 3.24446728e-06
Iter: 577 loss: 3.24153302e-06
Iter: 578 loss: 3.27708926e-06
Iter: 579 loss: 3.24148573e-06
Iter: 580 loss: 3.23920244e-06
Iter: 581 loss: 3.24320263e-06
Iter: 582 loss: 3.23817699e-06
Iter: 583 loss: 3.23549625e-06
Iter: 584 loss: 3.23426843e-06
Iter: 585 loss: 3.23292238e-06
Iter: 586 loss: 3.22952701e-06
Iter: 587 loss: 3.2730668e-06
Iter: 588 loss: 3.22945607e-06
Iter: 589 loss: 3.2273224e-06
Iter: 590 loss: 3.22677897e-06
Iter: 591 loss: 3.22539722e-06
Iter: 592 loss: 3.22253572e-06
Iter: 593 loss: 3.23576819e-06
Iter: 594 loss: 3.22201277e-06
Iter: 595 loss: 3.2190942e-06
Iter: 596 loss: 3.23762106e-06
Iter: 597 loss: 3.21874631e-06
Iter: 598 loss: 3.21640164e-06
Iter: 599 loss: 3.22656297e-06
Iter: 600 loss: 3.21592415e-06
Iter: 601 loss: 3.21413177e-06
Iter: 602 loss: 3.20991876e-06
Iter: 603 loss: 3.25830615e-06
Iter: 604 loss: 3.20955792e-06
Iter: 605 loss: 3.20537447e-06
Iter: 606 loss: 3.21784955e-06
Iter: 607 loss: 3.204113e-06
Iter: 608 loss: 3.20017807e-06
Iter: 609 loss: 3.22237429e-06
Iter: 610 loss: 3.1996326e-06
Iter: 611 loss: 3.19605397e-06
Iter: 612 loss: 3.2070493e-06
Iter: 613 loss: 3.19504875e-06
Iter: 614 loss: 3.19131e-06
Iter: 615 loss: 3.21241669e-06
Iter: 616 loss: 3.19083142e-06
Iter: 617 loss: 3.18759339e-06
Iter: 618 loss: 3.19255855e-06
Iter: 619 loss: 3.18609e-06
Iter: 620 loss: 3.18301e-06
Iter: 621 loss: 3.18903722e-06
Iter: 622 loss: 3.1816935e-06
Iter: 623 loss: 3.17796093e-06
Iter: 624 loss: 3.19278706e-06
Iter: 625 loss: 3.17711192e-06
Iter: 626 loss: 3.17429976e-06
Iter: 627 loss: 3.17690478e-06
Iter: 628 loss: 3.17261015e-06
Iter: 629 loss: 3.1701461e-06
Iter: 630 loss: 3.20259551e-06
Iter: 631 loss: 3.17013973e-06
Iter: 632 loss: 3.1680147e-06
Iter: 633 loss: 3.17417721e-06
Iter: 634 loss: 3.16733622e-06
Iter: 635 loss: 3.164997e-06
Iter: 636 loss: 3.16606702e-06
Iter: 637 loss: 3.16338378e-06
Iter: 638 loss: 3.16119281e-06
Iter: 639 loss: 3.15826946e-06
Iter: 640 loss: 3.15814395e-06
Iter: 641 loss: 3.15368197e-06
Iter: 642 loss: 3.16064666e-06
Iter: 643 loss: 3.15163743e-06
Iter: 644 loss: 3.14760337e-06
Iter: 645 loss: 3.18724142e-06
Iter: 646 loss: 3.14745671e-06
Iter: 647 loss: 3.14426097e-06
Iter: 648 loss: 3.15693546e-06
Iter: 649 loss: 3.14355975e-06
Iter: 650 loss: 3.14056297e-06
Iter: 651 loss: 3.15774241e-06
Iter: 652 loss: 3.14014937e-06
Iter: 653 loss: 3.13810961e-06
Iter: 654 loss: 3.13922374e-06
Iter: 655 loss: 3.13675673e-06
Iter: 656 loss: 3.13422584e-06
Iter: 657 loss: 3.14452154e-06
Iter: 658 loss: 3.13362148e-06
Iter: 659 loss: 3.13100963e-06
Iter: 660 loss: 3.13487089e-06
Iter: 661 loss: 3.12970769e-06
Iter: 662 loss: 3.12743691e-06
Iter: 663 loss: 3.13452892e-06
Iter: 664 loss: 3.12680413e-06
Iter: 665 loss: 3.12438692e-06
Iter: 666 loss: 3.14301633e-06
Iter: 667 loss: 3.12417569e-06
Iter: 668 loss: 3.12218572e-06
Iter: 669 loss: 3.12589259e-06
Iter: 670 loss: 3.12127941e-06
Iter: 671 loss: 3.11899566e-06
Iter: 672 loss: 3.11557505e-06
Iter: 673 loss: 3.11550275e-06
Iter: 674 loss: 3.11155645e-06
Iter: 675 loss: 3.11602957e-06
Iter: 676 loss: 3.10942278e-06
Iter: 677 loss: 3.10490805e-06
Iter: 678 loss: 3.11292229e-06
Iter: 679 loss: 3.1029947e-06
Iter: 680 loss: 3.09857296e-06
Iter: 681 loss: 3.15007173e-06
Iter: 682 loss: 3.09851293e-06
Iter: 683 loss: 3.09568622e-06
Iter: 684 loss: 3.11390113e-06
Iter: 685 loss: 3.09538154e-06
Iter: 686 loss: 3.09278312e-06
Iter: 687 loss: 3.09348911e-06
Iter: 688 loss: 3.09085635e-06
Iter: 689 loss: 3.08792642e-06
Iter: 690 loss: 3.09928055e-06
Iter: 691 loss: 3.08721519e-06
Iter: 692 loss: 3.08439576e-06
Iter: 693 loss: 3.09469578e-06
Iter: 694 loss: 3.08369818e-06
Iter: 695 loss: 3.08099652e-06
Iter: 696 loss: 3.08100516e-06
Iter: 697 loss: 3.07886125e-06
Iter: 698 loss: 3.07662094e-06
Iter: 699 loss: 3.0765566e-06
Iter: 700 loss: 3.07470054e-06
Iter: 701 loss: 3.07811e-06
Iter: 702 loss: 3.07383971e-06
Iter: 703 loss: 3.07173173e-06
Iter: 704 loss: 3.07335313e-06
Iter: 705 loss: 3.07043047e-06
Iter: 706 loss: 3.06839161e-06
Iter: 707 loss: 3.06726793e-06
Iter: 708 loss: 3.06634752e-06
Iter: 709 loss: 3.06364564e-06
Iter: 710 loss: 3.06733705e-06
Iter: 711 loss: 3.06229708e-06
Iter: 712 loss: 3.05902518e-06
Iter: 713 loss: 3.07152823e-06
Iter: 714 loss: 3.05825688e-06
Iter: 715 loss: 3.05512231e-06
Iter: 716 loss: 3.07865048e-06
Iter: 717 loss: 3.05490403e-06
Iter: 718 loss: 3.05201593e-06
Iter: 719 loss: 3.05988e-06
Iter: 720 loss: 3.05111712e-06
Iter: 721 loss: 3.04832361e-06
Iter: 722 loss: 3.05015965e-06
Iter: 723 loss: 3.04654213e-06
Iter: 724 loss: 3.04358127e-06
Iter: 725 loss: 3.0629833e-06
Iter: 726 loss: 3.0432725e-06
Iter: 727 loss: 3.04053924e-06
Iter: 728 loss: 3.04248215e-06
Iter: 729 loss: 3.0388685e-06
Iter: 730 loss: 3.03600814e-06
Iter: 731 loss: 3.04789364e-06
Iter: 732 loss: 3.03544812e-06
Iter: 733 loss: 3.0328074e-06
Iter: 734 loss: 3.0580527e-06
Iter: 735 loss: 3.03272418e-06
Iter: 736 loss: 3.03082652e-06
Iter: 737 loss: 3.03175284e-06
Iter: 738 loss: 3.02956778e-06
Iter: 739 loss: 3.02705712e-06
Iter: 740 loss: 3.0260353e-06
Iter: 741 loss: 3.02471244e-06
Iter: 742 loss: 3.02163517e-06
Iter: 743 loss: 3.02182616e-06
Iter: 744 loss: 3.01922182e-06
Iter: 745 loss: 3.01520458e-06
Iter: 746 loss: 3.0281517e-06
Iter: 747 loss: 3.01403634e-06
Iter: 748 loss: 3.01002638e-06
Iter: 749 loss: 3.03178649e-06
Iter: 750 loss: 3.00945817e-06
Iter: 751 loss: 3.00605188e-06
Iter: 752 loss: 3.03683282e-06
Iter: 753 loss: 3.00587794e-06
Iter: 754 loss: 3.00366492e-06
Iter: 755 loss: 3.00793818e-06
Iter: 756 loss: 3.00273314e-06
Iter: 757 loss: 3.00058605e-06
Iter: 758 loss: 3.00324314e-06
Iter: 759 loss: 2.99946214e-06
Iter: 760 loss: 2.99696126e-06
Iter: 761 loss: 3.01159389e-06
Iter: 762 loss: 2.99659837e-06
Iter: 763 loss: 2.99459793e-06
Iter: 764 loss: 2.99405929e-06
Iter: 765 loss: 2.99282738e-06
Iter: 766 loss: 2.99046724e-06
Iter: 767 loss: 2.99047497e-06
Iter: 768 loss: 2.98844543e-06
Iter: 769 loss: 2.99033081e-06
Iter: 770 loss: 2.98729492e-06
Iter: 771 loss: 2.98511623e-06
Iter: 772 loss: 2.98848e-06
Iter: 773 loss: 2.9841176e-06
Iter: 774 loss: 2.98183204e-06
Iter: 775 loss: 2.97919519e-06
Iter: 776 loss: 2.97890324e-06
Iter: 777 loss: 2.97540623e-06
Iter: 778 loss: 2.98503483e-06
Iter: 779 loss: 2.97428414e-06
Iter: 780 loss: 2.97114138e-06
Iter: 781 loss: 2.98718169e-06
Iter: 782 loss: 2.97066e-06
Iter: 783 loss: 2.96829398e-06
Iter: 784 loss: 2.99207363e-06
Iter: 785 loss: 2.96821486e-06
Iter: 786 loss: 2.96602821e-06
Iter: 787 loss: 2.96818916e-06
Iter: 788 loss: 2.96474173e-06
Iter: 789 loss: 2.96225562e-06
Iter: 790 loss: 2.96877488e-06
Iter: 791 loss: 2.96141252e-06
Iter: 792 loss: 2.95919381e-06
Iter: 793 loss: 2.96639496e-06
Iter: 794 loss: 2.95854716e-06
Iter: 795 loss: 2.95587824e-06
Iter: 796 loss: 2.95703057e-06
Iter: 797 loss: 2.95397012e-06
Iter: 798 loss: 2.95113705e-06
Iter: 799 loss: 2.97115821e-06
Iter: 800 loss: 2.95088284e-06
Iter: 801 loss: 2.94824736e-06
Iter: 802 loss: 2.96279518e-06
Iter: 803 loss: 2.94782558e-06
Iter: 804 loss: 2.94585971e-06
Iter: 805 loss: 2.94662868e-06
Iter: 806 loss: 2.94452275e-06
Iter: 807 loss: 2.94191796e-06
Iter: 808 loss: 2.94266079e-06
Iter: 809 loss: 2.94004576e-06
Iter: 810 loss: 2.93729272e-06
Iter: 811 loss: 2.9387777e-06
Iter: 812 loss: 2.93548374e-06
Iter: 813 loss: 2.93221501e-06
Iter: 814 loss: 2.93861126e-06
Iter: 815 loss: 2.93087828e-06
Iter: 816 loss: 2.92754157e-06
Iter: 817 loss: 2.95259588e-06
Iter: 818 loss: 2.92727941e-06
Iter: 819 loss: 2.92441678e-06
Iter: 820 loss: 2.94309575e-06
Iter: 821 loss: 2.92406412e-06
Iter: 822 loss: 2.92158256e-06
Iter: 823 loss: 2.92193886e-06
Iter: 824 loss: 2.91968172e-06
Iter: 825 loss: 2.91636343e-06
Iter: 826 loss: 2.92777645e-06
Iter: 827 loss: 2.91552351e-06
Iter: 828 loss: 2.91273136e-06
Iter: 829 loss: 2.92816026e-06
Iter: 830 loss: 2.91233209e-06
Iter: 831 loss: 2.91003221e-06
Iter: 832 loss: 2.91112019e-06
Iter: 833 loss: 2.90853131e-06
Iter: 834 loss: 2.90651042e-06
Iter: 835 loss: 2.90649677e-06
Iter: 836 loss: 2.90498224e-06
Iter: 837 loss: 2.90446678e-06
Iter: 838 loss: 2.9035898e-06
Iter: 839 loss: 2.90162984e-06
Iter: 840 loss: 2.90763955e-06
Iter: 841 loss: 2.90106709e-06
Iter: 842 loss: 2.89935906e-06
Iter: 843 loss: 2.8974664e-06
Iter: 844 loss: 2.89722129e-06
Iter: 845 loss: 2.8940326e-06
Iter: 846 loss: 2.89743753e-06
Iter: 847 loss: 2.89230275e-06
Iter: 848 loss: 2.8885006e-06
Iter: 849 loss: 2.8997938e-06
Iter: 850 loss: 2.88731212e-06
Iter: 851 loss: 2.88464798e-06
Iter: 852 loss: 2.88459205e-06
Iter: 853 loss: 2.88260549e-06
Iter: 854 loss: 2.88569936e-06
Iter: 855 loss: 2.88165302e-06
Iter: 856 loss: 2.87963394e-06
Iter: 857 loss: 2.88201772e-06
Iter: 858 loss: 2.87849889e-06
Iter: 859 loss: 2.87605758e-06
Iter: 860 loss: 2.88635e-06
Iter: 861 loss: 2.87553667e-06
Iter: 862 loss: 2.87324792e-06
Iter: 863 loss: 2.87776425e-06
Iter: 864 loss: 2.87230864e-06
Iter: 865 loss: 2.87025068e-06
Iter: 866 loss: 2.88251499e-06
Iter: 867 loss: 2.86997624e-06
Iter: 868 loss: 2.86757586e-06
Iter: 869 loss: 2.87149624e-06
Iter: 870 loss: 2.86647742e-06
Iter: 871 loss: 2.86424256e-06
Iter: 872 loss: 2.86636714e-06
Iter: 873 loss: 2.86295563e-06
Iter: 874 loss: 2.85996362e-06
Iter: 875 loss: 2.8596487e-06
Iter: 876 loss: 2.85746501e-06
Iter: 877 loss: 2.85372471e-06
Iter: 878 loss: 2.85679744e-06
Iter: 879 loss: 2.851506e-06
Iter: 880 loss: 2.84757334e-06
Iter: 881 loss: 2.86256682e-06
Iter: 882 loss: 2.84667976e-06
Iter: 883 loss: 2.84431371e-06
Iter: 884 loss: 2.87216562e-06
Iter: 885 loss: 2.84427188e-06
Iter: 886 loss: 2.84233556e-06
Iter: 887 loss: 2.85286364e-06
Iter: 888 loss: 2.8420468e-06
Iter: 889 loss: 2.84053067e-06
Iter: 890 loss: 2.84184e-06
Iter: 891 loss: 2.83967211e-06
Iter: 892 loss: 2.83792951e-06
Iter: 893 loss: 2.84339467e-06
Iter: 894 loss: 2.83741e-06
Iter: 895 loss: 2.83555619e-06
Iter: 896 loss: 2.84025555e-06
Iter: 897 loss: 2.83493341e-06
Iter: 898 loss: 2.83314148e-06
Iter: 899 loss: 2.83757322e-06
Iter: 900 loss: 2.83249869e-06
Iter: 901 loss: 2.83078e-06
Iter: 902 loss: 2.85064152e-06
Iter: 903 loss: 2.8307536e-06
Iter: 904 loss: 2.82946348e-06
Iter: 905 loss: 2.82756673e-06
Iter: 906 loss: 2.8275249e-06
Iter: 907 loss: 2.82494e-06
Iter: 908 loss: 2.83459576e-06
Iter: 909 loss: 2.82428027e-06
Iter: 910 loss: 2.8221616e-06
Iter: 911 loss: 2.82116321e-06
Iter: 912 loss: 2.82012661e-06
Iter: 913 loss: 2.81712914e-06
Iter: 914 loss: 2.82313135e-06
Iter: 915 loss: 2.81598341e-06
Iter: 916 loss: 2.81305233e-06
Iter: 917 loss: 2.82056908e-06
Iter: 918 loss: 2.8120669e-06
Iter: 919 loss: 2.8096149e-06
Iter: 920 loss: 2.80959944e-06
Iter: 921 loss: 2.80743848e-06
Iter: 922 loss: 2.80753193e-06
Iter: 923 loss: 2.80576546e-06
Iter: 924 loss: 2.80314953e-06
Iter: 925 loss: 2.81261873e-06
Iter: 926 loss: 2.80252038e-06
Iter: 927 loss: 2.80002268e-06
Iter: 928 loss: 2.80795803e-06
Iter: 929 loss: 2.79931828e-06
Iter: 930 loss: 2.79676465e-06
Iter: 931 loss: 2.80112431e-06
Iter: 932 loss: 2.79563392e-06
Iter: 933 loss: 2.79359392e-06
Iter: 934 loss: 2.8224274e-06
Iter: 935 loss: 2.79359301e-06
Iter: 936 loss: 2.7918029e-06
Iter: 937 loss: 2.79222104e-06
Iter: 938 loss: 2.79050164e-06
Iter: 939 loss: 2.78866014e-06
Iter: 940 loss: 2.79238066e-06
Iter: 941 loss: 2.78794641e-06
Iter: 942 loss: 2.78587822e-06
Iter: 943 loss: 2.78684547e-06
Iter: 944 loss: 2.78444031e-06
Iter: 945 loss: 2.78217635e-06
Iter: 946 loss: 2.78272546e-06
Iter: 947 loss: 2.78051607e-06
Iter: 948 loss: 2.77726031e-06
Iter: 949 loss: 2.78257653e-06
Iter: 950 loss: 2.77579397e-06
Iter: 951 loss: 2.77337358e-06
Iter: 952 loss: 2.80727363e-06
Iter: 953 loss: 2.77336426e-06
Iter: 954 loss: 2.77124172e-06
Iter: 955 loss: 2.7822332e-06
Iter: 956 loss: 2.77091476e-06
Iter: 957 loss: 2.76929859e-06
Iter: 958 loss: 2.76936044e-06
Iter: 959 loss: 2.7680253e-06
Iter: 960 loss: 2.76594665e-06
Iter: 961 loss: 2.77902836e-06
Iter: 962 loss: 2.76572678e-06
Iter: 963 loss: 2.76402898e-06
Iter: 964 loss: 2.76752075e-06
Iter: 965 loss: 2.76338869e-06
Iter: 966 loss: 2.76167361e-06
Iter: 967 loss: 2.76770629e-06
Iter: 968 loss: 2.76118567e-06
Iter: 969 loss: 2.75944558e-06
Iter: 970 loss: 2.77281742e-06
Iter: 971 loss: 2.75929847e-06
Iter: 972 loss: 2.75818934e-06
Iter: 973 loss: 2.75726984e-06
Iter: 974 loss: 2.75695288e-06
Iter: 975 loss: 2.75506272e-06
Iter: 976 loss: 2.76003129e-06
Iter: 977 loss: 2.75442153e-06
Iter: 978 loss: 2.75240041e-06
Iter: 979 loss: 2.75087473e-06
Iter: 980 loss: 2.75019556e-06
Iter: 981 loss: 2.74727563e-06
Iter: 982 loss: 2.75418e-06
Iter: 983 loss: 2.7461756e-06
Iter: 984 loss: 2.74325475e-06
Iter: 985 loss: 2.75256207e-06
Iter: 986 loss: 2.74241302e-06
Iter: 987 loss: 2.74090439e-06
Iter: 988 loss: 2.74076592e-06
Iter: 989 loss: 2.73942896e-06
Iter: 990 loss: 2.73894148e-06
Iter: 991 loss: 2.73820569e-06
Iter: 992 loss: 2.73644969e-06
Iter: 993 loss: 2.74223339e-06
Iter: 994 loss: 2.73597675e-06
Iter: 995 loss: 2.7341614e-06
Iter: 996 loss: 2.74055606e-06
Iter: 997 loss: 2.7337e-06
Iter: 998 loss: 2.7321048e-06
Iter: 999 loss: 2.73649493e-06
Iter: 1000 loss: 2.73158594e-06
Iter: 1001 loss: 2.73019714e-06
Iter: 1002 loss: 2.74384456e-06
Iter: 1003 loss: 2.73014416e-06
Iter: 1004 loss: 2.72878879e-06
Iter: 1005 loss: 2.72720013e-06
Iter: 1006 loss: 2.727018e-06
Iter: 1007 loss: 2.724963e-06
Iter: 1008 loss: 2.73260343e-06
Iter: 1009 loss: 2.72446596e-06
Iter: 1010 loss: 2.72244506e-06
Iter: 1011 loss: 2.72423449e-06
Iter: 1012 loss: 2.72126795e-06
Iter: 1013 loss: 2.71902491e-06
Iter: 1014 loss: 2.71862064e-06
Iter: 1015 loss: 2.71709723e-06
Iter: 1016 loss: 2.7142496e-06
Iter: 1017 loss: 2.72441184e-06
Iter: 1018 loss: 2.7135236e-06
Iter: 1019 loss: 2.71122394e-06
Iter: 1020 loss: 2.72671014e-06
Iter: 1021 loss: 2.71097315e-06
Iter: 1022 loss: 2.70891042e-06
Iter: 1023 loss: 2.72631064e-06
Iter: 1024 loss: 2.7088e-06
Iter: 1025 loss: 2.70745159e-06
Iter: 1026 loss: 2.70681676e-06
Iter: 1027 loss: 2.70617511e-06
Iter: 1028 loss: 2.70422311e-06
Iter: 1029 loss: 2.71682029e-06
Iter: 1030 loss: 2.70402279e-06
Iter: 1031 loss: 2.70232795e-06
Iter: 1032 loss: 2.70426949e-06
Iter: 1033 loss: 2.70139935e-06
Iter: 1034 loss: 2.69962243e-06
Iter: 1035 loss: 2.71316753e-06
Iter: 1036 loss: 2.69949351e-06
Iter: 1037 loss: 2.69798466e-06
Iter: 1038 loss: 2.70508372e-06
Iter: 1039 loss: 2.69768884e-06
Iter: 1040 loss: 2.69664724e-06
Iter: 1041 loss: 2.69551174e-06
Iter: 1042 loss: 2.69534644e-06
Iter: 1043 loss: 2.69343127e-06
Iter: 1044 loss: 2.700913e-06
Iter: 1045 loss: 2.69297357e-06
Iter: 1046 loss: 2.69126303e-06
Iter: 1047 loss: 2.69185193e-06
Iter: 1048 loss: 2.69005614e-06
Iter: 1049 loss: 2.68803797e-06
Iter: 1050 loss: 2.68819576e-06
Iter: 1051 loss: 2.6864634e-06
Iter: 1052 loss: 2.68374811e-06
Iter: 1053 loss: 2.69473912e-06
Iter: 1054 loss: 2.68313784e-06
Iter: 1055 loss: 2.68141798e-06
Iter: 1056 loss: 2.68141275e-06
Iter: 1057 loss: 2.67972882e-06
Iter: 1058 loss: 2.67907467e-06
Iter: 1059 loss: 2.67815881e-06
Iter: 1060 loss: 2.67620612e-06
Iter: 1061 loss: 2.68444319e-06
Iter: 1062 loss: 2.6757948e-06
Iter: 1063 loss: 2.67387236e-06
Iter: 1064 loss: 2.68121812e-06
Iter: 1065 loss: 2.67343921e-06
Iter: 1066 loss: 2.67183532e-06
Iter: 1067 loss: 2.67624364e-06
Iter: 1068 loss: 2.67130213e-06
Iter: 1069 loss: 2.66988536e-06
Iter: 1070 loss: 2.68437952e-06
Iter: 1071 loss: 2.66981147e-06
Iter: 1072 loss: 2.66868688e-06
Iter: 1073 loss: 2.66824372e-06
Iter: 1074 loss: 2.66763118e-06
Iter: 1075 loss: 2.6662583e-06
Iter: 1076 loss: 2.66873985e-06
Iter: 1077 loss: 2.6656644e-06
Iter: 1078 loss: 2.66385882e-06
Iter: 1079 loss: 2.6651328e-06
Iter: 1080 loss: 2.66272446e-06
Iter: 1081 loss: 2.66060033e-06
Iter: 1082 loss: 2.66288544e-06
Iter: 1083 loss: 2.659453e-06
Iter: 1084 loss: 2.65727613e-06
Iter: 1085 loss: 2.6588998e-06
Iter: 1086 loss: 2.65596418e-06
Iter: 1087 loss: 2.65322501e-06
Iter: 1088 loss: 2.66768711e-06
Iter: 1089 loss: 2.65281528e-06
Iter: 1090 loss: 2.65055155e-06
Iter: 1091 loss: 2.68057397e-06
Iter: 1092 loss: 2.65056747e-06
Iter: 1093 loss: 2.64894607e-06
Iter: 1094 loss: 2.64652772e-06
Iter: 1095 loss: 2.64647815e-06
Iter: 1096 loss: 2.64407527e-06
Iter: 1097 loss: 2.67857831e-06
Iter: 1098 loss: 2.64406663e-06
Iter: 1099 loss: 2.64236064e-06
Iter: 1100 loss: 2.6448788e-06
Iter: 1101 loss: 2.64155869e-06
Iter: 1102 loss: 2.63997458e-06
Iter: 1103 loss: 2.65322547e-06
Iter: 1104 loss: 2.6398925e-06
Iter: 1105 loss: 2.63840047e-06
Iter: 1106 loss: 2.64077062e-06
Iter: 1107 loss: 2.63770198e-06
Iter: 1108 loss: 2.63622951e-06
Iter: 1109 loss: 2.63583297e-06
Iter: 1110 loss: 2.63491984e-06
Iter: 1111 loss: 2.63302263e-06
Iter: 1112 loss: 2.6425846e-06
Iter: 1113 loss: 2.63268612e-06
Iter: 1114 loss: 2.63093943e-06
Iter: 1115 loss: 2.63053084e-06
Iter: 1116 loss: 2.62941057e-06
Iter: 1117 loss: 2.62705271e-06
Iter: 1118 loss: 2.62971753e-06
Iter: 1119 loss: 2.62579624e-06
Iter: 1120 loss: 2.62306139e-06
Iter: 1121 loss: 2.62712274e-06
Iter: 1122 loss: 2.62177196e-06
Iter: 1123 loss: 2.61975833e-06
Iter: 1124 loss: 2.61971923e-06
Iter: 1125 loss: 2.61780974e-06
Iter: 1126 loss: 2.62088e-06
Iter: 1127 loss: 2.61693e-06
Iter: 1128 loss: 2.6153848e-06
Iter: 1129 loss: 2.61682817e-06
Iter: 1130 loss: 2.61447281e-06
Iter: 1131 loss: 2.61259015e-06
Iter: 1132 loss: 2.6270618e-06
Iter: 1133 loss: 2.61245464e-06
Iter: 1134 loss: 2.61124887e-06
Iter: 1135 loss: 2.61441664e-06
Iter: 1136 loss: 2.6108637e-06
Iter: 1137 loss: 2.60959882e-06
Iter: 1138 loss: 2.61853279e-06
Iter: 1139 loss: 2.60948627e-06
Iter: 1140 loss: 2.60843285e-06
Iter: 1141 loss: 2.60757861e-06
Iter: 1142 loss: 2.60727029e-06
Iter: 1143 loss: 2.60564593e-06
Iter: 1144 loss: 2.6084449e-06
Iter: 1145 loss: 2.60498382e-06
Iter: 1146 loss: 2.6030425e-06
Iter: 1147 loss: 2.60821344e-06
Iter: 1148 loss: 2.60242336e-06
Iter: 1149 loss: 2.60052911e-06
Iter: 1150 loss: 2.60010802e-06
Iter: 1151 loss: 2.59891499e-06
Iter: 1152 loss: 2.59650847e-06
Iter: 1153 loss: 2.60225852e-06
Iter: 1154 loss: 2.59564786e-06
Iter: 1155 loss: 2.59331046e-06
Iter: 1156 loss: 2.59955323e-06
Iter: 1157 loss: 2.592486e-06
Iter: 1158 loss: 2.59109493e-06
Iter: 1159 loss: 2.59095782e-06
Iter: 1160 loss: 2.58987643e-06
Iter: 1161 loss: 2.58848922e-06
Iter: 1162 loss: 2.58840055e-06
Iter: 1163 loss: 2.58667296e-06
Iter: 1164 loss: 2.59792569e-06
Iter: 1165 loss: 2.58648788e-06
Iter: 1166 loss: 2.5847603e-06
Iter: 1167 loss: 2.58773366e-06
Iter: 1168 loss: 2.58399632e-06
Iter: 1169 loss: 2.58262207e-06
Iter: 1170 loss: 2.59859371e-06
Iter: 1171 loss: 2.58259274e-06
Iter: 1172 loss: 2.58135287e-06
Iter: 1173 loss: 2.58166619e-06
Iter: 1174 loss: 2.58045475e-06
Iter: 1175 loss: 2.57892611e-06
Iter: 1176 loss: 2.57974239e-06
Iter: 1177 loss: 2.5779259e-06
Iter: 1178 loss: 2.57620422e-06
Iter: 1179 loss: 2.58351429e-06
Iter: 1180 loss: 2.57585907e-06
Iter: 1181 loss: 2.5742238e-06
Iter: 1182 loss: 2.57568581e-06
Iter: 1183 loss: 2.57327429e-06
Iter: 1184 loss: 2.57152033e-06
Iter: 1185 loss: 2.57206739e-06
Iter: 1186 loss: 2.57023476e-06
Iter: 1187 loss: 2.56805924e-06
Iter: 1188 loss: 2.57307852e-06
Iter: 1189 loss: 2.56730618e-06
Iter: 1190 loss: 2.56516614e-06
Iter: 1191 loss: 2.57859347e-06
Iter: 1192 loss: 2.56493945e-06
Iter: 1193 loss: 2.56270278e-06
Iter: 1194 loss: 2.57463876e-06
Iter: 1195 loss: 2.56239264e-06
Iter: 1196 loss: 2.56100202e-06
Iter: 1197 loss: 2.56064413e-06
Iter: 1198 loss: 2.55975783e-06
Iter: 1199 loss: 2.55786358e-06
Iter: 1200 loss: 2.57455986e-06
Iter: 1201 loss: 2.55775058e-06
Iter: 1202 loss: 2.55631358e-06
Iter: 1203 loss: 2.55928762e-06
Iter: 1204 loss: 2.55570194e-06
Iter: 1205 loss: 2.55414625e-06
Iter: 1206 loss: 2.5669865e-06
Iter: 1207 loss: 2.55409896e-06
Iter: 1208 loss: 2.55313535e-06
Iter: 1209 loss: 2.55259692e-06
Iter: 1210 loss: 2.55219402e-06
Iter: 1211 loss: 2.55067744e-06
Iter: 1212 loss: 2.55298482e-06
Iter: 1213 loss: 2.54998145e-06
Iter: 1214 loss: 2.54845963e-06
Iter: 1215 loss: 2.55522332e-06
Iter: 1216 loss: 2.54814677e-06
Iter: 1217 loss: 2.54683209e-06
Iter: 1218 loss: 2.54689621e-06
Iter: 1219 loss: 2.54580982e-06
Iter: 1220 loss: 2.54402858e-06
Iter: 1221 loss: 2.54458632e-06
Iter: 1222 loss: 2.54276233e-06
Iter: 1223 loss: 2.54033876e-06
Iter: 1224 loss: 2.54725614e-06
Iter: 1225 loss: 2.5395625e-06
Iter: 1226 loss: 2.538236e-06
Iter: 1227 loss: 2.53810504e-06
Iter: 1228 loss: 2.53679764e-06
Iter: 1229 loss: 2.5356926e-06
Iter: 1230 loss: 2.53531698e-06
Iter: 1231 loss: 2.53379199e-06
Iter: 1232 loss: 2.54343877e-06
Iter: 1233 loss: 2.53362691e-06
Iter: 1234 loss: 2.53212306e-06
Iter: 1235 loss: 2.53624512e-06
Iter: 1236 loss: 2.53162625e-06
Iter: 1237 loss: 2.53034204e-06
Iter: 1238 loss: 2.53982535e-06
Iter: 1239 loss: 2.53023222e-06
Iter: 1240 loss: 2.52893051e-06
Iter: 1241 loss: 2.52865129e-06
Iter: 1242 loss: 2.52776044e-06
Iter: 1243 loss: 2.52627433e-06
Iter: 1244 loss: 2.52992822e-06
Iter: 1245 loss: 2.52573727e-06
Iter: 1246 loss: 2.52419522e-06
Iter: 1247 loss: 2.52622158e-06
Iter: 1248 loss: 2.52341306e-06
Iter: 1249 loss: 2.52150312e-06
Iter: 1250 loss: 2.52609129e-06
Iter: 1251 loss: 2.52080463e-06
Iter: 1252 loss: 2.51901679e-06
Iter: 1253 loss: 2.51961501e-06
Iter: 1254 loss: 2.51774986e-06
Iter: 1255 loss: 2.51559345e-06
Iter: 1256 loss: 2.51856818e-06
Iter: 1257 loss: 2.51449387e-06
Iter: 1258 loss: 2.51240454e-06
Iter: 1259 loss: 2.52804307e-06
Iter: 1260 loss: 2.5122622e-06
Iter: 1261 loss: 2.51078791e-06
Iter: 1262 loss: 2.53315557e-06
Iter: 1263 loss: 2.5107845e-06
Iter: 1264 loss: 2.50988205e-06
Iter: 1265 loss: 2.50830908e-06
Iter: 1266 loss: 2.50830544e-06
Iter: 1267 loss: 2.50692892e-06
Iter: 1268 loss: 2.50691255e-06
Iter: 1269 loss: 2.50582457e-06
Iter: 1270 loss: 2.50739845e-06
Iter: 1271 loss: 2.50528842e-06
Iter: 1272 loss: 2.50408129e-06
Iter: 1273 loss: 2.51341021e-06
Iter: 1274 loss: 2.50399148e-06
Iter: 1275 loss: 2.50305357e-06
Iter: 1276 loss: 2.50163293e-06
Iter: 1277 loss: 2.50160065e-06
Iter: 1278 loss: 2.49984305e-06
Iter: 1279 loss: 2.50919311e-06
Iter: 1280 loss: 2.4995511e-06
Iter: 1281 loss: 2.49814047e-06
Iter: 1282 loss: 2.50049015e-06
Iter: 1283 loss: 2.4975111e-06
Iter: 1284 loss: 2.49581649e-06
Iter: 1285 loss: 2.498409e-06
Iter: 1286 loss: 2.49502909e-06
Iter: 1287 loss: 2.49338495e-06
Iter: 1288 loss: 2.49469713e-06
Iter: 1289 loss: 2.49244931e-06
Iter: 1290 loss: 2.4904682e-06
Iter: 1291 loss: 2.49228106e-06
Iter: 1292 loss: 2.48935885e-06
Iter: 1293 loss: 2.48752531e-06
Iter: 1294 loss: 2.48754554e-06
Iter: 1295 loss: 2.48577362e-06
Iter: 1296 loss: 2.48842207e-06
Iter: 1297 loss: 2.48496053e-06
Iter: 1298 loss: 2.48351898e-06
Iter: 1299 loss: 2.48418064e-06
Iter: 1300 loss: 2.48252809e-06
Iter: 1301 loss: 2.48080823e-06
Iter: 1302 loss: 2.5014e-06
Iter: 1303 loss: 2.48078709e-06
Iter: 1304 loss: 2.47971684e-06
Iter: 1305 loss: 2.48383822e-06
Iter: 1306 loss: 2.47945263e-06
Iter: 1307 loss: 2.47814114e-06
Iter: 1308 loss: 2.47838238e-06
Iter: 1309 loss: 2.47715479e-06
Iter: 1310 loss: 2.475786e-06
Iter: 1311 loss: 2.47738171e-06
Iter: 1312 loss: 2.47508024e-06
Iter: 1313 loss: 2.47350044e-06
Iter: 1314 loss: 2.47918251e-06
Iter: 1315 loss: 2.47307526e-06
Iter: 1316 loss: 2.47172375e-06
Iter: 1317 loss: 2.47429193e-06
Iter: 1318 loss: 2.47112803e-06
Iter: 1319 loss: 2.46946411e-06
Iter: 1320 loss: 2.4705314e-06
Iter: 1321 loss: 2.46843547e-06
Iter: 1322 loss: 2.4665469e-06
Iter: 1323 loss: 2.46719355e-06
Iter: 1324 loss: 2.46523155e-06
Iter: 1325 loss: 2.46277978e-06
Iter: 1326 loss: 2.47257458e-06
Iter: 1327 loss: 2.46220111e-06
Iter: 1328 loss: 2.46078616e-06
Iter: 1329 loss: 2.46068203e-06
Iter: 1330 loss: 2.4595879e-06
Iter: 1331 loss: 2.45826732e-06
Iter: 1332 loss: 2.45812e-06
Iter: 1333 loss: 2.45669912e-06
Iter: 1334 loss: 2.4699616e-06
Iter: 1335 loss: 2.45663159e-06
Iter: 1336 loss: 2.45529282e-06
Iter: 1337 loss: 2.4594442e-06
Iter: 1338 loss: 2.45491424e-06
Iter: 1339 loss: 2.4539147e-06
Iter: 1340 loss: 2.46376067e-06
Iter: 1341 loss: 2.453869e-06
Iter: 1342 loss: 2.45311821e-06
Iter: 1343 loss: 2.45186084e-06
Iter: 1344 loss: 2.4837509e-06
Iter: 1345 loss: 2.45184651e-06
Iter: 1346 loss: 2.45040042e-06
Iter: 1347 loss: 2.45803949e-06
Iter: 1348 loss: 2.45017e-06
Iter: 1349 loss: 2.44882722e-06
Iter: 1350 loss: 2.450598e-06
Iter: 1351 loss: 2.44816124e-06
Iter: 1352 loss: 2.44661078e-06
Iter: 1353 loss: 2.44939679e-06
Iter: 1354 loss: 2.44592252e-06
Iter: 1355 loss: 2.4441174e-06
Iter: 1356 loss: 2.44614648e-06
Iter: 1357 loss: 2.44317653e-06
