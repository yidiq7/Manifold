+ RUN=3
+ export CUDA_VISIBLE_DEVICES=3
+ CUDA_VISIBLE_DEVICES=3
+ LAYERS=300_300_300_1
+ case $RUN in
+ PSI=0
+ OPTIONS='			 --optimizer adam 				 --n_pairs 50000 				 --batch_size 5000 				 --max_epochs 200 				 --learning_rate 0.001 				 --decay_rate 0.98 				 --loss_func weighted_MSE 
'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output80
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output81
+ for fn in f1
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL='--load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0
+ date
Mon Nov  2 08:23:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4
+ date
Mon Nov  2 08:23:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8
+ date
Mon Nov  2 08:23:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0568bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca055b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca05ef730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0525598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca05251e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca05ef7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0525048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca04117b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0411840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02db1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca04850d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0467d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03acbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca047f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03a5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca00fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca047f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca031cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0326d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca031c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03f4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca01e41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca03f4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0063f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0065620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0286c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca0286488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca01701e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bf0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02b5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bfe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca02bf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbc5473e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca022c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbca00b5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 8.216926e-05
test_loss: 7.9119265e-05
train_loss: 2.7157625e-05
test_loss: 2.6379157e-05
train_loss: 1.4953286e-05
test_loss: 1.4993718e-05
train_loss: 1.05363615e-05
test_loss: 1.0222612e-05
train_loss: 7.1873988e-06
test_loss: 7.733457e-06
train_loss: 6.15719e-06
test_loss: 6.1828973e-06
train_loss: 5.1035304e-06
test_loss: 5.3403587e-06
train_loss: 4.720052e-06
test_loss: 4.726378e-06
train_loss: 4.075523e-06
test_loss: 4.2897727e-06
train_loss: 3.7766736e-06
test_loss: 4.027294e-06
train_loss: 3.6861602e-06
test_loss: 3.7895384e-06
train_loss: 3.5211422e-06
test_loss: 3.5783332e-06
train_loss: 3.2120652e-06
test_loss: 3.4376385e-06
train_loss: 3.3228562e-06
test_loss: 3.3004135e-06
train_loss: 3.094392e-06
test_loss: 3.1880309e-06
train_loss: 2.931721e-06
test_loss: 3.1044915e-06
train_loss: 2.9443454e-06
test_loss: 3.0290498e-06
train_loss: 2.8592808e-06
test_loss: 3.0059382e-06
train_loss: 2.708738e-06
test_loss: 2.9309165e-06
train_loss: 2.7724677e-06
test_loss: 2.8165919e-06
train_loss: 2.621251e-06
test_loss: 2.8030465e-06
train_loss: 2.7403785e-06
test_loss: 2.7565186e-06
train_loss: 2.6872394e-06
test_loss: 2.7237386e-06
train_loss: 2.595432e-06
test_loss: 2.6609316e-06
train_loss: 2.4806632e-06
test_loss: 2.6381865e-06
train_loss: 2.5350553e-06
test_loss: 2.5687307e-06
train_loss: 2.4390886e-06
test_loss: 2.5763616e-06
train_loss: 2.3225546e-06
test_loss: 2.5463219e-06
train_loss: 2.2953095e-06
test_loss: 2.5223248e-06
train_loss: 2.3330615e-06
test_loss: 2.4701158e-06
train_loss: 2.4471733e-06
test_loss: 2.4822061e-06
train_loss: 2.3267357e-06
test_loss: 2.4499882e-06
train_loss: 2.3122766e-06
test_loss: 2.4284932e-06
train_loss: 2.4472533e-06
test_loss: 2.4035364e-06
train_loss: 2.246581e-06
test_loss: 2.4002218e-06
train_loss: 2.357249e-06
test_loss: 2.4214437e-06
train_loss: 2.4301955e-06
test_loss: 2.374118e-06
train_loss: 2.3189266e-06
test_loss: 2.359728e-06
train_loss: 2.289785e-06
test_loss: 2.3541777e-06
train_loss: 2.1633332e-06
test_loss: 2.3399703e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bddbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6be30ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6be24268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd817b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd81ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd81488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bd81c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc658c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc65400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc3d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bc31268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59a38f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59a38d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bcccd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599caf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599a7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59a09c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6bccc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c599a7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c598b1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c598c5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c598fc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5985bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5985ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5985ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5986bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5986b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597f51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597b8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597d8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c5970bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c596aaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c597b8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c596e1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c59768f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.17011234e-06
Iter: 2 loss: 2.15406317e-06
Iter: 3 loss: 2.15337104e-06
Iter: 4 loss: 2.1448966e-06
Iter: 5 loss: 2.15142973e-06
Iter: 6 loss: 2.13972817e-06
Iter: 7 loss: 2.13671274e-06
Iter: 8 loss: 2.14291913e-06
Iter: 9 loss: 2.13551289e-06
Iter: 10 loss: 2.13391581e-06
Iter: 11 loss: 2.13378053e-06
Iter: 12 loss: 2.13271051e-06
Iter: 13 loss: 2.13317253e-06
Iter: 14 loss: 2.13196654e-06
Iter: 15 loss: 2.13077374e-06
Iter: 16 loss: 2.13500152e-06
Iter: 17 loss: 2.13045541e-06
Iter: 18 loss: 2.1293049e-06
Iter: 19 loss: 2.1348842e-06
Iter: 20 loss: 2.12909663e-06
Iter: 21 loss: 2.12823443e-06
Iter: 22 loss: 2.12647797e-06
Iter: 23 loss: 2.1596652e-06
Iter: 24 loss: 2.12644909e-06
Iter: 25 loss: 2.12590544e-06
Iter: 26 loss: 2.12536497e-06
Iter: 27 loss: 2.12483656e-06
Iter: 28 loss: 2.12354212e-06
Iter: 29 loss: 2.13603221e-06
Iter: 30 loss: 2.12335976e-06
Iter: 31 loss: 2.12233954e-06
Iter: 32 loss: 2.12578948e-06
Iter: 33 loss: 2.12207e-06
Iter: 34 loss: 2.12122632e-06
Iter: 35 loss: 2.12377108e-06
Iter: 36 loss: 2.12095438e-06
Iter: 37 loss: 2.12008808e-06
Iter: 38 loss: 2.12124542e-06
Iter: 39 loss: 2.11964607e-06
Iter: 40 loss: 2.11898396e-06
Iter: 41 loss: 2.12543182e-06
Iter: 42 loss: 2.11896304e-06
Iter: 43 loss: 2.11884844e-06
Iter: 44 loss: 2.11869497e-06
Iter: 45 loss: 2.11853512e-06
Iter: 46 loss: 2.118054e-06
Iter: 47 loss: 2.12348732e-06
Iter: 48 loss: 2.11800307e-06
Iter: 49 loss: 2.1176952e-06
Iter: 50 loss: 2.12048462e-06
Iter: 51 loss: 2.11768793e-06
Iter: 52 loss: 2.11726592e-06
Iter: 53 loss: 2.11751058e-06
Iter: 54 loss: 2.11698853e-06
Iter: 55 loss: 2.11654833e-06
Iter: 56 loss: 2.11650286e-06
Iter: 57 loss: 2.11619772e-06
Iter: 58 loss: 2.11576548e-06
Iter: 59 loss: 2.11574798e-06
Iter: 60 loss: 2.11553015e-06
Iter: 61 loss: 2.11511269e-06
Iter: 62 loss: 2.11511588e-06
Iter: 63 loss: 2.1148519e-06
Iter: 64 loss: 2.11482234e-06
Iter: 65 loss: 2.11462975e-06
Iter: 66 loss: 2.11456063e-06
Iter: 67 loss: 2.11446263e-06
Iter: 68 loss: 2.11413953e-06
Iter: 69 loss: 2.11388692e-06
Iter: 70 loss: 2.1138087e-06
Iter: 71 loss: 2.11336669e-06
Iter: 72 loss: 2.11328552e-06
Iter: 73 loss: 2.11301517e-06
Iter: 74 loss: 2.11241331e-06
Iter: 75 loss: 2.11649694e-06
Iter: 76 loss: 2.11235511e-06
Iter: 77 loss: 2.11235647e-06
Iter: 78 loss: 2.11216638e-06
Iter: 79 loss: 2.11202041e-06
Iter: 80 loss: 2.11173779e-06
Iter: 81 loss: 2.11749057e-06
Iter: 82 loss: 2.11174256e-06
Iter: 83 loss: 2.11152474e-06
Iter: 84 loss: 2.11238194e-06
Iter: 85 loss: 2.11147108e-06
Iter: 86 loss: 2.11117413e-06
Iter: 87 loss: 2.11260385e-06
Iter: 88 loss: 2.11112956e-06
Iter: 89 loss: 2.11096039e-06
Iter: 90 loss: 2.11051861e-06
Iter: 91 loss: 2.11355655e-06
Iter: 92 loss: 2.11041743e-06
Iter: 93 loss: 2.11000656e-06
Iter: 94 loss: 2.10997632e-06
Iter: 95 loss: 2.10973622e-06
Iter: 96 loss: 2.10947064e-06
Iter: 97 loss: 2.10943881e-06
Iter: 98 loss: 2.10919643e-06
Iter: 99 loss: 2.10917347e-06
Iter: 100 loss: 2.1090234e-06
Iter: 101 loss: 2.10887515e-06
Iter: 102 loss: 2.10884e-06
Iter: 103 loss: 2.10862027e-06
Iter: 104 loss: 2.10926601e-06
Iter: 105 loss: 2.10856751e-06
Iter: 106 loss: 2.10839153e-06
Iter: 107 loss: 2.10828057e-06
Iter: 108 loss: 2.10821781e-06
Iter: 109 loss: 2.10802932e-06
Iter: 110 loss: 2.10803182e-06
Iter: 111 loss: 2.10783628e-06
Iter: 112 loss: 2.10747066e-06
Iter: 113 loss: 2.11511815e-06
Iter: 114 loss: 2.10745202e-06
Iter: 115 loss: 2.10708049e-06
Iter: 116 loss: 2.10726284e-06
Iter: 117 loss: 2.10681742e-06
Iter: 118 loss: 2.10672943e-06
Iter: 119 loss: 2.10658e-06
Iter: 120 loss: 2.10643566e-06
Iter: 121 loss: 2.1061428e-06
Iter: 122 loss: 2.11339716e-06
Iter: 123 loss: 2.10613689e-06
Iter: 124 loss: 2.10590201e-06
Iter: 125 loss: 2.10767985e-06
Iter: 126 loss: 2.10588519e-06
Iter: 127 loss: 2.10556664e-06
Iter: 128 loss: 2.1057258e-06
Iter: 129 loss: 2.10535518e-06
Iter: 130 loss: 2.10513213e-06
Iter: 131 loss: 2.106995e-06
Iter: 132 loss: 2.1051e-06
Iter: 133 loss: 2.1048786e-06
Iter: 134 loss: 2.10483245e-06
Iter: 135 loss: 2.10468261e-06
Iter: 136 loss: 2.10443864e-06
Iter: 137 loss: 2.10507778e-06
Iter: 138 loss: 2.1043561e-06
Iter: 139 loss: 2.10410735e-06
Iter: 140 loss: 2.10396888e-06
Iter: 141 loss: 2.10385224e-06
Iter: 142 loss: 2.10355802e-06
Iter: 143 loss: 2.10594135e-06
Iter: 144 loss: 2.10353846e-06
Iter: 145 loss: 2.10330336e-06
Iter: 146 loss: 2.10546682e-06
Iter: 147 loss: 2.10329881e-06
Iter: 148 loss: 2.10311759e-06
Iter: 149 loss: 2.10264966e-06
Iter: 150 loss: 2.10671351e-06
Iter: 151 loss: 2.10258531e-06
Iter: 152 loss: 2.10217195e-06
Iter: 153 loss: 2.10216535e-06
Iter: 154 loss: 2.10173403e-06
Iter: 155 loss: 2.10233884e-06
Iter: 156 loss: 2.1015353e-06
Iter: 157 loss: 2.1012645e-06
Iter: 158 loss: 2.10143367e-06
Iter: 159 loss: 2.10107419e-06
Iter: 160 loss: 2.10075154e-06
Iter: 161 loss: 2.10415806e-06
Iter: 162 loss: 2.10074e-06
Iter: 163 loss: 2.1005385e-06
Iter: 164 loss: 2.10058124e-06
Iter: 165 loss: 2.10035569e-06
Iter: 166 loss: 2.10010262e-06
Iter: 167 loss: 2.10216376e-06
Iter: 168 loss: 2.10009807e-06
Iter: 169 loss: 2.09993527e-06
Iter: 170 loss: 2.09972882e-06
Iter: 171 loss: 2.09970267e-06
Iter: 172 loss: 2.09934433e-06
Iter: 173 loss: 2.09977043e-06
Iter: 174 loss: 2.09916652e-06
Iter: 175 loss: 2.09874929e-06
Iter: 176 loss: 2.09957e-06
Iter: 177 loss: 2.09857535e-06
Iter: 178 loss: 2.09839072e-06
Iter: 179 loss: 2.09835616e-06
Iter: 180 loss: 2.0981397e-06
Iter: 181 loss: 2.09775408e-06
Iter: 182 loss: 2.10442704e-06
Iter: 183 loss: 2.09773157e-06
Iter: 184 loss: 2.09744553e-06
Iter: 185 loss: 2.10159942e-06
Iter: 186 loss: 2.09745576e-06
Iter: 187 loss: 2.09719337e-06
Iter: 188 loss: 2.09855261e-06
Iter: 189 loss: 2.09715358e-06
Iter: 190 loss: 2.09696645e-06
Iter: 191 loss: 2.09660402e-06
Iter: 192 loss: 2.10314283e-06
Iter: 193 loss: 2.09661403e-06
Iter: 194 loss: 2.09632026e-06
Iter: 195 loss: 2.09631071e-06
Iter: 196 loss: 2.09610857e-06
Iter: 197 loss: 2.09594623e-06
Iter: 198 loss: 2.09588848e-06
Iter: 199 loss: 2.09556674e-06
Iter: 200 loss: 2.09813265e-06
Iter: 201 loss: 2.09555378e-06
Iter: 202 loss: 2.0953612e-06
Iter: 203 loss: 2.09516884e-06
Iter: 204 loss: 2.09513428e-06
Iter: 205 loss: 2.09483642e-06
Iter: 206 loss: 2.09625773e-06
Iter: 207 loss: 2.09481504e-06
Iter: 208 loss: 2.09455266e-06
Iter: 209 loss: 2.09457016e-06
Iter: 210 loss: 2.09432437e-06
Iter: 211 loss: 2.09407131e-06
Iter: 212 loss: 2.09721202e-06
Iter: 213 loss: 2.09405903e-06
Iter: 214 loss: 2.09371024e-06
Iter: 215 loss: 2.09338987e-06
Iter: 216 loss: 2.09331779e-06
Iter: 217 loss: 2.09288373e-06
Iter: 218 loss: 2.09385689e-06
Iter: 219 loss: 2.09275822e-06
Iter: 220 loss: 2.0924108e-06
Iter: 221 loss: 2.09588893e-06
Iter: 222 loss: 2.09239238e-06
Iter: 223 loss: 2.09219752e-06
Iter: 224 loss: 2.09182963e-06
Iter: 225 loss: 2.10023609e-06
Iter: 226 loss: 2.09182554e-06
Iter: 227 loss: 2.09155451e-06
Iter: 228 loss: 2.09153268e-06
Iter: 229 loss: 2.09122732e-06
Iter: 230 loss: 2.09115e-06
Iter: 231 loss: 2.09097357e-06
Iter: 232 loss: 2.09070504e-06
Iter: 233 loss: 2.09463883e-06
Iter: 234 loss: 2.09071231e-06
Iter: 235 loss: 2.09049176e-06
Iter: 236 loss: 2.09006885e-06
Iter: 237 loss: 2.09761e-06
Iter: 238 loss: 2.09007e-06
Iter: 239 loss: 2.08960955e-06
Iter: 240 loss: 2.09253062e-06
Iter: 241 loss: 2.08955225e-06
Iter: 242 loss: 2.08915526e-06
Iter: 243 loss: 2.09023642e-06
Iter: 244 loss: 2.08904385e-06
Iter: 245 loss: 2.08873257e-06
Iter: 246 loss: 2.08849815e-06
Iter: 247 loss: 2.08841129e-06
Iter: 248 loss: 2.08842334e-06
Iter: 249 loss: 2.08819756e-06
Iter: 250 loss: 2.08803431e-06
Iter: 251 loss: 2.08747974e-06
Iter: 252 loss: 2.09055315e-06
Iter: 253 loss: 2.08730626e-06
Iter: 254 loss: 2.0871305e-06
Iter: 255 loss: 2.08701636e-06
Iter: 256 loss: 2.08668484e-06
Iter: 257 loss: 2.08655456e-06
Iter: 258 loss: 2.08640859e-06
Iter: 259 loss: 2.08611823e-06
Iter: 260 loss: 2.08661231e-06
Iter: 261 loss: 2.08598317e-06
Iter: 262 loss: 2.08571623e-06
Iter: 263 loss: 2.08910842e-06
Iter: 264 loss: 2.08569941e-06
Iter: 265 loss: 2.08555912e-06
Iter: 266 loss: 2.08551705e-06
Iter: 267 loss: 2.08540087e-06
Iter: 268 loss: 2.08510346e-06
Iter: 269 loss: 2.0857874e-06
Iter: 270 loss: 2.08497931e-06
Iter: 271 loss: 2.08472966e-06
Iter: 272 loss: 2.0844202e-06
Iter: 273 loss: 2.08438632e-06
Iter: 274 loss: 2.08403708e-06
Iter: 275 loss: 2.08724964e-06
Iter: 276 loss: 2.08401298e-06
Iter: 277 loss: 2.08368056e-06
Iter: 278 loss: 2.083445e-06
Iter: 279 loss: 2.08333586e-06
Iter: 280 loss: 2.08301708e-06
Iter: 281 loss: 2.0859984e-06
Iter: 282 loss: 2.08298366e-06
Iter: 283 loss: 2.08279312e-06
Iter: 284 loss: 2.08278129e-06
Iter: 285 loss: 2.08259394e-06
Iter: 286 loss: 2.08213328e-06
Iter: 287 loss: 2.08476695e-06
Iter: 288 loss: 2.08200481e-06
Iter: 289 loss: 2.08181018e-06
Iter: 290 loss: 2.08166693e-06
Iter: 291 loss: 2.08140455e-06
Iter: 292 loss: 2.08084316e-06
Iter: 293 loss: 2.08904908e-06
Iter: 294 loss: 2.08085658e-06
Iter: 295 loss: 2.08051915e-06
Iter: 296 loss: 2.08052438e-06
Iter: 297 loss: 2.08021493e-06
Iter: 298 loss: 2.08094525e-06
Iter: 299 loss: 2.08010897e-06
Iter: 300 loss: 2.07994708e-06
Iter: 301 loss: 2.08111851e-06
Iter: 302 loss: 2.07993253e-06
Iter: 303 loss: 2.07976336e-06
Iter: 304 loss: 2.07959101e-06
Iter: 305 loss: 2.07956805e-06
Iter: 306 loss: 2.07936296e-06
Iter: 307 loss: 2.07946096e-06
Iter: 308 loss: 2.07920698e-06
Iter: 309 loss: 2.07883272e-06
Iter: 310 loss: 2.07987614e-06
Iter: 311 loss: 2.07874837e-06
Iter: 312 loss: 2.07838457e-06
Iter: 313 loss: 2.07820653e-06
Iter: 314 loss: 2.07802464e-06
Iter: 315 loss: 2.07754215e-06
Iter: 316 loss: 2.0793866e-06
Iter: 317 loss: 2.07742687e-06
Iter: 318 loss: 2.07701828e-06
Iter: 319 loss: 2.07882044e-06
Iter: 320 loss: 2.07695211e-06
Iter: 321 loss: 2.07676203e-06
Iter: 322 loss: 2.07676476e-06
Iter: 323 loss: 2.07654216e-06
Iter: 324 loss: 2.07621633e-06
Iter: 325 loss: 2.07622634e-06
Iter: 326 loss: 2.07597259e-06
Iter: 327 loss: 2.07837934e-06
Iter: 328 loss: 2.07595735e-06
Iter: 329 loss: 2.07568883e-06
Iter: 330 loss: 2.07589915e-06
Iter: 331 loss: 2.07554376e-06
Iter: 332 loss: 2.07537778e-06
Iter: 333 loss: 2.07648532e-06
Iter: 334 loss: 2.07530866e-06
Iter: 335 loss: 2.07510493e-06
Iter: 336 loss: 2.07528774e-06
Iter: 337 loss: 2.0749942e-06
Iter: 338 loss: 2.07481708e-06
Iter: 339 loss: 2.07521271e-06
Iter: 340 loss: 2.07472613e-06
Iter: 341 loss: 2.07455378e-06
Iter: 342 loss: 2.07599032e-06
Iter: 343 loss: 2.07451944e-06
Iter: 344 loss: 2.07436187e-06
Iter: 345 loss: 2.07417315e-06
Iter: 346 loss: 2.0741677e-06
Iter: 347 loss: 2.07384892e-06
Iter: 348 loss: 2.07410721e-06
Iter: 349 loss: 2.073627e-06
Iter: 350 loss: 2.07320977e-06
Iter: 351 loss: 2.07314633e-06
Iter: 352 loss: 2.07287167e-06
Iter: 353 loss: 2.07238395e-06
Iter: 354 loss: 2.07557423e-06
Iter: 355 loss: 2.07231119e-06
Iter: 356 loss: 2.0721634e-06
Iter: 357 loss: 2.07208905e-06
Iter: 358 loss: 2.07191852e-06
Iter: 359 loss: 2.07167795e-06
Iter: 360 loss: 2.07165249e-06
Iter: 361 loss: 2.07140738e-06
Iter: 362 loss: 2.07302082e-06
Iter: 363 loss: 2.07137282e-06
Iter: 364 loss: 2.07105495e-06
Iter: 365 loss: 2.0709731e-06
Iter: 366 loss: 2.07078187e-06
Iter: 367 loss: 2.07052494e-06
Iter: 368 loss: 2.07316702e-06
Iter: 369 loss: 2.07050471e-06
Iter: 370 loss: 2.07021094e-06
Iter: 371 loss: 2.07010271e-06
Iter: 372 loss: 2.06997197e-06
Iter: 373 loss: 2.06968502e-06
Iter: 374 loss: 2.07107769e-06
Iter: 375 loss: 2.06961431e-06
Iter: 376 loss: 2.06932714e-06
Iter: 377 loss: 2.07018638e-06
Iter: 378 loss: 2.06920458e-06
Iter: 379 loss: 2.06898903e-06
Iter: 380 loss: 2.06904565e-06
Iter: 381 loss: 2.06882169e-06
Iter: 382 loss: 2.0684804e-06
Iter: 383 loss: 2.06859795e-06
Iter: 384 loss: 2.06822688e-06
Iter: 385 loss: 2.06777395e-06
Iter: 386 loss: 2.06794539e-06
Iter: 387 loss: 2.06746654e-06
Iter: 388 loss: 2.06696291e-06
Iter: 389 loss: 2.07090511e-06
Iter: 390 loss: 2.06694813e-06
Iter: 391 loss: 2.06659251e-06
Iter: 392 loss: 2.06659797e-06
Iter: 393 loss: 2.06642972e-06
Iter: 394 loss: 2.06619666e-06
Iter: 395 loss: 2.06618597e-06
Iter: 396 loss: 2.06592381e-06
Iter: 397 loss: 2.06592131e-06
Iter: 398 loss: 2.06576146e-06
Iter: 399 loss: 2.06539903e-06
Iter: 400 loss: 2.07359017e-06
Iter: 401 loss: 2.06540221e-06
Iter: 402 loss: 2.06514392e-06
Iter: 403 loss: 2.06513096e-06
Iter: 404 loss: 2.06494815e-06
Iter: 405 loss: 2.06461709e-06
Iter: 406 loss: 2.06461482e-06
Iter: 407 loss: 2.06426421e-06
Iter: 408 loss: 2.06870845e-06
Iter: 409 loss: 2.0642633e-06
Iter: 410 loss: 2.06398772e-06
Iter: 411 loss: 2.06353798e-06
Iter: 412 loss: 2.06352115e-06
Iter: 413 loss: 2.06307641e-06
Iter: 414 loss: 2.06529103e-06
Iter: 415 loss: 2.06298091e-06
Iter: 416 loss: 2.06252889e-06
Iter: 417 loss: 2.06252616e-06
Iter: 418 loss: 2.06215282e-06
Iter: 419 loss: 2.06164805e-06
Iter: 420 loss: 2.06324103e-06
Iter: 421 loss: 2.0615289e-06
Iter: 422 loss: 2.06114782e-06
Iter: 423 loss: 2.06651703e-06
Iter: 424 loss: 2.06114714e-06
Iter: 425 loss: 2.06076515e-06
Iter: 426 loss: 2.06047025e-06
Iter: 427 loss: 2.06032519e-06
Iter: 428 loss: 2.05990136e-06
Iter: 429 loss: 2.06324967e-06
Iter: 430 loss: 2.05986385e-06
Iter: 431 loss: 2.05944957e-06
Iter: 432 loss: 2.05965e-06
Iter: 433 loss: 2.05913148e-06
Iter: 434 loss: 2.05873357e-06
Iter: 435 loss: 2.06088725e-06
Iter: 436 loss: 2.05867013e-06
Iter: 437 loss: 2.05823835e-06
Iter: 438 loss: 2.05861193e-06
Iter: 439 loss: 2.05795914e-06
Iter: 440 loss: 2.05757806e-06
Iter: 441 loss: 2.05875176e-06
Iter: 442 loss: 2.05746051e-06
Iter: 443 loss: 2.05697597e-06
Iter: 444 loss: 2.05786182e-06
Iter: 445 loss: 2.05675406e-06
Iter: 446 loss: 2.05628703e-06
Iter: 447 loss: 2.05574133e-06
Iter: 448 loss: 2.05568017e-06
Iter: 449 loss: 2.05494757e-06
Iter: 450 loss: 2.06109144e-06
Iter: 451 loss: 2.05492461e-06
Iter: 452 loss: 2.05442529e-06
Iter: 453 loss: 2.05423612e-06
Iter: 454 loss: 2.05398032e-06
Iter: 455 loss: 2.05356832e-06
Iter: 456 loss: 2.0535681e-06
Iter: 457 loss: 2.0531329e-06
Iter: 458 loss: 2.05408696e-06
Iter: 459 loss: 2.05297579e-06
Iter: 460 loss: 2.05264314e-06
Iter: 461 loss: 2.05279275e-06
Iter: 462 loss: 2.05239053e-06
Iter: 463 loss: 2.05187189e-06
Iter: 464 loss: 2.05533797e-06
Iter: 465 loss: 2.05184097e-06
Iter: 466 loss: 2.05146284e-06
Iter: 467 loss: 2.05112497e-06
Iter: 468 loss: 2.05103811e-06
Iter: 469 loss: 2.05042465e-06
Iter: 470 loss: 2.05721039e-06
Iter: 471 loss: 2.05043489e-06
Iter: 472 loss: 2.05011747e-06
Iter: 473 loss: 2.04996059e-06
Iter: 474 loss: 2.04979528e-06
Iter: 475 loss: 2.04946809e-06
Iter: 476 loss: 2.04947719e-06
Iter: 477 loss: 2.04928119e-06
Iter: 478 loss: 2.04890603e-06
Iter: 479 loss: 2.05727201e-06
Iter: 480 loss: 2.04890443e-06
Iter: 481 loss: 2.04841035e-06
Iter: 482 loss: 2.04972412e-06
Iter: 483 loss: 2.04825164e-06
Iter: 484 loss: 2.04760818e-06
Iter: 485 loss: 2.04797311e-06
Iter: 486 loss: 2.04721e-06
Iter: 487 loss: 2.04639446e-06
Iter: 488 loss: 2.04657272e-06
Iter: 489 loss: 2.04579419e-06
Iter: 490 loss: 2.04618277e-06
Iter: 491 loss: 2.04539833e-06
Iter: 492 loss: 2.04514959e-06
Iter: 493 loss: 2.04468256e-06
Iter: 494 loss: 2.05404308e-06
Iter: 495 loss: 2.04469166e-06
Iter: 496 loss: 2.04431217e-06
Iter: 497 loss: 2.04431285e-06
Iter: 498 loss: 2.04406319e-06
Iter: 499 loss: 2.04376238e-06
Iter: 500 loss: 2.043726e-06
Iter: 501 loss: 2.04342177e-06
Iter: 502 loss: 2.04342041e-06
Iter: 503 loss: 2.04316075e-06
Iter: 504 loss: 2.04277057e-06
Iter: 505 loss: 2.04274966e-06
Iter: 506 loss: 2.04233811e-06
Iter: 507 loss: 2.04664548e-06
Iter: 508 loss: 2.04231469e-06
Iter: 509 loss: 2.04189064e-06
Iter: 510 loss: 2.0417383e-06
Iter: 511 loss: 2.0414609e-06
Iter: 512 loss: 2.0410273e-06
Iter: 513 loss: 2.04144e-06
Iter: 514 loss: 2.04076105e-06
Iter: 515 loss: 2.04028788e-06
Iter: 516 loss: 2.04316621e-06
Iter: 517 loss: 2.04024127e-06
Iter: 518 loss: 2.03987111e-06
Iter: 519 loss: 2.03978016e-06
Iter: 520 loss: 2.03951367e-06
Iter: 521 loss: 2.03921127e-06
Iter: 522 loss: 2.04469598e-06
Iter: 523 loss: 2.03920604e-06
Iter: 524 loss: 2.03881655e-06
Iter: 525 loss: 2.03867512e-06
Iter: 526 loss: 2.03843661e-06
Iter: 527 loss: 2.03804666e-06
Iter: 528 loss: 2.03978334e-06
Iter: 529 loss: 2.03797867e-06
Iter: 530 loss: 2.0375046e-06
Iter: 531 loss: 2.03844274e-06
Iter: 532 loss: 2.03732429e-06
Iter: 533 loss: 2.03703485e-06
Iter: 534 loss: 2.03838408e-06
Iter: 535 loss: 2.03697141e-06
Iter: 536 loss: 2.03668287e-06
Iter: 537 loss: 2.0372288e-06
Iter: 538 loss: 2.03657464e-06
Iter: 539 loss: 2.03627496e-06
Iter: 540 loss: 2.03635818e-06
Iter: 541 loss: 2.03607397e-06
Iter: 542 loss: 2.03569698e-06
Iter: 543 loss: 2.03876334e-06
Iter: 544 loss: 2.03566719e-06
Iter: 545 loss: 2.03540139e-06
Iter: 546 loss: 2.03492755e-06
Iter: 547 loss: 2.04635785e-06
Iter: 548 loss: 2.03493437e-06
Iter: 549 loss: 2.03434729e-06
Iter: 550 loss: 2.03662171e-06
Iter: 551 loss: 2.03419404e-06
Iter: 552 loss: 2.03367881e-06
Iter: 553 loss: 2.03580066e-06
Iter: 554 loss: 2.03356421e-06
Iter: 555 loss: 2.03328e-06
Iter: 556 loss: 2.03423e-06
Iter: 557 loss: 2.03320837e-06
Iter: 558 loss: 2.03286345e-06
Iter: 559 loss: 2.03689433e-06
Iter: 560 loss: 2.03286322e-06
Iter: 561 loss: 2.03269019e-06
Iter: 562 loss: 2.03229297e-06
Iter: 563 loss: 2.03843342e-06
Iter: 564 loss: 2.03229229e-06
Iter: 565 loss: 2.03200898e-06
Iter: 566 loss: 2.03196259e-06
Iter: 567 loss: 2.03178638e-06
Iter: 568 loss: 2.0313546e-06
Iter: 569 loss: 2.03700984e-06
Iter: 570 loss: 2.03131731e-06
Iter: 571 loss: 2.03087393e-06
Iter: 572 loss: 2.03086665e-06
Iter: 573 loss: 2.03059676e-06
Iter: 574 loss: 2.0303155e-06
Iter: 575 loss: 2.0302748e-06
Iter: 576 loss: 2.02996489e-06
Iter: 577 loss: 2.02996648e-06
Iter: 578 loss: 2.02969886e-06
Iter: 579 loss: 2.02941874e-06
Iter: 580 loss: 2.02938872e-06
Iter: 581 loss: 2.02904016e-06
Iter: 582 loss: 2.02944875e-06
Iter: 583 loss: 2.02884803e-06
Iter: 584 loss: 2.02841693e-06
Iter: 585 loss: 2.03036279e-06
Iter: 586 loss: 2.02831961e-06
Iter: 587 loss: 2.02788715e-06
Iter: 588 loss: 2.02731849e-06
Iter: 589 loss: 2.02725278e-06
Iter: 590 loss: 2.02670458e-06
Iter: 591 loss: 2.03292893e-06
Iter: 592 loss: 2.02671185e-06
Iter: 593 loss: 2.0263617e-06
Iter: 594 loss: 2.02635965e-06
Iter: 595 loss: 2.02621845e-06
Iter: 596 loss: 2.02593537e-06
Iter: 597 loss: 2.03081368e-06
Iter: 598 loss: 2.02590581e-06
Iter: 599 loss: 2.02557658e-06
Iter: 600 loss: 2.02558567e-06
Iter: 601 loss: 2.02538649e-06
Iter: 602 loss: 2.02501155e-06
Iter: 603 loss: 2.03246464e-06
Iter: 604 loss: 2.02500178e-06
Iter: 605 loss: 2.0246157e-06
Iter: 606 loss: 2.02457659e-06
Iter: 607 loss: 2.02437241e-06
Iter: 608 loss: 2.02392425e-06
Iter: 609 loss: 2.0314144e-06
Iter: 610 loss: 2.02389765e-06
Iter: 611 loss: 2.02365186e-06
Iter: 612 loss: 2.02359615e-06
Iter: 613 loss: 2.02337651e-06
Iter: 614 loss: 2.02304818e-06
Iter: 615 loss: 2.02305273e-06
Iter: 616 loss: 2.02271667e-06
Iter: 617 loss: 2.02278534e-06
Iter: 618 loss: 2.02249839e-06
Iter: 619 loss: 2.02204092e-06
Iter: 620 loss: 2.02473666e-06
Iter: 621 loss: 2.022e-06
Iter: 622 loss: 2.02156366e-06
Iter: 623 loss: 2.02197748e-06
Iter: 624 loss: 2.0213165e-06
Iter: 625 loss: 2.02092974e-06
Iter: 626 loss: 2.02243177e-06
Iter: 627 loss: 2.02084743e-06
Iter: 628 loss: 2.02055799e-06
Iter: 629 loss: 2.02053525e-06
Iter: 630 loss: 2.0204111e-06
Iter: 631 loss: 2.02005799e-06
Iter: 632 loss: 2.02324395e-06
Iter: 633 loss: 2.02001365e-06
Iter: 634 loss: 2.01987064e-06
Iter: 635 loss: 2.01977787e-06
Iter: 636 loss: 2.01961575e-06
Iter: 637 loss: 2.01921557e-06
Iter: 638 loss: 2.02357865e-06
Iter: 639 loss: 2.01916691e-06
Iter: 640 loss: 2.01893067e-06
Iter: 641 loss: 2.01888224e-06
Iter: 642 loss: 2.01870398e-06
Iter: 643 loss: 2.01829266e-06
Iter: 644 loss: 2.02499268e-06
Iter: 645 loss: 2.01829698e-06
Iter: 646 loss: 2.01807052e-06
Iter: 647 loss: 2.01805506e-06
Iter: 648 loss: 2.01783428e-06
Iter: 649 loss: 2.01757166e-06
Iter: 650 loss: 2.01755347e-06
Iter: 651 loss: 2.01723606e-06
Iter: 652 loss: 2.01740727e-06
Iter: 653 loss: 2.01703824e-06
Iter: 654 loss: 2.01680064e-06
Iter: 655 loss: 2.01660623e-06
Iter: 656 loss: 2.0165121e-06
Iter: 657 loss: 2.01607645e-06
Iter: 658 loss: 2.01726516e-06
Iter: 659 loss: 2.01591411e-06
Iter: 660 loss: 2.01548164e-06
Iter: 661 loss: 2.01985813e-06
Iter: 662 loss: 2.01545845e-06
Iter: 663 loss: 2.01520106e-06
Iter: 664 loss: 2.01479065e-06
Iter: 665 loss: 2.01478906e-06
Iter: 666 loss: 2.01450712e-06
Iter: 667 loss: 2.01448438e-06
Iter: 668 loss: 2.014237e-06
Iter: 669 loss: 2.01375769e-06
Iter: 670 loss: 2.0226164e-06
Iter: 671 loss: 2.01374451e-06
Iter: 672 loss: 2.01352896e-06
Iter: 673 loss: 2.01352032e-06
Iter: 674 loss: 2.0132602e-06
Iter: 675 loss: 2.01316243e-06
Iter: 676 loss: 2.01303828e-06
Iter: 677 loss: 2.01278749e-06
Iter: 678 loss: 2.01433022e-06
Iter: 679 loss: 2.01277612e-06
Iter: 680 loss: 2.0124653e-06
Iter: 681 loss: 2.01225816e-06
Iter: 682 loss: 2.01216653e-06
Iter: 683 loss: 2.01182775e-06
Iter: 684 loss: 2.01541889e-06
Iter: 685 loss: 2.01184412e-06
Iter: 686 loss: 2.01157263e-06
Iter: 687 loss: 2.01124226e-06
Iter: 688 loss: 2.01122202e-06
Iter: 689 loss: 2.01087141e-06
Iter: 690 loss: 2.01081957e-06
Iter: 691 loss: 2.01059242e-06
Iter: 692 loss: 2.01025114e-06
Iter: 693 loss: 2.01025796e-06
Iter: 694 loss: 2.00986301e-06
Iter: 695 loss: 2.01039074e-06
Iter: 696 loss: 2.0096852e-06
Iter: 697 loss: 2.00937029e-06
Iter: 698 loss: 2.00954446e-06
Iter: 699 loss: 2.00917657e-06
Iter: 700 loss: 2.00898444e-06
Iter: 701 loss: 2.00895556e-06
Iter: 702 loss: 2.00880186e-06
Iter: 703 loss: 2.00838235e-06
Iter: 704 loss: 2.01135208e-06
Iter: 705 loss: 2.00828958e-06
Iter: 706 loss: 2.00842032e-06
Iter: 707 loss: 2.00816271e-06
Iter: 708 loss: 2.00805448e-06
Iter: 709 loss: 2.00781096e-06
Iter: 710 loss: 2.0116513e-06
Iter: 711 loss: 2.00780141e-06
Iter: 712 loss: 2.00768409e-06
Iter: 713 loss: 2.00765407e-06
Iter: 714 loss: 2.0075413e-06
Iter: 715 loss: 2.00723071e-06
Iter: 716 loss: 2.01160219e-06
Iter: 717 loss: 2.00717113e-06
Iter: 718 loss: 2.0068685e-06
Iter: 719 loss: 2.00755176e-06
Iter: 720 loss: 2.00672162e-06
Iter: 721 loss: 2.00635941e-06
Iter: 722 loss: 2.00636578e-06
Iter: 723 loss: 2.00616887e-06
Iter: 724 loss: 2.00605382e-06
Iter: 725 loss: 2.0059822e-06
Iter: 726 loss: 2.00576687e-06
Iter: 727 loss: 2.00806221e-06
Iter: 728 loss: 2.00574596e-06
Iter: 729 loss: 2.00560726e-06
Iter: 730 loss: 2.00541717e-06
Iter: 731 loss: 2.00539034e-06
Iter: 732 loss: 2.00522982e-06
Iter: 733 loss: 2.00648878e-06
Iter: 734 loss: 2.00521777e-06
Iter: 735 loss: 2.00497379e-06
Iter: 736 loss: 2.00529394e-06
Iter: 737 loss: 2.0048617e-06
Iter: 738 loss: 2.00467366e-06
Iter: 739 loss: 2.00432396e-06
Iter: 740 loss: 2.00433442e-06
Iter: 741 loss: 2.00409886e-06
Iter: 742 loss: 2.00408022e-06
Iter: 743 loss: 2.00384716e-06
Iter: 744 loss: 2.00395971e-06
Iter: 745 loss: 2.00368777e-06
Iter: 746 loss: 2.00349041e-06
Iter: 747 loss: 2.00438217e-06
Iter: 748 loss: 2.00347267e-06
Iter: 749 loss: 2.00326576e-06
Iter: 750 loss: 2.00372551e-06
Iter: 751 loss: 2.00320073e-06
Iter: 752 loss: 2.00306181e-06
Iter: 753 loss: 2.00274599e-06
Iter: 754 loss: 2.00793784e-06
Iter: 755 loss: 2.00276509e-06
Iter: 756 loss: 2.00248201e-06
Iter: 757 loss: 2.00631325e-06
Iter: 758 loss: 2.00249906e-06
Iter: 759 loss: 2.00221984e-06
Iter: 760 loss: 2.00283785e-06
Iter: 761 loss: 2.00213844e-06
Iter: 762 loss: 2.00187196e-06
Iter: 763 loss: 2.00294335e-06
Iter: 764 loss: 2.00184331e-06
Iter: 765 loss: 2.00166e-06
Iter: 766 loss: 2.00139971e-06
Iter: 767 loss: 2.00139402e-06
Iter: 768 loss: 2.0011671e-06
Iter: 769 loss: 2.00413797e-06
Iter: 770 loss: 2.00117529e-06
Iter: 771 loss: 2.0009627e-06
Iter: 772 loss: 2.00222576e-06
Iter: 773 loss: 2.00093086e-06
Iter: 774 loss: 2.00082422e-06
Iter: 775 loss: 2.00048157e-06
Iter: 776 loss: 2.00252202e-06
Iter: 777 loss: 2.00038244e-06
Iter: 778 loss: 1.99991314e-06
Iter: 779 loss: 2.00126965e-06
Iter: 780 loss: 1.99976967e-06
Iter: 781 loss: 1.99931e-06
Iter: 782 loss: 2.0006978e-06
Iter: 783 loss: 1.99916735e-06
Iter: 784 loss: 1.99903957e-06
Iter: 785 loss: 1.99894885e-06
Iter: 786 loss: 1.99874444e-06
Iter: 787 loss: 1.99864712e-06
Iter: 788 loss: 1.99858096e-06
Iter: 789 loss: 1.99835381e-06
Iter: 790 loss: 1.99841725e-06
Iter: 791 loss: 1.99821875e-06
Iter: 792 loss: 1.99792476e-06
Iter: 793 loss: 2.0018274e-06
Iter: 794 loss: 1.99794567e-06
Iter: 795 loss: 1.99775604e-06
Iter: 796 loss: 1.99777014e-06
Iter: 797 loss: 1.99761212e-06
Iter: 798 loss: 1.99735678e-06
Iter: 799 loss: 1.99740089e-06
Iter: 800 loss: 1.99718079e-06
Iter: 801 loss: 1.9968827e-06
Iter: 802 loss: 1.99860915e-06
Iter: 803 loss: 1.99684246e-06
Iter: 804 loss: 1.99652209e-06
Iter: 805 loss: 1.9979334e-06
Iter: 806 loss: 1.99645638e-06
Iter: 807 loss: 1.99628676e-06
Iter: 808 loss: 1.99591477e-06
Iter: 809 loss: 2.00151862e-06
Iter: 810 loss: 1.995905e-06
Iter: 811 loss: 1.99574151e-06
Iter: 812 loss: 1.99570241e-06
Iter: 813 loss: 1.99544502e-06
Iter: 814 loss: 1.99489727e-06
Iter: 815 loss: 2.00346881e-06
Iter: 816 loss: 1.99489068e-06
Iter: 817 loss: 1.99439978e-06
Iter: 818 loss: 1.99524243e-06
Iter: 819 loss: 1.99416627e-06
Iter: 820 loss: 1.99375199e-06
Iter: 821 loss: 1.99373608e-06
Iter: 822 loss: 1.99344163e-06
Iter: 823 loss: 1.99324404e-06
Iter: 824 loss: 1.9931324e-06
Iter: 825 loss: 1.99287479e-06
Iter: 826 loss: 1.99543433e-06
Iter: 827 loss: 1.99286478e-06
Iter: 828 loss: 1.99262604e-06
Iter: 829 loss: 1.99310648e-06
Iter: 830 loss: 1.99252e-06
Iter: 831 loss: 1.99234137e-06
Iter: 832 loss: 1.99255919e-06
Iter: 833 loss: 1.99221404e-06
Iter: 834 loss: 1.99197439e-06
Iter: 835 loss: 1.99170881e-06
Iter: 836 loss: 1.99167403e-06
Iter: 837 loss: 1.99131273e-06
Iter: 838 loss: 1.99134365e-06
Iter: 839 loss: 1.99098122e-06
Iter: 840 loss: 1.99034957e-06
Iter: 841 loss: 2.00551403e-06
Iter: 842 loss: 1.99036185e-06
Iter: 843 loss: 1.98978705e-06
Iter: 844 loss: 1.99047417e-06
Iter: 845 loss: 1.98947919e-06
Iter: 846 loss: 1.98923362e-06
Iter: 847 loss: 1.98912198e-06
Iter: 848 loss: 1.9889444e-06
Iter: 849 loss: 1.98852558e-06
Iter: 850 loss: 1.99277724e-06
Iter: 851 loss: 1.98849193e-06
Iter: 852 loss: 1.98819498e-06
Iter: 853 loss: 1.99166516e-06
Iter: 854 loss: 1.98818498e-06
Iter: 855 loss: 1.98787166e-06
Iter: 856 loss: 1.98916223e-06
Iter: 857 loss: 1.98780958e-06
Iter: 858 loss: 1.98760517e-06
Iter: 859 loss: 1.98774342e-06
Iter: 860 loss: 1.98748126e-06
Iter: 861 loss: 1.9872009e-06
Iter: 862 loss: 1.98833959e-06
Iter: 863 loss: 1.98714952e-06
Iter: 864 loss: 1.98688804e-06
Iter: 865 loss: 1.98661837e-06
Iter: 866 loss: 1.98654766e-06
Iter: 867 loss: 1.9860945e-06
Iter: 868 loss: 1.9881129e-06
Iter: 869 loss: 1.98600492e-06
Iter: 870 loss: 1.98567386e-06
Iter: 871 loss: 1.98756061e-06
Iter: 872 loss: 1.98563771e-06
Iter: 873 loss: 1.98529915e-06
Iter: 874 loss: 1.98668158e-06
Iter: 875 loss: 1.98522503e-06
Iter: 876 loss: 1.98503471e-06
Iter: 877 loss: 1.98465068e-06
Iter: 878 loss: 1.9916979e-06
Iter: 879 loss: 1.98464068e-06
Iter: 880 loss: 1.9843751e-06
Iter: 881 loss: 1.9843726e-06
Iter: 882 loss: 1.98404882e-06
Iter: 883 loss: 1.98378302e-06
Iter: 884 loss: 1.98370708e-06
Iter: 885 loss: 1.98344219e-06
Iter: 886 loss: 1.98376483e-06
Iter: 887 loss: 1.98331691e-06
Iter: 888 loss: 1.98313023e-06
Iter: 889 loss: 1.98311045e-06
Iter: 890 loss: 1.9829854e-06
Iter: 891 loss: 1.98296607e-06
Iter: 892 loss: 1.98286943e-06
Iter: 893 loss: 1.98269754e-06
Iter: 894 loss: 1.98377188e-06
Iter: 895 loss: 1.98269254e-06
Iter: 896 loss: 1.98253338e-06
Iter: 897 loss: 1.98226098e-06
Iter: 898 loss: 1.98227212e-06
Iter: 899 loss: 1.98189696e-06
Iter: 900 loss: 1.98296539e-06
Iter: 901 loss: 1.98178577e-06
Iter: 902 loss: 1.9814529e-06
Iter: 903 loss: 1.98285488e-06
Iter: 904 loss: 1.98136695e-06
Iter: 905 loss: 1.98107136e-06
Iter: 906 loss: 1.98430962e-06
Iter: 907 loss: 1.9810409e-06
Iter: 908 loss: 1.98084763e-06
Iter: 909 loss: 1.98039334e-06
Iter: 910 loss: 1.98834732e-06
Iter: 911 loss: 1.9803872e-06
Iter: 912 loss: 1.98027351e-06
Iter: 913 loss: 1.98023963e-06
Iter: 914 loss: 1.98008433e-06
Iter: 915 loss: 1.98020712e-06
Iter: 916 loss: 1.98002022e-06
Iter: 917 loss: 1.97985696e-06
Iter: 918 loss: 1.97956365e-06
Iter: 919 loss: 1.98661132e-06
Iter: 920 loss: 1.97956797e-06
Iter: 921 loss: 1.97942654e-06
Iter: 922 loss: 1.97940562e-06
Iter: 923 loss: 1.97922191e-06
Iter: 924 loss: 1.97921e-06
Iter: 925 loss: 1.97905183e-06
Iter: 926 loss: 1.97887812e-06
Iter: 927 loss: 1.98074395e-06
Iter: 928 loss: 1.97887562e-06
Iter: 929 loss: 1.97871577e-06
Iter: 930 loss: 1.97855775e-06
Iter: 931 loss: 1.97851477e-06
Iter: 932 loss: 1.97829422e-06
Iter: 933 loss: 1.97893132e-06
Iter: 934 loss: 1.97824329e-06
Iter: 935 loss: 1.97802456e-06
Iter: 936 loss: 1.97812437e-06
Iter: 937 loss: 1.97786858e-06
Iter: 938 loss: 1.97757413e-06
Iter: 939 loss: 1.98157727e-06
Iter: 940 loss: 1.97755708e-06
Iter: 941 loss: 1.97736335e-06
Iter: 942 loss: 1.97720328e-06
Iter: 943 loss: 1.97713371e-06
Iter: 944 loss: 1.97692134e-06
Iter: 945 loss: 1.9772508e-06
Iter: 946 loss: 1.97680629e-06
Iter: 947 loss: 1.97655345e-06
Iter: 948 loss: 1.98032194e-06
Iter: 949 loss: 1.97655322e-06
Iter: 950 loss: 1.97644817e-06
Iter: 951 loss: 1.97621875e-06
Iter: 952 loss: 1.97622558e-06
Iter: 953 loss: 1.97601821e-06
Iter: 954 loss: 1.97685745e-06
Iter: 955 loss: 1.97600639e-06
Iter: 956 loss: 1.97574309e-06
Iter: 957 loss: 1.97761619e-06
Iter: 958 loss: 1.97576128e-06
Iter: 959 loss: 1.97562531e-06
Iter: 960 loss: 1.97579948e-06
Iter: 961 loss: 1.9755264e-06
Iter: 962 loss: 1.97530153e-06
Iter: 963 loss: 1.9753079e-06
Iter: 964 loss: 1.97514373e-06
Iter: 965 loss: 1.9748627e-06
Iter: 966 loss: 1.97515101e-06
Iter: 967 loss: 1.97470854e-06
Iter: 968 loss: 1.97442796e-06
Iter: 969 loss: 1.97492045e-06
Iter: 970 loss: 1.97430177e-06
Iter: 971 loss: 1.97402778e-06
Iter: 972 loss: 1.97403938e-06
Iter: 973 loss: 1.97381655e-06
Iter: 974 loss: 1.97393501e-06
Iter: 975 loss: 1.97365671e-06
Iter: 976 loss: 1.97345776e-06
Iter: 977 loss: 1.97328723e-06
Iter: 978 loss: 1.97320924e-06
Iter: 979 loss: 1.97299096e-06
Iter: 980 loss: 1.97298186e-06
Iter: 981 loss: 1.97274676e-06
Iter: 982 loss: 1.97234704e-06
Iter: 983 loss: 1.9811e-06
Iter: 984 loss: 1.97232566e-06
Iter: 985 loss: 1.97199415e-06
Iter: 986 loss: 1.97295e-06
Iter: 987 loss: 1.97184954e-06
Iter: 988 loss: 1.97169152e-06
Iter: 989 loss: 1.9716465e-06
Iter: 990 loss: 1.97148802e-06
Iter: 991 loss: 1.97142799e-06
Iter: 992 loss: 1.97133932e-06
Iter: 993 loss: 1.97113127e-06
Iter: 994 loss: 1.97320514e-06
Iter: 995 loss: 1.97112877e-06
Iter: 996 loss: 1.9709878e-06
Iter: 997 loss: 1.97070835e-06
Iter: 998 loss: 1.97538702e-06
Iter: 999 loss: 1.97066947e-06
Iter: 1000 loss: 1.97032409e-06
Iter: 1001 loss: 1.97159534e-06
Iter: 1002 loss: 1.97021245e-06
Iter: 1003 loss: 1.96983046e-06
Iter: 1004 loss: 1.97087138e-06
Iter: 1005 loss: 1.96971e-06
Iter: 1006 loss: 1.96931569e-06
Iter: 1007 loss: 1.97370173e-06
Iter: 1008 loss: 1.96934297e-06
Iter: 1009 loss: 1.9691106e-06
Iter: 1010 loss: 1.96887049e-06
Iter: 1011 loss: 1.96882047e-06
Iter: 1012 loss: 1.96858764e-06
Iter: 1013 loss: 1.96989322e-06
Iter: 1014 loss: 1.96853216e-06
Iter: 1015 loss: 1.96826204e-06
Iter: 1016 loss: 1.97020677e-06
Iter: 1017 loss: 1.96824817e-06
Iter: 1018 loss: 1.96809174e-06
Iter: 1019 loss: 1.96776864e-06
Iter: 1020 loss: 1.97182044e-06
Iter: 1021 loss: 1.96773954e-06
Iter: 1022 loss: 1.96741507e-06
Iter: 1023 loss: 1.97005829e-06
Iter: 1024 loss: 1.96740393e-06
Iter: 1025 loss: 1.96708879e-06
Iter: 1026 loss: 1.96863971e-06
Iter: 1027 loss: 1.96701149e-06
Iter: 1028 loss: 1.9667782e-06
Iter: 1029 loss: 1.9678223e-06
Iter: 1030 loss: 1.96674546e-06
Iter: 1031 loss: 1.96650967e-06
Iter: 1032 loss: 1.96653627e-06
Iter: 1033 loss: 1.966333e-06
Iter: 1034 loss: 1.96607107e-06
Iter: 1035 loss: 1.96600399e-06
Iter: 1036 loss: 1.9658537e-06
Iter: 1037 loss: 1.96551673e-06
Iter: 1038 loss: 1.96710198e-06
Iter: 1039 loss: 1.96546216e-06
Iter: 1040 loss: 1.9651643e-06
Iter: 1041 loss: 1.96747442e-06
Iter: 1042 loss: 1.96516567e-06
Iter: 1043 loss: 1.96488372e-06
Iter: 1044 loss: 1.96517e-06
Iter: 1045 loss: 1.96471296e-06
Iter: 1046 loss: 1.96445058e-06
Iter: 1047 loss: 1.96419478e-06
Iter: 1048 loss: 1.96413134e-06
Iter: 1049 loss: 1.96392443e-06
Iter: 1050 loss: 1.96389442e-06
Iter: 1051 loss: 1.96366318e-06
Iter: 1052 loss: 1.96351266e-06
Iter: 1053 loss: 1.96345763e-06
Iter: 1054 loss: 1.96324481e-06
Iter: 1055 loss: 1.96302904e-06
Iter: 1056 loss: 1.96297287e-06
Iter: 1057 loss: 1.96275346e-06
Iter: 1058 loss: 1.96617952e-06
Iter: 1059 loss: 1.96274323e-06
Iter: 1060 loss: 1.96246901e-06
Iter: 1061 loss: 1.96260271e-06
Iter: 1062 loss: 1.96228143e-06
Iter: 1063 loss: 1.9619556e-06
Iter: 1064 loss: 1.96368956e-06
Iter: 1065 loss: 1.96190786e-06
Iter: 1066 loss: 1.96158157e-06
Iter: 1067 loss: 1.96151177e-06
Iter: 1068 loss: 1.96127644e-06
Iter: 1069 loss: 1.96091628e-06
Iter: 1070 loss: 1.96105248e-06
Iter: 1071 loss: 1.96067185e-06
Iter: 1072 loss: 1.9602578e-06
Iter: 1073 loss: 1.96207384e-06
Iter: 1074 loss: 1.96017913e-06
Iter: 1075 loss: 1.95983966e-06
Iter: 1076 loss: 1.96408291e-06
Iter: 1077 loss: 1.95987059e-06
Iter: 1078 loss: 1.95955477e-06
Iter: 1079 loss: 1.95954158e-06
Iter: 1080 loss: 1.95933217e-06
Iter: 1081 loss: 1.95898792e-06
Iter: 1082 loss: 1.9587826e-06
Iter: 1083 loss: 1.95866323e-06
Iter: 1084 loss: 1.95825692e-06
Iter: 1085 loss: 1.95824646e-06
Iter: 1086 loss: 1.9579677e-06
Iter: 1087 loss: 1.95746247e-06
Iter: 1088 loss: 1.95745952e-06
Iter: 1089 loss: 1.95700477e-06
Iter: 1090 loss: 1.95761163e-06
Iter: 1091 loss: 1.95675966e-06
Iter: 1092 loss: 1.95646453e-06
Iter: 1093 loss: 1.95644816e-06
Iter: 1094 loss: 1.95618986e-06
Iter: 1095 loss: 1.95653502e-06
Iter: 1096 loss: 1.95601865e-06
Iter: 1097 loss: 1.95580697e-06
Iter: 1098 loss: 1.95753819e-06
Iter: 1099 loss: 1.95578878e-06
Iter: 1100 loss: 1.95553821e-06
Iter: 1101 loss: 1.95501957e-06
Iter: 1102 loss: 1.9648478e-06
Iter: 1103 loss: 1.95503026e-06
Iter: 1104 loss: 1.95439088e-06
Iter: 1105 loss: 1.95490247e-06
Iter: 1106 loss: 1.954033e-06
Iter: 1107 loss: 1.95341818e-06
Iter: 1108 loss: 1.95778875e-06
Iter: 1109 loss: 1.95337316e-06
Iter: 1110 loss: 1.95297434e-06
Iter: 1111 loss: 1.9591489e-06
Iter: 1112 loss: 1.95295274e-06
Iter: 1113 loss: 1.9526376e-06
Iter: 1114 loss: 1.95251096e-06
Iter: 1115 loss: 1.95233656e-06
Iter: 1116 loss: 1.95197185e-06
Iter: 1117 loss: 1.95281245e-06
Iter: 1118 loss: 1.95186612e-06
Iter: 1119 loss: 1.95154098e-06
Iter: 1120 loss: 1.95551934e-06
Iter: 1121 loss: 1.95152097e-06
Iter: 1122 loss: 1.95133248e-06
Iter: 1123 loss: 1.95087932e-06
Iter: 1124 loss: 1.9567442e-06
Iter: 1125 loss: 1.95085363e-06
Iter: 1126 loss: 1.95025018e-06
Iter: 1127 loss: 1.95061261e-06
Iter: 1128 loss: 1.94987297e-06
Iter: 1129 loss: 1.94941731e-06
Iter: 1130 loss: 1.94940503e-06
Iter: 1131 loss: 1.94893346e-06
Iter: 1132 loss: 1.94987206e-06
Iter: 1133 loss: 1.94876975e-06
Iter: 1134 loss: 1.9484612e-06
Iter: 1135 loss: 1.94984e-06
Iter: 1136 loss: 1.94837958e-06
Iter: 1137 loss: 1.9479869e-06
Iter: 1138 loss: 1.94783138e-06
Iter: 1139 loss: 1.94760742e-06
Iter: 1140 loss: 1.94715085e-06
Iter: 1141 loss: 1.94685163e-06
Iter: 1142 loss: 1.94666609e-06
Iter: 1143 loss: 1.94589074e-06
Iter: 1144 loss: 1.94863742e-06
Iter: 1145 loss: 1.94571817e-06
Iter: 1146 loss: 1.94513518e-06
Iter: 1147 loss: 1.94512495e-06
Iter: 1148 loss: 1.94467225e-06
Iter: 1149 loss: 1.94454333e-06
Iter: 1150 loss: 1.94427798e-06
Iter: 1151 loss: 1.94377208e-06
Iter: 1152 loss: 1.94483914e-06
Iter: 1153 loss: 1.94357017e-06
Iter: 1154 loss: 1.94318523e-06
Iter: 1155 loss: 1.9432091e-06
Iter: 1156 loss: 1.94295717e-06
Iter: 1157 loss: 1.94246786e-06
Iter: 1158 loss: 1.94969584e-06
Iter: 1159 loss: 1.94242193e-06
Iter: 1160 loss: 1.94187101e-06
Iter: 1161 loss: 1.94271229e-06
Iter: 1162 loss: 1.94159361e-06
Iter: 1163 loss: 1.94104587e-06
Iter: 1164 loss: 1.94748782e-06
Iter: 1165 loss: 1.94102404e-06
Iter: 1166 loss: 1.94034988e-06
Iter: 1167 loss: 1.94008885e-06
Iter: 1168 loss: 1.93971346e-06
Iter: 1169 loss: 1.93912e-06
Iter: 1170 loss: 1.94706217e-06
Iter: 1171 loss: 1.93913047e-06
Iter: 1172 loss: 1.93858682e-06
Iter: 1173 loss: 1.93807023e-06
Iter: 1174 loss: 1.93792675e-06
Iter: 1175 loss: 1.93730602e-06
Iter: 1176 loss: 1.93747e-06
Iter: 1177 loss: 1.93687401e-06
Iter: 1178 loss: 1.93623191e-06
Iter: 1179 loss: 1.94286554e-06
Iter: 1180 loss: 1.93621463e-06
Iter: 1181 loss: 1.93577694e-06
Iter: 1182 loss: 1.94093582e-06
Iter: 1183 loss: 1.9357808e-06
Iter: 1184 loss: 1.93547612e-06
Iter: 1185 loss: 1.93500591e-06
Iter: 1186 loss: 1.93497476e-06
Iter: 1187 loss: 1.93446544e-06
Iter: 1188 loss: 1.93720621e-06
Iter: 1189 loss: 1.93434335e-06
Iter: 1190 loss: 1.93378969e-06
Iter: 1191 loss: 1.93668257e-06
Iter: 1192 loss: 1.93368442e-06
Iter: 1193 loss: 1.93331971e-06
Iter: 1194 loss: 1.93262917e-06
Iter: 1195 loss: 1.94794893e-06
Iter: 1196 loss: 1.93261258e-06
Iter: 1197 loss: 1.93190635e-06
Iter: 1198 loss: 1.93523397e-06
Iter: 1199 loss: 1.93175038e-06
Iter: 1200 loss: 1.9312115e-06
Iter: 1201 loss: 1.93988217e-06
Iter: 1202 loss: 1.93119877e-06
Iter: 1203 loss: 1.93071742e-06
Iter: 1204 loss: 1.93003689e-06
Iter: 1205 loss: 1.9299855e-06
Iter: 1206 loss: 1.92948096e-06
Iter: 1207 loss: 1.92943276e-06
Iter: 1208 loss: 1.92907828e-06
Iter: 1209 loss: 1.92816e-06
Iter: 1210 loss: 1.93661162e-06
Iter: 1211 loss: 1.92799621e-06
Iter: 1212 loss: 1.92703624e-06
Iter: 1213 loss: 1.93086021e-06
Iter: 1214 loss: 1.92683501e-06
Iter: 1215 loss: 1.92628681e-06
Iter: 1216 loss: 1.92626521e-06
Iter: 1217 loss: 1.9257418e-06
Iter: 1218 loss: 1.92636e-06
Iter: 1219 loss: 1.92545122e-06
Iter: 1220 loss: 1.92493462e-06
Iter: 1221 loss: 1.92507105e-06
Iter: 1222 loss: 1.92458674e-06
Iter: 1223 loss: 1.92412858e-06
Iter: 1224 loss: 1.9241445e-06
Iter: 1225 loss: 1.9237491e-06
Iter: 1226 loss: 1.92332482e-06
Iter: 1227 loss: 1.92327707e-06
Iter: 1228 loss: 1.92261e-06
Iter: 1229 loss: 1.92218477e-06
Iter: 1230 loss: 1.92194216e-06
Iter: 1231 loss: 1.92125481e-06
Iter: 1232 loss: 1.92123753e-06
Iter: 1233 loss: 1.92059315e-06
Iter: 1234 loss: 1.92189123e-06
Iter: 1235 loss: 1.92032917e-06
Iter: 1236 loss: 1.91974414e-06
Iter: 1237 loss: 1.92086054e-06
Iter: 1238 loss: 1.91948811e-06
Iter: 1239 loss: 1.91859658e-06
Iter: 1240 loss: 1.92034076e-06
Iter: 1241 loss: 1.91823483e-06
Iter: 1242 loss: 1.91763638e-06
Iter: 1243 loss: 1.91671825e-06
Iter: 1244 loss: 1.91673485e-06
Iter: 1245 loss: 1.91565096e-06
Iter: 1246 loss: 1.92307448e-06
Iter: 1247 loss: 1.91555e-06
Iter: 1248 loss: 1.9149345e-06
Iter: 1249 loss: 1.91491176e-06
Iter: 1250 loss: 1.91452273e-06
Iter: 1251 loss: 1.91383378e-06
Iter: 1252 loss: 1.91383424e-06
Iter: 1253 loss: 1.9130805e-06
Iter: 1254 loss: 1.91660365e-06
Iter: 1255 loss: 1.91291792e-06
Iter: 1256 loss: 1.91221761e-06
Iter: 1257 loss: 1.91822301e-06
Iter: 1258 loss: 1.91217987e-06
Iter: 1259 loss: 1.91175286e-06
Iter: 1260 loss: 1.9112988e-06
Iter: 1261 loss: 1.91122808e-06
Iter: 1262 loss: 1.91061645e-06
Iter: 1263 loss: 1.91216236e-06
Iter: 1264 loss: 1.91041227e-06
Iter: 1265 loss: 1.90974606e-06
Iter: 1266 loss: 1.9159927e-06
Iter: 1267 loss: 1.90970786e-06
Iter: 1268 loss: 1.90921287e-06
Iter: 1269 loss: 1.90879518e-06
Iter: 1270 loss: 1.90864193e-06
Iter: 1271 loss: 1.90797437e-06
Iter: 1272 loss: 1.90798301e-06
Iter: 1273 loss: 1.90751575e-06
Iter: 1274 loss: 1.90649826e-06
Iter: 1275 loss: 1.92355628e-06
Iter: 1276 loss: 1.90647711e-06
Iter: 1277 loss: 1.90562048e-06
Iter: 1278 loss: 1.90761375e-06
Iter: 1279 loss: 1.90531966e-06
Iter: 1280 loss: 1.90480341e-06
Iter: 1281 loss: 1.90476612e-06
Iter: 1282 loss: 1.90422361e-06
Iter: 1283 loss: 1.90441438e-06
Iter: 1284 loss: 1.90385174e-06
Iter: 1285 loss: 1.9032866e-06
Iter: 1286 loss: 1.9032268e-06
Iter: 1287 loss: 1.90283527e-06
Iter: 1288 loss: 1.90218702e-06
Iter: 1289 loss: 1.91233767e-06
Iter: 1290 loss: 1.90218702e-06
Iter: 1291 loss: 1.90165565e-06
Iter: 1292 loss: 1.90147114e-06
Iter: 1293 loss: 1.90115543e-06
Iter: 1294 loss: 1.90060712e-06
Iter: 1295 loss: 1.90124342e-06
Iter: 1296 loss: 1.90029562e-06
Iter: 1297 loss: 1.8997971e-06
Iter: 1298 loss: 1.90712308e-06
Iter: 1299 loss: 1.89979664e-06
Iter: 1300 loss: 1.89935758e-06
Iter: 1301 loss: 1.89918489e-06
Iter: 1302 loss: 1.89892967e-06
Iter: 1303 loss: 1.89844422e-06
Iter: 1304 loss: 1.90297055e-06
Iter: 1305 loss: 1.89843149e-06
Iter: 1306 loss: 1.8978518e-06
Iter: 1307 loss: 1.8973825e-06
Iter: 1308 loss: 1.89722164e-06
Iter: 1309 loss: 1.89637092e-06
Iter: 1310 loss: 1.89526008e-06
Iter: 1311 loss: 1.89517687e-06
Iter: 1312 loss: 1.89404341e-06
Iter: 1313 loss: 1.91023241e-06
Iter: 1314 loss: 1.8940375e-06
Iter: 1315 loss: 1.89306797e-06
Iter: 1316 loss: 1.90151854e-06
Iter: 1317 loss: 1.89304137e-06
Iter: 1318 loss: 1.89248112e-06
Iter: 1319 loss: 1.89206162e-06
Iter: 1320 loss: 1.89190507e-06
Iter: 1321 loss: 1.89131219e-06
Iter: 1322 loss: 1.89695152e-06
Iter: 1323 loss: 1.89130674e-06
Iter: 1324 loss: 1.89068214e-06
Iter: 1325 loss: 1.89189859e-06
Iter: 1326 loss: 1.89042851e-06
Iter: 1327 loss: 1.88992203e-06
Iter: 1328 loss: 1.88963168e-06
Iter: 1329 loss: 1.88940589e-06
Iter: 1330 loss: 1.88871104e-06
Iter: 1331 loss: 1.89328148e-06
Iter: 1332 loss: 1.8886509e-06
Iter: 1333 loss: 1.8878859e-06
Iter: 1334 loss: 1.88881643e-06
Iter: 1335 loss: 1.88747742e-06
Iter: 1336 loss: 1.88667809e-06
Iter: 1337 loss: 1.88783713e-06
Iter: 1338 loss: 1.88625324e-06
Iter: 1339 loss: 1.88532476e-06
Iter: 1340 loss: 1.89448212e-06
Iter: 1341 loss: 1.88529793e-06
Iter: 1342 loss: 1.88481863e-06
Iter: 1343 loss: 1.8838557e-06
Iter: 1344 loss: 1.90118135e-06
Iter: 1345 loss: 1.88381273e-06
Iter: 1346 loss: 1.88269109e-06
Iter: 1347 loss: 1.88554554e-06
Iter: 1348 loss: 1.88231866e-06
Iter: 1349 loss: 1.88197225e-06
Iter: 1350 loss: 1.88172908e-06
Iter: 1351 loss: 1.88130412e-06
Iter: 1352 loss: 1.88058175e-06
Iter: 1353 loss: 1.89826596e-06
Iter: 1354 loss: 1.88057857e-06
Iter: 1355 loss: 1.8796718e-06
Iter: 1356 loss: 1.88127319e-06
Iter: 1357 loss: 1.87930209e-06
Iter: 1358 loss: 1.87850594e-06
Iter: 1359 loss: 1.87849059e-06
Iter: 1360 loss: 1.8780139e-06
Iter: 1361 loss: 1.87735236e-06
Iter: 1362 loss: 1.87733588e-06
Iter: 1363 loss: 1.87655291e-06
Iter: 1364 loss: 1.87927367e-06
Iter: 1365 loss: 1.87633782e-06
Iter: 1366 loss: 1.87561318e-06
Iter: 1367 loss: 1.8821022e-06
Iter: 1368 loss: 1.87557862e-06
Iter: 1369 loss: 1.87504656e-06
Iter: 1370 loss: 1.87457181e-06
Iter: 1371 loss: 1.87442674e-06
Iter: 1372 loss: 1.87383887e-06
Iter: 1373 loss: 1.87384035e-06
Iter: 1374 loss: 1.87337673e-06
Iter: 1375 loss: 1.87224009e-06
Iter: 1376 loss: 1.8862313e-06
Iter: 1377 loss: 1.8721521e-06
Iter: 1378 loss: 1.87080889e-06
Iter: 1379 loss: 1.872761e-06
Iter: 1380 loss: 1.870186e-06
Iter: 1381 loss: 1.86956345e-06
Iter: 1382 loss: 1.86942066e-06
Iter: 1383 loss: 1.86868715e-06
Iter: 1384 loss: 1.86876696e-06
Iter: 1385 loss: 1.86808984e-06
Iter: 1386 loss: 1.86740101e-06
Iter: 1387 loss: 1.8681535e-06
Iter: 1388 loss: 1.8670579e-06
Iter: 1389 loss: 1.8665487e-06
Iter: 1390 loss: 1.86651801e-06
Iter: 1391 loss: 1.86608554e-06
Iter: 1392 loss: 1.86583736e-06
Iter: 1393 loss: 1.86561647e-06
Iter: 1394 loss: 1.86505019e-06
Iter: 1395 loss: 1.86541e-06
Iter: 1396 loss: 1.86467707e-06
Iter: 1397 loss: 1.86397233e-06
Iter: 1398 loss: 1.87143223e-06
Iter: 1399 loss: 1.86397824e-06
Iter: 1400 loss: 1.86334853e-06
Iter: 1401 loss: 1.86278476e-06
Iter: 1402 loss: 1.86262503e-06
Iter: 1403 loss: 1.86201123e-06
Iter: 1404 loss: 1.87130399e-06
Iter: 1405 loss: 1.86199975e-06
Iter: 1406 loss: 1.86134298e-06
Iter: 1407 loss: 1.86115653e-06
Iter: 1408 loss: 1.86074431e-06
Iter: 1409 loss: 1.86007412e-06
Iter: 1410 loss: 1.85971658e-06
Iter: 1411 loss: 1.85942213e-06
Iter: 1412 loss: 1.85845101e-06
Iter: 1413 loss: 1.86363411e-06
Iter: 1414 loss: 1.85833153e-06
Iter: 1415 loss: 1.85734814e-06
Iter: 1416 loss: 1.86598049e-06
Iter: 1417 loss: 1.85729959e-06
Iter: 1418 loss: 1.85673161e-06
Iter: 1419 loss: 1.85586623e-06
Iter: 1420 loss: 1.85586259e-06
Iter: 1421 loss: 1.85496742e-06
Iter: 1422 loss: 1.86431748e-06
Iter: 1423 loss: 1.85493991e-06
Iter: 1424 loss: 1.85413012e-06
Iter: 1425 loss: 1.85709553e-06
Iter: 1426 loss: 1.85390138e-06
Iter: 1427 loss: 1.85336751e-06
Iter: 1428 loss: 1.85325052e-06
Iter: 1429 loss: 1.8529247e-06
Iter: 1430 loss: 1.85240606e-06
Iter: 1431 loss: 1.85933641e-06
Iter: 1432 loss: 1.85240197e-06
Iter: 1433 loss: 1.85196893e-06
Iter: 1434 loss: 1.85226349e-06
Iter: 1435 loss: 1.85167119e-06
Iter: 1436 loss: 1.85125464e-06
Iter: 1437 loss: 1.85176395e-06
Iter: 1438 loss: 1.85102544e-06
Iter: 1439 loss: 1.8503988e-06
Iter: 1440 loss: 1.85492752e-06
Iter: 1441 loss: 1.8503581e-06
Iter: 1442 loss: 1.85000897e-06
Iter: 1443 loss: 1.84926671e-06
Iter: 1444 loss: 1.86187208e-06
Iter: 1445 loss: 1.8492301e-06
Iter: 1446 loss: 1.84847e-06
Iter: 1447 loss: 1.85156364e-06
Iter: 1448 loss: 1.84826808e-06
Iter: 1449 loss: 1.84779901e-06
Iter: 1450 loss: 1.84778219e-06
Iter: 1451 loss: 1.84735427e-06
Iter: 1452 loss: 1.84652e-06
Iter: 1453 loss: 1.86174793e-06
Iter: 1454 loss: 1.84651435e-06
Iter: 1455 loss: 1.84581404e-06
Iter: 1456 loss: 1.85074566e-06
Iter: 1457 loss: 1.84575856e-06
Iter: 1458 loss: 1.84519558e-06
Iter: 1459 loss: 1.85094018e-06
Iter: 1460 loss: 1.84520059e-06
Iter: 1461 loss: 1.8448e-06
Iter: 1462 loss: 1.84438682e-06
Iter: 1463 loss: 1.84431394e-06
Iter: 1464 loss: 1.84384885e-06
Iter: 1465 loss: 1.84709279e-06
Iter: 1466 loss: 1.84378712e-06
Iter: 1467 loss: 1.84332646e-06
Iter: 1468 loss: 1.84526243e-06
Iter: 1469 loss: 1.84320345e-06
Iter: 1470 loss: 1.84287887e-06
Iter: 1471 loss: 1.84278338e-06
Iter: 1472 loss: 1.84257692e-06
Iter: 1473 loss: 1.84231556e-06
Iter: 1474 loss: 1.84227451e-06
Iter: 1475 loss: 1.84204828e-06
Iter: 1476 loss: 1.84143119e-06
Iter: 1477 loss: 1.84602197e-06
Iter: 1478 loss: 1.8413059e-06
Iter: 1479 loss: 1.84050521e-06
Iter: 1480 loss: 1.84204907e-06
Iter: 1481 loss: 1.84020075e-06
Iter: 1482 loss: 1.83972122e-06
Iter: 1483 loss: 1.83967268e-06
Iter: 1484 loss: 1.83916745e-06
Iter: 1485 loss: 1.8387442e-06
Iter: 1486 loss: 1.83857696e-06
Iter: 1487 loss: 1.83795396e-06
Iter: 1488 loss: 1.83858231e-06
Iter: 1489 loss: 1.83764143e-06
Iter: 1490 loss: 1.83724035e-06
Iter: 1491 loss: 1.83721909e-06
Iter: 1492 loss: 1.83687735e-06
Iter: 1493 loss: 1.83658062e-06
Iter: 1494 loss: 1.8365115e-06
Iter: 1495 loss: 1.83601082e-06
Iter: 1496 loss: 1.83691168e-06
Iter: 1497 loss: 1.83580687e-06
Iter: 1498 loss: 1.83536565e-06
Iter: 1499 loss: 1.84177361e-06
Iter: 1500 loss: 1.83535781e-06
Iter: 1501 loss: 1.8350853e-06
Iter: 1502 loss: 1.83468387e-06
Iter: 1503 loss: 1.83466545e-06
Iter: 1504 loss: 1.83429779e-06
Iter: 1505 loss: 1.83972929e-06
Iter: 1506 loss: 1.83430916e-06
Iter: 1507 loss: 1.83392535e-06
Iter: 1508 loss: 1.83392615e-06
Iter: 1509 loss: 1.83362795e-06
Iter: 1510 loss: 1.83335055e-06
Iter: 1511 loss: 1.83330849e-06
Iter: 1512 loss: 1.83312011e-06
Iter: 1513 loss: 1.83278348e-06
Iter: 1514 loss: 1.83608313e-06
Iter: 1515 loss: 1.83277575e-06
Iter: 1516 loss: 1.83240888e-06
Iter: 1517 loss: 1.83305508e-06
Iter: 1518 loss: 1.83222937e-06
Iter: 1519 loss: 1.83188399e-06
Iter: 1520 loss: 1.83136888e-06
Iter: 1521 loss: 1.83135762e-06
Iter: 1522 loss: 1.83090754e-06
Iter: 1523 loss: 1.8308865e-06
Iter: 1524 loss: 1.83042812e-06
Iter: 1525 loss: 1.83069187e-06
Iter: 1526 loss: 1.83013469e-06
Iter: 1527 loss: 1.82969688e-06
Iter: 1528 loss: 1.83032068e-06
Iter: 1529 loss: 1.82945314e-06
Iter: 1530 loss: 1.8291496e-06
Iter: 1531 loss: 1.82914914e-06
Iter: 1532 loss: 1.82892722e-06
Iter: 1533 loss: 1.82878853e-06
Iter: 1534 loss: 1.82870019e-06
Iter: 1535 loss: 1.82840756e-06
Iter: 1536 loss: 1.82954625e-06
Iter: 1537 loss: 1.82832252e-06
Iter: 1538 loss: 1.828e-06
Iter: 1539 loss: 1.82903887e-06
Iter: 1540 loss: 1.82788153e-06
Iter: 1541 loss: 1.82761016e-06
Iter: 1542 loss: 1.82717031e-06
Iter: 1543 loss: 1.82717235e-06
Iter: 1544 loss: 1.82667873e-06
Iter: 1545 loss: 1.82982922e-06
Iter: 1546 loss: 1.82665258e-06
Iter: 1547 loss: 1.82624092e-06
Iter: 1548 loss: 1.8312694e-06
Iter: 1549 loss: 1.82624103e-06
Iter: 1550 loss: 1.82601275e-06
Iter: 1551 loss: 1.82562349e-06
Iter: 1552 loss: 1.82563087e-06
Iter: 1553 loss: 1.82522854e-06
Iter: 1554 loss: 1.82735766e-06
Iter: 1555 loss: 1.8251751e-06
Iter: 1556 loss: 1.82468386e-06
Iter: 1557 loss: 1.82649137e-06
Iter: 1558 loss: 1.82456108e-06
Iter: 1559 loss: 1.82418171e-06
Iter: 1560 loss: 1.82397162e-06
Iter: 1561 loss: 1.82378972e-06
Iter: 1562 loss: 1.82325766e-06
Iter: 1563 loss: 1.82755e-06
Iter: 1564 loss: 1.82323515e-06
Iter: 1565 loss: 1.82274016e-06
Iter: 1566 loss: 1.82308338e-06
Iter: 1567 loss: 1.82237955e-06
Iter: 1568 loss: 1.82193025e-06
Iter: 1569 loss: 1.8228003e-06
Iter: 1570 loss: 1.82171607e-06
Iter: 1571 loss: 1.82130668e-06
Iter: 1572 loss: 1.8212977e-06
Iter: 1573 loss: 1.8210751e-06
Iter: 1574 loss: 1.82064946e-06
Iter: 1575 loss: 1.82863732e-06
Iter: 1576 loss: 1.82062854e-06
Iter: 1577 loss: 1.82014742e-06
Iter: 1578 loss: 1.82190774e-06
Iter: 1579 loss: 1.82006283e-06
Iter: 1580 loss: 1.81978385e-06
Iter: 1581 loss: 1.81976748e-06
Iter: 1582 loss: 1.81952907e-06
Iter: 1583 loss: 1.81907149e-06
Iter: 1584 loss: 1.82636472e-06
Iter: 1585 loss: 1.81904227e-06
Iter: 1586 loss: 1.81849259e-06
Iter: 1587 loss: 1.81992118e-06
Iter: 1588 loss: 1.81832866e-06
Iter: 1589 loss: 1.81783901e-06
Iter: 1590 loss: 1.81785435e-06
Iter: 1591 loss: 1.81748851e-06
Iter: 1592 loss: 1.81697726e-06
Iter: 1593 loss: 1.81696601e-06
Iter: 1594 loss: 1.81635414e-06
Iter: 1595 loss: 1.82044619e-06
Iter: 1596 loss: 1.81628161e-06
Iter: 1597 loss: 1.81571772e-06
Iter: 1598 loss: 1.81782434e-06
Iter: 1599 loss: 1.81553344e-06
Iter: 1600 loss: 1.81515429e-06
Iter: 1601 loss: 1.81498342e-06
Iter: 1602 loss: 1.81476082e-06
Iter: 1603 loss: 1.81440896e-06
Iter: 1604 loss: 1.81439236e-06
Iter: 1605 loss: 1.81413577e-06
Iter: 1606 loss: 1.81365976e-06
Iter: 1607 loss: 1.81365408e-06
Iter: 1608 loss: 1.8132024e-06
Iter: 1609 loss: 1.81386065e-06
Iter: 1610 loss: 1.81300379e-06
Iter: 1611 loss: 1.81277528e-06
Iter: 1612 loss: 1.81271639e-06
Iter: 1613 loss: 1.81248367e-06
Iter: 1614 loss: 1.81204769e-06
Iter: 1615 loss: 1.81204916e-06
Iter: 1616 loss: 1.81165933e-06
Iter: 1617 loss: 1.81207656e-06
Iter: 1618 loss: 1.81143116e-06
Iter: 1619 loss: 1.81109635e-06
Iter: 1620 loss: 1.81109681e-06
Iter: 1621 loss: 1.81077462e-06
Iter: 1622 loss: 1.81026178e-06
Iter: 1623 loss: 1.81024416e-06
Iter: 1624 loss: 1.80971688e-06
Iter: 1625 loss: 1.81305688e-06
Iter: 1626 loss: 1.80965401e-06
Iter: 1627 loss: 1.80916277e-06
Iter: 1628 loss: 1.8116441e-06
Iter: 1629 loss: 1.80910229e-06
Iter: 1630 loss: 1.80868119e-06
Iter: 1631 loss: 1.80827124e-06
Iter: 1632 loss: 1.80820962e-06
Iter: 1633 loss: 1.80789061e-06
Iter: 1634 loss: 1.80785287e-06
Iter: 1635 loss: 1.80752829e-06
Iter: 1636 loss: 1.80716836e-06
Iter: 1637 loss: 1.80712379e-06
Iter: 1638 loss: 1.80667939e-06
Iter: 1639 loss: 1.80673578e-06
Iter: 1640 loss: 1.80634106e-06
Iter: 1641 loss: 1.80606321e-06
Iter: 1642 loss: 1.80600182e-06
Iter: 1643 loss: 1.80569214e-06
Iter: 1644 loss: 1.80576149e-06
Iter: 1645 loss: 1.80543327e-06
Iter: 1646 loss: 1.80513916e-06
Iter: 1647 loss: 1.80517088e-06
Iter: 1648 loss: 1.80490019e-06
Iter: 1649 loss: 1.80469351e-06
Iter: 1650 loss: 1.80469715e-06
Iter: 1651 loss: 1.80444715e-06
Iter: 1652 loss: 1.80439042e-06
Iter: 1653 loss: 1.80423683e-06
Iter: 1654 loss: 1.80398365e-06
Iter: 1655 loss: 1.80421057e-06
Iter: 1656 loss: 1.80379016e-06
Iter: 1657 loss: 1.80341578e-06
Iter: 1658 loss: 1.8059601e-06
Iter: 1659 loss: 1.80336838e-06
Iter: 1660 loss: 1.80296615e-06
Iter: 1661 loss: 1.80239579e-06
Iter: 1662 loss: 1.8024142e-06
Iter: 1663 loss: 1.80186873e-06
Iter: 1664 loss: 1.80970221e-06
Iter: 1665 loss: 1.80187112e-06
Iter: 1666 loss: 1.80143172e-06
Iter: 1667 loss: 1.80269535e-06
Iter: 1668 loss: 1.80129086e-06
Iter: 1669 loss: 1.80106099e-06
Iter: 1670 loss: 1.80080212e-06
Iter: 1671 loss: 1.80078951e-06
Iter: 1672 loss: 1.80049074e-06
Iter: 1673 loss: 1.80425081e-06
Iter: 1674 loss: 1.80049767e-06
Iter: 1675 loss: 1.80023721e-06
Iter: 1676 loss: 1.80158372e-06
Iter: 1677 loss: 1.80018833e-06
Iter: 1678 loss: 1.80005759e-06
Iter: 1679 loss: 1.7997329e-06
Iter: 1680 loss: 1.80459938e-06
Iter: 1681 loss: 1.7997387e-06
Iter: 1682 loss: 1.7994189e-06
Iter: 1683 loss: 1.80322354e-06
Iter: 1684 loss: 1.79941935e-06
Iter: 1685 loss: 1.7991357e-06
Iter: 1686 loss: 1.80027496e-06
Iter: 1687 loss: 1.7990651e-06
Iter: 1688 loss: 1.79890822e-06
Iter: 1689 loss: 1.79877532e-06
Iter: 1690 loss: 1.79869915e-06
Iter: 1691 loss: 1.79844687e-06
Iter: 1692 loss: 1.80133122e-06
Iter: 1693 loss: 1.79845119e-06
Iter: 1694 loss: 1.79823235e-06
Iter: 1695 loss: 1.79803374e-06
Iter: 1696 loss: 1.79797712e-06
Iter: 1697 loss: 1.79768563e-06
Iter: 1698 loss: 1.79863707e-06
Iter: 1699 loss: 1.79758808e-06
Iter: 1700 loss: 1.79722599e-06
Iter: 1701 loss: 1.79942958e-06
Iter: 1702 loss: 1.7971845e-06
Iter: 1703 loss: 1.7969611e-06
Iter: 1704 loss: 1.79646804e-06
Iter: 1705 loss: 1.80569407e-06
Iter: 1706 loss: 1.79648919e-06
Iter: 1707 loss: 1.79608242e-06
Iter: 1708 loss: 1.80039547e-06
Iter: 1709 loss: 1.79607878e-06
Iter: 1710 loss: 1.79582753e-06
Iter: 1711 loss: 1.79583958e-06
Iter: 1712 loss: 1.79569133e-06
Iter: 1713 loss: 1.79537653e-06
Iter: 1714 loss: 1.79907749e-06
Iter: 1715 loss: 1.79536119e-06
Iter: 1716 loss: 1.79506776e-06
Iter: 1717 loss: 1.7975517e-06
Iter: 1718 loss: 1.79504809e-06
Iter: 1719 loss: 1.79480674e-06
Iter: 1720 loss: 1.79695598e-06
Iter: 1721 loss: 1.79480389e-06
Iter: 1722 loss: 1.7946013e-06
Iter: 1723 loss: 1.79430208e-06
Iter: 1724 loss: 1.79429912e-06
Iter: 1725 loss: 1.7940381e-06
Iter: 1726 loss: 1.79839196e-06
Iter: 1727 loss: 1.79403855e-06
Iter: 1728 loss: 1.79379833e-06
Iter: 1729 loss: 1.7938778e-06
Iter: 1730 loss: 1.793622e-06
Iter: 1731 loss: 1.7933545e-06
Iter: 1732 loss: 1.79348763e-06
Iter: 1733 loss: 1.79317794e-06
Iter: 1734 loss: 1.79294398e-06
Iter: 1735 loss: 1.79293477e-06
Iter: 1736 loss: 1.79275935e-06
Iter: 1737 loss: 1.79240135e-06
Iter: 1738 loss: 1.79778044e-06
Iter: 1739 loss: 1.79236895e-06
Iter: 1740 loss: 1.7920363e-06
Iter: 1741 loss: 1.79322569e-06
Iter: 1742 loss: 1.79192011e-06
Iter: 1743 loss: 1.79168455e-06
Iter: 1744 loss: 1.79165465e-06
Iter: 1745 loss: 1.79148219e-06
Iter: 1746 loss: 1.7911575e-06
Iter: 1747 loss: 1.79847393e-06
Iter: 1748 loss: 1.79115568e-06
Iter: 1749 loss: 1.79083963e-06
Iter: 1750 loss: 1.79155e-06
Iter: 1751 loss: 1.79074073e-06
Iter: 1752 loss: 1.79046765e-06
Iter: 1753 loss: 1.79045844e-06
Iter: 1754 loss: 1.79030349e-06
Iter: 1755 loss: 1.79003109e-06
Iter: 1756 loss: 1.79003439e-06
Iter: 1757 loss: 1.78979985e-06
Iter: 1758 loss: 1.79178971e-06
Iter: 1759 loss: 1.78977484e-06
Iter: 1760 loss: 1.78951097e-06
Iter: 1761 loss: 1.79005167e-06
Iter: 1762 loss: 1.78942946e-06
Iter: 1763 loss: 1.78916184e-06
Iter: 1764 loss: 1.78909e-06
Iter: 1765 loss: 1.7889613e-06
Iter: 1766 loss: 1.7887794e-06
Iter: 1767 loss: 1.78876087e-06
Iter: 1768 loss: 1.78857829e-06
Iter: 1769 loss: 1.78824075e-06
Iter: 1770 loss: 1.78823734e-06
Iter: 1771 loss: 1.7879147e-06
Iter: 1772 loss: 1.78818368e-06
Iter: 1773 loss: 1.78774098e-06
Iter: 1774 loss: 1.78752339e-06
Iter: 1775 loss: 1.78749656e-06
Iter: 1776 loss: 1.78726918e-06
Iter: 1777 loss: 1.78699065e-06
Iter: 1778 loss: 1.78695154e-06
Iter: 1779 loss: 1.7866023e-06
Iter: 1780 loss: 1.78642006e-06
Iter: 1781 loss: 1.78625089e-06
Iter: 1782 loss: 1.78612447e-06
Iter: 1783 loss: 1.78599316e-06
Iter: 1784 loss: 1.78579739e-06
Iter: 1785 loss: 1.78556866e-06
Iter: 1786 loss: 1.78552853e-06
Iter: 1787 loss: 1.78524624e-06
Iter: 1788 loss: 1.78607866e-06
Iter: 1789 loss: 1.78520929e-06
Iter: 1790 loss: 1.78492189e-06
Iter: 1791 loss: 1.78727203e-06
Iter: 1792 loss: 1.78489518e-06
Iter: 1793 loss: 1.78472521e-06
Iter: 1794 loss: 1.78454479e-06
Iter: 1795 loss: 1.78450773e-06
Iter: 1796 loss: 1.78428172e-06
Iter: 1797 loss: 1.78635037e-06
Iter: 1798 loss: 1.78427035e-06
Iter: 1799 loss: 1.78400023e-06
Iter: 1800 loss: 1.78411426e-06
Iter: 1801 loss: 1.78381401e-06
Iter: 1802 loss: 1.7835273e-06
Iter: 1803 loss: 1.78325536e-06
Iter: 1804 loss: 1.78318396e-06
Iter: 1805 loss: 1.78297682e-06
Iter: 1806 loss: 1.78294852e-06
Iter: 1807 loss: 1.78271421e-06
Iter: 1808 loss: 1.78287075e-06
Iter: 1809 loss: 1.78257801e-06
Iter: 1810 loss: 1.78233313e-06
Iter: 1811 loss: 1.78211621e-06
Iter: 1812 loss: 1.78209712e-06
Iter: 1813 loss: 1.78187827e-06
Iter: 1814 loss: 1.78187258e-06
Iter: 1815 loss: 1.7816501e-06
Iter: 1816 loss: 1.78168841e-06
Iter: 1817 loss: 1.7814873e-06
Iter: 1818 loss: 1.78120899e-06
Iter: 1819 loss: 1.78116284e-06
Iter: 1820 loss: 1.78098276e-06
Iter: 1821 loss: 1.7806633e-06
Iter: 1822 loss: 1.78068012e-06
Iter: 1823 loss: 1.7804357e-06
Iter: 1824 loss: 1.78021878e-06
Iter: 1825 loss: 1.78013795e-06
Iter: 1826 loss: 1.77985089e-06
Iter: 1827 loss: 1.78093842e-06
Iter: 1828 loss: 1.77978382e-06
Iter: 1829 loss: 1.77947607e-06
Iter: 1830 loss: 1.78244545e-06
Iter: 1831 loss: 1.77946799e-06
Iter: 1832 loss: 1.77931884e-06
Iter: 1833 loss: 1.7789921e-06
Iter: 1834 loss: 1.78550454e-06
Iter: 1835 loss: 1.77900097e-06
Iter: 1836 loss: 1.77870129e-06
Iter: 1837 loss: 1.78078426e-06
Iter: 1838 loss: 1.77868128e-06
Iter: 1839 loss: 1.77832317e-06
Iter: 1840 loss: 1.77985487e-06
Iter: 1841 loss: 1.77827019e-06
Iter: 1842 loss: 1.77804156e-06
Iter: 1843 loss: 1.77768857e-06
Iter: 1844 loss: 1.77768698e-06
Iter: 1845 loss: 1.77734796e-06
Iter: 1846 loss: 1.77944e-06
Iter: 1847 loss: 1.77730476e-06
Iter: 1848 loss: 1.77700747e-06
Iter: 1849 loss: 1.78053801e-06
Iter: 1850 loss: 1.77700292e-06
Iter: 1851 loss: 1.77683569e-06
Iter: 1852 loss: 1.77663037e-06
Iter: 1853 loss: 1.77661809e-06
Iter: 1854 loss: 1.77638242e-06
Iter: 1855 loss: 1.77976017e-06
Iter: 1856 loss: 1.77638617e-06
Iter: 1857 loss: 1.77619063e-06
Iter: 1858 loss: 1.77617812e-06
Iter: 1859 loss: 1.77602135e-06
Iter: 1860 loss: 1.77574975e-06
Iter: 1861 loss: 1.77550646e-06
Iter: 1862 loss: 1.77544052e-06
Iter: 1863 loss: 1.77514289e-06
Iter: 1864 loss: 1.77513402e-06
Iter: 1865 loss: 1.77489096e-06
Iter: 1866 loss: 1.77446373e-06
Iter: 1867 loss: 1.77447691e-06
Iter: 1868 loss: 1.77413187e-06
Iter: 1869 loss: 1.77532365e-06
Iter: 1870 loss: 1.77404604e-06
Iter: 1871 loss: 1.77380934e-06
Iter: 1872 loss: 1.77379206e-06
Iter: 1873 loss: 1.77365064e-06
Iter: 1874 loss: 1.77340485e-06
Iter: 1875 loss: 1.77921743e-06
Iter: 1876 loss: 1.7733845e-06
Iter: 1877 loss: 1.77312904e-06
Iter: 1878 loss: 1.77325501e-06
Iter: 1879 loss: 1.77292156e-06
Iter: 1880 loss: 1.7727491e-06
Iter: 1881 loss: 1.7727e-06
Iter: 1882 loss: 1.77254174e-06
Iter: 1883 loss: 1.77218249e-06
Iter: 1884 loss: 1.77854758e-06
Iter: 1885 loss: 1.77215986e-06
Iter: 1886 loss: 1.77182289e-06
Iter: 1887 loss: 1.77496759e-06
Iter: 1888 loss: 1.77182881e-06
Iter: 1889 loss: 1.77152936e-06
Iter: 1890 loss: 1.77244419e-06
Iter: 1891 loss: 1.77142e-06
Iter: 1892 loss: 1.77114782e-06
Iter: 1893 loss: 1.7708785e-06
Iter: 1894 loss: 1.77082347e-06
Iter: 1895 loss: 1.77050219e-06
Iter: 1896 loss: 1.77052425e-06
Iter: 1897 loss: 1.77019183e-06
Iter: 1898 loss: 1.77001493e-06
Iter: 1899 loss: 1.76987396e-06
Iter: 1900 loss: 1.76954302e-06
Iter: 1901 loss: 1.76964022e-06
Iter: 1902 loss: 1.76928233e-06
Iter: 1903 loss: 1.76909771e-06
Iter: 1904 loss: 1.76904246e-06
Iter: 1905 loss: 1.76883782e-06
Iter: 1906 loss: 1.76852336e-06
Iter: 1907 loss: 1.76851199e-06
Iter: 1908 loss: 1.76820936e-06
Iter: 1909 loss: 1.76846743e-06
Iter: 1910 loss: 1.76804485e-06
Iter: 1911 loss: 1.76778985e-06
Iter: 1912 loss: 1.76780782e-06
Iter: 1913 loss: 1.76754702e-06
Iter: 1914 loss: 1.76735534e-06
Iter: 1915 loss: 1.76724507e-06
Iter: 1916 loss: 1.76694698e-06
Iter: 1917 loss: 1.76744061e-06
Iter: 1918 loss: 1.76679964e-06
Iter: 1919 loss: 1.76647848e-06
Iter: 1920 loss: 1.77039806e-06
Iter: 1921 loss: 1.76647973e-06
Iter: 1922 loss: 1.76623439e-06
Iter: 1923 loss: 1.7659886e-06
Iter: 1924 loss: 1.76596291e-06
Iter: 1925 loss: 1.76565152e-06
Iter: 1926 loss: 1.76718561e-06
Iter: 1927 loss: 1.76559661e-06
Iter: 1928 loss: 1.7653017e-06
Iter: 1929 loss: 1.76761216e-06
Iter: 1930 loss: 1.76527772e-06
Iter: 1931 loss: 1.76509411e-06
Iter: 1932 loss: 1.76467609e-06
Iter: 1933 loss: 1.77026925e-06
Iter: 1934 loss: 1.76464596e-06
Iter: 1935 loss: 1.76424055e-06
Iter: 1936 loss: 1.76942592e-06
Iter: 1937 loss: 1.76423305e-06
Iter: 1938 loss: 1.76381104e-06
Iter: 1939 loss: 1.76474873e-06
Iter: 1940 loss: 1.76362641e-06
Iter: 1941 loss: 1.76332799e-06
Iter: 1942 loss: 1.76298261e-06
Iter: 1943 loss: 1.762956e-06
Iter: 1944 loss: 1.76253729e-06
Iter: 1945 loss: 1.76566539e-06
Iter: 1946 loss: 1.76251069e-06
Iter: 1947 loss: 1.76221624e-06
Iter: 1948 loss: 1.76222375e-06
Iter: 1949 loss: 1.76209096e-06
Iter: 1950 loss: 1.76182743e-06
Iter: 1951 loss: 1.76639492e-06
Iter: 1952 loss: 1.76181959e-06
Iter: 1953 loss: 1.76159438e-06
Iter: 1954 loss: 1.7615763e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2
+ date
Mon Nov  2 09:28:08 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 1.2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb050365598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb050359950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0503d67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05032b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05032b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0503d66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501f4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb050174598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501746a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501341e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0501ab840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045e2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045e2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004615158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00460d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045e2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0045ce9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00463eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004654b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00463e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004510620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0500621e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004510b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05020bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00455aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043db0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043dba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb05009a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043dbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0043dbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb00453f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb0042b0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb004456f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.00015391581
test_loss: 0.00015114415
train_loss: 4.627009e-05
test_loss: 4.9310293e-05
train_loss: 2.6609345e-05
test_loss: 2.5978763e-05
train_loss: 1.7781349e-05
test_loss: 1.7543207e-05
train_loss: 1.31421675e-05
test_loss: 1.3268239e-05
train_loss: 1.0640626e-05
test_loss: 1.0947131e-05
train_loss: 9.185814e-06
test_loss: 9.156303e-06
train_loss: 8.137786e-06
test_loss: 8.093242e-06
train_loss: 7.0265496e-06
test_loss: 7.4031686e-06
train_loss: 6.440058e-06
test_loss: 6.6395896e-06
train_loss: 6.3274188e-06
test_loss: 6.157083e-06
train_loss: 5.8263954e-06
test_loss: 5.6566987e-06
train_loss: 5.382752e-06
test_loss: 5.365601e-06
train_loss: 4.9352707e-06
test_loss: 5.127628e-06
train_loss: 4.866726e-06
test_loss: 4.9099003e-06
train_loss: 4.5995453e-06
test_loss: 4.6651253e-06
train_loss: 4.23269e-06
test_loss: 4.547619e-06
train_loss: 4.3342066e-06
test_loss: 4.368615e-06
train_loss: 3.7521959e-06
test_loss: 4.232341e-06
train_loss: 3.928519e-06
test_loss: 4.1193866e-06
train_loss: 3.7182845e-06
test_loss: 4.0367295e-06
train_loss: 3.6721385e-06
test_loss: 3.8951425e-06
train_loss: 3.717274e-06
test_loss: 3.822197e-06
train_loss: 3.5353783e-06
test_loss: 3.7468478e-06
train_loss: 3.4097402e-06
test_loss: 3.6879705e-06
train_loss: 3.3099873e-06
test_loss: 3.5606954e-06
train_loss: 3.3987142e-06
test_loss: 3.549347e-06
train_loss: 3.2426663e-06
test_loss: 3.5272026e-06
train_loss: 3.4318496e-06
test_loss: 3.4346072e-06
train_loss: 3.0909482e-06
test_loss: 3.4095538e-06
train_loss: 3.2933904e-06
test_loss: 3.357889e-06
train_loss: 2.9852959e-06
test_loss: 3.3326874e-06
train_loss: 3.059511e-06
test_loss: 3.3025228e-06
train_loss: 3.1358145e-06
test_loss: 3.2705095e-06
train_loss: 3.1576765e-06
test_loss: 3.23205e-06
train_loss: 2.9916082e-06
test_loss: 3.1945135e-06
train_loss: 3.0333754e-06
test_loss: 3.1978602e-06
train_loss: 2.8467489e-06
test_loss: 3.1483755e-06
train_loss: 3.049747e-06
test_loss: 3.1262846e-06
train_loss: 3.002253e-06
test_loss: 3.13198e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.2/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.2/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7e3a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7e4eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b37d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b95158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b950d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0f00b95400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d8fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7dc2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb034df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0356f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d567b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d59598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb02d7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ed7d58510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0297f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb032af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0321488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb02a5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0356598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0321d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb01dc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb01dcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0177c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0133d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb01339d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0133730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0088ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb0088488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb004e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb005f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb00617b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb00daea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0e903939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0eb005f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0e90393b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0e90310d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.91327729e-06
Iter: 2 loss: 2.87803186e-06
Iter: 3 loss: 3.38368181e-06
Iter: 4 loss: 2.87798184e-06
Iter: 5 loss: 2.86637692e-06
Iter: 6 loss: 2.95544487e-06
Iter: 7 loss: 2.86548425e-06
Iter: 8 loss: 2.85805163e-06
Iter: 9 loss: 2.87238436e-06
Iter: 10 loss: 2.85496935e-06
Iter: 11 loss: 2.85076021e-06
Iter: 12 loss: 2.90618709e-06
Iter: 13 loss: 2.85073293e-06
Iter: 14 loss: 2.84812768e-06
Iter: 15 loss: 2.85090027e-06
Iter: 16 loss: 2.84669363e-06
Iter: 17 loss: 2.84495536e-06
Iter: 18 loss: 2.85700344e-06
Iter: 19 loss: 2.84474868e-06
Iter: 20 loss: 2.84300722e-06
Iter: 21 loss: 2.84190855e-06
Iter: 22 loss: 2.84121597e-06
Iter: 23 loss: 2.83965164e-06
Iter: 24 loss: 2.84164298e-06
Iter: 25 loss: 2.83886425e-06
Iter: 26 loss: 2.83710597e-06
Iter: 27 loss: 2.86466434e-06
Iter: 28 loss: 2.83710551e-06
Iter: 29 loss: 2.83635472e-06
Iter: 30 loss: 2.83498412e-06
Iter: 31 loss: 2.86547538e-06
Iter: 32 loss: 2.83497798e-06
Iter: 33 loss: 2.83368627e-06
Iter: 34 loss: 2.83888767e-06
Iter: 35 loss: 2.83339705e-06
Iter: 36 loss: 2.83225927e-06
Iter: 37 loss: 2.83265103e-06
Iter: 38 loss: 2.83146892e-06
Iter: 39 loss: 2.83019767e-06
Iter: 40 loss: 2.83799704e-06
Iter: 41 loss: 2.83008626e-06
Iter: 42 loss: 2.8291231e-06
Iter: 43 loss: 2.8333086e-06
Iter: 44 loss: 2.82893e-06
Iter: 45 loss: 2.82880023e-06
Iter: 46 loss: 2.82853898e-06
Iter: 47 loss: 2.82824863e-06
Iter: 48 loss: 2.82766246e-06
Iter: 49 loss: 2.83978261e-06
Iter: 50 loss: 2.82767792e-06
Iter: 51 loss: 2.82716564e-06
Iter: 52 loss: 2.82717133e-06
Iter: 53 loss: 2.82679343e-06
Iter: 54 loss: 2.82601331e-06
Iter: 55 loss: 2.83959071e-06
Iter: 56 loss: 2.82600877e-06
Iter: 57 loss: 2.82552696e-06
Iter: 58 loss: 2.82551105e-06
Iter: 59 loss: 2.82507744e-06
Iter: 60 loss: 2.82412111e-06
Iter: 61 loss: 2.83965574e-06
Iter: 62 loss: 2.82412043e-06
Iter: 63 loss: 2.8233394e-06
Iter: 64 loss: 2.82932865e-06
Iter: 65 loss: 2.82330097e-06
Iter: 66 loss: 2.82264909e-06
Iter: 67 loss: 2.82675501e-06
Iter: 68 loss: 2.82257952e-06
Iter: 69 loss: 2.82212773e-06
Iter: 70 loss: 2.82481324e-06
Iter: 71 loss: 2.82205815e-06
Iter: 72 loss: 2.82173437e-06
Iter: 73 loss: 2.82115798e-06
Iter: 74 loss: 2.82115798e-06
Iter: 75 loss: 2.82060091e-06
Iter: 76 loss: 2.82075121e-06
Iter: 77 loss: 2.82018482e-06
Iter: 78 loss: 2.81950361e-06
Iter: 79 loss: 2.82251153e-06
Iter: 80 loss: 2.81937719e-06
Iter: 81 loss: 2.81911048e-06
Iter: 82 loss: 2.81899293e-06
Iter: 83 loss: 2.81871689e-06
Iter: 84 loss: 2.81820803e-06
Iter: 85 loss: 2.82558767e-06
Iter: 86 loss: 2.81815778e-06
Iter: 87 loss: 2.81751522e-06
Iter: 88 loss: 2.82585597e-06
Iter: 89 loss: 2.81749954e-06
Iter: 90 loss: 2.81715984e-06
Iter: 91 loss: 2.81688131e-06
Iter: 92 loss: 2.81676034e-06
Iter: 93 loss: 2.81634379e-06
Iter: 94 loss: 2.8224481e-06
Iter: 95 loss: 2.81631219e-06
Iter: 96 loss: 2.81603207e-06
Iter: 97 loss: 2.81559596e-06
Iter: 98 loss: 2.81559619e-06
Iter: 99 loss: 2.81522875e-06
Iter: 100 loss: 2.81742678e-06
Iter: 101 loss: 2.81516964e-06
Iter: 102 loss: 2.81473649e-06
Iter: 103 loss: 2.81623375e-06
Iter: 104 loss: 2.81460029e-06
Iter: 105 loss: 2.81415714e-06
Iter: 106 loss: 2.8149193e-06
Iter: 107 loss: 2.81398911e-06
Iter: 108 loss: 2.81351845e-06
Iter: 109 loss: 2.81285816e-06
Iter: 110 loss: 2.81283337e-06
Iter: 111 loss: 2.81201869e-06
Iter: 112 loss: 2.8157242e-06
Iter: 113 loss: 2.81188977e-06
Iter: 114 loss: 2.8113709e-06
Iter: 115 loss: 2.81662597e-06
Iter: 116 loss: 2.81131815e-06
Iter: 117 loss: 2.81076836e-06
Iter: 118 loss: 2.81391885e-06
Iter: 119 loss: 2.8106906e-06
Iter: 120 loss: 2.81045959e-06
Iter: 121 loss: 2.81052121e-06
Iter: 122 loss: 2.81025063e-06
Iter: 123 loss: 2.809737e-06
Iter: 124 loss: 2.8102645e-06
Iter: 125 loss: 2.80948234e-06
Iter: 126 loss: 2.80912877e-06
Iter: 127 loss: 2.80965196e-06
Iter: 128 loss: 2.80899667e-06
Iter: 129 loss: 2.80843051e-06
Iter: 130 loss: 2.80936683e-06
Iter: 131 loss: 2.80817721e-06
Iter: 132 loss: 2.80765062e-06
Iter: 133 loss: 2.80722043e-06
Iter: 134 loss: 2.80708264e-06
Iter: 135 loss: 2.80671384e-06
Iter: 136 loss: 2.80667791e-06
Iter: 137 loss: 2.80627955e-06
Iter: 138 loss: 2.80607765e-06
Iter: 139 loss: 2.80589325e-06
Iter: 140 loss: 2.80524728e-06
Iter: 141 loss: 2.80646213e-06
Iter: 142 loss: 2.80496852e-06
Iter: 143 loss: 2.80435506e-06
Iter: 144 loss: 2.80440372e-06
Iter: 145 loss: 2.80385984e-06
Iter: 146 loss: 2.8030604e-06
Iter: 147 loss: 2.80516042e-06
Iter: 148 loss: 2.80281529e-06
Iter: 149 loss: 2.80283439e-06
Iter: 150 loss: 2.80248105e-06
Iter: 151 loss: 2.80224344e-06
Iter: 152 loss: 2.8017912e-06
Iter: 153 loss: 2.81096641e-06
Iter: 154 loss: 2.80177551e-06
Iter: 155 loss: 2.80146514e-06
Iter: 156 loss: 2.80144582e-06
Iter: 157 loss: 2.80115592e-06
Iter: 158 loss: 2.80043946e-06
Iter: 159 loss: 2.80683344e-06
Iter: 160 loss: 2.80035033e-06
Iter: 161 loss: 2.79967867e-06
Iter: 162 loss: 2.79964979e-06
Iter: 163 loss: 2.79899677e-06
Iter: 164 loss: 2.79796154e-06
Iter: 165 loss: 2.7979454e-06
Iter: 166 loss: 2.79685128e-06
Iter: 167 loss: 2.79909636e-06
Iter: 168 loss: 2.79643223e-06
Iter: 169 loss: 2.7959004e-06
Iter: 170 loss: 2.79578762e-06
Iter: 171 loss: 2.79538949e-06
Iter: 172 loss: 2.79490587e-06
Iter: 173 loss: 2.79482947e-06
Iter: 174 loss: 2.79421215e-06
Iter: 175 loss: 2.79651977e-06
Iter: 176 loss: 2.79408687e-06
Iter: 177 loss: 2.79346045e-06
Iter: 178 loss: 2.79352298e-06
Iter: 179 loss: 2.79296273e-06
Iter: 180 loss: 2.79229653e-06
Iter: 181 loss: 2.79552614e-06
Iter: 182 loss: 2.79215146e-06
Iter: 183 loss: 2.7914441e-06
Iter: 184 loss: 2.79856522e-06
Iter: 185 loss: 2.79139022e-06
Iter: 186 loss: 2.7910246e-06
Iter: 187 loss: 2.7905096e-06
Iter: 188 loss: 2.79048595e-06
Iter: 189 loss: 2.78956554e-06
Iter: 190 loss: 2.79463211e-06
Iter: 191 loss: 2.78942821e-06
Iter: 192 loss: 2.7889896e-06
Iter: 193 loss: 2.78863604e-06
Iter: 194 loss: 2.78851712e-06
Iter: 195 loss: 2.78779817e-06
Iter: 196 loss: 2.79530468e-06
Iter: 197 loss: 2.78780203e-06
Iter: 198 loss: 2.78731227e-06
Iter: 199 loss: 2.78657103e-06
Iter: 200 loss: 2.78654329e-06
Iter: 201 loss: 2.78578614e-06
Iter: 202 loss: 2.78820789e-06
Iter: 203 loss: 2.78554853e-06
Iter: 204 loss: 2.78451807e-06
Iter: 205 loss: 2.79129154e-06
Iter: 206 loss: 2.78441485e-06
Iter: 207 loss: 2.78395555e-06
Iter: 208 loss: 2.78347579e-06
Iter: 209 loss: 2.78340804e-06
Iter: 210 loss: 2.78237667e-06
Iter: 211 loss: 2.78406083e-06
Iter: 212 loss: 2.7819242e-06
Iter: 213 loss: 2.78094785e-06
Iter: 214 loss: 2.78104403e-06
Iter: 215 loss: 2.78015955e-06
Iter: 216 loss: 2.77937193e-06
Iter: 217 loss: 2.77931213e-06
Iter: 218 loss: 2.77843537e-06
Iter: 219 loss: 2.77950039e-06
Iter: 220 loss: 2.77799859e-06
Iter: 221 loss: 2.7773458e-06
Iter: 222 loss: 2.77869412e-06
Iter: 223 loss: 2.77709387e-06
Iter: 224 loss: 2.77611207e-06
Iter: 225 loss: 2.77666413e-06
Iter: 226 loss: 2.77545587e-06
Iter: 227 loss: 2.77471e-06
Iter: 228 loss: 2.77530307e-06
Iter: 229 loss: 2.77426e-06
Iter: 230 loss: 2.773181e-06
Iter: 231 loss: 2.78114271e-06
Iter: 232 loss: 2.77310369e-06
Iter: 233 loss: 2.77255413e-06
Iter: 234 loss: 2.77163122e-06
Iter: 235 loss: 2.77164622e-06
Iter: 236 loss: 2.77105892e-06
Iter: 237 loss: 2.77102799e-06
Iter: 238 loss: 2.77035429e-06
Iter: 239 loss: 2.76959645e-06
Iter: 240 loss: 2.76950777e-06
Iter: 241 loss: 2.76854212e-06
Iter: 242 loss: 2.76862897e-06
Iter: 243 loss: 2.76782475e-06
Iter: 244 loss: 2.76635365e-06
Iter: 245 loss: 2.77433355e-06
Iter: 246 loss: 2.76611718e-06
Iter: 247 loss: 2.76504034e-06
Iter: 248 loss: 2.76683659e-06
Iter: 249 loss: 2.7645724e-06
Iter: 250 loss: 2.76407968e-06
Iter: 251 loss: 2.76397941e-06
Iter: 252 loss: 2.76338369e-06
Iter: 253 loss: 2.76230548e-06
Iter: 254 loss: 2.78625e-06
Iter: 255 loss: 2.76228684e-06
Iter: 256 loss: 2.76187302e-06
Iter: 257 loss: 2.76179435e-06
Iter: 258 loss: 2.76135574e-06
Iter: 259 loss: 2.76056244e-06
Iter: 260 loss: 2.77957815e-06
Iter: 261 loss: 2.76057335e-06
Iter: 262 loss: 2.75982075e-06
Iter: 263 loss: 2.7615597e-06
Iter: 264 loss: 2.75952152e-06
Iter: 265 loss: 2.75849561e-06
Iter: 266 loss: 2.76548781e-06
Iter: 267 loss: 2.75839875e-06
Iter: 268 loss: 2.75783941e-06
Iter: 269 loss: 2.75658863e-06
Iter: 270 loss: 2.77427444e-06
Iter: 271 loss: 2.75651746e-06
Iter: 272 loss: 2.75534239e-06
Iter: 273 loss: 2.77097888e-06
Iter: 274 loss: 2.75537059e-06
Iter: 275 loss: 2.75423599e-06
Iter: 276 loss: 2.75947059e-06
Iter: 277 loss: 2.75400612e-06
Iter: 278 loss: 2.75339835e-06
Iter: 279 loss: 2.75241678e-06
Iter: 280 loss: 2.75239654e-06
Iter: 281 loss: 2.75118373e-06
Iter: 282 loss: 2.75595448e-06
Iter: 283 loss: 2.75090429e-06
Iter: 284 loss: 2.75041543e-06
Iter: 285 loss: 2.75031834e-06
Iter: 286 loss: 2.74977901e-06
Iter: 287 loss: 2.75057528e-06
Iter: 288 loss: 2.74952708e-06
Iter: 289 loss: 2.74878084e-06
Iter: 290 loss: 2.74806507e-06
Iter: 291 loss: 2.74790455e-06
Iter: 292 loss: 2.74737795e-06
Iter: 293 loss: 2.74731633e-06
Iter: 294 loss: 2.74683316e-06
Iter: 295 loss: 2.74563672e-06
Iter: 296 loss: 2.7573933e-06
Iter: 297 loss: 2.74548e-06
Iter: 298 loss: 2.74448621e-06
Iter: 299 loss: 2.75507887e-06
Iter: 300 loss: 2.74443778e-06
Iter: 301 loss: 2.7434171e-06
Iter: 302 loss: 2.74648619e-06
Iter: 303 loss: 2.7431347e-06
Iter: 304 loss: 2.74224931e-06
Iter: 305 loss: 2.74108743e-06
Iter: 306 loss: 2.74101808e-06
Iter: 307 loss: 2.73995101e-06
Iter: 308 loss: 2.75362072e-06
Iter: 309 loss: 2.73993692e-06
Iter: 310 loss: 2.73878504e-06
Iter: 311 loss: 2.741966e-06
Iter: 312 loss: 2.73839532e-06
Iter: 313 loss: 2.73772e-06
Iter: 314 loss: 2.73640489e-06
Iter: 315 loss: 2.76101218e-06
Iter: 316 loss: 2.73639171e-06
Iter: 317 loss: 2.73518708e-06
Iter: 318 loss: 2.74489457e-06
Iter: 319 loss: 2.73508658e-06
Iter: 320 loss: 2.73465776e-06
Iter: 321 loss: 2.73449541e-06
Iter: 322 loss: 2.73402156e-06
Iter: 323 loss: 2.73311593e-06
Iter: 324 loss: 2.7510705e-06
Iter: 325 loss: 2.73310457e-06
Iter: 326 loss: 2.73198611e-06
Iter: 327 loss: 2.73888372e-06
Iter: 328 loss: 2.73183377e-06
Iter: 329 loss: 2.73096884e-06
Iter: 330 loss: 2.73589058e-06
Iter: 331 loss: 2.73085016e-06
Iter: 332 loss: 2.730191e-06
Iter: 333 loss: 2.7287349e-06
Iter: 334 loss: 2.7526562e-06
Iter: 335 loss: 2.72869102e-06
Iter: 336 loss: 2.72775696e-06
Iter: 337 loss: 2.72774287e-06
Iter: 338 loss: 2.72702891e-06
Iter: 339 loss: 2.73017918e-06
Iter: 340 loss: 2.72693751e-06
Iter: 341 loss: 2.72649959e-06
Iter: 342 loss: 2.72549141e-06
Iter: 343 loss: 2.73714204e-06
Iter: 344 loss: 2.72543184e-06
Iter: 345 loss: 2.72518355e-06
Iter: 346 loss: 2.7248916e-06
Iter: 347 loss: 2.72436705e-06
Iter: 348 loss: 2.72344278e-06
Iter: 349 loss: 2.72344028e-06
Iter: 350 loss: 2.7223773e-06
Iter: 351 loss: 2.72224702e-06
Iter: 352 loss: 2.72147963e-06
Iter: 353 loss: 2.72026682e-06
Iter: 354 loss: 2.72896523e-06
Iter: 355 loss: 2.72016086e-06
Iter: 356 loss: 2.71905947e-06
Iter: 357 loss: 2.73381283e-06
Iter: 358 loss: 2.7190772e-06
Iter: 359 loss: 2.71854287e-06
Iter: 360 loss: 2.71792578e-06
Iter: 361 loss: 2.71785325e-06
Iter: 362 loss: 2.71718204e-06
Iter: 363 loss: 2.71718659e-06
Iter: 364 loss: 2.71669114e-06
Iter: 365 loss: 2.71632643e-06
Iter: 366 loss: 2.7161966e-06
Iter: 367 loss: 2.71539739e-06
Iter: 368 loss: 2.71667113e-06
Iter: 369 loss: 2.71500949e-06
Iter: 370 loss: 2.71430258e-06
Iter: 371 loss: 2.719549e-06
Iter: 372 loss: 2.71421914e-06
Iter: 373 loss: 2.71348176e-06
Iter: 374 loss: 2.71407862e-06
Iter: 375 loss: 2.71301224e-06
Iter: 376 loss: 2.71232511e-06
Iter: 377 loss: 2.71148429e-06
Iter: 378 loss: 2.71141789e-06
Iter: 379 loss: 2.71112049e-06
Iter: 380 loss: 2.71080376e-06
Iter: 381 loss: 2.7103024e-06
Iter: 382 loss: 2.7090598e-06
Iter: 383 loss: 2.72345324e-06
Iter: 384 loss: 2.70896703e-06
Iter: 385 loss: 2.70771511e-06
Iter: 386 loss: 2.71077533e-06
Iter: 387 loss: 2.70727833e-06
Iter: 388 loss: 2.70612372e-06
Iter: 389 loss: 2.71231784e-06
Iter: 390 loss: 2.70594e-06
Iter: 391 loss: 2.70479313e-06
Iter: 392 loss: 2.71752197e-06
Iter: 393 loss: 2.70474447e-06
Iter: 394 loss: 2.70430178e-06
Iter: 395 loss: 2.70349506e-06
Iter: 396 loss: 2.72162242e-06
Iter: 397 loss: 2.70350711e-06
Iter: 398 loss: 2.7025842e-06
Iter: 399 loss: 2.71629165e-06
Iter: 400 loss: 2.70256396e-06
Iter: 401 loss: 2.70197097e-06
Iter: 402 loss: 2.70091664e-06
Iter: 403 loss: 2.72603847e-06
Iter: 404 loss: 2.70092096e-06
Iter: 405 loss: 2.69982866e-06
Iter: 406 loss: 2.71109093e-06
Iter: 407 loss: 2.69978773e-06
Iter: 408 loss: 2.69894463e-06
Iter: 409 loss: 2.70174883e-06
Iter: 410 loss: 2.6987002e-06
Iter: 411 loss: 2.69785141e-06
Iter: 412 loss: 2.69826273e-06
Iter: 413 loss: 2.69723023e-06
Iter: 414 loss: 2.69614907e-06
Iter: 415 loss: 2.69601014e-06
Iter: 416 loss: 2.69524617e-06
Iter: 417 loss: 2.6944108e-06
Iter: 418 loss: 2.69426096e-06
Iter: 419 loss: 2.69362226e-06
Iter: 420 loss: 2.69230213e-06
Iter: 421 loss: 2.71821773e-06
Iter: 422 loss: 2.69229e-06
Iter: 423 loss: 2.69100747e-06
Iter: 424 loss: 2.69171687e-06
Iter: 425 loss: 2.69014708e-06
Iter: 426 loss: 2.68971144e-06
Iter: 427 loss: 2.68948088e-06
Iter: 428 loss: 2.68869121e-06
Iter: 429 loss: 2.68856161e-06
Iter: 430 loss: 2.68797703e-06
Iter: 431 loss: 2.68712643e-06
Iter: 432 loss: 2.68758686e-06
Iter: 433 loss: 2.68657095e-06
Iter: 434 loss: 2.6856469e-06
Iter: 435 loss: 2.69877205e-06
Iter: 436 loss: 2.68564281e-06
Iter: 437 loss: 2.6849234e-06
Iter: 438 loss: 2.682993e-06
Iter: 439 loss: 2.69618249e-06
Iter: 440 loss: 2.68255462e-06
Iter: 441 loss: 2.68185886e-06
Iter: 442 loss: 2.68151121e-06
Iter: 443 loss: 2.68051576e-06
Iter: 444 loss: 2.67934661e-06
Iter: 445 loss: 2.67922246e-06
Iter: 446 loss: 2.67806e-06
Iter: 447 loss: 2.68833674e-06
Iter: 448 loss: 2.67802511e-06
Iter: 449 loss: 2.67715518e-06
Iter: 450 loss: 2.67759242e-06
Iter: 451 loss: 2.67654877e-06
Iter: 452 loss: 2.675627e-06
Iter: 453 loss: 2.69024667e-06
Iter: 454 loss: 2.67563928e-06
Iter: 455 loss: 2.67503901e-06
Iter: 456 loss: 2.67378437e-06
Iter: 457 loss: 2.69635098e-06
Iter: 458 loss: 2.67377482e-06
Iter: 459 loss: 2.67211794e-06
Iter: 460 loss: 2.67097448e-06
Iter: 461 loss: 2.67036239e-06
Iter: 462 loss: 2.66796565e-06
Iter: 463 loss: 2.6794678e-06
Iter: 464 loss: 2.66748248e-06
Iter: 465 loss: 2.66688448e-06
Iter: 466 loss: 2.66645793e-06
Iter: 467 loss: 2.66543179e-06
Iter: 468 loss: 2.66490861e-06
Iter: 469 loss: 2.66442157e-06
Iter: 470 loss: 2.66343477e-06
Iter: 471 loss: 2.66458846e-06
Iter: 472 loss: 2.66287589e-06
Iter: 473 loss: 2.66151028e-06
Iter: 474 loss: 2.67371752e-06
Iter: 475 loss: 2.66146571e-06
Iter: 476 loss: 2.660684e-06
Iter: 477 loss: 2.65920494e-06
Iter: 478 loss: 2.69085922e-06
Iter: 479 loss: 2.6591797e-06
Iter: 480 loss: 2.65843732e-06
Iter: 481 loss: 2.65834569e-06
Iter: 482 loss: 2.65750759e-06
Iter: 483 loss: 2.65623976e-06
Iter: 484 loss: 2.65619337e-06
Iter: 485 loss: 2.6548787e-06
Iter: 486 loss: 2.66519692e-06
Iter: 487 loss: 2.65481412e-06
Iter: 488 loss: 2.65366248e-06
Iter: 489 loss: 2.65621225e-06
Iter: 490 loss: 2.65324843e-06
Iter: 491 loss: 2.6519217e-06
Iter: 492 loss: 2.65744893e-06
Iter: 493 loss: 2.65164658e-06
Iter: 494 loss: 2.65061976e-06
Iter: 495 loss: 2.64848e-06
Iter: 496 loss: 2.68437952e-06
Iter: 497 loss: 2.64842765e-06
Iter: 498 loss: 2.64641358e-06
Iter: 499 loss: 2.6580733e-06
Iter: 500 loss: 2.646133e-06
Iter: 501 loss: 2.64495043e-06
Iter: 502 loss: 2.64490905e-06
Iter: 503 loss: 2.64364917e-06
Iter: 504 loss: 2.64551591e-06
Iter: 505 loss: 2.64305299e-06
Iter: 506 loss: 2.64224172e-06
Iter: 507 loss: 2.64148366e-06
Iter: 508 loss: 2.64128767e-06
Iter: 509 loss: 2.64046503e-06
Iter: 510 loss: 2.64041091e-06
Iter: 511 loss: 2.63976835e-06
Iter: 512 loss: 2.63852985e-06
Iter: 513 loss: 2.6618975e-06
Iter: 514 loss: 2.6385e-06
Iter: 515 loss: 2.6370717e-06
Iter: 516 loss: 2.63938659e-06
Iter: 517 loss: 2.6364703e-06
Iter: 518 loss: 2.63461516e-06
Iter: 519 loss: 2.65195558e-06
Iter: 520 loss: 2.63455786e-06
Iter: 521 loss: 2.63348284e-06
Iter: 522 loss: 2.63208494e-06
Iter: 523 loss: 2.63200468e-06
Iter: 524 loss: 2.63028119e-06
Iter: 525 loss: 2.65329822e-06
Iter: 526 loss: 2.6302821e-06
Iter: 527 loss: 2.62922708e-06
Iter: 528 loss: 2.63298216e-06
Iter: 529 loss: 2.62898016e-06
Iter: 530 loss: 2.62788535e-06
Iter: 531 loss: 2.62623325e-06
Iter: 532 loss: 2.6262112e-06
Iter: 533 loss: 2.62455887e-06
Iter: 534 loss: 2.62833328e-06
Iter: 535 loss: 2.62394747e-06
Iter: 536 loss: 2.62281e-06
Iter: 537 loss: 2.62275171e-06
Iter: 538 loss: 2.62136859e-06
Iter: 539 loss: 2.62080016e-06
Iter: 540 loss: 2.6200596e-06
Iter: 541 loss: 2.61875266e-06
Iter: 542 loss: 2.61894593e-06
Iter: 543 loss: 2.61774812e-06
Iter: 544 loss: 2.61642936e-06
Iter: 545 loss: 2.61638934e-06
Iter: 546 loss: 2.61545483e-06
Iter: 547 loss: 2.61351261e-06
Iter: 548 loss: 2.64576533e-06
Iter: 549 loss: 2.61346713e-06
Iter: 550 loss: 2.61193054e-06
Iter: 551 loss: 2.62364392e-06
Iter: 552 loss: 2.61183959e-06
Iter: 553 loss: 2.61040259e-06
Iter: 554 loss: 2.6198295e-06
Iter: 555 loss: 2.6102548e-06
Iter: 556 loss: 2.60939169e-06
Iter: 557 loss: 2.60944785e-06
Iter: 558 loss: 2.6086866e-06
Iter: 559 loss: 2.60770071e-06
Iter: 560 loss: 2.61805621e-06
Iter: 561 loss: 2.60768957e-06
Iter: 562 loss: 2.60685e-06
Iter: 563 loss: 2.60638217e-06
Iter: 564 loss: 2.60600245e-06
Iter: 565 loss: 2.60452953e-06
Iter: 566 loss: 2.60737033e-06
Iter: 567 loss: 2.60392972e-06
Iter: 568 loss: 2.60264528e-06
Iter: 569 loss: 2.60066872e-06
Iter: 570 loss: 2.60064e-06
Iter: 571 loss: 2.59920603e-06
Iter: 572 loss: 2.59910075e-06
Iter: 573 loss: 2.59733315e-06
Iter: 574 loss: 2.60102934e-06
Iter: 575 loss: 2.59664648e-06
Iter: 576 loss: 2.59551325e-06
Iter: 577 loss: 2.59433159e-06
Iter: 578 loss: 2.594119e-06
Iter: 579 loss: 2.59355e-06
Iter: 580 loss: 2.59327339e-06
Iter: 581 loss: 2.59254671e-06
Iter: 582 loss: 2.59118883e-06
Iter: 583 loss: 2.61881951e-06
Iter: 584 loss: 2.59116177e-06
Iter: 585 loss: 2.58992122e-06
Iter: 586 loss: 2.59255739e-06
Iter: 587 loss: 2.58945329e-06
Iter: 588 loss: 2.58835826e-06
Iter: 589 loss: 2.58837099e-06
Iter: 590 loss: 2.5876393e-06
Iter: 591 loss: 2.58683872e-06
Iter: 592 loss: 2.58670502e-06
Iter: 593 loss: 2.58591149e-06
Iter: 594 loss: 2.58591126e-06
Iter: 595 loss: 2.58515161e-06
Iter: 596 loss: 2.58460159e-06
Iter: 597 loss: 2.58434e-06
Iter: 598 loss: 2.58313207e-06
Iter: 599 loss: 2.5861425e-06
Iter: 600 loss: 2.58269665e-06
Iter: 601 loss: 2.58144928e-06
Iter: 602 loss: 2.58096179e-06
Iter: 603 loss: 2.58027103e-06
Iter: 604 loss: 2.5788886e-06
Iter: 605 loss: 2.59224907e-06
Iter: 606 loss: 2.57882084e-06
Iter: 607 loss: 2.57768966e-06
Iter: 608 loss: 2.59147214e-06
Iter: 609 loss: 2.57767465e-06
Iter: 610 loss: 2.57708962e-06
Iter: 611 loss: 2.57587135e-06
Iter: 612 loss: 2.59318517e-06
Iter: 613 loss: 2.57580814e-06
Iter: 614 loss: 2.57532474e-06
Iter: 615 loss: 2.57518468e-06
Iter: 616 loss: 2.57449892e-06
Iter: 617 loss: 2.57298598e-06
Iter: 618 loss: 2.5936688e-06
Iter: 619 loss: 2.57292709e-06
Iter: 620 loss: 2.57148758e-06
Iter: 621 loss: 2.57694023e-06
Iter: 622 loss: 2.57116926e-06
Iter: 623 loss: 2.56991143e-06
Iter: 624 loss: 2.584188e-06
Iter: 625 loss: 2.56990461e-06
Iter: 626 loss: 2.56886597e-06
Iter: 627 loss: 2.56722615e-06
Iter: 628 loss: 2.56720182e-06
Iter: 629 loss: 2.56610474e-06
Iter: 630 loss: 2.5660861e-06
Iter: 631 loss: 2.56505746e-06
Iter: 632 loss: 2.56435351e-06
Iter: 633 loss: 2.56403337e-06
Iter: 634 loss: 2.56292128e-06
Iter: 635 loss: 2.5683853e-06
Iter: 636 loss: 2.56270232e-06
Iter: 637 loss: 2.56153498e-06
Iter: 638 loss: 2.56049566e-06
Iter: 639 loss: 2.56025533e-06
Iter: 640 loss: 2.55908708e-06
Iter: 641 loss: 2.55907798e-06
Iter: 642 loss: 2.55794157e-06
Iter: 643 loss: 2.56290014e-06
Iter: 644 loss: 2.5577026e-06
Iter: 645 loss: 2.55690475e-06
Iter: 646 loss: 2.55511736e-06
Iter: 647 loss: 2.57975807e-06
Iter: 648 loss: 2.55501504e-06
Iter: 649 loss: 2.55491932e-06
Iter: 650 loss: 2.55422538e-06
Iter: 651 loss: 2.55358145e-06
Iter: 652 loss: 2.55212422e-06
Iter: 653 loss: 2.57294323e-06
Iter: 654 loss: 2.55204532e-06
Iter: 655 loss: 2.55063446e-06
Iter: 656 loss: 2.55644045e-06
Iter: 657 loss: 2.55034047e-06
Iter: 658 loss: 2.54897873e-06
Iter: 659 loss: 2.56287785e-06
Iter: 660 loss: 2.54895986e-06
Iter: 661 loss: 2.5480972e-06
Iter: 662 loss: 2.54663314e-06
Iter: 663 loss: 2.54663018e-06
Iter: 664 loss: 2.54528868e-06
Iter: 665 loss: 2.54525503e-06
Iter: 666 loss: 2.5443951e-06
Iter: 667 loss: 2.54375186e-06
Iter: 668 loss: 2.54348652e-06
Iter: 669 loss: 2.54238967e-06
Iter: 670 loss: 2.54490715e-06
Iter: 671 loss: 2.54196971e-06
Iter: 672 loss: 2.54062161e-06
Iter: 673 loss: 2.54267161e-06
Iter: 674 loss: 2.53995313e-06
Iter: 675 loss: 2.53915209e-06
Iter: 676 loss: 2.55037412e-06
Iter: 677 loss: 2.53917324e-06
Iter: 678 loss: 2.53810799e-06
Iter: 679 loss: 2.53741723e-06
Iter: 680 loss: 2.53704843e-06
Iter: 681 loss: 2.53582039e-06
Iter: 682 loss: 2.53531493e-06
Iter: 683 loss: 2.53466965e-06
Iter: 684 loss: 2.53348048e-06
Iter: 685 loss: 2.53340136e-06
Iter: 686 loss: 2.5325437e-06
Iter: 687 loss: 2.53101598e-06
Iter: 688 loss: 2.53100688e-06
Iter: 689 loss: 2.52954214e-06
Iter: 690 loss: 2.53260805e-06
Iter: 691 loss: 2.52896143e-06
Iter: 692 loss: 2.52792779e-06
Iter: 693 loss: 2.52786117e-06
Iter: 694 loss: 2.52726932e-06
Iter: 695 loss: 2.52615746e-06
Iter: 696 loss: 2.55032865e-06
Iter: 697 loss: 2.52614041e-06
Iter: 698 loss: 2.52518089e-06
Iter: 699 loss: 2.52516293e-06
Iter: 700 loss: 2.52437053e-06
Iter: 701 loss: 2.52304926e-06
Iter: 702 loss: 2.52304517e-06
Iter: 703 loss: 2.52148311e-06
Iter: 704 loss: 2.52497603e-06
Iter: 705 loss: 2.52094151e-06
Iter: 706 loss: 2.51925098e-06
Iter: 707 loss: 2.52577047e-06
Iter: 708 loss: 2.51889242e-06
Iter: 709 loss: 2.51787219e-06
Iter: 710 loss: 2.52511632e-06
Iter: 711 loss: 2.51776237e-06
Iter: 712 loss: 2.51655274e-06
Iter: 713 loss: 2.51983192e-06
Iter: 714 loss: 2.51616439e-06
Iter: 715 loss: 2.51532674e-06
Iter: 716 loss: 2.51432061e-06
Iter: 717 loss: 2.51425e-06
Iter: 718 loss: 2.51333313e-06
Iter: 719 loss: 2.51327265e-06
Iter: 720 loss: 2.51258916e-06
Iter: 721 loss: 2.51104484e-06
Iter: 722 loss: 2.53209464e-06
Iter: 723 loss: 2.51095116e-06
Iter: 724 loss: 2.50945595e-06
Iter: 725 loss: 2.51477172e-06
Iter: 726 loss: 2.5090676e-06
Iter: 727 loss: 2.50786275e-06
Iter: 728 loss: 2.5078507e-06
Iter: 729 loss: 2.50707512e-06
Iter: 730 loss: 2.5060026e-06
Iter: 731 loss: 2.50596668e-06
Iter: 732 loss: 2.50487051e-06
Iter: 733 loss: 2.52136033e-06
Iter: 734 loss: 2.50486096e-06
Iter: 735 loss: 2.50379912e-06
Iter: 736 loss: 2.50233234e-06
Iter: 737 loss: 2.50228277e-06
Iter: 738 loss: 2.50064909e-06
Iter: 739 loss: 2.50291896e-06
Iter: 740 loss: 2.49983896e-06
Iter: 741 loss: 2.49763252e-06
Iter: 742 loss: 2.50518406e-06
Iter: 743 loss: 2.49703885e-06
Iter: 744 loss: 2.49563686e-06
Iter: 745 loss: 2.49867571e-06
Iter: 746 loss: 2.49510595e-06
Iter: 747 loss: 2.49401683e-06
Iter: 748 loss: 2.49393634e-06
Iter: 749 loss: 2.49319419e-06
Iter: 750 loss: 2.49202026e-06
Iter: 751 loss: 2.49202822e-06
Iter: 752 loss: 2.49132063e-06
Iter: 753 loss: 2.49127902e-06
Iter: 754 loss: 2.49058758e-06
Iter: 755 loss: 2.48909896e-06
Iter: 756 loss: 2.51264692e-06
Iter: 757 loss: 2.48906372e-06
Iter: 758 loss: 2.48739252e-06
Iter: 759 loss: 2.48875176e-06
Iter: 760 loss: 2.48640117e-06
Iter: 761 loss: 2.48540164e-06
Iter: 762 loss: 2.48529886e-06
Iter: 763 loss: 2.48414381e-06
Iter: 764 loss: 2.48234664e-06
Iter: 765 loss: 2.48231208e-06
Iter: 766 loss: 2.4809608e-06
Iter: 767 loss: 2.49672303e-06
Iter: 768 loss: 2.48092761e-06
Iter: 769 loss: 2.4795404e-06
Iter: 770 loss: 2.48122319e-06
Iter: 771 loss: 2.47878188e-06
Iter: 772 loss: 2.47754087e-06
Iter: 773 loss: 2.47666367e-06
Iter: 774 loss: 2.47625712e-06
Iter: 775 loss: 2.47451885e-06
Iter: 776 loss: 2.4813171e-06
Iter: 777 loss: 2.47409821e-06
Iter: 778 loss: 2.47309254e-06
Iter: 779 loss: 2.4730623e-06
Iter: 780 loss: 2.47219714e-06
Iter: 781 loss: 2.4745575e-06
Iter: 782 loss: 2.4718961e-06
Iter: 783 loss: 2.47101661e-06
Iter: 784 loss: 2.46965806e-06
Iter: 785 loss: 2.46963327e-06
Iter: 786 loss: 2.46827426e-06
Iter: 787 loss: 2.48969491e-06
Iter: 788 loss: 2.4682779e-06
Iter: 789 loss: 2.46707123e-06
Iter: 790 loss: 2.46636955e-06
Iter: 791 loss: 2.46586615e-06
Iter: 792 loss: 2.46432387e-06
Iter: 793 loss: 2.46377613e-06
Iter: 794 loss: 2.4629071e-06
Iter: 795 loss: 2.4612641e-06
Iter: 796 loss: 2.47630942e-06
Iter: 797 loss: 2.46118952e-06
Iter: 798 loss: 2.45980732e-06
Iter: 799 loss: 2.47253e-06
Iter: 800 loss: 2.45976207e-06
Iter: 801 loss: 2.45883439e-06
Iter: 802 loss: 2.45740262e-06
Iter: 803 loss: 2.45737056e-06
Iter: 804 loss: 2.45646311e-06
Iter: 805 loss: 2.45637057e-06
Iter: 806 loss: 2.45550359e-06
Iter: 807 loss: 2.45359161e-06
Iter: 808 loss: 2.48120341e-06
Iter: 809 loss: 2.45350293e-06
Iter: 810 loss: 2.4516271e-06
Iter: 811 loss: 2.45692308e-06
Iter: 812 loss: 2.4510216e-06
Iter: 813 loss: 2.44956527e-06
Iter: 814 loss: 2.44953389e-06
Iter: 815 loss: 2.44820421e-06
Iter: 816 loss: 2.44982812e-06
Iter: 817 loss: 2.447508e-06
Iter: 818 loss: 2.44628063e-06
Iter: 819 loss: 2.44699777e-06
Iter: 820 loss: 2.44550051e-06
Iter: 821 loss: 2.4442711e-06
Iter: 822 loss: 2.4562969e-06
Iter: 823 loss: 2.44422654e-06
Iter: 824 loss: 2.44306716e-06
Iter: 825 loss: 2.44230273e-06
Iter: 826 loss: 2.44188095e-06
Iter: 827 loss: 2.44043713e-06
Iter: 828 loss: 2.44001308e-06
Iter: 829 loss: 2.43915406e-06
Iter: 830 loss: 2.43741215e-06
Iter: 831 loss: 2.45330921e-06
Iter: 832 loss: 2.43733984e-06
Iter: 833 loss: 2.43600425e-06
Iter: 834 loss: 2.45074921e-06
Iter: 835 loss: 2.43599561e-06
Iter: 836 loss: 2.43531645e-06
Iter: 837 loss: 2.43439922e-06
Iter: 838 loss: 2.43435306e-06
Iter: 839 loss: 2.43338059e-06
Iter: 840 loss: 2.43338377e-06
Iter: 841 loss: 2.43257182e-06
Iter: 842 loss: 2.43075965e-06
Iter: 843 loss: 2.45577553e-06
Iter: 844 loss: 2.43064665e-06
Iter: 845 loss: 2.42874285e-06
Iter: 846 loss: 2.43513068e-06
Iter: 847 loss: 2.42821e-06
Iter: 848 loss: 2.42651845e-06
Iter: 849 loss: 2.42651049e-06
Iter: 850 loss: 2.42534111e-06
Iter: 851 loss: 2.42468377e-06
Iter: 852 loss: 2.42418901e-06
Iter: 853 loss: 2.42281953e-06
Iter: 854 loss: 2.42927172e-06
Iter: 855 loss: 2.42257829e-06
Iter: 856 loss: 2.42153e-06
Iter: 857 loss: 2.43029695e-06
Iter: 858 loss: 2.42148371e-06
Iter: 859 loss: 2.42074793e-06
Iter: 860 loss: 2.41956946e-06
Iter: 861 loss: 2.41955127e-06
Iter: 862 loss: 2.41831231e-06
Iter: 863 loss: 2.42148371e-06
Iter: 864 loss: 2.41787893e-06
Iter: 865 loss: 2.4169176e-06
Iter: 866 loss: 2.42948636e-06
Iter: 867 loss: 2.41691851e-06
Iter: 868 loss: 2.41587281e-06
Iter: 869 loss: 2.41540965e-06
Iter: 870 loss: 2.4148485e-06
Iter: 871 loss: 2.41371026e-06
Iter: 872 loss: 2.41802104e-06
Iter: 873 loss: 2.4134406e-06
Iter: 874 loss: 2.41217322e-06
Iter: 875 loss: 2.41894918e-06
Iter: 876 loss: 2.41200814e-06
Iter: 877 loss: 2.41109683e-06
Iter: 878 loss: 2.4096471e-06
Iter: 879 loss: 2.40961754e-06
Iter: 880 loss: 2.40890904e-06
Iter: 881 loss: 2.40881081e-06
Iter: 882 loss: 2.40788768e-06
Iter: 883 loss: 2.40820145e-06
Iter: 884 loss: 2.4072433e-06
Iter: 885 loss: 2.40625832e-06
Iter: 886 loss: 2.40774716e-06
Iter: 887 loss: 2.40580357e-06
Iter: 888 loss: 2.40484906e-06
Iter: 889 loss: 2.4103856e-06
Iter: 890 loss: 2.40473719e-06
Iter: 891 loss: 2.40368308e-06
Iter: 892 loss: 2.40411782e-06
Iter: 893 loss: 2.40296868e-06
Iter: 894 loss: 2.40180088e-06
Iter: 895 loss: 2.40111876e-06
Iter: 896 loss: 2.4005908e-06
Iter: 897 loss: 2.39907558e-06
Iter: 898 loss: 2.40637792e-06
Iter: 899 loss: 2.39881956e-06
Iter: 900 loss: 2.39775773e-06
Iter: 901 loss: 2.39775591e-06
Iter: 902 loss: 2.39701876e-06
Iter: 903 loss: 2.39575957e-06
Iter: 904 loss: 2.39577957e-06
Iter: 905 loss: 2.39475e-06
Iter: 906 loss: 2.39474025e-06
Iter: 907 loss: 2.39383303e-06
Iter: 908 loss: 2.39375822e-06
Iter: 909 loss: 2.3931043e-06
Iter: 910 loss: 2.39217707e-06
Iter: 911 loss: 2.39225119e-06
Iter: 912 loss: 2.39149108e-06
Iter: 913 loss: 2.39103861e-06
Iter: 914 loss: 2.39077053e-06
Iter: 915 loss: 2.39028896e-06
Iter: 916 loss: 2.3893067e-06
Iter: 917 loss: 2.4077674e-06
Iter: 918 loss: 2.38927169e-06
Iter: 919 loss: 2.38835401e-06
Iter: 920 loss: 2.3962441e-06
Iter: 921 loss: 2.38827397e-06
Iter: 922 loss: 2.38750044e-06
Iter: 923 loss: 2.39034125e-06
Iter: 924 loss: 2.38729353e-06
Iter: 925 loss: 2.38650091e-06
Iter: 926 loss: 2.38598386e-06
Iter: 927 loss: 2.38567782e-06
Iter: 928 loss: 2.3846078e-06
Iter: 929 loss: 2.38442317e-06
Iter: 930 loss: 2.38366215e-06
Iter: 931 loss: 2.3824698e-06
Iter: 932 loss: 2.40119721e-06
Iter: 933 loss: 2.38246753e-06
Iter: 934 loss: 2.38132952e-06
Iter: 935 loss: 2.38383632e-06
Iter: 936 loss: 2.38088728e-06
Iter: 937 loss: 2.3800535e-06
Iter: 938 loss: 2.38005987e-06
Iter: 939 loss: 2.37935183e-06
Iter: 940 loss: 2.37830568e-06
Iter: 941 loss: 2.39362e-06
Iter: 942 loss: 2.37832228e-06
Iter: 943 loss: 2.37764857e-06
Iter: 944 loss: 2.37676477e-06
Iter: 945 loss: 2.37671725e-06
Iter: 946 loss: 2.37596851e-06
Iter: 947 loss: 2.38503389e-06
Iter: 948 loss: 2.37597669e-06
Iter: 949 loss: 2.3750938e-06
Iter: 950 loss: 2.37674703e-06
Iter: 951 loss: 2.37477798e-06
Iter: 952 loss: 2.37404e-06
Iter: 953 loss: 2.37358677e-06
Iter: 954 loss: 2.37334143e-06
Iter: 955 loss: 2.37237828e-06
Iter: 956 loss: 2.3839707e-06
Iter: 957 loss: 2.37233144e-06
Iter: 958 loss: 2.37162249e-06
Iter: 959 loss: 2.3721509e-06
Iter: 960 loss: 2.37118502e-06
Iter: 961 loss: 2.37032509e-06
Iter: 962 loss: 2.36962615e-06
Iter: 963 loss: 2.36936035e-06
Iter: 964 loss: 2.36823598e-06
Iter: 965 loss: 2.37211407e-06
Iter: 966 loss: 2.3679122e-06
Iter: 967 loss: 2.36717779e-06
Iter: 968 loss: 2.36715846e-06
Iter: 969 loss: 2.36657411e-06
Iter: 970 loss: 2.36583719e-06
Iter: 971 loss: 2.36580331e-06
Iter: 972 loss: 2.36509095e-06
Iter: 973 loss: 2.3720745e-06
Iter: 974 loss: 2.36504638e-06
Iter: 975 loss: 2.36426422e-06
Iter: 976 loss: 2.36446726e-06
Iter: 977 loss: 2.36368e-06
Iter: 978 loss: 2.36278197e-06
Iter: 979 loss: 2.36223059e-06
Iter: 980 loss: 2.36185042e-06
Iter: 981 loss: 2.36116512e-06
Iter: 982 loss: 2.36094866e-06
Iter: 983 loss: 2.36033679e-06
Iter: 984 loss: 2.3593434e-06
Iter: 985 loss: 2.35934044e-06
Iter: 986 loss: 2.35838547e-06
Iter: 987 loss: 2.36452843e-06
Iter: 988 loss: 2.35826337e-06
Iter: 989 loss: 2.35722132e-06
Iter: 990 loss: 2.35888456e-06
Iter: 991 loss: 2.35675202e-06
Iter: 992 loss: 2.3556338e-06
Iter: 993 loss: 2.35720063e-06
Iter: 994 loss: 2.35512198e-06
Iter: 995 loss: 2.35424204e-06
Iter: 996 loss: 2.35423704e-06
Iter: 997 loss: 2.35350308e-06
Iter: 998 loss: 2.35259768e-06
Iter: 999 loss: 2.36432879e-06
Iter: 1000 loss: 2.35258017e-06
Iter: 1001 loss: 2.35167977e-06
Iter: 1002 loss: 2.35357948e-06
Iter: 1003 loss: 2.35130483e-06
Iter: 1004 loss: 2.35061589e-06
Iter: 1005 loss: 2.35072844e-06
Iter: 1006 loss: 2.35013385e-06
Iter: 1007 loss: 2.34933873e-06
Iter: 1008 loss: 2.3607945e-06
Iter: 1009 loss: 2.3493526e-06
Iter: 1010 loss: 2.34880895e-06
Iter: 1011 loss: 2.34787149e-06
Iter: 1012 loss: 2.34786626e-06
Iter: 1013 loss: 2.34718664e-06
Iter: 1014 loss: 2.34718027e-06
Iter: 1015 loss: 2.34644085e-06
Iter: 1016 loss: 2.34667732e-06
Iter: 1017 loss: 2.34591653e-06
Iter: 1018 loss: 2.34511481e-06
Iter: 1019 loss: 2.34525851e-06
Iter: 1020 loss: 2.34458616e-06
Iter: 1021 loss: 2.34364279e-06
Iter: 1022 loss: 2.35449102e-06
Iter: 1023 loss: 2.34363142e-06
Iter: 1024 loss: 2.34291497e-06
Iter: 1025 loss: 2.34268191e-06
Iter: 1026 loss: 2.34229105e-06
Iter: 1027 loss: 2.34128106e-06
Iter: 1028 loss: 2.34205345e-06
Iter: 1029 loss: 2.34064601e-06
Iter: 1030 loss: 2.3397422e-06
Iter: 1031 loss: 2.34288518e-06
Iter: 1032 loss: 2.33949982e-06
Iter: 1033 loss: 2.3388543e-06
Iter: 1034 loss: 2.33886431e-06
Iter: 1035 loss: 2.33834908e-06
Iter: 1036 loss: 2.33728701e-06
Iter: 1037 loss: 2.35320908e-06
Iter: 1038 loss: 2.3372595e-06
Iter: 1039 loss: 2.33622382e-06
Iter: 1040 loss: 2.35027255e-06
Iter: 1041 loss: 2.33623973e-06
Iter: 1042 loss: 2.33525316e-06
Iter: 1043 loss: 2.33557557e-06
Iter: 1044 loss: 2.3345583e-06
Iter: 1045 loss: 2.33352262e-06
Iter: 1046 loss: 2.33365517e-06
Iter: 1047 loss: 2.33271021e-06
Iter: 1048 loss: 2.33159972e-06
Iter: 1049 loss: 2.33156698e-06
Iter: 1050 loss: 2.3308894e-06
Iter: 1051 loss: 2.32971843e-06
Iter: 1052 loss: 2.35779e-06
Iter: 1053 loss: 2.32971706e-06
Iter: 1054 loss: 2.32892717e-06
Iter: 1055 loss: 2.32893171e-06
Iter: 1056 loss: 2.32826142e-06
Iter: 1057 loss: 2.32892216e-06
Iter: 1058 loss: 2.32787306e-06
Iter: 1059 loss: 2.32722778e-06
Iter: 1060 loss: 2.3277189e-06
Iter: 1061 loss: 2.32680554e-06
Iter: 1062 loss: 2.32593584e-06
Iter: 1063 loss: 2.32529874e-06
Iter: 1064 loss: 2.32502316e-06
Iter: 1065 loss: 2.32378648e-06
Iter: 1066 loss: 2.33996934e-06
Iter: 1067 loss: 2.3237626e-06
Iter: 1068 loss: 2.32259436e-06
Iter: 1069 loss: 2.32404818e-06
Iter: 1070 loss: 2.32192292e-06
Iter: 1071 loss: 2.32100774e-06
Iter: 1072 loss: 2.32172397e-06
Iter: 1073 loss: 2.32047023e-06
Iter: 1074 loss: 2.31912145e-06
Iter: 1075 loss: 2.32747789e-06
Iter: 1076 loss: 2.31897411e-06
Iter: 1077 loss: 2.31811828e-06
Iter: 1078 loss: 2.31775584e-06
Iter: 1079 loss: 2.3173161e-06
Iter: 1080 loss: 2.31685431e-06
Iter: 1081 loss: 2.31674539e-06
Iter: 1082 loss: 2.31616013e-06
Iter: 1083 loss: 2.3151224e-06
Iter: 1084 loss: 2.34021354e-06
Iter: 1085 loss: 2.31513218e-06
Iter: 1086 loss: 2.31422564e-06
Iter: 1087 loss: 2.31900867e-06
Iter: 1088 loss: 2.31408967e-06
Iter: 1089 loss: 2.31325089e-06
Iter: 1090 loss: 2.31833246e-06
Iter: 1091 loss: 2.31314789e-06
Iter: 1092 loss: 2.31257036e-06
Iter: 1093 loss: 2.31239324e-06
Iter: 1094 loss: 2.31203308e-06
Iter: 1095 loss: 2.31120703e-06
Iter: 1096 loss: 2.31240961e-06
Iter: 1097 loss: 2.31080526e-06
Iter: 1098 loss: 2.31002878e-06
Iter: 1099 loss: 2.31243257e-06
Iter: 1100 loss: 2.30980459e-06
Iter: 1101 loss: 2.30895739e-06
Iter: 1102 loss: 2.31665149e-06
Iter: 1103 loss: 2.30890328e-06
Iter: 1104 loss: 2.30831074e-06
Iter: 1105 loss: 2.30736418e-06
Iter: 1106 loss: 2.30737191e-06
Iter: 1107 loss: 2.30661726e-06
Iter: 1108 loss: 2.3065918e-06
Iter: 1109 loss: 2.30594628e-06
Iter: 1110 loss: 2.30477963e-06
Iter: 1111 loss: 2.30478122e-06
Iter: 1112 loss: 2.3038242e-06
Iter: 1113 loss: 2.31612762e-06
Iter: 1114 loss: 2.30383466e-06
Iter: 1115 loss: 2.30297337e-06
Iter: 1116 loss: 2.30773367e-06
Iter: 1117 loss: 2.30285968e-06
Iter: 1118 loss: 2.30241221e-06
Iter: 1119 loss: 2.30184332e-06
Iter: 1120 loss: 2.30180467e-06
Iter: 1121 loss: 2.30118917e-06
Iter: 1122 loss: 2.30119122e-06
Iter: 1123 loss: 2.30069918e-06
Iter: 1124 loss: 2.30022056e-06
Iter: 1125 loss: 2.30011892e-06
Iter: 1126 loss: 2.29927e-06
Iter: 1127 loss: 2.30018759e-06
Iter: 1128 loss: 2.29878583e-06
Iter: 1129 loss: 2.29772354e-06
Iter: 1130 loss: 2.2987906e-06
Iter: 1131 loss: 2.29711213e-06
Iter: 1132 loss: 2.29631632e-06
Iter: 1133 loss: 2.29630336e-06
Iter: 1134 loss: 2.29557736e-06
Iter: 1135 loss: 2.2948991e-06
Iter: 1136 loss: 2.2947022e-06
Iter: 1137 loss: 2.2938334e-06
Iter: 1138 loss: 2.298043e-06
Iter: 1139 loss: 2.29367333e-06
Iter: 1140 loss: 2.29263287e-06
Iter: 1141 loss: 2.2952604e-06
Iter: 1142 loss: 2.29230091e-06
Iter: 1143 loss: 2.29157286e-06
Iter: 1144 loss: 2.29177476e-06
Iter: 1145 loss: 2.29109833e-06
Iter: 1146 loss: 2.29043235e-06
Iter: 1147 loss: 2.29040847e-06
Iter: 1148 loss: 2.28994531e-06
Iter: 1149 loss: 2.28889712e-06
Iter: 1150 loss: 2.30524483e-06
Iter: 1151 loss: 2.28889303e-06
Iter: 1152 loss: 2.28839e-06
Iter: 1153 loss: 2.28835643e-06
Iter: 1154 loss: 2.28786189e-06
Iter: 1155 loss: 2.28768477e-06
Iter: 1156 loss: 2.28745967e-06
Iter: 1157 loss: 2.28674139e-06
Iter: 1158 loss: 2.28680869e-06
Iter: 1159 loss: 2.28620888e-06
Iter: 1160 loss: 2.28515705e-06
Iter: 1161 loss: 2.28628323e-06
Iter: 1162 loss: 2.28457475e-06
Iter: 1163 loss: 2.28364979e-06
Iter: 1164 loss: 2.29500938e-06
Iter: 1165 loss: 2.28360886e-06
Iter: 1166 loss: 2.28278395e-06
Iter: 1167 loss: 2.28466752e-06
Iter: 1168 loss: 2.28248086e-06
Iter: 1169 loss: 2.28173758e-06
Iter: 1170 loss: 2.2816912e-06
Iter: 1171 loss: 2.281153e-06
Iter: 1172 loss: 2.28027238e-06
Iter: 1173 loss: 2.29172201e-06
Iter: 1174 loss: 2.28026965e-06
Iter: 1175 loss: 2.27969235e-06
Iter: 1176 loss: 2.27883584e-06
Iter: 1177 loss: 2.27884129e-06
Iter: 1178 loss: 2.2785207e-06
Iter: 1179 loss: 2.27833289e-06
Iter: 1180 loss: 2.27790179e-06
Iter: 1181 loss: 2.27721603e-06
Iter: 1182 loss: 2.27719033e-06
Iter: 1183 loss: 2.27651208e-06
Iter: 1184 loss: 2.27869805e-06
Iter: 1185 loss: 2.27631176e-06
Iter: 1186 loss: 2.27546207e-06
Iter: 1187 loss: 2.27883584e-06
Iter: 1188 loss: 2.27530109e-06
Iter: 1189 loss: 2.27461055e-06
Iter: 1190 loss: 2.27423425e-06
Iter: 1191 loss: 2.27393912e-06
Iter: 1192 loss: 2.27289456e-06
Iter: 1193 loss: 2.27485111e-06
Iter: 1194 loss: 2.27240707e-06
Iter: 1195 loss: 2.2714687e-06
Iter: 1196 loss: 2.27601572e-06
Iter: 1197 loss: 2.27131454e-06
Iter: 1198 loss: 2.27047735e-06
Iter: 1199 loss: 2.27816827e-06
Iter: 1200 loss: 2.27044643e-06
Iter: 1201 loss: 2.26986276e-06
Iter: 1202 loss: 2.2695574e-06
Iter: 1203 loss: 2.26927591e-06
Iter: 1204 loss: 2.26873362e-06
Iter: 1205 loss: 2.27698729e-06
Iter: 1206 loss: 2.26874818e-06
Iter: 1207 loss: 2.26822522e-06
Iter: 1208 loss: 2.26762586e-06
Iter: 1209 loss: 2.26757948e-06
Iter: 1210 loss: 2.26698967e-06
Iter: 1211 loss: 2.2738709e-06
Iter: 1212 loss: 2.26696852e-06
Iter: 1213 loss: 2.26634484e-06
Iter: 1214 loss: 2.2671943e-06
Iter: 1215 loss: 2.26598058e-06
Iter: 1216 loss: 2.26553539e-06
Iter: 1217 loss: 2.26534894e-06
Iter: 1218 loss: 2.26505e-06
Iter: 1219 loss: 2.26435282e-06
Iter: 1220 loss: 2.27191231e-06
Iter: 1221 loss: 2.26431257e-06
Iter: 1222 loss: 2.26372185e-06
Iter: 1223 loss: 2.26299289e-06
Iter: 1224 loss: 2.26291559e-06
Iter: 1225 loss: 2.2619738e-06
Iter: 1226 loss: 2.26537077e-06
Iter: 1227 loss: 2.26170937e-06
Iter: 1228 loss: 2.26092379e-06
Iter: 1229 loss: 2.26251905e-06
Iter: 1230 loss: 2.26058319e-06
Iter: 1231 loss: 2.26015163e-06
Iter: 1232 loss: 2.26011707e-06
Iter: 1233 loss: 2.25973e-06
Iter: 1234 loss: 2.25932968e-06
Iter: 1235 loss: 2.25925851e-06
Iter: 1236 loss: 2.25876e-06
Iter: 1237 loss: 2.262105e-06
Iter: 1238 loss: 2.25870394e-06
Iter: 1239 loss: 2.25814074e-06
Iter: 1240 loss: 2.2587476e-06
Iter: 1241 loss: 2.25787562e-06
Iter: 1242 loss: 2.25734811e-06
Iter: 1243 loss: 2.25774261e-06
Iter: 1244 loss: 2.25698341e-06
Iter: 1245 loss: 2.25629447e-06
Iter: 1246 loss: 2.26449038e-06
Iter: 1247 loss: 2.2562815e-06
Iter: 1248 loss: 2.25585973e-06
Iter: 1249 loss: 2.25502072e-06
Iter: 1250 loss: 2.26949624e-06
Iter: 1251 loss: 2.25500298e-06
Iter: 1252 loss: 2.25452709e-06
Iter: 1253 loss: 2.25444819e-06
Iter: 1254 loss: 2.25401777e-06
Iter: 1255 loss: 2.2541185e-06
Iter: 1256 loss: 2.25367785e-06
Iter: 1257 loss: 2.2532422e-06
Iter: 1258 loss: 2.25363056e-06
Iter: 1259 loss: 2.2529714e-06
Iter: 1260 loss: 2.25238387e-06
Iter: 1261 loss: 2.25277813e-06
Iter: 1262 loss: 2.25198482e-06
Iter: 1263 loss: 2.25139183e-06
Iter: 1264 loss: 2.25619624e-06
Iter: 1265 loss: 2.25137819e-06
Iter: 1266 loss: 2.25069903e-06
Iter: 1267 loss: 2.2526674e-06
Iter: 1268 loss: 2.2505028e-06
Iter: 1269 loss: 2.25003532e-06
Iter: 1270 loss: 2.25044141e-06
Iter: 1271 loss: 2.24976361e-06
Iter: 1272 loss: 2.24919e-06
Iter: 1273 loss: 2.25324902e-06
Iter: 1274 loss: 2.24911719e-06
Iter: 1275 loss: 2.24870791e-06
Iter: 1276 loss: 2.24839141e-06
Iter: 1277 loss: 2.2482327e-06
Iter: 1278 loss: 2.24786845e-06
Iter: 1279 loss: 2.2478057e-06
Iter: 1280 loss: 2.24750511e-06
Iter: 1281 loss: 2.24676523e-06
Iter: 1282 loss: 2.25644521e-06
Iter: 1283 loss: 2.24672613e-06
Iter: 1284 loss: 2.24605947e-06
Iter: 1285 loss: 2.25013378e-06
Iter: 1286 loss: 2.24592782e-06
Iter: 1287 loss: 2.24512814e-06
Iter: 1288 loss: 2.24762039e-06
Iter: 1289 loss: 2.244896e-06
Iter: 1290 loss: 2.24429823e-06
Iter: 1291 loss: 2.24458086e-06
Iter: 1292 loss: 2.24390874e-06
Iter: 1293 loss: 2.24330051e-06
Iter: 1294 loss: 2.24503174e-06
Iter: 1295 loss: 2.24315613e-06
Iter: 1296 loss: 2.24254291e-06
Iter: 1297 loss: 2.2427148e-06
Iter: 1298 loss: 2.24210225e-06
Iter: 1299 loss: 2.24146061e-06
Iter: 1300 loss: 2.24144515e-06
Iter: 1301 loss: 2.24099585e-06
Iter: 1302 loss: 2.24026508e-06
Iter: 1303 loss: 2.24025507e-06
Iter: 1304 loss: 2.23949701e-06
Iter: 1305 loss: 2.25002782e-06
Iter: 1306 loss: 2.23949723e-06
Iter: 1307 loss: 2.23890811e-06
Iter: 1308 loss: 2.23850316e-06
Iter: 1309 loss: 2.23827237e-06
Iter: 1310 loss: 2.23777761e-06
Iter: 1311 loss: 2.23776237e-06
Iter: 1312 loss: 2.23726602e-06
Iter: 1313 loss: 2.23681286e-06
Iter: 1314 loss: 2.23669031e-06
Iter: 1315 loss: 2.23611733e-06
Iter: 1316 loss: 2.23752363e-06
Iter: 1317 loss: 2.23595089e-06
Iter: 1318 loss: 2.23542384e-06
Iter: 1319 loss: 2.24070982e-06
Iter: 1320 loss: 2.23545112e-06
Iter: 1321 loss: 2.23513348e-06
Iter: 1322 loss: 2.23474854e-06
Iter: 1323 loss: 2.23470215e-06
Iter: 1324 loss: 2.23407596e-06
Iter: 1325 loss: 2.23477491e-06
Iter: 1326 loss: 2.2337515e-06
Iter: 1327 loss: 2.23292818e-06
Iter: 1328 loss: 2.23422421e-06
Iter: 1329 loss: 2.23254165e-06
Iter: 1330 loss: 2.2318809e-06
Iter: 1331 loss: 2.23188954e-06
Iter: 1332 loss: 2.23119196e-06
Iter: 1333 loss: 2.23062125e-06
Iter: 1334 loss: 2.23045663e-06
Iter: 1335 loss: 2.22974268e-06
Iter: 1336 loss: 2.23740449e-06
Iter: 1337 loss: 2.22974177e-06
Iter: 1338 loss: 2.22918879e-06
Iter: 1339 loss: 2.22990138e-06
Iter: 1340 loss: 2.22885046e-06
Iter: 1341 loss: 2.22839549e-06
Iter: 1342 loss: 2.23075017e-06
Iter: 1343 loss: 2.22830931e-06
Iter: 1344 loss: 2.22777794e-06
Iter: 1345 loss: 2.22884364e-06
Iter: 1346 loss: 2.22754852e-06
Iter: 1347 loss: 2.22713197e-06
Iter: 1348 loss: 2.2268564e-06
Iter: 1349 loss: 2.22670178e-06
Iter: 1350 loss: 2.22619155e-06
Iter: 1351 loss: 2.23370853e-06
Iter: 1352 loss: 2.22618041e-06
Iter: 1353 loss: 2.22575818e-06
Iter: 1354 loss: 2.22523045e-06
Iter: 1355 loss: 2.22520475e-06
Iter: 1356 loss: 2.22447625e-06
Iter: 1357 loss: 2.22633435e-06
Iter: 1358 loss: 2.22421249e-06
Iter: 1359 loss: 2.2235497e-06
Iter: 1360 loss: 2.22505787e-06
Iter: 1361 loss: 2.22328026e-06
Iter: 1362 loss: 2.2226e-06
Iter: 1363 loss: 2.22605786e-06
Iter: 1364 loss: 2.22247877e-06
Iter: 1365 loss: 2.22168865e-06
Iter: 1366 loss: 2.22531617e-06
Iter: 1367 loss: 2.2215736e-06
Iter: 1368 loss: 2.22109293e-06
Iter: 1369 loss: 2.22115114e-06
Iter: 1370 loss: 2.22074391e-06
Iter: 1371 loss: 2.21998835e-06
Iter: 1372 loss: 2.22379731e-06
Iter: 1373 loss: 2.21982282e-06
Iter: 1374 loss: 2.21930782e-06
Iter: 1375 loss: 2.21984237e-06
Iter: 1376 loss: 2.21900086e-06
Iter: 1377 loss: 2.21838582e-06
Iter: 1378 loss: 2.22532481e-06
Iter: 1379 loss: 2.21836899e-06
Iter: 1380 loss: 2.21799246e-06
Iter: 1381 loss: 2.21746473e-06
Iter: 1382 loss: 2.21745881e-06
Iter: 1383 loss: 2.21702021e-06
Iter: 1384 loss: 2.21699793e-06
Iter: 1385 loss: 2.21661094e-06
Iter: 1386 loss: 2.21631285e-06
Iter: 1387 loss: 2.21617029e-06
Iter: 1388 loss: 2.21559139e-06
Iter: 1389 loss: 2.21616665e-06
Iter: 1390 loss: 2.21525443e-06
Iter: 1391 loss: 2.21451501e-06
Iter: 1392 loss: 2.21577511e-06
Iter: 1393 loss: 2.21419327e-06
Iter: 1394 loss: 2.21338769e-06
Iter: 1395 loss: 2.21659911e-06
Iter: 1396 loss: 2.21321784e-06
Iter: 1397 loss: 2.21259461e-06
Iter: 1398 loss: 2.22192193e-06
Iter: 1399 loss: 2.21260461e-06
Iter: 1400 loss: 2.21220739e-06
Iter: 1401 loss: 2.21180744e-06
Iter: 1402 loss: 2.21174037e-06
Iter: 1403 loss: 2.21119444e-06
Iter: 1404 loss: 2.21821642e-06
Iter: 1405 loss: 2.21120627e-06
Iter: 1406 loss: 2.21084701e-06
Iter: 1407 loss: 2.21044411e-06
Iter: 1408 loss: 2.21033952e-06
Iter: 1409 loss: 2.20999345e-06
Iter: 1410 loss: 2.20995207e-06
Iter: 1411 loss: 2.2096674e-06
Iter: 1412 loss: 2.20919401e-06
Iter: 1413 loss: 2.22075505e-06
Iter: 1414 loss: 2.2091815e-06
Iter: 1415 loss: 2.20873972e-06
Iter: 1416 loss: 2.21338519e-06
Iter: 1417 loss: 2.20871948e-06
Iter: 1418 loss: 2.20833908e-06
Iter: 1419 loss: 2.20836523e-06
Iter: 1420 loss: 2.20802031e-06
Iter: 1421 loss: 2.20757e-06
Iter: 1422 loss: 2.20791435e-06
Iter: 1423 loss: 2.20728725e-06
Iter: 1424 loss: 2.20663651e-06
Iter: 1425 loss: 2.20724223e-06
Iter: 1426 loss: 2.20628749e-06
Iter: 1427 loss: 2.20544098e-06
Iter: 1428 loss: 2.20798688e-06
Iter: 1429 loss: 2.20520724e-06
Iter: 1430 loss: 2.20469929e-06
Iter: 1431 loss: 2.20466791e-06
Iter: 1432 loss: 2.20426023e-06
Iter: 1433 loss: 2.20389302e-06
Iter: 1434 loss: 2.20379343e-06
Iter: 1435 loss: 2.20339757e-06
Iter: 1436 loss: 2.2033978e-06
Iter: 1437 loss: 2.20309948e-06
Iter: 1438 loss: 2.20298443e-06
Iter: 1439 loss: 2.20281e-06
Iter: 1440 loss: 2.20252196e-06
Iter: 1441 loss: 2.20251832e-06
Iter: 1442 loss: 2.20224729e-06
Iter: 1443 loss: 2.20174752e-06
Iter: 1444 loss: 2.21393134e-06
Iter: 1445 loss: 2.20175207e-06
Iter: 1446 loss: 2.20129891e-06
Iter: 1447 loss: 2.20489846e-06
Iter: 1448 loss: 2.20122661e-06
Iter: 1449 loss: 2.20078141e-06
Iter: 1450 loss: 2.20088486e-06
Iter: 1451 loss: 2.20043739e-06
Iter: 1452 loss: 2.19984327e-06
Iter: 1453 loss: 2.19973936e-06
Iter: 1454 loss: 2.19932326e-06
Iter: 1455 loss: 2.19850517e-06
Iter: 1456 loss: 2.20274228e-06
Iter: 1457 loss: 2.19838171e-06
Iter: 1458 loss: 2.19781487e-06
Iter: 1459 loss: 2.20002676e-06
Iter: 1460 loss: 2.19765411e-06
Iter: 1461 loss: 2.19728463e-06
Iter: 1462 loss: 2.20136144e-06
Iter: 1463 loss: 2.19723961e-06
Iter: 1464 loss: 2.19685e-06
Iter: 1465 loss: 2.19694289e-06
Iter: 1466 loss: 2.19654748e-06
Iter: 1467 loss: 2.19617e-06
Iter: 1468 loss: 2.19804588e-06
Iter: 1469 loss: 2.19609979e-06
Iter: 1470 loss: 2.19565095e-06
Iter: 1471 loss: 2.19585536e-06
Iter: 1472 loss: 2.19536605e-06
Iter: 1473 loss: 2.19496042e-06
Iter: 1474 loss: 2.19919821e-06
Iter: 1475 loss: 2.19495541e-06
Iter: 1476 loss: 2.19456979e-06
Iter: 1477 loss: 2.19445883e-06
Iter: 1478 loss: 2.1941969e-06
Iter: 1479 loss: 2.19384719e-06
Iter: 1480 loss: 2.19559161e-06
Iter: 1481 loss: 2.19375238e-06
Iter: 1482 loss: 2.19335129e-06
Iter: 1483 loss: 2.1940225e-06
Iter: 1484 loss: 2.19314529e-06
Iter: 1485 loss: 2.19271305e-06
Iter: 1486 loss: 2.19252934e-06
Iter: 1487 loss: 2.19230014e-06
Iter: 1488 loss: 2.1917192e-06
Iter: 1489 loss: 2.19398862e-06
Iter: 1490 loss: 2.19160074e-06
Iter: 1491 loss: 2.19100593e-06
Iter: 1492 loss: 2.19171307e-06
Iter: 1493 loss: 2.19065578e-06
Iter: 1494 loss: 2.19010781e-06
Iter: 1495 loss: 2.19607841e-06
Iter: 1496 loss: 2.19007552e-06
Iter: 1497 loss: 2.18959644e-06
Iter: 1498 loss: 2.19174672e-06
Iter: 1499 loss: 2.18953301e-06
Iter: 1500 loss: 2.18921491e-06
Iter: 1501 loss: 2.18934565e-06
Iter: 1502 loss: 2.18901232e-06
Iter: 1503 loss: 2.18856258e-06
Iter: 1504 loss: 2.19089475e-06
Iter: 1505 loss: 2.18846935e-06
Iter: 1506 loss: 2.1882388e-06
Iter: 1507 loss: 2.18889613e-06
Iter: 1508 loss: 2.18815285e-06
Iter: 1509 loss: 2.18775267e-06
Iter: 1510 loss: 2.18860418e-06
Iter: 1511 loss: 2.18763535e-06
Iter: 1512 loss: 2.18734772e-06
Iter: 1513 loss: 2.18718401e-06
Iter: 1514 loss: 2.18701939e-06
Iter: 1515 loss: 2.18640389e-06
Iter: 1516 loss: 2.18860896e-06
Iter: 1517 loss: 2.18623882e-06
Iter: 1518 loss: 2.18567629e-06
Iter: 1519 loss: 2.18492414e-06
Iter: 1520 loss: 2.18486935e-06
Iter: 1521 loss: 2.18384707e-06
Iter: 1522 loss: 2.18810987e-06
Iter: 1523 loss: 2.18364403e-06
Iter: 1524 loss: 2.18288187e-06
Iter: 1525 loss: 2.18672267e-06
Iter: 1526 loss: 2.18274386e-06
Iter: 1527 loss: 2.18230821e-06
Iter: 1528 loss: 2.18546529e-06
Iter: 1529 loss: 2.18226069e-06
Iter: 1530 loss: 2.18184096e-06
Iter: 1531 loss: 2.18435093e-06
Iter: 1532 loss: 2.18179821e-06
Iter: 1533 loss: 2.18147807e-06
Iter: 1534 loss: 2.18121295e-06
Iter: 1535 loss: 2.18111245e-06
Iter: 1536 loss: 2.18064e-06
Iter: 1537 loss: 2.18542186e-06
Iter: 1538 loss: 2.18063315e-06
Iter: 1539 loss: 2.18028481e-06
Iter: 1540 loss: 2.18011064e-06
Iter: 1541 loss: 2.17994307e-06
Iter: 1542 loss: 2.179386e-06
Iter: 1543 loss: 2.18489072e-06
Iter: 1544 loss: 2.17935349e-06
Iter: 1545 loss: 2.17902152e-06
Iter: 1546 loss: 2.17849765e-06
Iter: 1547 loss: 2.17846332e-06
Iter: 1548 loss: 2.17788897e-06
Iter: 1549 loss: 2.18522837e-06
Iter: 1550 loss: 2.17786351e-06
Iter: 1551 loss: 2.17744309e-06
Iter: 1552 loss: 2.17698607e-06
Iter: 1553 loss: 2.17694014e-06
Iter: 1554 loss: 2.17629668e-06
Iter: 1555 loss: 2.17778552e-06
Iter: 1556 loss: 2.17607135e-06
Iter: 1557 loss: 2.17543607e-06
Iter: 1558 loss: 2.1774606e-06
Iter: 1559 loss: 2.17525212e-06
Iter: 1560 loss: 2.17468323e-06
Iter: 1561 loss: 2.17641218e-06
Iter: 1562 loss: 2.17448769e-06
Iter: 1563 loss: 2.17401839e-06
Iter: 1564 loss: 2.18023024e-06
Iter: 1565 loss: 2.17404886e-06
Iter: 1566 loss: 2.17367142e-06
Iter: 1567 loss: 2.17335037e-06
Iter: 1568 loss: 2.17324373e-06
Iter: 1569 loss: 2.17273396e-06
Iter: 1570 loss: 2.17718571e-06
Iter: 1571 loss: 2.17273191e-06
Iter: 1572 loss: 2.17227898e-06
Iter: 1573 loss: 2.17196043e-06
Iter: 1574 loss: 2.17178149e-06
Iter: 1575 loss: 2.171284e-06
Iter: 1576 loss: 2.17129445e-06
Iter: 1577 loss: 2.17087882e-06
Iter: 1578 loss: 2.17014735e-06
Iter: 1579 loss: 2.18534296e-06
Iter: 1580 loss: 2.17014144e-06
Iter: 1581 loss: 2.16963372e-06
Iter: 1582 loss: 2.16962553e-06
Iter: 1583 loss: 2.16925832e-06
Iter: 1584 loss: 2.16871899e-06
Iter: 1585 loss: 2.16869012e-06
Iter: 1586 loss: 2.16805438e-06
Iter: 1587 loss: 2.16900253e-06
Iter: 1588 loss: 2.16776562e-06
Iter: 1589 loss: 2.1671292e-06
Iter: 1590 loss: 2.17001025e-06
Iter: 1591 loss: 2.16700255e-06
Iter: 1592 loss: 2.16650687e-06
Iter: 1593 loss: 2.16769331e-06
Iter: 1594 loss: 2.16631315e-06
Iter: 1595 loss: 2.16585795e-06
Iter: 1596 loss: 2.17009892e-06
Iter: 1597 loss: 2.16581179e-06
Iter: 1598 loss: 2.16538456e-06
Iter: 1599 loss: 2.16549938e-06
Iter: 1600 loss: 2.16509261e-06
Iter: 1601 loss: 2.1645692e-06
Iter: 1602 loss: 2.16685817e-06
Iter: 1603 loss: 2.16448052e-06
Iter: 1604 loss: 2.1639969e-06
Iter: 1605 loss: 2.1646465e-06
Iter: 1606 loss: 2.16371927e-06
Iter: 1607 loss: 2.16333183e-06
Iter: 1608 loss: 2.16756371e-06
Iter: 1609 loss: 2.1633e-06
Iter: 1610 loss: 2.16286753e-06
Iter: 1611 loss: 2.16240255e-06
Iter: 1612 loss: 2.16232479e-06
Iter: 1613 loss: 2.16182821e-06
Iter: 1614 loss: 2.16591502e-06
Iter: 1615 loss: 2.16180024e-06
Iter: 1616 loss: 2.16126136e-06
Iter: 1617 loss: 2.16100352e-06
Iter: 1618 loss: 2.16076705e-06
Iter: 1619 loss: 2.16015314e-06
Iter: 1620 loss: 2.16111539e-06
Iter: 1621 loss: 2.159833e-06
Iter: 1622 loss: 2.15925456e-06
Iter: 1623 loss: 2.16147873e-06
Iter: 1624 loss: 2.1591211e-06
Iter: 1625 loss: 2.15858859e-06
Iter: 1626 loss: 2.15976661e-06
Iter: 1627 loss: 2.15837736e-06
Iter: 1628 loss: 2.15791079e-06
Iter: 1629 loss: 2.16311673e-06
Iter: 1630 loss: 2.15790624e-06
Iter: 1631 loss: 2.15747013e-06
Iter: 1632 loss: 2.15814e-06
Iter: 1633 loss: 2.15725595e-06
Iter: 1634 loss: 2.1568369e-06
Iter: 1635 loss: 2.15722457e-06
Iter: 1636 loss: 2.15657565e-06
Iter: 1637 loss: 2.15589534e-06
Iter: 1638 loss: 2.15772593e-06
Iter: 1639 loss: 2.15566706e-06
Iter: 1640 loss: 2.15503928e-06
Iter: 1641 loss: 2.15755e-06
Iter: 1642 loss: 2.15492537e-06
Iter: 1643 loss: 2.15421255e-06
Iter: 1644 loss: 2.15544082e-06
Iter: 1645 loss: 2.15390196e-06
Iter: 1646 loss: 2.1534297e-06
Iter: 1647 loss: 2.15426257e-06
Iter: 1648 loss: 2.1532046e-06
Iter: 1649 loss: 2.15256296e-06
Iter: 1650 loss: 2.15502769e-06
Iter: 1651 loss: 2.1524e-06
Iter: 1652 loss: 2.15200362e-06
Iter: 1653 loss: 2.15163845e-06
Iter: 1654 loss: 2.15151658e-06
Iter: 1655 loss: 2.15090904e-06
Iter: 1656 loss: 2.15283967e-06
Iter: 1657 loss: 2.15074533e-06
Iter: 1658 loss: 2.15011323e-06
Iter: 1659 loss: 2.1515973e-06
Iter: 1660 loss: 2.14988449e-06
Iter: 1661 loss: 2.14925967e-06
Iter: 1662 loss: 2.15335785e-06
Iter: 1663 loss: 2.14922761e-06
Iter: 1664 loss: 2.14859392e-06
Iter: 1665 loss: 2.15023488e-06
Iter: 1666 loss: 2.14840315e-06
Iter: 1667 loss: 2.14781e-06
Iter: 1668 loss: 2.14857255e-06
Iter: 1669 loss: 2.14751617e-06
Iter: 1670 loss: 2.14694091e-06
Iter: 1671 loss: 2.15148248e-06
Iter: 1672 loss: 2.14691931e-06
Iter: 1673 loss: 2.14654415e-06
Iter: 1674 loss: 2.14709803e-06
Iter: 1675 loss: 2.14634565e-06
Iter: 1676 loss: 2.14585816e-06
Iter: 1677 loss: 2.14833176e-06
Iter: 1678 loss: 2.1457713e-06
Iter: 1679 loss: 2.1454091e-06
Iter: 1680 loss: 2.14500346e-06
Iter: 1681 loss: 2.14494821e-06
Iter: 1682 loss: 2.14433862e-06
Iter: 1683 loss: 2.15155478e-06
Iter: 1684 loss: 2.14432566e-06
Iter: 1685 loss: 2.14397824e-06
Iter: 1686 loss: 2.14339343e-06
Iter: 1687 loss: 2.14339343e-06
Iter: 1688 loss: 2.14277588e-06
Iter: 1689 loss: 2.14568399e-06
Iter: 1690 loss: 2.14265083e-06
Iter: 1691 loss: 2.14211832e-06
Iter: 1692 loss: 2.14392253e-06
Iter: 1693 loss: 2.1419628e-06
Iter: 1694 loss: 2.14149168e-06
Iter: 1695 loss: 2.14351576e-06
Iter: 1696 loss: 2.1413739e-06
Iter: 1697 loss: 2.1408905e-06
Iter: 1698 loss: 2.14342708e-06
Iter: 1699 loss: 2.14082343e-06
Iter: 1700 loss: 2.14042529e-06
Iter: 1701 loss: 2.1406322e-06
Iter: 1702 loss: 2.14016018e-06
Iter: 1703 loss: 2.13964e-06
Iter: 1704 loss: 2.1423707e-06
Iter: 1705 loss: 2.13954581e-06
Iter: 1706 loss: 2.13909516e-06
Iter: 1707 loss: 2.1394444e-06
Iter: 1708 loss: 2.13882504e-06
Iter: 1709 loss: 2.1383114e-06
Iter: 1710 loss: 2.14445231e-06
Iter: 1711 loss: 2.1383089e-06
Iter: 1712 loss: 2.13799285e-06
Iter: 1713 loss: 2.13756357e-06
Iter: 1714 loss: 2.13752583e-06
Iter: 1715 loss: 2.13715703e-06
Iter: 1716 loss: 2.13713747e-06
Iter: 1717 loss: 2.13683143e-06
Iter: 1718 loss: 2.13627663e-06
Iter: 1719 loss: 2.14703596e-06
Iter: 1720 loss: 2.13624912e-06
Iter: 1721 loss: 2.13560475e-06
Iter: 1722 loss: 2.13773978e-06
Iter: 1723 loss: 2.13543e-06
Iter: 1724 loss: 2.13478324e-06
Iter: 1725 loss: 2.13642761e-06
Iter: 1726 loss: 2.1345586e-06
Iter: 1727 loss: 2.13384124e-06
Iter: 1728 loss: 2.13660724e-06
Iter: 1729 loss: 2.13371868e-06
Iter: 1730 loss: 2.13301018e-06
Iter: 1731 loss: 2.13925796e-06
Iter: 1732 loss: 2.13301064e-06
Iter: 1733 loss: 2.1324945e-06
Iter: 1734 loss: 2.13258386e-06
Iter: 1735 loss: 2.13213571e-06
Iter: 1736 loss: 2.13161775e-06
Iter: 1737 loss: 2.13589101e-06
Iter: 1738 loss: 2.13155977e-06
Iter: 1739 loss: 2.13115527e-06
Iter: 1740 loss: 2.13189446e-06
Iter: 1741 loss: 2.13100293e-06
Iter: 1742 loss: 2.1306837e-06
Iter: 1743 loss: 2.13480075e-06
Iter: 1744 loss: 2.13067597e-06
Iter: 1745 loss: 2.13044814e-06
Iter: 1746 loss: 2.13003909e-06
Iter: 1747 loss: 2.1300466e-06
Iter: 1748 loss: 2.1296737e-06
Iter: 1749 loss: 2.1343576e-06
Iter: 1750 loss: 2.12967461e-06
Iter: 1751 loss: 2.12930627e-06
Iter: 1752 loss: 2.12877217e-06
Iter: 1753 loss: 2.12877467e-06
Iter: 1754 loss: 2.12822488e-06
Iter: 1755 loss: 2.12904069e-06
Iter: 1756 loss: 2.12793202e-06
Iter: 1757 loss: 2.12724444e-06
Iter: 1758 loss: 2.12928717e-06
Iter: 1759 loss: 2.12701548e-06
Iter: 1760 loss: 2.12633222e-06
Iter: 1761 loss: 2.128088e-06
Iter: 1762 loss: 2.12608302e-06
Iter: 1763 loss: 2.12557734e-06
Iter: 1764 loss: 2.1255596e-06
Iter: 1765 loss: 2.12522082e-06
Iter: 1766 loss: 2.12511168e-06
Iter: 1767 loss: 2.12490431e-06
Iter: 1768 loss: 2.12448185e-06
Iter: 1769 loss: 2.12684313e-06
Iter: 1770 loss: 2.12439295e-06
Iter: 1771 loss: 2.12399186e-06
Iter: 1772 loss: 2.12480154e-06
Iter: 1773 loss: 2.12383475e-06
Iter: 1774 loss: 2.12351483e-06
Iter: 1775 loss: 2.12672694e-06
Iter: 1776 loss: 2.12350915e-06
Iter: 1777 loss: 2.12320242e-06
Iter: 1778 loss: 2.12286727e-06
Iter: 1779 loss: 2.12284635e-06
Iter: 1780 loss: 2.12243594e-06
Iter: 1781 loss: 2.12527266e-06
Iter: 1782 loss: 2.12242071e-06
Iter: 1783 loss: 2.12198461e-06
Iter: 1784 loss: 2.12189548e-06
Iter: 1785 loss: 2.12163604e-06
Iter: 1786 loss: 2.12115901e-06
Iter: 1787 loss: 2.12086411e-06
Iter: 1788 loss: 2.12067425e-06
Iter: 1789 loss: 2.11989254e-06
Iter: 1790 loss: 2.12302734e-06
Iter: 1791 loss: 2.119702e-06
Iter: 1792 loss: 2.11905262e-06
Iter: 1793 loss: 2.12148257e-06
Iter: 1794 loss: 2.11887937e-06
Iter: 1795 loss: 2.11845054e-06
Iter: 1796 loss: 2.12464192e-06
Iter: 1797 loss: 2.11844781e-06
Iter: 1798 loss: 2.1180233e-06
Iter: 1799 loss: 2.11822044e-06
Iter: 1800 loss: 2.11773295e-06
Iter: 1801 loss: 2.11733686e-06
Iter: 1802 loss: 2.11934434e-06
Iter: 1803 loss: 2.11727934e-06
Iter: 1804 loss: 2.11691463e-06
Iter: 1805 loss: 2.11794304e-06
Iter: 1806 loss: 2.1168039e-06
Iter: 1807 loss: 2.11649353e-06
Iter: 1808 loss: 2.11804763e-06
Iter: 1809 loss: 2.11645897e-06
Iter: 1810 loss: 2.11611041e-06
Iter: 1811 loss: 2.1161195e-06
Iter: 1812 loss: 2.11581664e-06
Iter: 1813 loss: 2.11547558e-06
Iter: 1814 loss: 2.1164044e-06
Iter: 1815 loss: 2.1153628e-06
Iter: 1816 loss: 2.11490556e-06
Iter: 1817 loss: 2.11637234e-06
Iter: 1818 loss: 2.11480142e-06
Iter: 1819 loss: 2.11448969e-06
Iter: 1820 loss: 2.11392239e-06
Iter: 1821 loss: 2.11391762e-06
Iter: 1822 loss: 2.11323095e-06
Iter: 1823 loss: 2.11633414e-06
Iter: 1824 loss: 2.1130852e-06
Iter: 1825 loss: 2.11242491e-06
Iter: 1826 loss: 2.1138087e-06
Iter: 1827 loss: 2.11215865e-06
Iter: 1828 loss: 2.11150495e-06
Iter: 1829 loss: 2.11540328e-06
Iter: 1830 loss: 2.11141059e-06
Iter: 1831 loss: 2.11085126e-06
Iter: 1832 loss: 2.11544852e-06
Iter: 1833 loss: 2.11079214e-06
Iter: 1834 loss: 2.11048473e-06
Iter: 1835 loss: 2.11070687e-06
Iter: 1836 loss: 2.11029919e-06
Iter: 1837 loss: 2.1098358e-06
Iter: 1838 loss: 2.11127826e-06
Iter: 1839 loss: 2.10973394e-06
Iter: 1840 loss: 2.10933013e-06
Iter: 1841 loss: 2.11058068e-06
Iter: 1842 loss: 2.10919984e-06
Iter: 1843 loss: 2.10875714e-06
Iter: 1844 loss: 2.11008592e-06
Iter: 1845 loss: 2.10858889e-06
Iter: 1846 loss: 2.1082169e-06
Iter: 1847 loss: 2.10781673e-06
Iter: 1848 loss: 2.10773987e-06
Iter: 1849 loss: 2.10700023e-06
Iter: 1850 loss: 2.1130968e-06
Iter: 1851 loss: 2.10697385e-06
Iter: 1852 loss: 2.1064202e-06
Iter: 1853 loss: 2.10545204e-06
Iter: 1854 loss: 2.12863574e-06
Iter: 1855 loss: 2.10544954e-06
Iter: 1856 loss: 2.10448343e-06
Iter: 1857 loss: 2.1088938e-06
Iter: 1858 loss: 2.10431472e-06
Iter: 1859 loss: 2.10350186e-06
Iter: 1860 loss: 2.10742519e-06
Iter: 1861 loss: 2.10336952e-06
Iter: 1862 loss: 2.10279472e-06
Iter: 1863 loss: 2.10491226e-06
Iter: 1864 loss: 2.10263352e-06
Iter: 1865 loss: 2.10221651e-06
Iter: 1866 loss: 2.10221515e-06
Iter: 1867 loss: 2.10192479e-06
Iter: 1868 loss: 2.10162125e-06
Iter: 1869 loss: 2.10156213e-06
Iter: 1870 loss: 2.10107237e-06
Iter: 1871 loss: 2.10441794e-06
Iter: 1872 loss: 2.10102644e-06
Iter: 1873 loss: 2.10057988e-06
Iter: 1874 loss: 2.10101962e-06
Iter: 1875 loss: 2.10034887e-06
Iter: 1876 loss: 2.0997727e-06
Iter: 1877 loss: 2.10291364e-06
Iter: 1878 loss: 2.0997029e-06
Iter: 1879 loss: 2.09927339e-06
Iter: 1880 loss: 2.09869131e-06
Iter: 1881 loss: 2.09863538e-06
Iter: 1882 loss: 2.09810196e-06
Iter: 1883 loss: 2.09811196e-06
Iter: 1884 loss: 2.09769178e-06
Iter: 1885 loss: 2.09707241e-06
Iter: 1886 loss: 2.09704535e-06
Iter: 1887 loss: 2.09631526e-06
Iter: 1888 loss: 2.09689051e-06
Iter: 1889 loss: 2.09588688e-06
Iter: 1890 loss: 2.09498876e-06
Iter: 1891 loss: 2.09945392e-06
Iter: 1892 loss: 2.09482141e-06
Iter: 1893 loss: 2.09407972e-06
Iter: 1894 loss: 2.09660448e-06
Iter: 1895 loss: 2.09385416e-06
Iter: 1896 loss: 2.09334576e-06
Iter: 1897 loss: 2.10118151e-06
Iter: 1898 loss: 2.09334326e-06
Iter: 1899 loss: 2.09293421e-06
Iter: 1900 loss: 2.09282757e-06
Iter: 1901 loss: 2.0925313e-06
Iter: 1902 loss: 2.09209065e-06
Iter: 1903 loss: 2.09586483e-06
Iter: 1904 loss: 2.09203586e-06
Iter: 1905 loss: 2.09158702e-06
Iter: 1906 loss: 2.09166592e-06
Iter: 1907 loss: 2.09127029e-06
Iter: 1908 loss: 2.09072869e-06
Iter: 1909 loss: 2.09579343e-06
Iter: 1910 loss: 2.09070868e-06
Iter: 1911 loss: 2.09025302e-06
Iter: 1912 loss: 2.08958181e-06
Iter: 1913 loss: 2.08956521e-06
Iter: 1914 loss: 2.08887445e-06
Iter: 1915 loss: 2.09567452e-06
Iter: 1916 loss: 2.08885194e-06
Iter: 1917 loss: 2.08813685e-06
Iter: 1918 loss: 2.08784923e-06
Iter: 1919 loss: 2.08747e-06
Iter: 1920 loss: 2.08669735e-06
Iter: 1921 loss: 2.08691654e-06
Iter: 1922 loss: 2.08611209e-06
Iter: 1923 loss: 2.08534766e-06
Iter: 1924 loss: 2.09091604e-06
Iter: 1925 loss: 2.08527354e-06
Iter: 1926 loss: 2.08471215e-06
Iter: 1927 loss: 2.08662777e-06
Iter: 1928 loss: 2.08454321e-06
Iter: 1929 loss: 2.08407027e-06
Iter: 1930 loss: 2.08728397e-06
Iter: 1931 loss: 2.08405527e-06
Iter: 1932 loss: 2.0835098e-06
Iter: 1933 loss: 2.08475944e-06
Iter: 1934 loss: 2.08333768e-06
Iter: 1935 loss: 2.08295728e-06
Iter: 1936 loss: 2.08353549e-06
Iter: 1937 loss: 2.0827556e-06
Iter: 1938 loss: 2.082126e-06
Iter: 1939 loss: 2.08326378e-06
Iter: 1940 loss: 2.0818693e-06
Iter: 1941 loss: 2.08132474e-06
Iter: 1942 loss: 2.08546953e-06
Iter: 1943 loss: 2.08128813e-06
Iter: 1944 loss: 2.08073152e-06
Iter: 1945 loss: 2.08022857e-06
Iter: 1946 loss: 2.08007418e-06
Iter: 1947 loss: 2.07934499e-06
Iter: 1948 loss: 2.082219e-06
Iter: 1949 loss: 2.07914854e-06
Iter: 1950 loss: 2.07833409e-06
Iter: 1951 loss: 2.08141364e-06
Iter: 1952 loss: 2.07812673e-06
Iter: 1953 loss: 2.07756511e-06
Iter: 1954 loss: 2.07686821e-06
Iter: 1955 loss: 2.07682979e-06
Iter: 1956 loss: 2.07603375e-06
Iter: 1957 loss: 2.07968401e-06
Iter: 1958 loss: 2.07586936e-06
Iter: 1959 loss: 2.075167e-06
Iter: 1960 loss: 2.07740368e-06
Iter: 1961 loss: 2.07495418e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6
+ date
Mon Nov  2 10:27:25 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 1.6 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c06c0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04f7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c06188c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c056e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c056e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03eab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03ea1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c041d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c041d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0330048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03308c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0396d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01b6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0498620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04bc598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04b6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c04b6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0482ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0487d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0482268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01fb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c01fbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c028af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c025e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0098c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0098a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c0013378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647e9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c03768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1c02f7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb1647b4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0003102277
test_loss: 0.00030856306
train_loss: 0.00010696893
test_loss: 0.00010296803
train_loss: 5.2176518e-05
test_loss: 5.5098833e-05
train_loss: 3.42468e-05
test_loss: 3.5562865e-05
train_loss: 2.4483e-05
test_loss: 2.5425008e-05
train_loss: 1.8542747e-05
test_loss: 1.9851323e-05
train_loss: 1.655989e-05
test_loss: 1.6219059e-05
train_loss: 1.3383284e-05
test_loss: 1.3703258e-05
train_loss: 1.142823e-05
test_loss: 1.1906918e-05
train_loss: 1.0442903e-05
test_loss: 1.0811771e-05
train_loss: 9.119788e-06
test_loss: 9.707376e-06
train_loss: 8.3646555e-06
test_loss: 9.0008025e-06
train_loss: 7.937836e-06
test_loss: 8.287357e-06
train_loss: 7.466826e-06
test_loss: 7.796926e-06
train_loss: 7.350961e-06
test_loss: 7.4859067e-06
train_loss: 6.5535387e-06
test_loss: 7.0123306e-06
train_loss: 6.3755106e-06
test_loss: 6.667846e-06
train_loss: 6.175044e-06
test_loss: 6.433241e-06
train_loss: 5.843612e-06
test_loss: 6.195071e-06
train_loss: 5.628615e-06
test_loss: 5.9760014e-06
train_loss: 5.4197535e-06
test_loss: 5.768735e-06
train_loss: 5.2629994e-06
test_loss: 5.58827e-06
train_loss: 5.1320912e-06
test_loss: 5.445861e-06
train_loss: 5.091033e-06
test_loss: 5.306619e-06
train_loss: 5.0066906e-06
test_loss: 5.2894256e-06
train_loss: 4.6057457e-06
test_loss: 5.0790177e-06
train_loss: 4.8179386e-06
test_loss: 5.002538e-06
train_loss: 4.4831518e-06
test_loss: 4.9071955e-06
train_loss: 4.6867863e-06
test_loss: 4.8003144e-06
train_loss: 4.4230337e-06
test_loss: 4.7096414e-06
train_loss: 4.130893e-06
test_loss: 4.6311507e-06
train_loss: 4.388346e-06
test_loss: 4.5277693e-06
train_loss: 4.4608782e-06
test_loss: 4.505902e-06
train_loss: 3.956608e-06
test_loss: 4.456349e-06
train_loss: 4.0571986e-06
test_loss: 4.3710916e-06
train_loss: 4.181527e-06
test_loss: 4.2984175e-06
train_loss: 4.207542e-06
test_loss: 4.2723514e-06
train_loss: 3.9278452e-06
test_loss: 4.2390107e-06
train_loss: 3.8112132e-06
test_loss: 4.182871e-06
train_loss: 3.8525436e-06
test_loss: 4.180134e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi1.6/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi1.6/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe662301d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500aca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500bed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500f6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500f6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500f62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe65002a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500288c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe650028400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe65000c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe6500112f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe650011488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ff95c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ffb0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ff47f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fee2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fef0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64ff3d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe65000c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fec4048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fec4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fec4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fdadc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd5a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd5a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd5a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fdfad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fdfa7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fd57158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fce52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fcfe7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fc39ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fc50840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fce51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fc50bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe64fcc7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.89588649e-06
Iter: 2 loss: 3.85133808e-06
Iter: 3 loss: 3.85125395e-06
Iter: 4 loss: 3.83411498e-06
Iter: 5 loss: 3.8339781e-06
Iter: 6 loss: 3.82798953e-06
Iter: 7 loss: 3.82279177e-06
Iter: 8 loss: 3.82117696e-06
Iter: 9 loss: 3.81312634e-06
Iter: 10 loss: 3.86385773e-06
Iter: 11 loss: 3.81221162e-06
Iter: 12 loss: 3.80834e-06
Iter: 13 loss: 3.82286771e-06
Iter: 14 loss: 3.80738516e-06
Iter: 15 loss: 3.80409665e-06
Iter: 16 loss: 3.81270934e-06
Iter: 17 loss: 3.80292408e-06
Iter: 18 loss: 3.80055712e-06
Iter: 19 loss: 3.82350208e-06
Iter: 20 loss: 3.80044617e-06
Iter: 21 loss: 3.79909943e-06
Iter: 22 loss: 3.79738412e-06
Iter: 23 loss: 3.79726634e-06
Iter: 24 loss: 3.79546145e-06
Iter: 25 loss: 3.79544099e-06
Iter: 26 loss: 3.79414223e-06
Iter: 27 loss: 3.79271614e-06
Iter: 28 loss: 3.7924965e-06
Iter: 29 loss: 3.79081962e-06
Iter: 30 loss: 3.7935954e-06
Iter: 31 loss: 3.79001472e-06
Iter: 32 loss: 3.78859659e-06
Iter: 33 loss: 3.79505059e-06
Iter: 34 loss: 3.78832942e-06
Iter: 35 loss: 3.78725326e-06
Iter: 36 loss: 3.79182643e-06
Iter: 37 loss: 3.78698519e-06
Iter: 38 loss: 3.78596314e-06
Iter: 39 loss: 3.78575828e-06
Iter: 40 loss: 3.78504956e-06
Iter: 41 loss: 3.78483332e-06
Iter: 42 loss: 3.78415712e-06
Iter: 43 loss: 3.7838131e-06
Iter: 44 loss: 3.78266213e-06
Iter: 45 loss: 3.78473896e-06
Iter: 46 loss: 3.7819168e-06
Iter: 47 loss: 3.78073241e-06
Iter: 48 loss: 3.78071536e-06
Iter: 49 loss: 3.77967331e-06
Iter: 50 loss: 3.7810355e-06
Iter: 51 loss: 3.77908327e-06
Iter: 52 loss: 3.778272e-06
Iter: 53 loss: 3.78055211e-06
Iter: 54 loss: 3.7780344e-06
Iter: 55 loss: 3.77690048e-06
Iter: 56 loss: 3.77943707e-06
Iter: 57 loss: 3.776521e-06
Iter: 58 loss: 3.77580614e-06
Iter: 59 loss: 3.77859851e-06
Iter: 60 loss: 3.77565721e-06
Iter: 61 loss: 3.7749187e-06
Iter: 62 loss: 3.77577521e-06
Iter: 63 loss: 3.77454421e-06
Iter: 64 loss: 3.77358037e-06
Iter: 65 loss: 3.77518177e-06
Iter: 66 loss: 3.77314132e-06
Iter: 67 loss: 3.77215929e-06
Iter: 68 loss: 3.77562219e-06
Iter: 69 loss: 3.77191304e-06
Iter: 70 loss: 3.77110473e-06
Iter: 71 loss: 3.76973685e-06
Iter: 72 loss: 3.76973367e-06
Iter: 73 loss: 3.76820708e-06
Iter: 74 loss: 3.77394463e-06
Iter: 75 loss: 3.76779622e-06
Iter: 76 loss: 3.7665925e-06
Iter: 77 loss: 3.77916081e-06
Iter: 78 loss: 3.76656e-06
Iter: 79 loss: 3.7664131e-06
Iter: 80 loss: 3.76619573e-06
Iter: 81 loss: 3.76576736e-06
Iter: 82 loss: 3.76459093e-06
Iter: 83 loss: 3.77054698e-06
Iter: 84 loss: 3.76420439e-06
Iter: 85 loss: 3.76329422e-06
Iter: 86 loss: 3.76461685e-06
Iter: 87 loss: 3.76284652e-06
Iter: 88 loss: 3.76161233e-06
Iter: 89 loss: 3.7752302e-06
Iter: 90 loss: 3.76161233e-06
Iter: 91 loss: 3.76084427e-06
Iter: 92 loss: 3.76071557e-06
Iter: 93 loss: 3.76015851e-06
Iter: 94 loss: 3.75930495e-06
Iter: 95 loss: 3.76573212e-06
Iter: 96 loss: 3.75924401e-06
Iter: 97 loss: 3.75828267e-06
Iter: 98 loss: 3.75811487e-06
Iter: 99 loss: 3.75746458e-06
Iter: 100 loss: 3.75666468e-06
Iter: 101 loss: 3.76029811e-06
Iter: 102 loss: 3.75648801e-06
Iter: 103 loss: 3.75536456e-06
Iter: 104 loss: 3.75628497e-06
Iter: 105 loss: 3.75470518e-06
Iter: 106 loss: 3.75390096e-06
Iter: 107 loss: 3.75584113e-06
Iter: 108 loss: 3.75359491e-06
Iter: 109 loss: 3.75265245e-06
Iter: 110 loss: 3.75321179e-06
Iter: 111 loss: 3.75203945e-06
Iter: 112 loss: 3.75053742e-06
Iter: 113 loss: 3.75409e-06
Iter: 114 loss: 3.75000491e-06
Iter: 115 loss: 3.74872616e-06
Iter: 116 loss: 3.75248578e-06
Iter: 117 loss: 3.74835554e-06
Iter: 118 loss: 3.74690535e-06
Iter: 119 loss: 3.76735989e-06
Iter: 120 loss: 3.74693309e-06
Iter: 121 loss: 3.74649835e-06
Iter: 122 loss: 3.7453874e-06
Iter: 123 loss: 3.75276068e-06
Iter: 124 loss: 3.74510569e-06
Iter: 125 loss: 3.74364618e-06
Iter: 126 loss: 3.74759702e-06
Iter: 127 loss: 3.74317119e-06
Iter: 128 loss: 3.74223532e-06
Iter: 129 loss: 3.74216347e-06
Iter: 130 loss: 3.74147703e-06
Iter: 131 loss: 3.73997818e-06
Iter: 132 loss: 3.76347089e-06
Iter: 133 loss: 3.73993134e-06
Iter: 134 loss: 3.73880312e-06
Iter: 135 loss: 3.73879766e-06
Iter: 136 loss: 3.73778562e-06
Iter: 137 loss: 3.73742478e-06
Iter: 138 loss: 3.73686203e-06
Iter: 139 loss: 3.73560169e-06
Iter: 140 loss: 3.7374657e-06
Iter: 141 loss: 3.73496869e-06
Iter: 142 loss: 3.7337054e-06
Iter: 143 loss: 3.75027912e-06
Iter: 144 loss: 3.73372404e-06
Iter: 145 loss: 3.73284479e-06
Iter: 146 loss: 3.73101466e-06
Iter: 147 loss: 3.75766194e-06
Iter: 148 loss: 3.73092325e-06
Iter: 149 loss: 3.72939621e-06
Iter: 150 loss: 3.7383661e-06
Iter: 151 loss: 3.72922568e-06
Iter: 152 loss: 3.72760974e-06
Iter: 153 loss: 3.73269677e-06
Iter: 154 loss: 3.72712793e-06
Iter: 155 loss: 3.72545765e-06
Iter: 156 loss: 3.73051353e-06
Iter: 157 loss: 3.72497925e-06
Iter: 158 loss: 3.72399973e-06
Iter: 159 loss: 3.72387649e-06
Iter: 160 loss: 3.72322802e-06
Iter: 161 loss: 3.72125055e-06
Iter: 162 loss: 3.72629165e-06
Iter: 163 loss: 3.72013028e-06
Iter: 164 loss: 3.71791202e-06
Iter: 165 loss: 3.72600152e-06
Iter: 166 loss: 3.71736064e-06
Iter: 167 loss: 3.71494207e-06
Iter: 168 loss: 3.72354771e-06
Iter: 169 loss: 3.71433953e-06
Iter: 170 loss: 3.71364649e-06
Iter: 171 loss: 3.71338774e-06
Iter: 172 loss: 3.71251144e-06
Iter: 173 loss: 3.71056854e-06
Iter: 174 loss: 3.7387083e-06
Iter: 175 loss: 3.71045689e-06
Iter: 176 loss: 3.70921316e-06
Iter: 177 loss: 3.70918178e-06
Iter: 178 loss: 3.70795647e-06
Iter: 179 loss: 3.70717953e-06
Iter: 180 loss: 3.70674229e-06
Iter: 181 loss: 3.70513703e-06
Iter: 182 loss: 3.70886301e-06
Iter: 183 loss: 3.70452244e-06
Iter: 184 loss: 3.70320595e-06
Iter: 185 loss: 3.7195091e-06
Iter: 186 loss: 3.70314683e-06
Iter: 187 loss: 3.70199746e-06
Iter: 188 loss: 3.69927398e-06
Iter: 189 loss: 3.73146031e-06
Iter: 190 loss: 3.69904024e-06
Iter: 191 loss: 3.69712802e-06
Iter: 192 loss: 3.71982105e-06
Iter: 193 loss: 3.6971262e-06
Iter: 194 loss: 3.69581312e-06
Iter: 195 loss: 3.6958163e-06
Iter: 196 loss: 3.69486565e-06
Iter: 197 loss: 3.69431018e-06
Iter: 198 loss: 3.69396344e-06
Iter: 199 loss: 3.69279655e-06
Iter: 200 loss: 3.69191753e-06
Iter: 201 loss: 3.69154895e-06
Iter: 202 loss: 3.68948827e-06
Iter: 203 loss: 3.69092595e-06
Iter: 204 loss: 3.68817291e-06
Iter: 205 loss: 3.68561723e-06
Iter: 206 loss: 3.68805104e-06
Iter: 207 loss: 3.68415772e-06
Iter: 208 loss: 3.68284759e-06
Iter: 209 loss: 3.68230394e-06
Iter: 210 loss: 3.68118162e-06
Iter: 211 loss: 3.67967414e-06
Iter: 212 loss: 3.67959865e-06
Iter: 213 loss: 3.67808207e-06
Iter: 214 loss: 3.6951385e-06
Iter: 215 loss: 3.67810708e-06
Iter: 216 loss: 3.67665689e-06
Iter: 217 loss: 3.67627536e-06
Iter: 218 loss: 3.67536222e-06
Iter: 219 loss: 3.67360485e-06
Iter: 220 loss: 3.6745555e-06
Iter: 221 loss: 3.67248981e-06
Iter: 222 loss: 3.6702545e-06
Iter: 223 loss: 3.69651434e-06
Iter: 224 loss: 3.67024563e-06
Iter: 225 loss: 3.669e-06
Iter: 226 loss: 3.66688982e-06
Iter: 227 loss: 3.66689414e-06
Iter: 228 loss: 3.66665336e-06
Iter: 229 loss: 3.66574704e-06
Iter: 230 loss: 3.66462473e-06
Iter: 231 loss: 3.66278255e-06
Iter: 232 loss: 3.66280574e-06
Iter: 233 loss: 3.66129325e-06
Iter: 234 loss: 3.66454924e-06
Iter: 235 loss: 3.66066388e-06
Iter: 236 loss: 3.65867754e-06
Iter: 237 loss: 3.65923756e-06
Iter: 238 loss: 3.657251e-06
Iter: 239 loss: 3.65509209e-06
Iter: 240 loss: 3.65669666e-06
Iter: 241 loss: 3.65376104e-06
Iter: 242 loss: 3.65139886e-06
Iter: 243 loss: 3.65136907e-06
Iter: 244 loss: 3.64996731e-06
Iter: 245 loss: 3.64864263e-06
Iter: 246 loss: 3.64835068e-06
Iter: 247 loss: 3.64631046e-06
Iter: 248 loss: 3.65825736e-06
Iter: 249 loss: 3.64605512e-06
Iter: 250 loss: 3.64377979e-06
Iter: 251 loss: 3.64633115e-06
Iter: 252 loss: 3.6425065e-06
Iter: 253 loss: 3.6406841e-06
Iter: 254 loss: 3.63965432e-06
Iter: 255 loss: 3.63887102e-06
Iter: 256 loss: 3.63630716e-06
Iter: 257 loss: 3.67145685e-06
Iter: 258 loss: 3.63631898e-06
Iter: 259 loss: 3.63419167e-06
Iter: 260 loss: 3.63430172e-06
Iter: 261 loss: 3.63247e-06
Iter: 262 loss: 3.63130266e-06
Iter: 263 loss: 3.63128743e-06
Iter: 264 loss: 3.62974879e-06
Iter: 265 loss: 3.6272163e-06
Iter: 266 loss: 3.62722e-06
Iter: 267 loss: 3.62524816e-06
Iter: 268 loss: 3.62568881e-06
Iter: 269 loss: 3.62381843e-06
Iter: 270 loss: 3.62113428e-06
Iter: 271 loss: 3.63279901e-06
Iter: 272 loss: 3.62062701e-06
Iter: 273 loss: 3.61832326e-06
Iter: 274 loss: 3.62663855e-06
Iter: 275 loss: 3.61773823e-06
Iter: 276 loss: 3.615781e-06
Iter: 277 loss: 3.6191268e-06
Iter: 278 loss: 3.61492903e-06
Iter: 279 loss: 3.61278171e-06
Iter: 280 loss: 3.63944127e-06
Iter: 281 loss: 3.61276761e-06
Iter: 282 loss: 3.61155367e-06
Iter: 283 loss: 3.60854801e-06
Iter: 284 loss: 3.64099515e-06
Iter: 285 loss: 3.60823014e-06
Iter: 286 loss: 3.6070046e-06
Iter: 287 loss: 3.60634886e-06
Iter: 288 loss: 3.60514468e-06
Iter: 289 loss: 3.60281206e-06
Iter: 290 loss: 3.64741982e-06
Iter: 291 loss: 3.6027709e-06
Iter: 292 loss: 3.60043941e-06
Iter: 293 loss: 3.6149836e-06
Iter: 294 loss: 3.60013246e-06
Iter: 295 loss: 3.5982016e-06
Iter: 296 loss: 3.61606e-06
Iter: 297 loss: 3.59815181e-06
Iter: 298 loss: 3.59681735e-06
Iter: 299 loss: 3.59461387e-06
Iter: 300 loss: 3.59462115e-06
Iter: 301 loss: 3.59417618e-06
Iter: 302 loss: 3.59312753e-06
Iter: 303 loss: 3.59248497e-06
Iter: 304 loss: 3.59032583e-06
Iter: 305 loss: 3.59627688e-06
Iter: 306 loss: 3.58913599e-06
Iter: 307 loss: 3.58581792e-06
Iter: 308 loss: 3.59362139e-06
Iter: 309 loss: 3.58459056e-06
Iter: 310 loss: 3.58192028e-06
Iter: 311 loss: 3.60714853e-06
Iter: 312 loss: 3.58182751e-06
Iter: 313 loss: 3.579652e-06
Iter: 314 loss: 3.58376724e-06
Iter: 315 loss: 3.57871522e-06
Iter: 316 loss: 3.57686031e-06
Iter: 317 loss: 3.58304146e-06
Iter: 318 loss: 3.57637396e-06
Iter: 319 loss: 3.57423414e-06
Iter: 320 loss: 3.58790589e-06
Iter: 321 loss: 3.5739954e-06
Iter: 322 loss: 3.57214e-06
Iter: 323 loss: 3.56957753e-06
Iter: 324 loss: 3.56944884e-06
Iter: 325 loss: 3.56705823e-06
Iter: 326 loss: 3.60206e-06
Iter: 327 loss: 3.56711598e-06
Iter: 328 loss: 3.56470809e-06
Iter: 329 loss: 3.56286318e-06
Iter: 330 loss: 3.56215537e-06
Iter: 331 loss: 3.55954489e-06
Iter: 332 loss: 3.56626038e-06
Iter: 333 loss: 3.55868451e-06
Iter: 334 loss: 3.55547786e-06
Iter: 335 loss: 3.57490808e-06
Iter: 336 loss: 3.55511884e-06
Iter: 337 loss: 3.55322413e-06
Iter: 338 loss: 3.55509565e-06
Iter: 339 loss: 3.55212683e-06
Iter: 340 loss: 3.55048292e-06
Iter: 341 loss: 3.55044631e-06
Iter: 342 loss: 3.54938493e-06
Iter: 343 loss: 3.54634312e-06
Iter: 344 loss: 3.56390274e-06
Iter: 345 loss: 3.54555618e-06
Iter: 346 loss: 3.54242343e-06
Iter: 347 loss: 3.54269923e-06
Iter: 348 loss: 3.54000258e-06
Iter: 349 loss: 3.53582186e-06
Iter: 350 loss: 3.57747831e-06
Iter: 351 loss: 3.53561245e-06
Iter: 352 loss: 3.53215955e-06
Iter: 353 loss: 3.54121721e-06
Iter: 354 loss: 3.53101768e-06
Iter: 355 loss: 3.52841676e-06
Iter: 356 loss: 3.55090128e-06
Iter: 357 loss: 3.52828647e-06
Iter: 358 loss: 3.52579627e-06
Iter: 359 loss: 3.53112773e-06
Iter: 360 loss: 3.5248795e-06
Iter: 361 loss: 3.52285178e-06
Iter: 362 loss: 3.52077313e-06
Iter: 363 loss: 3.52039706e-06
Iter: 364 loss: 3.51731887e-06
Iter: 365 loss: 3.51732729e-06
Iter: 366 loss: 3.5153912e-06
Iter: 367 loss: 3.51409358e-06
Iter: 368 loss: 3.51337894e-06
Iter: 369 loss: 3.51090739e-06
Iter: 370 loss: 3.52043116e-06
Iter: 371 loss: 3.51031895e-06
Iter: 372 loss: 3.50743335e-06
Iter: 373 loss: 3.51878748e-06
Iter: 374 loss: 3.50682467e-06
Iter: 375 loss: 3.50476785e-06
Iter: 376 loss: 3.50910523e-06
Iter: 377 loss: 3.50396203e-06
Iter: 378 loss: 3.50054188e-06
Iter: 379 loss: 3.50630398e-06
Iter: 380 loss: 3.49898687e-06
Iter: 381 loss: 3.49733659e-06
Iter: 382 loss: 3.49508673e-06
Iter: 383 loss: 3.49498714e-06
Iter: 384 loss: 3.49174229e-06
Iter: 385 loss: 3.49506126e-06
Iter: 386 loss: 3.48993126e-06
Iter: 387 loss: 3.4869181e-06
Iter: 388 loss: 3.51811036e-06
Iter: 389 loss: 3.48683125e-06
Iter: 390 loss: 3.48427648e-06
Iter: 391 loss: 3.48883623e-06
Iter: 392 loss: 3.48318599e-06
Iter: 393 loss: 3.48114145e-06
Iter: 394 loss: 3.50771688e-06
Iter: 395 loss: 3.48113326e-06
Iter: 396 loss: 3.47922128e-06
Iter: 397 loss: 3.47702348e-06
Iter: 398 loss: 3.47673767e-06
Iter: 399 loss: 3.4739669e-06
Iter: 400 loss: 3.48433241e-06
Iter: 401 loss: 3.47327932e-06
Iter: 402 loss: 3.46985962e-06
Iter: 403 loss: 3.48113e-06
Iter: 404 loss: 3.4689208e-06
Iter: 405 loss: 3.46623233e-06
Iter: 406 loss: 3.46361185e-06
Iter: 407 loss: 3.46307615e-06
Iter: 408 loss: 3.4605373e-06
Iter: 409 loss: 3.4603936e-06
Iter: 410 loss: 3.45852277e-06
Iter: 411 loss: 3.45751e-06
Iter: 412 loss: 3.45666103e-06
Iter: 413 loss: 3.45517628e-06
Iter: 414 loss: 3.45509898e-06
Iter: 415 loss: 3.45335684e-06
Iter: 416 loss: 3.45192348e-06
Iter: 417 loss: 3.45142826e-06
Iter: 418 loss: 3.44944283e-06
Iter: 419 loss: 3.44516434e-06
Iter: 420 loss: 3.51089193e-06
Iter: 421 loss: 3.44503064e-06
Iter: 422 loss: 3.44095747e-06
Iter: 423 loss: 3.48050708e-06
Iter: 424 loss: 3.44081627e-06
Iter: 425 loss: 3.43705187e-06
Iter: 426 loss: 3.44227601e-06
Iter: 427 loss: 3.43516604e-06
Iter: 428 loss: 3.43161514e-06
Iter: 429 loss: 3.46731213e-06
Iter: 430 loss: 3.43152442e-06
Iter: 431 loss: 3.42959152e-06
Iter: 432 loss: 3.44773184e-06
Iter: 433 loss: 3.42952444e-06
Iter: 434 loss: 3.42786097e-06
Iter: 435 loss: 3.42557041e-06
Iter: 436 loss: 3.42543262e-06
Iter: 437 loss: 3.42328053e-06
Iter: 438 loss: 3.43622423e-06
Iter: 439 loss: 3.42303315e-06
Iter: 440 loss: 3.42052226e-06
Iter: 441 loss: 3.42568319e-06
Iter: 442 loss: 3.41947e-06
Iter: 443 loss: 3.41724149e-06
Iter: 444 loss: 3.4170539e-06
Iter: 445 loss: 3.41539453e-06
Iter: 446 loss: 3.41296277e-06
Iter: 447 loss: 3.44636055e-06
Iter: 448 loss: 3.41295231e-06
Iter: 449 loss: 3.4107336e-06
Iter: 450 loss: 3.41119767e-06
Iter: 451 loss: 3.40907809e-06
Iter: 452 loss: 3.40688962e-06
Iter: 453 loss: 3.40685506e-06
Iter: 454 loss: 3.40562679e-06
Iter: 455 loss: 3.40258885e-06
Iter: 456 loss: 3.43436909e-06
Iter: 457 loss: 3.4022537e-06
Iter: 458 loss: 3.39937446e-06
Iter: 459 loss: 3.40458678e-06
Iter: 460 loss: 3.39809912e-06
Iter: 461 loss: 3.39510507e-06
Iter: 462 loss: 3.40928273e-06
Iter: 463 loss: 3.39454823e-06
Iter: 464 loss: 3.39170242e-06
Iter: 465 loss: 3.40136944e-06
Iter: 466 loss: 3.3909655e-06
Iter: 467 loss: 3.38831569e-06
Iter: 468 loss: 3.39554981e-06
Iter: 469 loss: 3.38746804e-06
Iter: 470 loss: 3.3846743e-06
Iter: 471 loss: 3.40633619e-06
Iter: 472 loss: 3.3844849e-06
Iter: 473 loss: 3.38226437e-06
Iter: 474 loss: 3.38154405e-06
Iter: 475 loss: 3.38026257e-06
Iter: 476 loss: 3.37827373e-06
Iter: 477 loss: 3.40040106e-06
Iter: 478 loss: 3.37821893e-06
Iter: 479 loss: 3.37613392e-06
Iter: 480 loss: 3.3734857e-06
Iter: 481 loss: 3.3733063e-06
Iter: 482 loss: 3.37037454e-06
Iter: 483 loss: 3.38658901e-06
Iter: 484 loss: 3.36997846e-06
Iter: 485 loss: 3.36672656e-06
Iter: 486 loss: 3.37642587e-06
Iter: 487 loss: 3.36576568e-06
Iter: 488 loss: 3.36387689e-06
Iter: 489 loss: 3.39196185e-06
Iter: 490 loss: 3.36389121e-06
Iter: 491 loss: 3.36206585e-06
Iter: 492 loss: 3.3609665e-06
Iter: 493 loss: 3.36020958e-06
Iter: 494 loss: 3.35809955e-06
Iter: 495 loss: 3.35361074e-06
Iter: 496 loss: 3.42678686e-06
Iter: 497 loss: 3.3534584e-06
Iter: 498 loss: 3.3497713e-06
Iter: 499 loss: 3.34977608e-06
Iter: 500 loss: 3.34668698e-06
Iter: 501 loss: 3.34751303e-06
Iter: 502 loss: 3.3444735e-06
Iter: 503 loss: 3.3410829e-06
Iter: 504 loss: 3.37428e-06
Iter: 505 loss: 3.34094966e-06
Iter: 506 loss: 3.33845446e-06
Iter: 507 loss: 3.35217e-06
Iter: 508 loss: 3.3381375e-06
Iter: 509 loss: 3.33590947e-06
Iter: 510 loss: 3.3340998e-06
Iter: 511 loss: 3.33350727e-06
Iter: 512 loss: 3.33056596e-06
Iter: 513 loss: 3.35967025e-06
Iter: 514 loss: 3.33048274e-06
Iter: 515 loss: 3.32805166e-06
Iter: 516 loss: 3.32973968e-06
Iter: 517 loss: 3.32649506e-06
Iter: 518 loss: 3.32405898e-06
Iter: 519 loss: 3.32671698e-06
Iter: 520 loss: 3.32274567e-06
Iter: 521 loss: 3.3197266e-06
Iter: 522 loss: 3.34859442e-06
Iter: 523 loss: 3.31958768e-06
Iter: 524 loss: 3.31831552e-06
Iter: 525 loss: 3.3347992e-06
Iter: 526 loss: 3.3183419e-06
Iter: 527 loss: 3.31702427e-06
Iter: 528 loss: 3.31375327e-06
Iter: 529 loss: 3.34126639e-06
Iter: 530 loss: 3.31315e-06
Iter: 531 loss: 3.30961939e-06
Iter: 532 loss: 3.31505294e-06
Iter: 533 loss: 3.30788816e-06
Iter: 534 loss: 3.30397233e-06
Iter: 535 loss: 3.31666661e-06
Iter: 536 loss: 3.30286548e-06
Iter: 537 loss: 3.29901013e-06
Iter: 538 loss: 3.31651017e-06
Iter: 539 loss: 3.29831073e-06
Iter: 540 loss: 3.29490513e-06
Iter: 541 loss: 3.3082315e-06
Iter: 542 loss: 3.29416321e-06
Iter: 543 loss: 3.29107206e-06
Iter: 544 loss: 3.3137876e-06
Iter: 545 loss: 3.29084287e-06
Iter: 546 loss: 3.2886569e-06
Iter: 547 loss: 3.28742317e-06
Iter: 548 loss: 3.28647729e-06
Iter: 549 loss: 3.28319402e-06
Iter: 550 loss: 3.30188686e-06
Iter: 551 loss: 3.2827561e-06
Iter: 552 loss: 3.2794178e-06
Iter: 553 loss: 3.2813432e-06
Iter: 554 loss: 3.27727366e-06
Iter: 555 loss: 3.27386374e-06
Iter: 556 loss: 3.28033957e-06
Iter: 557 loss: 3.27241014e-06
Iter: 558 loss: 3.26806162e-06
Iter: 559 loss: 3.29702084e-06
Iter: 560 loss: 3.26760619e-06
Iter: 561 loss: 3.26517511e-06
Iter: 562 loss: 3.29690147e-06
Iter: 563 loss: 3.26519284e-06
Iter: 564 loss: 3.26352074e-06
Iter: 565 loss: 3.25981591e-06
Iter: 566 loss: 3.31556544e-06
Iter: 567 loss: 3.2596763e-06
Iter: 568 loss: 3.25599558e-06
Iter: 569 loss: 3.25716928e-06
Iter: 570 loss: 3.25336669e-06
Iter: 571 loss: 3.24960047e-06
Iter: 572 loss: 3.27990711e-06
Iter: 573 loss: 3.24938765e-06
Iter: 574 loss: 3.24596112e-06
Iter: 575 loss: 3.25200381e-06
Iter: 576 loss: 3.24446728e-06
Iter: 577 loss: 3.24153302e-06
Iter: 578 loss: 3.27708926e-06
Iter: 579 loss: 3.24148573e-06
Iter: 580 loss: 3.23920244e-06
Iter: 581 loss: 3.24320263e-06
Iter: 582 loss: 3.23817699e-06
Iter: 583 loss: 3.23549625e-06
Iter: 584 loss: 3.23426843e-06
Iter: 585 loss: 3.23292238e-06
Iter: 586 loss: 3.22952701e-06
Iter: 587 loss: 3.2730668e-06
Iter: 588 loss: 3.22945607e-06
Iter: 589 loss: 3.2273224e-06
Iter: 590 loss: 3.22677897e-06
Iter: 591 loss: 3.22539722e-06
Iter: 592 loss: 3.22253572e-06
Iter: 593 loss: 3.23576819e-06
Iter: 594 loss: 3.22201277e-06
Iter: 595 loss: 3.2190942e-06
Iter: 596 loss: 3.23762106e-06
Iter: 597 loss: 3.21874631e-06
Iter: 598 loss: 3.21640164e-06
Iter: 599 loss: 3.22656297e-06
Iter: 600 loss: 3.21592415e-06
Iter: 601 loss: 3.21413177e-06
Iter: 602 loss: 3.20991876e-06
Iter: 603 loss: 3.25830615e-06
Iter: 604 loss: 3.20955792e-06
Iter: 605 loss: 3.20537447e-06
Iter: 606 loss: 3.21784955e-06
Iter: 607 loss: 3.204113e-06
Iter: 608 loss: 3.20017807e-06
Iter: 609 loss: 3.22237429e-06
Iter: 610 loss: 3.1996326e-06
Iter: 611 loss: 3.19605397e-06
Iter: 612 loss: 3.2070493e-06
Iter: 613 loss: 3.19504875e-06
Iter: 614 loss: 3.19131e-06
Iter: 615 loss: 3.21241669e-06
Iter: 616 loss: 3.19083142e-06
Iter: 617 loss: 3.18759339e-06
Iter: 618 loss: 3.19255855e-06
Iter: 619 loss: 3.18609e-06
Iter: 620 loss: 3.18301e-06
Iter: 621 loss: 3.18903722e-06
Iter: 622 loss: 3.1816935e-06
Iter: 623 loss: 3.17796093e-06
Iter: 624 loss: 3.19278706e-06
Iter: 625 loss: 3.17711192e-06
Iter: 626 loss: 3.17429976e-06
Iter: 627 loss: 3.17690478e-06
Iter: 628 loss: 3.17261015e-06
Iter: 629 loss: 3.1701461e-06
Iter: 630 loss: 3.20259551e-06
Iter: 631 loss: 3.17013973e-06
Iter: 632 loss: 3.1680147e-06
Iter: 633 loss: 3.17417721e-06
Iter: 634 loss: 3.16733622e-06
Iter: 635 loss: 3.164997e-06
Iter: 636 loss: 3.16606702e-06
Iter: 637 loss: 3.16338378e-06
Iter: 638 loss: 3.16119281e-06
Iter: 639 loss: 3.15826946e-06
Iter: 640 loss: 3.15814395e-06
Iter: 641 loss: 3.15368197e-06
Iter: 642 loss: 3.16064666e-06
Iter: 643 loss: 3.15163743e-06
Iter: 644 loss: 3.14760337e-06
Iter: 645 loss: 3.18724142e-06
Iter: 646 loss: 3.14745671e-06
Iter: 647 loss: 3.14426097e-06
Iter: 648 loss: 3.15693546e-06
Iter: 649 loss: 3.14355975e-06
Iter: 650 loss: 3.14056297e-06
Iter: 651 loss: 3.15774241e-06
Iter: 652 loss: 3.14014937e-06
Iter: 653 loss: 3.13810961e-06
Iter: 654 loss: 3.13922374e-06
Iter: 655 loss: 3.13675673e-06
Iter: 656 loss: 3.13422584e-06
Iter: 657 loss: 3.14452154e-06
Iter: 658 loss: 3.13362148e-06
Iter: 659 loss: 3.13100963e-06
Iter: 660 loss: 3.13487089e-06
Iter: 661 loss: 3.12970769e-06
Iter: 662 loss: 3.12743691e-06
Iter: 663 loss: 3.13452892e-06
Iter: 664 loss: 3.12680413e-06
Iter: 665 loss: 3.12438692e-06
Iter: 666 loss: 3.14301633e-06
Iter: 667 loss: 3.12417569e-06
Iter: 668 loss: 3.12218572e-06
Iter: 669 loss: 3.12589259e-06
Iter: 670 loss: 3.12127941e-06
Iter: 671 loss: 3.11899566e-06
Iter: 672 loss: 3.11557505e-06
Iter: 673 loss: 3.11550275e-06
Iter: 674 loss: 3.11155645e-06
Iter: 675 loss: 3.11602957e-06
Iter: 676 loss: 3.10942278e-06
Iter: 677 loss: 3.10490805e-06
Iter: 678 loss: 3.11292229e-06
Iter: 679 loss: 3.1029947e-06
Iter: 680 loss: 3.09857296e-06
Iter: 681 loss: 3.15007173e-06
Iter: 682 loss: 3.09851293e-06
Iter: 683 loss: 3.09568622e-06
Iter: 684 loss: 3.11390113e-06
Iter: 685 loss: 3.09538154e-06
Iter: 686 loss: 3.09278312e-06
Iter: 687 loss: 3.09348911e-06
Iter: 688 loss: 3.09085635e-06
Iter: 689 loss: 3.08792642e-06
Iter: 690 loss: 3.09928055e-06
Iter: 691 loss: 3.08721519e-06
Iter: 692 loss: 3.08439576e-06
Iter: 693 loss: 3.09469578e-06
Iter: 694 loss: 3.08369818e-06
Iter: 695 loss: 3.08099652e-06
Iter: 696 loss: 3.08100516e-06
Iter: 697 loss: 3.07886125e-06
Iter: 698 loss: 3.07662094e-06
Iter: 699 loss: 3.0765566e-06
Iter: 700 loss: 3.07470054e-06
Iter: 701 loss: 3.07811e-06
Iter: 702 loss: 3.07383971e-06
Iter: 703 loss: 3.07173173e-06
Iter: 704 loss: 3.07335313e-06
Iter: 705 loss: 3.07043047e-06
Iter: 706 loss: 3.06839161e-06
Iter: 707 loss: 3.06726793e-06
Iter: 708 loss: 3.06634752e-06
Iter: 709 loss: 3.06364564e-06
Iter: 710 loss: 3.06733705e-06
Iter: 711 loss: 3.06229708e-06
Iter: 712 loss: 3.05902518e-06
Iter: 713 loss: 3.07152823e-06
Iter: 714 loss: 3.05825688e-06
Iter: 715 loss: 3.05512231e-06
Iter: 716 loss: 3.07865048e-06
Iter: 717 loss: 3.05490403e-06
Iter: 718 loss: 3.05201593e-06
Iter: 719 loss: 3.05988e-06
Iter: 720 loss: 3.05111712e-06
Iter: 721 loss: 3.04832361e-06
Iter: 722 loss: 3.05015965e-06
Iter: 723 loss: 3.04654213e-06
Iter: 724 loss: 3.04358127e-06
Iter: 725 loss: 3.0629833e-06
Iter: 726 loss: 3.0432725e-06
Iter: 727 loss: 3.04053924e-06
Iter: 728 loss: 3.04248215e-06
Iter: 729 loss: 3.0388685e-06
Iter: 730 loss: 3.03600814e-06
Iter: 731 loss: 3.04789364e-06
Iter: 732 loss: 3.03544812e-06
Iter: 733 loss: 3.0328074e-06
Iter: 734 loss: 3.0580527e-06
Iter: 735 loss: 3.03272418e-06
Iter: 736 loss: 3.03082652e-06
Iter: 737 loss: 3.03175284e-06
Iter: 738 loss: 3.02956778e-06
Iter: 739 loss: 3.02705712e-06
Iter: 740 loss: 3.0260353e-06
Iter: 741 loss: 3.02471244e-06
Iter: 742 loss: 3.02163517e-06
Iter: 743 loss: 3.02182616e-06
Iter: 744 loss: 3.01922182e-06
Iter: 745 loss: 3.01520458e-06
Iter: 746 loss: 3.0281517e-06
Iter: 747 loss: 3.01403634e-06
Iter: 748 loss: 3.01002638e-06
Iter: 749 loss: 3.03178649e-06
Iter: 750 loss: 3.00945817e-06
Iter: 751 loss: 3.00605188e-06
Iter: 752 loss: 3.03683282e-06
Iter: 753 loss: 3.00587794e-06
Iter: 754 loss: 3.00366492e-06
Iter: 755 loss: 3.00793818e-06
Iter: 756 loss: 3.00273314e-06
Iter: 757 loss: 3.00058605e-06
Iter: 758 loss: 3.00324314e-06
Iter: 759 loss: 2.99946214e-06
Iter: 760 loss: 2.99696126e-06
Iter: 761 loss: 3.01159389e-06
Iter: 762 loss: 2.99659837e-06
Iter: 763 loss: 2.99459793e-06
Iter: 764 loss: 2.99405929e-06
Iter: 765 loss: 2.99282738e-06
Iter: 766 loss: 2.99046724e-06
Iter: 767 loss: 2.99047497e-06
Iter: 768 loss: 2.98844543e-06
Iter: 769 loss: 2.99033081e-06
Iter: 770 loss: 2.98729492e-06
Iter: 771 loss: 2.98511623e-06
Iter: 772 loss: 2.98848e-06
Iter: 773 loss: 2.9841176e-06
Iter: 774 loss: 2.98183204e-06
Iter: 775 loss: 2.97919519e-06
Iter: 776 loss: 2.97890324e-06
Iter: 777 loss: 2.97540623e-06
Iter: 778 loss: 2.98503483e-06
Iter: 779 loss: 2.97428414e-06
Iter: 780 loss: 2.97114138e-06
Iter: 781 loss: 2.98718169e-06
Iter: 782 loss: 2.97066e-06
Iter: 783 loss: 2.96829398e-06
Iter: 784 loss: 2.99207363e-06
Iter: 785 loss: 2.96821486e-06
Iter: 786 loss: 2.96602821e-06
Iter: 787 loss: 2.96818916e-06
Iter: 788 loss: 2.96474173e-06
Iter: 789 loss: 2.96225562e-06
Iter: 790 loss: 2.96877488e-06
Iter: 791 loss: 2.96141252e-06
Iter: 792 loss: 2.95919381e-06
Iter: 793 loss: 2.96639496e-06
Iter: 794 loss: 2.95854716e-06
Iter: 795 loss: 2.95587824e-06
Iter: 796 loss: 2.95703057e-06
Iter: 797 loss: 2.95397012e-06
Iter: 798 loss: 2.95113705e-06
Iter: 799 loss: 2.97115821e-06
Iter: 800 loss: 2.95088284e-06
Iter: 801 loss: 2.94824736e-06
Iter: 802 loss: 2.96279518e-06
Iter: 803 loss: 2.94782558e-06
Iter: 804 loss: 2.94585971e-06
Iter: 805 loss: 2.94662868e-06
Iter: 806 loss: 2.94452275e-06
Iter: 807 loss: 2.94191796e-06
Iter: 808 loss: 2.94266079e-06
Iter: 809 loss: 2.94004576e-06
Iter: 810 loss: 2.93729272e-06
Iter: 811 loss: 2.9387777e-06
Iter: 812 loss: 2.93548374e-06
Iter: 813 loss: 2.93221501e-06
Iter: 814 loss: 2.93861126e-06
Iter: 815 loss: 2.93087828e-06
Iter: 816 loss: 2.92754157e-06
Iter: 817 loss: 2.95259588e-06
Iter: 818 loss: 2.92727941e-06
Iter: 819 loss: 2.92441678e-06
Iter: 820 loss: 2.94309575e-06
Iter: 821 loss: 2.92406412e-06
Iter: 822 loss: 2.92158256e-06
Iter: 823 loss: 2.92193886e-06
Iter: 824 loss: 2.91968172e-06
Iter: 825 loss: 2.91636343e-06
Iter: 826 loss: 2.92777645e-06
Iter: 827 loss: 2.91552351e-06
Iter: 828 loss: 2.91273136e-06
Iter: 829 loss: 2.92816026e-06
Iter: 830 loss: 2.91233209e-06
Iter: 831 loss: 2.91003221e-06
Iter: 832 loss: 2.91112019e-06
Iter: 833 loss: 2.90853131e-06
Iter: 834 loss: 2.90651042e-06
Iter: 835 loss: 2.90649677e-06
Iter: 836 loss: 2.90498224e-06
Iter: 837 loss: 2.90446678e-06
Iter: 838 loss: 2.9035898e-06
Iter: 839 loss: 2.90162984e-06
Iter: 840 loss: 2.90763955e-06
Iter: 841 loss: 2.90106709e-06
Iter: 842 loss: 2.89935906e-06
Iter: 843 loss: 2.8974664e-06
Iter: 844 loss: 2.89722129e-06
Iter: 845 loss: 2.8940326e-06
Iter: 846 loss: 2.89743753e-06
Iter: 847 loss: 2.89230275e-06
Iter: 848 loss: 2.8885006e-06
Iter: 849 loss: 2.8997938e-06
Iter: 850 loss: 2.88731212e-06
Iter: 851 loss: 2.88464798e-06
Iter: 852 loss: 2.88459205e-06
Iter: 853 loss: 2.88260549e-06
Iter: 854 loss: 2.88569936e-06
Iter: 855 loss: 2.88165302e-06
Iter: 856 loss: 2.87963394e-06
Iter: 857 loss: 2.88201772e-06
Iter: 858 loss: 2.87849889e-06
Iter: 859 loss: 2.87605758e-06
Iter: 860 loss: 2.88635e-06
Iter: 861 loss: 2.87553667e-06
Iter: 862 loss: 2.87324792e-06
Iter: 863 loss: 2.87776425e-06
Iter: 864 loss: 2.87230864e-06
Iter: 865 loss: 2.87025068e-06
Iter: 866 loss: 2.88251499e-06
Iter: 867 loss: 2.86997624e-06
Iter: 868 loss: 2.86757586e-06
Iter: 869 loss: 2.87149624e-06
Iter: 870 loss: 2.86647742e-06
Iter: 871 loss: 2.86424256e-06
Iter: 872 loss: 2.86636714e-06
Iter: 873 loss: 2.86295563e-06
Iter: 874 loss: 2.85996362e-06
Iter: 875 loss: 2.8596487e-06
Iter: 876 loss: 2.85746501e-06
Iter: 877 loss: 2.85372471e-06
Iter: 878 loss: 2.85679744e-06
Iter: 879 loss: 2.851506e-06
Iter: 880 loss: 2.84757334e-06
Iter: 881 loss: 2.86256682e-06
Iter: 882 loss: 2.84667976e-06
Iter: 883 loss: 2.84431371e-06
Iter: 884 loss: 2.87216562e-06
Iter: 885 loss: 2.84427188e-06
Iter: 886 loss: 2.84233556e-06
Iter: 887 loss: 2.85286364e-06
Iter: 888 loss: 2.8420468e-06
Iter: 889 loss: 2.84053067e-06
Iter: 890 loss: 2.84184e-06
Iter: 891 loss: 2.83967211e-06
Iter: 892 loss: 2.83792951e-06
Iter: 893 loss: 2.84339467e-06
Iter: 894 loss: 2.83741e-06
Iter: 895 loss: 2.83555619e-06
Iter: 896 loss: 2.84025555e-06
Iter: 897 loss: 2.83493341e-06
Iter: 898 loss: 2.83314148e-06
Iter: 899 loss: 2.83757322e-06
Iter: 900 loss: 2.83249869e-06
Iter: 901 loss: 2.83078e-06
Iter: 902 loss: 2.85064152e-06
Iter: 903 loss: 2.8307536e-06
Iter: 904 loss: 2.82946348e-06
Iter: 905 loss: 2.82756673e-06
Iter: 906 loss: 2.8275249e-06
Iter: 907 loss: 2.82494e-06
Iter: 908 loss: 2.83459576e-06
Iter: 909 loss: 2.82428027e-06
Iter: 910 loss: 2.8221616e-06
Iter: 911 loss: 2.82116321e-06
Iter: 912 loss: 2.82012661e-06
Iter: 913 loss: 2.81712914e-06
Iter: 914 loss: 2.82313135e-06
Iter: 915 loss: 2.81598341e-06
Iter: 916 loss: 2.81305233e-06
Iter: 917 loss: 2.82056908e-06
Iter: 918 loss: 2.8120669e-06
Iter: 919 loss: 2.8096149e-06
Iter: 920 loss: 2.80959944e-06
Iter: 921 loss: 2.80743848e-06
Iter: 922 loss: 2.80753193e-06
Iter: 923 loss: 2.80576546e-06
Iter: 924 loss: 2.80314953e-06
Iter: 925 loss: 2.81261873e-06
Iter: 926 loss: 2.80252038e-06
Iter: 927 loss: 2.80002268e-06
Iter: 928 loss: 2.80795803e-06
Iter: 929 loss: 2.79931828e-06
Iter: 930 loss: 2.79676465e-06
Iter: 931 loss: 2.80112431e-06
Iter: 932 loss: 2.79563392e-06
Iter: 933 loss: 2.79359392e-06
Iter: 934 loss: 2.8224274e-06
Iter: 935 loss: 2.79359301e-06
Iter: 936 loss: 2.7918029e-06
Iter: 937 loss: 2.79222104e-06
Iter: 938 loss: 2.79050164e-06
Iter: 939 loss: 2.78866014e-06
Iter: 940 loss: 2.79238066e-06
Iter: 941 loss: 2.78794641e-06
Iter: 942 loss: 2.78587822e-06
Iter: 943 loss: 2.78684547e-06
Iter: 944 loss: 2.78444031e-06
Iter: 945 loss: 2.78217635e-06
Iter: 946 loss: 2.78272546e-06
Iter: 947 loss: 2.78051607e-06
Iter: 948 loss: 2.77726031e-06
Iter: 949 loss: 2.78257653e-06
Iter: 950 loss: 2.77579397e-06
Iter: 951 loss: 2.77337358e-06
Iter: 952 loss: 2.80727363e-06
Iter: 953 loss: 2.77336426e-06
Iter: 954 loss: 2.77124172e-06
Iter: 955 loss: 2.7822332e-06
Iter: 956 loss: 2.77091476e-06
Iter: 957 loss: 2.76929859e-06
Iter: 958 loss: 2.76936044e-06
Iter: 959 loss: 2.7680253e-06
Iter: 960 loss: 2.76594665e-06
Iter: 961 loss: 2.77902836e-06
Iter: 962 loss: 2.76572678e-06
Iter: 963 loss: 2.76402898e-06
Iter: 964 loss: 2.76752075e-06
Iter: 965 loss: 2.76338869e-06
Iter: 966 loss: 2.76167361e-06
Iter: 967 loss: 2.76770629e-06
Iter: 968 loss: 2.76118567e-06
Iter: 969 loss: 2.75944558e-06
Iter: 970 loss: 2.77281742e-06
Iter: 971 loss: 2.75929847e-06
Iter: 972 loss: 2.75818934e-06
Iter: 973 loss: 2.75726984e-06
Iter: 974 loss: 2.75695288e-06
Iter: 975 loss: 2.75506272e-06
Iter: 976 loss: 2.76003129e-06
Iter: 977 loss: 2.75442153e-06
Iter: 978 loss: 2.75240041e-06
Iter: 979 loss: 2.75087473e-06
Iter: 980 loss: 2.75019556e-06
Iter: 981 loss: 2.74727563e-06
Iter: 982 loss: 2.75418e-06
Iter: 983 loss: 2.7461756e-06
Iter: 984 loss: 2.74325475e-06
Iter: 985 loss: 2.75256207e-06
Iter: 986 loss: 2.74241302e-06
Iter: 987 loss: 2.74090439e-06
Iter: 988 loss: 2.74076592e-06
Iter: 989 loss: 2.73942896e-06
Iter: 990 loss: 2.73894148e-06
Iter: 991 loss: 2.73820569e-06
Iter: 992 loss: 2.73644969e-06
Iter: 993 loss: 2.74223339e-06
Iter: 994 loss: 2.73597675e-06
Iter: 995 loss: 2.7341614e-06
Iter: 996 loss: 2.74055606e-06
Iter: 997 loss: 2.7337e-06
Iter: 998 loss: 2.7321048e-06
Iter: 999 loss: 2.73649493e-06
Iter: 1000 loss: 2.73158594e-06
Iter: 1001 loss: 2.73019714e-06
Iter: 1002 loss: 2.74384456e-06
Iter: 1003 loss: 2.73014416e-06
Iter: 1004 loss: 2.72878879e-06
Iter: 1005 loss: 2.72720013e-06
Iter: 1006 loss: 2.727018e-06
Iter: 1007 loss: 2.724963e-06
Iter: 1008 loss: 2.73260343e-06
Iter: 1009 loss: 2.72446596e-06
Iter: 1010 loss: 2.72244506e-06
Iter: 1011 loss: 2.72423449e-06
Iter: 1012 loss: 2.72126795e-06
Iter: 1013 loss: 2.71902491e-06
Iter: 1014 loss: 2.71862064e-06
Iter: 1015 loss: 2.71709723e-06
Iter: 1016 loss: 2.7142496e-06
Iter: 1017 loss: 2.72441184e-06
Iter: 1018 loss: 2.7135236e-06
Iter: 1019 loss: 2.71122394e-06
Iter: 1020 loss: 2.72671014e-06
Iter: 1021 loss: 2.71097315e-06
Iter: 1022 loss: 2.70891042e-06
Iter: 1023 loss: 2.72631064e-06
Iter: 1024 loss: 2.7088e-06
Iter: 1025 loss: 2.70745159e-06
Iter: 1026 loss: 2.70681676e-06
Iter: 1027 loss: 2.70617511e-06
Iter: 1028 loss: 2.70422311e-06
Iter: 1029 loss: 2.71682029e-06
Iter: 1030 loss: 2.70402279e-06
Iter: 1031 loss: 2.70232795e-06
Iter: 1032 loss: 2.70426949e-06
Iter: 1033 loss: 2.70139935e-06
Iter: 1034 loss: 2.69962243e-06
Iter: 1035 loss: 2.71316753e-06
Iter: 1036 loss: 2.69949351e-06
Iter: 1037 loss: 2.69798466e-06
Iter: 1038 loss: 2.70508372e-06
Iter: 1039 loss: 2.69768884e-06
Iter: 1040 loss: 2.69664724e-06
Iter: 1041 loss: 2.69551174e-06
Iter: 1042 loss: 2.69534644e-06
Iter: 1043 loss: 2.69343127e-06
Iter: 1044 loss: 2.700913e-06
Iter: 1045 loss: 2.69297357e-06
Iter: 1046 loss: 2.69126303e-06
Iter: 1047 loss: 2.69185193e-06
Iter: 1048 loss: 2.69005614e-06
Iter: 1049 loss: 2.68803797e-06
Iter: 1050 loss: 2.68819576e-06
Iter: 1051 loss: 2.6864634e-06
Iter: 1052 loss: 2.68374811e-06
Iter: 1053 loss: 2.69473912e-06
Iter: 1054 loss: 2.68313784e-06
Iter: 1055 loss: 2.68141798e-06
Iter: 1056 loss: 2.68141275e-06
Iter: 1057 loss: 2.67972882e-06
Iter: 1058 loss: 2.67907467e-06
Iter: 1059 loss: 2.67815881e-06
Iter: 1060 loss: 2.67620612e-06
Iter: 1061 loss: 2.68444319e-06
Iter: 1062 loss: 2.6757948e-06
Iter: 1063 loss: 2.67387236e-06
Iter: 1064 loss: 2.68121812e-06
Iter: 1065 loss: 2.67343921e-06
Iter: 1066 loss: 2.67183532e-06
Iter: 1067 loss: 2.67624364e-06
Iter: 1068 loss: 2.67130213e-06
Iter: 1069 loss: 2.66988536e-06
Iter: 1070 loss: 2.68437952e-06
Iter: 1071 loss: 2.66981147e-06
Iter: 1072 loss: 2.66868688e-06
Iter: 1073 loss: 2.66824372e-06
Iter: 1074 loss: 2.66763118e-06
Iter: 1075 loss: 2.6662583e-06
Iter: 1076 loss: 2.66873985e-06
Iter: 1077 loss: 2.6656644e-06
Iter: 1078 loss: 2.66385882e-06
Iter: 1079 loss: 2.6651328e-06
Iter: 1080 loss: 2.66272446e-06
Iter: 1081 loss: 2.66060033e-06
Iter: 1082 loss: 2.66288544e-06
Iter: 1083 loss: 2.659453e-06
Iter: 1084 loss: 2.65727613e-06
Iter: 1085 loss: 2.6588998e-06
Iter: 1086 loss: 2.65596418e-06
Iter: 1087 loss: 2.65322501e-06
Iter: 1088 loss: 2.66768711e-06
Iter: 1089 loss: 2.65281528e-06
Iter: 1090 loss: 2.65055155e-06
Iter: 1091 loss: 2.68057397e-06
Iter: 1092 loss: 2.65056747e-06
Iter: 1093 loss: 2.64894607e-06
Iter: 1094 loss: 2.64652772e-06
Iter: 1095 loss: 2.64647815e-06
Iter: 1096 loss: 2.64407527e-06
Iter: 1097 loss: 2.67857831e-06
Iter: 1098 loss: 2.64406663e-06
Iter: 1099 loss: 2.64236064e-06
Iter: 1100 loss: 2.6448788e-06
Iter: 1101 loss: 2.64155869e-06
Iter: 1102 loss: 2.63997458e-06
Iter: 1103 loss: 2.65322547e-06
Iter: 1104 loss: 2.6398925e-06
Iter: 1105 loss: 2.63840047e-06
Iter: 1106 loss: 2.64077062e-06
Iter: 1107 loss: 2.63770198e-06
Iter: 1108 loss: 2.63622951e-06
Iter: 1109 loss: 2.63583297e-06
Iter: 1110 loss: 2.63491984e-06
Iter: 1111 loss: 2.63302263e-06
Iter: 1112 loss: 2.6425846e-06
Iter: 1113 loss: 2.63268612e-06
Iter: 1114 loss: 2.63093943e-06
Iter: 1115 loss: 2.63053084e-06
Iter: 1116 loss: 2.62941057e-06
Iter: 1117 loss: 2.62705271e-06
Iter: 1118 loss: 2.62971753e-06
Iter: 1119 loss: 2.62579624e-06
Iter: 1120 loss: 2.62306139e-06
Iter: 1121 loss: 2.62712274e-06
Iter: 1122 loss: 2.62177196e-06
Iter: 1123 loss: 2.61975833e-06
Iter: 1124 loss: 2.61971923e-06
Iter: 1125 loss: 2.61780974e-06
Iter: 1126 loss: 2.62088e-06
Iter: 1127 loss: 2.61693e-06
Iter: 1128 loss: 2.6153848e-06
Iter: 1129 loss: 2.61682817e-06
Iter: 1130 loss: 2.61447281e-06
Iter: 1131 loss: 2.61259015e-06
Iter: 1132 loss: 2.6270618e-06
Iter: 1133 loss: 2.61245464e-06
Iter: 1134 loss: 2.61124887e-06
Iter: 1135 loss: 2.61441664e-06
Iter: 1136 loss: 2.6108637e-06
Iter: 1137 loss: 2.60959882e-06
Iter: 1138 loss: 2.61853279e-06
Iter: 1139 loss: 2.60948627e-06
Iter: 1140 loss: 2.60843285e-06
Iter: 1141 loss: 2.60757861e-06
Iter: 1142 loss: 2.60727029e-06
Iter: 1143 loss: 2.60564593e-06
Iter: 1144 loss: 2.6084449e-06
Iter: 1145 loss: 2.60498382e-06
Iter: 1146 loss: 2.6030425e-06
Iter: 1147 loss: 2.60821344e-06
Iter: 1148 loss: 2.60242336e-06
Iter: 1149 loss: 2.60052911e-06
Iter: 1150 loss: 2.60010802e-06
Iter: 1151 loss: 2.59891499e-06
Iter: 1152 loss: 2.59650847e-06
Iter: 1153 loss: 2.60225852e-06
Iter: 1154 loss: 2.59564786e-06
Iter: 1155 loss: 2.59331046e-06
Iter: 1156 loss: 2.59955323e-06
Iter: 1157 loss: 2.592486e-06
Iter: 1158 loss: 2.59109493e-06
Iter: 1159 loss: 2.59095782e-06
Iter: 1160 loss: 2.58987643e-06
Iter: 1161 loss: 2.58848922e-06
Iter: 1162 loss: 2.58840055e-06
Iter: 1163 loss: 2.58667296e-06
Iter: 1164 loss: 2.59792569e-06
Iter: 1165 loss: 2.58648788e-06
Iter: 1166 loss: 2.5847603e-06
Iter: 1167 loss: 2.58773366e-06
Iter: 1168 loss: 2.58399632e-06
Iter: 1169 loss: 2.58262207e-06
Iter: 1170 loss: 2.59859371e-06
Iter: 1171 loss: 2.58259274e-06
Iter: 1172 loss: 2.58135287e-06
Iter: 1173 loss: 2.58166619e-06
Iter: 1174 loss: 2.58045475e-06
Iter: 1175 loss: 2.57892611e-06
Iter: 1176 loss: 2.57974239e-06
Iter: 1177 loss: 2.5779259e-06
Iter: 1178 loss: 2.57620422e-06
Iter: 1179 loss: 2.58351429e-06
Iter: 1180 loss: 2.57585907e-06
Iter: 1181 loss: 2.5742238e-06
Iter: 1182 loss: 2.57568581e-06
Iter: 1183 loss: 2.57327429e-06
Iter: 1184 loss: 2.57152033e-06
Iter: 1185 loss: 2.57206739e-06
Iter: 1186 loss: 2.57023476e-06
Iter: 1187 loss: 2.56805924e-06
Iter: 1188 loss: 2.57307852e-06
Iter: 1189 loss: 2.56730618e-06
Iter: 1190 loss: 2.56516614e-06
Iter: 1191 loss: 2.57859347e-06
Iter: 1192 loss: 2.56493945e-06
Iter: 1193 loss: 2.56270278e-06
Iter: 1194 loss: 2.57463876e-06
Iter: 1195 loss: 2.56239264e-06
Iter: 1196 loss: 2.56100202e-06
Iter: 1197 loss: 2.56064413e-06
Iter: 1198 loss: 2.55975783e-06
Iter: 1199 loss: 2.55786358e-06
Iter: 1200 loss: 2.57455986e-06
Iter: 1201 loss: 2.55775058e-06
Iter: 1202 loss: 2.55631358e-06
Iter: 1203 loss: 2.55928762e-06
Iter: 1204 loss: 2.55570194e-06
Iter: 1205 loss: 2.55414625e-06
Iter: 1206 loss: 2.5669865e-06
Iter: 1207 loss: 2.55409896e-06
Iter: 1208 loss: 2.55313535e-06
Iter: 1209 loss: 2.55259692e-06
Iter: 1210 loss: 2.55219402e-06
Iter: 1211 loss: 2.55067744e-06
Iter: 1212 loss: 2.55298482e-06
Iter: 1213 loss: 2.54998145e-06
Iter: 1214 loss: 2.54845963e-06
Iter: 1215 loss: 2.55522332e-06
Iter: 1216 loss: 2.54814677e-06
Iter: 1217 loss: 2.54683209e-06
Iter: 1218 loss: 2.54689621e-06
Iter: 1219 loss: 2.54580982e-06
Iter: 1220 loss: 2.54402858e-06
Iter: 1221 loss: 2.54458632e-06
Iter: 1222 loss: 2.54276233e-06
Iter: 1223 loss: 2.54033876e-06
Iter: 1224 loss: 2.54725614e-06
Iter: 1225 loss: 2.5395625e-06
Iter: 1226 loss: 2.538236e-06
Iter: 1227 loss: 2.53810504e-06
Iter: 1228 loss: 2.53679764e-06
Iter: 1229 loss: 2.5356926e-06
Iter: 1230 loss: 2.53531698e-06
Iter: 1231 loss: 2.53379199e-06
Iter: 1232 loss: 2.54343877e-06
Iter: 1233 loss: 2.53362691e-06
Iter: 1234 loss: 2.53212306e-06
Iter: 1235 loss: 2.53624512e-06
Iter: 1236 loss: 2.53162625e-06
Iter: 1237 loss: 2.53034204e-06
Iter: 1238 loss: 2.53982535e-06
Iter: 1239 loss: 2.53023222e-06
Iter: 1240 loss: 2.52893051e-06
Iter: 1241 loss: 2.52865129e-06
Iter: 1242 loss: 2.52776044e-06
Iter: 1243 loss: 2.52627433e-06
Iter: 1244 loss: 2.52992822e-06
Iter: 1245 loss: 2.52573727e-06
Iter: 1246 loss: 2.52419522e-06
Iter: 1247 loss: 2.52622158e-06
Iter: 1248 loss: 2.52341306e-06
Iter: 1249 loss: 2.52150312e-06
Iter: 1250 loss: 2.52609129e-06
Iter: 1251 loss: 2.52080463e-06
Iter: 1252 loss: 2.51901679e-06
Iter: 1253 loss: 2.51961501e-06
Iter: 1254 loss: 2.51774986e-06
Iter: 1255 loss: 2.51559345e-06
Iter: 1256 loss: 2.51856818e-06
Iter: 1257 loss: 2.51449387e-06
Iter: 1258 loss: 2.51240454e-06
Iter: 1259 loss: 2.52804307e-06
Iter: 1260 loss: 2.5122622e-06
Iter: 1261 loss: 2.51078791e-06
Iter: 1262 loss: 2.53315557e-06
Iter: 1263 loss: 2.5107845e-06
Iter: 1264 loss: 2.50988205e-06
Iter: 1265 loss: 2.50830908e-06
Iter: 1266 loss: 2.50830544e-06
Iter: 1267 loss: 2.50692892e-06
Iter: 1268 loss: 2.50691255e-06
Iter: 1269 loss: 2.50582457e-06
Iter: 1270 loss: 2.50739845e-06
Iter: 1271 loss: 2.50528842e-06
Iter: 1272 loss: 2.50408129e-06
Iter: 1273 loss: 2.51341021e-06
Iter: 1274 loss: 2.50399148e-06
Iter: 1275 loss: 2.50305357e-06
Iter: 1276 loss: 2.50163293e-06
Iter: 1277 loss: 2.50160065e-06
Iter: 1278 loss: 2.49984305e-06
Iter: 1279 loss: 2.50919311e-06
Iter: 1280 loss: 2.4995511e-06
Iter: 1281 loss: 2.49814047e-06
Iter: 1282 loss: 2.50049015e-06
Iter: 1283 loss: 2.4975111e-06
Iter: 1284 loss: 2.49581649e-06
Iter: 1285 loss: 2.498409e-06
Iter: 1286 loss: 2.49502909e-06
Iter: 1287 loss: 2.49338495e-06
Iter: 1288 loss: 2.49469713e-06
Iter: 1289 loss: 2.49244931e-06
Iter: 1290 loss: 2.4904682e-06
Iter: 1291 loss: 2.49228106e-06
Iter: 1292 loss: 2.48935885e-06
Iter: 1293 loss: 2.48752531e-06
Iter: 1294 loss: 2.48754554e-06
Iter: 1295 loss: 2.48577362e-06
Iter: 1296 loss: 2.48842207e-06
Iter: 1297 loss: 2.48496053e-06
Iter: 1298 loss: 2.48351898e-06
Iter: 1299 loss: 2.48418064e-06
Iter: 1300 loss: 2.48252809e-06
Iter: 1301 loss: 2.48080823e-06
Iter: 1302 loss: 2.5014e-06
Iter: 1303 loss: 2.48078709e-06
Iter: 1304 loss: 2.47971684e-06
Iter: 1305 loss: 2.48383822e-06
Iter: 1306 loss: 2.47945263e-06
Iter: 1307 loss: 2.47814114e-06
Iter: 1308 loss: 2.47838238e-06
Iter: 1309 loss: 2.47715479e-06
Iter: 1310 loss: 2.475786e-06
Iter: 1311 loss: 2.47738171e-06
Iter: 1312 loss: 2.47508024e-06
Iter: 1313 loss: 2.47350044e-06
Iter: 1314 loss: 2.47918251e-06
Iter: 1315 loss: 2.47307526e-06
Iter: 1316 loss: 2.47172375e-06
Iter: 1317 loss: 2.47429193e-06
Iter: 1318 loss: 2.47112803e-06
Iter: 1319 loss: 2.46946411e-06
Iter: 1320 loss: 2.4705314e-06
Iter: 1321 loss: 2.46843547e-06
Iter: 1322 loss: 2.4665469e-06
Iter: 1323 loss: 2.46719355e-06
Iter: 1324 loss: 2.46523155e-06
Iter: 1325 loss: 2.46277978e-06
Iter: 1326 loss: 2.47257458e-06
Iter: 1327 loss: 2.46220111e-06
Iter: 1328 loss: 2.46078616e-06
Iter: 1329 loss: 2.46068203e-06
Iter: 1330 loss: 2.4595879e-06
Iter: 1331 loss: 2.45826732e-06
Iter: 1332 loss: 2.45812e-06
Iter: 1333 loss: 2.45669912e-06
Iter: 1334 loss: 2.4699616e-06
Iter: 1335 loss: 2.45663159e-06
Iter: 1336 loss: 2.45529282e-06
Iter: 1337 loss: 2.4594442e-06
Iter: 1338 loss: 2.45491424e-06
Iter: 1339 loss: 2.4539147e-06
Iter: 1340 loss: 2.46376067e-06
Iter: 1341 loss: 2.453869e-06
Iter: 1342 loss: 2.45311821e-06
Iter: 1343 loss: 2.45186084e-06
Iter: 1344 loss: 2.4837509e-06
Iter: 1345 loss: 2.45184651e-06
Iter: 1346 loss: 2.45040042e-06
Iter: 1347 loss: 2.45803949e-06
Iter: 1348 loss: 2.45017e-06
Iter: 1349 loss: 2.44882722e-06
Iter: 1350 loss: 2.450598e-06
Iter: 1351 loss: 2.44816124e-06
Iter: 1352 loss: 2.44661078e-06
Iter: 1353 loss: 2.44939679e-06
Iter: 1354 loss: 2.44592252e-06
Iter: 1355 loss: 2.4441174e-06
Iter: 1356 loss: 2.44614648e-06
Iter: 1357 loss: 2.44317653e-06
Iter: 1358 loss: 2.4415649e-06
Iter: 1359 loss: 2.44321154e-06
Iter: 1360 loss: 2.44067405e-06
Iter: 1361 loss: 2.43905856e-06
Iter: 1362 loss: 2.45702427e-06
Iter: 1363 loss: 2.43903514e-06
Iter: 1364 loss: 2.43767727e-06
Iter: 1365 loss: 2.44690955e-06
Iter: 1366 loss: 2.43755176e-06
Iter: 1367 loss: 2.43668364e-06
Iter: 1368 loss: 2.43567683e-06
Iter: 1369 loss: 2.43559225e-06
Iter: 1370 loss: 2.43435034e-06
Iter: 1371 loss: 2.43435466e-06
Iter: 1372 loss: 2.43335739e-06
Iter: 1373 loss: 2.43450927e-06
Iter: 1374 loss: 2.43283421e-06
Iter: 1375 loss: 2.43136265e-06
Iter: 1376 loss: 2.43417844e-06
Iter: 1377 loss: 2.43075965e-06
Iter: 1378 loss: 2.42950955e-06
Iter: 1379 loss: 2.42829242e-06
Iter: 1380 loss: 2.42804936e-06
Iter: 1381 loss: 2.42590772e-06
Iter: 1382 loss: 2.4404942e-06
Iter: 1383 loss: 2.42569013e-06
Iter: 1384 loss: 2.42421447e-06
Iter: 1385 loss: 2.42704482e-06
Iter: 1386 loss: 2.423571e-06
Iter: 1387 loss: 2.42201736e-06
Iter: 1388 loss: 2.42489295e-06
Iter: 1389 loss: 2.42138503e-06
Iter: 1390 loss: 2.41964608e-06
Iter: 1391 loss: 2.41983298e-06
Iter: 1392 loss: 2.41832481e-06
Iter: 1393 loss: 2.41622729e-06
Iter: 1394 loss: 2.41914222e-06
Iter: 1395 loss: 2.41519956e-06
Iter: 1396 loss: 2.41359839e-06
Iter: 1397 loss: 2.41350449e-06
Iter: 1398 loss: 2.41201678e-06
Iter: 1399 loss: 2.41197608e-06
Iter: 1400 loss: 2.4108117e-06
Iter: 1401 loss: 2.4091737e-06
Iter: 1402 loss: 2.41187126e-06
Iter: 1403 loss: 2.40846748e-06
Iter: 1404 loss: 2.40652435e-06
Iter: 1405 loss: 2.42443048e-06
Iter: 1406 loss: 2.40643249e-06
Iter: 1407 loss: 2.40518739e-06
Iter: 1408 loss: 2.41070165e-06
Iter: 1409 loss: 2.40496524e-06
Iter: 1410 loss: 2.40371082e-06
Iter: 1411 loss: 2.40279132e-06
Iter: 1412 loss: 2.40240115e-06
Iter: 1413 loss: 2.4010883e-06
Iter: 1414 loss: 2.40491454e-06
Iter: 1415 loss: 2.40065901e-06
Iter: 1416 loss: 2.39914561e-06
Iter: 1417 loss: 2.40371946e-06
Iter: 1418 loss: 2.39869814e-06
Iter: 1419 loss: 2.39732412e-06
Iter: 1420 loss: 2.39957035e-06
Iter: 1421 loss: 2.39668657e-06
Iter: 1422 loss: 2.39504561e-06
Iter: 1423 loss: 2.39672613e-06
Iter: 1424 loss: 2.39412839e-06
Iter: 1425 loss: 2.39209976e-06
Iter: 1426 loss: 2.39262295e-06
Iter: 1427 loss: 2.39062842e-06
Iter: 1428 loss: 2.3882908e-06
Iter: 1429 loss: 2.39670089e-06
Iter: 1430 loss: 2.38770053e-06
Iter: 1431 loss: 2.38606162e-06
Iter: 1432 loss: 2.38600819e-06
Iter: 1433 loss: 2.38476332e-06
Iter: 1434 loss: 2.38331268e-06
Iter: 1435 loss: 2.38316989e-06
Iter: 1436 loss: 2.38180746e-06
Iter: 1437 loss: 2.39927431e-06
Iter: 1438 loss: 2.38177654e-06
Iter: 1439 loss: 2.38051098e-06
Iter: 1440 loss: 2.3846369e-06
Iter: 1441 loss: 2.38014854e-06
Iter: 1442 loss: 2.37914651e-06
Iter: 1443 loss: 2.38459643e-06
Iter: 1444 loss: 2.3789803e-06
Iter: 1445 loss: 2.37813219e-06
Iter: 1446 loss: 2.37677159e-06
Iter: 1447 loss: 2.37674658e-06
Iter: 1448 loss: 2.3753239e-06
Iter: 1449 loss: 2.38470034e-06
Iter: 1450 loss: 2.37518498e-06
Iter: 1451 loss: 2.37369272e-06
Iter: 1452 loss: 2.37487711e-06
Iter: 1453 loss: 2.37284917e-06
Iter: 1454 loss: 2.37123095e-06
Iter: 1455 loss: 2.37663153e-06
Iter: 1456 loss: 2.37079803e-06
Iter: 1457 loss: 2.36930214e-06
Iter: 1458 loss: 2.37110726e-06
Iter: 1459 loss: 2.36852748e-06
Iter: 1460 loss: 2.36686583e-06
Iter: 1461 loss: 2.36788537e-06
Iter: 1462 loss: 2.36579763e-06
Iter: 1463 loss: 2.36413052e-06
Iter: 1464 loss: 2.37496465e-06
Iter: 1465 loss: 2.36398773e-06
Iter: 1466 loss: 2.36262485e-06
Iter: 1467 loss: 2.37772474e-06
Iter: 1468 loss: 2.36259075e-06
Iter: 1469 loss: 2.36162077e-06
Iter: 1470 loss: 2.36022288e-06
Iter: 1471 loss: 2.36018423e-06
Iter: 1472 loss: 2.3592e-06
Iter: 1473 loss: 2.35915286e-06
Iter: 1474 loss: 2.35816333e-06
Iter: 1475 loss: 2.3583184e-06
Iter: 1476 loss: 2.35742209e-06
Iter: 1477 loss: 2.35611606e-06
Iter: 1478 loss: 2.36161759e-06
Iter: 1479 loss: 2.35583093e-06
Iter: 1480 loss: 2.35479797e-06
Iter: 1481 loss: 2.3533521e-06
Iter: 1482 loss: 2.35330526e-06
Iter: 1483 loss: 2.35181892e-06
Iter: 1484 loss: 2.36718415e-06
Iter: 1485 loss: 2.35175617e-06
Iter: 1486 loss: 2.35030893e-06
Iter: 1487 loss: 2.34981508e-06
Iter: 1488 loss: 2.34899449e-06
Iter: 1489 loss: 2.3471739e-06
Iter: 1490 loss: 2.35714333e-06
Iter: 1491 loss: 2.3469529e-06
Iter: 1492 loss: 2.34541449e-06
Iter: 1493 loss: 2.34610843e-06
Iter: 1494 loss: 2.3443954e-06
Iter: 1495 loss: 2.34255504e-06
Iter: 1496 loss: 2.3457244e-06
Iter: 1497 loss: 2.34175923e-06
Iter: 1498 loss: 2.34034474e-06
Iter: 1499 loss: 2.353946e-06
Iter: 1500 loss: 2.34026766e-06
Iter: 1501 loss: 2.33880064e-06
Iter: 1502 loss: 2.34463823e-06
Iter: 1503 loss: 2.3384755e-06
Iter: 1504 loss: 2.33733249e-06
Iter: 1505 loss: 2.33652372e-06
Iter: 1506 loss: 2.33613582e-06
Iter: 1507 loss: 2.33505853e-06
Iter: 1508 loss: 2.33496121e-06
Iter: 1509 loss: 2.33405831e-06
Iter: 1510 loss: 2.3336288e-06
Iter: 1511 loss: 2.33321498e-06
Iter: 1512 loss: 2.33164747e-06
Iter: 1513 loss: 2.33516425e-06
Iter: 1514 loss: 2.33110518e-06
Iter: 1515 loss: 2.32981142e-06
Iter: 1516 loss: 2.32898083e-06
Iter: 1517 loss: 2.32849015e-06
Iter: 1518 loss: 2.3268824e-06
Iter: 1519 loss: 2.34427353e-06
Iter: 1520 loss: 2.32682305e-06
Iter: 1521 loss: 2.3253549e-06
Iter: 1522 loss: 2.32410798e-06
Iter: 1523 loss: 2.32371053e-06
Iter: 1524 loss: 2.32181083e-06
Iter: 1525 loss: 2.33650348e-06
Iter: 1526 loss: 2.3216603e-06
Iter: 1527 loss: 2.32008688e-06
Iter: 1528 loss: 2.31932518e-06
Iter: 1529 loss: 2.31858121e-06
Iter: 1530 loss: 2.31645618e-06
Iter: 1531 loss: 2.32394837e-06
Iter: 1532 loss: 2.31590138e-06
Iter: 1533 loss: 2.314433e-06
Iter: 1534 loss: 2.33317792e-06
Iter: 1535 loss: 2.31442687e-06
Iter: 1536 loss: 2.31285662e-06
Iter: 1537 loss: 2.31384911e-06
Iter: 1538 loss: 2.31189142e-06
Iter: 1539 loss: 2.31050399e-06
Iter: 1540 loss: 2.31368472e-06
Iter: 1541 loss: 2.31000058e-06
Iter: 1542 loss: 2.30856813e-06
Iter: 1543 loss: 2.3257835e-06
Iter: 1544 loss: 2.3085081e-06
Iter: 1545 loss: 2.30765045e-06
Iter: 1546 loss: 2.30825231e-06
Iter: 1547 loss: 2.30715114e-06
Iter: 1548 loss: 2.30594355e-06
Iter: 1549 loss: 2.30690694e-06
Iter: 1550 loss: 2.30521141e-06
Iter: 1551 loss: 2.30408068e-06
Iter: 1552 loss: 2.30443675e-06
Iter: 1553 loss: 2.3032776e-06
Iter: 1554 loss: 2.30185969e-06
Iter: 1555 loss: 2.31438912e-06
Iter: 1556 loss: 2.30178557e-06
Iter: 1557 loss: 2.30059459e-06
Iter: 1558 loss: 2.29980697e-06
Iter: 1559 loss: 2.29940497e-06
Iter: 1560 loss: 2.29793841e-06
Iter: 1561 loss: 2.30939827e-06
Iter: 1562 loss: 2.297827e-06
Iter: 1563 loss: 2.29662737e-06
Iter: 1564 loss: 2.295473e-06
Iter: 1565 loss: 2.29516581e-06
Iter: 1566 loss: 2.29346415e-06
Iter: 1567 loss: 2.30501655e-06
Iter: 1568 loss: 2.29332113e-06
Iter: 1569 loss: 2.29206262e-06
Iter: 1570 loss: 2.30701266e-06
Iter: 1571 loss: 2.2920317e-06
Iter: 1572 loss: 2.29095031e-06
Iter: 1573 loss: 2.28996078e-06
Iter: 1574 loss: 2.28970794e-06
Iter: 1575 loss: 2.28888848e-06
Iter: 1576 loss: 2.28886051e-06
Iter: 1577 loss: 2.28800582e-06
Iter: 1578 loss: 2.28778117e-06
Iter: 1579 loss: 2.28724775e-06
Iter: 1580 loss: 2.28620092e-06
Iter: 1581 loss: 2.2916181e-06
Iter: 1582 loss: 2.28603949e-06
Iter: 1583 loss: 2.28511817e-06
Iter: 1584 loss: 2.28428325e-06
Iter: 1585 loss: 2.28403451e-06
Iter: 1586 loss: 2.28276622e-06
Iter: 1587 loss: 2.28679255e-06
Iter: 1588 loss: 2.28239333e-06
Iter: 1589 loss: 2.28085673e-06
Iter: 1590 loss: 2.28692488e-06
Iter: 1591 loss: 2.28055069e-06
Iter: 1592 loss: 2.27933151e-06
Iter: 1593 loss: 2.27950204e-06
Iter: 1594 loss: 2.27841679e-06
Iter: 1595 loss: 2.27700775e-06
Iter: 1596 loss: 2.28619183e-06
Iter: 1597 loss: 2.2768304e-06
Iter: 1598 loss: 2.27567853e-06
Iter: 1599 loss: 2.2747563e-06
Iter: 1600 loss: 2.2744357e-06
Iter: 1601 loss: 2.27332839e-06
Iter: 1602 loss: 2.27329633e-06
Iter: 1603 loss: 2.27218607e-06
Iter: 1604 loss: 2.27537157e-06
Iter: 1605 loss: 2.27185319e-06
Iter: 1606 loss: 2.27084e-06
Iter: 1607 loss: 2.27070245e-06
Iter: 1608 loss: 2.27000692e-06
Iter: 1609 loss: 2.26945031e-06
Iter: 1610 loss: 2.26925908e-06
Iter: 1611 loss: 2.26877228e-06
Iter: 1612 loss: 2.26788484e-06
Iter: 1613 loss: 2.2678837e-06
Iter: 1614 loss: 2.26674911e-06
Iter: 1615 loss: 2.27283226e-06
Iter: 1616 loss: 2.26659813e-06
Iter: 1617 loss: 2.26574639e-06
Iter: 1618 loss: 2.26499833e-06
Iter: 1619 loss: 2.26477869e-06
Iter: 1620 loss: 2.26360953e-06
Iter: 1621 loss: 2.27255759e-06
Iter: 1622 loss: 2.26351176e-06
Iter: 1623 loss: 2.26239945e-06
Iter: 1624 loss: 2.26360339e-06
Iter: 1625 loss: 2.26174552e-06
Iter: 1626 loss: 2.26070892e-06
Iter: 1627 loss: 2.26293e-06
Iter: 1628 loss: 2.26024963e-06
Iter: 1629 loss: 2.25914664e-06
Iter: 1630 loss: 2.26280054e-06
Iter: 1631 loss: 2.25882832e-06
Iter: 1632 loss: 2.25773556e-06
Iter: 1633 loss: 2.25697659e-06
Iter: 1634 loss: 2.25659869e-06
Iter: 1635 loss: 2.2558645e-06
Iter: 1636 loss: 2.25568419e-06
Iter: 1637 loss: 2.254837e-06
Iter: 1638 loss: 2.25420536e-06
Iter: 1639 loss: 2.25393e-06
Iter: 1640 loss: 2.25287476e-06
Iter: 1641 loss: 2.2597078e-06
Iter: 1642 loss: 2.25275335e-06
Iter: 1643 loss: 2.25168196e-06
Iter: 1644 loss: 2.2571362e-06
Iter: 1645 loss: 2.25147278e-06
Iter: 1646 loss: 2.25079566e-06
Iter: 1647 loss: 2.25079816e-06
Iter: 1648 loss: 2.25024428e-06
Iter: 1649 loss: 2.24909536e-06
Iter: 1650 loss: 2.25050735e-06
Iter: 1651 loss: 2.24848691e-06
Iter: 1652 loss: 2.2474344e-06
Iter: 1653 loss: 2.24824021e-06
Iter: 1654 loss: 2.24680321e-06
Iter: 1655 loss: 2.2458978e-06
Iter: 1656 loss: 2.25884651e-06
Iter: 1657 loss: 2.24588257e-06
Iter: 1658 loss: 2.24520227e-06
Iter: 1659 loss: 2.2449376e-06
Iter: 1660 loss: 2.24455493e-06
Iter: 1661 loss: 2.24360019e-06
Iter: 1662 loss: 2.24557698e-06
Iter: 1663 loss: 2.24326413e-06
Iter: 1664 loss: 2.24208725e-06
Iter: 1665 loss: 2.2443603e-06
Iter: 1666 loss: 2.24161249e-06
Iter: 1667 loss: 2.24045039e-06
Iter: 1668 loss: 2.24187716e-06
Iter: 1669 loss: 2.23985489e-06
Iter: 1670 loss: 2.23899588e-06
Iter: 1671 loss: 2.23897405e-06
Iter: 1672 loss: 2.23829375e-06
Iter: 1673 loss: 2.23734219e-06
Iter: 1674 loss: 2.23734742e-06
Iter: 1675 loss: 2.23665984e-06
Iter: 1676 loss: 2.23658662e-06
Iter: 1677 loss: 2.23597726e-06
Iter: 1678 loss: 2.23510278e-06
Iter: 1679 loss: 2.23505e-06
Iter: 1680 loss: 2.23410279e-06
Iter: 1681 loss: 2.24160067e-06
Iter: 1682 loss: 2.23405755e-06
Iter: 1683 loss: 2.23327925e-06
Iter: 1684 loss: 2.23264487e-06
Iter: 1685 loss: 2.2324316e-06
Iter: 1686 loss: 2.23140478e-06
Iter: 1687 loss: 2.23459028e-06
Iter: 1688 loss: 2.23111283e-06
Iter: 1689 loss: 2.23003e-06
Iter: 1690 loss: 2.23702682e-06
Iter: 1691 loss: 2.22988228e-06
Iter: 1692 loss: 2.22899507e-06
Iter: 1693 loss: 2.22841095e-06
Iter: 1694 loss: 2.22807284e-06
Iter: 1695 loss: 2.2267252e-06
Iter: 1696 loss: 2.23174811e-06
Iter: 1697 loss: 2.22638892e-06
Iter: 1698 loss: 2.22510857e-06
Iter: 1699 loss: 2.22759854e-06
Iter: 1700 loss: 2.22454696e-06
Iter: 1701 loss: 2.22352787e-06
Iter: 1702 loss: 2.23082543e-06
Iter: 1703 loss: 2.22345034e-06
Iter: 1704 loss: 2.22237304e-06
Iter: 1705 loss: 2.22662857e-06
Iter: 1706 loss: 2.22212e-06
Iter: 1707 loss: 2.2214781e-06
Iter: 1708 loss: 2.22274184e-06
Iter: 1709 loss: 2.22125595e-06
Iter: 1710 loss: 2.22039262e-06
Iter: 1711 loss: 2.22529934e-06
Iter: 1712 loss: 2.22026938e-06
Iter: 1713 loss: 2.21971413e-06
Iter: 1714 loss: 2.21945493e-06
Iter: 1715 loss: 2.21920618e-06
Iter: 1716 loss: 2.21827122e-06
Iter: 1717 loss: 2.22160202e-06
Iter: 1718 loss: 2.21805089e-06
Iter: 1719 loss: 2.21726827e-06
Iter: 1720 loss: 2.21634014e-06
Iter: 1721 loss: 2.21624e-06
Iter: 1722 loss: 2.2150241e-06
Iter: 1723 loss: 2.22656581e-06
Iter: 1724 loss: 2.21499545e-06
Iter: 1725 loss: 2.21390565e-06
Iter: 1726 loss: 2.21691676e-06
Iter: 1727 loss: 2.21356e-06
Iter: 1728 loss: 2.21273717e-06
Iter: 1729 loss: 2.21328537e-06
Iter: 1730 loss: 2.21223399e-06
Iter: 1731 loss: 2.21122946e-06
Iter: 1732 loss: 2.21520372e-06
Iter: 1733 loss: 2.21101527e-06
Iter: 1734 loss: 2.21012124e-06
Iter: 1735 loss: 2.21141318e-06
Iter: 1736 loss: 2.20972106e-06
Iter: 1737 loss: 2.20913944e-06
Iter: 1738 loss: 2.20913148e-06
Iter: 1739 loss: 2.20857282e-06
Iter: 1740 loss: 2.20795391e-06
Iter: 1741 loss: 2.20785637e-06
Iter: 1742 loss: 2.20745869e-06
Iter: 1743 loss: 2.20740731e-06
Iter: 1744 loss: 2.20693073e-06
Iter: 1745 loss: 2.20600054e-06
Iter: 1746 loss: 2.22482458e-06
Iter: 1747 loss: 2.2059744e-06
Iter: 1748 loss: 2.20508537e-06
Iter: 1749 loss: 2.21148775e-06
Iter: 1750 loss: 2.20497e-06
Iter: 1751 loss: 2.20413631e-06
Iter: 1752 loss: 2.20456786e-06
Iter: 1753 loss: 2.2035747e-06
Iter: 1754 loss: 2.20274978e-06
Iter: 1755 loss: 2.202921e-06
Iter: 1756 loss: 2.20214133e-06
Iter: 1757 loss: 2.2011584e-06
Iter: 1758 loss: 2.21249934e-06
Iter: 1759 loss: 2.20113884e-06
Iter: 1760 loss: 2.20044763e-06
Iter: 1761 loss: 2.20065249e-06
Iter: 1762 loss: 2.19991534e-06
Iter: 1763 loss: 2.1990154e-06
Iter: 1764 loss: 2.19986941e-06
Iter: 1765 loss: 2.19850881e-06
Iter: 1766 loss: 2.19734738e-06
Iter: 1767 loss: 2.20135303e-06
Iter: 1768 loss: 2.19705476e-06
Iter: 1769 loss: 2.19603317e-06
Iter: 1770 loss: 2.19811159e-06
Iter: 1771 loss: 2.19563299e-06
Iter: 1772 loss: 2.19468211e-06
Iter: 1773 loss: 2.2093177e-06
Iter: 1774 loss: 2.19468347e-06
Iter: 1775 loss: 2.19404092e-06
Iter: 1776 loss: 2.19330013e-06
Iter: 1777 loss: 2.19322328e-06
Iter: 1778 loss: 2.19262756e-06
Iter: 1779 loss: 2.19252888e-06
Iter: 1780 loss: 2.19209869e-06
Iter: 1781 loss: 2.19119852e-06
Iter: 1782 loss: 2.20221e-06
Iter: 1783 loss: 2.19111575e-06
Iter: 1784 loss: 2.19022832e-06
Iter: 1785 loss: 2.20291804e-06
Iter: 1786 loss: 2.19024355e-06
Iter: 1787 loss: 2.18963578e-06
Iter: 1788 loss: 2.18936884e-06
Iter: 1789 loss: 2.1890728e-06
Iter: 1790 loss: 2.18828927e-06
Iter: 1791 loss: 2.18924515e-06
Iter: 1792 loss: 2.18786795e-06
Iter: 1793 loss: 2.18669311e-06
Iter: 1794 loss: 2.19283311e-06
Iter: 1795 loss: 2.18650712e-06
Iter: 1796 loss: 2.18565856e-06
Iter: 1797 loss: 2.18625269e-06
Iter: 1798 loss: 2.18513924e-06
Iter: 1799 loss: 2.18416199e-06
Iter: 1800 loss: 2.18596801e-06
Iter: 1801 loss: 2.18374953e-06
Iter: 1802 loss: 2.18265268e-06
Iter: 1803 loss: 2.18538685e-06
Iter: 1804 loss: 2.1822666e-06
Iter: 1805 loss: 2.18131731e-06
Iter: 1806 loss: 2.18714172e-06
Iter: 1807 loss: 2.18119203e-06
Iter: 1808 loss: 2.18009268e-06
Iter: 1809 loss: 2.18397076e-06
Iter: 1810 loss: 2.17984416e-06
Iter: 1811 loss: 2.17920206e-06
Iter: 1812 loss: 2.18225387e-06
Iter: 1813 loss: 2.17912134e-06
Iter: 1814 loss: 2.17837601e-06
Iter: 1815 loss: 2.1799483e-06
Iter: 1816 loss: 2.17808861e-06
Iter: 1817 loss: 2.17762499e-06
Iter: 1818 loss: 2.17732941e-06
Iter: 1819 loss: 2.17713932e-06
Iter: 1820 loss: 2.17625643e-06
Iter: 1821 loss: 2.18001151e-06
Iter: 1822 loss: 2.1760618e-06
Iter: 1823 loss: 2.17536899e-06
Iter: 1824 loss: 2.17490901e-06
Iter: 1825 loss: 2.17467459e-06
Iter: 1826 loss: 2.17372417e-06
Iter: 1827 loss: 2.18013543e-06
Iter: 1828 loss: 2.17362503e-06
Iter: 1829 loss: 2.17267711e-06
Iter: 1830 loss: 2.17446177e-06
Iter: 1831 loss: 2.17225079e-06
Iter: 1832 loss: 2.1714302e-06
Iter: 1833 loss: 2.17239131e-06
Iter: 1834 loss: 2.17100137e-06
Iter: 1835 loss: 2.16994363e-06
Iter: 1836 loss: 2.17127604e-06
Iter: 1837 loss: 2.16941521e-06
Iter: 1838 loss: 2.16827539e-06
Iter: 1839 loss: 2.17342017e-06
Iter: 1840 loss: 2.16802982e-06
Iter: 1841 loss: 2.16726198e-06
Iter: 1842 loss: 2.17713841e-06
Iter: 1843 loss: 2.16725766e-06
Iter: 1844 loss: 2.1666051e-06
Iter: 1845 loss: 2.16649869e-06
Iter: 1846 loss: 2.16600597e-06
Iter: 1847 loss: 2.16546982e-06
Iter: 1848 loss: 2.16543685e-06
Iter: 1849 loss: 2.16497529e-06
Iter: 1850 loss: 2.16395392e-06
Iter: 1851 loss: 2.17908064e-06
Iter: 1852 loss: 2.16391823e-06
Iter: 1853 loss: 2.16308467e-06
Iter: 1854 loss: 2.17069737e-06
Iter: 1855 loss: 2.16306125e-06
Iter: 1856 loss: 2.16223793e-06
Iter: 1857 loss: 2.16248213e-06
Iter: 1858 loss: 2.16166154e-06
Iter: 1859 loss: 2.16084277e-06
Iter: 1860 loss: 2.16157832e-06
Iter: 1861 loss: 2.16035187e-06
Iter: 1862 loss: 2.15949694e-06
Iter: 1863 loss: 2.16905983e-06
Iter: 1864 loss: 2.15949058e-06
Iter: 1865 loss: 2.15873388e-06
Iter: 1866 loss: 2.15821979e-06
Iter: 1867 loss: 2.15793e-06
Iter: 1868 loss: 2.15691875e-06
Iter: 1869 loss: 2.16054013e-06
Iter: 1870 loss: 2.15668592e-06
Iter: 1871 loss: 2.15569662e-06
Iter: 1872 loss: 2.15656246e-06
Iter: 1873 loss: 2.15508749e-06
Iter: 1874 loss: 2.15387854e-06
Iter: 1875 loss: 2.16087892e-06
Iter: 1876 loss: 2.15375303e-06
Iter: 1877 loss: 2.15280079e-06
Iter: 1878 loss: 2.16130866e-06
Iter: 1879 loss: 2.15274713e-06
Iter: 1880 loss: 2.15203409e-06
Iter: 1881 loss: 2.15248474e-06
Iter: 1882 loss: 2.15155956e-06
Iter: 1883 loss: 2.15053251e-06
Iter: 1884 loss: 2.15733439e-06
Iter: 1885 loss: 2.15042837e-06
Iter: 1886 loss: 2.14987676e-06
Iter: 1887 loss: 2.14891224e-06
Iter: 1888 loss: 2.14891065e-06
Iter: 1889 loss: 2.14815486e-06
Iter: 1890 loss: 2.14814645e-06
Iter: 1891 loss: 2.14754891e-06
Iter: 1892 loss: 2.14661577e-06
Iter: 1893 loss: 2.14659e-06
Iter: 1894 loss: 2.14562374e-06
Iter: 1895 loss: 2.15166551e-06
Iter: 1896 loss: 2.14553e-06
Iter: 1897 loss: 2.14472584e-06
Iter: 1898 loss: 2.15047567e-06
Iter: 1899 loss: 2.14465581e-06
Iter: 1900 loss: 2.1440037e-06
Iter: 1901 loss: 2.14314105e-06
Iter: 1902 loss: 2.1430892e-06
Iter: 1903 loss: 2.14191e-06
Iter: 1904 loss: 2.14873648e-06
Iter: 1905 loss: 2.14178e-06
Iter: 1906 loss: 2.14083411e-06
Iter: 1907 loss: 2.14171314e-06
Iter: 1908 loss: 2.1402775e-06
Iter: 1909 loss: 2.13935573e-06
Iter: 1910 loss: 2.15294017e-06
Iter: 1911 loss: 2.13934572e-06
Iter: 1912 loss: 2.13865724e-06
Iter: 1913 loss: 2.1406463e-06
Iter: 1914 loss: 2.13845078e-06
Iter: 1915 loss: 2.13797284e-06
Iter: 1916 loss: 2.14310967e-06
Iter: 1917 loss: 2.1379476e-06
Iter: 1918 loss: 2.13749172e-06
Iter: 1919 loss: 2.13667113e-06
Iter: 1920 loss: 2.13666453e-06
Iter: 1921 loss: 2.13596718e-06
Iter: 1922 loss: 2.13800968e-06
Iter: 1923 loss: 2.1357605e-06
Iter: 1924 loss: 2.13494832e-06
Iter: 1925 loss: 2.13997669e-06
Iter: 1926 loss: 2.13484736e-06
Iter: 1927 loss: 2.13425346e-06
Iter: 1928 loss: 2.13311614e-06
Iter: 1929 loss: 2.15688328e-06
Iter: 1930 loss: 2.13311614e-06
Iter: 1931 loss: 2.13217982e-06
Iter: 1932 loss: 2.13216663e-06
Iter: 1933 loss: 2.13140379e-06
Iter: 1934 loss: 2.13284216e-06
Iter: 1935 loss: 2.13108387e-06
Iter: 1936 loss: 2.13037629e-06
Iter: 1937 loss: 2.13032354e-06
Iter: 1938 loss: 2.12979785e-06
Iter: 1939 loss: 2.12894975e-06
Iter: 1940 loss: 2.13491194e-06
Iter: 1941 loss: 2.12887267e-06
Iter: 1942 loss: 2.12821851e-06
Iter: 1943 loss: 2.12891882e-06
Iter: 1944 loss: 2.12785721e-06
Iter: 1945 loss: 2.12711939e-06
Iter: 1946 loss: 2.13683779e-06
Iter: 1947 loss: 2.12711166e-06
Iter: 1948 loss: 2.12660598e-06
Iter: 1949 loss: 2.12728719e-06
Iter: 1950 loss: 2.12636542e-06
Iter: 1951 loss: 2.1257606e-06
Iter: 1952 loss: 2.13047633e-06
Iter: 1953 loss: 2.12575537e-06
Iter: 1954 loss: 2.1253361e-06
Iter: 1955 loss: 2.12433361e-06
Iter: 1956 loss: 2.1342621e-06
Iter: 1957 loss: 2.12419263e-06
Iter: 1958 loss: 2.12335635e-06
Iter: 1959 loss: 2.13642079e-06
Iter: 1960 loss: 2.12336545e-06
Iter: 1961 loss: 2.12255509e-06
Iter: 1962 loss: 2.12315285e-06
Iter: 1963 loss: 2.1220726e-06
Iter: 1964 loss: 2.12132272e-06
Iter: 1965 loss: 2.12141276e-06
Iter: 1966 loss: 2.12074087e-06
Iter: 1967 loss: 2.12002487e-06
Iter: 1968 loss: 2.12002624e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2
+ date
Mon Nov  2 11:28:16 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3503e7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3502d99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35041f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3502c7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd350353c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3502d91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3501f0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd350257158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3501ee488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3500bd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3500bd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd350141048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd350141d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3502901e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3502a27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3500f1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3500daf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd350181ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd350162d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3501812f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3045896a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35001c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd304589f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd30461bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3046596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd304426ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd304504510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd304426268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd30447d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3044980d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd30446a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3043be0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3043be6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd30452dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3044121e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3043dc598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0018453135
test_loss: 0.0017924452
train_loss: 0.00053469377
test_loss: 0.0005321891
train_loss: 0.00023735821
test_loss: 0.0002548992
train_loss: 0.00015670437
test_loss: 0.00016237693
train_loss: 0.000114766975
test_loss: 0.0001172634
train_loss: 8.528806e-05
test_loss: 9.009464e-05
train_loss: 6.7127316e-05
test_loss: 7.133973e-05
train_loss: 5.541739e-05
test_loss: 5.9022568e-05
train_loss: 4.4982695e-05
test_loss: 4.969199e-05
train_loss: 4.1143056e-05
test_loss: 4.2440326e-05
train_loss: 3.48033e-05
test_loss: 3.6861427e-05
train_loss: 3.2195367e-05
test_loss: 3.2639793e-05
train_loss: 2.8108469e-05
test_loss: 2.9156907e-05
train_loss: 2.7177275e-05
test_loss: 2.6573558e-05
train_loss: 2.4648403e-05
test_loss: 2.447309e-05
train_loss: 2.1651962e-05
test_loss: 2.2593498e-05
train_loss: 1.9788306e-05
test_loss: 2.1236325e-05
train_loss: 1.7499302e-05
test_loss: 1.9741361e-05
train_loss: 1.8898301e-05
test_loss: 1.8713652e-05
train_loss: 1.6751315e-05
test_loss: 1.7760794e-05
train_loss: 1.6943275e-05
test_loss: 1.678932e-05
train_loss: 1.43457155e-05
test_loss: 1.6239645e-05
train_loss: 1.5942607e-05
test_loss: 1.5485588e-05
train_loss: 1.3318094e-05
test_loss: 1.4876999e-05
train_loss: 1.4373114e-05
test_loss: 1.44414425e-05
train_loss: 1.2630577e-05
test_loss: 1.3872773e-05
train_loss: 1.2229868e-05
test_loss: 1.3566714e-05
train_loss: 1.2255876e-05
test_loss: 1.3132085e-05
train_loss: 1.1962674e-05
test_loss: 1.2748236e-05
train_loss: 1.12209655e-05
test_loss: 1.244747e-05
train_loss: 1.1464549e-05
test_loss: 1.2044887e-05
train_loss: 1.1333241e-05
test_loss: 1.1811697e-05
train_loss: 1.05064455e-05
test_loss: 1.16063375e-05
train_loss: 1.1107525e-05
test_loss: 1.1383555e-05
train_loss: 1.0096284e-05
test_loss: 1.1213633e-05
train_loss: 1.0245614e-05
test_loss: 1.09488765e-05
train_loss: 9.893438e-06
test_loss: 1.07945225e-05
train_loss: 9.732028e-06
test_loss: 1.0643279e-05
train_loss: 1.0202171e-05
test_loss: 1.0479486e-05
train_loss: 9.129408e-06
test_loss: 1.035421e-05
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff25697dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff25694e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff25695ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2569fe620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff256925598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff256925840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff25682bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff256868a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff256868158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff25687a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2568686a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff25687a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22dae2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22db861e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22db5ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22da79ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22da87e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22db55268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2081a7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff22da872f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff20816f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff20818a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff208151510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080f5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080f57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080f8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080a6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080a6c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff20806f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080302f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff20806f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff20806f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff1f00a9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2080306a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff1f00a9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff20804b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.614394e-06
Iter: 2 loss: 9.54772713e-06
Iter: 3 loss: 9.5338e-06
Iter: 4 loss: 9.49547757e-06
Iter: 5 loss: 1.0092479e-05
Iter: 6 loss: 9.49546666e-06
Iter: 7 loss: 9.48023899e-06
Iter: 8 loss: 9.47345143e-06
Iter: 9 loss: 9.46581713e-06
Iter: 10 loss: 9.44887e-06
Iter: 11 loss: 9.49119931e-06
Iter: 12 loss: 9.44297608e-06
Iter: 13 loss: 9.43306259e-06
Iter: 14 loss: 9.48424713e-06
Iter: 15 loss: 9.43159102e-06
Iter: 16 loss: 9.42357201e-06
Iter: 17 loss: 9.42645238e-06
Iter: 18 loss: 9.41802591e-06
Iter: 19 loss: 9.41282542e-06
Iter: 20 loss: 9.41282633e-06
Iter: 21 loss: 9.40917198e-06
Iter: 22 loss: 9.40906193e-06
Iter: 23 loss: 9.40619066e-06
Iter: 24 loss: 9.40195241e-06
Iter: 25 loss: 9.40393511e-06
Iter: 26 loss: 9.3990393e-06
Iter: 27 loss: 9.39502479e-06
Iter: 28 loss: 9.39497841e-06
Iter: 29 loss: 9.39133679e-06
Iter: 30 loss: 9.38416633e-06
Iter: 31 loss: 9.52642313e-06
Iter: 32 loss: 9.3841054e-06
Iter: 33 loss: 9.37631e-06
Iter: 34 loss: 9.41925282e-06
Iter: 35 loss: 9.37514778e-06
Iter: 36 loss: 9.36787364e-06
Iter: 37 loss: 9.36630931e-06
Iter: 38 loss: 9.36148354e-06
Iter: 39 loss: 9.37428194e-06
Iter: 40 loss: 9.3585486e-06
Iter: 41 loss: 9.35640128e-06
Iter: 42 loss: 9.35034495e-06
Iter: 43 loss: 9.38023e-06
Iter: 44 loss: 9.34840318e-06
Iter: 45 loss: 9.34087439e-06
Iter: 46 loss: 9.3731469e-06
Iter: 47 loss: 9.33915635e-06
Iter: 48 loss: 9.33060619e-06
Iter: 49 loss: 9.34492436e-06
Iter: 50 loss: 9.32674448e-06
Iter: 51 loss: 9.31898649e-06
Iter: 52 loss: 9.32946e-06
Iter: 53 loss: 9.31513e-06
Iter: 54 loss: 9.30636e-06
Iter: 55 loss: 9.34807213e-06
Iter: 56 loss: 9.3047729e-06
Iter: 57 loss: 9.29710131e-06
Iter: 58 loss: 9.32280454e-06
Iter: 59 loss: 9.29497219e-06
Iter: 60 loss: 9.28901864e-06
Iter: 61 loss: 9.30586248e-06
Iter: 62 loss: 9.28709233e-06
Iter: 63 loss: 9.28030931e-06
Iter: 64 loss: 9.28151258e-06
Iter: 65 loss: 9.27524707e-06
Iter: 66 loss: 9.2672708e-06
Iter: 67 loss: 9.28901227e-06
Iter: 68 loss: 9.26462144e-06
Iter: 69 loss: 9.25620952e-06
Iter: 70 loss: 9.31072282e-06
Iter: 71 loss: 9.25535e-06
Iter: 72 loss: 9.24792221e-06
Iter: 73 loss: 9.24638243e-06
Iter: 74 loss: 9.24147389e-06
Iter: 75 loss: 9.23484913e-06
Iter: 76 loss: 9.30064652e-06
Iter: 77 loss: 9.2346645e-06
Iter: 78 loss: 9.22493564e-06
Iter: 79 loss: 9.22518939e-06
Iter: 80 loss: 9.21723768e-06
Iter: 81 loss: 9.21136e-06
Iter: 82 loss: 9.20373623e-06
Iter: 83 loss: 9.20313414e-06
Iter: 84 loss: 9.193398e-06
Iter: 85 loss: 9.27199108e-06
Iter: 86 loss: 9.19276681e-06
Iter: 87 loss: 9.18411388e-06
Iter: 88 loss: 9.21514402e-06
Iter: 89 loss: 9.18189471e-06
Iter: 90 loss: 9.17520447e-06
Iter: 91 loss: 9.16532736e-06
Iter: 92 loss: 9.16504632e-06
Iter: 93 loss: 9.15675628e-06
Iter: 94 loss: 9.15650799e-06
Iter: 95 loss: 9.14863449e-06
Iter: 96 loss: 9.13602526e-06
Iter: 97 loss: 9.13587155e-06
Iter: 98 loss: 9.12481664e-06
Iter: 99 loss: 9.28245572e-06
Iter: 100 loss: 9.12483665e-06
Iter: 101 loss: 9.11593452e-06
Iter: 102 loss: 9.10904782e-06
Iter: 103 loss: 9.10626659e-06
Iter: 104 loss: 9.0928952e-06
Iter: 105 loss: 9.15316e-06
Iter: 106 loss: 9.09031223e-06
Iter: 107 loss: 9.07669619e-06
Iter: 108 loss: 9.11024836e-06
Iter: 109 loss: 9.07188405e-06
Iter: 110 loss: 9.0550293e-06
Iter: 111 loss: 9.05901834e-06
Iter: 112 loss: 9.04268381e-06
Iter: 113 loss: 9.02806823e-06
Iter: 114 loss: 9.10652125e-06
Iter: 115 loss: 9.02589545e-06
Iter: 116 loss: 9.01390558e-06
Iter: 117 loss: 9.01375279e-06
Iter: 118 loss: 9.00756459e-06
Iter: 119 loss: 8.99124916e-06
Iter: 120 loss: 9.11076313e-06
Iter: 121 loss: 8.98773396e-06
Iter: 122 loss: 8.96792517e-06
Iter: 123 loss: 8.97755854e-06
Iter: 124 loss: 8.95467929e-06
Iter: 125 loss: 8.93846573e-06
Iter: 126 loss: 8.93793e-06
Iter: 127 loss: 8.92324533e-06
Iter: 128 loss: 8.93118431e-06
Iter: 129 loss: 8.91370382e-06
Iter: 130 loss: 8.89927469e-06
Iter: 131 loss: 8.89103649e-06
Iter: 132 loss: 8.88477e-06
Iter: 133 loss: 8.86725684e-06
Iter: 134 loss: 9.14078646e-06
Iter: 135 loss: 8.86726684e-06
Iter: 136 loss: 8.85260579e-06
Iter: 137 loss: 8.86308953e-06
Iter: 138 loss: 8.84361543e-06
Iter: 139 loss: 8.8278739e-06
Iter: 140 loss: 8.87490296e-06
Iter: 141 loss: 8.82306631e-06
Iter: 142 loss: 8.80790867e-06
Iter: 143 loss: 8.86073212e-06
Iter: 144 loss: 8.8039651e-06
Iter: 145 loss: 8.79062736e-06
Iter: 146 loss: 8.78436e-06
Iter: 147 loss: 8.77783714e-06
Iter: 148 loss: 8.76539525e-06
Iter: 149 loss: 8.76460763e-06
Iter: 150 loss: 8.75648402e-06
Iter: 151 loss: 8.84742713e-06
Iter: 152 loss: 8.75627484e-06
Iter: 153 loss: 8.75048863e-06
Iter: 154 loss: 8.73530189e-06
Iter: 155 loss: 8.85057125e-06
Iter: 156 loss: 8.73224144e-06
Iter: 157 loss: 8.71280827e-06
Iter: 158 loss: 8.74434591e-06
Iter: 159 loss: 8.70392523e-06
Iter: 160 loss: 8.6856362e-06
Iter: 161 loss: 8.78631545e-06
Iter: 162 loss: 8.68304505e-06
Iter: 163 loss: 8.66153277e-06
Iter: 164 loss: 8.71879547e-06
Iter: 165 loss: 8.65440597e-06
Iter: 166 loss: 8.6355376e-06
Iter: 167 loss: 8.65376205e-06
Iter: 168 loss: 8.62486468e-06
Iter: 169 loss: 8.60446926e-06
Iter: 170 loss: 8.62142224e-06
Iter: 171 loss: 8.59236934e-06
Iter: 172 loss: 8.57262148e-06
Iter: 173 loss: 8.57263876e-06
Iter: 174 loss: 8.56027054e-06
Iter: 175 loss: 8.54409882e-06
Iter: 176 loss: 8.54300561e-06
Iter: 177 loss: 8.52392714e-06
Iter: 178 loss: 8.71082557e-06
Iter: 179 loss: 8.52320136e-06
Iter: 180 loss: 8.5091724e-06
Iter: 181 loss: 8.53171696e-06
Iter: 182 loss: 8.50253127e-06
Iter: 183 loss: 8.49588469e-06
Iter: 184 loss: 8.49456137e-06
Iter: 185 loss: 8.48661512e-06
Iter: 186 loss: 8.47684896e-06
Iter: 187 loss: 8.4759713e-06
Iter: 188 loss: 8.46127841e-06
Iter: 189 loss: 8.47283263e-06
Iter: 190 loss: 8.452359e-06
Iter: 191 loss: 8.43950602e-06
Iter: 192 loss: 8.42887493e-06
Iter: 193 loss: 8.42515692e-06
Iter: 194 loss: 8.39904715e-06
Iter: 195 loss: 8.49261232e-06
Iter: 196 loss: 8.39236145e-06
Iter: 197 loss: 8.37196603e-06
Iter: 198 loss: 8.66876508e-06
Iter: 199 loss: 8.37192056e-06
Iter: 200 loss: 8.3607265e-06
Iter: 201 loss: 8.33718e-06
Iter: 202 loss: 8.73243516e-06
Iter: 203 loss: 8.33670856e-06
Iter: 204 loss: 8.31226498e-06
Iter: 205 loss: 8.55779399e-06
Iter: 206 loss: 8.3115192e-06
Iter: 207 loss: 8.29508e-06
Iter: 208 loss: 8.40815119e-06
Iter: 209 loss: 8.29353e-06
Iter: 210 loss: 8.27831173e-06
Iter: 211 loss: 8.25690859e-06
Iter: 212 loss: 8.25609641e-06
Iter: 213 loss: 8.23180562e-06
Iter: 214 loss: 8.41819e-06
Iter: 215 loss: 8.23007576e-06
Iter: 216 loss: 8.21318463e-06
Iter: 217 loss: 8.3090863e-06
Iter: 218 loss: 8.2108636e-06
Iter: 219 loss: 8.19871457e-06
Iter: 220 loss: 8.19874549e-06
Iter: 221 loss: 8.18843546e-06
Iter: 222 loss: 8.17168075e-06
Iter: 223 loss: 8.17153159e-06
Iter: 224 loss: 8.1548169e-06
Iter: 225 loss: 8.18715216e-06
Iter: 226 loss: 8.14787563e-06
Iter: 227 loss: 8.12600047e-06
Iter: 228 loss: 8.1282451e-06
Iter: 229 loss: 8.10923666e-06
Iter: 230 loss: 8.08497134e-06
Iter: 231 loss: 8.17731598e-06
Iter: 232 loss: 8.07928154e-06
Iter: 233 loss: 8.05920354e-06
Iter: 234 loss: 8.28514567e-06
Iter: 235 loss: 8.05881064e-06
Iter: 236 loss: 8.04085084e-06
Iter: 237 loss: 8.01371e-06
Iter: 238 loss: 8.01323404e-06
Iter: 239 loss: 7.99209374e-06
Iter: 240 loss: 8.21762114e-06
Iter: 241 loss: 7.99157624e-06
Iter: 242 loss: 7.97155e-06
Iter: 243 loss: 8.03149123e-06
Iter: 244 loss: 7.96553923e-06
Iter: 245 loss: 7.94563312e-06
Iter: 246 loss: 7.95183314e-06
Iter: 247 loss: 7.93140498e-06
Iter: 248 loss: 7.91103776e-06
Iter: 249 loss: 7.97102803e-06
Iter: 250 loss: 7.90475497e-06
Iter: 251 loss: 7.88914804e-06
Iter: 252 loss: 7.88899e-06
Iter: 253 loss: 7.87421413e-06
Iter: 254 loss: 7.91887487e-06
Iter: 255 loss: 7.86972942e-06
Iter: 256 loss: 7.86043347e-06
Iter: 257 loss: 7.8545e-06
Iter: 258 loss: 7.85081465e-06
Iter: 259 loss: 7.83505948e-06
Iter: 260 loss: 7.83251744e-06
Iter: 261 loss: 7.82167444e-06
Iter: 262 loss: 7.80108167e-06
Iter: 263 loss: 7.96415225e-06
Iter: 264 loss: 7.79967104e-06
Iter: 265 loss: 7.78347203e-06
Iter: 266 loss: 7.77077457e-06
Iter: 267 loss: 7.76578236e-06
Iter: 268 loss: 7.75176704e-06
Iter: 269 loss: 7.74946875e-06
Iter: 270 loss: 7.74033651e-06
Iter: 271 loss: 7.72214662e-06
Iter: 272 loss: 8.0737982e-06
Iter: 273 loss: 7.72192652e-06
Iter: 274 loss: 7.70249517e-06
Iter: 275 loss: 7.84575877e-06
Iter: 276 loss: 7.70091538e-06
Iter: 277 loss: 7.68244172e-06
Iter: 278 loss: 7.77118294e-06
Iter: 279 loss: 7.67910478e-06
Iter: 280 loss: 7.66531775e-06
Iter: 281 loss: 7.64604192e-06
Iter: 282 loss: 7.6452161e-06
Iter: 283 loss: 7.62291802e-06
Iter: 284 loss: 7.70788483e-06
Iter: 285 loss: 7.61764159e-06
Iter: 286 loss: 7.60816511e-06
Iter: 287 loss: 7.6029487e-06
Iter: 288 loss: 7.59348404e-06
Iter: 289 loss: 7.57572798e-06
Iter: 290 loss: 7.97866596e-06
Iter: 291 loss: 7.57569251e-06
Iter: 292 loss: 7.55439896e-06
Iter: 293 loss: 7.57636599e-06
Iter: 294 loss: 7.54263874e-06
Iter: 295 loss: 7.51781226e-06
Iter: 296 loss: 7.59681598e-06
Iter: 297 loss: 7.51077778e-06
Iter: 298 loss: 7.48852744e-06
Iter: 299 loss: 7.56873942e-06
Iter: 300 loss: 7.4828904e-06
Iter: 301 loss: 7.46337446e-06
Iter: 302 loss: 7.53144695e-06
Iter: 303 loss: 7.45831858e-06
Iter: 304 loss: 7.44189038e-06
Iter: 305 loss: 7.56943564e-06
Iter: 306 loss: 7.44068711e-06
Iter: 307 loss: 7.42756174e-06
Iter: 308 loss: 7.42185421e-06
Iter: 309 loss: 7.41512304e-06
Iter: 310 loss: 7.39680399e-06
Iter: 311 loss: 7.39989173e-06
Iter: 312 loss: 7.38310928e-06
Iter: 313 loss: 7.36620859e-06
Iter: 314 loss: 7.36594939e-06
Iter: 315 loss: 7.35222284e-06
Iter: 316 loss: 7.34867263e-06
Iter: 317 loss: 7.34002288e-06
Iter: 318 loss: 7.32546368e-06
Iter: 319 loss: 7.38338258e-06
Iter: 320 loss: 7.32213e-06
Iter: 321 loss: 7.30637885e-06
Iter: 322 loss: 7.43436703e-06
Iter: 323 loss: 7.30536431e-06
Iter: 324 loss: 7.29797e-06
Iter: 325 loss: 7.28079885e-06
Iter: 326 loss: 7.49628362e-06
Iter: 327 loss: 7.27953e-06
Iter: 328 loss: 7.25621976e-06
Iter: 329 loss: 7.30845568e-06
Iter: 330 loss: 7.24747133e-06
Iter: 331 loss: 7.2235448e-06
Iter: 332 loss: 7.41556869e-06
Iter: 333 loss: 7.2220173e-06
Iter: 334 loss: 7.206e-06
Iter: 335 loss: 7.20049184e-06
Iter: 336 loss: 7.19134277e-06
Iter: 337 loss: 7.16953173e-06
Iter: 338 loss: 7.37167466e-06
Iter: 339 loss: 7.16859586e-06
Iter: 340 loss: 7.15498572e-06
Iter: 341 loss: 7.19491754e-06
Iter: 342 loss: 7.15092165e-06
Iter: 343 loss: 7.13318059e-06
Iter: 344 loss: 7.14529506e-06
Iter: 345 loss: 7.1221e-06
Iter: 346 loss: 7.10563563e-06
Iter: 347 loss: 7.13059217e-06
Iter: 348 loss: 7.0978972e-06
Iter: 349 loss: 7.07812615e-06
Iter: 350 loss: 7.10174027e-06
Iter: 351 loss: 7.06770243e-06
Iter: 352 loss: 7.04985723e-06
Iter: 353 loss: 7.04987906e-06
Iter: 354 loss: 7.03853129e-06
Iter: 355 loss: 7.06364e-06
Iter: 356 loss: 7.03421574e-06
Iter: 357 loss: 7.01744057e-06
Iter: 358 loss: 7.07984054e-06
Iter: 359 loss: 7.01339877e-06
Iter: 360 loss: 7.00312603e-06
Iter: 361 loss: 6.97895439e-06
Iter: 362 loss: 7.25561222e-06
Iter: 363 loss: 6.97670202e-06
Iter: 364 loss: 6.95251492e-06
Iter: 365 loss: 7.11649e-06
Iter: 366 loss: 6.95022163e-06
Iter: 367 loss: 6.92783806e-06
Iter: 368 loss: 6.99794327e-06
Iter: 369 loss: 6.92134199e-06
Iter: 370 loss: 6.90177694e-06
Iter: 371 loss: 6.911539e-06
Iter: 372 loss: 6.88872296e-06
Iter: 373 loss: 6.86613657e-06
Iter: 374 loss: 7.02385296e-06
Iter: 375 loss: 6.86408839e-06
Iter: 376 loss: 6.8445479e-06
Iter: 377 loss: 6.88131604e-06
Iter: 378 loss: 6.83638427e-06
Iter: 379 loss: 6.81477786e-06
Iter: 380 loss: 6.92217782e-06
Iter: 381 loss: 6.81111487e-06
Iter: 382 loss: 6.79385357e-06
Iter: 383 loss: 6.78168408e-06
Iter: 384 loss: 6.77564276e-06
Iter: 385 loss: 6.75218234e-06
Iter: 386 loss: 6.85197756e-06
Iter: 387 loss: 6.74736748e-06
Iter: 388 loss: 6.72631359e-06
Iter: 389 loss: 6.74115972e-06
Iter: 390 loss: 6.71333692e-06
Iter: 391 loss: 6.71520866e-06
Iter: 392 loss: 6.70349755e-06
Iter: 393 loss: 6.69469136e-06
Iter: 394 loss: 6.68905795e-06
Iter: 395 loss: 6.6855946e-06
Iter: 396 loss: 6.67164477e-06
Iter: 397 loss: 6.68559278e-06
Iter: 398 loss: 6.66379128e-06
Iter: 399 loss: 6.64920481e-06
Iter: 400 loss: 6.65471816e-06
Iter: 401 loss: 6.63908349e-06
Iter: 402 loss: 6.62129241e-06
Iter: 403 loss: 6.69383917e-06
Iter: 404 loss: 6.61736613e-06
Iter: 405 loss: 6.59862508e-06
Iter: 406 loss: 6.64841627e-06
Iter: 407 loss: 6.59243233e-06
Iter: 408 loss: 6.57638384e-06
Iter: 409 loss: 6.58646422e-06
Iter: 410 loss: 6.5661975e-06
Iter: 411 loss: 6.5469676e-06
Iter: 412 loss: 6.66612414e-06
Iter: 413 loss: 6.54466476e-06
Iter: 414 loss: 6.5288923e-06
Iter: 415 loss: 6.58104227e-06
Iter: 416 loss: 6.52444578e-06
Iter: 417 loss: 6.51109667e-06
Iter: 418 loss: 6.58897443e-06
Iter: 419 loss: 6.50933407e-06
Iter: 420 loss: 6.49737194e-06
Iter: 421 loss: 6.49249114e-06
Iter: 422 loss: 6.48620062e-06
Iter: 423 loss: 6.47736942e-06
Iter: 424 loss: 6.47701427e-06
Iter: 425 loss: 6.46822355e-06
Iter: 426 loss: 6.49040248e-06
Iter: 427 loss: 6.46515355e-06
Iter: 428 loss: 6.45732234e-06
Iter: 429 loss: 6.45776936e-06
Iter: 430 loss: 6.45117416e-06
Iter: 431 loss: 6.44023976e-06
Iter: 432 loss: 6.45255659e-06
Iter: 433 loss: 6.43436806e-06
Iter: 434 loss: 6.42332088e-06
Iter: 435 loss: 6.43092426e-06
Iter: 436 loss: 6.4164683e-06
Iter: 437 loss: 6.40157668e-06
Iter: 438 loss: 6.45604814e-06
Iter: 439 loss: 6.39778909e-06
Iter: 440 loss: 6.3837274e-06
Iter: 441 loss: 6.41050246e-06
Iter: 442 loss: 6.37776247e-06
Iter: 443 loss: 6.36378354e-06
Iter: 444 loss: 6.37598623e-06
Iter: 445 loss: 6.35556626e-06
Iter: 446 loss: 6.33814307e-06
Iter: 447 loss: 6.46058e-06
Iter: 448 loss: 6.33656e-06
Iter: 449 loss: 6.32465571e-06
Iter: 450 loss: 6.37247e-06
Iter: 451 loss: 6.3219718e-06
Iter: 452 loss: 6.30935847e-06
Iter: 453 loss: 6.32458432e-06
Iter: 454 loss: 6.30275417e-06
Iter: 455 loss: 6.28847829e-06
Iter: 456 loss: 6.31053535e-06
Iter: 457 loss: 6.28179851e-06
Iter: 458 loss: 6.2786844e-06
Iter: 459 loss: 6.27429927e-06
Iter: 460 loss: 6.26988185e-06
Iter: 461 loss: 6.26099154e-06
Iter: 462 loss: 6.42649047e-06
Iter: 463 loss: 6.2608342e-06
Iter: 464 loss: 6.25015855e-06
Iter: 465 loss: 6.28745192e-06
Iter: 466 loss: 6.24734548e-06
Iter: 467 loss: 6.2375484e-06
Iter: 468 loss: 6.23867345e-06
Iter: 469 loss: 6.23003416e-06
Iter: 470 loss: 6.21858771e-06
Iter: 471 loss: 6.26402e-06
Iter: 472 loss: 6.21598656e-06
Iter: 473 loss: 6.20522678e-06
Iter: 474 loss: 6.24558288e-06
Iter: 475 loss: 6.2026038e-06
Iter: 476 loss: 6.19366801e-06
Iter: 477 loss: 6.19658476e-06
Iter: 478 loss: 6.18732975e-06
Iter: 479 loss: 6.17477735e-06
Iter: 480 loss: 6.20469382e-06
Iter: 481 loss: 6.17018759e-06
Iter: 482 loss: 6.15728914e-06
Iter: 483 loss: 6.24423228e-06
Iter: 484 loss: 6.15593626e-06
Iter: 485 loss: 6.14567671e-06
Iter: 486 loss: 6.16507e-06
Iter: 487 loss: 6.1414039e-06
Iter: 488 loss: 6.12821077e-06
Iter: 489 loss: 6.14047167e-06
Iter: 490 loss: 6.12069289e-06
Iter: 491 loss: 6.11167616e-06
Iter: 492 loss: 6.11147334e-06
Iter: 493 loss: 6.10202369e-06
Iter: 494 loss: 6.10285269e-06
Iter: 495 loss: 6.09465724e-06
Iter: 496 loss: 6.08581604e-06
Iter: 497 loss: 6.08832306e-06
Iter: 498 loss: 6.07944639e-06
Iter: 499 loss: 6.06563481e-06
Iter: 500 loss: 6.09201106e-06
Iter: 501 loss: 6.05987407e-06
Iter: 502 loss: 6.0473476e-06
Iter: 503 loss: 6.06238609e-06
Iter: 504 loss: 6.04087654e-06
Iter: 505 loss: 6.02944465e-06
Iter: 506 loss: 6.12284748e-06
Iter: 507 loss: 6.02875434e-06
Iter: 508 loss: 6.02043565e-06
Iter: 509 loss: 6.03116769e-06
Iter: 510 loss: 6.01623788e-06
Iter: 511 loss: 6.00656267e-06
Iter: 512 loss: 6.00892054e-06
Iter: 513 loss: 5.999515e-06
Iter: 514 loss: 5.98750239e-06
Iter: 515 loss: 6.07968241e-06
Iter: 516 loss: 5.98668e-06
Iter: 517 loss: 5.97759026e-06
Iter: 518 loss: 6.01809143e-06
Iter: 519 loss: 5.97571943e-06
Iter: 520 loss: 5.96675363e-06
Iter: 521 loss: 5.97328e-06
Iter: 522 loss: 5.9612621e-06
Iter: 523 loss: 5.9510644e-06
Iter: 524 loss: 6.02658383e-06
Iter: 525 loss: 5.9502554e-06
Iter: 526 loss: 5.94155881e-06
Iter: 527 loss: 6.02153659e-06
Iter: 528 loss: 5.94124776e-06
Iter: 529 loss: 5.93643426e-06
Iter: 530 loss: 5.92638571e-06
Iter: 531 loss: 6.09885956e-06
Iter: 532 loss: 5.92623928e-06
Iter: 533 loss: 5.91470871e-06
Iter: 534 loss: 5.97939243e-06
Iter: 535 loss: 5.913108e-06
Iter: 536 loss: 5.90257196e-06
Iter: 537 loss: 5.90321815e-06
Iter: 538 loss: 5.89434239e-06
Iter: 539 loss: 5.88163e-06
Iter: 540 loss: 5.91977e-06
Iter: 541 loss: 5.87776049e-06
Iter: 542 loss: 5.86453734e-06
Iter: 543 loss: 5.9177969e-06
Iter: 544 loss: 5.86160741e-06
Iter: 545 loss: 5.84990494e-06
Iter: 546 loss: 5.85482621e-06
Iter: 547 loss: 5.84191e-06
Iter: 548 loss: 5.82739358e-06
Iter: 549 loss: 5.87105842e-06
Iter: 550 loss: 5.82308166e-06
Iter: 551 loss: 5.80992219e-06
Iter: 552 loss: 5.90840227e-06
Iter: 553 loss: 5.80891901e-06
Iter: 554 loss: 5.79874722e-06
Iter: 555 loss: 5.83356041e-06
Iter: 556 loss: 5.79608422e-06
Iter: 557 loss: 5.7867951e-06
Iter: 558 loss: 5.80140295e-06
Iter: 559 loss: 5.78250456e-06
Iter: 560 loss: 5.7768e-06
Iter: 561 loss: 5.77615356e-06
Iter: 562 loss: 5.77114406e-06
Iter: 563 loss: 5.76078537e-06
Iter: 564 loss: 5.93793948e-06
Iter: 565 loss: 5.7605057e-06
Iter: 566 loss: 5.75033164e-06
Iter: 567 loss: 5.78057598e-06
Iter: 568 loss: 5.74725618e-06
Iter: 569 loss: 5.73745e-06
Iter: 570 loss: 5.78120262e-06
Iter: 571 loss: 5.73545913e-06
Iter: 572 loss: 5.72775389e-06
Iter: 573 loss: 5.72477438e-06
Iter: 574 loss: 5.72057115e-06
Iter: 575 loss: 5.70902921e-06
Iter: 576 loss: 5.77452e-06
Iter: 577 loss: 5.70740303e-06
Iter: 578 loss: 5.69772419e-06
Iter: 579 loss: 5.71729333e-06
Iter: 580 loss: 5.69388067e-06
Iter: 581 loss: 5.68354881e-06
Iter: 582 loss: 5.68597898e-06
Iter: 583 loss: 5.67600637e-06
Iter: 584 loss: 5.66459403e-06
Iter: 585 loss: 5.76483171e-06
Iter: 586 loss: 5.66404833e-06
Iter: 587 loss: 5.65473238e-06
Iter: 588 loss: 5.68152791e-06
Iter: 589 loss: 5.65190294e-06
Iter: 590 loss: 5.64205175e-06
Iter: 591 loss: 5.66392464e-06
Iter: 592 loss: 5.63834874e-06
Iter: 593 loss: 5.63104095e-06
Iter: 594 loss: 5.73786838e-06
Iter: 595 loss: 5.63100184e-06
Iter: 596 loss: 5.62415562e-06
Iter: 597 loss: 5.63340245e-06
Iter: 598 loss: 5.62068954e-06
Iter: 599 loss: 5.61555407e-06
Iter: 600 loss: 5.60798208e-06
Iter: 601 loss: 5.60775197e-06
Iter: 602 loss: 5.59780437e-06
Iter: 603 loss: 5.66470953e-06
Iter: 604 loss: 5.59681393e-06
Iter: 605 loss: 5.58868578e-06
Iter: 606 loss: 5.5951441e-06
Iter: 607 loss: 5.58377769e-06
Iter: 608 loss: 5.57440217e-06
Iter: 609 loss: 5.58891315e-06
Iter: 610 loss: 5.57005706e-06
Iter: 611 loss: 5.55963652e-06
Iter: 612 loss: 5.62115e-06
Iter: 613 loss: 5.55827501e-06
Iter: 614 loss: 5.55040151e-06
Iter: 615 loss: 5.55148063e-06
Iter: 616 loss: 5.54436565e-06
Iter: 617 loss: 5.53241262e-06
Iter: 618 loss: 5.54859071e-06
Iter: 619 loss: 5.52639813e-06
Iter: 620 loss: 5.51606809e-06
Iter: 621 loss: 5.65974278e-06
Iter: 622 loss: 5.5160076e-06
Iter: 623 loss: 5.50808318e-06
Iter: 624 loss: 5.51342191e-06
Iter: 625 loss: 5.50311916e-06
Iter: 626 loss: 5.49412198e-06
Iter: 627 loss: 5.56906662e-06
Iter: 628 loss: 5.49356128e-06
Iter: 629 loss: 5.48624394e-06
Iter: 630 loss: 5.54611142e-06
Iter: 631 loss: 5.48582875e-06
Iter: 632 loss: 5.48131447e-06
Iter: 633 loss: 5.47279751e-06
Iter: 634 loss: 5.65660139e-06
Iter: 635 loss: 5.47278432e-06
Iter: 636 loss: 5.46327738e-06
Iter: 637 loss: 5.48600838e-06
Iter: 638 loss: 5.45987223e-06
Iter: 639 loss: 5.44822797e-06
Iter: 640 loss: 5.48458684e-06
Iter: 641 loss: 5.44489285e-06
Iter: 642 loss: 5.43560054e-06
Iter: 643 loss: 5.44654813e-06
Iter: 644 loss: 5.43065289e-06
Iter: 645 loss: 5.42058797e-06
Iter: 646 loss: 5.46662841e-06
Iter: 647 loss: 5.41868258e-06
Iter: 648 loss: 5.40938754e-06
Iter: 649 loss: 5.43169381e-06
Iter: 650 loss: 5.40595101e-06
Iter: 651 loss: 5.39708662e-06
Iter: 652 loss: 5.39924895e-06
Iter: 653 loss: 5.39058556e-06
Iter: 654 loss: 5.37960568e-06
Iter: 655 loss: 5.45233797e-06
Iter: 656 loss: 5.37850156e-06
Iter: 657 loss: 5.36998186e-06
Iter: 658 loss: 5.42494581e-06
Iter: 659 loss: 5.36907282e-06
Iter: 660 loss: 5.36267e-06
Iter: 661 loss: 5.37151664e-06
Iter: 662 loss: 5.35941081e-06
Iter: 663 loss: 5.3535141e-06
Iter: 664 loss: 5.35346589e-06
Iter: 665 loss: 5.34914079e-06
Iter: 666 loss: 5.34411583e-06
Iter: 667 loss: 5.34353876e-06
Iter: 668 loss: 5.33730963e-06
Iter: 669 loss: 5.33546608e-06
Iter: 670 loss: 5.3316835e-06
Iter: 671 loss: 5.32328295e-06
Iter: 672 loss: 5.38937684e-06
Iter: 673 loss: 5.32268587e-06
Iter: 674 loss: 5.31587148e-06
Iter: 675 loss: 5.31637033e-06
Iter: 676 loss: 5.31052865e-06
Iter: 677 loss: 5.30126272e-06
Iter: 678 loss: 5.3225358e-06
Iter: 679 loss: 5.29788576e-06
Iter: 680 loss: 5.2884634e-06
Iter: 681 loss: 5.33607e-06
Iter: 682 loss: 5.28693e-06
Iter: 683 loss: 5.27880729e-06
Iter: 684 loss: 5.28235341e-06
Iter: 685 loss: 5.27337261e-06
Iter: 686 loss: 5.26264284e-06
Iter: 687 loss: 5.27605243e-06
Iter: 688 loss: 5.25706309e-06
Iter: 689 loss: 5.24633469e-06
Iter: 690 loss: 5.36069319e-06
Iter: 691 loss: 5.24603365e-06
Iter: 692 loss: 5.23712333e-06
Iter: 693 loss: 5.24583083e-06
Iter: 694 loss: 5.23199196e-06
Iter: 695 loss: 5.22463415e-06
Iter: 696 loss: 5.22464052e-06
Iter: 697 loss: 5.21751372e-06
Iter: 698 loss: 5.21656739e-06
Iter: 699 loss: 5.21152742e-06
Iter: 700 loss: 5.20304229e-06
Iter: 701 loss: 5.20133e-06
Iter: 702 loss: 5.19566947e-06
Iter: 703 loss: 5.18584466e-06
Iter: 704 loss: 5.22480241e-06
Iter: 705 loss: 5.18358775e-06
Iter: 706 loss: 5.17398894e-06
Iter: 707 loss: 5.20537469e-06
Iter: 708 loss: 5.17130775e-06
Iter: 709 loss: 5.16279488e-06
Iter: 710 loss: 5.16357068e-06
Iter: 711 loss: 5.15623424e-06
Iter: 712 loss: 5.14548174e-06
Iter: 713 loss: 5.22055143e-06
Iter: 714 loss: 5.14443673e-06
Iter: 715 loss: 5.13574196e-06
Iter: 716 loss: 5.15088504e-06
Iter: 717 loss: 5.13194891e-06
Iter: 718 loss: 5.12238194e-06
Iter: 719 loss: 5.12792394e-06
Iter: 720 loss: 5.11613416e-06
Iter: 721 loss: 5.10612199e-06
Iter: 722 loss: 5.1695215e-06
Iter: 723 loss: 5.10497557e-06
Iter: 724 loss: 5.09584061e-06
Iter: 725 loss: 5.14093335e-06
Iter: 726 loss: 5.09425763e-06
Iter: 727 loss: 5.08757148e-06
Iter: 728 loss: 5.12657607e-06
Iter: 729 loss: 5.08667199e-06
Iter: 730 loss: 5.0801923e-06
Iter: 731 loss: 5.12019051e-06
Iter: 732 loss: 5.07935783e-06
Iter: 733 loss: 5.0753697e-06
Iter: 734 loss: 5.06965e-06
Iter: 735 loss: 5.06944e-06
Iter: 736 loss: 5.06132847e-06
Iter: 737 loss: 5.06660763e-06
Iter: 738 loss: 5.0562121e-06
Iter: 739 loss: 5.0472554e-06
Iter: 740 loss: 5.12109409e-06
Iter: 741 loss: 5.04673972e-06
Iter: 742 loss: 5.0398753e-06
Iter: 743 loss: 5.04359923e-06
Iter: 744 loss: 5.03532e-06
Iter: 745 loss: 5.02716603e-06
Iter: 746 loss: 5.0454646e-06
Iter: 747 loss: 5.02403918e-06
Iter: 748 loss: 5.01572777e-06
Iter: 749 loss: 5.06712831e-06
Iter: 750 loss: 5.01469094e-06
Iter: 751 loss: 5.00808164e-06
Iter: 752 loss: 5.00839178e-06
Iter: 753 loss: 5.00285523e-06
Iter: 754 loss: 4.99299813e-06
Iter: 755 loss: 5.01038267e-06
Iter: 756 loss: 4.98869304e-06
Iter: 757 loss: 4.98093414e-06
Iter: 758 loss: 5.09342408e-06
Iter: 759 loss: 4.98095778e-06
Iter: 760 loss: 4.97501287e-06
Iter: 761 loss: 4.98612053e-06
Iter: 762 loss: 4.97241945e-06
Iter: 763 loss: 4.96653956e-06
Iter: 764 loss: 5.04434865e-06
Iter: 765 loss: 4.96656094e-06
Iter: 766 loss: 4.96207031e-06
Iter: 767 loss: 4.95513132e-06
Iter: 768 loss: 4.95501e-06
Iter: 769 loss: 4.94764254e-06
Iter: 770 loss: 4.9614373e-06
Iter: 771 loss: 4.94450114e-06
Iter: 772 loss: 4.93654488e-06
Iter: 773 loss: 4.95199492e-06
Iter: 774 loss: 4.93325933e-06
Iter: 775 loss: 4.92469826e-06
Iter: 776 loss: 4.96815801e-06
Iter: 777 loss: 4.92328172e-06
Iter: 778 loss: 4.91720539e-06
Iter: 779 loss: 4.91835544e-06
Iter: 780 loss: 4.91262472e-06
Iter: 781 loss: 4.9043565e-06
Iter: 782 loss: 4.94542928e-06
Iter: 783 loss: 4.90299908e-06
Iter: 784 loss: 4.89551439e-06
Iter: 785 loss: 4.91174114e-06
Iter: 786 loss: 4.89262447e-06
Iter: 787 loss: 4.88566457e-06
Iter: 788 loss: 4.88953765e-06
Iter: 789 loss: 4.8812135e-06
Iter: 790 loss: 4.8717443e-06
Iter: 791 loss: 4.9074597e-06
Iter: 792 loss: 4.8695e-06
Iter: 793 loss: 4.86150066e-06
Iter: 794 loss: 4.93784864e-06
Iter: 795 loss: 4.8612e-06
Iter: 796 loss: 4.8571e-06
Iter: 797 loss: 4.90399725e-06
Iter: 798 loss: 4.85698592e-06
Iter: 799 loss: 4.85289911e-06
Iter: 800 loss: 4.84990051e-06
Iter: 801 loss: 4.84851762e-06
Iter: 802 loss: 4.84306111e-06
Iter: 803 loss: 4.84465818e-06
Iter: 804 loss: 4.83918711e-06
Iter: 805 loss: 4.83269832e-06
Iter: 806 loss: 4.85415148e-06
Iter: 807 loss: 4.83094209e-06
Iter: 808 loss: 4.82447558e-06
Iter: 809 loss: 4.83818121e-06
Iter: 810 loss: 4.8219e-06
Iter: 811 loss: 4.81418101e-06
Iter: 812 loss: 4.82526e-06
Iter: 813 loss: 4.81047e-06
Iter: 814 loss: 4.8028478e-06
Iter: 815 loss: 4.81726693e-06
Iter: 816 loss: 4.7996491e-06
Iter: 817 loss: 4.78962693e-06
Iter: 818 loss: 4.81752522e-06
Iter: 819 loss: 4.78642596e-06
Iter: 820 loss: 4.77667436e-06
Iter: 821 loss: 4.78809625e-06
Iter: 822 loss: 4.77153935e-06
Iter: 823 loss: 4.76187961e-06
Iter: 824 loss: 4.7887952e-06
Iter: 825 loss: 4.75877277e-06
Iter: 826 loss: 4.74958642e-06
Iter: 827 loss: 4.81757e-06
Iter: 828 loss: 4.74879835e-06
Iter: 829 loss: 4.74177068e-06
Iter: 830 loss: 4.79051778e-06
Iter: 831 loss: 4.74115677e-06
Iter: 832 loss: 4.73544969e-06
Iter: 833 loss: 4.77987078e-06
Iter: 834 loss: 4.73500859e-06
Iter: 835 loss: 4.73182445e-06
Iter: 836 loss: 4.72570355e-06
Iter: 837 loss: 4.85584042e-06
Iter: 838 loss: 4.72565853e-06
Iter: 839 loss: 4.7186445e-06
Iter: 840 loss: 4.74178159e-06
Iter: 841 loss: 4.71668682e-06
Iter: 842 loss: 4.71038857e-06
Iter: 843 loss: 4.73327327e-06
Iter: 844 loss: 4.70871692e-06
Iter: 845 loss: 4.70289797e-06
Iter: 846 loss: 4.71892099e-06
Iter: 847 loss: 4.70095938e-06
Iter: 848 loss: 4.69481347e-06
Iter: 849 loss: 4.69675615e-06
Iter: 850 loss: 4.69039969e-06
Iter: 851 loss: 4.68331154e-06
Iter: 852 loss: 4.73361752e-06
Iter: 853 loss: 4.68264352e-06
Iter: 854 loss: 4.67676273e-06
Iter: 855 loss: 4.68757207e-06
Iter: 856 loss: 4.67423615e-06
Iter: 857 loss: 4.66843949e-06
Iter: 858 loss: 4.67076552e-06
Iter: 859 loss: 4.66440406e-06
Iter: 860 loss: 4.65690846e-06
Iter: 861 loss: 4.6956493e-06
Iter: 862 loss: 4.65569065e-06
Iter: 863 loss: 4.64994719e-06
Iter: 864 loss: 4.71574276e-06
Iter: 865 loss: 4.64984805e-06
Iter: 866 loss: 4.64554705e-06
Iter: 867 loss: 4.67146765e-06
Iter: 868 loss: 4.64504865e-06
Iter: 869 loss: 4.64052e-06
Iter: 870 loss: 4.63404967e-06
Iter: 871 loss: 4.63380502e-06
Iter: 872 loss: 4.62672142e-06
Iter: 873 loss: 4.6377254e-06
Iter: 874 loss: 4.62347089e-06
Iter: 875 loss: 4.61510581e-06
Iter: 876 loss: 4.63195283e-06
Iter: 877 loss: 4.61175659e-06
Iter: 878 loss: 4.60202864e-06
Iter: 879 loss: 4.62886737e-06
Iter: 880 loss: 4.59885359e-06
Iter: 881 loss: 4.59022931e-06
Iter: 882 loss: 4.6260111e-06
Iter: 883 loss: 4.58835257e-06
Iter: 884 loss: 4.5818224e-06
Iter: 885 loss: 4.58990826e-06
Iter: 886 loss: 4.57844726e-06
Iter: 887 loss: 4.57070564e-06
Iter: 888 loss: 4.6116611e-06
Iter: 889 loss: 4.5694278e-06
Iter: 890 loss: 4.56305315e-06
Iter: 891 loss: 4.56626731e-06
Iter: 892 loss: 4.55873851e-06
Iter: 893 loss: 4.55175541e-06
Iter: 894 loss: 4.57348506e-06
Iter: 895 loss: 4.54972815e-06
Iter: 896 loss: 4.54358315e-06
Iter: 897 loss: 4.59681905e-06
Iter: 898 loss: 4.5432671e-06
Iter: 899 loss: 4.53924577e-06
Iter: 900 loss: 4.59412058e-06
Iter: 901 loss: 4.53926623e-06
Iter: 902 loss: 4.53601024e-06
Iter: 903 loss: 4.53693156e-06
Iter: 904 loss: 4.53364783e-06
Iter: 905 loss: 4.52962649e-06
Iter: 906 loss: 4.52448785e-06
Iter: 907 loss: 4.52416953e-06
Iter: 908 loss: 4.51795404e-06
Iter: 909 loss: 4.55428108e-06
Iter: 910 loss: 4.51716551e-06
Iter: 911 loss: 4.51149026e-06
Iter: 912 loss: 4.519306e-06
Iter: 913 loss: 4.50868129e-06
Iter: 914 loss: 4.50177322e-06
Iter: 915 loss: 4.52070071e-06
Iter: 916 loss: 4.49952904e-06
Iter: 917 loss: 4.49340223e-06
Iter: 918 loss: 4.51031474e-06
Iter: 919 loss: 4.49133586e-06
Iter: 920 loss: 4.48524315e-06
Iter: 921 loss: 4.49718573e-06
Iter: 922 loss: 4.48271112e-06
Iter: 923 loss: 4.47521688e-06
Iter: 924 loss: 4.49840718e-06
Iter: 925 loss: 4.47307e-06
Iter: 926 loss: 4.46751073e-06
Iter: 927 loss: 4.47302364e-06
Iter: 928 loss: 4.46441436e-06
Iter: 929 loss: 4.45760634e-06
Iter: 930 loss: 4.47834282e-06
Iter: 931 loss: 4.45547948e-06
Iter: 932 loss: 4.4501412e-06
Iter: 933 loss: 4.45013848e-06
Iter: 934 loss: 4.44592843e-06
Iter: 935 loss: 4.46713511e-06
Iter: 936 loss: 4.44519355e-06
Iter: 937 loss: 4.44193029e-06
Iter: 938 loss: 4.43764566e-06
Iter: 939 loss: 4.43735917e-06
Iter: 940 loss: 4.43178806e-06
Iter: 941 loss: 4.43682347e-06
Iter: 942 loss: 4.42857163e-06
Iter: 943 loss: 4.4229414e-06
Iter: 944 loss: 4.46678132e-06
Iter: 945 loss: 4.42260671e-06
Iter: 946 loss: 4.41803923e-06
Iter: 947 loss: 4.4213175e-06
Iter: 948 loss: 4.41518387e-06
Iter: 949 loss: 4.40892427e-06
Iter: 950 loss: 4.42119472e-06
Iter: 951 loss: 4.40633266e-06
Iter: 952 loss: 4.40057693e-06
Iter: 953 loss: 4.42291e-06
Iter: 954 loss: 4.39920859e-06
Iter: 955 loss: 4.39374662e-06
Iter: 956 loss: 4.40977146e-06
Iter: 957 loss: 4.39209543e-06
Iter: 958 loss: 4.3864743e-06
Iter: 959 loss: 4.39550877e-06
Iter: 960 loss: 4.38389952e-06
Iter: 961 loss: 4.3790169e-06
Iter: 962 loss: 4.38558618e-06
Iter: 963 loss: 4.37661129e-06
Iter: 964 loss: 4.37108e-06
Iter: 965 loss: 4.40896201e-06
Iter: 966 loss: 4.37054086e-06
Iter: 967 loss: 4.36731079e-06
Iter: 968 loss: 4.36723758e-06
Iter: 969 loss: 4.36473829e-06
Iter: 970 loss: 4.36399068e-06
Iter: 971 loss: 4.36254277e-06
Iter: 972 loss: 4.35890161e-06
Iter: 973 loss: 4.3545374e-06
Iter: 974 loss: 4.35413585e-06
Iter: 975 loss: 4.34794219e-06
Iter: 976 loss: 4.36907658e-06
Iter: 977 loss: 4.34626781e-06
Iter: 978 loss: 4.34039521e-06
Iter: 979 loss: 4.36754e-06
Iter: 980 loss: 4.33929608e-06
Iter: 981 loss: 4.33352261e-06
Iter: 982 loss: 4.3357968e-06
Iter: 983 loss: 4.32955721e-06
Iter: 984 loss: 4.32154366e-06
Iter: 985 loss: 4.34184312e-06
Iter: 986 loss: 4.3188129e-06
Iter: 987 loss: 4.31248282e-06
Iter: 988 loss: 4.34392223e-06
Iter: 989 loss: 4.31143735e-06
Iter: 990 loss: 4.3053119e-06
Iter: 991 loss: 4.31849548e-06
Iter: 992 loss: 4.3029595e-06
Iter: 993 loss: 4.29697775e-06
Iter: 994 loss: 4.30703903e-06
Iter: 995 loss: 4.29429292e-06
Iter: 996 loss: 4.28863223e-06
Iter: 997 loss: 4.29404099e-06
Iter: 998 loss: 4.28528392e-06
Iter: 999 loss: 4.27963e-06
Iter: 1000 loss: 4.36129312e-06
Iter: 1001 loss: 4.2795732e-06
Iter: 1002 loss: 4.27547047e-06
Iter: 1003 loss: 4.3228747e-06
Iter: 1004 loss: 4.27537816e-06
Iter: 1005 loss: 4.27259965e-06
Iter: 1006 loss: 4.27021041e-06
Iter: 1007 loss: 4.26946735e-06
Iter: 1008 loss: 4.26482302e-06
Iter: 1009 loss: 4.26364795e-06
Iter: 1010 loss: 4.26073439e-06
Iter: 1011 loss: 4.25499366e-06
Iter: 1012 loss: 4.27640498e-06
Iter: 1013 loss: 4.2535894e-06
Iter: 1014 loss: 4.24775135e-06
Iter: 1015 loss: 4.268873e-06
Iter: 1016 loss: 4.24629116e-06
Iter: 1017 loss: 4.24076734e-06
Iter: 1018 loss: 4.2487336e-06
Iter: 1019 loss: 4.23802339e-06
Iter: 1020 loss: 4.23159872e-06
Iter: 1021 loss: 4.24337031e-06
Iter: 1022 loss: 4.2288666e-06
Iter: 1023 loss: 4.22310131e-06
Iter: 1024 loss: 4.25024336e-06
Iter: 1025 loss: 4.2219458e-06
Iter: 1026 loss: 4.21597815e-06
Iter: 1027 loss: 4.22618359e-06
Iter: 1028 loss: 4.21330606e-06
Iter: 1029 loss: 4.20652941e-06
Iter: 1030 loss: 4.20891683e-06
Iter: 1031 loss: 4.2017e-06
Iter: 1032 loss: 4.193319e-06
Iter: 1033 loss: 4.2162651e-06
Iter: 1034 loss: 4.19052958e-06
Iter: 1035 loss: 4.18444142e-06
Iter: 1036 loss: 4.26827228e-06
Iter: 1037 loss: 4.18436775e-06
Iter: 1038 loss: 4.17923548e-06
Iter: 1039 loss: 4.22520316e-06
Iter: 1040 loss: 4.17900264e-06
Iter: 1041 loss: 4.17558704e-06
Iter: 1042 loss: 4.17469e-06
Iter: 1043 loss: 4.17262709e-06
Iter: 1044 loss: 4.16822149e-06
Iter: 1045 loss: 4.16998637e-06
Iter: 1046 loss: 4.16518378e-06
Iter: 1047 loss: 4.16006333e-06
Iter: 1048 loss: 4.16720195e-06
Iter: 1049 loss: 4.15755312e-06
Iter: 1050 loss: 4.15138175e-06
Iter: 1051 loss: 4.1877629e-06
Iter: 1052 loss: 4.15062095e-06
Iter: 1053 loss: 4.14618808e-06
Iter: 1054 loss: 4.15577824e-06
Iter: 1055 loss: 4.14442593e-06
Iter: 1056 loss: 4.1398871e-06
Iter: 1057 loss: 4.14880651e-06
Iter: 1058 loss: 4.13804355e-06
Iter: 1059 loss: 4.13381713e-06
Iter: 1060 loss: 4.14793385e-06
Iter: 1061 loss: 4.13270118e-06
Iter: 1062 loss: 4.12828376e-06
Iter: 1063 loss: 4.14258102e-06
Iter: 1064 loss: 4.12704776e-06
Iter: 1065 loss: 4.12280315e-06
Iter: 1066 loss: 4.12430381e-06
Iter: 1067 loss: 4.1198532e-06
Iter: 1068 loss: 4.11488418e-06
Iter: 1069 loss: 4.12831378e-06
Iter: 1070 loss: 4.11321525e-06
Iter: 1071 loss: 4.1092535e-06
Iter: 1072 loss: 4.16091916e-06
Iter: 1073 loss: 4.10922166e-06
Iter: 1074 loss: 4.10538814e-06
Iter: 1075 loss: 4.12615782e-06
Iter: 1076 loss: 4.10483608e-06
Iter: 1077 loss: 4.10235862e-06
Iter: 1078 loss: 4.10234952e-06
Iter: 1079 loss: 4.10039911e-06
Iter: 1080 loss: 4.09706263e-06
Iter: 1081 loss: 4.09689346e-06
Iter: 1082 loss: 4.09436052e-06
Iter: 1083 loss: 4.08984261e-06
Iter: 1084 loss: 4.09662107e-06
Iter: 1085 loss: 4.08770575e-06
Iter: 1086 loss: 4.0827e-06
Iter: 1087 loss: 4.11910969e-06
Iter: 1088 loss: 4.08227243e-06
Iter: 1089 loss: 4.07837524e-06
Iter: 1090 loss: 4.08045844e-06
Iter: 1091 loss: 4.07582593e-06
Iter: 1092 loss: 4.0707173e-06
Iter: 1093 loss: 4.08369579e-06
Iter: 1094 loss: 4.06888785e-06
Iter: 1095 loss: 4.0643431e-06
Iter: 1096 loss: 4.07989e-06
Iter: 1097 loss: 4.06310573e-06
Iter: 1098 loss: 4.05861692e-06
Iter: 1099 loss: 4.07516e-06
Iter: 1100 loss: 4.0575278e-06
Iter: 1101 loss: 4.05303672e-06
Iter: 1102 loss: 4.05232277e-06
Iter: 1103 loss: 4.04931234e-06
Iter: 1104 loss: 4.04378625e-06
Iter: 1105 loss: 4.06765184e-06
Iter: 1106 loss: 4.04268167e-06
Iter: 1107 loss: 4.03981812e-06
Iter: 1108 loss: 4.03954709e-06
Iter: 1109 loss: 4.03658942e-06
Iter: 1110 loss: 4.03722743e-06
Iter: 1111 loss: 4.03439253e-06
Iter: 1112 loss: 4.03140621e-06
Iter: 1113 loss: 4.03615741e-06
Iter: 1114 loss: 4.03001832e-06
Iter: 1115 loss: 4.02681735e-06
Iter: 1116 loss: 4.02615115e-06
Iter: 1117 loss: 4.02402929e-06
Iter: 1118 loss: 4.01984516e-06
Iter: 1119 loss: 4.03417198e-06
Iter: 1120 loss: 4.0187183e-06
Iter: 1121 loss: 4.01478474e-06
Iter: 1122 loss: 4.04002913e-06
Iter: 1123 loss: 4.01433454e-06
Iter: 1124 loss: 4.0112227e-06
Iter: 1125 loss: 4.01189936e-06
Iter: 1126 loss: 4.00888e-06
Iter: 1127 loss: 4.00481895e-06
Iter: 1128 loss: 4.02010301e-06
Iter: 1129 loss: 4.00383897e-06
Iter: 1130 loss: 4.00037516e-06
Iter: 1131 loss: 4.0098721e-06
Iter: 1132 loss: 3.99924647e-06
Iter: 1133 loss: 3.9955853e-06
Iter: 1134 loss: 4.00890394e-06
Iter: 1135 loss: 3.99466353e-06
Iter: 1136 loss: 3.99139299e-06
Iter: 1137 loss: 3.99092323e-06
Iter: 1138 loss: 3.98858629e-06
Iter: 1139 loss: 3.98476232e-06
Iter: 1140 loss: 4.01821171e-06
Iter: 1141 loss: 3.98454722e-06
Iter: 1142 loss: 3.9813367e-06
Iter: 1143 loss: 4.01917623e-06
Iter: 1144 loss: 3.98123666e-06
Iter: 1145 loss: 3.97901749e-06
Iter: 1146 loss: 3.97670738e-06
Iter: 1147 loss: 3.97631811e-06
Iter: 1148 loss: 3.97262193e-06
Iter: 1149 loss: 3.98125485e-06
Iter: 1150 loss: 3.97131407e-06
Iter: 1151 loss: 3.96795531e-06
Iter: 1152 loss: 3.97037547e-06
Iter: 1153 loss: 3.96590531e-06
Iter: 1154 loss: 3.96258474e-06
Iter: 1155 loss: 3.98216071e-06
Iter: 1156 loss: 3.96216319e-06
Iter: 1157 loss: 3.9589213e-06
Iter: 1158 loss: 3.96679e-06
Iter: 1159 loss: 3.95778261e-06
Iter: 1160 loss: 3.95482766e-06
Iter: 1161 loss: 3.95917777e-06
Iter: 1162 loss: 3.95335701e-06
Iter: 1163 loss: 3.95028428e-06
Iter: 1164 loss: 3.96252835e-06
Iter: 1165 loss: 3.94963308e-06
Iter: 1166 loss: 3.94684412e-06
Iter: 1167 loss: 3.95309962e-06
Iter: 1168 loss: 3.94578274e-06
Iter: 1169 loss: 3.94249491e-06
Iter: 1170 loss: 3.95110692e-06
Iter: 1171 loss: 3.94141261e-06
Iter: 1172 loss: 3.93843129e-06
Iter: 1173 loss: 3.93843402e-06
Iter: 1174 loss: 3.93604751e-06
Iter: 1175 loss: 3.93588334e-06
Iter: 1176 loss: 3.93441223e-06
Iter: 1177 loss: 3.93278333e-06
Iter: 1178 loss: 3.9314973e-06
Iter: 1179 loss: 3.93103528e-06
Iter: 1180 loss: 3.92902075e-06
Iter: 1181 loss: 3.93412756e-06
Iter: 1182 loss: 3.92832e-06
Iter: 1183 loss: 3.92605762e-06
Iter: 1184 loss: 3.92577567e-06
Iter: 1185 loss: 3.92421043e-06
Iter: 1186 loss: 3.92105267e-06
Iter: 1187 loss: 3.92603852e-06
Iter: 1188 loss: 3.91956746e-06
Iter: 1189 loss: 3.91663707e-06
Iter: 1190 loss: 3.9412007e-06
Iter: 1191 loss: 3.91647836e-06
Iter: 1192 loss: 3.91393723e-06
Iter: 1193 loss: 3.91684898e-06
Iter: 1194 loss: 3.91261347e-06
Iter: 1195 loss: 3.91014237e-06
Iter: 1196 loss: 3.91581261e-06
Iter: 1197 loss: 3.90917739e-06
Iter: 1198 loss: 3.90663172e-06
Iter: 1199 loss: 3.91282e-06
Iter: 1200 loss: 3.90557307e-06
Iter: 1201 loss: 3.90248442e-06
Iter: 1202 loss: 3.90981722e-06
Iter: 1203 loss: 3.90135938e-06
Iter: 1204 loss: 3.89816023e-06
Iter: 1205 loss: 3.90850801e-06
Iter: 1206 loss: 3.89729e-06
Iter: 1207 loss: 3.89492152e-06
Iter: 1208 loss: 3.89854813e-06
Iter: 1209 loss: 3.89384e-06
Iter: 1210 loss: 3.89233628e-06
Iter: 1211 loss: 3.89201386e-06
Iter: 1212 loss: 3.8910116e-06
Iter: 1213 loss: 3.8888e-06
Iter: 1214 loss: 3.91953654e-06
Iter: 1215 loss: 3.88868739e-06
Iter: 1216 loss: 3.88607805e-06
Iter: 1217 loss: 3.89901061e-06
Iter: 1218 loss: 3.88564649e-06
Iter: 1219 loss: 3.88334865e-06
Iter: 1220 loss: 3.88289482e-06
Iter: 1221 loss: 3.88135868e-06
Iter: 1222 loss: 3.87840146e-06
Iter: 1223 loss: 3.89024945e-06
Iter: 1224 loss: 3.87777254e-06
Iter: 1225 loss: 3.87519549e-06
Iter: 1226 loss: 3.88985836e-06
Iter: 1227 loss: 3.87486398e-06
Iter: 1228 loss: 3.87247337e-06
Iter: 1229 loss: 3.87218824e-06
Iter: 1230 loss: 3.87043474e-06
Iter: 1231 loss: 3.86734291e-06
Iter: 1232 loss: 3.87841646e-06
Iter: 1233 loss: 3.86656666e-06
Iter: 1234 loss: 3.86378315e-06
Iter: 1235 loss: 3.87360933e-06
Iter: 1236 loss: 3.86304646e-06
Iter: 1237 loss: 3.86024931e-06
Iter: 1238 loss: 3.8678163e-06
Iter: 1239 loss: 3.8592766e-06
Iter: 1240 loss: 3.85679232e-06
Iter: 1241 loss: 3.86521242e-06
Iter: 1242 loss: 3.85616659e-06
Iter: 1243 loss: 3.85459407e-06
Iter: 1244 loss: 3.87166938e-06
Iter: 1245 loss: 3.85455132e-06
Iter: 1246 loss: 3.85256499e-06
Iter: 1247 loss: 3.85240628e-06
Iter: 1248 loss: 3.85096337e-06
Iter: 1249 loss: 3.84918803e-06
Iter: 1250 loss: 3.85097428e-06
Iter: 1251 loss: 3.8482e-06
Iter: 1252 loss: 3.84588839e-06
Iter: 1253 loss: 3.85166504e-06
Iter: 1254 loss: 3.84509622e-06
Iter: 1255 loss: 3.8429971e-06
Iter: 1256 loss: 3.84339546e-06
Iter: 1257 loss: 3.84138184e-06
Iter: 1258 loss: 3.83889937e-06
Iter: 1259 loss: 3.85514795e-06
Iter: 1260 loss: 3.83860697e-06
Iter: 1261 loss: 3.83653878e-06
Iter: 1262 loss: 3.84431951e-06
Iter: 1263 loss: 3.8360572e-06
Iter: 1264 loss: 3.833954e-06
Iter: 1265 loss: 3.83308497e-06
Iter: 1266 loss: 3.83197948e-06
Iter: 1267 loss: 3.82915869e-06
Iter: 1268 loss: 3.84369969e-06
Iter: 1269 loss: 3.82870076e-06
Iter: 1270 loss: 3.82639291e-06
Iter: 1271 loss: 3.83530733e-06
Iter: 1272 loss: 3.82585677e-06
Iter: 1273 loss: 3.8235853e-06
Iter: 1274 loss: 3.82816552e-06
Iter: 1275 loss: 3.82262306e-06
Iter: 1276 loss: 3.82049257e-06
Iter: 1277 loss: 3.82850703e-06
Iter: 1278 loss: 3.8199878e-06
Iter: 1279 loss: 3.81898462e-06
Iter: 1280 loss: 3.81881591e-06
Iter: 1281 loss: 3.81786595e-06
Iter: 1282 loss: 3.81532436e-06
Iter: 1283 loss: 3.83019778e-06
Iter: 1284 loss: 3.81458517e-06
Iter: 1285 loss: 3.81207747e-06
Iter: 1286 loss: 3.8443377e-06
Iter: 1287 loss: 3.81204745e-06
Iter: 1288 loss: 3.81021528e-06
Iter: 1289 loss: 3.81009431e-06
Iter: 1290 loss: 3.8087328e-06
Iter: 1291 loss: 3.80624965e-06
Iter: 1292 loss: 3.81065411e-06
Iter: 1293 loss: 3.80523488e-06
Iter: 1294 loss: 3.80281585e-06
Iter: 1295 loss: 3.82026519e-06
Iter: 1296 loss: 3.8025903e-06
Iter: 1297 loss: 3.80052143e-06
Iter: 1298 loss: 3.80371284e-06
Iter: 1299 loss: 3.79955759e-06
Iter: 1300 loss: 3.79708513e-06
Iter: 1301 loss: 3.7971131e-06
Iter: 1302 loss: 3.7951645e-06
Iter: 1303 loss: 3.79195399e-06
Iter: 1304 loss: 3.80952633e-06
Iter: 1305 loss: 3.79145899e-06
Iter: 1306 loss: 3.78878917e-06
Iter: 1307 loss: 3.79816629e-06
Iter: 1308 loss: 3.78803907e-06
Iter: 1309 loss: 3.7853406e-06
Iter: 1310 loss: 3.79021094e-06
Iter: 1311 loss: 3.78413483e-06
Iter: 1312 loss: 3.7825148e-06
Iter: 1313 loss: 3.78247546e-06
Iter: 1314 loss: 3.78081154e-06
Iter: 1315 loss: 3.78213144e-06
Iter: 1316 loss: 3.77980632e-06
Iter: 1317 loss: 3.77846482e-06
Iter: 1318 loss: 3.77679316e-06
Iter: 1319 loss: 3.77666493e-06
Iter: 1320 loss: 3.77402284e-06
Iter: 1321 loss: 3.79102175e-06
Iter: 1322 loss: 3.77367769e-06
Iter: 1323 loss: 3.77189326e-06
Iter: 1324 loss: 3.77175684e-06
Iter: 1325 loss: 3.77039578e-06
Iter: 1326 loss: 3.76816683e-06
Iter: 1327 loss: 3.77797551e-06
Iter: 1328 loss: 3.76770049e-06
Iter: 1329 loss: 3.76561911e-06
Iter: 1330 loss: 3.77711763e-06
Iter: 1331 loss: 3.76533603e-06
Iter: 1332 loss: 3.76359503e-06
Iter: 1333 loss: 3.76498019e-06
Iter: 1334 loss: 3.76250864e-06
Iter: 1335 loss: 3.76041862e-06
Iter: 1336 loss: 3.76292269e-06
Iter: 1337 loss: 3.75933314e-06
Iter: 1338 loss: 3.75711397e-06
Iter: 1339 loss: 3.77368315e-06
Iter: 1340 loss: 3.75695845e-06
Iter: 1341 loss: 3.75535342e-06
Iter: 1342 loss: 3.75953255e-06
Iter: 1343 loss: 3.75481159e-06
Iter: 1344 loss: 3.75328977e-06
Iter: 1345 loss: 3.75828e-06
Iter: 1346 loss: 3.75284208e-06
Iter: 1347 loss: 3.75156151e-06
Iter: 1348 loss: 3.75161108e-06
Iter: 1349 loss: 3.750838e-06
Iter: 1350 loss: 3.74920023e-06
Iter: 1351 loss: 3.77383844e-06
Iter: 1352 loss: 3.74918568e-06
Iter: 1353 loss: 3.74771753e-06
Iter: 1354 loss: 3.75669947e-06
Iter: 1355 loss: 3.74751971e-06
Iter: 1356 loss: 3.74594333e-06
Iter: 1357 loss: 3.74608112e-06
Iter: 1358 loss: 3.7446946e-06
Iter: 1359 loss: 3.74287538e-06
Iter: 1360 loss: 3.7459622e-06
Iter: 1361 loss: 3.74204592e-06
Iter: 1362 loss: 3.74013962e-06
Iter: 1363 loss: 3.75164973e-06
Iter: 1364 loss: 3.73986495e-06
Iter: 1365 loss: 3.73810417e-06
Iter: 1366 loss: 3.74236902e-06
Iter: 1367 loss: 3.73745456e-06
Iter: 1368 loss: 3.73575676e-06
Iter: 1369 loss: 3.73706825e-06
Iter: 1370 loss: 3.7347063e-06
Iter: 1371 loss: 3.73251373e-06
Iter: 1372 loss: 3.73655394e-06
Iter: 1373 loss: 3.731569e-06
Iter: 1374 loss: 3.72908539e-06
Iter: 1375 loss: 3.74380988e-06
Iter: 1376 loss: 3.72875979e-06
Iter: 1377 loss: 3.72691738e-06
Iter: 1378 loss: 3.73209559e-06
Iter: 1379 loss: 3.72634668e-06
Iter: 1380 loss: 3.72533214e-06
Iter: 1381 loss: 3.72522982e-06
Iter: 1382 loss: 3.72420641e-06
Iter: 1383 loss: 3.72299019e-06
Iter: 1384 loss: 3.72283603e-06
Iter: 1385 loss: 3.72143768e-06
Iter: 1386 loss: 3.72138766e-06
Iter: 1387 loss: 3.72024e-06
Iter: 1388 loss: 3.71826104e-06
Iter: 1389 loss: 3.73168928e-06
Iter: 1390 loss: 3.71801502e-06
Iter: 1391 loss: 3.71627266e-06
Iter: 1392 loss: 3.71472174e-06
Iter: 1393 loss: 3.7143368e-06
Iter: 1394 loss: 3.71201986e-06
Iter: 1395 loss: 3.72722275e-06
Iter: 1396 loss: 3.71174247e-06
Iter: 1397 loss: 3.70976659e-06
Iter: 1398 loss: 3.71919032e-06
Iter: 1399 loss: 3.70941393e-06
Iter: 1400 loss: 3.70766043e-06
Iter: 1401 loss: 3.70924477e-06
Iter: 1402 loss: 3.70660291e-06
Iter: 1403 loss: 3.7046168e-06
Iter: 1404 loss: 3.7076129e-06
Iter: 1405 loss: 3.70364296e-06
Iter: 1406 loss: 3.70152952e-06
Iter: 1407 loss: 3.71218653e-06
Iter: 1408 loss: 3.70117823e-06
Iter: 1409 loss: 3.6991255e-06
Iter: 1410 loss: 3.70480166e-06
Iter: 1411 loss: 3.69850113e-06
Iter: 1412 loss: 3.69681925e-06
Iter: 1413 loss: 3.70908128e-06
Iter: 1414 loss: 3.69662439e-06
Iter: 1415 loss: 3.69495433e-06
Iter: 1416 loss: 3.70536509e-06
Iter: 1417 loss: 3.69477084e-06
Iter: 1418 loss: 3.69380814e-06
Iter: 1419 loss: 3.69206759e-06
Iter: 1420 loss: 3.73504417e-06
Iter: 1421 loss: 3.69209602e-06
Iter: 1422 loss: 3.69017607e-06
Iter: 1423 loss: 3.69939698e-06
Iter: 1424 loss: 3.68987821e-06
Iter: 1425 loss: 3.68790415e-06
Iter: 1426 loss: 3.69123632e-06
Iter: 1427 loss: 3.6870133e-06
Iter: 1428 loss: 3.6851925e-06
Iter: 1429 loss: 3.68478527e-06
Iter: 1430 loss: 3.68358405e-06
Iter: 1431 loss: 3.68132214e-06
Iter: 1432 loss: 3.70626503e-06
Iter: 1433 loss: 3.68127371e-06
Iter: 1434 loss: 3.67948951e-06
Iter: 1435 loss: 3.68353176e-06
Iter: 1436 loss: 3.67878988e-06
Iter: 1437 loss: 3.67706298e-06
Iter: 1438 loss: 3.67872599e-06
Iter: 1439 loss: 3.67609232e-06
Iter: 1440 loss: 3.67409507e-06
Iter: 1441 loss: 3.67855637e-06
Iter: 1442 loss: 3.67329449e-06
Iter: 1443 loss: 3.67151733e-06
Iter: 1444 loss: 3.68749852e-06
Iter: 1445 loss: 3.67137977e-06
Iter: 1446 loss: 3.67006623e-06
Iter: 1447 loss: 3.67294797e-06
Iter: 1448 loss: 3.66955715e-06
Iter: 1449 loss: 3.6685974e-06
Iter: 1450 loss: 3.6686065e-06
Iter: 1451 loss: 3.66784298e-06
Iter: 1452 loss: 3.66644099e-06
Iter: 1453 loss: 3.6964243e-06
Iter: 1454 loss: 3.66643326e-06
Iter: 1455 loss: 3.66507948e-06
Iter: 1456 loss: 3.66818449e-06
Iter: 1457 loss: 3.66459017e-06
Iter: 1458 loss: 3.66311451e-06
Iter: 1459 loss: 3.66960785e-06
Iter: 1460 loss: 3.6628046e-06
Iter: 1461 loss: 3.66136146e-06
Iter: 1462 loss: 3.66125209e-06
Iter: 1463 loss: 3.66020686e-06
Iter: 1464 loss: 3.65860978e-06
Iter: 1465 loss: 3.66343215e-06
Iter: 1466 loss: 3.65816027e-06
Iter: 1467 loss: 3.65637152e-06
Iter: 1468 loss: 3.66542895e-06
Iter: 1469 loss: 3.65607139e-06
Iter: 1470 loss: 3.65439678e-06
Iter: 1471 loss: 3.65512187e-06
Iter: 1472 loss: 3.65325195e-06
Iter: 1473 loss: 3.65122764e-06
Iter: 1474 loss: 3.65585493e-06
Iter: 1475 loss: 3.65050892e-06
Iter: 1476 loss: 3.64839616e-06
Iter: 1477 loss: 3.65502274e-06
Iter: 1478 loss: 3.64779044e-06
Iter: 1479 loss: 3.64584184e-06
Iter: 1480 loss: 3.65952201e-06
Iter: 1481 loss: 3.64573816e-06
Iter: 1482 loss: 3.6445922e-06
Iter: 1483 loss: 3.65713777e-06
Iter: 1484 loss: 3.64461812e-06
Iter: 1485 loss: 3.64344123e-06
Iter: 1486 loss: 3.6435531e-06
Iter: 1487 loss: 3.6426045e-06
Iter: 1488 loss: 3.64139669e-06
Iter: 1489 loss: 3.6402048e-06
Iter: 1490 loss: 3.63992308e-06
Iter: 1491 loss: 3.63828622e-06
Iter: 1492 loss: 3.65308642e-06
Iter: 1493 loss: 3.6381989e-06
Iter: 1494 loss: 3.63680147e-06
Iter: 1495 loss: 3.63834033e-06
Iter: 1496 loss: 3.63602703e-06
Iter: 1497 loss: 3.63448135e-06
Iter: 1498 loss: 3.63508275e-06
Iter: 1499 loss: 3.63343588e-06
Iter: 1500 loss: 3.63202093e-06
Iter: 1501 loss: 3.64753259e-06
Iter: 1502 loss: 3.63195477e-06
Iter: 1503 loss: 3.63062236e-06
Iter: 1504 loss: 3.63091044e-06
Iter: 1505 loss: 3.62958122e-06
Iter: 1506 loss: 3.62770015e-06
Iter: 1507 loss: 3.63007371e-06
Iter: 1508 loss: 3.62672654e-06
Iter: 1509 loss: 3.6247543e-06
Iter: 1510 loss: 3.63241179e-06
Iter: 1511 loss: 3.62422657e-06
Iter: 1512 loss: 3.62244646e-06
Iter: 1513 loss: 3.6303104e-06
Iter: 1514 loss: 3.62209175e-06
Iter: 1515 loss: 3.62049218e-06
Iter: 1516 loss: 3.63004801e-06
Iter: 1517 loss: 3.62032142e-06
Iter: 1518 loss: 3.61893922e-06
Iter: 1519 loss: 3.63188838e-06
Iter: 1520 loss: 3.61886509e-06
Iter: 1521 loss: 3.61807747e-06
Iter: 1522 loss: 3.61644697e-06
Iter: 1523 loss: 3.64714515e-06
Iter: 1524 loss: 3.61646266e-06
Iter: 1525 loss: 3.61478214e-06
Iter: 1526 loss: 3.62076253e-06
Iter: 1527 loss: 3.61431421e-06
Iter: 1528 loss: 3.61279035e-06
Iter: 1529 loss: 3.62203218e-06
Iter: 1530 loss: 3.61257526e-06
Iter: 1531 loss: 3.61135517e-06
Iter: 1532 loss: 3.61112052e-06
Iter: 1533 loss: 3.61027878e-06
Iter: 1534 loss: 3.60859576e-06
Iter: 1535 loss: 3.61126445e-06
Iter: 1536 loss: 3.60777153e-06
Iter: 1537 loss: 3.60607874e-06
Iter: 1538 loss: 3.62637456e-06
Iter: 1539 loss: 3.60606577e-06
Iter: 1540 loss: 3.60482682e-06
Iter: 1541 loss: 3.60405784e-06
Iter: 1542 loss: 3.6035467e-06
Iter: 1543 loss: 3.60157901e-06
Iter: 1544 loss: 3.60715558e-06
Iter: 1545 loss: 3.60095e-06
Iter: 1546 loss: 3.59926707e-06
Iter: 1547 loss: 3.60814647e-06
Iter: 1548 loss: 3.59902697e-06
Iter: 1549 loss: 3.59762544e-06
Iter: 1550 loss: 3.60531249e-06
Iter: 1551 loss: 3.59744536e-06
Iter: 1552 loss: 3.59645719e-06
Iter: 1553 loss: 3.60929835e-06
Iter: 1554 loss: 3.59645105e-06
Iter: 1555 loss: 3.59555474e-06
Iter: 1556 loss: 3.59420483e-06
Iter: 1557 loss: 3.5942312e-06
Iter: 1558 loss: 3.59284695e-06
Iter: 1559 loss: 3.59423757e-06
Iter: 1560 loss: 3.59215096e-06
Iter: 1561 loss: 3.59061687e-06
Iter: 1562 loss: 3.59938781e-06
Iter: 1563 loss: 3.59039132e-06
Iter: 1564 loss: 3.5888977e-06
Iter: 1565 loss: 3.58996704e-06
Iter: 1566 loss: 3.58804618e-06
Iter: 1567 loss: 3.58648163e-06
Iter: 1568 loss: 3.58904231e-06
Iter: 1569 loss: 3.58573857e-06
Iter: 1570 loss: 3.58432544e-06
Iter: 1571 loss: 3.59312617e-06
Iter: 1572 loss: 3.58417287e-06
Iter: 1573 loss: 3.58261514e-06
Iter: 1574 loss: 3.58528246e-06
Iter: 1575 loss: 3.58197053e-06
Iter: 1576 loss: 3.58061379e-06
Iter: 1577 loss: 3.58206262e-06
Iter: 1578 loss: 3.57976569e-06
Iter: 1579 loss: 3.577999e-06
Iter: 1580 loss: 3.58182979e-06
Iter: 1581 loss: 3.5772855e-06
Iter: 1582 loss: 3.57548197e-06
Iter: 1583 loss: 3.58864531e-06
Iter: 1584 loss: 3.57536283e-06
Iter: 1585 loss: 3.57419367e-06
Iter: 1586 loss: 3.58713601e-06
Iter: 1587 loss: 3.57418594e-06
Iter: 1588 loss: 3.57314366e-06
Iter: 1589 loss: 3.57477643e-06
Iter: 1590 loss: 3.57261661e-06
Iter: 1591 loss: 3.57167437e-06
Iter: 1592 loss: 3.57019258e-06
Iter: 1593 loss: 3.57018553e-06
Iter: 1594 loss: 3.56851319e-06
Iter: 1595 loss: 3.57919089e-06
Iter: 1596 loss: 3.56830674e-06
Iter: 1597 loss: 3.56684313e-06
Iter: 1598 loss: 3.57210729e-06
Iter: 1599 loss: 3.56646e-06
Iter: 1600 loss: 3.5650005e-06
Iter: 1601 loss: 3.5640137e-06
Iter: 1602 loss: 3.56344799e-06
Iter: 1603 loss: 3.56145711e-06
Iter: 1604 loss: 3.57177419e-06
Iter: 1605 loss: 3.56114151e-06
Iter: 1606 loss: 3.5596413e-06
Iter: 1607 loss: 3.57311774e-06
Iter: 1608 loss: 3.559574e-06
Iter: 1609 loss: 3.55825e-06
Iter: 1610 loss: 3.55700604e-06
Iter: 1611 loss: 3.55672114e-06
Iter: 1612 loss: 3.55481e-06
Iter: 1613 loss: 3.56477517e-06
Iter: 1614 loss: 3.5544922e-06
Iter: 1615 loss: 3.5527728e-06
Iter: 1616 loss: 3.55653356e-06
Iter: 1617 loss: 3.55206498e-06
Iter: 1618 loss: 3.55035627e-06
Iter: 1619 loss: 3.56885084e-06
Iter: 1620 loss: 3.55026896e-06
Iter: 1621 loss: 3.54893677e-06
Iter: 1622 loss: 3.55761404e-06
Iter: 1623 loss: 3.5487617e-06
Iter: 1624 loss: 3.54786721e-06
Iter: 1625 loss: 3.54677604e-06
Iter: 1626 loss: 3.54666281e-06
Iter: 1627 loss: 3.54534723e-06
Iter: 1628 loss: 3.54653321e-06
Iter: 1629 loss: 3.54455551e-06
Iter: 1630 loss: 3.54295958e-06
Iter: 1631 loss: 3.5538892e-06
Iter: 1632 loss: 3.54281337e-06
Iter: 1633 loss: 3.5413957e-06
Iter: 1634 loss: 3.54262875e-06
Iter: 1635 loss: 3.54056897e-06
Iter: 1636 loss: 3.53898213e-06
Iter: 1637 loss: 3.5390035e-06
Iter: 1638 loss: 3.53770974e-06
Iter: 1639 loss: 3.5357366e-06
Iter: 1640 loss: 3.55453358e-06
Iter: 1641 loss: 3.53564906e-06
Iter: 1642 loss: 3.53398036e-06
Iter: 1643 loss: 3.53850055e-06
Iter: 1644 loss: 3.53346013e-06
Iter: 1645 loss: 3.53200016e-06
Iter: 1646 loss: 3.53119412e-06
Iter: 1647 loss: 3.53054725e-06
Iter: 1648 loss: 3.52842881e-06
Iter: 1649 loss: 3.54478198e-06
Iter: 1650 loss: 3.52829511e-06
Iter: 1651 loss: 3.52685265e-06
Iter: 1652 loss: 3.53641826e-06
Iter: 1653 loss: 3.52666757e-06
Iter: 1654 loss: 3.52542656e-06
Iter: 1655 loss: 3.53572841e-06
Iter: 1656 loss: 3.52532311e-06
Iter: 1657 loss: 3.52424649e-06
Iter: 1658 loss: 3.52340567e-06
Iter: 1659 loss: 3.52305051e-06
Iter: 1660 loss: 3.52177767e-06
Iter: 1661 loss: 3.52348798e-06
Iter: 1662 loss: 3.52115558e-06
Iter: 1663 loss: 3.51997323e-06
Iter: 1664 loss: 3.52612028e-06
Iter: 1665 loss: 3.51985864e-06
Iter: 1666 loss: 3.51861354e-06
Iter: 1667 loss: 3.52019015e-06
Iter: 1668 loss: 3.51799235e-06
Iter: 1669 loss: 3.51670406e-06
Iter: 1670 loss: 3.51818244e-06
Iter: 1671 loss: 3.5160183e-06
Iter: 1672 loss: 3.51466861e-06
Iter: 1673 loss: 3.51850031e-06
Iter: 1674 loss: 3.51421227e-06
Iter: 1675 loss: 3.5127041e-06
Iter: 1676 loss: 3.52127449e-06
Iter: 1677 loss: 3.51249628e-06
Iter: 1678 loss: 3.51128392e-06
Iter: 1679 loss: 3.51192693e-06
Iter: 1680 loss: 3.51052859e-06
Iter: 1681 loss: 3.50917435e-06
Iter: 1682 loss: 3.511675e-06
Iter: 1683 loss: 3.50864457e-06
Iter: 1684 loss: 3.50712912e-06
Iter: 1685 loss: 3.51641097e-06
Iter: 1686 loss: 3.50690198e-06
Iter: 1687 loss: 3.50580854e-06
Iter: 1688 loss: 3.5210478e-06
Iter: 1689 loss: 3.50579353e-06
Iter: 1690 loss: 3.50496043e-06
Iter: 1691 loss: 3.50512391e-06
Iter: 1692 loss: 3.50429855e-06
Iter: 1693 loss: 3.50334449e-06
Iter: 1694 loss: 3.50235791e-06
Iter: 1695 loss: 3.50210462e-06
Iter: 1696 loss: 3.50061464e-06
Iter: 1697 loss: 3.50687105e-06
Iter: 1698 loss: 3.50030905e-06
Iter: 1699 loss: 3.49899983e-06
Iter: 1700 loss: 3.50718346e-06
Iter: 1701 loss: 3.4987911e-06
Iter: 1702 loss: 3.49762331e-06
Iter: 1703 loss: 3.49670927e-06
Iter: 1704 loss: 3.49632955e-06
Iter: 1705 loss: 3.49441e-06
Iter: 1706 loss: 3.49945321e-06
Iter: 1707 loss: 3.49376228e-06
Iter: 1708 loss: 3.4923255e-06
Iter: 1709 loss: 3.51081826e-06
Iter: 1710 loss: 3.4923346e-06
Iter: 1711 loss: 3.49120819e-06
Iter: 1712 loss: 3.49161792e-06
Iter: 1713 loss: 3.49038442e-06
Iter: 1714 loss: 3.4891068e-06
Iter: 1715 loss: 3.4912307e-06
Iter: 1716 loss: 3.48849835e-06
Iter: 1717 loss: 3.48724234e-06
Iter: 1718 loss: 3.49549146e-06
Iter: 1719 loss: 3.48710591e-06
Iter: 1720 loss: 3.48617073e-06
Iter: 1721 loss: 3.49686184e-06
Iter: 1722 loss: 3.48612957e-06
Iter: 1723 loss: 3.48525236e-06
Iter: 1724 loss: 3.48616777e-06
Iter: 1725 loss: 3.484731e-06
Iter: 1726 loss: 3.48378626e-06
Iter: 1727 loss: 3.48383969e-06
Iter: 1728 loss: 3.48308413e-06
Iter: 1729 loss: 3.48205413e-06
Iter: 1730 loss: 3.48303683e-06
Iter: 1731 loss: 3.48151e-06
Iter: 1732 loss: 3.48031335e-06
Iter: 1733 loss: 3.48719914e-06
Iter: 1734 loss: 3.48016715e-06
Iter: 1735 loss: 3.47897503e-06
Iter: 1736 loss: 3.48058279e-06
Iter: 1737 loss: 3.47841069e-06
Iter: 1738 loss: 3.47730065e-06
Iter: 1739 loss: 3.4782156e-06
Iter: 1740 loss: 3.47660216e-06
Iter: 1741 loss: 3.47530113e-06
Iter: 1742 loss: 3.48013464e-06
Iter: 1743 loss: 3.47496666e-06
Iter: 1744 loss: 3.47348464e-06
Iter: 1745 loss: 3.48105323e-06
Iter: 1746 loss: 3.47321384e-06
Iter: 1747 loss: 3.47217474e-06
Iter: 1748 loss: 3.47215882e-06
Iter: 1749 loss: 3.47129162e-06
Iter: 1750 loss: 3.46997467e-06
Iter: 1751 loss: 3.47613195e-06
Iter: 1752 loss: 3.46972388e-06
Iter: 1753 loss: 3.46874958e-06
Iter: 1754 loss: 3.48254389e-06
Iter: 1755 loss: 3.4687705e-06
Iter: 1756 loss: 3.46798311e-06
Iter: 1757 loss: 3.47138575e-06
Iter: 1758 loss: 3.46781371e-06
Iter: 1759 loss: 3.46717388e-06
Iter: 1760 loss: 3.46660431e-06
Iter: 1761 loss: 3.46645447e-06
Iter: 1762 loss: 3.465399e-06
Iter: 1763 loss: 3.46570323e-06
Iter: 1764 loss: 3.46462389e-06
Iter: 1765 loss: 3.46349248e-06
Iter: 1766 loss: 3.47109653e-06
Iter: 1767 loss: 3.46339243e-06
Iter: 1768 loss: 3.46233401e-06
Iter: 1769 loss: 3.4650393e-06
Iter: 1770 loss: 3.46193406e-06
Iter: 1771 loss: 3.46092065e-06
Iter: 1772 loss: 3.46103252e-06
Iter: 1773 loss: 3.46012894e-06
Iter: 1774 loss: 3.45897206e-06
Iter: 1775 loss: 3.46427441e-06
Iter: 1776 loss: 3.45871649e-06
Iter: 1777 loss: 3.45769058e-06
Iter: 1778 loss: 3.46362253e-06
Iter: 1779 loss: 3.4575487e-06
Iter: 1780 loss: 3.45654371e-06
Iter: 1781 loss: 3.4567106e-06
Iter: 1782 loss: 3.45573199e-06
Iter: 1783 loss: 3.45469152e-06
Iter: 1784 loss: 3.45818421e-06
Iter: 1785 loss: 3.4543782e-06
Iter: 1786 loss: 3.45347416e-06
Iter: 1787 loss: 3.46274419e-06
Iter: 1788 loss: 3.45347325e-06
Iter: 1789 loss: 3.4526247e-06
Iter: 1790 loss: 3.45711624e-06
Iter: 1791 loss: 3.45254966e-06
Iter: 1792 loss: 3.45184026e-06
Iter: 1793 loss: 3.45153194e-06
Iter: 1794 loss: 3.45116837e-06
Iter: 1795 loss: 3.45036233e-06
Iter: 1796 loss: 3.45141598e-06
Iter: 1797 loss: 3.44991395e-06
Iter: 1798 loss: 3.44902105e-06
Iter: 1799 loss: 3.4499742e-06
Iter: 1800 loss: 3.44851424e-06
Iter: 1801 loss: 3.44743694e-06
Iter: 1802 loss: 3.45644e-06
Iter: 1803 loss: 3.44741557e-06
Iter: 1804 loss: 3.44664068e-06
Iter: 1805 loss: 3.44676573e-06
Iter: 1806 loss: 3.44607156e-06
Iter: 1807 loss: 3.44507635e-06
Iter: 1808 loss: 3.4457712e-06
Iter: 1809 loss: 3.44449381e-06
Iter: 1810 loss: 3.44336468e-06
Iter: 1811 loss: 3.45397439e-06
Iter: 1812 loss: 3.44335604e-06
Iter: 1813 loss: 3.44237469e-06
Iter: 1814 loss: 3.44351838e-06
Iter: 1815 loss: 3.44187674e-06
Iter: 1816 loss: 3.44084538e-06
Iter: 1817 loss: 3.44197315e-06
Iter: 1818 loss: 3.44030263e-06
Iter: 1819 loss: 3.43943839e-06
Iter: 1820 loss: 3.4489226e-06
Iter: 1821 loss: 3.43940974e-06
Iter: 1822 loss: 3.43873262e-06
Iter: 1823 loss: 3.44642876e-06
Iter: 1824 loss: 3.43873671e-06
Iter: 1825 loss: 3.43829129e-06
Iter: 1826 loss: 3.43790543e-06
Iter: 1827 loss: 3.43770967e-06
Iter: 1828 loss: 3.43693932e-06
Iter: 1829 loss: 3.43706211e-06
Iter: 1830 loss: 3.43634906e-06
Iter: 1831 loss: 3.43541433e-06
Iter: 1832 loss: 3.43806846e-06
Iter: 1833 loss: 3.43511874e-06
Iter: 1834 loss: 3.43430474e-06
Iter: 1835 loss: 3.438975e-06
Iter: 1836 loss: 3.43417355e-06
Iter: 1837 loss: 3.43335114e-06
Iter: 1838 loss: 3.43350484e-06
Iter: 1839 loss: 3.43268607e-06
Iter: 1840 loss: 3.43160536e-06
Iter: 1841 loss: 3.43327451e-06
Iter: 1842 loss: 3.43110105e-06
Iter: 1843 loss: 3.43002284e-06
Iter: 1844 loss: 3.43409306e-06
Iter: 1845 loss: 3.42974545e-06
Iter: 1846 loss: 3.42858e-06
Iter: 1847 loss: 3.43431975e-06
Iter: 1848 loss: 3.42840804e-06
Iter: 1849 loss: 3.42741623e-06
Iter: 1850 loss: 3.42763633e-06
Iter: 1851 loss: 3.42673547e-06
Iter: 1852 loss: 3.42568228e-06
Iter: 1853 loss: 3.43143915e-06
Iter: 1854 loss: 3.4255695e-06
Iter: 1855 loss: 3.4248319e-06
Iter: 1856 loss: 3.42481e-06
Iter: 1857 loss: 3.42421299e-06
Iter: 1858 loss: 3.42425824e-06
Iter: 1859 loss: 3.42377507e-06
Iter: 1860 loss: 3.42301246e-06
Iter: 1861 loss: 3.42313342e-06
Iter: 1862 loss: 3.42243197e-06
Iter: 1863 loss: 3.42149406e-06
Iter: 1864 loss: 3.42228805e-06
Iter: 1865 loss: 3.4209188e-06
Iter: 1866 loss: 3.41982377e-06
Iter: 1867 loss: 3.42484964e-06
Iter: 1868 loss: 3.41956934e-06
Iter: 1869 loss: 3.41859618e-06
Iter: 1870 loss: 3.42449039e-06
Iter: 1871 loss: 3.41847681e-06
Iter: 1872 loss: 3.41774694e-06
Iter: 1873 loss: 3.41705982e-06
Iter: 1874 loss: 3.41687928e-06
Iter: 1875 loss: 3.4156019e-06
Iter: 1876 loss: 3.41946952e-06
Iter: 1877 loss: 3.41522127e-06
Iter: 1878 loss: 3.4141035e-06
Iter: 1879 loss: 3.42523026e-06
Iter: 1880 loss: 3.4140819e-06
Iter: 1881 loss: 3.41320492e-06
Iter: 1882 loss: 3.41299665e-06
Iter: 1883 loss: 3.41241434e-06
Iter: 1884 loss: 3.41124269e-06
Iter: 1885 loss: 3.41466648e-06
Iter: 1886 loss: 3.41087798e-06
Iter: 1887 loss: 3.41028453e-06
Iter: 1888 loss: 3.41021087e-06
Iter: 1889 loss: 3.40961287e-06
Iter: 1890 loss: 3.41004147e-06
Iter: 1891 loss: 3.40923339e-06
Iter: 1892 loss: 3.40852307e-06
Iter: 1893 loss: 3.4082741e-06
Iter: 1894 loss: 3.4078148e-06
Iter: 1895 loss: 3.40685574e-06
Iter: 1896 loss: 3.4087841e-06
Iter: 1897 loss: 3.40638439e-06
Iter: 1898 loss: 3.40549173e-06
Iter: 1899 loss: 3.40856946e-06
Iter: 1900 loss: 3.40526321e-06
Iter: 1901 loss: 3.40440533e-06
Iter: 1902 loss: 3.40851784e-06
Iter: 1903 loss: 3.40423617e-06
Iter: 1904 loss: 3.40330644e-06
Iter: 1905 loss: 3.40333372e-06
Iter: 1906 loss: 3.40263296e-06
Iter: 1907 loss: 3.40159636e-06
Iter: 1908 loss: 3.40391466e-06
Iter: 1909 loss: 3.40118959e-06
Iter: 1910 loss: 3.40017709e-06
Iter: 1911 loss: 3.40628867e-06
Iter: 1912 loss: 3.40002453e-06
Iter: 1913 loss: 3.39903727e-06
Iter: 1914 loss: 3.40149973e-06
Iter: 1915 loss: 3.39866938e-06
Iter: 1916 loss: 3.39779581e-06
Iter: 1917 loss: 3.39845201e-06
Iter: 1918 loss: 3.39735766e-06
Iter: 1919 loss: 3.39656981e-06
Iter: 1920 loss: 3.40810288e-06
Iter: 1921 loss: 3.39655276e-06
Iter: 1922 loss: 3.39576513e-06
Iter: 1923 loss: 3.39899952e-06
Iter: 1924 loss: 3.39563599e-06
Iter: 1925 loss: 3.39512189e-06
Iter: 1926 loss: 3.39492703e-06
Iter: 1927 loss: 3.39465123e-06
Iter: 1928 loss: 3.39390681e-06
Iter: 1929 loss: 3.39405187e-06
Iter: 1930 loss: 3.39333474e-06
Iter: 1931 loss: 3.39229246e-06
Iter: 1932 loss: 3.39372446e-06
Iter: 1933 loss: 3.39171129e-06
Iter: 1934 loss: 3.3907495e-06
Iter: 1935 loss: 3.40072665e-06
Iter: 1936 loss: 3.39069948e-06
Iter: 1937 loss: 3.38992254e-06
Iter: 1938 loss: 3.39090639e-06
Iter: 1939 loss: 3.38946938e-06
Iter: 1940 loss: 3.38855352e-06
Iter: 1941 loss: 3.38838117e-06
Iter: 1942 loss: 3.38782206e-06
Iter: 1943 loss: 3.38663813e-06
Iter: 1944 loss: 3.39429107e-06
Iter: 1945 loss: 3.38647169e-06
Iter: 1946 loss: 3.38540735e-06
Iter: 1947 loss: 3.3900053e-06
Iter: 1948 loss: 3.38521568e-06
Iter: 1949 loss: 3.38420705e-06
Iter: 1950 loss: 3.38379095e-06
Iter: 1951 loss: 3.38327027e-06
Iter: 1952 loss: 3.38234418e-06
Iter: 1953 loss: 3.38235373e-06
Iter: 1954 loss: 3.38166706e-06
Iter: 1955 loss: 3.38809059e-06
Iter: 1956 loss: 3.38159612e-06
Iter: 1957 loss: 3.38109726e-06
Iter: 1958 loss: 3.38036807e-06
Iter: 1959 loss: 3.38032828e-06
Iter: 1960 loss: 3.37923939e-06
Iter: 1961 loss: 3.38048039e-06
Iter: 1962 loss: 3.37874644e-06
Iter: 1963 loss: 3.3776073e-06
Iter: 1964 loss: 3.38032351e-06
Iter: 1965 loss: 3.37722531e-06
Iter: 1966 loss: 3.37618167e-06
Iter: 1967 loss: 3.38032669e-06
Iter: 1968 loss: 3.37596362e-06
Iter: 1969 loss: 3.37492747e-06
Iter: 1970 loss: 3.37947176e-06
Iter: 1971 loss: 3.37475285e-06
Iter: 1972 loss: 3.37392748e-06
Iter: 1973 loss: 3.37383676e-06
Iter: 1974 loss: 3.37325537e-06
Iter: 1975 loss: 3.37210531e-06
Iter: 1976 loss: 3.37477923e-06
Iter: 1977 loss: 3.37169126e-06
Iter: 1978 loss: 3.37050437e-06
Iter: 1979 loss: 3.37983465e-06
Iter: 1980 loss: 3.37047527e-06
Iter: 1981 loss: 3.36950143e-06
Iter: 1982 loss: 3.37007486e-06
Iter: 1983 loss: 3.36887115e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.4 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.4
+ date
Mon Nov  2 12:29:00 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.4/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80496950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80543950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa804eb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80559730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa805c7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa804eb6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa803bdae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa803bd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80326488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa801b6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa801e5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa802c5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa802c57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa802cb158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa802cc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa802c5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa801e4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8035aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa801e4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8035a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80103488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa800cd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80103f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8004fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8004f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8004f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8004fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8007ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa800780d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80078a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa8009d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80078e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa80078c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa804208c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa346c8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa34606f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 13730.755
test_loss: 16560.146
train_loss: 10765.299
test_loss: 14657.619
train_loss: 8905.401
test_loss: 124319.4
train_loss: 9149.076
test_loss: 2825695.2
train_loss: 18151.705
test_loss: 2880970.8
train_loss: 29083.62
test_loss: 19326.258
train_loss: 22525.93
test_loss: 20636.25
train_loss: 27260.287
test_loss: 19172.443
train_loss: 22111.193
test_loss: 17985.143
train_loss: 63070.824
test_loss: 21776.98
train_loss: 10691.795
test_loss: 21107.02
train_loss: 31112.969
test_loss: 22447.91
train_loss: 58720.594
test_loss: 19102.81
train_loss: 6531.1753
test_loss: 22224.074
train_loss: 22495.361
test_loss: 20580.018
train_loss: 4463.12
test_loss: 23675.586
train_loss: 30931.523
test_loss: 25041.098
train_loss: 32658.053
test_loss: 20816.582
train_loss: 23076.643
test_loss: 23552.297
train_loss: 19710.133
test_loss: 21236.604
train_loss: 13203.88
test_loss: 19680.924
train_loss: 10088.41
test_loss: 25598.912
train_loss: 15775.449
test_loss: 22960.777
train_loss: 20332.496
test_loss: 23239.336
train_loss: 65458.957
test_loss: 22329.178
train_loss: 16435.969
test_loss: 20690.873
train_loss: 30717.32
test_loss: 50172.266
train_loss: 67534.11
test_loss: 25000.299
train_loss: 20016.635
test_loss: 27630.588
train_loss: 12703.926
test_loss: 23120.316
train_loss: 23616.979
test_loss: 32938.15
train_loss: 10931.794
test_loss: 23127.586
train_loss: 29039.09
test_loss: 21468.494
train_loss: 23335.883
test_loss: 23830.42
train_loss: 30660.174
test_loss: 18440.428
train_loss: 42855.246
test_loss: 179963.67
train_loss: 12309.652
test_loss: 21284.443
train_loss: 5192.975
test_loss: 49290.086
train_loss: 14085.947
test_loss: 22728.129
train_loss: 24542.922
test_loss: 27353.738
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.4/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa2bcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa39b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa3d78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa322730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa322268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa3d7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa27b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa1fe6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa1fe158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3e330d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2afa1fea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3e5ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3ea1f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3ea12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3eacd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3ec1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3eb32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3e96268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3e69bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3de40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3d28f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3d28268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3d28158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3d04158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3cde730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3ca5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3c16d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3c97048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3b7c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3b85268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3b7c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3b7c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3c3c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3b85158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3bea378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2af3bd6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 419142.344
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_32]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_14711]

Function call stack:
f -> f

++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.8 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.8
+ date
Mon Nov  2 13:12:13 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.8/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186026d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186024aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18602b67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18603a6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18603a61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18603a6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18603a62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18600d9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18600d92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186001ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1860024158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186001ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186001e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186015c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186014b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186005c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f186005d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1814564ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f181455fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1814564268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18600ab620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f181463c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18600abb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1814425f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1814440620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18145b3c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18145b3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18601e71e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18143ee0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18143eea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18143e2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18143eee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18143ee598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18142a68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f181450e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1814523f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.029683689
test_loss: 0.025392555
train_loss: 0.0071975095
test_loss: 0.007874403
train_loss: 0.0039508995
test_loss: 0.004244269
train_loss: 0.0028488887
test_loss: 0.0029940475
train_loss: 0.0021958654
test_loss: 0.0023312964
train_loss: 0.0017983166
test_loss: 0.0018301357
train_loss: 0.0013764073
test_loss: 0.0014335547
train_loss: 0.0009641154
test_loss: 0.0010661758
train_loss: 0.00075718825
test_loss: 0.0008747807
train_loss: 0.0007724976
test_loss: 0.0007572951
train_loss: 0.0006265019
test_loss: 0.0006281438
train_loss: 0.00050947524
test_loss: 0.0005539252
train_loss: 0.00044424328
test_loss: 0.0004942837
train_loss: 0.00040115623
test_loss: 0.0004375222
train_loss: 0.00036457554
test_loss: 0.00039660718
train_loss: 0.00034084587
test_loss: 0.00035571514
train_loss: 0.0002955374
test_loss: 0.00032904427
train_loss: 0.00028420464
test_loss: 0.00030250588
train_loss: 0.0002777846
test_loss: 0.00028179004
train_loss: 0.00025222532
test_loss: 0.00026369147
train_loss: 0.00020718134
test_loss: 0.00024754545
train_loss: 0.00020474645
test_loss: 0.00023540725
train_loss: 0.00020948864
test_loss: 0.00022717187
train_loss: 0.00020434169
test_loss: 0.0002165639
train_loss: 0.00018538284
test_loss: 0.0002063822
train_loss: 0.00018169287
test_loss: 0.00019786815
train_loss: 0.00016915088
test_loss: 0.00019160692
train_loss: 0.00015103888
test_loss: 0.00018753659
train_loss: 0.00017449344
test_loss: 0.00018027985
train_loss: 0.00016596912
test_loss: 0.0001756606
train_loss: 0.0001589099
test_loss: 0.00017294954
train_loss: 0.00015067827
test_loss: 0.00016687282
train_loss: 0.00015005626
test_loss: 0.00016376059
train_loss: 0.00015013982
test_loss: 0.00016134421
train_loss: 0.00013954498
test_loss: 0.00015851221
train_loss: 0.00014753923
test_loss: 0.000155363
train_loss: 0.00014032883
test_loss: 0.00015296786
train_loss: 0.000128071
test_loss: 0.00015105812
train_loss: 0.00013241933
test_loss: 0.00014860099
train_loss: 0.0001224388
test_loss: 0.00014747192
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi2.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi2.8/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7ccf0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7cd0eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7cd74d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7ce05378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7ce05510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7ce05268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7cc78a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f7ccb8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53f97598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53edb158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53edb9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53f05ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53f52d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53f481e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53f37f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53ec2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53eb2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53f15510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c4b3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f53eb2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c406950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c3dab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c3da1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c37db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c37dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c37d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c2f4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c2f4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c2e2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c3372f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c31e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c25df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c292730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c3371e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c292d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9f2c1bfbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.000133905414
Iter: 2 loss: 0.000164687503
Iter: 3 loss: 0.000133404887
Iter: 4 loss: 0.000133037756
Iter: 5 loss: 0.000133683323
Iter: 6 loss: 0.000132874149
Iter: 7 loss: 0.000132705041
Iter: 8 loss: 0.000132433037
Iter: 9 loss: 0.000132430883
Iter: 10 loss: 0.000132223111
Iter: 11 loss: 0.000132565299
Iter: 12 loss: 0.000132127752
Iter: 13 loss: 0.000131980749
Iter: 14 loss: 0.000131861016
Iter: 15 loss: 0.000131817971
Iter: 16 loss: 0.000131683832
Iter: 17 loss: 0.000131593697
Iter: 18 loss: 0.000131543478
Iter: 19 loss: 0.00013140119
Iter: 20 loss: 0.000131483743
Iter: 21 loss: 0.000131309163
Iter: 22 loss: 0.000131143941
Iter: 23 loss: 0.000131227076
Iter: 24 loss: 0.000131034205
Iter: 25 loss: 0.000130822184
Iter: 26 loss: 0.000131000605
Iter: 27 loss: 0.000130696862
Iter: 28 loss: 0.000130446424
Iter: 29 loss: 0.000130985689
Iter: 30 loss: 0.000130348664
Iter: 31 loss: 0.000130062806
Iter: 32 loss: 0.000131600638
Iter: 33 loss: 0.000130019936
Iter: 34 loss: 0.00012982756
Iter: 35 loss: 0.000130173867
Iter: 36 loss: 0.000129743828
Iter: 37 loss: 0.000129536798
Iter: 38 loss: 0.000130165266
Iter: 39 loss: 0.000129475287
Iter: 40 loss: 0.000129662571
Iter: 41 loss: 0.000129408087
Iter: 42 loss: 0.000129370281
Iter: 43 loss: 0.000129264576
Iter: 44 loss: 0.000129856198
Iter: 45 loss: 0.000129233347
Iter: 46 loss: 0.000129112275
Iter: 47 loss: 0.00013081127
Iter: 48 loss: 0.000129112319
Iter: 49 loss: 0.000129043314
Iter: 50 loss: 0.000128908083
Iter: 51 loss: 0.000131619716
Iter: 52 loss: 0.000128906948
Iter: 53 loss: 0.000128743777
Iter: 54 loss: 0.000129093736
Iter: 55 loss: 0.000128680316
Iter: 56 loss: 0.000128484739
Iter: 57 loss: 0.000128525455
Iter: 58 loss: 0.000128339598
Iter: 59 loss: 0.000128123967
Iter: 60 loss: 0.000128808897
Iter: 61 loss: 0.000128062529
Iter: 62 loss: 0.000127854597
Iter: 63 loss: 0.000128280037
Iter: 64 loss: 0.000127771651
Iter: 65 loss: 0.000127601495
Iter: 66 loss: 0.000128434272
Iter: 67 loss: 0.000127571868
Iter: 68 loss: 0.000127415784
Iter: 69 loss: 0.000127573672
Iter: 70 loss: 0.000127328763
Iter: 71 loss: 0.000127139487
Iter: 72 loss: 0.000127042542
Iter: 73 loss: 0.000126954765
Iter: 74 loss: 0.000126727449
Iter: 75 loss: 0.000127215491
Iter: 76 loss: 0.000126639061
Iter: 77 loss: 0.000126724335
Iter: 78 loss: 0.000126525934
Iter: 79 loss: 0.000126486688
Iter: 80 loss: 0.000126395113
Iter: 81 loss: 0.000127470557
Iter: 82 loss: 0.000126387677
Iter: 83 loss: 0.000126244267
Iter: 84 loss: 0.000126646511
Iter: 85 loss: 0.000126198982
Iter: 86 loss: 0.000126088431
Iter: 87 loss: 0.000125929859
Iter: 88 loss: 0.000125925115
Iter: 89 loss: 0.000125657156
Iter: 90 loss: 0.000126393803
Iter: 91 loss: 0.000125569815
Iter: 92 loss: 0.000125353457
Iter: 93 loss: 0.000125381426
Iter: 94 loss: 0.000125188759
Iter: 95 loss: 0.000124861021
Iter: 96 loss: 0.000126612053
Iter: 97 loss: 0.000124811981
Iter: 98 loss: 0.000124528946
Iter: 99 loss: 0.000124806887
Iter: 100 loss: 0.000124368569
Iter: 101 loss: 0.000124086917
Iter: 102 loss: 0.000127338833
Iter: 103 loss: 0.000124082537
Iter: 104 loss: 0.000123872946
Iter: 105 loss: 0.000123747785
Iter: 106 loss: 0.000123660837
Iter: 107 loss: 0.000123375
Iter: 108 loss: 0.000123372476
Iter: 109 loss: 0.00012362127
Iter: 110 loss: 0.000123305639
Iter: 111 loss: 0.000123276055
Iter: 112 loss: 0.000123193546
Iter: 113 loss: 0.00012370685
Iter: 114 loss: 0.000123171805
Iter: 115 loss: 0.000122979211
Iter: 116 loss: 0.000124127575
Iter: 117 loss: 0.000122956219
Iter: 118 loss: 0.000122842321
Iter: 119 loss: 0.000123044811
Iter: 120 loss: 0.000122791826
Iter: 121 loss: 0.000122598794
Iter: 122 loss: 0.000122528421
Iter: 123 loss: 0.000122420635
Iter: 124 loss: 0.000122220372
Iter: 125 loss: 0.000124275961
Iter: 126 loss: 0.000122214566
Iter: 127 loss: 0.000122028301
Iter: 128 loss: 0.000122334837
Iter: 129 loss: 0.000121944031
Iter: 130 loss: 0.000121719757
Iter: 131 loss: 0.000121910241
Iter: 132 loss: 0.000121586796
Iter: 133 loss: 0.000121340214
Iter: 134 loss: 0.000121849596
Iter: 135 loss: 0.000121242032
Iter: 136 loss: 0.000120944809
Iter: 137 loss: 0.000121529913
Iter: 138 loss: 0.000120821947
Iter: 139 loss: 0.00012054266
Iter: 140 loss: 0.000121616686
Iter: 141 loss: 0.000120476812
Iter: 142 loss: 0.000120227443
Iter: 143 loss: 0.000121183781
Iter: 144 loss: 0.000120168217
Iter: 145 loss: 0.000120390119
Iter: 146 loss: 0.00012008757
Iter: 147 loss: 0.000120038007
Iter: 148 loss: 0.000119902572
Iter: 149 loss: 0.000120686564
Iter: 150 loss: 0.000119866061
Iter: 151 loss: 0.000119676624
Iter: 152 loss: 0.000120468889
Iter: 153 loss: 0.000119635661
Iter: 154 loss: 0.000119490964
Iter: 155 loss: 0.000119435
Iter: 156 loss: 0.000119356468
Iter: 157 loss: 0.000119022632
Iter: 158 loss: 0.00011970842
Iter: 159 loss: 0.000118888158
Iter: 160 loss: 0.000118654367
Iter: 161 loss: 0.000118617434
Iter: 162 loss: 0.000118396543
Iter: 163 loss: 0.00011851349
Iter: 164 loss: 0.000118251439
Iter: 165 loss: 0.000118004435
Iter: 166 loss: 0.000117856893
Iter: 167 loss: 0.00011775452
Iter: 168 loss: 0.000117457166
Iter: 169 loss: 0.000118847034
Iter: 170 loss: 0.00011740208
Iter: 171 loss: 0.00011714935
Iter: 172 loss: 0.000117441174
Iter: 173 loss: 0.000117015021
Iter: 174 loss: 0.00011675834
Iter: 175 loss: 0.000117559772
Iter: 176 loss: 0.000116682524
Iter: 177 loss: 0.000116728283
Iter: 178 loss: 0.000116586278
Iter: 179 loss: 0.000116485171
Iter: 180 loss: 0.000116317518
Iter: 181 loss: 0.000116317271
Iter: 182 loss: 0.000116182171
Iter: 183 loss: 0.000116406089
Iter: 184 loss: 0.000116120849
Iter: 185 loss: 0.000115958537
Iter: 186 loss: 0.000116327254
Iter: 187 loss: 0.000115897783
Iter: 188 loss: 0.000115685347
Iter: 189 loss: 0.000115864736
Iter: 190 loss: 0.00011555689
Iter: 191 loss: 0.000115327479
Iter: 192 loss: 0.00011525939
Iter: 193 loss: 0.000115121948
Iter: 194 loss: 0.000114923401
Iter: 195 loss: 0.000115481154
Iter: 196 loss: 0.000114859948
Iter: 197 loss: 0.000114683658
Iter: 198 loss: 0.000114950089
Iter: 199 loss: 0.000114599789
Iter: 200 loss: 0.000114388538
Iter: 201 loss: 0.000114675669
Iter: 202 loss: 0.000114282731
Iter: 203 loss: 0.000114031936
Iter: 204 loss: 0.000114203831
Iter: 205 loss: 0.00011387399
Iter: 206 loss: 0.000113511109
Iter: 207 loss: 0.000114872717
Iter: 208 loss: 0.000113426431
Iter: 209 loss: 0.000113421156
Iter: 210 loss: 0.000113289585
Iter: 211 loss: 0.00011321326
Iter: 212 loss: 0.000113114453
Iter: 213 loss: 0.000113108006
Iter: 214 loss: 0.000112943657
Iter: 215 loss: 0.000112781374
Iter: 216 loss: 0.000112747512
Iter: 217 loss: 0.000112500464
Iter: 218 loss: 0.00011536634
Iter: 219 loss: 0.000112495938
Iter: 220 loss: 0.000112307433
Iter: 221 loss: 0.000112320049
Iter: 222 loss: 0.000112160567
Iter: 223 loss: 0.000111880589
Iter: 224 loss: 0.000111969486
Iter: 225 loss: 0.000111680361
Iter: 226 loss: 0.000111502406
Iter: 227 loss: 0.000111485351
Iter: 228 loss: 0.000111346126
Iter: 229 loss: 0.000111223882
Iter: 230 loss: 0.000111187022
Iter: 231 loss: 0.000110940411
Iter: 232 loss: 0.000110938861
Iter: 233 loss: 0.000110743014
Iter: 234 loss: 0.000110443478
Iter: 235 loss: 0.000111152956
Iter: 236 loss: 0.000110334746
Iter: 237 loss: 0.000110024062
Iter: 238 loss: 0.000111323956
Iter: 239 loss: 0.000109958011
Iter: 240 loss: 0.000109921777
Iter: 241 loss: 0.000109842083
Iter: 242 loss: 0.000109705
Iter: 243 loss: 0.000109638109
Iter: 244 loss: 0.0001095716
Iter: 245 loss: 0.000109381457
Iter: 246 loss: 0.000109637607
Iter: 247 loss: 0.000109286208
Iter: 248 loss: 0.000109077278
Iter: 249 loss: 0.000109477565
Iter: 250 loss: 0.000108986016
Iter: 251 loss: 0.000108812885
Iter: 252 loss: 0.000110817084
Iter: 253 loss: 0.000108810113
Iter: 254 loss: 0.000108621716
Iter: 255 loss: 0.00010875499
Iter: 256 loss: 0.000108503831
Iter: 257 loss: 0.000108303844
Iter: 258 loss: 0.000108311651
Iter: 259 loss: 0.000108147055
Iter: 260 loss: 0.000108037493
Iter: 261 loss: 0.000107991764
Iter: 262 loss: 0.000107842468
Iter: 263 loss: 0.000107934444
Iter: 264 loss: 0.000107743253
Iter: 265 loss: 0.000107572545
Iter: 266 loss: 0.000107810061
Iter: 267 loss: 0.000107488806
Iter: 268 loss: 0.00010730241
Iter: 269 loss: 0.0001073694
Iter: 270 loss: 0.000107168606
Iter: 271 loss: 0.00010701039
Iter: 272 loss: 0.000107102867
Iter: 273 loss: 0.000106908723
Iter: 274 loss: 0.00010672948
Iter: 275 loss: 0.000107740125
Iter: 276 loss: 0.000106704436
Iter: 277 loss: 0.000106473453
Iter: 278 loss: 0.000107456683
Iter: 279 loss: 0.000106423366
Iter: 280 loss: 0.000106269974
Iter: 281 loss: 0.000106194871
Iter: 282 loss: 0.00010612121
Iter: 283 loss: 0.000105923085
Iter: 284 loss: 0.000106025538
Iter: 285 loss: 0.000105787301
Iter: 286 loss: 0.000105522297
Iter: 287 loss: 0.000106637672
Iter: 288 loss: 0.000105466373
Iter: 289 loss: 0.000105222149
Iter: 290 loss: 0.000106305291
Iter: 291 loss: 0.000105173225
Iter: 292 loss: 0.000104977786
Iter: 293 loss: 0.000106446234
Iter: 294 loss: 0.000104962295
Iter: 295 loss: 0.000104824685
Iter: 296 loss: 0.00010516154
Iter: 297 loss: 0.000104775609
Iter: 298 loss: 0.00010461059
Iter: 299 loss: 0.000104397826
Iter: 300 loss: 0.000104383245
Iter: 301 loss: 0.000104248451
Iter: 302 loss: 0.000104228602
Iter: 303 loss: 0.000104075094
Iter: 304 loss: 0.000104526145
Iter: 305 loss: 0.000104028164
Iter: 306 loss: 0.000103912396
Iter: 307 loss: 0.000104025865
Iter: 308 loss: 0.000103846891
Iter: 309 loss: 0.00010372643
Iter: 310 loss: 0.000104027044
Iter: 311 loss: 0.000103683407
Iter: 312 loss: 0.000103541912
Iter: 313 loss: 0.00010377969
Iter: 314 loss: 0.000103478334
Iter: 315 loss: 0.000103309489
Iter: 316 loss: 0.000103540428
Iter: 317 loss: 0.000103225102
Iter: 318 loss: 0.000103073049
Iter: 319 loss: 0.000102936334
Iter: 320 loss: 0.000102898433
Iter: 321 loss: 0.000102642436
Iter: 322 loss: 0.000103369006
Iter: 323 loss: 0.000102561
Iter: 324 loss: 0.00010228507
Iter: 325 loss: 0.00010299086
Iter: 326 loss: 0.000102190737
Iter: 327 loss: 0.000102016071
Iter: 328 loss: 0.000104646744
Iter: 329 loss: 0.000102015969
Iter: 330 loss: 0.000101874502
Iter: 331 loss: 0.000102286183
Iter: 332 loss: 0.000101831101
Iter: 333 loss: 0.00010165562
Iter: 334 loss: 0.000101559432
Iter: 335 loss: 0.000101480582
Iter: 336 loss: 0.000101362064
Iter: 337 loss: 0.000101342113
Iter: 338 loss: 0.000101250087
Iter: 339 loss: 0.000102254962
Iter: 340 loss: 0.000101248021
Iter: 341 loss: 0.000101175683
Iter: 342 loss: 0.000100996367
Iter: 343 loss: 0.000102706443
Iter: 344 loss: 0.000100971636
Iter: 345 loss: 0.00010084
Iter: 346 loss: 0.000100836856
Iter: 347 loss: 0.000100713063
Iter: 348 loss: 0.000100818725
Iter: 349 loss: 0.000100635676
Iter: 350 loss: 0.000100406738
Iter: 351 loss: 0.000100648591
Iter: 352 loss: 0.000100281715
Iter: 353 loss: 0.000100112775
Iter: 354 loss: 0.000100852747
Iter: 355 loss: 0.000100077988
Iter: 356 loss: 9.99979893e-05
Iter: 357 loss: 9.98727046e-05
Iter: 358 loss: 9.98714822e-05
Iter: 359 loss: 9.96139133e-05
Iter: 360 loss: 0.000100811914
Iter: 361 loss: 9.95652081e-05
Iter: 362 loss: 9.9312565e-05
Iter: 363 loss: 9.93082213e-05
Iter: 364 loss: 9.91312409e-05
Iter: 365 loss: 9.98971664e-05
Iter: 366 loss: 9.90953849e-05
Iter: 367 loss: 9.89430337e-05
Iter: 368 loss: 9.93520807e-05
Iter: 369 loss: 9.8887409e-05
Iter: 370 loss: 9.87352541e-05
Iter: 371 loss: 9.9460507e-05
Iter: 372 loss: 9.87082894e-05
Iter: 373 loss: 9.86017476e-05
Iter: 374 loss: 9.87222811e-05
Iter: 375 loss: 9.8544333e-05
Iter: 376 loss: 9.84113358e-05
Iter: 377 loss: 9.94902075e-05
Iter: 378 loss: 9.84018043e-05
Iter: 379 loss: 9.82080819e-05
Iter: 380 loss: 9.85957449e-05
Iter: 381 loss: 9.81322228e-05
Iter: 382 loss: 9.79657052e-05
Iter: 383 loss: 9.79086471e-05
Iter: 384 loss: 9.78135649e-05
Iter: 385 loss: 9.76243173e-05
Iter: 386 loss: 9.95936e-05
Iter: 387 loss: 9.76193041e-05
Iter: 388 loss: 9.74708819e-05
Iter: 389 loss: 9.93685535e-05
Iter: 390 loss: 9.74697687e-05
Iter: 391 loss: 9.73861752e-05
Iter: 392 loss: 9.7315984e-05
Iter: 393 loss: 9.72899e-05
Iter: 394 loss: 9.70866095e-05
Iter: 395 loss: 9.80048062e-05
Iter: 396 loss: 9.70491747e-05
Iter: 397 loss: 9.68873937e-05
Iter: 398 loss: 9.73394053e-05
Iter: 399 loss: 9.68354288e-05
Iter: 400 loss: 9.66996304e-05
Iter: 401 loss: 9.74058494e-05
Iter: 402 loss: 9.6677657e-05
Iter: 403 loss: 9.65547515e-05
Iter: 404 loss: 9.71493e-05
Iter: 405 loss: 9.65337749e-05
Iter: 406 loss: 9.6443182e-05
Iter: 407 loss: 9.64541905e-05
Iter: 408 loss: 9.63739658e-05
Iter: 409 loss: 9.61953701e-05
Iter: 410 loss: 9.61859e-05
Iter: 411 loss: 9.6050062e-05
Iter: 412 loss: 9.58672e-05
Iter: 413 loss: 9.85181905e-05
Iter: 414 loss: 9.58667952e-05
Iter: 415 loss: 9.57251177e-05
Iter: 416 loss: 9.59821627e-05
Iter: 417 loss: 9.56644508e-05
Iter: 418 loss: 9.54846619e-05
Iter: 419 loss: 9.55224605e-05
Iter: 420 loss: 9.53521e-05
Iter: 421 loss: 9.53682102e-05
Iter: 422 loss: 9.52738e-05
Iter: 423 loss: 9.52029513e-05
Iter: 424 loss: 9.51360053e-05
Iter: 425 loss: 9.51193215e-05
Iter: 426 loss: 9.50078174e-05
Iter: 427 loss: 9.49552341e-05
Iter: 428 loss: 9.48998204e-05
Iter: 429 loss: 9.47145672e-05
Iter: 430 loss: 9.53027338e-05
Iter: 431 loss: 9.46615328e-05
Iter: 432 loss: 9.44829881e-05
Iter: 433 loss: 9.50028e-05
Iter: 434 loss: 9.4426432e-05
Iter: 435 loss: 9.42384795e-05
Iter: 436 loss: 9.45850843e-05
Iter: 437 loss: 9.41586477e-05
Iter: 438 loss: 9.40154787e-05
Iter: 439 loss: 9.5151714e-05
Iter: 440 loss: 9.40063037e-05
Iter: 441 loss: 9.38470912e-05
Iter: 442 loss: 9.43028281e-05
Iter: 443 loss: 9.3797993e-05
Iter: 444 loss: 9.36798679e-05
Iter: 445 loss: 9.3660623e-05
Iter: 446 loss: 9.35795324e-05
Iter: 447 loss: 9.34356431e-05
Iter: 448 loss: 9.4560819e-05
Iter: 449 loss: 9.34251148e-05
Iter: 450 loss: 9.33040646e-05
Iter: 451 loss: 9.40083264e-05
Iter: 452 loss: 9.32879266e-05
Iter: 453 loss: 9.31839895e-05
Iter: 454 loss: 9.32644907e-05
Iter: 455 loss: 9.31207906e-05
Iter: 456 loss: 9.31088944e-05
Iter: 457 loss: 9.30480455e-05
Iter: 458 loss: 9.29869e-05
Iter: 459 loss: 9.31393e-05
Iter: 460 loss: 9.29646922e-05
Iter: 461 loss: 9.2881317e-05
Iter: 462 loss: 9.28387963e-05
Iter: 463 loss: 9.28001245e-05
Iter: 464 loss: 9.26331122e-05
Iter: 465 loss: 9.3068018e-05
Iter: 466 loss: 9.25764471e-05
Iter: 467 loss: 9.24071428e-05
Iter: 468 loss: 9.22935869e-05
Iter: 469 loss: 9.22305335e-05
Iter: 470 loss: 9.20433595e-05
Iter: 471 loss: 9.42922125e-05
Iter: 472 loss: 9.20408638e-05
Iter: 473 loss: 9.1902446e-05
Iter: 474 loss: 9.23562184e-05
Iter: 475 loss: 9.18647929e-05
Iter: 476 loss: 9.17493599e-05
Iter: 477 loss: 9.17488214e-05
Iter: 478 loss: 9.16612262e-05
Iter: 479 loss: 9.1705e-05
Iter: 480 loss: 9.16025747e-05
Iter: 481 loss: 9.15092533e-05
Iter: 482 loss: 9.17212164e-05
Iter: 483 loss: 9.14745324e-05
Iter: 484 loss: 9.13707772e-05
Iter: 485 loss: 9.1594964e-05
Iter: 486 loss: 9.13302501e-05
Iter: 487 loss: 9.12512332e-05
Iter: 488 loss: 9.2501039e-05
Iter: 489 loss: 9.12511314e-05
Iter: 490 loss: 9.11840834e-05
Iter: 491 loss: 9.1988084e-05
Iter: 492 loss: 9.11830793e-05
Iter: 493 loss: 9.11537427e-05
Iter: 494 loss: 9.10649105e-05
Iter: 495 loss: 9.12920805e-05
Iter: 496 loss: 9.10152739e-05
Iter: 497 loss: 9.08815709e-05
Iter: 498 loss: 9.1949405e-05
Iter: 499 loss: 9.0872476e-05
Iter: 500 loss: 9.07485955e-05
Iter: 501 loss: 9.06570349e-05
Iter: 502 loss: 9.061538e-05
Iter: 503 loss: 9.0421192e-05
Iter: 504 loss: 9.14864431e-05
Iter: 505 loss: 9.03918481e-05
Iter: 506 loss: 9.01953172e-05
Iter: 507 loss: 9.07306312e-05
Iter: 508 loss: 9.01329404e-05
Iter: 509 loss: 8.99789884e-05
Iter: 510 loss: 9.13508557e-05
Iter: 511 loss: 8.99719598e-05
Iter: 512 loss: 8.98288e-05
Iter: 513 loss: 9.06554706e-05
Iter: 514 loss: 8.98095896e-05
Iter: 515 loss: 8.97080172e-05
Iter: 516 loss: 8.95336925e-05
Iter: 517 loss: 8.95334888e-05
Iter: 518 loss: 8.93711331e-05
Iter: 519 loss: 9.10779781e-05
Iter: 520 loss: 8.93668184e-05
Iter: 521 loss: 8.92470125e-05
Iter: 522 loss: 8.94529658e-05
Iter: 523 loss: 8.91937234e-05
Iter: 524 loss: 8.90644151e-05
Iter: 525 loss: 8.91446398e-05
Iter: 526 loss: 8.89784569e-05
Iter: 527 loss: 8.90125593e-05
Iter: 528 loss: 8.89062649e-05
Iter: 529 loss: 8.88552822e-05
Iter: 530 loss: 8.88204377e-05
Iter: 531 loss: 8.88018549e-05
Iter: 532 loss: 8.8619192e-05
Iter: 533 loss: 8.86421694e-05
Iter: 534 loss: 8.84767942e-05
Iter: 535 loss: 8.82604145e-05
Iter: 536 loss: 8.97697319e-05
Iter: 537 loss: 8.82407039e-05
Iter: 538 loss: 8.80574953e-05
Iter: 539 loss: 8.83684479e-05
Iter: 540 loss: 8.79751897e-05
Iter: 541 loss: 8.7777531e-05
Iter: 542 loss: 8.9112189e-05
Iter: 543 loss: 8.77583952e-05
Iter: 544 loss: 8.76239646e-05
Iter: 545 loss: 8.82995082e-05
Iter: 546 loss: 8.76017511e-05
Iter: 547 loss: 8.74479e-05
Iter: 548 loss: 8.82575e-05
Iter: 549 loss: 8.74244579e-05
Iter: 550 loss: 8.73202371e-05
Iter: 551 loss: 8.72085511e-05
Iter: 552 loss: 8.7190565e-05
Iter: 553 loss: 8.7039065e-05
Iter: 554 loss: 8.84574401e-05
Iter: 555 loss: 8.70327494e-05
Iter: 556 loss: 8.69089199e-05
Iter: 557 loss: 8.73141253e-05
Iter: 558 loss: 8.68743082e-05
Iter: 559 loss: 8.67778872e-05
Iter: 560 loss: 8.67752096e-05
Iter: 561 loss: 8.66817281e-05
Iter: 562 loss: 8.67180497e-05
Iter: 563 loss: 8.6616863e-05
Iter: 564 loss: 8.64723697e-05
Iter: 565 loss: 8.6586e-05
Iter: 566 loss: 8.63854293e-05
Iter: 567 loss: 8.6227752e-05
Iter: 568 loss: 8.60462533e-05
Iter: 569 loss: 8.60241344e-05
Iter: 570 loss: 8.57877312e-05
Iter: 571 loss: 8.67546187e-05
Iter: 572 loss: 8.57350897e-05
Iter: 573 loss: 8.55494291e-05
Iter: 574 loss: 8.7166678e-05
Iter: 575 loss: 8.55397811e-05
Iter: 576 loss: 8.54152386e-05
Iter: 577 loss: 8.62504821e-05
Iter: 578 loss: 8.54028476e-05
Iter: 579 loss: 8.53095771e-05
Iter: 580 loss: 8.58418207e-05
Iter: 581 loss: 8.52967714e-05
Iter: 582 loss: 8.52169469e-05
Iter: 583 loss: 8.5292726e-05
Iter: 584 loss: 8.5171996e-05
Iter: 585 loss: 8.5039821e-05
Iter: 586 loss: 8.60101572e-05
Iter: 587 loss: 8.50256911e-05
Iter: 588 loss: 8.49113203e-05
Iter: 589 loss: 8.52621451e-05
Iter: 590 loss: 8.4878e-05
Iter: 591 loss: 8.47752817e-05
Iter: 592 loss: 8.61253284e-05
Iter: 593 loss: 8.47746123e-05
Iter: 594 loss: 8.46613e-05
Iter: 595 loss: 8.46286057e-05
Iter: 596 loss: 8.45601171e-05
Iter: 597 loss: 8.43436719e-05
Iter: 598 loss: 8.67209383e-05
Iter: 599 loss: 8.43366215e-05
Iter: 600 loss: 8.41786605e-05
Iter: 601 loss: 8.4346e-05
Iter: 602 loss: 8.4092e-05
Iter: 603 loss: 8.39066488e-05
Iter: 604 loss: 8.44355891e-05
Iter: 605 loss: 8.38491542e-05
Iter: 606 loss: 8.36929539e-05
Iter: 607 loss: 8.37680709e-05
Iter: 608 loss: 8.35892642e-05
Iter: 609 loss: 8.34041e-05
Iter: 610 loss: 8.46053154e-05
Iter: 611 loss: 8.33787635e-05
Iter: 612 loss: 8.33471422e-05
Iter: 613 loss: 8.33129307e-05
Iter: 614 loss: 8.32334481e-05
Iter: 615 loss: 8.33149825e-05
Iter: 616 loss: 8.31881189e-05
Iter: 617 loss: 8.3089355e-05
Iter: 618 loss: 8.30704084e-05
Iter: 619 loss: 8.30042263e-05
Iter: 620 loss: 8.28759e-05
Iter: 621 loss: 8.46686453e-05
Iter: 622 loss: 8.28753327e-05
Iter: 623 loss: 8.27589247e-05
Iter: 624 loss: 8.2830782e-05
Iter: 625 loss: 8.26844189e-05
Iter: 626 loss: 8.25531315e-05
Iter: 627 loss: 8.40268694e-05
Iter: 628 loss: 8.25509123e-05
Iter: 629 loss: 8.24480812e-05
Iter: 630 loss: 8.24580929e-05
Iter: 631 loss: 8.23696319e-05
Iter: 632 loss: 8.21473295e-05
Iter: 633 loss: 8.36372346e-05
Iter: 634 loss: 8.21213835e-05
Iter: 635 loss: 8.19721608e-05
Iter: 636 loss: 8.32374353e-05
Iter: 637 loss: 8.19641573e-05
Iter: 638 loss: 8.18507e-05
Iter: 639 loss: 8.18287e-05
Iter: 640 loss: 8.17530236e-05
Iter: 641 loss: 8.16401e-05
Iter: 642 loss: 8.18009285e-05
Iter: 643 loss: 8.15810781e-05
Iter: 644 loss: 8.14850937e-05
Iter: 645 loss: 8.15374733e-05
Iter: 646 loss: 8.14224477e-05
Iter: 647 loss: 8.13268052e-05
Iter: 648 loss: 8.13268562e-05
Iter: 649 loss: 8.12541257e-05
Iter: 650 loss: 8.13613879e-05
Iter: 651 loss: 8.12190192e-05
Iter: 652 loss: 8.11094505e-05
Iter: 653 loss: 8.13839142e-05
Iter: 654 loss: 8.10710771e-05
Iter: 655 loss: 8.09250632e-05
Iter: 656 loss: 8.14566083e-05
Iter: 657 loss: 8.08867189e-05
Iter: 658 loss: 8.0761165e-05
Iter: 659 loss: 8.22649308e-05
Iter: 660 loss: 8.07598699e-05
Iter: 661 loss: 8.06403405e-05
Iter: 662 loss: 8.06793687e-05
Iter: 663 loss: 8.05568416e-05
Iter: 664 loss: 8.04597e-05
Iter: 665 loss: 8.04615556e-05
Iter: 666 loss: 8.03798466e-05
Iter: 667 loss: 8.02621216e-05
Iter: 668 loss: 8.09495541e-05
Iter: 669 loss: 8.02474824e-05
Iter: 670 loss: 8.01219867e-05
Iter: 671 loss: 8.01635e-05
Iter: 672 loss: 8.00282214e-05
Iter: 673 loss: 7.98838737e-05
Iter: 674 loss: 8.02426948e-05
Iter: 675 loss: 7.98331e-05
Iter: 676 loss: 7.97133835e-05
Iter: 677 loss: 7.97037646e-05
Iter: 678 loss: 7.95922315e-05
Iter: 679 loss: 7.95583474e-05
Iter: 680 loss: 7.94917869e-05
Iter: 681 loss: 7.94309963e-05
Iter: 682 loss: 7.93919462e-05
Iter: 683 loss: 7.92801438e-05
Iter: 684 loss: 7.93835e-05
Iter: 685 loss: 7.92158535e-05
Iter: 686 loss: 7.90794875e-05
Iter: 687 loss: 7.93679937e-05
Iter: 688 loss: 7.90243503e-05
Iter: 689 loss: 7.89348705e-05
Iter: 690 loss: 7.93957734e-05
Iter: 691 loss: 7.89203186e-05
Iter: 692 loss: 7.88474354e-05
Iter: 693 loss: 7.8862693e-05
Iter: 694 loss: 7.87929603e-05
Iter: 695 loss: 7.87196477e-05
Iter: 696 loss: 7.90362756e-05
Iter: 697 loss: 7.87056488e-05
Iter: 698 loss: 7.86187884e-05
Iter: 699 loss: 7.86776509e-05
Iter: 700 loss: 7.8564095e-05
Iter: 701 loss: 7.84422446e-05
Iter: 702 loss: 7.8663521e-05
Iter: 703 loss: 7.83921714e-05
Iter: 704 loss: 7.8222467e-05
Iter: 705 loss: 7.9748912e-05
Iter: 706 loss: 7.81995623e-05
Iter: 707 loss: 7.80678529e-05
Iter: 708 loss: 7.87991157e-05
Iter: 709 loss: 7.80493647e-05
Iter: 710 loss: 7.79545298e-05
Iter: 711 loss: 7.78631365e-05
Iter: 712 loss: 7.78404865e-05
Iter: 713 loss: 7.77153327e-05
Iter: 714 loss: 7.83235228e-05
Iter: 715 loss: 7.76967499e-05
Iter: 716 loss: 7.75648514e-05
Iter: 717 loss: 7.76891393e-05
Iter: 718 loss: 7.7486271e-05
Iter: 719 loss: 7.73126667e-05
Iter: 720 loss: 7.87916797e-05
Iter: 721 loss: 7.73033244e-05
Iter: 722 loss: 7.71974228e-05
Iter: 723 loss: 7.80905466e-05
Iter: 724 loss: 7.71915e-05
Iter: 725 loss: 7.71144e-05
Iter: 726 loss: 7.74902437e-05
Iter: 727 loss: 7.71007471e-05
Iter: 728 loss: 7.70284751e-05
Iter: 729 loss: 7.70377301e-05
Iter: 730 loss: 7.69735489e-05
Iter: 731 loss: 7.68496393e-05
Iter: 732 loss: 7.772135e-05
Iter: 733 loss: 7.68382379e-05
Iter: 734 loss: 7.67279198e-05
Iter: 735 loss: 7.69450708e-05
Iter: 736 loss: 7.66833618e-05
Iter: 737 loss: 7.65544755e-05
Iter: 738 loss: 7.6690063e-05
Iter: 739 loss: 7.64826837e-05
Iter: 740 loss: 7.63065691e-05
Iter: 741 loss: 7.6533026e-05
Iter: 742 loss: 7.62170093e-05
Iter: 743 loss: 7.60653274e-05
Iter: 744 loss: 7.77206e-05
Iter: 745 loss: 7.60601397e-05
Iter: 746 loss: 7.59701215e-05
Iter: 747 loss: 7.65612203e-05
Iter: 748 loss: 7.59607865e-05
Iter: 749 loss: 7.5876691e-05
Iter: 750 loss: 7.57906819e-05
Iter: 751 loss: 7.57741218e-05
Iter: 752 loss: 7.56479e-05
Iter: 753 loss: 7.68633618e-05
Iter: 754 loss: 7.56428635e-05
Iter: 755 loss: 7.55749788e-05
Iter: 756 loss: 7.55743822e-05
Iter: 757 loss: 7.55121655e-05
Iter: 758 loss: 7.58617534e-05
Iter: 759 loss: 7.55035799e-05
Iter: 760 loss: 7.54599605e-05
Iter: 761 loss: 7.54899738e-05
Iter: 762 loss: 7.54318462e-05
Iter: 763 loss: 7.53778804e-05
Iter: 764 loss: 7.53349814e-05
Iter: 765 loss: 7.5318334e-05
Iter: 766 loss: 7.52312772e-05
Iter: 767 loss: 7.52986234e-05
Iter: 768 loss: 7.51767075e-05
Iter: 769 loss: 7.50786567e-05
Iter: 770 loss: 7.51697808e-05
Iter: 771 loss: 7.50231411e-05
Iter: 772 loss: 7.48669554e-05
Iter: 773 loss: 7.48554594e-05
Iter: 774 loss: 7.4736221e-05
Iter: 775 loss: 7.45427315e-05
Iter: 776 loss: 7.51586558e-05
Iter: 777 loss: 7.44833378e-05
Iter: 778 loss: 7.43111741e-05
Iter: 779 loss: 7.65955047e-05
Iter: 780 loss: 7.43099663e-05
Iter: 781 loss: 7.41367e-05
Iter: 782 loss: 7.55916335e-05
Iter: 783 loss: 7.41207914e-05
Iter: 784 loss: 7.39721145e-05
Iter: 785 loss: 7.59932664e-05
Iter: 786 loss: 7.39712559e-05
Iter: 787 loss: 7.38725648e-05
Iter: 788 loss: 7.46206642e-05
Iter: 789 loss: 7.38650924e-05
Iter: 790 loss: 7.37988e-05
Iter: 791 loss: 7.39055395e-05
Iter: 792 loss: 7.37656956e-05
Iter: 793 loss: 7.36915899e-05
Iter: 794 loss: 7.36559814e-05
Iter: 795 loss: 7.36202201e-05
Iter: 796 loss: 7.35335489e-05
Iter: 797 loss: 7.35268477e-05
Iter: 798 loss: 7.34126297e-05
Iter: 799 loss: 7.37435621e-05
Iter: 800 loss: 7.33767956e-05
Iter: 801 loss: 7.32662447e-05
Iter: 802 loss: 7.46007e-05
Iter: 803 loss: 7.32644112e-05
Iter: 804 loss: 7.31496e-05
Iter: 805 loss: 7.32848566e-05
Iter: 806 loss: 7.30886823e-05
Iter: 807 loss: 7.29450549e-05
Iter: 808 loss: 7.49797618e-05
Iter: 809 loss: 7.2943978e-05
Iter: 810 loss: 7.28066807e-05
Iter: 811 loss: 7.31072068e-05
Iter: 812 loss: 7.27541483e-05
Iter: 813 loss: 7.2594521e-05
Iter: 814 loss: 7.30126631e-05
Iter: 815 loss: 7.25304853e-05
Iter: 816 loss: 7.24102138e-05
Iter: 817 loss: 7.37248047e-05
Iter: 818 loss: 7.24076453e-05
Iter: 819 loss: 7.23285775e-05
Iter: 820 loss: 7.23728735e-05
Iter: 821 loss: 7.22742e-05
Iter: 822 loss: 7.2128445e-05
Iter: 823 loss: 7.26475701e-05
Iter: 824 loss: 7.2091847e-05
Iter: 825 loss: 7.19442469e-05
Iter: 826 loss: 7.23792182e-05
Iter: 827 loss: 7.18990341e-05
Iter: 828 loss: 7.17997318e-05
Iter: 829 loss: 7.22375262e-05
Iter: 830 loss: 7.17782241e-05
Iter: 831 loss: 7.17088551e-05
Iter: 832 loss: 7.16449576e-05
Iter: 833 loss: 7.15752e-05
Iter: 834 loss: 7.17526709e-05
Iter: 835 loss: 7.15519345e-05
Iter: 836 loss: 7.14929556e-05
Iter: 837 loss: 7.15191127e-05
Iter: 838 loss: 7.14513662e-05
Iter: 839 loss: 7.13732879e-05
Iter: 840 loss: 7.14154157e-05
Iter: 841 loss: 7.13225891e-05
Iter: 842 loss: 7.12097535e-05
Iter: 843 loss: 7.13652262e-05
Iter: 844 loss: 7.11536413e-05
Iter: 845 loss: 7.10441454e-05
Iter: 846 loss: 7.13554764e-05
Iter: 847 loss: 7.10091554e-05
Iter: 848 loss: 7.08834777e-05
Iter: 849 loss: 7.14188936e-05
Iter: 850 loss: 7.0857117e-05
Iter: 851 loss: 7.07637882e-05
Iter: 852 loss: 7.08511652e-05
Iter: 853 loss: 7.07101426e-05
Iter: 854 loss: 7.05768325e-05
Iter: 855 loss: 7.08638399e-05
Iter: 856 loss: 7.05254279e-05
Iter: 857 loss: 7.0427981e-05
Iter: 858 loss: 7.16337672e-05
Iter: 859 loss: 7.0427217e-05
Iter: 860 loss: 7.03389669e-05
Iter: 861 loss: 7.03688274e-05
Iter: 862 loss: 7.02767793e-05
Iter: 863 loss: 7.01540048e-05
Iter: 864 loss: 7.05496204e-05
Iter: 865 loss: 7.01174431e-05
Iter: 866 loss: 7.0067952e-05
Iter: 867 loss: 7.00677047e-05
Iter: 868 loss: 7.00230885e-05
Iter: 869 loss: 7.00063101e-05
Iter: 870 loss: 6.99813536e-05
Iter: 871 loss: 6.99155207e-05
Iter: 872 loss: 6.98327785e-05
Iter: 873 loss: 6.98263611e-05
Iter: 874 loss: 6.96773059e-05
Iter: 875 loss: 7.12717447e-05
Iter: 876 loss: 6.96731731e-05
Iter: 877 loss: 6.95587514e-05
Iter: 878 loss: 6.96921197e-05
Iter: 879 loss: 6.94976188e-05
Iter: 880 loss: 6.93512047e-05
Iter: 881 loss: 6.96932548e-05
Iter: 882 loss: 6.92974427e-05
Iter: 883 loss: 6.91815076e-05
Iter: 884 loss: 6.97791038e-05
Iter: 885 loss: 6.91626919e-05
Iter: 886 loss: 6.903147e-05
Iter: 887 loss: 6.91996e-05
Iter: 888 loss: 6.89626613e-05
Iter: 889 loss: 6.88618893e-05
Iter: 890 loss: 6.91370951e-05
Iter: 891 loss: 6.88287764e-05
Iter: 892 loss: 6.87362117e-05
Iter: 893 loss: 6.86995772e-05
Iter: 894 loss: 6.86493368e-05
Iter: 895 loss: 6.85223349e-05
Iter: 896 loss: 6.91451569e-05
Iter: 897 loss: 6.85007908e-05
Iter: 898 loss: 6.84123806e-05
Iter: 899 loss: 6.859321e-05
Iter: 900 loss: 6.83767284e-05
Iter: 901 loss: 6.86359417e-05
Iter: 902 loss: 6.83205071e-05
Iter: 903 loss: 6.82719838e-05
Iter: 904 loss: 6.8357047e-05
Iter: 905 loss: 6.82484533e-05
Iter: 906 loss: 6.81604e-05
Iter: 907 loss: 6.81812526e-05
Iter: 908 loss: 6.80958037e-05
Iter: 909 loss: 6.79763762e-05
Iter: 910 loss: 6.80959783e-05
Iter: 911 loss: 6.79072473e-05
Iter: 912 loss: 6.77760108e-05
Iter: 913 loss: 6.84112e-05
Iter: 914 loss: 6.77536445e-05
Iter: 915 loss: 6.76452328e-05
Iter: 916 loss: 6.82477475e-05
Iter: 917 loss: 6.76303098e-05
Iter: 918 loss: 6.75360279e-05
Iter: 919 loss: 6.77871285e-05
Iter: 920 loss: 6.74990879e-05
Iter: 921 loss: 6.74069e-05
Iter: 922 loss: 6.8041074e-05
Iter: 923 loss: 6.73978793e-05
Iter: 924 loss: 6.73423274e-05
Iter: 925 loss: 6.73613104e-05
Iter: 926 loss: 6.73016111e-05
Iter: 927 loss: 6.72196184e-05
Iter: 928 loss: 6.71705202e-05
Iter: 929 loss: 6.7136687e-05
Iter: 930 loss: 6.70246081e-05
Iter: 931 loss: 6.79039804e-05
Iter: 932 loss: 6.70167792e-05
Iter: 933 loss: 6.69095316e-05
Iter: 934 loss: 6.74163894e-05
Iter: 935 loss: 6.68876892e-05
Iter: 936 loss: 6.67794448e-05
Iter: 937 loss: 6.69308938e-05
Iter: 938 loss: 6.67257846e-05
Iter: 939 loss: 6.66484411e-05
Iter: 940 loss: 6.77062199e-05
Iter: 941 loss: 6.66479e-05
Iter: 942 loss: 6.65570551e-05
Iter: 943 loss: 6.65570406e-05
Iter: 944 loss: 6.64944528e-05
Iter: 945 loss: 6.6479115e-05
Iter: 946 loss: 6.64395484e-05
Iter: 947 loss: 6.6351553e-05
Iter: 948 loss: 6.69876899e-05
Iter: 949 loss: 6.63390383e-05
Iter: 950 loss: 6.62696839e-05
Iter: 951 loss: 6.6252629e-05
Iter: 952 loss: 6.62091697e-05
Iter: 953 loss: 6.60683e-05
Iter: 954 loss: 6.67525819e-05
Iter: 955 loss: 6.60427104e-05
Iter: 956 loss: 6.59524885e-05
Iter: 957 loss: 6.6488923e-05
Iter: 958 loss: 6.59410071e-05
Iter: 959 loss: 6.58843273e-05
Iter: 960 loss: 6.58025529e-05
Iter: 961 loss: 6.57999626e-05
Iter: 962 loss: 6.57051423e-05
Iter: 963 loss: 6.58555364e-05
Iter: 964 loss: 6.56610937e-05
Iter: 965 loss: 6.559545e-05
Iter: 966 loss: 6.5504908e-05
Iter: 967 loss: 6.55006879e-05
Iter: 968 loss: 6.53877796e-05
Iter: 969 loss: 6.64439212e-05
Iter: 970 loss: 6.53822426e-05
Iter: 971 loss: 6.52733142e-05
Iter: 972 loss: 6.63400715e-05
Iter: 973 loss: 6.52707e-05
Iter: 974 loss: 6.51161754e-05
Iter: 975 loss: 6.63723185e-05
Iter: 976 loss: 6.51043156e-05
Iter: 977 loss: 6.53613315e-05
Iter: 978 loss: 6.50505535e-05
Iter: 979 loss: 6.4999258e-05
Iter: 980 loss: 6.51327209e-05
Iter: 981 loss: 6.49817302e-05
Iter: 982 loss: 6.49402937e-05
Iter: 983 loss: 6.48667483e-05
Iter: 984 loss: 6.4866821e-05
Iter: 985 loss: 6.47553534e-05
Iter: 986 loss: 6.49937501e-05
Iter: 987 loss: 6.47119596e-05
Iter: 988 loss: 6.46377521e-05
Iter: 989 loss: 6.47635607e-05
Iter: 990 loss: 6.46043e-05
Iter: 991 loss: 6.4514963e-05
Iter: 992 loss: 6.46718836e-05
Iter: 993 loss: 6.4477048e-05
Iter: 994 loss: 6.43678e-05
Iter: 995 loss: 6.53335373e-05
Iter: 996 loss: 6.43618623e-05
Iter: 997 loss: 6.42767773e-05
Iter: 998 loss: 6.42297528e-05
Iter: 999 loss: 6.41925144e-05
Iter: 1000 loss: 6.41014849e-05
Iter: 1001 loss: 6.55296462e-05
Iter: 1002 loss: 6.40984072e-05
Iter: 1003 loss: 6.40359794e-05
Iter: 1004 loss: 6.4014559e-05
Iter: 1005 loss: 6.39789287e-05
Iter: 1006 loss: 6.38509664e-05
Iter: 1007 loss: 6.3713218e-05
Iter: 1008 loss: 6.36918267e-05
Iter: 1009 loss: 6.35379693e-05
Iter: 1010 loss: 6.50675356e-05
Iter: 1011 loss: 6.35319e-05
Iter: 1012 loss: 6.34396e-05
Iter: 1013 loss: 6.40002254e-05
Iter: 1014 loss: 6.34285097e-05
Iter: 1015 loss: 6.33183954e-05
Iter: 1016 loss: 6.39292775e-05
Iter: 1017 loss: 6.33030722e-05
Iter: 1018 loss: 6.32295851e-05
Iter: 1019 loss: 6.38938727e-05
Iter: 1020 loss: 6.32240844e-05
Iter: 1021 loss: 6.31604926e-05
Iter: 1022 loss: 6.34340395e-05
Iter: 1023 loss: 6.3147847e-05
Iter: 1024 loss: 6.30652e-05
Iter: 1025 loss: 6.31217554e-05
Iter: 1026 loss: 6.30117e-05
Iter: 1027 loss: 6.29428832e-05
Iter: 1028 loss: 6.30854702e-05
Iter: 1029 loss: 6.29150745e-05
Iter: 1030 loss: 6.28250637e-05
Iter: 1031 loss: 6.28025737e-05
Iter: 1032 loss: 6.27456902e-05
Iter: 1033 loss: 6.26223482e-05
Iter: 1034 loss: 6.32831434e-05
Iter: 1035 loss: 6.26010442e-05
Iter: 1036 loss: 6.24581e-05
Iter: 1037 loss: 6.34615353e-05
Iter: 1038 loss: 6.24451131e-05
Iter: 1039 loss: 6.22324951e-05
Iter: 1040 loss: 6.27240443e-05
Iter: 1041 loss: 6.21464133e-05
Iter: 1042 loss: 6.21574218e-05
Iter: 1043 loss: 6.20421051e-05
Iter: 1044 loss: 6.19517814e-05
Iter: 1045 loss: 6.31364092e-05
Iter: 1046 loss: 6.19515049e-05
Iter: 1047 loss: 6.18656704e-05
Iter: 1048 loss: 6.22529333e-05
Iter: 1049 loss: 6.18490958e-05
Iter: 1050 loss: 6.17848855e-05
Iter: 1051 loss: 6.19142083e-05
Iter: 1052 loss: 6.17592741e-05
Iter: 1053 loss: 6.16869947e-05
Iter: 1054 loss: 6.167627e-05
Iter: 1055 loss: 6.16263278e-05
Iter: 1056 loss: 6.15334357e-05
Iter: 1057 loss: 6.25150642e-05
Iter: 1058 loss: 6.15282188e-05
Iter: 1059 loss: 6.15065073e-05
Iter: 1060 loss: 6.14690362e-05
Iter: 1061 loss: 6.14344e-05
Iter: 1062 loss: 6.1380284e-05
Iter: 1063 loss: 6.13794691e-05
Iter: 1064 loss: 6.12971489e-05
Iter: 1065 loss: 6.13642042e-05
Iter: 1066 loss: 6.12478689e-05
Iter: 1067 loss: 6.11462456e-05
Iter: 1068 loss: 6.12900913e-05
Iter: 1069 loss: 6.10931384e-05
Iter: 1070 loss: 6.0931925e-05
Iter: 1071 loss: 6.30996656e-05
Iter: 1072 loss: 6.09313211e-05
Iter: 1073 loss: 6.08330556e-05
Iter: 1074 loss: 6.14833698e-05
Iter: 1075 loss: 6.0823495e-05
Iter: 1076 loss: 6.07460061e-05
Iter: 1077 loss: 6.07231595e-05
Iter: 1078 loss: 6.06771573e-05
Iter: 1079 loss: 6.05965652e-05
Iter: 1080 loss: 6.11455e-05
Iter: 1081 loss: 6.05886562e-05
Iter: 1082 loss: 6.05209279e-05
Iter: 1083 loss: 6.06858302e-05
Iter: 1084 loss: 6.04968336e-05
Iter: 1085 loss: 6.04282905e-05
Iter: 1086 loss: 6.03848166e-05
Iter: 1087 loss: 6.03573499e-05
Iter: 1088 loss: 6.02672189e-05
Iter: 1089 loss: 6.06154354e-05
Iter: 1090 loss: 6.02468026e-05
Iter: 1091 loss: 6.01974643e-05
Iter: 1092 loss: 6.01920583e-05
Iter: 1093 loss: 6.01433312e-05
Iter: 1094 loss: 6.00962521e-05
Iter: 1095 loss: 6.00854801e-05
Iter: 1096 loss: 5.99852647e-05
Iter: 1097 loss: 6.00039275e-05
Iter: 1098 loss: 5.99105115e-05
Iter: 1099 loss: 5.97732142e-05
Iter: 1100 loss: 6.01754145e-05
Iter: 1101 loss: 5.97315156e-05
Iter: 1102 loss: 5.96125719e-05
Iter: 1103 loss: 5.99409468e-05
Iter: 1104 loss: 5.9573722e-05
Iter: 1105 loss: 5.9494454e-05
Iter: 1106 loss: 5.97103863e-05
Iter: 1107 loss: 5.94686862e-05
Iter: 1108 loss: 5.93984332e-05
Iter: 1109 loss: 6.00031308e-05
Iter: 1110 loss: 5.93945224e-05
Iter: 1111 loss: 5.93419682e-05
Iter: 1112 loss: 5.93317054e-05
Iter: 1113 loss: 5.92964352e-05
Iter: 1114 loss: 5.92196375e-05
Iter: 1115 loss: 5.92190627e-05
Iter: 1116 loss: 5.91582793e-05
Iter: 1117 loss: 5.90797572e-05
Iter: 1118 loss: 5.95927777e-05
Iter: 1119 loss: 5.90714044e-05
Iter: 1120 loss: 5.90089621e-05
Iter: 1121 loss: 5.96288737e-05
Iter: 1122 loss: 5.90068084e-05
Iter: 1123 loss: 5.89677875e-05
Iter: 1124 loss: 5.92490396e-05
Iter: 1125 loss: 5.89646734e-05
Iter: 1126 loss: 5.89152623e-05
Iter: 1127 loss: 5.88871335e-05
Iter: 1128 loss: 5.88659605e-05
Iter: 1129 loss: 5.87990289e-05
Iter: 1130 loss: 5.87893592e-05
Iter: 1131 loss: 5.87423965e-05
Iter: 1132 loss: 5.86356837e-05
Iter: 1133 loss: 5.86099632e-05
Iter: 1134 loss: 5.8542133e-05
Iter: 1135 loss: 5.83905203e-05
Iter: 1136 loss: 5.92011093e-05
Iter: 1137 loss: 5.8367732e-05
Iter: 1138 loss: 5.82373e-05
Iter: 1139 loss: 5.8366837e-05
Iter: 1140 loss: 5.81641798e-05
Iter: 1141 loss: 5.80948326e-05
Iter: 1142 loss: 5.807868e-05
Iter: 1143 loss: 5.80141932e-05
Iter: 1144 loss: 5.81481509e-05
Iter: 1145 loss: 5.7988349e-05
Iter: 1146 loss: 5.79292609e-05
Iter: 1147 loss: 5.78274085e-05
Iter: 1148 loss: 5.78273539e-05
Iter: 1149 loss: 5.77412502e-05
Iter: 1150 loss: 5.90942363e-05
Iter: 1151 loss: 5.77411338e-05
Iter: 1152 loss: 5.7686575e-05
Iter: 1153 loss: 5.79818661e-05
Iter: 1154 loss: 5.76784951e-05
Iter: 1155 loss: 5.76246166e-05
Iter: 1156 loss: 5.77792234e-05
Iter: 1157 loss: 5.76074162e-05
Iter: 1158 loss: 5.75468221e-05
Iter: 1159 loss: 5.77675528e-05
Iter: 1160 loss: 5.75316444e-05
Iter: 1161 loss: 5.74856967e-05
Iter: 1162 loss: 5.74352562e-05
Iter: 1163 loss: 5.74277365e-05
Iter: 1164 loss: 5.73627331e-05
Iter: 1165 loss: 5.73560865e-05
Iter: 1166 loss: 5.73082871e-05
Iter: 1167 loss: 5.71969213e-05
Iter: 1168 loss: 5.75096346e-05
Iter: 1169 loss: 5.71615674e-05
Iter: 1170 loss: 5.70547345e-05
Iter: 1171 loss: 5.72514473e-05
Iter: 1172 loss: 5.70093107e-05
Iter: 1173 loss: 5.68919859e-05
Iter: 1174 loss: 5.74798905e-05
Iter: 1175 loss: 5.68720352e-05
Iter: 1176 loss: 5.6802357e-05
Iter: 1177 loss: 5.68014948e-05
Iter: 1178 loss: 5.6752222e-05
Iter: 1179 loss: 5.66788185e-05
Iter: 1180 loss: 5.6676894e-05
Iter: 1181 loss: 5.65714763e-05
Iter: 1182 loss: 5.66215604e-05
Iter: 1183 loss: 5.6500503e-05
Iter: 1184 loss: 5.64095863e-05
Iter: 1185 loss: 5.73090219e-05
Iter: 1186 loss: 5.64065558e-05
Iter: 1187 loss: 5.63469657e-05
Iter: 1188 loss: 5.63451758e-05
Iter: 1189 loss: 5.62916975e-05
Iter: 1190 loss: 5.63091926e-05
Iter: 1191 loss: 5.62541e-05
Iter: 1192 loss: 5.61820707e-05
Iter: 1193 loss: 5.6232042e-05
Iter: 1194 loss: 5.61368324e-05
Iter: 1195 loss: 5.60684493e-05
Iter: 1196 loss: 5.59722612e-05
Iter: 1197 loss: 5.59687542e-05
Iter: 1198 loss: 5.5819226e-05
Iter: 1199 loss: 5.64568581e-05
Iter: 1200 loss: 5.57879503e-05
Iter: 1201 loss: 5.56727318e-05
Iter: 1202 loss: 5.60149092e-05
Iter: 1203 loss: 5.56371961e-05
Iter: 1204 loss: 5.5517452e-05
Iter: 1205 loss: 5.58937245e-05
Iter: 1206 loss: 5.54829421e-05
Iter: 1207 loss: 5.54110411e-05
Iter: 1208 loss: 5.54109902e-05
Iter: 1209 loss: 5.53354876e-05
Iter: 1210 loss: 5.53139507e-05
Iter: 1211 loss: 5.52679267e-05
Iter: 1212 loss: 5.51644589e-05
Iter: 1213 loss: 5.51917838e-05
Iter: 1214 loss: 5.50892e-05
Iter: 1215 loss: 5.49818e-05
Iter: 1216 loss: 5.51287812e-05
Iter: 1217 loss: 5.49279648e-05
Iter: 1218 loss: 5.48386088e-05
Iter: 1219 loss: 5.48379103e-05
Iter: 1220 loss: 5.47753298e-05
Iter: 1221 loss: 5.47753334e-05
Iter: 1222 loss: 5.47483869e-05
Iter: 1223 loss: 5.46893571e-05
Iter: 1224 loss: 5.5586308e-05
Iter: 1225 loss: 5.46866722e-05
Iter: 1226 loss: 5.45848343e-05
Iter: 1227 loss: 5.46773445e-05
Iter: 1228 loss: 5.45261028e-05
Iter: 1229 loss: 5.44407376e-05
Iter: 1230 loss: 5.5159624e-05
Iter: 1231 loss: 5.4435568e-05
Iter: 1232 loss: 5.43649294e-05
Iter: 1233 loss: 5.43150854e-05
Iter: 1234 loss: 5.4289867e-05
Iter: 1235 loss: 5.4188793e-05
Iter: 1236 loss: 5.49577708e-05
Iter: 1237 loss: 5.41814334e-05
Iter: 1238 loss: 5.41054251e-05
Iter: 1239 loss: 5.42939379e-05
Iter: 1240 loss: 5.4079148e-05
Iter: 1241 loss: 5.39910397e-05
Iter: 1242 loss: 5.4383876e-05
Iter: 1243 loss: 5.39730827e-05
Iter: 1244 loss: 5.39143584e-05
Iter: 1245 loss: 5.38827626e-05
Iter: 1246 loss: 5.38562526e-05
Iter: 1247 loss: 5.373764e-05
Iter: 1248 loss: 5.36516236e-05
Iter: 1249 loss: 5.36103616e-05
Iter: 1250 loss: 5.3468284e-05
Iter: 1251 loss: 5.38705208e-05
Iter: 1252 loss: 5.34247229e-05
Iter: 1253 loss: 5.33391576e-05
Iter: 1254 loss: 5.32983577e-05
Iter: 1255 loss: 5.32569065e-05
Iter: 1256 loss: 5.33262973e-05
Iter: 1257 loss: 5.31940095e-05
Iter: 1258 loss: 5.3158321e-05
Iter: 1259 loss: 5.31246078e-05
Iter: 1260 loss: 5.31161859e-05
Iter: 1261 loss: 5.30028701e-05
Iter: 1262 loss: 5.29159443e-05
Iter: 1263 loss: 5.287975e-05
Iter: 1264 loss: 5.27553384e-05
Iter: 1265 loss: 5.27514312e-05
Iter: 1266 loss: 5.26293443e-05
Iter: 1267 loss: 5.2933472e-05
Iter: 1268 loss: 5.25877476e-05
Iter: 1269 loss: 5.24969255e-05
Iter: 1270 loss: 5.26039366e-05
Iter: 1271 loss: 5.24460083e-05
Iter: 1272 loss: 5.23698036e-05
Iter: 1273 loss: 5.29134704e-05
Iter: 1274 loss: 5.23630843e-05
Iter: 1275 loss: 5.22965565e-05
Iter: 1276 loss: 5.22829905e-05
Iter: 1277 loss: 5.22388509e-05
Iter: 1278 loss: 5.21699403e-05
Iter: 1279 loss: 5.23130439e-05
Iter: 1280 loss: 5.21424226e-05
Iter: 1281 loss: 5.20657341e-05
Iter: 1282 loss: 5.20471149e-05
Iter: 1283 loss: 5.1998446e-05
Iter: 1284 loss: 5.18794805e-05
Iter: 1285 loss: 5.23869458e-05
Iter: 1286 loss: 5.18552697e-05
Iter: 1287 loss: 5.18464949e-05
Iter: 1288 loss: 5.18078377e-05
Iter: 1289 loss: 5.17572262e-05
Iter: 1290 loss: 5.17574881e-05
Iter: 1291 loss: 5.17166627e-05
Iter: 1292 loss: 5.16560103e-05
Iter: 1293 loss: 5.17922e-05
Iter: 1294 loss: 5.16312357e-05
Iter: 1295 loss: 5.15600259e-05
Iter: 1296 loss: 5.15973516e-05
Iter: 1297 loss: 5.15129868e-05
Iter: 1298 loss: 5.14116327e-05
Iter: 1299 loss: 5.14964595e-05
Iter: 1300 loss: 5.13509221e-05
Iter: 1301 loss: 5.12711558e-05
Iter: 1302 loss: 5.15788e-05
Iter: 1303 loss: 5.12531842e-05
Iter: 1304 loss: 5.11619364e-05
Iter: 1305 loss: 5.13438827e-05
Iter: 1306 loss: 5.11249e-05
Iter: 1307 loss: 5.10403115e-05
Iter: 1308 loss: 5.19090718e-05
Iter: 1309 loss: 5.10371538e-05
Iter: 1310 loss: 5.0984454e-05
Iter: 1311 loss: 5.16893815e-05
Iter: 1312 loss: 5.0984163e-05
Iter: 1313 loss: 5.09191595e-05
Iter: 1314 loss: 5.09288657e-05
Iter: 1315 loss: 5.08700141e-05
Iter: 1316 loss: 5.07932855e-05
Iter: 1317 loss: 5.0800918e-05
Iter: 1318 loss: 5.07341829e-05
Iter: 1319 loss: 5.06273318e-05
Iter: 1320 loss: 5.08198864e-05
Iter: 1321 loss: 5.05811695e-05
Iter: 1322 loss: 5.05622302e-05
Iter: 1323 loss: 5.05251155e-05
Iter: 1324 loss: 5.04953823e-05
Iter: 1325 loss: 5.04532436e-05
Iter: 1326 loss: 5.04517884e-05
Iter: 1327 loss: 5.03707233e-05
Iter: 1328 loss: 5.03650881e-05
Iter: 1329 loss: 5.03038173e-05
Iter: 1330 loss: 5.01911345e-05
Iter: 1331 loss: 5.03756964e-05
Iter: 1332 loss: 5.01398499e-05
Iter: 1333 loss: 5.00536626e-05
Iter: 1334 loss: 5.03955307e-05
Iter: 1335 loss: 5.00339302e-05
Iter: 1336 loss: 4.99386e-05
Iter: 1337 loss: 5.03145857e-05
Iter: 1338 loss: 4.99171729e-05
Iter: 1339 loss: 4.98464215e-05
Iter: 1340 loss: 4.99069902e-05
Iter: 1341 loss: 4.98045192e-05
Iter: 1342 loss: 4.97285473e-05
Iter: 1343 loss: 4.98608206e-05
Iter: 1344 loss: 4.96946523e-05
Iter: 1345 loss: 4.9613689e-05
Iter: 1346 loss: 5.01462891e-05
Iter: 1347 loss: 4.96054454e-05
Iter: 1348 loss: 4.95303393e-05
Iter: 1349 loss: 4.9769933e-05
Iter: 1350 loss: 4.95091117e-05
Iter: 1351 loss: 4.94403357e-05
Iter: 1352 loss: 4.95425411e-05
Iter: 1353 loss: 4.94080814e-05
Iter: 1354 loss: 4.93895568e-05
Iter: 1355 loss: 4.93787e-05
Iter: 1356 loss: 4.93463886e-05
Iter: 1357 loss: 4.92909021e-05
Iter: 1358 loss: 4.92907348e-05
Iter: 1359 loss: 4.92179897e-05
Iter: 1360 loss: 4.92519903e-05
Iter: 1361 loss: 4.91681676e-05
Iter: 1362 loss: 4.90679413e-05
Iter: 1363 loss: 4.94699561e-05
Iter: 1364 loss: 4.90454222e-05
Iter: 1365 loss: 4.89645972e-05
Iter: 1366 loss: 4.89202575e-05
Iter: 1367 loss: 4.88844162e-05
Iter: 1368 loss: 4.87616744e-05
Iter: 1369 loss: 4.96003522e-05
Iter: 1370 loss: 4.87502148e-05
Iter: 1371 loss: 4.86510689e-05
Iter: 1372 loss: 4.9143564e-05
Iter: 1373 loss: 4.86340068e-05
Iter: 1374 loss: 4.85513447e-05
Iter: 1375 loss: 4.85200762e-05
Iter: 1376 loss: 4.84748671e-05
Iter: 1377 loss: 4.83785043e-05
Iter: 1378 loss: 4.9197617e-05
Iter: 1379 loss: 4.83730219e-05
Iter: 1380 loss: 4.82746109e-05
Iter: 1381 loss: 4.88366859e-05
Iter: 1382 loss: 4.8260823e-05
Iter: 1383 loss: 4.81855022e-05
Iter: 1384 loss: 4.8246573e-05
Iter: 1385 loss: 4.81403549e-05
Iter: 1386 loss: 4.80900271e-05
Iter: 1387 loss: 4.85815253e-05
Iter: 1388 loss: 4.80882081e-05
Iter: 1389 loss: 4.80365889e-05
Iter: 1390 loss: 4.80064227e-05
Iter: 1391 loss: 4.7985086e-05
Iter: 1392 loss: 4.79105947e-05
Iter: 1393 loss: 4.79050796e-05
Iter: 1394 loss: 4.78492948e-05
Iter: 1395 loss: 4.77460198e-05
Iter: 1396 loss: 4.84292577e-05
Iter: 1397 loss: 4.77351969e-05
Iter: 1398 loss: 4.76204514e-05
Iter: 1399 loss: 4.76322784e-05
Iter: 1400 loss: 4.75319794e-05
Iter: 1401 loss: 4.74130575e-05
Iter: 1402 loss: 4.77431677e-05
Iter: 1403 loss: 4.73747787e-05
Iter: 1404 loss: 4.72775937e-05
Iter: 1405 loss: 4.75974957e-05
Iter: 1406 loss: 4.72507454e-05
Iter: 1407 loss: 4.7150359e-05
Iter: 1408 loss: 4.75677116e-05
Iter: 1409 loss: 4.71292369e-05
Iter: 1410 loss: 4.70354571e-05
Iter: 1411 loss: 4.71086059e-05
Iter: 1412 loss: 4.69787483e-05
Iter: 1413 loss: 4.68536309e-05
Iter: 1414 loss: 4.70703417e-05
Iter: 1415 loss: 4.67979808e-05
Iter: 1416 loss: 4.66917409e-05
Iter: 1417 loss: 4.69314837e-05
Iter: 1418 loss: 4.66518541e-05
Iter: 1419 loss: 4.66186793e-05
Iter: 1420 loss: 4.65803168e-05
Iter: 1421 loss: 4.65153571e-05
Iter: 1422 loss: 4.66084748e-05
Iter: 1423 loss: 4.64838704e-05
Iter: 1424 loss: 4.64256591e-05
Iter: 1425 loss: 4.63517135e-05
Iter: 1426 loss: 4.63459255e-05
Iter: 1427 loss: 4.62331882e-05
Iter: 1428 loss: 4.61005911e-05
Iter: 1429 loss: 4.60863e-05
Iter: 1430 loss: 4.60026131e-05
Iter: 1431 loss: 4.59889125e-05
Iter: 1432 loss: 4.59288094e-05
Iter: 1433 loss: 4.6039906e-05
Iter: 1434 loss: 4.59032854e-05
Iter: 1435 loss: 4.58187569e-05
Iter: 1436 loss: 4.58100731e-05
Iter: 1437 loss: 4.57485876e-05
Iter: 1438 loss: 4.56602575e-05
Iter: 1439 loss: 4.58968316e-05
Iter: 1440 loss: 4.56312482e-05
Iter: 1441 loss: 4.55139889e-05
Iter: 1442 loss: 4.55403242e-05
Iter: 1443 loss: 4.54277942e-05
Iter: 1444 loss: 4.53323482e-05
Iter: 1445 loss: 4.54099718e-05
Iter: 1446 loss: 4.52753e-05
Iter: 1447 loss: 4.51525702e-05
Iter: 1448 loss: 4.56238922e-05
Iter: 1449 loss: 4.51234919e-05
Iter: 1450 loss: 4.50376101e-05
Iter: 1451 loss: 4.54730543e-05
Iter: 1452 loss: 4.502312e-05
Iter: 1453 loss: 4.50114676e-05
Iter: 1454 loss: 4.49778381e-05
Iter: 1455 loss: 4.49474101e-05
Iter: 1456 loss: 4.48721e-05
Iter: 1457 loss: 4.56159978e-05
Iter: 1458 loss: 4.4862114e-05
Iter: 1459 loss: 4.47797356e-05
Iter: 1460 loss: 4.49599465e-05
Iter: 1461 loss: 4.47482234e-05
Iter: 1462 loss: 4.46575e-05
Iter: 1463 loss: 4.46821759e-05
Iter: 1464 loss: 4.45920232e-05
Iter: 1465 loss: 4.45189326e-05
Iter: 1466 loss: 4.45183541e-05
Iter: 1467 loss: 4.44595207e-05
Iter: 1468 loss: 4.45400656e-05
Iter: 1469 loss: 4.44303369e-05
Iter: 1470 loss: 4.43397294e-05
Iter: 1471 loss: 4.42772107e-05
Iter: 1472 loss: 4.42447745e-05
Iter: 1473 loss: 4.41443408e-05
Iter: 1474 loss: 4.50669068e-05
Iter: 1475 loss: 4.41399898e-05
Iter: 1476 loss: 4.40531e-05
Iter: 1477 loss: 4.42282762e-05
Iter: 1478 loss: 4.40180665e-05
Iter: 1479 loss: 4.39189098e-05
Iter: 1480 loss: 4.44655161e-05
Iter: 1481 loss: 4.39047435e-05
Iter: 1482 loss: 4.38299467e-05
Iter: 1483 loss: 4.38029383e-05
Iter: 1484 loss: 4.37614945e-05
Iter: 1485 loss: 4.37609924e-05
Iter: 1486 loss: 4.37191848e-05
Iter: 1487 loss: 4.36933733e-05
Iter: 1488 loss: 4.36622213e-05
Iter: 1489 loss: 4.36591181e-05
Iter: 1490 loss: 4.36213086e-05
Iter: 1491 loss: 4.35613183e-05
Iter: 1492 loss: 4.35607144e-05
Iter: 1493 loss: 4.34722424e-05
Iter: 1494 loss: 4.40159347e-05
Iter: 1495 loss: 4.34620852e-05
Iter: 1496 loss: 4.33922833e-05
Iter: 1497 loss: 4.35635884e-05
Iter: 1498 loss: 4.33676832e-05
Iter: 1499 loss: 4.32845954e-05
Iter: 1500 loss: 4.35161455e-05
Iter: 1501 loss: 4.32582419e-05
Iter: 1502 loss: 4.31709886e-05
Iter: 1503 loss: 4.36802948e-05
Iter: 1504 loss: 4.31595581e-05
Iter: 1505 loss: 4.30985019e-05
Iter: 1506 loss: 4.30884174e-05
Iter: 1507 loss: 4.30463951e-05
Iter: 1508 loss: 4.29692664e-05
Iter: 1509 loss: 4.33167588e-05
Iter: 1510 loss: 4.29543106e-05
Iter: 1511 loss: 4.28898456e-05
Iter: 1512 loss: 4.30241416e-05
Iter: 1513 loss: 4.28645835e-05
Iter: 1514 loss: 4.27986233e-05
Iter: 1515 loss: 4.28583407e-05
Iter: 1516 loss: 4.27605301e-05
Iter: 1517 loss: 4.27899577e-05
Iter: 1518 loss: 4.27332707e-05
Iter: 1519 loss: 4.27056875e-05
Iter: 1520 loss: 4.26590632e-05
Iter: 1521 loss: 4.26590486e-05
Iter: 1522 loss: 4.25896033e-05
Iter: 1523 loss: 4.25598773e-05
Iter: 1524 loss: 4.25239523e-05
Iter: 1525 loss: 4.24433674e-05
Iter: 1526 loss: 4.27427658e-05
Iter: 1527 loss: 4.24237696e-05
Iter: 1528 loss: 4.23431629e-05
Iter: 1529 loss: 4.26842598e-05
Iter: 1530 loss: 4.2326159e-05
Iter: 1531 loss: 4.22518933e-05
Iter: 1532 loss: 4.25509788e-05
Iter: 1533 loss: 4.22353332e-05
Iter: 1534 loss: 4.21567856e-05
Iter: 1535 loss: 4.23774545e-05
Iter: 1536 loss: 4.2131891e-05
Iter: 1537 loss: 4.20599e-05
Iter: 1538 loss: 4.28690437e-05
Iter: 1539 loss: 4.20583856e-05
Iter: 1540 loss: 4.20225697e-05
Iter: 1541 loss: 4.19688367e-05
Iter: 1542 loss: 4.19675125e-05
Iter: 1543 loss: 4.18904383e-05
Iter: 1544 loss: 4.22498269e-05
Iter: 1545 loss: 4.18757118e-05
Iter: 1546 loss: 4.18024356e-05
Iter: 1547 loss: 4.202329e-05
Iter: 1548 loss: 4.17806623e-05
Iter: 1549 loss: 4.1738258e-05
Iter: 1550 loss: 4.23114761e-05
Iter: 1551 loss: 4.17381234e-05
Iter: 1552 loss: 4.16873372e-05
Iter: 1553 loss: 4.18400195e-05
Iter: 1554 loss: 4.16725234e-05
Iter: 1555 loss: 4.16232833e-05
Iter: 1556 loss: 4.16314288e-05
Iter: 1557 loss: 4.15865e-05
Iter: 1558 loss: 4.15187606e-05
Iter: 1559 loss: 4.15194445e-05
Iter: 1560 loss: 4.1464933e-05
Iter: 1561 loss: 4.138039e-05
Iter: 1562 loss: 4.20072975e-05
Iter: 1563 loss: 4.13732487e-05
Iter: 1564 loss: 4.13035305e-05
Iter: 1565 loss: 4.14546739e-05
Iter: 1566 loss: 4.12766822e-05
Iter: 1567 loss: 4.12067457e-05
Iter: 1568 loss: 4.16997791e-05
Iter: 1569 loss: 4.12003901e-05
Iter: 1570 loss: 4.11592373e-05
Iter: 1571 loss: 4.12814079e-05
Iter: 1572 loss: 4.11469446e-05
Iter: 1573 loss: 4.10850116e-05
Iter: 1574 loss: 4.12580848e-05
Iter: 1575 loss: 4.10649445e-05
Iter: 1576 loss: 4.1017207e-05
Iter: 1577 loss: 4.10774192e-05
Iter: 1578 loss: 4.09926579e-05
Iter: 1579 loss: 4.09483109e-05
Iter: 1580 loss: 4.09403e-05
Iter: 1581 loss: 4.09099921e-05
Iter: 1582 loss: 4.08520427e-05
Iter: 1583 loss: 4.11389847e-05
Iter: 1584 loss: 4.08423293e-05
Iter: 1585 loss: 4.07999469e-05
Iter: 1586 loss: 4.10147113e-05
Iter: 1587 loss: 4.07928e-05
Iter: 1588 loss: 4.07606203e-05
Iter: 1589 loss: 4.06926338e-05
Iter: 1590 loss: 4.18134732e-05
Iter: 1591 loss: 4.06909967e-05
Iter: 1592 loss: 4.06294421e-05
Iter: 1593 loss: 4.09225468e-05
Iter: 1594 loss: 4.06183171e-05
Iter: 1595 loss: 4.05600658e-05
Iter: 1596 loss: 4.07704138e-05
Iter: 1597 loss: 4.05452301e-05
Iter: 1598 loss: 4.0489027e-05
Iter: 1599 loss: 4.05136743e-05
Iter: 1600 loss: 4.04505045e-05
Iter: 1601 loss: 4.03818267e-05
Iter: 1602 loss: 4.07658627e-05
Iter: 1603 loss: 4.03723898e-05
Iter: 1604 loss: 4.03215381e-05
Iter: 1605 loss: 4.04831153e-05
Iter: 1606 loss: 4.0306928e-05
Iter: 1607 loss: 4.02673031e-05
Iter: 1608 loss: 4.01913931e-05
Iter: 1609 loss: 4.17624724e-05
Iter: 1610 loss: 4.01910802e-05
Iter: 1611 loss: 4.01488287e-05
Iter: 1612 loss: 4.01401849e-05
Iter: 1613 loss: 4.00982353e-05
Iter: 1614 loss: 4.03187332e-05
Iter: 1615 loss: 4.00915233e-05
Iter: 1616 loss: 4.00579265e-05
Iter: 1617 loss: 4.02401347e-05
Iter: 1618 loss: 4.00529243e-05
Iter: 1619 loss: 4.00154022e-05
Iter: 1620 loss: 4.02544392e-05
Iter: 1621 loss: 4.0011033e-05
Iter: 1622 loss: 3.99878591e-05
Iter: 1623 loss: 3.99498749e-05
Iter: 1624 loss: 3.99497039e-05
Iter: 1625 loss: 3.99105484e-05
Iter: 1626 loss: 3.99691307e-05
Iter: 1627 loss: 3.98917909e-05
Iter: 1628 loss: 3.98486518e-05
Iter: 1629 loss: 4.00239733e-05
Iter: 1630 loss: 3.98392331e-05
Iter: 1631 loss: 3.97988406e-05
Iter: 1632 loss: 3.97973381e-05
Iter: 1633 loss: 3.9765986e-05
Iter: 1634 loss: 3.97029507e-05
Iter: 1635 loss: 3.99011842e-05
Iter: 1636 loss: 3.96846808e-05
Iter: 1637 loss: 3.96284595e-05
Iter: 1638 loss: 3.96791e-05
Iter: 1639 loss: 3.95958341e-05
Iter: 1640 loss: 3.95374445e-05
Iter: 1641 loss: 4.00952085e-05
Iter: 1642 loss: 3.95354255e-05
Iter: 1643 loss: 3.94823546e-05
Iter: 1644 loss: 3.94399394e-05
Iter: 1645 loss: 3.94240888e-05
Iter: 1646 loss: 3.93424634e-05
Iter: 1647 loss: 4.01171565e-05
Iter: 1648 loss: 3.933876e-05
Iter: 1649 loss: 3.93123555e-05
Iter: 1650 loss: 3.93093942e-05
Iter: 1651 loss: 3.92853872e-05
Iter: 1652 loss: 3.93800947e-05
Iter: 1653 loss: 3.92796501e-05
Iter: 1654 loss: 3.92549955e-05
Iter: 1655 loss: 3.92272777e-05
Iter: 1656 loss: 3.92234579e-05
Iter: 1657 loss: 3.91899848e-05
Iter: 1658 loss: 3.91897229e-05
Iter: 1659 loss: 3.91630965e-05
Iter: 1660 loss: 3.91180656e-05
Iter: 1661 loss: 3.93166774e-05
Iter: 1662 loss: 3.91094e-05
Iter: 1663 loss: 3.90638161e-05
Iter: 1664 loss: 3.92297188e-05
Iter: 1665 loss: 3.90524874e-05
Iter: 1666 loss: 3.90171263e-05
Iter: 1667 loss: 3.90126079e-05
Iter: 1668 loss: 3.89874767e-05
Iter: 1669 loss: 3.89280176e-05
Iter: 1670 loss: 3.90778223e-05
Iter: 1671 loss: 3.89075067e-05
Iter: 1672 loss: 3.88645058e-05
Iter: 1673 loss: 3.90910536e-05
Iter: 1674 loss: 3.88578701e-05
Iter: 1675 loss: 3.88171538e-05
Iter: 1676 loss: 3.88643311e-05
Iter: 1677 loss: 3.87953296e-05
Iter: 1678 loss: 3.87439504e-05
Iter: 1679 loss: 3.8895636e-05
Iter: 1680 loss: 3.87281507e-05
Iter: 1681 loss: 3.86856445e-05
Iter: 1682 loss: 3.8678445e-05
Iter: 1683 loss: 3.86496904e-05
Iter: 1684 loss: 3.86071515e-05
Iter: 1685 loss: 3.89337401e-05
Iter: 1686 loss: 3.8603961e-05
Iter: 1687 loss: 3.86088141e-05
Iter: 1688 loss: 3.85923304e-05
Iter: 1689 loss: 3.85805e-05
Iter: 1690 loss: 3.85484745e-05
Iter: 1691 loss: 3.87592627e-05
Iter: 1692 loss: 3.85404637e-05
Iter: 1693 loss: 3.85078056e-05
Iter: 1694 loss: 3.87259643e-05
Iter: 1695 loss: 3.85046042e-05
Iter: 1696 loss: 3.84799459e-05
Iter: 1697 loss: 3.84813611e-05
Iter: 1698 loss: 3.84607847e-05
Iter: 1699 loss: 3.84199047e-05
Iter: 1700 loss: 3.85364692e-05
Iter: 1701 loss: 3.84068699e-05
Iter: 1702 loss: 3.83743863e-05
Iter: 1703 loss: 3.86405154e-05
Iter: 1704 loss: 3.83726656e-05
Iter: 1705 loss: 3.83465522e-05
Iter: 1706 loss: 3.8300459e-05
Iter: 1707 loss: 3.943915e-05
Iter: 1708 loss: 3.83005354e-05
Iter: 1709 loss: 3.82497383e-05
Iter: 1710 loss: 3.85735912e-05
Iter: 1711 loss: 3.82441e-05
Iter: 1712 loss: 3.82051e-05
Iter: 1713 loss: 3.82877624e-05
Iter: 1714 loss: 3.81898208e-05
Iter: 1715 loss: 3.81509162e-05
Iter: 1716 loss: 3.83986917e-05
Iter: 1717 loss: 3.81467507e-05
Iter: 1718 loss: 3.81192876e-05
Iter: 1719 loss: 3.81316131e-05
Iter: 1720 loss: 3.81005884e-05
Iter: 1721 loss: 3.80594138e-05
Iter: 1722 loss: 3.8113154e-05
Iter: 1723 loss: 3.80385645e-05
Iter: 1724 loss: 3.80684796e-05
Iter: 1725 loss: 3.80233614e-05
Iter: 1726 loss: 3.80123165e-05
Iter: 1727 loss: 3.79759731e-05
Iter: 1728 loss: 3.79971825e-05
Iter: 1729 loss: 3.79437733e-05
Iter: 1730 loss: 3.7901842e-05
Iter: 1731 loss: 3.82509643e-05
Iter: 1732 loss: 3.78993755e-05
Iter: 1733 loss: 3.78733166e-05
Iter: 1734 loss: 3.80280617e-05
Iter: 1735 loss: 3.78699515e-05
Iter: 1736 loss: 3.78406185e-05
Iter: 1737 loss: 3.78081604e-05
Iter: 1738 loss: 3.78035184e-05
Iter: 1739 loss: 3.77513315e-05
Iter: 1740 loss: 3.79530138e-05
Iter: 1741 loss: 3.77389115e-05
Iter: 1742 loss: 3.7692e-05
Iter: 1743 loss: 3.77512915e-05
Iter: 1744 loss: 3.76675453e-05
Iter: 1745 loss: 3.7611564e-05
Iter: 1746 loss: 3.79567282e-05
Iter: 1747 loss: 3.76051939e-05
Iter: 1748 loss: 3.75708e-05
Iter: 1749 loss: 3.76053213e-05
Iter: 1750 loss: 3.75516829e-05
Iter: 1751 loss: 3.75054296e-05
Iter: 1752 loss: 3.76198659e-05
Iter: 1753 loss: 3.74893425e-05
Iter: 1754 loss: 3.74443916e-05
Iter: 1755 loss: 3.76469179e-05
Iter: 1756 loss: 3.7435675e-05
Iter: 1757 loss: 3.74037627e-05
Iter: 1758 loss: 3.76443204e-05
Iter: 1759 loss: 3.7401187e-05
Iter: 1760 loss: 3.73573639e-05
Iter: 1761 loss: 3.74632436e-05
Iter: 1762 loss: 3.7341837e-05
Iter: 1763 loss: 3.73241564e-05
Iter: 1764 loss: 3.73053845e-05
Iter: 1765 loss: 3.73023504e-05
Iter: 1766 loss: 3.72566392e-05
Iter: 1767 loss: 3.74326264e-05
Iter: 1768 loss: 3.7246049e-05
Iter: 1769 loss: 3.7197955e-05
Iter: 1770 loss: 3.78486438e-05
Iter: 1771 loss: 3.71976021e-05
Iter: 1772 loss: 3.71756832e-05
Iter: 1773 loss: 3.71570131e-05
Iter: 1774 loss: 3.71509959e-05
Iter: 1775 loss: 3.7102378e-05
Iter: 1776 loss: 3.7111713e-05
Iter: 1777 loss: 3.70660418e-05
Iter: 1778 loss: 3.70069174e-05
Iter: 1779 loss: 3.73817347e-05
Iter: 1780 loss: 3.70006019e-05
Iter: 1781 loss: 3.69495465e-05
Iter: 1782 loss: 3.6995516e-05
Iter: 1783 loss: 3.69198824e-05
Iter: 1784 loss: 3.68670371e-05
Iter: 1785 loss: 3.71186434e-05
Iter: 1786 loss: 3.68573092e-05
Iter: 1787 loss: 3.6815858e-05
Iter: 1788 loss: 3.68451038e-05
Iter: 1789 loss: 3.67897592e-05
Iter: 1790 loss: 3.67300236e-05
Iter: 1791 loss: 3.69827903e-05
Iter: 1792 loss: 3.67178727e-05
Iter: 1793 loss: 3.6728994e-05
Iter: 1794 loss: 3.67048815e-05
Iter: 1795 loss: 3.66911408e-05
Iter: 1796 loss: 3.66504828e-05
Iter: 1797 loss: 3.67923785e-05
Iter: 1798 loss: 3.66325075e-05
Iter: 1799 loss: 3.6583122e-05
Iter: 1800 loss: 3.68352557e-05
Iter: 1801 loss: 3.65748e-05
Iter: 1802 loss: 3.65294254e-05
Iter: 1803 loss: 3.66576205e-05
Iter: 1804 loss: 3.65151354e-05
Iter: 1805 loss: 3.64701809e-05
Iter: 1806 loss: 3.68637848e-05
Iter: 1807 loss: 3.64678235e-05
Iter: 1808 loss: 3.64339467e-05
Iter: 1809 loss: 3.64339e-05
Iter: 1810 loss: 3.64071966e-05
Iter: 1811 loss: 3.63709369e-05
Iter: 1812 loss: 3.63458239e-05
Iter: 1813 loss: 3.6333211e-05
Iter: 1814 loss: 3.62784704e-05
Iter: 1815 loss: 3.64361294e-05
Iter: 1816 loss: 3.62614264e-05
Iter: 1817 loss: 3.62109968e-05
Iter: 1818 loss: 3.66797212e-05
Iter: 1819 loss: 3.62088103e-05
Iter: 1820 loss: 3.61719649e-05
Iter: 1821 loss: 3.62545434e-05
Iter: 1822 loss: 3.61581042e-05
Iter: 1823 loss: 3.61256498e-05
Iter: 1824 loss: 3.62206738e-05
Iter: 1825 loss: 3.61155835e-05
Iter: 1826 loss: 3.60856538e-05
Iter: 1827 loss: 3.63093495e-05
Iter: 1828 loss: 3.60832018e-05
Iter: 1829 loss: 3.60726044e-05
Iter: 1830 loss: 3.60675585e-05
Iter: 1831 loss: 3.60603408e-05
Iter: 1832 loss: 3.60391e-05
Iter: 1833 loss: 3.6135134e-05
Iter: 1834 loss: 3.6031226e-05
Iter: 1835 loss: 3.59917103e-05
Iter: 1836 loss: 3.59914338e-05
Iter: 1837 loss: 3.59608093e-05
Iter: 1838 loss: 3.60237464e-05
Iter: 1839 loss: 3.5948713e-05
Iter: 1840 loss: 3.59171063e-05
Iter: 1841 loss: 3.62248102e-05
Iter: 1842 loss: 3.59161641e-05
Iter: 1843 loss: 3.58947218e-05
Iter: 1844 loss: 3.59223704e-05
Iter: 1845 loss: 3.5883455e-05
Iter: 1846 loss: 3.58608158e-05
Iter: 1847 loss: 3.58254547e-05
Iter: 1848 loss: 3.58251636e-05
Iter: 1849 loss: 3.57970712e-05
Iter: 1850 loss: 3.60104714e-05
Iter: 1851 loss: 3.57948957e-05
Iter: 1852 loss: 3.57809295e-05
Iter: 1853 loss: 3.5760997e-05
Iter: 1854 loss: 3.57601748e-05
Iter: 1855 loss: 3.57256758e-05
Iter: 1856 loss: 3.58442376e-05
Iter: 1857 loss: 3.57164208e-05
Iter: 1858 loss: 3.56828241e-05
Iter: 1859 loss: 3.5697125e-05
Iter: 1860 loss: 3.56597047e-05
Iter: 1861 loss: 3.56157761e-05
Iter: 1862 loss: 3.56931414e-05
Iter: 1863 loss: 3.55965021e-05
Iter: 1864 loss: 3.55592056e-05
Iter: 1865 loss: 3.58276338e-05
Iter: 1866 loss: 3.55559605e-05
Iter: 1867 loss: 3.55151897e-05
Iter: 1868 loss: 3.58382094e-05
Iter: 1869 loss: 3.55128e-05
Iter: 1870 loss: 3.54875592e-05
Iter: 1871 loss: 3.54596486e-05
Iter: 1872 loss: 3.54554286e-05
Iter: 1873 loss: 3.54303338e-05
Iter: 1874 loss: 3.55020384e-05
Iter: 1875 loss: 3.54224721e-05
Iter: 1876 loss: 3.54017684e-05
Iter: 1877 loss: 3.54134536e-05
Iter: 1878 loss: 3.53882824e-05
Iter: 1879 loss: 3.53704672e-05
Iter: 1880 loss: 3.53703836e-05
Iter: 1881 loss: 3.53531505e-05
Iter: 1882 loss: 3.53775904e-05
Iter: 1883 loss: 3.53446085e-05
Iter: 1884 loss: 3.53231808e-05
Iter: 1885 loss: 3.52980096e-05
Iter: 1886 loss: 3.52952702e-05
Iter: 1887 loss: 3.52602e-05
Iter: 1888 loss: 3.54440344e-05
Iter: 1889 loss: 3.52547577e-05
Iter: 1890 loss: 3.52135103e-05
Iter: 1891 loss: 3.53385149e-05
Iter: 1892 loss: 3.52013158e-05
Iter: 1893 loss: 3.51699819e-05
Iter: 1894 loss: 3.52218631e-05
Iter: 1895 loss: 3.51557464e-05
Iter: 1896 loss: 3.51215494e-05
Iter: 1897 loss: 3.51442213e-05
Iter: 1898 loss: 3.50996452e-05
Iter: 1899 loss: 3.50558475e-05
Iter: 1900 loss: 3.50541e-05
Iter: 1901 loss: 3.50170449e-05
Iter: 1902 loss: 3.55907323e-05
Iter: 1903 loss: 3.50170412e-05
Iter: 1904 loss: 3.50041228e-05
Iter: 1905 loss: 3.49914044e-05
Iter: 1906 loss: 3.49884394e-05
Iter: 1907 loss: 3.49534384e-05
Iter: 1908 loss: 3.49384864e-05
Iter: 1909 loss: 3.49203183e-05
Iter: 1910 loss: 3.4880286e-05
Iter: 1911 loss: 3.4987308e-05
Iter: 1912 loss: 3.4867e-05
Iter: 1913 loss: 3.48302383e-05
Iter: 1914 loss: 3.51283234e-05
Iter: 1915 loss: 3.48280228e-05
Iter: 1916 loss: 3.4794306e-05
Iter: 1917 loss: 3.50025584e-05
Iter: 1918 loss: 3.47906062e-05
Iter: 1919 loss: 3.47707792e-05
Iter: 1920 loss: 3.47586611e-05
Iter: 1921 loss: 3.47506102e-05
Iter: 1922 loss: 3.47194873e-05
Iter: 1923 loss: 3.47306486e-05
Iter: 1924 loss: 3.46977977e-05
Iter: 1925 loss: 3.46632587e-05
Iter: 1926 loss: 3.46807319e-05
Iter: 1927 loss: 3.46403904e-05
Iter: 1928 loss: 3.45917069e-05
Iter: 1929 loss: 3.4672561e-05
Iter: 1930 loss: 3.45690969e-05
Iter: 1931 loss: 3.45317821e-05
Iter: 1932 loss: 3.47461646e-05
Iter: 1933 loss: 3.45267617e-05
Iter: 1934 loss: 3.44872969e-05
Iter: 1935 loss: 3.45366316e-05
Iter: 1936 loss: 3.44670589e-05
Iter: 1937 loss: 3.447786e-05
Iter: 1938 loss: 3.44511573e-05
Iter: 1939 loss: 3.44322652e-05
Iter: 1940 loss: 3.44381297e-05
Iter: 1941 loss: 3.44185319e-05
Iter: 1942 loss: 3.44005603e-05
Iter: 1943 loss: 3.43827123e-05
Iter: 1944 loss: 3.43790671e-05
Iter: 1945 loss: 3.43434403e-05
Iter: 1946 loss: 3.45120679e-05
Iter: 1947 loss: 3.43368556e-05
Iter: 1948 loss: 3.43087e-05
Iter: 1949 loss: 3.44521613e-05
Iter: 1950 loss: 3.43042921e-05
Iter: 1951 loss: 3.42756975e-05
Iter: 1952 loss: 3.43211213e-05
Iter: 1953 loss: 3.42624662e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi3
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi3
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi3 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi3
+ date
Mon Nov  2 14:11:24 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi3/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi3/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3d00045400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3d00075730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb454dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4580730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb457e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb457e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb457e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb43ce6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb43ce598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb436d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb436d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4296048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4296d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb42c01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb429b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4234950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4229b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4161f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4197a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb41612f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4479510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb434b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4479f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb4344ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb42e26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb40faea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb40b1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb40fa268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cac79a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cac7b60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cac78d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb45160d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb45166a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cac7deae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb44a41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3cb44a8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.00253971
test_loss: 0.0024348858
train_loss: 0.0008167131
test_loss: 0.00083693
train_loss: 0.0004086353
test_loss: 0.00044050862
train_loss: 0.0002581987
test_loss: 0.00028554082
train_loss: 0.00018048537
test_loss: 0.00019546492
train_loss: 0.00013677256
test_loss: 0.00014442317
train_loss: 0.00010725909
test_loss: 0.00011247073
train_loss: 8.545454e-05
test_loss: 9.296122e-05
train_loss: 7.3138974e-05
test_loss: 8.0221325e-05
train_loss: 6.613281e-05
test_loss: 7.0134425e-05
train_loss: 5.703845e-05
test_loss: 5.943928e-05
train_loss: 5.317391e-05
test_loss: 5.3584503e-05
train_loss: 4.5504232e-05
test_loss: 4.8704143e-05
train_loss: 4.1852494e-05
test_loss: 4.4197965e-05
train_loss: 3.9421684e-05
test_loss: 4.087076e-05
train_loss: 3.680384e-05
test_loss: 3.836398e-05
train_loss: 3.1905016e-05
test_loss: 3.54326e-05
train_loss: 3.2068085e-05
test_loss: 3.3758428e-05
train_loss: 2.9158868e-05
test_loss: 3.1778356e-05
train_loss: 2.9090443e-05
test_loss: 3.065611e-05
train_loss: 2.6991445e-05
test_loss: 2.9505158e-05
train_loss: 2.4481738e-05
test_loss: 2.7392354e-05
train_loss: 2.4242987e-05
test_loss: 2.679978e-05
train_loss: 2.3880551e-05
test_loss: 2.5607735e-05
train_loss: 2.3481942e-05
test_loss: 2.4865656e-05
train_loss: 2.202209e-05
test_loss: 2.3967086e-05
train_loss: 2.06896e-05
test_loss: 2.3135397e-05
train_loss: 2.0331969e-05
test_loss: 2.2500042e-05
train_loss: 2.0816826e-05
test_loss: 2.2121418e-05
train_loss: 1.9339208e-05
test_loss: 2.1634361e-05
train_loss: 1.9672712e-05
test_loss: 2.1228514e-05
train_loss: 1.9047535e-05
test_loss: 2.0550448e-05
train_loss: 1.7357363e-05
test_loss: 2.0216337e-05
train_loss: 1.8059482e-05
test_loss: 1.9928135e-05
train_loss: 1.806491e-05
test_loss: 1.9323523e-05
train_loss: 1.8249739e-05
test_loss: 1.9065596e-05
train_loss: 1.7292437e-05
test_loss: 1.875598e-05
train_loss: 1.6490645e-05
test_loss: 1.8573754e-05
train_loss: 1.607175e-05
test_loss: 1.8331968e-05
train_loss: 1.639812e-05
test_loss: 1.8020613e-05
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi3/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi3/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi3/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b981cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b9851378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b987e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b97c4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b97c4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b987e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8b987e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8add3fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8add3f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8add1f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adca90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adcd6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adc499d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adca52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adc937b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adcdf6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adc02a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adc02158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adb3aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adb5db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adb84ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adb84598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adacc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adb94d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ada9d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ada85c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adafdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8adafdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ada56488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ada1a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ada17620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ad99e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ad96d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ad9d0ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ad8f42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8ad8fed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.63488185e-05
Iter: 2 loss: 1.78056143e-05
Iter: 3 loss: 1.6255246e-05
Iter: 4 loss: 1.62188044e-05
Iter: 5 loss: 1.61550925e-05
Iter: 6 loss: 1.61551015e-05
Iter: 7 loss: 1.61101016e-05
Iter: 8 loss: 1.62210654e-05
Iter: 9 loss: 1.60943164e-05
Iter: 10 loss: 1.60673153e-05
Iter: 11 loss: 1.61690114e-05
Iter: 12 loss: 1.60608488e-05
Iter: 13 loss: 1.60424242e-05
Iter: 14 loss: 1.61064254e-05
Iter: 15 loss: 1.60376367e-05
Iter: 16 loss: 1.60220206e-05
Iter: 17 loss: 1.61074313e-05
Iter: 18 loss: 1.60197178e-05
Iter: 19 loss: 1.60121672e-05
Iter: 20 loss: 1.60202944e-05
Iter: 21 loss: 1.60079198e-05
Iter: 22 loss: 1.59974734e-05
Iter: 23 loss: 1.60086274e-05
Iter: 24 loss: 1.59917308e-05
Iter: 25 loss: 1.5981499e-05
Iter: 26 loss: 1.60783165e-05
Iter: 27 loss: 1.59810534e-05
Iter: 28 loss: 1.59708725e-05
Iter: 29 loss: 1.59640986e-05
Iter: 30 loss: 1.59604e-05
Iter: 31 loss: 1.59476676e-05
Iter: 32 loss: 1.60631753e-05
Iter: 33 loss: 1.59470583e-05
Iter: 34 loss: 1.59386309e-05
Iter: 35 loss: 1.59536139e-05
Iter: 36 loss: 1.59349675e-05
Iter: 37 loss: 1.59298488e-05
Iter: 38 loss: 1.59295068e-05
Iter: 39 loss: 1.59234278e-05
Iter: 40 loss: 1.59162228e-05
Iter: 41 loss: 1.59153733e-05
Iter: 42 loss: 1.59095071e-05
Iter: 43 loss: 1.59006886e-05
Iter: 44 loss: 1.59004157e-05
Iter: 45 loss: 1.58904986e-05
Iter: 46 loss: 1.60303571e-05
Iter: 47 loss: 1.58905132e-05
Iter: 48 loss: 1.58841758e-05
Iter: 49 loss: 1.5878044e-05
Iter: 50 loss: 1.58767616e-05
Iter: 51 loss: 1.58655585e-05
Iter: 52 loss: 1.59305782e-05
Iter: 53 loss: 1.58640105e-05
Iter: 54 loss: 1.58552484e-05
Iter: 55 loss: 1.58781804e-05
Iter: 56 loss: 1.58524308e-05
Iter: 57 loss: 1.58423754e-05
Iter: 58 loss: 1.58420753e-05
Iter: 59 loss: 1.58343e-05
Iter: 60 loss: 1.58240346e-05
Iter: 61 loss: 1.58650128e-05
Iter: 62 loss: 1.58217663e-05
Iter: 63 loss: 1.58081202e-05
Iter: 64 loss: 1.58530111e-05
Iter: 65 loss: 1.58044859e-05
Iter: 66 loss: 1.579526e-05
Iter: 67 loss: 1.58051425e-05
Iter: 68 loss: 1.57902359e-05
Iter: 69 loss: 1.57778086e-05
Iter: 70 loss: 1.58258335e-05
Iter: 71 loss: 1.57750219e-05
Iter: 72 loss: 1.57718205e-05
Iter: 73 loss: 1.5769956e-05
Iter: 74 loss: 1.57649974e-05
Iter: 75 loss: 1.57545128e-05
Iter: 76 loss: 1.59347837e-05
Iter: 77 loss: 1.57543163e-05
Iter: 78 loss: 1.57442137e-05
Iter: 79 loss: 1.57347022e-05
Iter: 80 loss: 1.57323302e-05
Iter: 81 loss: 1.57183022e-05
Iter: 82 loss: 1.58453677e-05
Iter: 83 loss: 1.57176091e-05
Iter: 84 loss: 1.57072718e-05
Iter: 85 loss: 1.57365757e-05
Iter: 86 loss: 1.57040777e-05
Iter: 87 loss: 1.56913302e-05
Iter: 88 loss: 1.56923597e-05
Iter: 89 loss: 1.56815222e-05
Iter: 90 loss: 1.56687893e-05
Iter: 91 loss: 1.57346476e-05
Iter: 92 loss: 1.56668721e-05
Iter: 93 loss: 1.56529477e-05
Iter: 94 loss: 1.56762362e-05
Iter: 95 loss: 1.56466776e-05
Iter: 96 loss: 1.56344286e-05
Iter: 97 loss: 1.5671194e-05
Iter: 98 loss: 1.56308124e-05
Iter: 99 loss: 1.56203787e-05
Iter: 100 loss: 1.56544811e-05
Iter: 101 loss: 1.56175411e-05
Iter: 102 loss: 1.56052956e-05
Iter: 103 loss: 1.56594087e-05
Iter: 104 loss: 1.56029819e-05
Iter: 105 loss: 1.55949929e-05
Iter: 106 loss: 1.55937196e-05
Iter: 107 loss: 1.55882626e-05
Iter: 108 loss: 1.55835278e-05
Iter: 109 loss: 1.55814741e-05
Iter: 110 loss: 1.55747493e-05
Iter: 111 loss: 1.55663674e-05
Iter: 112 loss: 1.55656453e-05
Iter: 113 loss: 1.55572234e-05
Iter: 114 loss: 1.5559257e-05
Iter: 115 loss: 1.55511807e-05
Iter: 116 loss: 1.55384405e-05
Iter: 117 loss: 1.5529251e-05
Iter: 118 loss: 1.552498e-05
Iter: 119 loss: 1.55113448e-05
Iter: 120 loss: 1.56337464e-05
Iter: 121 loss: 1.55106591e-05
Iter: 122 loss: 1.54960617e-05
Iter: 123 loss: 1.55213347e-05
Iter: 124 loss: 1.54895188e-05
Iter: 125 loss: 1.54750469e-05
Iter: 126 loss: 1.55053785e-05
Iter: 127 loss: 1.54693444e-05
Iter: 128 loss: 1.5453661e-05
Iter: 129 loss: 1.54796944e-05
Iter: 130 loss: 1.54466943e-05
Iter: 131 loss: 1.54331592e-05
Iter: 132 loss: 1.55692724e-05
Iter: 133 loss: 1.54327245e-05
Iter: 134 loss: 1.54220052e-05
Iter: 135 loss: 1.54068275e-05
Iter: 136 loss: 1.54061563e-05
Iter: 137 loss: 1.53892652e-05
Iter: 138 loss: 1.56118986e-05
Iter: 139 loss: 1.53891015e-05
Iter: 140 loss: 1.53753099e-05
Iter: 141 loss: 1.54014251e-05
Iter: 142 loss: 1.53695146e-05
Iter: 143 loss: 1.53601723e-05
Iter: 144 loss: 1.53600231e-05
Iter: 145 loss: 1.53498113e-05
Iter: 146 loss: 1.53518304e-05
Iter: 147 loss: 1.53421788e-05
Iter: 148 loss: 1.5335143e-05
Iter: 149 loss: 1.53197852e-05
Iter: 150 loss: 1.55432754e-05
Iter: 151 loss: 1.53189831e-05
Iter: 152 loss: 1.52976754e-05
Iter: 153 loss: 1.54331119e-05
Iter: 154 loss: 1.52952271e-05
Iter: 155 loss: 1.52811081e-05
Iter: 156 loss: 1.53023393e-05
Iter: 157 loss: 1.52742923e-05
Iter: 158 loss: 1.52559005e-05
Iter: 159 loss: 1.52706853e-05
Iter: 160 loss: 1.52447501e-05
Iter: 161 loss: 1.52281191e-05
Iter: 162 loss: 1.53859692e-05
Iter: 163 loss: 1.52274051e-05
Iter: 164 loss: 1.52124712e-05
Iter: 165 loss: 1.52451812e-05
Iter: 166 loss: 1.52066559e-05
Iter: 167 loss: 1.51875884e-05
Iter: 168 loss: 1.51889571e-05
Iter: 169 loss: 1.51727027e-05
Iter: 170 loss: 1.51508775e-05
Iter: 171 loss: 1.51906161e-05
Iter: 172 loss: 1.51415325e-05
Iter: 173 loss: 1.51191525e-05
Iter: 174 loss: 1.53804285e-05
Iter: 175 loss: 1.51189179e-05
Iter: 176 loss: 1.51054774e-05
Iter: 177 loss: 1.51088643e-05
Iter: 178 loss: 1.50957803e-05
Iter: 179 loss: 1.50816795e-05
Iter: 180 loss: 1.52862413e-05
Iter: 181 loss: 1.50816422e-05
Iter: 182 loss: 1.50693022e-05
Iter: 183 loss: 1.51530166e-05
Iter: 184 loss: 1.50680244e-05
Iter: 185 loss: 1.50590204e-05
Iter: 186 loss: 1.50443666e-05
Iter: 187 loss: 1.50442938e-05
Iter: 188 loss: 1.50303304e-05
Iter: 189 loss: 1.50121596e-05
Iter: 190 loss: 1.50109136e-05
Iter: 191 loss: 1.49869265e-05
Iter: 192 loss: 1.52423954e-05
Iter: 193 loss: 1.4986259e-05
Iter: 194 loss: 1.4967949e-05
Iter: 195 loss: 1.50214255e-05
Iter: 196 loss: 1.49621465e-05
Iter: 197 loss: 1.4944636e-05
Iter: 198 loss: 1.50144897e-05
Iter: 199 loss: 1.49407178e-05
Iter: 200 loss: 1.49265825e-05
Iter: 201 loss: 1.49133093e-05
Iter: 202 loss: 1.49100688e-05
Iter: 203 loss: 1.48912e-05
Iter: 204 loss: 1.48908111e-05
Iter: 205 loss: 1.48785148e-05
Iter: 206 loss: 1.48613435e-05
Iter: 207 loss: 1.48606596e-05
Iter: 208 loss: 1.48415293e-05
Iter: 209 loss: 1.50070446e-05
Iter: 210 loss: 1.4840547e-05
Iter: 211 loss: 1.48244744e-05
Iter: 212 loss: 1.48274394e-05
Iter: 213 loss: 1.48124236e-05
Iter: 214 loss: 1.4801426e-05
Iter: 215 loss: 1.48007466e-05
Iter: 216 loss: 1.47872161e-05
Iter: 217 loss: 1.47806622e-05
Iter: 218 loss: 1.47742248e-05
Iter: 219 loss: 1.47616447e-05
Iter: 220 loss: 1.47437804e-05
Iter: 221 loss: 1.47432402e-05
Iter: 222 loss: 1.47151422e-05
Iter: 223 loss: 1.49127391e-05
Iter: 224 loss: 1.47126493e-05
Iter: 225 loss: 1.46936818e-05
Iter: 226 loss: 1.4732439e-05
Iter: 227 loss: 1.46860866e-05
Iter: 228 loss: 1.46643724e-05
Iter: 229 loss: 1.46588845e-05
Iter: 230 loss: 1.46454022e-05
Iter: 231 loss: 1.46200373e-05
Iter: 232 loss: 1.48148456e-05
Iter: 233 loss: 1.46180155e-05
Iter: 234 loss: 1.4596967e-05
Iter: 235 loss: 1.46697894e-05
Iter: 236 loss: 1.45913054e-05
Iter: 237 loss: 1.45714439e-05
Iter: 238 loss: 1.46588372e-05
Iter: 239 loss: 1.45674949e-05
Iter: 240 loss: 1.45498161e-05
Iter: 241 loss: 1.45431604e-05
Iter: 242 loss: 1.45336217e-05
Iter: 243 loss: 1.45072736e-05
Iter: 244 loss: 1.46975053e-05
Iter: 245 loss: 1.45049617e-05
Iter: 246 loss: 1.44870883e-05
Iter: 247 loss: 1.45282247e-05
Iter: 248 loss: 1.44803153e-05
Iter: 249 loss: 1.44735031e-05
Iter: 250 loss: 1.44713586e-05
Iter: 251 loss: 1.44616324e-05
Iter: 252 loss: 1.4439298e-05
Iter: 253 loss: 1.47168121e-05
Iter: 254 loss: 1.44374444e-05
Iter: 255 loss: 1.44165842e-05
Iter: 256 loss: 1.44787973e-05
Iter: 257 loss: 1.44102614e-05
Iter: 258 loss: 1.4389143e-05
Iter: 259 loss: 1.44868045e-05
Iter: 260 loss: 1.43852558e-05
Iter: 261 loss: 1.43641992e-05
Iter: 262 loss: 1.43930229e-05
Iter: 263 loss: 1.43537345e-05
Iter: 264 loss: 1.43330744e-05
Iter: 265 loss: 1.43421039e-05
Iter: 266 loss: 1.43190373e-05
Iter: 267 loss: 1.42973404e-05
Iter: 268 loss: 1.42971803e-05
Iter: 269 loss: 1.42848758e-05
Iter: 270 loss: 1.42753079e-05
Iter: 271 loss: 1.42714098e-05
Iter: 272 loss: 1.42483013e-05
Iter: 273 loss: 1.426981e-05
Iter: 274 loss: 1.42350145e-05
Iter: 275 loss: 1.42121989e-05
Iter: 276 loss: 1.44108835e-05
Iter: 277 loss: 1.4211053e-05
Iter: 278 loss: 1.41895471e-05
Iter: 279 loss: 1.41786422e-05
Iter: 280 loss: 1.41685559e-05
Iter: 281 loss: 1.41586279e-05
Iter: 282 loss: 1.41562668e-05
Iter: 283 loss: 1.4141212e-05
Iter: 284 loss: 1.41591145e-05
Iter: 285 loss: 1.4133273e-05
Iter: 286 loss: 1.41204146e-05
Iter: 287 loss: 1.40979673e-05
Iter: 288 loss: 1.40979382e-05
Iter: 289 loss: 1.40728425e-05
Iter: 290 loss: 1.43679445e-05
Iter: 291 loss: 1.40725679e-05
Iter: 292 loss: 1.40525754e-05
Iter: 293 loss: 1.40893508e-05
Iter: 294 loss: 1.40439288e-05
Iter: 295 loss: 1.4017216e-05
Iter: 296 loss: 1.40096517e-05
Iter: 297 loss: 1.39934909e-05
Iter: 298 loss: 1.39668246e-05
Iter: 299 loss: 1.42563867e-05
Iter: 300 loss: 1.3966298e-05
Iter: 301 loss: 1.39413023e-05
Iter: 302 loss: 1.40348329e-05
Iter: 303 loss: 1.3935376e-05
Iter: 304 loss: 1.39161493e-05
Iter: 305 loss: 1.3929468e-05
Iter: 306 loss: 1.39042622e-05
Iter: 307 loss: 1.38811156e-05
Iter: 308 loss: 1.39483727e-05
Iter: 309 loss: 1.38739497e-05
Iter: 310 loss: 1.38528767e-05
Iter: 311 loss: 1.39412905e-05
Iter: 312 loss: 1.38484957e-05
Iter: 313 loss: 1.38318865e-05
Iter: 314 loss: 1.38539399e-05
Iter: 315 loss: 1.38234709e-05
Iter: 316 loss: 1.38006335e-05
Iter: 317 loss: 1.40334369e-05
Iter: 318 loss: 1.37999614e-05
Iter: 319 loss: 1.37879269e-05
Iter: 320 loss: 1.37661027e-05
Iter: 321 loss: 1.42829585e-05
Iter: 322 loss: 1.37661546e-05
Iter: 323 loss: 1.3742947e-05
Iter: 324 loss: 1.37590969e-05
Iter: 325 loss: 1.37285115e-05
Iter: 326 loss: 1.37017678e-05
Iter: 327 loss: 1.4005609e-05
Iter: 328 loss: 1.37014849e-05
Iter: 329 loss: 1.36804119e-05
Iter: 330 loss: 1.36787876e-05
Iter: 331 loss: 1.3663107e-05
Iter: 332 loss: 1.36383705e-05
Iter: 333 loss: 1.37362695e-05
Iter: 334 loss: 1.36326144e-05
Iter: 335 loss: 1.36076942e-05
Iter: 336 loss: 1.37110419e-05
Iter: 337 loss: 1.36023609e-05
Iter: 338 loss: 1.35834835e-05
Iter: 339 loss: 1.36160206e-05
Iter: 340 loss: 1.35751743e-05
Iter: 341 loss: 1.35536611e-05
Iter: 342 loss: 1.36191975e-05
Iter: 343 loss: 1.35473101e-05
Iter: 344 loss: 1.35264445e-05
Iter: 345 loss: 1.35436239e-05
Iter: 346 loss: 1.3513767e-05
Iter: 347 loss: 1.34916572e-05
Iter: 348 loss: 1.3511386e-05
Iter: 349 loss: 1.34787006e-05
Iter: 350 loss: 1.3461482e-05
Iter: 351 loss: 1.34602e-05
Iter: 352 loss: 1.34434722e-05
Iter: 353 loss: 1.35545743e-05
Iter: 354 loss: 1.34416323e-05
Iter: 355 loss: 1.34284273e-05
Iter: 356 loss: 1.33974045e-05
Iter: 357 loss: 1.37723837e-05
Iter: 358 loss: 1.33949397e-05
Iter: 359 loss: 1.33640333e-05
Iter: 360 loss: 1.3600652e-05
Iter: 361 loss: 1.33618778e-05
Iter: 362 loss: 1.3334994e-05
Iter: 363 loss: 1.35244072e-05
Iter: 364 loss: 1.33326412e-05
Iter: 365 loss: 1.33136182e-05
Iter: 366 loss: 1.33363255e-05
Iter: 367 loss: 1.33037129e-05
Iter: 368 loss: 1.32797086e-05
Iter: 369 loss: 1.32854648e-05
Iter: 370 loss: 1.32623436e-05
Iter: 371 loss: 1.32380019e-05
Iter: 372 loss: 1.35511855e-05
Iter: 373 loss: 1.32377845e-05
Iter: 374 loss: 1.32222194e-05
Iter: 375 loss: 1.32444748e-05
Iter: 376 loss: 1.32145542e-05
Iter: 377 loss: 1.31955694e-05
Iter: 378 loss: 1.32546502e-05
Iter: 379 loss: 1.31902143e-05
Iter: 380 loss: 1.31705538e-05
Iter: 381 loss: 1.32187597e-05
Iter: 382 loss: 1.31635279e-05
Iter: 383 loss: 1.31435827e-05
Iter: 384 loss: 1.31420784e-05
Iter: 385 loss: 1.31272036e-05
Iter: 386 loss: 1.31289e-05
Iter: 387 loss: 1.31176384e-05
Iter: 388 loss: 1.31066727e-05
Iter: 389 loss: 1.30971057e-05
Iter: 390 loss: 1.30943226e-05
Iter: 391 loss: 1.30801382e-05
Iter: 392 loss: 1.3062675e-05
Iter: 393 loss: 1.30610842e-05
Iter: 394 loss: 1.30340159e-05
Iter: 395 loss: 1.317038e-05
Iter: 396 loss: 1.30295048e-05
Iter: 397 loss: 1.30088774e-05
Iter: 398 loss: 1.29943601e-05
Iter: 399 loss: 1.29872151e-05
Iter: 400 loss: 1.29646096e-05
Iter: 401 loss: 1.29640966e-05
Iter: 402 loss: 1.29477321e-05
Iter: 403 loss: 1.29360187e-05
Iter: 404 loss: 1.29302953e-05
Iter: 405 loss: 1.29039436e-05
Iter: 406 loss: 1.30871631e-05
Iter: 407 loss: 1.29015216e-05
Iter: 408 loss: 1.28808706e-05
Iter: 409 loss: 1.3009887e-05
Iter: 410 loss: 1.28784741e-05
Iter: 411 loss: 1.28615993e-05
Iter: 412 loss: 1.28688926e-05
Iter: 413 loss: 1.28501051e-05
Iter: 414 loss: 1.28299343e-05
Iter: 415 loss: 1.28960055e-05
Iter: 416 loss: 1.28241882e-05
Iter: 417 loss: 1.28015463e-05
Iter: 418 loss: 1.29475175e-05
Iter: 419 loss: 1.27991643e-05
Iter: 420 loss: 1.27765234e-05
Iter: 421 loss: 1.29069313e-05
Iter: 422 loss: 1.27733592e-05
Iter: 423 loss: 1.27616668e-05
Iter: 424 loss: 1.27373987e-05
Iter: 425 loss: 1.31452907e-05
Iter: 426 loss: 1.27367593e-05
Iter: 427 loss: 1.2707048e-05
Iter: 428 loss: 1.28470238e-05
Iter: 429 loss: 1.27016174e-05
Iter: 430 loss: 1.26724917e-05
Iter: 431 loss: 1.27320582e-05
Iter: 432 loss: 1.26609366e-05
Iter: 433 loss: 1.2633227e-05
Iter: 434 loss: 1.26881587e-05
Iter: 435 loss: 1.26218993e-05
Iter: 436 loss: 1.25934403e-05
Iter: 437 loss: 1.28339125e-05
Iter: 438 loss: 1.25918395e-05
Iter: 439 loss: 1.25711122e-05
Iter: 440 loss: 1.25577026e-05
Iter: 441 loss: 1.25497045e-05
Iter: 442 loss: 1.25202105e-05
Iter: 443 loss: 1.26086316e-05
Iter: 444 loss: 1.25113638e-05
Iter: 445 loss: 1.24852486e-05
Iter: 446 loss: 1.2673012e-05
Iter: 447 loss: 1.24829912e-05
Iter: 448 loss: 1.24651506e-05
Iter: 449 loss: 1.24672133e-05
Iter: 450 loss: 1.24511917e-05
Iter: 451 loss: 1.242697e-05
Iter: 452 loss: 1.24772532e-05
Iter: 453 loss: 1.24172948e-05
Iter: 454 loss: 1.24166399e-05
Iter: 455 loss: 1.2408258e-05
Iter: 456 loss: 1.239823e-05
Iter: 457 loss: 1.23889622e-05
Iter: 458 loss: 1.23864811e-05
Iter: 459 loss: 1.23691025e-05
Iter: 460 loss: 1.23587906e-05
Iter: 461 loss: 1.23516256e-05
Iter: 462 loss: 1.23221107e-05
Iter: 463 loss: 1.26016976e-05
Iter: 464 loss: 1.23210439e-05
Iter: 465 loss: 1.22962538e-05
Iter: 466 loss: 1.2391276e-05
Iter: 467 loss: 1.22904021e-05
Iter: 468 loss: 1.22677329e-05
Iter: 469 loss: 1.23237051e-05
Iter: 470 loss: 1.22597194e-05
Iter: 471 loss: 1.22375222e-05
Iter: 472 loss: 1.23100353e-05
Iter: 473 loss: 1.22313231e-05
Iter: 474 loss: 1.22108786e-05
Iter: 475 loss: 1.22513065e-05
Iter: 476 loss: 1.22025849e-05
Iter: 477 loss: 1.21851917e-05
Iter: 478 loss: 1.21897438e-05
Iter: 479 loss: 1.21725243e-05
Iter: 480 loss: 1.21496687e-05
Iter: 481 loss: 1.22121273e-05
Iter: 482 loss: 1.21423791e-05
Iter: 483 loss: 1.21188314e-05
Iter: 484 loss: 1.22529036e-05
Iter: 485 loss: 1.21151461e-05
Iter: 486 loss: 1.20985078e-05
Iter: 487 loss: 1.21418307e-05
Iter: 488 loss: 1.20928325e-05
Iter: 489 loss: 1.20756167e-05
Iter: 490 loss: 1.21770117e-05
Iter: 491 loss: 1.20733475e-05
Iter: 492 loss: 1.20586701e-05
Iter: 493 loss: 1.2048702e-05
Iter: 494 loss: 1.20433615e-05
Iter: 495 loss: 1.20214099e-05
Iter: 496 loss: 1.20276873e-05
Iter: 497 loss: 1.20056184e-05
Iter: 498 loss: 1.1974691e-05
Iter: 499 loss: 1.20180412e-05
Iter: 500 loss: 1.19595206e-05
Iter: 501 loss: 1.19322985e-05
Iter: 502 loss: 1.22026104e-05
Iter: 503 loss: 1.1931329e-05
Iter: 504 loss: 1.19077486e-05
Iter: 505 loss: 1.19418874e-05
Iter: 506 loss: 1.18963726e-05
Iter: 507 loss: 1.18709149e-05
Iter: 508 loss: 1.19358101e-05
Iter: 509 loss: 1.1862252e-05
Iter: 510 loss: 1.18396847e-05
Iter: 511 loss: 1.19699962e-05
Iter: 512 loss: 1.18367134e-05
Iter: 513 loss: 1.1817312e-05
Iter: 514 loss: 1.1854796e-05
Iter: 515 loss: 1.18091921e-05
Iter: 516 loss: 1.17927138e-05
Iter: 517 loss: 1.17964919e-05
Iter: 518 loss: 1.17803474e-05
Iter: 519 loss: 1.17604177e-05
Iter: 520 loss: 1.18356111e-05
Iter: 521 loss: 1.1755541e-05
Iter: 522 loss: 1.17407453e-05
Iter: 523 loss: 1.1862131e-05
Iter: 524 loss: 1.17398777e-05
Iter: 525 loss: 1.17294539e-05
Iter: 526 loss: 1.17239251e-05
Iter: 527 loss: 1.1719374e-05
Iter: 528 loss: 1.17019563e-05
Iter: 529 loss: 1.16851934e-05
Iter: 530 loss: 1.16813571e-05
Iter: 531 loss: 1.16421488e-05
Iter: 532 loss: 1.18084181e-05
Iter: 533 loss: 1.16341143e-05
Iter: 534 loss: 1.16095653e-05
Iter: 535 loss: 1.17349337e-05
Iter: 536 loss: 1.16055126e-05
Iter: 537 loss: 1.15865623e-05
Iter: 538 loss: 1.16644569e-05
Iter: 539 loss: 1.15825205e-05
Iter: 540 loss: 1.15647044e-05
Iter: 541 loss: 1.15633684e-05
Iter: 542 loss: 1.15501616e-05
Iter: 543 loss: 1.15265238e-05
Iter: 544 loss: 1.15749262e-05
Iter: 545 loss: 1.15170387e-05
Iter: 546 loss: 1.14931672e-05
Iter: 547 loss: 1.15752819e-05
Iter: 548 loss: 1.14869099e-05
Iter: 549 loss: 1.14589129e-05
Iter: 550 loss: 1.1576215e-05
Iter: 551 loss: 1.14529985e-05
Iter: 552 loss: 1.14332124e-05
Iter: 553 loss: 1.14586828e-05
Iter: 554 loss: 1.14230425e-05
Iter: 555 loss: 1.14202758e-05
Iter: 556 loss: 1.14120285e-05
Iter: 557 loss: 1.14040104e-05
Iter: 558 loss: 1.13909737e-05
Iter: 559 loss: 1.139088e-05
Iter: 560 loss: 1.1375897e-05
Iter: 561 loss: 1.13856922e-05
Iter: 562 loss: 1.13663573e-05
Iter: 563 loss: 1.13480928e-05
Iter: 564 loss: 1.13787773e-05
Iter: 565 loss: 1.1339861e-05
Iter: 566 loss: 1.1314939e-05
Iter: 567 loss: 1.13770438e-05
Iter: 568 loss: 1.13064179e-05
Iter: 569 loss: 1.12807729e-05
Iter: 570 loss: 1.13763035e-05
Iter: 571 loss: 1.12744019e-05
Iter: 572 loss: 1.1255398e-05
Iter: 573 loss: 1.13158112e-05
Iter: 574 loss: 1.12500702e-05
Iter: 575 loss: 1.12313701e-05
Iter: 576 loss: 1.12332655e-05
Iter: 577 loss: 1.12170501e-05
Iter: 578 loss: 1.11947447e-05
Iter: 579 loss: 1.12032885e-05
Iter: 580 loss: 1.1179156e-05
Iter: 581 loss: 1.11588433e-05
Iter: 582 loss: 1.11586942e-05
Iter: 583 loss: 1.11426034e-05
Iter: 584 loss: 1.119835e-05
Iter: 585 loss: 1.11385107e-05
Iter: 586 loss: 1.11284362e-05
Iter: 587 loss: 1.11284253e-05
Iter: 588 loss: 1.11185964e-05
Iter: 589 loss: 1.11164427e-05
Iter: 590 loss: 1.11099826e-05
Iter: 591 loss: 1.10967167e-05
Iter: 592 loss: 1.11064728e-05
Iter: 593 loss: 1.10886658e-05
Iter: 594 loss: 1.10722176e-05
Iter: 595 loss: 1.10737556e-05
Iter: 596 loss: 1.1059502e-05
Iter: 597 loss: 1.10368774e-05
Iter: 598 loss: 1.11212157e-05
Iter: 599 loss: 1.10313576e-05
Iter: 600 loss: 1.10106757e-05
Iter: 601 loss: 1.12082407e-05
Iter: 602 loss: 1.10099418e-05
Iter: 603 loss: 1.09916627e-05
Iter: 604 loss: 1.09910907e-05
Iter: 605 loss: 1.09765324e-05
Iter: 606 loss: 1.0957423e-05
Iter: 607 loss: 1.10241217e-05
Iter: 608 loss: 1.09526081e-05
Iter: 609 loss: 1.0940159e-05
Iter: 610 loss: 1.09413631e-05
Iter: 611 loss: 1.09306211e-05
Iter: 612 loss: 1.09119383e-05
Iter: 613 loss: 1.09339799e-05
Iter: 614 loss: 1.09022403e-05
Iter: 615 loss: 1.08830245e-05
Iter: 616 loss: 1.09222983e-05
Iter: 617 loss: 1.08753511e-05
Iter: 618 loss: 1.08598742e-05
Iter: 619 loss: 1.10846895e-05
Iter: 620 loss: 1.08598088e-05
Iter: 621 loss: 1.08452641e-05
Iter: 622 loss: 1.08925105e-05
Iter: 623 loss: 1.08411868e-05
Iter: 624 loss: 1.08319973e-05
Iter: 625 loss: 1.08341383e-05
Iter: 626 loss: 1.08250715e-05
Iter: 627 loss: 1.08083805e-05
Iter: 628 loss: 1.08207387e-05
Iter: 629 loss: 1.07981978e-05
Iter: 630 loss: 1.07766928e-05
Iter: 631 loss: 1.08732802e-05
Iter: 632 loss: 1.07725373e-05
Iter: 633 loss: 1.07529795e-05
Iter: 634 loss: 1.07963433e-05
Iter: 635 loss: 1.07453943e-05
Iter: 636 loss: 1.07261403e-05
Iter: 637 loss: 1.08417153e-05
Iter: 638 loss: 1.0723671e-05
Iter: 639 loss: 1.07116521e-05
Iter: 640 loss: 1.07709948e-05
Iter: 641 loss: 1.07095893e-05
Iter: 642 loss: 1.07004016e-05
Iter: 643 loss: 1.06866173e-05
Iter: 644 loss: 1.06862799e-05
Iter: 645 loss: 1.06693578e-05
Iter: 646 loss: 1.06990028e-05
Iter: 647 loss: 1.06619173e-05
Iter: 648 loss: 1.06454227e-05
Iter: 649 loss: 1.07300848e-05
Iter: 650 loss: 1.06427706e-05
Iter: 651 loss: 1.06277821e-05
Iter: 652 loss: 1.07009746e-05
Iter: 653 loss: 1.06249527e-05
Iter: 654 loss: 1.06125553e-05
Iter: 655 loss: 1.07329e-05
Iter: 656 loss: 1.06122015e-05
Iter: 657 loss: 1.06036987e-05
Iter: 658 loss: 1.05997287e-05
Iter: 659 loss: 1.05955696e-05
Iter: 660 loss: 1.05810441e-05
Iter: 661 loss: 1.05754925e-05
Iter: 662 loss: 1.05676427e-05
Iter: 663 loss: 1.05490344e-05
Iter: 664 loss: 1.06344633e-05
Iter: 665 loss: 1.05455802e-05
Iter: 666 loss: 1.05312865e-05
Iter: 667 loss: 1.06254374e-05
Iter: 668 loss: 1.05298641e-05
Iter: 669 loss: 1.05165636e-05
Iter: 670 loss: 1.05260733e-05
Iter: 671 loss: 1.05083964e-05
Iter: 672 loss: 1.04951305e-05
Iter: 673 loss: 1.05676609e-05
Iter: 674 loss: 1.04931632e-05
Iter: 675 loss: 1.04805995e-05
Iter: 676 loss: 1.05098006e-05
Iter: 677 loss: 1.04759729e-05
Iter: 678 loss: 1.04611318e-05
Iter: 679 loss: 1.05493764e-05
Iter: 680 loss: 1.04592382e-05
Iter: 681 loss: 1.04468891e-05
Iter: 682 loss: 1.0472635e-05
Iter: 683 loss: 1.04418814e-05
Iter: 684 loss: 1.0434871e-05
Iter: 685 loss: 1.04217061e-05
Iter: 686 loss: 1.07057404e-05
Iter: 687 loss: 1.04216688e-05
Iter: 688 loss: 1.04101473e-05
Iter: 689 loss: 1.04095343e-05
Iter: 690 loss: 1.04027476e-05
Iter: 691 loss: 1.04074606e-05
Iter: 692 loss: 1.03985567e-05
Iter: 693 loss: 1.03827806e-05
Iter: 694 loss: 1.04369501e-05
Iter: 695 loss: 1.03785842e-05
Iter: 696 loss: 1.03582952e-05
Iter: 697 loss: 1.04976643e-05
Iter: 698 loss: 1.03565126e-05
Iter: 699 loss: 1.03455986e-05
Iter: 700 loss: 1.03384336e-05
Iter: 701 loss: 1.03340317e-05
Iter: 702 loss: 1.03217535e-05
Iter: 703 loss: 1.03400307e-05
Iter: 704 loss: 1.03158673e-05
Iter: 705 loss: 1.03049106e-05
Iter: 706 loss: 1.03024104e-05
Iter: 707 loss: 1.02951744e-05
Iter: 708 loss: 1.027915e-05
Iter: 709 loss: 1.03170423e-05
Iter: 710 loss: 1.0273322e-05
Iter: 711 loss: 1.0257887e-05
Iter: 712 loss: 1.03494376e-05
Iter: 713 loss: 1.02558861e-05
Iter: 714 loss: 1.02452641e-05
Iter: 715 loss: 1.02389376e-05
Iter: 716 loss: 1.02346276e-05
Iter: 717 loss: 1.0216505e-05
Iter: 718 loss: 1.03311431e-05
Iter: 719 loss: 1.02144368e-05
Iter: 720 loss: 1.01983696e-05
Iter: 721 loss: 1.02454705e-05
Iter: 722 loss: 1.01937458e-05
Iter: 723 loss: 1.01737005e-05
Iter: 724 loss: 1.03868479e-05
Iter: 725 loss: 1.0173263e-05
Iter: 726 loss: 1.01492715e-05
Iter: 727 loss: 1.02206841e-05
Iter: 728 loss: 1.01419737e-05
Iter: 729 loss: 1.01198566e-05
Iter: 730 loss: 1.01722126e-05
Iter: 731 loss: 1.01114283e-05
Iter: 732 loss: 1.0094469e-05
Iter: 733 loss: 1.03346993e-05
Iter: 734 loss: 1.00943507e-05
Iter: 735 loss: 1.00817797e-05
Iter: 736 loss: 1.01503574e-05
Iter: 737 loss: 1.00798716e-05
Iter: 738 loss: 1.00704619e-05
Iter: 739 loss: 1.00779525e-05
Iter: 740 loss: 1.0064914e-05
Iter: 741 loss: 1.00550233e-05
Iter: 742 loss: 1.00473781e-05
Iter: 743 loss: 1.00442476e-05
Iter: 744 loss: 1.00276247e-05
Iter: 745 loss: 1.01014884e-05
Iter: 746 loss: 1.00243469e-05
Iter: 747 loss: 1.00115676e-05
Iter: 748 loss: 1.00727566e-05
Iter: 749 loss: 1.00092075e-05
Iter: 750 loss: 9.99852091e-06
Iter: 751 loss: 1.00210473e-05
Iter: 752 loss: 9.99425083e-06
Iter: 753 loss: 9.98240284e-06
Iter: 754 loss: 9.99315e-06
Iter: 755 loss: 9.97552524e-06
Iter: 756 loss: 9.9633271e-06
Iter: 757 loss: 9.97290954e-06
Iter: 758 loss: 9.95587561e-06
Iter: 759 loss: 9.94209222e-06
Iter: 760 loss: 1.00841917e-05
Iter: 761 loss: 9.94169386e-06
Iter: 762 loss: 9.93187314e-06
Iter: 763 loss: 9.92526839e-06
Iter: 764 loss: 9.92157402e-06
Iter: 765 loss: 9.90612625e-06
Iter: 766 loss: 9.96184735e-06
Iter: 767 loss: 9.90212e-06
Iter: 768 loss: 9.89092132e-06
Iter: 769 loss: 9.99080112e-06
Iter: 770 loss: 9.8904211e-06
Iter: 771 loss: 9.88263673e-06
Iter: 772 loss: 9.8790706e-06
Iter: 773 loss: 9.87532894e-06
Iter: 774 loss: 9.86104715e-06
Iter: 775 loss: 9.88200281e-06
Iter: 776 loss: 9.85420229e-06
Iter: 777 loss: 9.84032e-06
Iter: 778 loss: 9.84468261e-06
Iter: 779 loss: 9.83044629e-06
Iter: 780 loss: 9.81709e-06
Iter: 781 loss: 9.88257307e-06
Iter: 782 loss: 9.81478388e-06
Iter: 783 loss: 9.80057484e-06
Iter: 784 loss: 9.8919736e-06
Iter: 785 loss: 9.79908782e-06
Iter: 786 loss: 9.79006381e-06
Iter: 787 loss: 9.80603818e-06
Iter: 788 loss: 9.78613753e-06
Iter: 789 loss: 9.77442e-06
Iter: 790 loss: 9.77977925e-06
Iter: 791 loss: 9.76645788e-06
Iter: 792 loss: 9.75382864e-06
Iter: 793 loss: 9.77193122e-06
Iter: 794 loss: 9.74755767e-06
Iter: 795 loss: 9.73460101e-06
Iter: 796 loss: 9.72630824e-06
Iter: 797 loss: 9.72118414e-06
Iter: 798 loss: 9.70598558e-06
Iter: 799 loss: 9.7058537e-06
Iter: 800 loss: 9.69324174e-06
Iter: 801 loss: 9.7089769e-06
Iter: 802 loss: 9.68660243e-06
Iter: 803 loss: 9.67356755e-06
Iter: 804 loss: 9.6898566e-06
Iter: 805 loss: 9.66689277e-06
Iter: 806 loss: 9.67178676e-06
Iter: 807 loss: 9.66190146e-06
Iter: 808 loss: 9.65766776e-06
Iter: 809 loss: 9.64609262e-06
Iter: 810 loss: 9.71026748e-06
Iter: 811 loss: 9.64262e-06
Iter: 812 loss: 9.62782e-06
Iter: 813 loss: 9.74982e-06
Iter: 814 loss: 9.62692502e-06
Iter: 815 loss: 9.61604565e-06
Iter: 816 loss: 9.63817729e-06
Iter: 817 loss: 9.61153455e-06
Iter: 818 loss: 9.59902354e-06
Iter: 819 loss: 9.59576391e-06
Iter: 820 loss: 9.58786586e-06
Iter: 821 loss: 9.57450175e-06
Iter: 822 loss: 9.77232048e-06
Iter: 823 loss: 9.57449083e-06
Iter: 824 loss: 9.56049189e-06
Iter: 825 loss: 9.59112913e-06
Iter: 826 loss: 9.55514e-06
Iter: 827 loss: 9.54424831e-06
Iter: 828 loss: 9.55668293e-06
Iter: 829 loss: 9.53853942e-06
Iter: 830 loss: 9.5263531e-06
Iter: 831 loss: 9.54461757e-06
Iter: 832 loss: 9.52056871e-06
Iter: 833 loss: 9.50675712e-06
Iter: 834 loss: 9.61198e-06
Iter: 835 loss: 9.50573667e-06
Iter: 836 loss: 9.49588321e-06
Iter: 837 loss: 9.47660192e-06
Iter: 838 loss: 9.87812655e-06
Iter: 839 loss: 9.47658373e-06
Iter: 840 loss: 9.47556873e-06
Iter: 841 loss: 9.46871478e-06
Iter: 842 loss: 9.45942884e-06
Iter: 843 loss: 9.46952605e-06
Iter: 844 loss: 9.45439297e-06
Iter: 845 loss: 9.44356634e-06
Iter: 846 loss: 9.45451757e-06
Iter: 847 loss: 9.43752275e-06
Iter: 848 loss: 9.42590668e-06
Iter: 849 loss: 9.43722807e-06
Iter: 850 loss: 9.41928829e-06
Iter: 851 loss: 9.40549398e-06
Iter: 852 loss: 9.41978669e-06
Iter: 853 loss: 9.39783786e-06
Iter: 854 loss: 9.38592621e-06
Iter: 855 loss: 9.46554883e-06
Iter: 856 loss: 9.38474477e-06
Iter: 857 loss: 9.37604273e-06
Iter: 858 loss: 9.44182284e-06
Iter: 859 loss: 9.37541881e-06
Iter: 860 loss: 9.36624747e-06
Iter: 861 loss: 9.38169342e-06
Iter: 862 loss: 9.36225842e-06
Iter: 863 loss: 9.35469325e-06
Iter: 864 loss: 9.38272387e-06
Iter: 865 loss: 9.35272328e-06
Iter: 866 loss: 9.34436e-06
Iter: 867 loss: 9.33964202e-06
Iter: 868 loss: 9.33605588e-06
Iter: 869 loss: 9.3241e-06
Iter: 870 loss: 9.36023753e-06
Iter: 871 loss: 9.32050898e-06
Iter: 872 loss: 9.31071554e-06
Iter: 873 loss: 9.34853597e-06
Iter: 874 loss: 9.3083836e-06
Iter: 875 loss: 9.29859e-06
Iter: 876 loss: 9.3806666e-06
Iter: 877 loss: 9.29792168e-06
Iter: 878 loss: 9.29009548e-06
Iter: 879 loss: 9.36891865e-06
Iter: 880 loss: 9.28981262e-06
Iter: 881 loss: 9.28572445e-06
Iter: 882 loss: 9.27417e-06
Iter: 883 loss: 9.33760384e-06
Iter: 884 loss: 9.27055862e-06
Iter: 885 loss: 9.25402674e-06
Iter: 886 loss: 9.31047816e-06
Iter: 887 loss: 9.24942924e-06
Iter: 888 loss: 9.23740299e-06
Iter: 889 loss: 9.35641401e-06
Iter: 890 loss: 9.23693278e-06
Iter: 891 loss: 9.22522395e-06
Iter: 892 loss: 9.24976848e-06
Iter: 893 loss: 9.22059371e-06
Iter: 894 loss: 9.21192077e-06
Iter: 895 loss: 9.22529125e-06
Iter: 896 loss: 9.20781167e-06
Iter: 897 loss: 9.19588092e-06
Iter: 898 loss: 9.29867747e-06
Iter: 899 loss: 9.19517606e-06
Iter: 900 loss: 9.18623e-06
Iter: 901 loss: 9.18350634e-06
Iter: 902 loss: 9.17819125e-06
Iter: 903 loss: 9.16773e-06
Iter: 904 loss: 9.21058836e-06
Iter: 905 loss: 9.16544195e-06
Iter: 906 loss: 9.1566526e-06
Iter: 907 loss: 9.16310546e-06
Iter: 908 loss: 9.15116e-06
Iter: 909 loss: 9.14159773e-06
Iter: 910 loss: 9.14608881e-06
Iter: 911 loss: 9.13518124e-06
Iter: 912 loss: 9.13232088e-06
Iter: 913 loss: 9.12943324e-06
Iter: 914 loss: 9.12558426e-06
Iter: 915 loss: 9.1144866e-06
Iter: 916 loss: 9.1556285e-06
Iter: 917 loss: 9.10979543e-06
Iter: 918 loss: 9.09346272e-06
Iter: 919 loss: 9.15718192e-06
Iter: 920 loss: 9.08988841e-06
Iter: 921 loss: 9.07598405e-06
Iter: 922 loss: 9.20236926e-06
Iter: 923 loss: 9.07536196e-06
Iter: 924 loss: 9.0657677e-06
Iter: 925 loss: 9.06604691e-06
Iter: 926 loss: 9.05837624e-06
Iter: 927 loss: 9.04484e-06
Iter: 928 loss: 9.06135392e-06
Iter: 929 loss: 9.03768523e-06
Iter: 930 loss: 9.02777e-06
Iter: 931 loss: 9.15324381e-06
Iter: 932 loss: 9.02763804e-06
Iter: 933 loss: 9.0169633e-06
Iter: 934 loss: 9.01202475e-06
Iter: 935 loss: 9.00664872e-06
Iter: 936 loss: 8.99777297e-06
Iter: 937 loss: 8.99768293e-06
Iter: 938 loss: 8.99108727e-06
Iter: 939 loss: 8.99404768e-06
Iter: 940 loss: 8.98663347e-06
Iter: 941 loss: 8.97836435e-06
Iter: 942 loss: 8.97779864e-06
Iter: 943 loss: 8.97154132e-06
Iter: 944 loss: 8.96293204e-06
Iter: 945 loss: 9.09378377e-06
Iter: 946 loss: 8.96287565e-06
Iter: 947 loss: 8.95651374e-06
Iter: 948 loss: 9.02357715e-06
Iter: 949 loss: 8.95633457e-06
Iter: 950 loss: 8.9507339e-06
Iter: 951 loss: 8.94055665e-06
Iter: 952 loss: 9.18053e-06
Iter: 953 loss: 8.94052846e-06
Iter: 954 loss: 8.93264678e-06
Iter: 955 loss: 8.94244204e-06
Iter: 956 loss: 8.92864e-06
Iter: 957 loss: 8.91910167e-06
Iter: 958 loss: 9.02721513e-06
Iter: 959 loss: 8.91893251e-06
Iter: 960 loss: 8.91014224e-06
Iter: 961 loss: 8.92066419e-06
Iter: 962 loss: 8.90547471e-06
Iter: 963 loss: 8.89642342e-06
Iter: 964 loss: 8.90342e-06
Iter: 965 loss: 8.89102466e-06
Iter: 966 loss: 8.88082286e-06
Iter: 967 loss: 9.01310705e-06
Iter: 968 loss: 8.88074101e-06
Iter: 969 loss: 8.87347051e-06
Iter: 970 loss: 8.88534123e-06
Iter: 971 loss: 8.8699735e-06
Iter: 972 loss: 8.86263479e-06
Iter: 973 loss: 8.88601608e-06
Iter: 974 loss: 8.86048e-06
Iter: 975 loss: 8.85187183e-06
Iter: 976 loss: 8.84591827e-06
Iter: 977 loss: 8.84281326e-06
Iter: 978 loss: 8.83142911e-06
Iter: 979 loss: 8.87390706e-06
Iter: 980 loss: 8.82866e-06
Iter: 981 loss: 8.82166751e-06
Iter: 982 loss: 8.82147287e-06
Iter: 983 loss: 8.81423239e-06
Iter: 984 loss: 8.83018402e-06
Iter: 985 loss: 8.81142296e-06
Iter: 986 loss: 8.80611788e-06
Iter: 987 loss: 8.8023844e-06
Iter: 988 loss: 8.80047264e-06
Iter: 989 loss: 8.79226627e-06
Iter: 990 loss: 8.78089213e-06
Iter: 991 loss: 8.7804e-06
Iter: 992 loss: 8.76728e-06
Iter: 993 loss: 8.80122207e-06
Iter: 994 loss: 8.76275772e-06
Iter: 995 loss: 8.74771467e-06
Iter: 996 loss: 8.82038694e-06
Iter: 997 loss: 8.74510533e-06
Iter: 998 loss: 8.73260615e-06
Iter: 999 loss: 8.77116872e-06
Iter: 1000 loss: 8.72894725e-06
Iter: 1001 loss: 8.71457087e-06
Iter: 1002 loss: 8.79540676e-06
Iter: 1003 loss: 8.71247903e-06
Iter: 1004 loss: 8.70469557e-06
Iter: 1005 loss: 8.76897138e-06
Iter: 1006 loss: 8.70418535e-06
Iter: 1007 loss: 8.69622272e-06
Iter: 1008 loss: 8.68725328e-06
Iter: 1009 loss: 8.68603092e-06
Iter: 1010 loss: 8.67446e-06
Iter: 1011 loss: 8.7082517e-06
Iter: 1012 loss: 8.67085328e-06
Iter: 1013 loss: 8.66339178e-06
Iter: 1014 loss: 8.74620764e-06
Iter: 1015 loss: 8.66322534e-06
Iter: 1016 loss: 8.65735365e-06
Iter: 1017 loss: 8.67137351e-06
Iter: 1018 loss: 8.6552609e-06
Iter: 1019 loss: 8.6463242e-06
Iter: 1020 loss: 8.66900427e-06
Iter: 1021 loss: 8.64321191e-06
Iter: 1022 loss: 8.63887e-06
Iter: 1023 loss: 8.63042e-06
Iter: 1024 loss: 8.80784046e-06
Iter: 1025 loss: 8.63041168e-06
Iter: 1026 loss: 8.61891e-06
Iter: 1027 loss: 8.65383845e-06
Iter: 1028 loss: 8.6155078e-06
Iter: 1029 loss: 8.60576347e-06
Iter: 1030 loss: 8.71384145e-06
Iter: 1031 loss: 8.60570617e-06
Iter: 1032 loss: 8.59873398e-06
Iter: 1033 loss: 8.592624e-06
Iter: 1034 loss: 8.59080683e-06
Iter: 1035 loss: 8.57972645e-06
Iter: 1036 loss: 8.60976252e-06
Iter: 1037 loss: 8.57611849e-06
Iter: 1038 loss: 8.56349834e-06
Iter: 1039 loss: 8.57037776e-06
Iter: 1040 loss: 8.55519102e-06
Iter: 1041 loss: 8.55596227e-06
Iter: 1042 loss: 8.54820246e-06
Iter: 1043 loss: 8.54351492e-06
Iter: 1044 loss: 8.53455094e-06
Iter: 1045 loss: 8.72935198e-06
Iter: 1046 loss: 8.53450456e-06
Iter: 1047 loss: 8.52556e-06
Iter: 1048 loss: 8.55307735e-06
Iter: 1049 loss: 8.52283665e-06
Iter: 1050 loss: 8.51454934e-06
Iter: 1051 loss: 8.5422007e-06
Iter: 1052 loss: 8.51233563e-06
Iter: 1053 loss: 8.50746892e-06
Iter: 1054 loss: 8.50742254e-06
Iter: 1055 loss: 8.50290235e-06
Iter: 1056 loss: 8.49294338e-06
Iter: 1057 loss: 8.62627166e-06
Iter: 1058 loss: 8.49232856e-06
Iter: 1059 loss: 8.48385662e-06
Iter: 1060 loss: 8.50613287e-06
Iter: 1061 loss: 8.48101445e-06
Iter: 1062 loss: 8.47250431e-06
Iter: 1063 loss: 8.52535868e-06
Iter: 1064 loss: 8.4714884e-06
Iter: 1065 loss: 8.463413e-06
Iter: 1066 loss: 8.46807e-06
Iter: 1067 loss: 8.45801424e-06
Iter: 1068 loss: 8.44955321e-06
Iter: 1069 loss: 8.45857903e-06
Iter: 1070 loss: 8.44488113e-06
Iter: 1071 loss: 8.43489215e-06
Iter: 1072 loss: 8.49962817e-06
Iter: 1073 loss: 8.43379439e-06
Iter: 1074 loss: 8.42710415e-06
Iter: 1075 loss: 8.47903e-06
Iter: 1076 loss: 8.4265539e-06
Iter: 1077 loss: 8.42072e-06
Iter: 1078 loss: 8.43200633e-06
Iter: 1079 loss: 8.41834117e-06
Iter: 1080 loss: 8.41017209e-06
Iter: 1081 loss: 8.43278e-06
Iter: 1082 loss: 8.40765188e-06
Iter: 1083 loss: 8.40322264e-06
Iter: 1084 loss: 8.40842313e-06
Iter: 1085 loss: 8.40099165e-06
Iter: 1086 loss: 8.39415e-06
Iter: 1087 loss: 8.41528345e-06
Iter: 1088 loss: 8.39219865e-06
Iter: 1089 loss: 8.38421329e-06
Iter: 1090 loss: 8.40592293e-06
Iter: 1091 loss: 8.38154483e-06
Iter: 1092 loss: 8.37592415e-06
Iter: 1093 loss: 8.37159132e-06
Iter: 1094 loss: 8.36974505e-06
Iter: 1095 loss: 8.36131585e-06
Iter: 1096 loss: 8.35891296e-06
Iter: 1097 loss: 8.35389073e-06
Iter: 1098 loss: 8.34456114e-06
Iter: 1099 loss: 8.47833508e-06
Iter: 1100 loss: 8.34453112e-06
Iter: 1101 loss: 8.33636204e-06
Iter: 1102 loss: 8.33448939e-06
Iter: 1103 loss: 8.32922888e-06
Iter: 1104 loss: 8.3185223e-06
Iter: 1105 loss: 8.34821367e-06
Iter: 1106 loss: 8.31502803e-06
Iter: 1107 loss: 8.30611e-06
Iter: 1108 loss: 8.32121532e-06
Iter: 1109 loss: 8.30213685e-06
Iter: 1110 loss: 8.29244891e-06
Iter: 1111 loss: 8.41926158e-06
Iter: 1112 loss: 8.29231431e-06
Iter: 1113 loss: 8.28566226e-06
Iter: 1114 loss: 8.32250862e-06
Iter: 1115 loss: 8.28466273e-06
Iter: 1116 loss: 8.27951408e-06
Iter: 1117 loss: 8.28099e-06
Iter: 1118 loss: 8.27573786e-06
Iter: 1119 loss: 8.26985524e-06
Iter: 1120 loss: 8.30551562e-06
Iter: 1121 loss: 8.26908217e-06
Iter: 1122 loss: 8.262763e-06
Iter: 1123 loss: 8.27566055e-06
Iter: 1124 loss: 8.26019732e-06
Iter: 1125 loss: 8.25448205e-06
Iter: 1126 loss: 8.26425276e-06
Iter: 1127 loss: 8.25199277e-06
Iter: 1128 loss: 8.24615745e-06
Iter: 1129 loss: 8.23781647e-06
Iter: 1130 loss: 8.23753089e-06
Iter: 1131 loss: 8.22812854e-06
Iter: 1132 loss: 8.27095209e-06
Iter: 1133 loss: 8.22629772e-06
Iter: 1134 loss: 8.21787762e-06
Iter: 1135 loss: 8.27096846e-06
Iter: 1136 loss: 8.21689628e-06
Iter: 1137 loss: 8.20932109e-06
Iter: 1138 loss: 8.22261791e-06
Iter: 1139 loss: 8.20594505e-06
Iter: 1140 loss: 8.19973684e-06
Iter: 1141 loss: 8.19514571e-06
Iter: 1142 loss: 8.19312118e-06
Iter: 1143 loss: 8.18682565e-06
Iter: 1144 loss: 8.18651461e-06
Iter: 1145 loss: 8.18110311e-06
Iter: 1146 loss: 8.20911373e-06
Iter: 1147 loss: 8.18014087e-06
Iter: 1148 loss: 8.17541695e-06
Iter: 1149 loss: 8.18359149e-06
Iter: 1150 loss: 8.17330783e-06
Iter: 1151 loss: 8.16820648e-06
Iter: 1152 loss: 8.17562795e-06
Iter: 1153 loss: 8.16574175e-06
Iter: 1154 loss: 8.16004467e-06
Iter: 1155 loss: 8.20328933e-06
Iter: 1156 loss: 8.15957173e-06
Iter: 1157 loss: 8.15535805e-06
Iter: 1158 loss: 8.15348631e-06
Iter: 1159 loss: 8.15141266e-06
Iter: 1160 loss: 8.1438684e-06
Iter: 1161 loss: 8.14321447e-06
Iter: 1162 loss: 8.13775569e-06
Iter: 1163 loss: 8.13079805e-06
Iter: 1164 loss: 8.14107534e-06
Iter: 1165 loss: 8.12743565e-06
Iter: 1166 loss: 8.11906102e-06
Iter: 1167 loss: 8.15384919e-06
Iter: 1168 loss: 8.11729569e-06
Iter: 1169 loss: 8.10966867e-06
Iter: 1170 loss: 8.15777548e-06
Iter: 1171 loss: 8.10885285e-06
Iter: 1172 loss: 8.10346683e-06
Iter: 1173 loss: 8.09524226e-06
Iter: 1174 loss: 8.09509e-06
Iter: 1175 loss: 8.08894e-06
Iter: 1176 loss: 8.08886398e-06
Iter: 1177 loss: 8.08443292e-06
Iter: 1178 loss: 8.12815233e-06
Iter: 1179 loss: 8.08418736e-06
Iter: 1180 loss: 8.08041295e-06
Iter: 1181 loss: 8.08408186e-06
Iter: 1182 loss: 8.07827109e-06
Iter: 1183 loss: 8.07348533e-06
Iter: 1184 loss: 8.08195182e-06
Iter: 1185 loss: 8.07145079e-06
Iter: 1186 loss: 8.06752905e-06
Iter: 1187 loss: 8.11108657e-06
Iter: 1188 loss: 8.06750177e-06
Iter: 1189 loss: 8.06450953e-06
Iter: 1190 loss: 8.06048592e-06
Iter: 1191 loss: 8.06025309e-06
Iter: 1192 loss: 8.05413947e-06
Iter: 1193 loss: 8.07268589e-06
Iter: 1194 loss: 8.05238597e-06
Iter: 1195 loss: 8.04782212e-06
Iter: 1196 loss: 8.04109e-06
Iter: 1197 loss: 8.04090269e-06
Iter: 1198 loss: 8.03153307e-06
Iter: 1199 loss: 8.08452933e-06
Iter: 1200 loss: 8.03027069e-06
Iter: 1201 loss: 8.02325121e-06
Iter: 1202 loss: 8.08239747e-06
Iter: 1203 loss: 8.02288196e-06
Iter: 1204 loss: 8.01680653e-06
Iter: 1205 loss: 8.00878e-06
Iter: 1206 loss: 8.00833186e-06
Iter: 1207 loss: 7.99881127e-06
Iter: 1208 loss: 8.05367927e-06
Iter: 1209 loss: 7.99753161e-06
Iter: 1210 loss: 7.99237569e-06
Iter: 1211 loss: 7.99213376e-06
Iter: 1212 loss: 7.98732617e-06
Iter: 1213 loss: 7.99104055e-06
Iter: 1214 loss: 7.9845322e-06
Iter: 1215 loss: 7.97899e-06
Iter: 1216 loss: 7.99770623e-06
Iter: 1217 loss: 7.97738448e-06
Iter: 1218 loss: 7.97338362e-06
Iter: 1219 loss: 7.99563168e-06
Iter: 1220 loss: 7.97278426e-06
Iter: 1221 loss: 7.9681231e-06
Iter: 1222 loss: 7.96161748e-06
Iter: 1223 loss: 7.96137829e-06
Iter: 1224 loss: 7.95344386e-06
Iter: 1225 loss: 8.00152e-06
Iter: 1226 loss: 7.95256e-06
Iter: 1227 loss: 7.94692642e-06
Iter: 1228 loss: 7.93879735e-06
Iter: 1229 loss: 7.93850086e-06
Iter: 1230 loss: 7.92775245e-06
Iter: 1231 loss: 7.97205757e-06
Iter: 1232 loss: 7.92541323e-06
Iter: 1233 loss: 7.91833463e-06
Iter: 1234 loss: 7.98402652e-06
Iter: 1235 loss: 7.91806815e-06
Iter: 1236 loss: 7.91092134e-06
Iter: 1237 loss: 7.90762169e-06
Iter: 1238 loss: 7.90401646e-06
Iter: 1239 loss: 7.89600381e-06
Iter: 1240 loss: 7.91499951e-06
Iter: 1241 loss: 7.8931007e-06
Iter: 1242 loss: 7.88645229e-06
Iter: 1243 loss: 7.88644138e-06
Iter: 1244 loss: 7.88045145e-06
Iter: 1245 loss: 7.90298509e-06
Iter: 1246 loss: 7.87902536e-06
Iter: 1247 loss: 7.87470071e-06
Iter: 1248 loss: 7.88712896e-06
Iter: 1249 loss: 7.87338467e-06
Iter: 1250 loss: 7.86916189e-06
Iter: 1251 loss: 7.87623503e-06
Iter: 1252 loss: 7.86736109e-06
Iter: 1253 loss: 7.86098826e-06
Iter: 1254 loss: 7.86471355e-06
Iter: 1255 loss: 7.85687462e-06
Iter: 1256 loss: 7.85148222e-06
Iter: 1257 loss: 7.86848796e-06
Iter: 1258 loss: 7.85001066e-06
Iter: 1259 loss: 7.84395343e-06
Iter: 1260 loss: 7.83827e-06
Iter: 1261 loss: 7.83685482e-06
Iter: 1262 loss: 7.82816096e-06
Iter: 1263 loss: 7.85675911e-06
Iter: 1264 loss: 7.82578081e-06
Iter: 1265 loss: 7.81923518e-06
Iter: 1266 loss: 7.8490184e-06
Iter: 1267 loss: 7.81790368e-06
Iter: 1268 loss: 7.8103385e-06
Iter: 1269 loss: 7.83178893e-06
Iter: 1270 loss: 7.80799746e-06
Iter: 1271 loss: 7.80195751e-06
Iter: 1272 loss: 7.79913171e-06
Iter: 1273 loss: 7.79615766e-06
Iter: 1274 loss: 7.78850153e-06
Iter: 1275 loss: 7.88021316e-06
Iter: 1276 loss: 7.78847152e-06
Iter: 1277 loss: 7.78315552e-06
Iter: 1278 loss: 7.86201144e-06
Iter: 1279 loss: 7.78315552e-06
Iter: 1280 loss: 7.78032063e-06
Iter: 1281 loss: 7.78030426e-06
Iter: 1282 loss: 7.77807509e-06
Iter: 1283 loss: 7.77356945e-06
Iter: 1284 loss: 7.78168942e-06
Iter: 1285 loss: 7.7715622e-06
Iter: 1286 loss: 7.76594516e-06
Iter: 1287 loss: 7.78779668e-06
Iter: 1288 loss: 7.76469e-06
Iter: 1289 loss: 7.76108755e-06
Iter: 1290 loss: 7.75990156e-06
Iter: 1291 loss: 7.75766784e-06
Iter: 1292 loss: 7.75133412e-06
Iter: 1293 loss: 7.7607765e-06
Iter: 1294 loss: 7.74821456e-06
Iter: 1295 loss: 7.74192449e-06
Iter: 1296 loss: 7.74745786e-06
Iter: 1297 loss: 7.73825559e-06
Iter: 1298 loss: 7.73147e-06
Iter: 1299 loss: 7.73985812e-06
Iter: 1300 loss: 7.72795374e-06
Iter: 1301 loss: 7.72013e-06
Iter: 1302 loss: 7.80992377e-06
Iter: 1303 loss: 7.72003568e-06
Iter: 1304 loss: 7.71514624e-06
Iter: 1305 loss: 7.7109471e-06
Iter: 1306 loss: 7.70964e-06
Iter: 1307 loss: 7.70221e-06
Iter: 1308 loss: 7.74134696e-06
Iter: 1309 loss: 7.70100178e-06
Iter: 1310 loss: 7.69925919e-06
Iter: 1311 loss: 7.69786675e-06
Iter: 1312 loss: 7.69569124e-06
Iter: 1313 loss: 7.69185863e-06
Iter: 1314 loss: 7.69179223e-06
Iter: 1315 loss: 7.68636892e-06
Iter: 1316 loss: 7.71304803e-06
Iter: 1317 loss: 7.68538939e-06
Iter: 1318 loss: 7.68153495e-06
Iter: 1319 loss: 7.70826591e-06
Iter: 1320 loss: 7.68109476e-06
Iter: 1321 loss: 7.67843449e-06
Iter: 1322 loss: 7.67400888e-06
Iter: 1323 loss: 7.67394704e-06
Iter: 1324 loss: 7.66776338e-06
Iter: 1325 loss: 7.69713552e-06
Iter: 1326 loss: 7.66663834e-06
Iter: 1327 loss: 7.66183439e-06
Iter: 1328 loss: 7.66297217e-06
Iter: 1329 loss: 7.65820914e-06
Iter: 1330 loss: 7.65209825e-06
Iter: 1331 loss: 7.65799086e-06
Iter: 1332 loss: 7.64852302e-06
Iter: 1333 loss: 7.64357e-06
Iter: 1334 loss: 7.6435972e-06
Iter: 1335 loss: 7.63915159e-06
Iter: 1336 loss: 7.63540174e-06
Iter: 1337 loss: 7.6341621e-06
Iter: 1338 loss: 7.6277679e-06
Iter: 1339 loss: 7.64731e-06
Iter: 1340 loss: 7.62575701e-06
Iter: 1341 loss: 7.62410855e-06
Iter: 1342 loss: 7.62291893e-06
Iter: 1343 loss: 7.62010859e-06
Iter: 1344 loss: 7.61578076e-06
Iter: 1345 loss: 7.61566434e-06
Iter: 1346 loss: 7.61080537e-06
Iter: 1347 loss: 7.65375717e-06
Iter: 1348 loss: 7.61056435e-06
Iter: 1349 loss: 7.60733747e-06
Iter: 1350 loss: 7.6194392e-06
Iter: 1351 loss: 7.60654211e-06
Iter: 1352 loss: 7.60325975e-06
Iter: 1353 loss: 7.59858267e-06
Iter: 1354 loss: 7.59845898e-06
Iter: 1355 loss: 7.59327486e-06
Iter: 1356 loss: 7.63063599e-06
Iter: 1357 loss: 7.59273235e-06
Iter: 1358 loss: 7.58847955e-06
Iter: 1359 loss: 7.5879052e-06
Iter: 1360 loss: 7.58484202e-06
Iter: 1361 loss: 7.5782491e-06
Iter: 1362 loss: 7.57923908e-06
Iter: 1363 loss: 7.57333146e-06
Iter: 1364 loss: 7.566985e-06
Iter: 1365 loss: 7.63024127e-06
Iter: 1366 loss: 7.56680447e-06
Iter: 1367 loss: 7.56015106e-06
Iter: 1368 loss: 7.56642567e-06
Iter: 1369 loss: 7.5564808e-06
Iter: 1370 loss: 7.54972689e-06
Iter: 1371 loss: 7.56075633e-06
Iter: 1372 loss: 7.5466578e-06
Iter: 1373 loss: 7.5412313e-06
Iter: 1374 loss: 7.61178762e-06
Iter: 1375 loss: 7.54125813e-06
Iter: 1376 loss: 7.53500399e-06
Iter: 1377 loss: 7.54580151e-06
Iter: 1378 loss: 7.53224185e-06
Iter: 1379 loss: 7.52857159e-06
Iter: 1380 loss: 7.55262499e-06
Iter: 1381 loss: 7.52822916e-06
Iter: 1382 loss: 7.52494452e-06
Iter: 1383 loss: 7.52775395e-06
Iter: 1384 loss: 7.52316e-06
Iter: 1385 loss: 7.51834432e-06
Iter: 1386 loss: 7.51771222e-06
Iter: 1387 loss: 7.51425705e-06
Iter: 1388 loss: 7.50883919e-06
Iter: 1389 loss: 7.52783353e-06
Iter: 1390 loss: 7.50756044e-06
Iter: 1391 loss: 7.50242543e-06
Iter: 1392 loss: 7.51053631e-06
Iter: 1393 loss: 7.50001664e-06
Iter: 1394 loss: 7.49385799e-06
Iter: 1395 loss: 7.49253968e-06
Iter: 1396 loss: 7.48848424e-06
Iter: 1397 loss: 7.48198636e-06
Iter: 1398 loss: 7.51232119e-06
Iter: 1399 loss: 7.4807931e-06
Iter: 1400 loss: 7.47458853e-06
Iter: 1401 loss: 7.52345204e-06
Iter: 1402 loss: 7.47407e-06
Iter: 1403 loss: 7.46989554e-06
Iter: 1404 loss: 7.4683262e-06
Iter: 1405 loss: 7.46606838e-06
Iter: 1406 loss: 7.46054593e-06
Iter: 1407 loss: 7.49523042e-06
Iter: 1408 loss: 7.45983789e-06
Iter: 1409 loss: 7.45515399e-06
Iter: 1410 loss: 7.52576443e-06
Iter: 1411 loss: 7.45518446e-06
Iter: 1412 loss: 7.4532245e-06
Iter: 1413 loss: 7.45370744e-06
Iter: 1414 loss: 7.45183706e-06
Iter: 1415 loss: 7.44856607e-06
Iter: 1416 loss: 7.45067246e-06
Iter: 1417 loss: 7.44642466e-06
Iter: 1418 loss: 7.44201407e-06
Iter: 1419 loss: 7.45511716e-06
Iter: 1420 loss: 7.44071076e-06
Iter: 1421 loss: 7.4371319e-06
Iter: 1422 loss: 7.4374625e-06
Iter: 1423 loss: 7.43431156e-06
Iter: 1424 loss: 7.42968086e-06
Iter: 1425 loss: 7.45118314e-06
Iter: 1426 loss: 7.42885504e-06
Iter: 1427 loss: 7.42467864e-06
Iter: 1428 loss: 7.42525663e-06
Iter: 1429 loss: 7.4215036e-06
Iter: 1430 loss: 7.4167906e-06
Iter: 1431 loss: 7.41938311e-06
Iter: 1432 loss: 7.41370104e-06
Iter: 1433 loss: 7.40876e-06
Iter: 1434 loss: 7.48741377e-06
Iter: 1435 loss: 7.40879432e-06
Iter: 1436 loss: 7.40511859e-06
Iter: 1437 loss: 7.40462747e-06
Iter: 1438 loss: 7.40202904e-06
Iter: 1439 loss: 7.39665302e-06
Iter: 1440 loss: 7.40666565e-06
Iter: 1441 loss: 7.39436473e-06
Iter: 1442 loss: 7.39405095e-06
Iter: 1443 loss: 7.39176585e-06
Iter: 1444 loss: 7.39028383e-06
Iter: 1445 loss: 7.38771269e-06
Iter: 1446 loss: 7.38776e-06
Iter: 1447 loss: 7.38348808e-06
Iter: 1448 loss: 7.39155075e-06
Iter: 1449 loss: 7.38163362e-06
Iter: 1450 loss: 7.37750634e-06
Iter: 1451 loss: 7.39702637e-06
Iter: 1452 loss: 7.37675646e-06
Iter: 1453 loss: 7.37344908e-06
Iter: 1454 loss: 7.37091614e-06
Iter: 1455 loss: 7.36987e-06
Iter: 1456 loss: 7.36458924e-06
Iter: 1457 loss: 7.38306608e-06
Iter: 1458 loss: 7.36318816e-06
Iter: 1459 loss: 7.35777621e-06
Iter: 1460 loss: 7.3680194e-06
Iter: 1461 loss: 7.355447e-06
Iter: 1462 loss: 7.35083313e-06
Iter: 1463 loss: 7.34675723e-06
Iter: 1464 loss: 7.3455758e-06
Iter: 1465 loss: 7.33951401e-06
Iter: 1466 loss: 7.4315e-06
Iter: 1467 loss: 7.33953129e-06
Iter: 1468 loss: 7.33446e-06
Iter: 1469 loss: 7.34041532e-06
Iter: 1470 loss: 7.33161733e-06
Iter: 1471 loss: 7.32619e-06
Iter: 1472 loss: 7.33471643e-06
Iter: 1473 loss: 7.32371655e-06
Iter: 1474 loss: 7.32379931e-06
Iter: 1475 loss: 7.32154922e-06
Iter: 1476 loss: 7.31962245e-06
Iter: 1477 loss: 7.31627642e-06
Iter: 1478 loss: 7.39421102e-06
Iter: 1479 loss: 7.31627188e-06
Iter: 1480 loss: 7.31175123e-06
Iter: 1481 loss: 7.3344745e-06
Iter: 1482 loss: 7.31092678e-06
Iter: 1483 loss: 7.30745887e-06
Iter: 1484 loss: 7.31827e-06
Iter: 1485 loss: 7.30643114e-06
Iter: 1486 loss: 7.3028591e-06
Iter: 1487 loss: 7.2997841e-06
Iter: 1488 loss: 7.2988023e-06
Iter: 1489 loss: 7.29339536e-06
Iter: 1490 loss: 7.31355203e-06
Iter: 1491 loss: 7.29215571e-06
Iter: 1492 loss: 7.28702616e-06
Iter: 1493 loss: 7.30247757e-06
Iter: 1494 loss: 7.28543091e-06
Iter: 1495 loss: 7.28097075e-06
Iter: 1496 loss: 7.27577162e-06
Iter: 1497 loss: 7.27514e-06
Iter: 1498 loss: 7.26880535e-06
Iter: 1499 loss: 7.33027173e-06
Iter: 1500 loss: 7.26859071e-06
Iter: 1501 loss: 7.26306416e-06
Iter: 1502 loss: 7.28452369e-06
Iter: 1503 loss: 7.26185226e-06
Iter: 1504 loss: 7.25701739e-06
Iter: 1505 loss: 7.26059e-06
Iter: 1506 loss: 7.25407972e-06
Iter: 1507 loss: 7.25245673e-06
Iter: 1508 loss: 7.25170867e-06
Iter: 1509 loss: 7.24908386e-06
Iter: 1510 loss: 7.24565871e-06
Iter: 1511 loss: 7.24544e-06
Iter: 1512 loss: 7.24134679e-06
Iter: 1513 loss: 7.27555e-06
Iter: 1514 loss: 7.24110669e-06
Iter: 1515 loss: 7.23831545e-06
Iter: 1516 loss: 7.24263828e-06
Iter: 1517 loss: 7.23702124e-06
Iter: 1518 loss: 7.23346056e-06
Iter: 1519 loss: 7.23244284e-06
Iter: 1520 loss: 7.23022276e-06
Iter: 1521 loss: 7.22551295e-06
Iter: 1522 loss: 7.23581888e-06
Iter: 1523 loss: 7.22370305e-06
Iter: 1524 loss: 7.21912875e-06
Iter: 1525 loss: 7.24255142e-06
Iter: 1526 loss: 7.21837114e-06
Iter: 1527 loss: 7.2142052e-06
Iter: 1528 loss: 7.20988646e-06
Iter: 1529 loss: 7.20916478e-06
Iter: 1530 loss: 7.20381513e-06
Iter: 1531 loss: 7.22725235e-06
Iter: 1532 loss: 7.20270873e-06
Iter: 1533 loss: 7.19734544e-06
Iter: 1534 loss: 7.2341436e-06
Iter: 1535 loss: 7.19678701e-06
Iter: 1536 loss: 7.19245827e-06
Iter: 1537 loss: 7.19352e-06
Iter: 1538 loss: 7.1892714e-06
Iter: 1539 loss: 7.18572937e-06
Iter: 1540 loss: 7.18575393e-06
Iter: 1541 loss: 7.18167212e-06
Iter: 1542 loss: 7.18741967e-06
Iter: 1543 loss: 7.17959847e-06
Iter: 1544 loss: 7.17677631e-06
Iter: 1545 loss: 7.19079253e-06
Iter: 1546 loss: 7.17628382e-06
Iter: 1547 loss: 7.17356306e-06
Iter: 1548 loss: 7.17399371e-06
Iter: 1549 loss: 7.17157263e-06
Iter: 1550 loss: 7.167082e-06
Iter: 1551 loss: 7.16979685e-06
Iter: 1552 loss: 7.1641507e-06
Iter: 1553 loss: 7.15941587e-06
Iter: 1554 loss: 7.16728e-06
Iter: 1555 loss: 7.15727219e-06
Iter: 1556 loss: 7.15235456e-06
Iter: 1557 loss: 7.17503553e-06
Iter: 1558 loss: 7.15151373e-06
Iter: 1559 loss: 7.1466211e-06
Iter: 1560 loss: 7.143723e-06
Iter: 1561 loss: 7.14177395e-06
Iter: 1562 loss: 7.13561e-06
Iter: 1563 loss: 7.14740509e-06
Iter: 1564 loss: 7.13302506e-06
Iter: 1565 loss: 7.12714836e-06
Iter: 1566 loss: 7.19693435e-06
Iter: 1567 loss: 7.12700057e-06
Iter: 1568 loss: 7.12264955e-06
Iter: 1569 loss: 7.12869314e-06
Iter: 1570 loss: 7.12052361e-06
Iter: 1571 loss: 7.11627126e-06
Iter: 1572 loss: 7.12747669e-06
Iter: 1573 loss: 7.11490975e-06
Iter: 1574 loss: 7.10984932e-06
Iter: 1575 loss: 7.16900649e-06
Iter: 1576 loss: 7.1098234e-06
Iter: 1577 loss: 7.10785935e-06
Iter: 1578 loss: 7.10860468e-06
Iter: 1579 loss: 7.10645645e-06
Iter: 1580 loss: 7.10327913e-06
Iter: 1581 loss: 7.10510176e-06
Iter: 1582 loss: 7.10124414e-06
Iter: 1583 loss: 7.09694632e-06
Iter: 1584 loss: 7.10817494e-06
Iter: 1585 loss: 7.09545384e-06
Iter: 1586 loss: 7.09158121e-06
Iter: 1587 loss: 7.0920878e-06
Iter: 1588 loss: 7.08865582e-06
Iter: 1589 loss: 7.08375865e-06
Iter: 1590 loss: 7.10065842e-06
Iter: 1591 loss: 7.0823844e-06
Iter: 1592 loss: 7.07695199e-06
Iter: 1593 loss: 7.08562538e-06
Iter: 1594 loss: 7.07439722e-06
Iter: 1595 loss: 7.06980245e-06
Iter: 1596 loss: 7.06800165e-06
Iter: 1597 loss: 7.06551373e-06
Iter: 1598 loss: 7.06047422e-06
Iter: 1599 loss: 7.06048559e-06
Iter: 1600 loss: 7.0564447e-06
Iter: 1601 loss: 7.06350056e-06
Iter: 1602 loss: 7.05474758e-06
Iter: 1603 loss: 7.05062257e-06
Iter: 1604 loss: 7.05312505e-06
Iter: 1605 loss: 7.04795821e-06
Iter: 1606 loss: 7.04623835e-06
Iter: 1607 loss: 7.04480908e-06
Iter: 1608 loss: 7.04350032e-06
Iter: 1609 loss: 7.04096237e-06
Iter: 1610 loss: 7.0984529e-06
Iter: 1611 loss: 7.04092281e-06
Iter: 1612 loss: 7.03698379e-06
Iter: 1613 loss: 7.04763806e-06
Iter: 1614 loss: 7.03568821e-06
Iter: 1615 loss: 7.03216938e-06
Iter: 1616 loss: 7.04454123e-06
Iter: 1617 loss: 7.03129035e-06
Iter: 1618 loss: 7.0282149e-06
Iter: 1619 loss: 7.02742955e-06
Iter: 1620 loss: 7.02543502e-06
Iter: 1621 loss: 7.02110128e-06
Iter: 1622 loss: 7.03013575e-06
Iter: 1623 loss: 7.0192882e-06
Iter: 1624 loss: 7.01413592e-06
Iter: 1625 loss: 7.03644082e-06
Iter: 1626 loss: 7.01311774e-06
Iter: 1627 loss: 7.00929331e-06
Iter: 1628 loss: 7.00385863e-06
Iter: 1629 loss: 7.00363216e-06
Iter: 1630 loss: 6.99762768e-06
Iter: 1631 loss: 7.06969422e-06
Iter: 1632 loss: 6.99747943e-06
Iter: 1633 loss: 6.99266866e-06
Iter: 1634 loss: 7.01341605e-06
Iter: 1635 loss: 6.9916523e-06
Iter: 1636 loss: 6.98720714e-06
Iter: 1637 loss: 6.98727263e-06
Iter: 1638 loss: 6.98364556e-06
Iter: 1639 loss: 6.9852822e-06
Iter: 1640 loss: 6.98150052e-06
Iter: 1641 loss: 6.98002714e-06
Iter: 1642 loss: 6.97652558e-06
Iter: 1643 loss: 7.02058605e-06
Iter: 1644 loss: 6.9763355e-06
Iter: 1645 loss: 6.9718817e-06
Iter: 1646 loss: 6.99954035e-06
Iter: 1647 loss: 6.97133191e-06
Iter: 1648 loss: 6.96837742e-06
Iter: 1649 loss: 6.97383939e-06
Iter: 1650 loss: 6.96712232e-06
Iter: 1651 loss: 6.96370489e-06
Iter: 1652 loss: 6.96496045e-06
Iter: 1653 loss: 6.96129155e-06
Iter: 1654 loss: 6.95667e-06
Iter: 1655 loss: 6.95820336e-06
Iter: 1656 loss: 6.95340441e-06
Iter: 1657 loss: 6.94821392e-06
Iter: 1658 loss: 7.0029937e-06
Iter: 1659 loss: 6.94806113e-06
Iter: 1660 loss: 6.94450773e-06
Iter: 1661 loss: 6.93838456e-06
Iter: 1662 loss: 6.93842458e-06
Iter: 1663 loss: 6.9320613e-06
Iter: 1664 loss: 6.98102303e-06
Iter: 1665 loss: 6.93163202e-06
Iter: 1666 loss: 6.92635513e-06
Iter: 1667 loss: 6.96676034e-06
Iter: 1668 loss: 6.92595222e-06
Iter: 1669 loss: 6.92181857e-06
Iter: 1670 loss: 6.92371304e-06
Iter: 1671 loss: 6.91897503e-06
Iter: 1672 loss: 6.91847708e-06
Iter: 1673 loss: 6.91693822e-06
Iter: 1674 loss: 6.91487548e-06
Iter: 1675 loss: 6.9113903e-06
Iter: 1676 loss: 6.91141713e-06
Iter: 1677 loss: 6.90780325e-06
Iter: 1678 loss: 6.93453e-06
Iter: 1679 loss: 6.90747038e-06
Iter: 1680 loss: 6.904766e-06
Iter: 1681 loss: 6.9045027e-06
Iter: 1682 loss: 6.90253728e-06
Iter: 1683 loss: 6.89821627e-06
Iter: 1684 loss: 6.90694833e-06
Iter: 1685 loss: 6.89646276e-06
Iter: 1686 loss: 6.89232911e-06
Iter: 1687 loss: 6.89719081e-06
Iter: 1688 loss: 6.89013223e-06
Iter: 1689 loss: 6.8866284e-06
Iter: 1690 loss: 6.9165626e-06
Iter: 1691 loss: 6.88638374e-06
Iter: 1692 loss: 6.88299042e-06
Iter: 1693 loss: 6.87759166e-06
Iter: 1694 loss: 6.87751708e-06
Iter: 1695 loss: 6.87167358e-06
Iter: 1696 loss: 6.89807166e-06
Iter: 1697 loss: 6.87054126e-06
Iter: 1698 loss: 6.86563e-06
Iter: 1699 loss: 6.91368541e-06
Iter: 1700 loss: 6.8655163e-06
Iter: 1701 loss: 6.86109524e-06
Iter: 1702 loss: 6.86374415e-06
Iter: 1703 loss: 6.85839404e-06
Iter: 1704 loss: 6.85569375e-06
Iter: 1705 loss: 6.85557825e-06
Iter: 1706 loss: 6.85236637e-06
Iter: 1707 loss: 6.85085524e-06
Iter: 1708 loss: 6.8493182e-06
Iter: 1709 loss: 6.84604765e-06
Iter: 1710 loss: 6.86665226e-06
Iter: 1711 loss: 6.84567749e-06
Iter: 1712 loss: 6.8430536e-06
Iter: 1713 loss: 6.84269526e-06
Iter: 1714 loss: 6.8407553e-06
Iter: 1715 loss: 6.83706e-06
Iter: 1716 loss: 6.85028772e-06
Iter: 1717 loss: 6.83616281e-06
Iter: 1718 loss: 6.83303097e-06
Iter: 1719 loss: 6.83456119e-06
Iter: 1720 loss: 6.83098915e-06
Iter: 1721 loss: 6.82748578e-06
Iter: 1722 loss: 6.84187307e-06
Iter: 1723 loss: 6.8267891e-06
Iter: 1724 loss: 6.82264e-06
Iter: 1725 loss: 6.82502423e-06
Iter: 1726 loss: 6.81987785e-06
Iter: 1727 loss: 6.81631809e-06
Iter: 1728 loss: 6.81895835e-06
Iter: 1729 loss: 6.81405299e-06
Iter: 1730 loss: 6.81017127e-06
Iter: 1731 loss: 6.84415863e-06
Iter: 1732 loss: 6.81000711e-06
Iter: 1733 loss: 6.80657195e-06
Iter: 1734 loss: 6.81638448e-06
Iter: 1735 loss: 6.80547328e-06
Iter: 1736 loss: 6.80265111e-06
Iter: 1737 loss: 6.81594838e-06
Iter: 1738 loss: 6.80214225e-06
Iter: 1739 loss: 6.79867e-06
Iter: 1740 loss: 6.81735537e-06
Iter: 1741 loss: 6.798085e-06
Iter: 1742 loss: 6.79644154e-06
Iter: 1743 loss: 6.79877485e-06
Iter: 1744 loss: 6.79565528e-06
Iter: 1745 loss: 6.79330969e-06
Iter: 1746 loss: 6.792352e-06
Iter: 1747 loss: 6.7911642e-06
Iter: 1748 loss: 6.7881042e-06
Iter: 1749 loss: 6.80224412e-06
Iter: 1750 loss: 6.78755669e-06
Iter: 1751 loss: 6.78489778e-06
Iter: 1752 loss: 6.7847086e-06
Iter: 1753 loss: 6.78264041e-06
Iter: 1754 loss: 6.7790952e-06
Iter: 1755 loss: 6.78756669e-06
Iter: 1756 loss: 6.77775552e-06
Iter: 1757 loss: 6.77348362e-06
Iter: 1758 loss: 6.79319601e-06
Iter: 1759 loss: 6.77276421e-06
Iter: 1760 loss: 6.76999343e-06
Iter: 1761 loss: 6.76655463e-06
Iter: 1762 loss: 6.76625768e-06
Iter: 1763 loss: 6.76161244e-06
Iter: 1764 loss: 6.79826735e-06
Iter: 1765 loss: 6.76123545e-06
Iter: 1766 loss: 6.75761e-06
Iter: 1767 loss: 6.77807384e-06
Iter: 1768 loss: 6.75713e-06
Iter: 1769 loss: 6.75381852e-06
Iter: 1770 loss: 6.75641877e-06
Iter: 1771 loss: 6.7518049e-06
Iter: 1772 loss: 6.74980902e-06
Iter: 1773 loss: 6.74925104e-06
Iter: 1774 loss: 6.74799867e-06
Iter: 1775 loss: 6.74641069e-06
Iter: 1776 loss: 6.7463734e-06
Iter: 1777 loss: 6.74359217e-06
Iter: 1778 loss: 6.74827152e-06
Iter: 1779 loss: 6.74238845e-06
Iter: 1780 loss: 6.74011108e-06
Iter: 1781 loss: 6.74806961e-06
Iter: 1782 loss: 6.73952218e-06
Iter: 1783 loss: 6.73721206e-06
Iter: 1784 loss: 6.73912109e-06
Iter: 1785 loss: 6.73593877e-06
Iter: 1786 loss: 6.73326076e-06
Iter: 1787 loss: 6.73355498e-06
Iter: 1788 loss: 6.73118029e-06
Iter: 1789 loss: 6.72785836e-06
Iter: 1790 loss: 6.76341e-06
Iter: 1791 loss: 6.72776105e-06
Iter: 1792 loss: 6.7254291e-06
Iter: 1793 loss: 6.72167243e-06
Iter: 1794 loss: 6.72163515e-06
Iter: 1795 loss: 6.71757607e-06
Iter: 1796 loss: 6.74145303e-06
Iter: 1797 loss: 6.71696716e-06
Iter: 1798 loss: 6.71306589e-06
Iter: 1799 loss: 6.72766282e-06
Iter: 1800 loss: 6.71213138e-06
Iter: 1801 loss: 6.70792815e-06
Iter: 1802 loss: 6.71844282e-06
Iter: 1803 loss: 6.70642612e-06
Iter: 1804 loss: 6.70629561e-06
Iter: 1805 loss: 6.70489408e-06
Iter: 1806 loss: 6.70378722e-06
Iter: 1807 loss: 6.70115242e-06
Iter: 1808 loss: 6.73635304e-06
Iter: 1809 loss: 6.70103418e-06
Iter: 1810 loss: 6.69785913e-06
Iter: 1811 loss: 6.71621638e-06
Iter: 1812 loss: 6.69740393e-06
Iter: 1813 loss: 6.69500514e-06
Iter: 1814 loss: 6.694695e-06
Iter: 1815 loss: 6.69298424e-06
Iter: 1816 loss: 6.68930443e-06
Iter: 1817 loss: 6.70256077e-06
Iter: 1818 loss: 6.68834673e-06
Iter: 1819 loss: 6.68524763e-06
Iter: 1820 loss: 6.68506254e-06
Iter: 1821 loss: 6.68267103e-06
Iter: 1822 loss: 6.67953736e-06
Iter: 1823 loss: 6.71690259e-06
Iter: 1824 loss: 6.67953373e-06
Iter: 1825 loss: 6.6768157e-06
Iter: 1826 loss: 6.67338509e-06
Iter: 1827 loss: 6.67302356e-06
Iter: 1828 loss: 6.66920641e-06
Iter: 1829 loss: 6.67974882e-06
Iter: 1830 loss: 6.66786855e-06
Iter: 1831 loss: 6.66373671e-06
Iter: 1832 loss: 6.68952543e-06
Iter: 1833 loss: 6.66314918e-06
Iter: 1834 loss: 6.65984362e-06
Iter: 1835 loss: 6.67862059e-06
Iter: 1836 loss: 6.6593866e-06
Iter: 1837 loss: 6.65768903e-06
Iter: 1838 loss: 6.65776406e-06
Iter: 1839 loss: 6.65576499e-06
Iter: 1840 loss: 6.65328889e-06
Iter: 1841 loss: 6.65313883e-06
Iter: 1842 loss: 6.65049038e-06
Iter: 1843 loss: 6.6651055e-06
Iter: 1844 loss: 6.65004973e-06
Iter: 1845 loss: 6.64758318e-06
Iter: 1846 loss: 6.64541176e-06
Iter: 1847 loss: 6.64475783e-06
Iter: 1848 loss: 6.64081472e-06
Iter: 1849 loss: 6.66524829e-06
Iter: 1850 loss: 6.64032405e-06
Iter: 1851 loss: 6.63697392e-06
Iter: 1852 loss: 6.63619312e-06
Iter: 1853 loss: 6.63403853e-06
Iter: 1854 loss: 6.63023593e-06
Iter: 1855 loss: 6.64954223e-06
Iter: 1856 loss: 6.6294956e-06
Iter: 1857 loss: 6.62526236e-06
Iter: 1858 loss: 6.63129231e-06
Iter: 1859 loss: 6.62313869e-06
Iter: 1860 loss: 6.6195521e-06
Iter: 1861 loss: 6.61825061e-06
Iter: 1862 loss: 6.61622516e-06
Iter: 1863 loss: 6.61168087e-06
Iter: 1864 loss: 6.6639318e-06
Iter: 1865 loss: 6.61160948e-06
Iter: 1866 loss: 6.60833484e-06
Iter: 1867 loss: 6.62386083e-06
Iter: 1868 loss: 6.60776413e-06
Iter: 1869 loss: 6.60501337e-06
Iter: 1870 loss: 6.61650802e-06
Iter: 1871 loss: 6.60447404e-06
Iter: 1872 loss: 6.6008738e-06
Iter: 1873 loss: 6.61569493e-06
Iter: 1874 loss: 6.60010573e-06
Iter: 1875 loss: 6.59838497e-06
Iter: 1876 loss: 6.59887428e-06
Iter: 1877 loss: 6.5973e-06
Iter: 1878 loss: 6.59446778e-06
Iter: 1879 loss: 6.59316265e-06
Iter: 1880 loss: 6.59180159e-06
Iter: 1881 loss: 6.58801764e-06
Iter: 1882 loss: 6.60944079e-06
Iter: 1883 loss: 6.58747e-06
Iter: 1884 loss: 6.58411864e-06
Iter: 1885 loss: 6.58840054e-06
Iter: 1886 loss: 6.58237877e-06
Iter: 1887 loss: 6.57945748e-06
Iter: 1888 loss: 6.58319732e-06
Iter: 1889 loss: 6.57798228e-06
Iter: 1890 loss: 6.57453938e-06
Iter: 1891 loss: 6.59885836e-06
Iter: 1892 loss: 6.57424243e-06
Iter: 1893 loss: 6.57171495e-06
Iter: 1894 loss: 6.56721568e-06
Iter: 1895 loss: 6.56720204e-06
Iter: 1896 loss: 6.56287739e-06
Iter: 1897 loss: 6.60919977e-06
Iter: 1898 loss: 6.56278416e-06
Iter: 1899 loss: 6.55931126e-06
Iter: 1900 loss: 6.57853e-06
Iter: 1901 loss: 6.55887879e-06
Iter: 1902 loss: 6.55570329e-06
Iter: 1903 loss: 6.56063821e-06
Iter: 1904 loss: 6.55416852e-06
Iter: 1905 loss: 6.5516424e-06
Iter: 1906 loss: 6.55137546e-06
Iter: 1907 loss: 6.55031454e-06
Iter: 1908 loss: 6.54742507e-06
Iter: 1909 loss: 6.57092642e-06
Iter: 1910 loss: 6.54697715e-06
Iter: 1911 loss: 6.54258929e-06
Iter: 1912 loss: 6.56030534e-06
Iter: 1913 loss: 6.54151199e-06
Iter: 1914 loss: 6.53876305e-06
Iter: 1915 loss: 6.54861833e-06
Iter: 1916 loss: 6.5380209e-06
Iter: 1917 loss: 6.53523148e-06
Iter: 1918 loss: 6.5406457e-06
Iter: 1919 loss: 6.53412599e-06
Iter: 1920 loss: 6.53100506e-06
Iter: 1921 loss: 6.52806148e-06
Iter: 1922 loss: 6.52743711e-06
Iter: 1923 loss: 6.52369272e-06
Iter: 1924 loss: 6.58077579e-06
Iter: 1925 loss: 6.52366953e-06
Iter: 1926 loss: 6.52034714e-06
Iter: 1927 loss: 6.51657137e-06
Iter: 1928 loss: 6.5160757e-06
Iter: 1929 loss: 6.51144546e-06
Iter: 1930 loss: 6.52747167e-06
Iter: 1931 loss: 6.5102704e-06
Iter: 1932 loss: 6.50599532e-06
Iter: 1933 loss: 6.55080748e-06
Iter: 1934 loss: 6.50585844e-06
Iter: 1935 loss: 6.50223046e-06
Iter: 1936 loss: 6.5051895e-06
Iter: 1937 loss: 6.49998856e-06
Iter: 1938 loss: 6.49923822e-06
Iter: 1939 loss: 6.49781032e-06
Iter: 1940 loss: 6.49616959e-06
Iter: 1941 loss: 6.49206231e-06
Iter: 1942 loss: 6.52853851e-06
Iter: 1943 loss: 6.49146e-06
Iter: 1944 loss: 6.48740661e-06
Iter: 1945 loss: 6.5285376e-06
Iter: 1946 loss: 6.48722744e-06
Iter: 1947 loss: 6.48473042e-06
Iter: 1948 loss: 6.48322748e-06
Iter: 1949 loss: 6.48216292e-06
Iter: 1950 loss: 6.47797606e-06
Iter: 1951 loss: 6.50448601e-06
Iter: 1952 loss: 6.47748311e-06
Iter: 1953 loss: 6.47375327e-06
Iter: 1954 loss: 6.47153547e-06
Iter: 1955 loss: 6.46999615e-06
Iter: 1956 loss: 6.46497165e-06
Iter: 1957 loss: 6.48045261e-06
Iter: 1958 loss: 6.46355238e-06
Iter: 1959 loss: 6.45746422e-06
Iter: 1960 loss: 6.48035348e-06
Iter: 1961 loss: 6.45605633e-06
Iter: 1962 loss: 6.45217733e-06
Iter: 1963 loss: 6.45034561e-06
Iter: 1964 loss: 6.44852662e-06
Iter: 1965 loss: 6.44326701e-06
Iter: 1966 loss: 6.4466285e-06
Iter: 1967 loss: 6.43984595e-06
Iter: 1968 loss: 6.43480689e-06
Iter: 1969 loss: 6.50566108e-06
Iter: 1970 loss: 6.4347505e-06
Iter: 1971 loss: 6.43143858e-06
Iter: 1972 loss: 6.44512693e-06
Iter: 1973 loss: 6.43073554e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
